abstract,introduction,methodology,results,conclusion,title,author,textdata,literature review
"Vision-language models have achieved impressive performance in aligning visual and textual data, but struggle with compositional reasoning tasks that require understanding the relationship between objects and their context in an image. To address this, we introduce a novel generative method that prompts large vision-language models (VLMs) to depict images and perform compositional reasoning. Our method outperforms embedding-based methods on the Winoground dataset, and further improves accuracy with optimal description prompts. We provide a fine-grained error analysis, highlighting key bottlenecks in understanding image content.","Recent advancements in vision-language models (VLMs) have rapidly accelerated progress in multimodal tasks. Large vision-language encoders learn a joint embedding space for combining visual and textual information. These aligned multimodal embeddings have been widely used for zero-shot image-text retrieval, visual question answering, and image captioning. However, embedding-based methods struggle with compositional reasoning tasks, particularly those evaluated in the recent Winoground task. This task involves understanding the compositional relation between objects in images and their associated captions, highlighting the need for alternative approaches.","To address the limitations of embedding-based methods, we propose a generative approach that utilizes the fine-grained reasoning capabilities of large generative models in comprehending image content and matching corresponding texts. Our method comprises three main steps:

1. **Keyword Detection:** We automatically detect a keyword set from the caption text to guide the VLM in describing the relevant contents of the images.
2. **Keyword-guided Description:** We use a pretrained VLM to generate text descriptions for images based on the extracted keywords. This ensures the VLM focuses on relevant image details for image-text matching.
3. **LLM Reasoning & Explanation:** We prompt a pretrained LLM to perform reasoning on the generated image descriptions and select an answer for Winoground tasks. Additionally, we incorporate an explanation instruction to prompt the LLM to explain its answer selection.","Our generative method, KEYCOMP, achieves a state-of-the-art image score on the Winoground dataset, surpassing the best embedding-based method by a significant 5.1% image score margin. KEYCOMP excels at multi-step reasoning for complex examples and unusual images. Further error analysis reveals a bottleneck in the image description quality of VLMs, which may be improved by selecting the best image descriptions or developing better spatial reasoning capabilities in VLMs.","We present KEYCOMP, a novel generative method that prompts large vision-language models for compositional reasoning. KEYCOMP achieves a new state-of-the-art image score on the Winoground dataset, and demonstrates promising results in complex reasoning and unusual image tasks. The method sheds light on the importance of accurate image description, highlighting the need for further research in VLM-based image understanding. Our findings suggest directions for future work, including effective prompting strategies, spatial reasoning of objects by VLMs, and interpretation of out-of-focus or partial objects by VLMs.",Prompting Large Vision-Language Models for Compositional Reasoning,"Timothy Ossowski, Ming Jiang, Junjie Hu","Prompting Large Vision-Language Models for Compositional Reasoning
Timothy Ossowski1, Ming Jiang3, Junjie Hu1,2
1Department of Computer Science, 2Department of Biostatistics and Medical Informatics
University of Wisconsin, Madison, WI, USA
3 Department of Human-centered Computing, Indiana University, Indianapolis, IN, USA
ossowski@wisc.edu, mj200@iu.edu, junjie.hu@wisc.edu
Abstract
Vision-language models such as CLIP have
shown impressive capabilities in encoding texts
and images into aligned embeddings, enabling
the retrieval of multimodal data in a shared
embedding space. However, these embedding-
based models still face challenges in effectively
matching images and texts with similar visio-
linguistic compositionality, as evidenced by
their performance on the recent Winoground
dataset. In this paper, we argue that this limita-
tion stems from two factors: the use of single
vector representations for complex multimodal
data, and the absence of step-by-step reasoning
in these embedding-based methods. To address
this issue, we make an exploratory step using
a novel generative method that prompts large
vision-language models (e.g., GPT-4) to de-
pict images and perform compositional reason-
ing. Our method outperforms other embedding-
based methods on the Winoground dataset, and
obtains further improvement of up to 10% accu-
racy when enhanced with the optimal descrip-
tion.1 More importantly, we provide a fine-
grained error analysis of our method’s outputs,
highlighting the key bottleneck in understand-
ing image contents by existing VLMs.
1
Introduction
Recent advancements in vision-language models
(VLMs) have rapidly accelerated progress in multi-
modal tasks such as visual question answering (An-
tol et al., 2015) and image captioning (Lin et al.,
2014). Large vision-language encoders such as
CLIP (Radford et al., 2021) and UNITER (Chen
et al., 2020) have been trained to learn a joint em-
bedding space for combining visual and textual in-
formation. These aligned multimodal embeddings
have been widely used for zero-shot image-text re-
trieval (Plummer et al., 2015) and other challenging
multimodal matching tasks (Thrush et al., 2022).
1Code is available at https://github.com/tossowski/
KeyComp.
Notably among these approaches, CACR (Pandey
et al., 2022) and IAIS (Ren et al., 2021) further
improve the multimodal representations by incen-
tivizing relation alignment during pretraining.
Despite remarkable advances, the embedding-
based methods still encounter difficulties in various
compositional reasoning tasks, particularly in the
recent Winoground task (Thrush et al., 2022). This
task evaluates the capability of VLMs to under-
stand the compositional relation among objects in
the images and their associated captions (see details
in §3). One primary limitation of embedding-based
methods is their reliance on compressing intricate
compositional information from an image or a text
into a single vector representation, which typically
emphasizes object encoding but is limited in distin-
guishing the nuanced relationships between objects
and their context in the image and caption. To
address this limitation, we propose an alternative
generative approach that utilizes the fine-grained
reasoning capabilities of large generative models in
comprehending image content and matching corre-
sponding texts. In contrast to traditional generative
methods that train specific modules for visual ques-
tion answering (Wang et al., 2022b; Uehara et al.,
2022), we use a tuning-free prompt-based method.
Specifically, our keyword-guided compositional
reasoning method (KEYCOMP) prompts a VLM
for depicting images based on the keywords de-
tected from the query text, and then uses a stronger
LLM to analyze the image description for match-
ing corresponding texts. Our method design is
mainly based on two considerations. First, our
analysis (§4) shows that directly prompting gener-
ative VLMs like MiniGPT4 (Zhu et al., 2023) or
BLIP-2 (Li et al., 2023) still poses a challenge for
the model in identifying key image and text con-
tents for further reasoning. Thus, proper guidance
is necessary to instruct the VLM to focus on key
image regions for image description. Second, we
believe that existing LLMs (e.g., GPT-4) possess
arXiv:2401.11337v1  [cs.CV]  20 Jan 2024
Keyword-guided Image
Description by VLM
A: Snake eats bird
B: Bird eats snake
A lightbulb
surrounding some
plants
A
B
Keyword Detection
e.g., {bird, snake, eat}
Prompt-based
Reasoning by LLM
Decision
e.g., Cap B/Img B
Text Score Task
Image Score Task
Figure 1: Illustration of our generative method for the
Winoground task. Appendix C shows more detailed
descriptions and model outputs. Text Score Task: Our
method chooses the more appropriate caption given a
single image. Image Score Task: Our method chooses
the best image given a single caption.
A bottle in water
Image Score Task
 Description
Image A: This image
shows a bottle floating in
the water. It appears to be
made of glass and has a
cork in the top ...
Image B: This is a clear
plastic bottle filled with
water. It has a blue cap on
top and is standing upright
on a white surface.
Keyword Detection
{Bottle, Water, In}
Prompt-based
Reasoning 
Select the best image
for the caption
""A bottle in water"".
Think step by step and
start your answer with
A or B.
Decision
A:  The image clearly
shows a glass bottle
partially submerged in
a body of water
A
B
Figure 2: A detailed example for the image score task.
stronger language reasoning capabilities than the
available VLMs, thus we use a LLM for multi-step
reasoning instead of a weaker VLM used in concur-
rent prompting-based methods (You et al., 2023;
Shen et al., 2023; Wu et al., 2023).
We conduct thorough quantitative and qualitative
analyses of our method against existing embedding-
based methods on Winoground. Overall, KEY-
COMP achieves a state-of-the-art image score on
Winoground, surpassing the best embedding-based
method by a clear margin of 5.1% image score. Our
method excels at multi-step reasoning for complex
examples (Fig. 9) and unusual images (Fig. 17).
More importantly, further error analysis of the fail-
ure cases (Appendix G) reveals a bottleneck in the
image description quality of VLMs, shedding in-
sights for future directions. Particularly, VLMs
still struggle with describing spatial reasoning and
LLMs may misinterpret VLM descriptions with
complex syntax structures.
2
Method
This section first describes the Winoground tasks,
and then introduces KEYCOMP in three steps (il-
lustrated in Fig. 1 and Fig. 2).
Problem Definition
Winoground (Thrush et al.,
2022) has two fundamental matching tasks to as-
sess the visio-linguistic compositionality of VLMs.
Given two aligned image-caption pairs (I0, C0)
and (I1, C1), a VLM is asked to select the correct
caption from {C0, C1} for a single image (either I0
or I1) in the text score task. In the image score task,
a VLM is asked to select the correct image from
{I0, I1} for a single caption (either C0 or C1).
Step 1: Keyword Detection
Our method first
detects a keyword set K = {w1, . . . , wk} automat-
ically from the caption text to help guide the VLM
to describe the relevant contents of the images. The
caption text is either a single caption in the image
task or the concatenation of two captions in the text
task. When detecting keywords, we use SpaCY2 to
identify nouns, verbs, prepositions, and adjectives.
The intuition is that nouns in a sentence usually de-
scribe the key entities in the scene, and adjectives
depict the attributes of the entities (e.g., color, size,
shape), while verbs and prepositions usually reveal
a relation between two entities in an image.
Step 2: Keyword-guided Description
Next, we
use a pretrained VLM fVLM such as MiniGPT4 or
BLIP-2 to generate text descriptions for images. To
ensure the VLM focuses on relevant image details
for image-text matching, we use the keywords K to
guide the generation of image descriptions. Specifi-
cally, we append all extracted keywords in K to the
end of a text “[Instruction]” to produce a prompt
PK. The prompt is then used to generate a high-
quality description of the entities and relations for
an image Ia by Eq. (2). Example descriptions and
prompts are presented in Appendix C and D.
PK = “[Instruction] w1, ..., wk”
(1)
DK,a = fVLM(Ia, PK), a ∈ [0, 1]
(2)
Step 3: LLM Reasoning & Explanation
As
LLMs have demonstrated an impressive zero-shot
language reasoning ability (Brown et al., 2020), we
prompt a LLM fLLM to perform reasoning on the
generated image descriptions and the given cap-
tions, and select an answer for Winoground tasks.
Additionally, inspired by recent chain-of-thought
prompting (Wei et al., 2022), we also add another
explanation instruction, such as “Think step by
step"", to prompt the LLM to explain its answer
selection. Specifically, in the image task for se-
lecting the correct image from I0, I1 for a caption
Ca, we construct a prompt Pimg,a by concatenating
2https://spacy.io/
Ca with a selection instruction, the two generated
image descriptions and an explanation instruction.
Similarly, we construct another prompt Ptxt,a for
an image Ia in the text task. Finally, we feed the
prompt to the LLM to get a text output y containing
the selection and the explanation.
Pimg,a = “[T] [Ca] [T] [DK,0] [DK,1] [T]”
(3)
Ptxt,a = “[T] [DK,a] [T] [C0] [C1] [T]”
(4)
y = fLLM(Pt,a), t ∈ {img, txt}
(5)
where all “[T]” placeholders are the texts surround-
ing the key information in the template to construct
the prompt. Appendix B shows all prompt variants.
3
Experimental Settings
Dataset & Evaluation
The Winoground dataset
consists of 400 items, each containing two image-
caption pairs (I0, C0), (I1, C1). While the images
in each item may be completely different, the two
captions {C0, C1} have an identical set of objects,
only in a different order. A model is evaluated by
the following text, image, and group scores.
• Text Score: The model is asked to pick the cor-
responding caption from {C0, C1} for a single
image Ia. The model gets a score of 1 if and only
if it picks the correct caption for both I0 and I1.
• Image Score: The model is asked to pick the
corresponding image from {I0, I1} for a caption
Ca. The model gets a score of 1 if and only if it
picks the correct image for both C0 and C1.
• Group Score: The model achieves a group score
of 1 for the item if and only if it receives a text
score of 1 and an image score of 1.
Methods in Comparison
We compare our gen-
erative method with strong embedding-based meth-
ods, i.e., IAIS (Ren et al., 2021), CACR (Pandey
et al., 2022) and CLIP (Radford et al., 2021). These
methods choose the better caption or image by com-
puting a similarity score between their multimodal
embeddings and selecting the one with the highest
score. In contrast, our generative method generates
a text output for selection. We use string match-
ing on the model output to extract the selection for
evaluation. If the LLM generates an invalid output
(e.g., “Neither”) indicating neither answer matches
the query, we consider the prediction incorrect de-
spite a slight underestimation of our method. Our
experiments show that this invalid output occurs
about 10% of the time in the test set.
Model Selection & Hyperparameters
To pro-
duce higher-quality descriptions of images, we use
an instruction-tuned VLM, i.e., MiniGPT4 (Zhu
et al., 2023) with a backbone LLM of Vicuna-13b.
All descriptions are generated using a temperature
of 1 and a beam size of 10. With a lower beam
size and temperature, we observe notably worse de-
scriptions. For the reasoning component, we utilize
OpenAI’s ChatGPT API with the GPT-3.5-turbo
and GPT-4 models using a temperature of 1 and the
default values of the other hyperparameters.
4
Results and Analysis
Overall Performance
Table 1 reports the overall
text, image, and group scores of our method com-
pared with existing embedding-based approaches.
Since LLMs are generative probabilistic models,
they do not have deterministic outputs. Therefore,
we report the average score across 3 different runs
of the LLM reasoning (Step 3) along with the stan-
dard deviation of our method. We observe several
findings: (1) Most notably, our method achieves a
significantly better image score than prior works,
reaching a new state-of-the-art image score. (2)
Our text and group scores are also competitive
with existing works, even when evaluating accu-
racy with strict string matching. (3) Despite the
stochastic nature of our method, the standard devia-
tion of LLM reasoning between runs rarely exceeds
1 − 2%. (4) However, we observe a significant dif-
ference in the image description quality from the
VLM (Step 2). To estimate an upper bound, we
instruct MiniGPT4 to sample 5 descriptions and
manually select the best image description to feed
into LLMs for reasoning. This leads to a large gain
of 12.4% text score and 3.2% image score, indicat-
ing a potential direction of automatically selecting
the best image descriptions for improvement.
Method
LLM
Text
Image
Group
KEYCOMP ∗
GPT-4
43.5 ± 0.7
28.7 ± 2.1
18.2 ± 0.9
KEYCOMP ∗
GPT-3.5
42.7 ± 0.8
27.8 ± 0.7
17.4 ± 0.3
KEYCOMP
GPT-3.5
30.3 ± 1.6
24.6 ± 1.2
12.4 ± 1.2
IAIS
-
42.5
19.5
16.0
CACR
-
39.3
17.8
14.3
CLIP
-
30.8
10.5
8.0
Table 1: Text, Image, and Group scores scaled by 100 in
Winoground. We report the average scores and standard
deviation in 3 different runs of LLM reasoning (Step 3).
Asterisk indicates an upper bound, where we select the
best caption among 5 generated descriptions.
Image Description Quality Matters.
Fig. 3 dis-
plays the average text score of our method on var-
0
20
40
60
Visually Difficult
5.00%
Ambiguously Correct
7.50%
Unusual Image
10.00%
Unusual Text
10.75%
Complex Reasoning
19.5%
No Tag
43.0%
LXMERT
UNITER
CLIP
KEYCOMP GPT-3.5 (Ours)
KeyCOMP GPT-4* (ours)
Figure 3: Fine-grained text score performance across different question categories. We give specific examples from
each category in Appendix C. Percentages on the x-axis indicate each question type’s proportion of the dataset. To
ensure representative results, question categories comprising less than 5% of the dataset are excluded.
ious question categories curated by Diwan et al.
(2022). We provide correct examples from each
category in Appendix C, D, and the image score
results in Appendix E. Notably, keyword guidance
improves image description quality for generative
approaches. When providing high-quality image
descriptions, our method obtains significant gains
in the categories of unusual images (Fig. 17) and
complex reasoning (Fig. 9). For instance in Fig. 9,
when a VLM depicts a rabbit and a turtle correctly,
the LLM has the commonsense knowledge to pick
the faster one. When prompted with keywords (e.g.,
“people” and “windows”) in Fig. 17, the VLM is
more likely to describe an unusual crayon draw-
ing correctly. This suggests that KEYCOMP has
the potential to surpass embedding-based methods
when external knowledge is necessary for complex
reasoning or when precise image information from
keywords is required for unusual images.
Error Analysis and Findings
We also manually
perform fine-grained error analysis on our method’s
outputs and illustrate three main categories of er-
rors in Appendix G. We identify a bottleneck of
image content understanding capability of VLMs
and highlight three key findings: 1) the VLM often
struggles to describe spatial relationships between
two objects, especially for two objects with similar
colors (e.g., bushes and hedge in Fig. 19); 2) the
LLM occasionally infers the wrong answer due to
the misinterpretation of a detailed VLM description
with a complicated syntax structure (see Fig. 20); 3)
the VLM produces inaccurate descriptions of scene
elements that are out of focus or missing parts of
objects (e.g., a man’s head is outside of Fig. 21).
Prompt and Model Ablations
Table 2 presents
the effect of different prompts on our method. We
observe that guiding VLM output with keywords
results in the most significant improvement ( 2 vs
5 ). Tuning the prompts for ChatGPT ( 3 - 5 ) pro-
vides further gains, suggesting future improvement
with more sophisticated prompting. Prompting the
LLM with chain of thought instructions yields a
small gain of 1.3% text score and 2.3% image score
over a simpler selection prompt ( 5 vs 3 ). Using a
VLM to answer questions directly ( 1 ) leads to in-
ferior performance, with only 2.0 group score and
11.9% lower image score than KEYCOMP. We also
explore different VLM/LLM sizes in Appendix F.
ID
Prompt Method
Text
Image
Group
1
MiniGPT4 end-to-end
20.8 ± 0.3
12.5 ± 1.7
2.0 ± 0.3
2
No Keyword Guidance
21.6 ± 1.0
21.8 ± 0.8
9.4 ± 1.0
3
Multiple Choice
29.0 ± 0.3
22.3 ± 0.4
11.9 ± 0.4
4
Explanation Prompting
26.3 ± 1.3
23.9 ± 1.5
11.5 ± 0.6
5
KEYCOMP
30.3 ± 1.6
24.6 ± 1.2
12.4 ± 1.2
6
Multiple Choice∗
35.2 ± 1.2
27.5 ± 0.7
14.8 ± 0.7
7
Explanation Prompting∗
36.1 ± 0.4
28.8 ± 0.6
15.9 ± 0.6
8
KEYCOMP ∗
42.7 ± 0.8
27.8 ± 0.7
17.4 ± 0.3
Table 2: Average performance and standard deviation of
prompt variants. To isolate the effect of the prompt, the
bottom three rows use the same image description. We
show detailed prompt templates in Appendix B. Aster-
isk indicates an upper bound, where we select the best
caption among 5 generated MiniGPT4 descriptions.
5
Discussion and Future Works
We propose to use VLMs to describe key enti-
ties and relations in images to perform composi-
tional reasoning. We empirically demonstrate the
effectiveness of our method against embedding-
based approaches and end-to-end VLM methods
on Winoground. More importantly, we showcase
successful examples, categorize common errors
made by generative approaches, and identify a key
bottleneck of image content understanding of ex-
isting VLMs. We hope to shed insights into future
works of image content understanding regarding
(1) effective prompting strategies to guide VLMs to
focus on key image regions; (2) spatial reasoning
of objects by VLMs; and (3) accurate interpretation
of out-of-focus or partial objects by VLMs.
Limitations
Our method shows promising results over embed-
ding based methods and end-to-end VLMs. How-
ever, small errors in the early steps can accumulate
and lead to erroneous reasoning. Using VLMs in
a pipeline, as reported by (You et al., 2023), is of-
ten limited by their performance. This bottleneck
explains why we noticed significant improvement
when we manually selected the best descriptions
generated by MiniGPT4. Additionally, designing a
universal prompt for image reasoning can be chal-
lenging, and the optimal prompt may change with
model updates. Appendix B illustrates the effect
of changing prompts, and future work may con-
sider automatic prompt learning techniques such
as prefix tuning (Li and Liang, 2021). Lastly, our
method uses a non-deterministic reasoner, resulting
in slight output variations even with 0 temperature.
Although the variance is low, this may pose issues
for downstream tasks.
References
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc,
Antoine Miech, Iain Barr, Yana Hasson, Karel
Lenc, Arthur Mensch, Katherine Millican, Malcolm
Reynolds, et al. 2022. Flamingo: a visual language
model for few-shot learning. Advances in Neural
Information Processing Systems, 35:23716–23736.
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
garet Mitchell, Dhruv Batra, C Lawrence Zitnick, and
Devi Parikh. 2015. Vqa: Visual question answering.
In Proceedings of the IEEE international conference
on computer vision, pages 2425–2433.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot
learners. Advances in neural information processing
systems, 33:1877–1901.
Jun Chen, Deyao Zhu, Kilichbek Haydarov, Xiang Li,
and Mohamed Elhoseiny. 2023. Video chatcaptioner:
Towards the enriched spatiotemporal descriptions.
arXiv preprint arXiv:2304.04227.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming
Yuan, Henrique Ponde de Oliveira Pinto, Jared Ka-
plan, Harri Edwards, Yuri Burda, Nicholas Joseph,
Greg Brockman, et al. 2021.
Evaluating large
language models trained on code. arXiv preprint
arXiv:2107.03374.
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed
El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and
Jingjing Liu. 2020. Uniter: Universal image-text
representation learning. In Computer Vision–ECCV
2020: 16th European Conference, Glasgow, UK, Au-
gust 23–28, 2020, Proceedings, Part XXX, pages 104–
120. Springer.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. 2009. Imagenet: A large-scale hier-
archical image database. In 2009 IEEE conference
on computer vision and pattern recognition, pages
248–255. Ieee.
Anuj Diwan, Layne Berry, Eunsol Choi, David Harwath,
and Kyle Mahowald. 2022.
Why is winoground
hard? investigating failures in visuolinguistic compo-
sitionality. In Proceedings of the 2022 Conference on
Empirical Methods in Natural Language Processing.
Tanmay Gupta and Aniruddha Kembhavi. 2023. Vi-
sual programming: Compositional visual reasoning
without training. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recog-
nition, pages 14953–14962.
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana
Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen
Li, and Tom Duerig. 2021. Scaling up visual and
vision-language representation learning with noisy
text supervision.
In International Conference on
Machine Learning, pages 4904–4916. PMLR.
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
2023. Blip-2: Bootstrapping language-image pre-
training with frozen image encoders and large lan-
guage models. In International Conference on Ma-
chine Learning.
Liunian Harold Li, Pengchuan Zhang, Haotian Zhang,
Jianwei Yang, Chunyuan Li, Yiwu Zhong, Lijuan
Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, et al.
2022. Grounded language-image pre-training. In
Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition, pages 10965–
10975.
Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:
Optimizing continuous prompts for generation. In
Proceedings of the 2021 Conference of the Associa-
tion for Computational Linguistics.
Tsung-Yi Lin, Michael Maire, Serge Belongie, James
Hays, Pietro Perona, Deva Ramanan, Piotr Dollár,
and C Lawrence Zitnick. 2014.
Microsoft coco:
Common objects in context. In Computer Vision–
ECCV 2014: 13th European Conference, Zurich,
Switzerland, September 6-12, 2014, Proceedings,
Part V 13, pages 740–755. Springer.
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae
Lee. 2023a. Improved baselines with visual instruc-
tion tuning.
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae
Lee. 2023b. Visual instruction tuning.
Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-
Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jian-
feng Gao. 2023. Chameleon: Plug-and-play compo-
sitional reasoning with large language models. arXiv
preprint arXiv:2304.09842.
Oscar Mañas, Pau Rodriguez, Saba Ahmadi, Aida Ne-
matzadeh, Yash Goyal, and Aishwarya Agrawal.
2023. Mapl: Parameter-efficient adaptation of uni-
modal pre-trained models for vision-language few-
shot prompting. In Proceedings of the 17th Confer-
ence of the European Chapter of the Association for
Computational Linguistics.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,
Carroll Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
2022. Training language models to follow instruc-
tions with human feedback.
Advances in Neural
Information Processing Systems, 35:27730–27744.
Rohan Pandey, Rulin Shao, Paul Pu Liang, Ruslan
Salakhutdinov, and Louis-Philippe Morency. 2022.
Cross-modal attention congruence regularization for
vision-language relation alignment. arXiv preprint
arXiv:2212.10549.
Bryan A Plummer, Liwei Wang, Chris M Cervantes,
Juan C Caicedo, Julia Hockenmaier, and Svetlana
Lazebnik. 2015.
Flickr30k entities:
Collecting
region-to-phrase correspondences for richer image-
to-sentence models.
In Proceedings of the IEEE
international conference on computer vision, pages
2641–2649.
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-
try, Amanda Askell, Pamela Mishkin, Jack Clark,
et al. 2021.
Learning transferable visual models
from natural language supervision. In International
Conference on Machine Learning, pages 8748–8763.
PMLR.
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian
Sun. 2015. Faster r-cnn: Towards real-time object
detection with region proposal networks. Advances
in neural information processing systems, 28.
Shuhuai Ren, Junyang Lin, Guangxiang Zhao, Rui Men,
An Yang, Jingren Zhou, Xu Sun, and Hongxia Yang.
2021.
Learning relation alignment for calibrated
cross-modal retrieval. In Proceedings of the Joint
Conference of the 59th Annual Meeting of the Associ-
ation for Computational Linguistics.
Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,
Weiming Lu, and Yueting Zhuang. 2023. Hugging-
gpt: Solving ai tasks with chatgpt and its friends in
huggingface. arXiv preprint arXiv:2303.17580.
Amanpreet Singh, Ronghang Hu, Vedanuj Goswami,
Guillaume Couairon, Wojciech Galuba, Marcus
Rohrbach, and Douwe Kiela. 2022. Flava: A founda-
tional language and vision alignment model. In Pro-
ceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 15638–15650.
Sanjay Subramanian, Medhini Narasimhan, Kushal
Khangaonkar, Kevin Yang, Arsha Nagrani, Cordelia
Schmid, Andy Zeng, Trevor Darrell, and Dan Klein.
2023. Modular visual question answering via code
generation. In Proceedings of the 2023 Conference
of the Association for Computational Linguistics.
Dídac Surís, Sachit Menon, and Carl Vondrick. 2023.
Vipergpt: Visual inference via python execution for
reasoning. arXiv preprint arXiv:2303.08128.
Tristan Thrush, Ryan Jiang, Max Bartolo, Amanpreet
Singh, Adina Williams, Douwe Kiela, and Candace
Ross. 2022. Winoground: Probing vision and lan-
guage models for visio-linguistic compositionality.
In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition, pages 5238–
5248.
Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi,
SM Eslami, Oriol Vinyals, and Felix Hill. 2021. Mul-
timodal few-shot learning with frozen language mod-
els. In Advances in Neural Information Processing
Systems, volume 34, pages 200–212.
Kohei Uehara, Nan Duan, and Tatsuya Harada. 2022.
Learning to ask informative sub-questions for visual
question answering. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recog-
nition, pages 4681–4690.
Peng Wang, An Yang, Rui Men, Junyang Lin, Shuai
Bai, Zhikang Li, Jianxin Ma, Chang Zhou, Jingren
Zhou, and Hongxia Yang. 2022a. Ofa: Unifying ar-
chitectures, tasks, and modalities through a simple
sequence-to-sequence learning framework. In Inter-
national Conference on Machine Learning, pages
23318–23340. PMLR.
Ruonan Wang, Yuxi Qian, Fangxiang Feng, Xiaojie
Wang, and Huixing Jiang. 2022b. Co-VQA : An-
swering by interactive sub question sequence. In
Findings of the Association for Computational Lin-
guistics: ACL 2022, pages 2396–2408, Dublin, Ire-
land. Association for Computational Linguistics.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.
Chain of thought prompting elicits reasoning in large
language models. In Advances in neural information
processing systems.
Chenfei Wu,
Shengming Yin,
Weizhen Qi,
Xi-
aodong Wang, Zecheng Tang, and Nan Duan.
2023. Visual chatgpt: Talking, drawing and edit-
ing with visual foundation models. arXiv preprint
arXiv:2303.04671.
Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin
Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu,
Ce Liu, Michael Zeng, and Lijuan Wang. 2023. Mm-
react: Prompting chatgpt for multimodal reasoning
and action. arXiv preprint arXiv:2303.11381.
Haoxuan You, Rui Sun, Zhecan Wang, Long Chen,
Gengyu Wang, Hammad A Ayyubi, Kai-Wei Chang,
and Shih-Fu Chang. 2023. Idealgpt: Iteratively de-
composing vision and language reasoning via large
language models. arXiv preprint arXiv:2305.14985.
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and
Mohamed Elhoseiny. 2023. Minigpt-4: Enhancing
vision-language understanding with advanced large
language models. arXiv preprint arXiv:2304.10592.
Appendix
A
Related Work
Vision Language Models
Language Models and Vision Models by themselves have shown impressive
performance in their respective tasks, but combining them to perform vision-language reasoning remains
a challenging problem. Popular encoder-based VLMs such as CLIP (Radford et al., 2021) or ALIGN (Jia
et al., 2021) perform contrastive learning on large datasets of image-text pairs, displaying remarkable
zero-shot transfer to unseen tasks such as image classification (Deng et al., 2009) and image-text retreival
(Plummer et al., 2015). GLIP (Li et al., 2022) improves the pretraining stage of CLIP by introducing phrase
level grounding, allowing for richer semantic representations for the object detection task (Ren et al.,
2015). Recent sequence-to-sequence VLMs such as OFA (Wang et al., 2022a) and FLAVA (Singh et al.,
2022) pretrain on a larger variety of vision-language tasks and objectives to allow for more sample-efficient
pretraining and cross-task trasnfer.
Other recent works combine the information from different modalities by introducing lightweight
tunable parameters to connect frozen image and text encoders. Flamingo (Alayrac et al., 2022) freezes a
vision encoder and inserts trainable cross attention layers to a frozen LLM to integrate visual features,
achieving state of the art few-shot performance. BLIP-2 (Li et al., 2023) also freezes a vision encoder and
LLM, aligning the modalities with a lightweight transformer called the Q-former. Works such as Frozen
(Tsimpoukelli et al., 2021) and MAPL (Mañas et al., 2023) propose methods which freeze a LLM, but
train a visual encoder to represent images as continuous embeddings, resulting in a multimodal few-shot
learner. Inspired by the success of instruction tuning LLMs with human feedback with ChatGPT (Ouyang
et al., 2022), MiniGPT4 (Zhu et al., 2023) and LLaVA (Liu et al., 2023b,a) further improves the quality of
BLIP-2 outputs and LLaMA-2 by instruction tuning with additional descriptions generated by ChatGPT.
Large Language Models as Reasoners
Concurrent work has explored the idea of using large lan-
guage models to connect visual foundation models. For example, HuggingGPT (Shen et al., 2023),
CHAMELEON (Lu et al., 2023), MM-React (Yang et al., 2023), and Visual ChatGPT (Wu et al., 2023)
utilize ChatGPT as a controller, allowing it to delegate visually demanding tasks to foundational visual
models. IdealGPT (You et al., 2023) proposes an iterative approach to decompose complex visual tasks
into a series of sub-questions and answers. ChatCaptioner (Chen et al., 2023) has BLIP-2 interact conver-
sationally with ChatGPT to create more informative image descriptions. ViperGPT (Surís et al., 2023),
VisProg, (Gupta and Kembhavi, 2023), and CodeVQA (Subramanian et al., 2023) use code LLMs such
as CodeX (Chen et al., 2021) to write python programs which invoke VLMs to solve challenging visual
tasks without any task-specific training. Different from these works, we replace the ChatGPT controller
with keyword-guided detailed descriptions of the contents of an image, delegating reasoning to a more
powerful LLM instead of a VLM. We also avoid iteratively prompting our models to avoid potential error
accumulation.
B
Prompt Variations
In Tables 3 and 4 we display all the different prompt variations used in our experiments.
Name
VLM Prompt (PK)
ChatGPT Prompt (Ptxt,a)
Performance
KEYCOMP
Describe the image in detail
using these keywords: {keywords}
Select the best caption for this image:
A: {caption_0}
B: {caption_1}
Think step-by-step and start your answer with A or B.
Even if you are unsure make a guess.
30.3
Explanation Prompting
Describe the image in detail
using these keywords: {keywords}
Select the best caption for this image:
A: {caption_0}
B: {caption_1}
Start your answer with A or B.
Even if you are unsure make a guess.
Briefly explain your decision in 1-2 sentences.
26.3
Multiple Choice
Describe the image in detail
using these keywords: {keywords}
Select the best caption for this image:
A: {caption_0}
B: {caption_1}
Start your answer with A or B.
Even if you are unsure make a guess.
29.0
No Keyword Guidance
Describe the image in detail
Select the best caption for this image:
A: {caption_0}
B: {caption_1}
Start your answer with A or B.
Even if you are unsure make a guess.
Briefly explain your decision in 1-2 sentences.
21.6
MiniGPT4 End-to-End
Which caption is more appropriate:
A: {caption_0}
B: {caption_1}
Answer in one sentence.
Even if you are unsure make a guess.
Briefly explain your decision in 1-2 sentences.
None
20.8
Table 3: Average performance of different prompt variants for text score across 3 different runs.
Name
VLM Prompt (PK)
ChatGPT Prompt (Pimg,a)
Performance
KEYCOMP
Describe the image in detail
using these keywords: {keywords}
Statement: {caption}
Image A: {description_0}
Image B: {description_1}
Think step by step and fill in the blank:
Situation {{}} is most consistent with the statement {caption} because ...
24.6
Explanation Prompting
Describe the image in detail
using these keywords: {keywords}
Statement: {caption}
Image A: {description_0}
Image B: {description_1}
Fill in the blank:
Situation {{}} is most consistent with the statement {caption} because ...
Explain your decision in 1-2 sentences.
23.9
Multiple Choice
Describe the image in detail
using these keywords: {keywords}
Image 1: {image_0_description}
Image 2: {image_1_description}
Consider the caption: {caption}
Select the better image for this caption:
A: {image_1}
B: {image_2}
Start your answer with A or B.
22.3
No Keyword Guidance
Describe the image in detail
Statement: {caption}
Image A: {description_0}
Image B: {description_1}
Think step by step and fill in the blank:
Situation {{}} is most consistent with the statement {caption} because ...
21.8
MiniGPT4 End-to-End
Given the following images:
A: <Img>ImageContent</Img>
B: <Img>ImageContent</Img>
Which image is more appropriate
for the caption {caption}?
Answer with A or B.
None
12.5
Table 4: Average performance of different prompt variants for image score across 3 separate runs.
C
Text Score Task for Question Categories
We compile several examples of our method, with one example from each question category defined by a
recent study (Diwan et al., 2022).
Text Score Task
A: Fire Truck
B: Truck Fire
Keyword Detection
{'Fire', 'Truck'}
Description
The image shows a red fire truck
driving down a city street. The
truck has a long ladder on its roof
and a large water tank on its
back. The truck is equipped with
various tools and equipment that
firefighters use to fight fires.
Prompt-Based Reasoning
Select the best caption for the image
A: Fire Truck
B: Truck Fire
Think step by step and start your answer with A or B.
Decision
A: ""It's a fire truck"" is the best caption for this image
as it accurately describes the vehicle shown in the
picture. Option B, ""It's a truck fire,"" is not an accurate
description of the image and could be interpreted as
the truck itself being on fire
Figure 4: Non-Compositional Question. The swapped words (“Fire” and “Truck”) do not necessarily contain the
same semantic entities, so compositional reasoning may not be required to solve the question.
Text Score Task
A: A dog sitting on a couch with a
person lying on the floor
B: A person lying on a couch with
a dog sitting on the floor
Keyword Detection
{'lying', 'dog', 'person',
'couch', 'floor'}
Description
The image shows a woman sitting on
a couch with a dog lying next to her
on the floor. The woman is holding a
cup of coffee and appears to be
relaxing in her living room.
Prompt-Based Reasoning
Select the best caption for the image
A: A dog sitting on a couch with a
person lying on the floor
B: A person lying on a couch with a
dog sitting on the floor
Think step by step and start your
answer with A or B.
Decision
B: ""A person lying on a couch with a dog sitting on the
floor."" The caption accurately describes the image and
correctly identifies the woman as sitting on the couch
rather than lying on the floor.
Figure 5: Ambiguously Correct Question. Note that the correct caption B describes the woman as lying on the
couch when she is sitting, but the LLM is still able to pick the ambiguously correct caption.
Text Score Task
A: The person in the middle is
floating and some others are standing
B: The person in the middle is
standing and some others are floating
Keyword Detection
{'person', 'middle', 'floating',
'standing', 'others'}
Description
The image shows a woman in a black
swimsuit standing in the water with her
arms outstretched. She is surrounded by
other people in swimsuits who are
floating on their backs in the water. The
sky is clear and blue, and there are
mountains in the distance.
Prompt-Based Reasoning
Select the best caption for the image
A: The person in the middle is floating and
some others are standing
B: The person in the middle is standing and
some others are floating
Think step by step and start your answer
with A or B.
Decision
B: ""The person in the middle is standing and some
others are floating."" The image clearly shows the woman
in the center standing with her arms outstretched while
others float on their backs around her.
Figure 6: Visually Difficult Question. To correctly answer, the model needs to identify the person floating on the
right.
Text Score Task
A: There are three
people and two windows
B: There are three
windows and two people
Keyword Detection
{'three', 'two', 'windows', 'people}
Description
The image shows a house with three
people standing in front of it. The house
has two windows on the side and a door
in the front. The roof is sloped and there
is a chimney on top of the house. The
image is drawn with colored pencils on a
white paper.
Prompt-Based Reasoning
Select the best caption for the image
A: There are three people and two windows
B: There are three windows and two people
Think step by step and start your answer with A or B.
Decision
A: ""There are three people and two windows"" is the best
caption for this image because it accurately describes the
number of people and windows in the image. Caption B
describes the opposite of what is shown in the image.
Figure 7: Unusual Image Question. The VLM is more likely to describe an unusual crayon drawing correctly, based
on the detected keywords “windows” and “people” in the prompt, while embedding-based methods are not feasible
to include any hints, and are sensitive to domain shifts in the image distribution.
Text Score Task
A: Some green on the ball
B: The ball on some green
Keyword Detection
{'green', 'ball', 'on'}
Description
The image shows a white golf ball sitting
on the green grass of a golf course. The
background is a lush, green forest with
tall trees in the distance. 
Prompt-Based Reasoning
Select the best caption for the image
A: Some green on the ball
B: The ball on some green
Think step by step and start your answer with A or B.
Decision
B: ""The ball on some green"". This caption accurately
describes the main focus of the image - the golf ball
sitting on the green grass of a golf course.
Figure 8: Unusual Text Question. The caption “The ball on some green"" is considered less common compared to an
alternative such as “the ball on some grass"".
Text Score Task
A: The green one is fast and the
one in white is slow
B: The green one is slow and the
one in white is fast
Keyword Detection
{'green', 'white', 'slow', 'fast}
Description
The image shows a white rabbit
and a turtle standing next to
each other on a white surface.
The turtle's shell is green, while
the rabbit's fur is white.
Prompt-Based Reasoning
Select the best caption for the image
A: The green one is fast and the one in white is slow
B: The green one is slow and the one in white is fast
Think step by step and start your answer with A or
B.
Decision
B: The image shows a turtle and a rabbit standing next
to each other. In general, turtles are slower than
rabbits, so the caption ""the green one is slow and the
one in white is comparatively fast"" makes more sense.
Figure 9: Complex Reasoning Question. This requires the knowledge that rabbits are typically faster than turtles.
Text Score Task
A: A mug in some grass
B: Some grass in a mug
Keyword Detection
{'mug', 'grass', 'in'}
Description
There is a mug sitting on a table
with a small plant growing out of it.
The mug has a cartoon character on
it and the plant is made up of small
blades of grass.
Prompt-Based Reasoning
Select the best caption for the image
A: A mug in some grass
B: Some grass in a mug
Think step by step and start your answer with A or B.
Decision
B: This caption accurately describes the main focus of the
image, which is a small plant growing out of a mug.
Additionally, the caption provides additional details about
the plant being made up of small blades of grass
Figure 10: No Tag Question.
D
Image Score Task for Question Categories
In this section we illustrate the details of our method when applied to the image score task. We include
one example from each question category, using the same image caption pairs used in Appendix C.
Image Score Task
Which image corresponds to the
caption: ""It's a truck fire""?
Keyword Detection
{'fire', 'truck'}
Description
A:The image shows a red fire truck driving
down a city street. The truck has a long
ladder on its roof and a large water tank on
its back. The truck is equipped with various
tools and equipment that firefighters use to
fight fires.
B: The image shows a truck on fire in the
middle of a grassy field. The truck is
completely engulfed in flames, with smoke
billowing out of the windows and the hood. 
Decision
B: Situation B is most consistent with the
statement it's a truck fire because the image
shows a truck that is completely engulfed in
flames, with smoke billowing out of the
windows and the hood. This aligns with the
description of a truck on fire.
Prompt-Based Reasoning
Statement: ""It's a truck fire""
Image A: The image shows a red fire truck driving
down a city street. The truck  has a long ladder on
its roof and a large water tank on its back ...
Image B: The image shows a truck on fire in the
middle of a grassy field. The truck is completely
engulfed in flames, with smoke billowing out of the
windows and the hood. 
Fill in the blank: Situation {{}} is most consistent
with the statement ""It's a truck fire"" because ...
A
B
Figure 11: Non-Compositional Question for the image score task.
Image Score Task
Which image corresponds to the
caption: ""A dog sitting on a couch
with a person lying on the floor""?
Keyword Detection
{'lying', 'dog', 'person',
'couch', 'floor'}
Description
A: The image shows a young girl sitting
on the floor next to a large black dog
that is lying on a couch.
B: The image shows a woman sitting on
a couch with a dog lying next to her on
the floor. The woman is holding a cup of
coffee and appears to be relaxing in her
living room.
Decision
A: Situation A is most consistent with the
statement ""a dog sitting on a couch with a person
lying on the floor"". In the image, there is a dog
sitting on a couch and a person (young girl) lying
on the floor. The position of the dog and the
person align with the statement.
A
B
Prompt-Based Reasoning
Statement: ""A dog sitting on a couch with a person
lying on the floor""
Image A: The image shows a young girl sitting on
the floor next to a large black dog that is lying on a
couch.
Image B: The image shows a woman sitting on a
couch with a dog lying next to her on the floor. The
woman is holding a cup of coffee and appears to be
relaxing in her living room.
Fill in the blank: Situation {{}} is most consistent
with the statement ""A dog sitting on a couch with a
person lying on the floor"" because ...
Figure 12: Ambiguously Correct Question. Refer to Appendix C for the ambiguity contained in image B.
Image Score Task
Keyword Detection
{'person', 'middle', 'floating',
'standing', 'others'}
Description
A: A group of women in swimsuits are floating
on inflatable tubes in the middle of a large
body of water. They are all smiling and having
a good time. In the background, there are
mountains and a clear blue sky.
B: The image shows a woman in a black
swimsuit standing in the water with her arms
outstretched. She is surrounded by other
people in swimsuits who are floating on their
backs in the water. The sky is clear and blue,
and there are mountains in the distance.
Decision
B: Situation B is most consistent with the
statement ""the person in the middle is
standing and some others are floating""
because it describes a woman in a black
swimsuit standing in the water with her arms
outstretched. It also mentions other people in
swimsuits floating on their backs in the water. 
Prompt-Based Reasoning
Statement: ""The person in the middle is standing and
some others are floating""
Image A: A group of women in swimsuits are floating on
inflatable tubes in the middle of a large body of
water. They are all smiling and having a good time ...
Image B: The image shows a woman in a black swimsuit
standing in the water with her arms outstretched. She is
surrounded by other people in swimsuits who are floating
on their backs in the water.
Fill in the blank: Situation {{}} is most consistent with
the statement ""The person in the middle is standing and
some others are floating"" because ...
A
B
Which image corresponds to the
caption: ""The person in the
middle is standing and some
others are floating""?
Figure 13: Visually Difficult Question for the image score task.
Image Score Task
Keyword Detection
{'three', 'two', 'windows', 'people}
Description
A: The image shows a house with three people
standing in front of it. The house has two
windows on the side and a door in the front. The
roof is sloped and there is a chimney on top of
the house. The image is drawn with colored
pencils on a white paper.
B: The image shows a child's drawing of a
house with three windows and two people
standing in front of it. There is a tree in the
front yard and the sun is shining in the
background
Prompt-Based Reasoning
Statement: ""There are three windows and two people""
Image A: The image shows a house with three people
standing in front of it. The house has two windows on the
side and a door in the front. The roof is sloped and there is
a chimney on top of the house. The image is drawn with
colored pencils on a white paper.
Image B: The image shows a child's drawing of a house
with three windows and two people standing in front of it.
There is a tree in the front yard and the sun is shining in
the background
Fill in the blank: Situation {{}} is most consistent with
the statement ""There are three windows and two people""
because ...
Which image corresponds to the
caption: ""There are three people and
two windows""?
Decision
A: Situation A is most consistent with the statement,
""there are three people and two windows"" because in
Image A, there are indeed three people standing in
front of the house, as stated in the statement.
Additionally, Image A specifically mentions that there
are two windows on the side of the house,
corroborating the statement's claim of there being
two windows.
A
B
Figure 14: Unusual Image Question. Although both images are cartoons, both descriptions match the contents of
the images accurately.
Image Score Task
Keyword Detection
{'green', 'ball', 'on'}
Description
A: The image shows a person wearing
black pants and a red shirt, holding a
green bowling ball on a wooden
bowling alley.
B: The image shows a white golf ball
sitting on the green grass of a golf
course. The background is a lush,
green forest with tall trees in the
distance. 
Decision
A: Situation A is most consistent with the
statement ""some green on the ball""
because the image describes a person
holding a green bowling ball. This implies
that there is some green color present on
the ball.
Prompt-Based Reasoning
Statement: ""Some green on the ball""
Image A: The image shows a person wearing
black pants and a red shirt, holding a green
bowling ball on a wooden bowling alley..
Image B: The image shows a white golf ball
sitting on the green grass of a golf course. The
background is a lush, green forest with tall
trees in the distance. 
Fill in the blank: Situation {{}} is most
consistent with the statement ""Some green on
the ball"" because ...
Which image corresponds to the
caption: ""Some green on the ball""?
B
A
Figure 15: Unusual Text question for the image score task.
Image Score Task
Keyword Detection
{'green', 'white', 'slow', 'fast}
Description
A: The image shows a man standing next
to a green muscle car. He is wearing a
white tank top and has his arms crossed in
front of him. The car is a classic muscle car
from the 1960s or 1970s, with a large V8
engine and distinctive body styling.
B: The image shows a white rabbit and a
turtle standing next to each other on a
white surface. The turtle's shell is green,
while the rabbit's fur is white.
Decision
A: Situation A is most consistent with the statement
""the green one is fast and the one in white is
comparatively slow"" because in the image, the green
muscle car is typically associated with speed and
high performance. On the other hand, the man in the
image is wearing a white tank top, which represents
the color mentioned in the statement as being
comparatively slow.
Prompt-Based Reasoning
Statement: ""The green one is fast and the one in
white is comparatively slow""
Image A: The image shows a man standing next to a
green muscle car. He is wearing a white tank top and
has his arms crossed in front of him ...
Image B: The image shows a white rabbit and a turtle
standing next to each other on a white surface. The
turtle's shell is green, while the rabbit's fur is white.
Fill in the blank: Situation {{}} is most consistent
with the statement ""The green one is fast and the one
in white is comparatively slow"" because ...
Which image corresponds to the caption:
""The green one is fast and the one in
white is comparatively slow""?
A
B
Figure 16: Complex Reasoning question for the image score task.
Image Score Task
Keyword Detection
{'mug', 'grass', 'in'}
Description
A: The image shows a white mug sitting on
a patch of green grass in a park. The mug
appears to be made of porcelain and has a
handle on one side and a spout on the
other. The grass is tall and lush, with blades
of green that sway gently in the breeze.
B: There is a mug sitting on a table with a
small plant growing out of it. The mug has
a cartoon character on it and the plant is
made up of small blades of grass.
Decision
A: Situation A is most consistent with the
statement ""there is a mug in some grass""
because the image shows a mug placed on a
patch of green grass in a park. The mug is
made of porcelain, has a handle and a spout,
and it is clearly depicted in the image.
Prompt-Based Reasoning
Statement: ""There is a mug in some grass""
Image A: The image shows a white mug sitting
on a patch of green grass in a park. The mug
appears to be made of porcelain and has a handle
on one side and a spout on the other. The grass is 
...
Image B: There is a mug sitting on a table with a
small plant growing out of it. The mug has a
cartoon character on it and the plant is made up of
small blades of grass.
Fill in the blank: Situation {{}} is most
consistent with the statement ""There is a mug in
some grass"" because ...
Which image corresponds to the caption:
""There is a mug in some grass""?
B
A
Figure 17: NoTag question for the image score task.
E
Fine Grained Image Scores
0
10
20
30
Visually Difficult
5.00%
Ambiguously Correct
7.50%
Unusual Image
10.00%
Unusual Text
10.75%
Complex Reasoning
19.5%
No Tag
43.0%
LXMERT
CLIP
UNITER
KEYCOMP (Ours)
Figure 18: Fine-grained image score performance across different question categories. We give specific examples
from each category in Appendix C. Percentages on the x-axis indicate each question type’s proportion of the dataset.
To ensure representative results, question categories comprising less than 5% of the dataset are excluded.
F
Effect of VLM Size and LLM Size
VLM
Text
Image
Group
MiniGPT-4 7b
23.3
25.5
0.1
MiniGPT-4 13b
30.3
24.6
12.4
Table 5: KEYCOMP performance while changing the size of the VLM image captioner.
LLM
Text
Image
Group
GPT-3.5
30.3
24.6
12.4
GPT-4
44.0
25.9
15.4
Table 6: KEYCOMP performance while changing the size of the LLM used for reasoning.
Tables 5 and 6 show the effect of changing the VLM and LLM sizes respectively. Our results suggest
that changing the LLM size improves text score significantly and offers marginal improvement in image
score. This intuitively makes sense because text score requires a deeper understanding of text to distinguish
between similar captions. Upgrading the VLM also provides improvement to text score, but does not
impact the image score.
G
Error Analysis
In this section, we detail what examples KEYCOMP struggles with and suggest future directions for
generative approaches. We categorize common errors as either VLM-based, LLM-based or both.
G.1
Spatial Reasoning (VLM)
For questions requiring spatial reasoning, we note that KEYCOMP sometimes produces inaccurate
descriptions of the scene. We believe this stems from the image captioning model (VLM) and may be
addressed by utilizing scene understanding models trained with object-relation level supervision.
VLM Prompt: Describe the image using these
keywords: {""behind"", ""bushes"", ""pointy"",
""rectangular""}
VLM Output: The image shows a rectangular
hedge with pointy bushes behind it.
VLM Prompt: Describe the image using these
keywords: {""behind"", ""bushes"", ""pointy"",
""rectangular""}
VLM Output: The image shows a row of pointy
bushes growing behind a rectangular hedge.
Figure 19: Spatial Reasoning Error. As the VLM does not explicitly model the spatial information of objects in an
image, the VLM mistakenly thinks the bushes are behind the hedges in the right image. This is particularly difficult
when two objects have similar colors.
G.2
Incorrect LLM Reasoning
Occasionally the LLM is presented with VLM descriptions that should contain enough information to
answer the question, but still selects the wrong answer. This often occurs when the VLM description has
a complicated syntax structure that involves multiple objects.
Which caption is better for this image? 
A: Circular food on heart-shaped wood
B: Heart-shaped food on circular wood
VLM Prompt: Describe the image using these
keywords: {""circular"", ""wood"", ""food"", ""heart""}
VLM Output: The image shows a woman in an apron
preparing a heart-shaped dish made of circular slices of
food on a wooden table in front of a fireplace.
LLM Output: B: ""heart-shaped food on circular wood""
sounds like the more appropriate caption because the
focus of the image is on the heart-shaped dish made of
circular slices of food on a circular wooden table.
Figure 20: LLM Interpretation Error. Although VLMs provide a sufficiently detailed description, the description
has a complicated syntax structure that involves multiple objects. The LLM response still does not match the VLM
description.
G.3
Describing Out of Focus or Occluded Objects (VLM)
Sometimes the VLM produces inaccurate descriptions of scene elements which are out of focus or missing
parts of objects. In these cases, even though the prompt requires the LLM to choose an option, the LLM
may sometimes refuse to choose, saying it is uncertain and offers a better caption. This makes it hard
to automate the evaluation and may be addressed with further fine-tuning in this instruction format or
additional prompt engineering.
Which caption is better for this image? 
A: The person closer to the camera weightlights and the
person farther from the camera runs
B: The person closer to the camera runs and the person
farther from the camera weightlifts
VLM Prompt: Describe the image using these
keywords: {""person"", ""farther"", ""camera"", ""weightlift"" ""run""}
VLM Output: The image shows a man and a woman
running on a treadmill in a gym. The man is wearing a
blue shirt and black shorts, while the woman is wearing
a black shirt and blue shorts. They are both wearing
athletic shoes and headphones.
LLM Output: Neither A nor B would be an accurate
caption for the described image. Both individuals
described are running on treadmills, not weightlifting. A
more accurate caption could be, ""A man and woman
exercising on treadmills in a busy gym"".
Figure 21: LLM does not give an answer. In this case, the VLM description also does not describe the scene
accurately, likely because the man is out of focus and his head is not visible.
","nanSeveral methods have explored improving the multimodal representations by incentivizing relation alignment during pretraining and further fine-tuning on specific modules for visual question answering. Despite these advances, embedding-based methods still encounter difficulties in compositional reasoning tasks. They often compress intricate compositional information into a single vector representation, emphasizing object encoding but limited in distinguishing the nuanced relationships between objects and their context."
"Nowadays, the diffusion of information through social networks is a powerful phenomenon. A common approach to model diffusions in social networks is the Independent Cascade (IC) model. Given a set of infected nodes according to the IC model, a natural problem is the source detection problem, in which the goal is to identify the unique node that has started the diffusion. Maximum Likelihood Estimation (MLE) is a common approach for tackling the source detection problem, but it is computationally hard. In this work, we propose an efficient method for the source detection problem under the MLE approach, which is based on computing the stationary distribution of a Markov chain. Using simulations, we demonstrate the effectiveness of our method compared to other state-of-the-art methods from the literature, both on random and real-world networks.","In the age of social media, the spread of information and infection through networks is a significant phenomenon. Understanding the dynamic of information spread and its origin are important for a wide range of applications, including marketing, public health, and identification of fake news. The Independent Cascade (IC) is a common model of the spread of information in a social network [5]. In the IC model, the process of diffusion concerns a message that is propagated through the network. Every connection between two friends is associated with a probability; this value determines the probability that if the first user shares the message, the second user will share the message with her friends as well. As commonly occurs in the spread of fake news, the diffusion process starts with a single initial source. A natural goal is that given a set of users who shared a specific message, to seek the unique source that started the diffusion.","The first to formalize the computational problem of finding the source of a diffusion in a network in the IC model are [12]. They show that for arbitrary graphs, the source detection problem is not only NP-hard to find but also NP-hard to approximate. Therefore, they propose an efficient heuristic, but it does not utilize the MLE principle. [22] present a heuristic that utilizes the MLE principle, and they further show that their heuristic outperforms the heuristic of [12]. However, their heuristic requires extensive computation and does not perform very well. In addition, they note that “although the IC model is popular in social network research, finding source in the IC model is rarely studied”. Recently, [2] provide a strong heuristic for finding the source of a diffusion in a network in the IC model.","In this paper, we propose an efficient method that uses the MLE principle for source detection in the IC model. Our method is based on computing the stationary distribution of a Markov chain and is inspired by [11]. Specifically, we recognize that if we represent the social network as a weighted directed graph, the diffusion in the IC model induces a tree that spans the set of users who shared the message, and the root of the tree is the user that initiated the diffusion. In addition, the tree is associated with a weight, which equals to the product of the weights of its edges. In order to estimate the probability of a specific user to be the source, we would like to sum the weights of all spanning tree rooted at this user. However, directly considering all trees is computationally expensive. Therefore, we propose converting the social network into a Markov chain, and the Markov chain tree theorem [13], allows us to compute the sum of the weights of all spanning trees rooted at each user in polynomial time. We consider two approaches for converting the social network to a Markov chain—the self-loops and the no-loops methods. We show that when using a direct calculation of the stationary distribution, both methods compute the exact value of the sum of the weights of all spanning trees rooted at each user, but this is not guaranteed when using a random walk to estimate the stationary distribution.","For future work, we would like to extend our Markov chain approach to settings in which not all weights, edges, or even nodes are known. We note that if there are missing edges or nodes, one must consider all active nodes as possible sources rather than only A’. In addition, we would like to extend our approach to other diffusion models, such as the linear threshold model [9], and the continuous time independent cascade model [10].",Source Detection in Networks using the Stationary Distribution of a Markov Chain,"Yael Sabato, Amos Azaria, Noam Hazon","Source Detection in Networks using the Stationary
Distribution of a Markov Chain
Yael Sabato
Ariel University
yael.sabato@msmail.ariel.ac.il
Amos Azaria
Ariel University
amos.azaria@ariel.ac.il
Noam Hazon
Ariel University
noamh@ariel.ac.il
Abstract
Nowadays, the diffusion of information through social networks is a powerful phenomenon.
One common way to model diffusions in social networks is the Independent Cascade (IC)
model. Given a set of infected nodes according to the IC model, a natural problem is the
source detection problem, in which the goal is to identify the unique node that has started
the diffusion. Maximum Likelihood Estimation (MLE) is a common approach for tackling
the source detection problem, but it is computationally hard.
In this work, we propose an efficient method for the source detection problem under
the MLE approach, which is based on computing the stationary distribution of a Markov
chain. Using simulations, we demonstrate the effectiveness of our method compared to other
state-of-the-art methods from the literature, both on random and real-world networks.
1
Introduction
In the age of social media, the spread of information and infection through networks is a signifi-
cant phenomenon. Understanding the dynamic of information spread and its origin are important
for a wide range of applications, including marketing, public health, and identification of fake
news. The Independent Cascade (IC) is a common model of the spread of information in a social
network [5]. In the IC model, the process of diffusion concerns a message that is propagated
through the network. Every connection between two friends is associated with a probability; this
value determines the probability that if the first user shares the message, the second user will
share the message with her friends as well. As commonly occurs in the spread of fake news, the
diffusion process starts with a single initial source. A natural goal is that given a set of users
who shared a specific message, to seek the unique source that started the diffusion.
There are many approaches to finding the source of a diffusion in the literature, each assuming
different spreading models and various amounts of knowledge of the network parameters (for
example, [12, 6, 23, 11]). When the probabilities associated with the connections are known or
can easily be estimated, a natural mathematical approach for finding the source of the diffusion
is the Maximum Likelihood Estimation (MLE) principle. According to the MLE principle, one
should compute the likelihood of each user being a source, and output the user with the maximum
likelihood.
The first to formalize the computational problem of finding the source of a diffusion in a
network in the IC model are [12]. They show that for arbitrary graphs, the source detection
problem is not only NP-hard to find but also NP-hard to approximate. Therefore, they propose
an efficient heuristic, but it does not utilize the MLE principle. [22] present a heuristic that
utilizes the MLE principle, and they further show that their heuristic outperforms the heuristic
1
arXiv:2401.11330v1  [cs.SI]  20 Jan 2024
of [12]. However, their heuristic requires extensive computation and does not perform very well.
In addition, they note that “although the IC model is popular in social network research, finding
source in the IC model is rarely studied”. Recently, [2] provide a strong heuristic for finding the
source of a diffusion in a network in the IC model.
In this paper, we propose an efficient method that uses the MLE principle for source detection
in the IC model. Our method is based on computing the stationary distribution of a Markov
chain and is inspired by [11]. Specifically, we recognize that if we represent the social network
as a weighted directed graph, the diffusion in the IC model induces a tree that spans the set of
users who shared the message, and the root of the tree is the user that initiated the diffusion. In
addition, the tree is associated with a weight, which equals to the product of the weights of its
edges. In order to estimate the probability of a specific user to be the source, we would like to
sum the weights of all spanning tree rooted at this user. However, directly considering all trees is
computationally expensive. Therefore, we propose converting the social network into a Markov
chain, and the Markov chain tree theorem [13], allows us to compute the sum of the weights
of all spanning trees rooted at each user in polynomial time. We consider two approaches for
converting the social network to a Markov chain—the self-loops and the no-loops methods. We
show that when using a direct calculation of the stationary distribution, both methods compute
the exact value of the sum of the weights of all spanning trees rooted at each user, but this is not
guaranteed when using a random walk to estimate the stationary distribution. For evaluating the
effectiveness of our approach, we use 14 types of random graphs, and sample 1000 graphs from
each type. In addition, we evaluate the effectiveness of our approach on 8 real-world networks,
including a portion of Digg, Facebook, and Twitter. We show that our methods outperform
several baseline methods, including the method proposed by [22] and [2]. We further show that
the no-loops method outperforms the self-loops method when using a random walk to estimate
the stationary distribution.
That is, the no-loops method requires fewer random walk steps
to approach the performance of our methods when using a direct calculation of the stationary
distribution.
2
Related Work
Viral spread of information trough social networks inspired various researchers. The most studied
problem is the Influence Maximization (IM) problem, in which the goal is to find the most
influential node (or set of nodes) in a social network [9]. The source detection problem, which
we focus on, is (in a way) the inverse of the IM problem: instead of finding the node that will
result in the maximal diffusion (i.e., the IM problem), we are given the outcome of a diffusion
that has occurred, and we would like to find the source node that initiated it.
There have been multiple approaches for attempting to solve the source detection problem,
with different models and with different settings, as can be seen in the following reviews [7, 19, 8].
Indeed, most of the prior work consider epidemic models such as the susceptible–infected (SI)
model, and the susceptible–infected–recovery (SIR) model. For example, [16] and [17] consider
the SIR and SI models, respectively, and present algorithms that are based on rumor centrality.
[1] also consider the SI model, and propose an algorithm that is based on geodesic distances on a
randomly-weighted version of the network. [11] consider the SI model, but with an assumption
that some information regarding the edges that participate in the diffusion is provided. Since
they consider the SI model, they assume that the network is undirected and the edges are
unweighted. That is, each user is equally likely to get infected (i.e., receive a message) by each
of her neighbors.
The IC model is the classic information-propagation model, and is widely used in social
2
network research. However, only few papers study the source detection problem with the IC
model.
[12] are the first to formulate the computational problem of finding the source of a
diffusion in the IC model.
They propose an efficient heuristic, which is based on dynamic
programming, but they do not utilize the MLE principle. [22] also consider the IC model, and
show that finding the source of a diffusion is #P-complete. Therefore, they develop a heuristic
that utilizes the MLE principle, and is based on a Markov chain. However, their use of the
Markov chain is completely different from ours. Specifically, they define the states of the Markov
chain as different samples of the network. Their algorithm then perform random walks on the
Markov chain, and for each sample it computes the set of all possible source nodes. Although
their algorithm outperforms the heuristic of [12], it requires extensive computation to do so, and
it does not perform well when compared to our method. Similar to the work of [22], [23] use a
Markov chain in which the states are different samples of the network. However, their model of
diffusion is the linear threshold model, instead of IC. [20] consider the IC model and utilize the
MLE approach, but they study a slightly different problem, the effector detection problem. That
is, instead of trying to find the source of a diffusion, their goal is to find the node that can best
explain the current state of the other nodes. Therefore, given the same input, the solution to the
effector detection problem may be different from the solution to the source detection problem.
Several works have considered the problem of finding multiple sources of diffusion [24, 21, 2].
However, we believe that, in practice, there usually is only a single source. For example, in
epidemics, there is a single patient zero, and it is very unlikely that two people (or more) will
simultaneously develop the exact same disease. Similarly, in fake news, there is a single author
of the news, and in rumor spreading, typically one individual or entity initiates the rumor.
3
Preliminaries
3.1
Directed Rooted Trees
A directed rooted tree is a directed acyclic graph (DAG) whose underlying undirected graph is a
tree, and one of its vertices has been designated the root. An out-tree is a directed rooted tree,
in which all the edges point away from the root. Similarly, an in-tree is a directed rooted tree,
in which all the edges point toward the root. Clearly, we can convert an out-tree into an in-tree
by reversing the directions of the edges. A spanning in-tree/out-tree is an in-tree/out-tree that
spans all vertices of the underlying graph.
3.2
The Diffusion Model
The research on the diffusion of information on social networks has considered several models.
In this paper we focus on the independent cascade model (IC), which is the following. There
is a social network that is represented by a weighted directed graph GN = (VN, EN) with no
self loops, where each user of the social network is represented by a node, every connection
between two users is an edge, and the weights represent the influence probabilities. The process
of diffusion concerns a message that is propagated thorough the social network. During this
process, each node can either be inactive or become active. The diffusion process starts with an
initial source v ∈ VN, which is the first active node. The process then unfolds in discrete steps
according to the following rule. Every node vi ∈ VN that becomes active in step t − 1, attempts
to activate each currently inactive neighbor vj in step t, and only in step t. The probability
that vi succeeds in activating an inactive neighbor vj is pij, which is the weight of the edge
(vi, vj) ∈ EN. We denote by win(vi) the weighted in-degree of a node vi, win(vi) = P
j pji. If
3
multiple neighbors of a vertex v try to activate it at the same time, their attempts are considered
in an arbitrary order. The process runs until no more activations occur.
Note that since each active node is activated by a single parent, the active nodes and activating
edges form an out-tree, which spans the set of active nodes, and the source node is the root of
the tree.
3.3
Markov Chain
A (discrete-time) Markov chain is an infinite sequence of discrete random variables (Xi)∞
i=0. All
variables have the same finite set of possible values, S = {s1, s2, . . . , sk}, which is called the state
set of the Markov chain. The variables of the sequence (Xi)∞
i=0 have the Markov property of
forgetfulness, that is, each variable Xt is dependent only on the previous variable Xt−1, and is
independent of all other previous variables. Moreover, all the variables have the same probability
distribution. Namely, for every t > 0, P(Xt = sit|X1 = si1, X2 = si2, ..., Xt−1 = sit−1) = P(Xt =
sit|Xt−1 = sit−1) = P(Xt+1 = sit|Xt = sit−1), where sij ∈ S. For a pair of states si and sj, let
qij = P(Xt = sj|Xt−1 = si). We call qij the transition probability. Note that Pk
j=1 qij = 1.
A Markov chain can be represented as a weighted directed graph GM = (SM, EM), where
each state is represented by a node. For clarity reasons, we refer to the nodes of SM as states.
There is an edge (si, sj) ∈ EM if the transition probability qij > 0, with a weight of qij. A
random walk on the graph GM is called a Markov process.
3.3.1
Irreducibility
A Markov chain is irreducible if for each pair of states si, sj, there are two directed paths si ⇝ sj
and sj ⇝ si in GM. That is, a Markov chain is irreducible if its graph, GM, is strongly connected.
3.3.2
Stationary Distribution
If the Markov chain is irreducible then the long run average number of visits of the Markov
process to any state si, converges to a number Πi, regardless of the initial state. That is, for
all si ∈ S it holds that Πi = limn→∞ 1
n
Pn−1
t=0 I(Xt = si), where I(·) is an indicator function.
Moreover, Π = (Π1, Π2, . . . , Πn) is a probability distribution over the set of states S, which is
called the Stationary Distribution1. The stationary distribution can be computed in polynomial
time [14]. However, if GM is very large the exact computation of the stationary distribution
may become impractical; in this case, it is common to estimate the stationary distribution by
sampling, i.e., using random walks on the graph.
3.4
Vector Notations
Let V be a vector, V = (V1, V2, . . . , Vn). We denote by ˆV the normalized vector, ˆV = (
V1
Pn
i=1 Vi ,
V2
Pn
i=1 Vi , . . . ,
Vn
Pn
i=1 Vi ).
4
Problem Statement
In this section, we define the source detection problem and present the MLE principle, which
provides a framework for addressing it.
1Some works provide a slightly different definition for the stationary distribution, which requires that the
Markov chain will also be ergodic [3].
4
Definition 1 (Source Detection). Given a social network, GN = (VN, EN), and a set of active
nodes A ⊆ VN at the end of a propagation process that is compatible to the IC diffusion model,
find the source node.
We first note that a source node v must be in A. Moreover, there must be a directed path from
v to each node in A. Let A′ ⊆ A be the set of all nodes that have directed paths to all nodes in
A. Clearly, A′ is strongly connected. In addition, if A′ is the singleton {v} then v is the source
node.
Our approach for identifying the source node is to follow the maximum likelihood principle
[15]. That is, each node is associated with the probability that it is the source, and we select a
node with the maximal probability. Formally, let Ri be the event that vi is the source node, and
let A be the event that the set A is the set of active nodes; A′ is defined similarly for A′. We
would like to solve the following problem:
Definition 2 (ML-Source). Given a social network, GN = (VN, EN), and a set of active nodes
A ⊆ VN at the end of a propagation process according to the IC diffusion model, find the most
likely source node v∗, i.e.,
v∗ = arg maxvi∈VN P(Ri|A).
Note that P(Ri|A) = P (Ri,A)
P (A) , and thus
arg max
vi∈VN P(Ri|A) = arg max
vi∈VN P(Ri, A).
Unfortunately, the ML-Source problem was shown to be computationally hard [22]. Indeed,
the following brute-force procedure computes the exact value of P(Ri, A), in exponential time.
Let GN[A] = (A, E(A)) be the subgraph of GN induced by the set A. That is, E(A) is the set
of edges of GN that have both nodes in A. We consider every subset X ⊆ E(A), and each such
X is associated with a probability for its occurrence:
p(X) =
Y
e∈X
pe ·
Y
e∈E(A)\X
(1 − pe).
Let GX be a graph, GX = (A, X). If there exists an out-tree in GX that spans A and with the
node vi as the root, then the probability p(X) should be added to P(Ri, A). Namely:
P(Ri, A) =
X
X⊆E(A)
I(X, vi) · p(X)
where I(X, vi) is an indicator function that returns 1 if the graph GX has a spanning out-tree
with vi as the root, and 0 otherwise. In order to return the most likely source node, one should
compute the above expression for every vi ∈ A. Moreover, each p(X) can be used more than
once, in the case where GX has multiple spanning out-trees with several roots.
5
The Markov Chain Approach
[11] suggested the Markov chain approach for estimating the probability of a node to be the
source, in their setting. Their main idea is to count for each node v every possible spanning
out-tree, in which v is the root, and for each such out-tree to calculate its occurrence probability.
We adapt the Markov chain approach to our setting, as follows.
For a diffusion that started with a source node vi, and resulted with a set A of active nodes, let
Ti,A be the corresponding spanning out-tree, and let Ti,A be the associated event. We denote by
5
w(T) the weight of a directed rooted tree, w(T) = Q
e∈T pe. A good estimation of the probability
of Ti,A is:
P(Ti,A) ≈ P(Ri) · w(Ti,A).
Note that this is an estimation, since we ignore the edges that are not part of the spanning
out-tree. In order to calculate the probability of a single node vi to be the source, we go over
every spanning out-tree rooted at vi and sum the weights of those out-trees:
P(Ri, A) ≈
X
Ti,A∈OTi,A
P(Ti,A).
where OTi,A is a set of all the out-trees of GN[A] that are rooted at vi and span A. Note that
this summation is also an estimation, since the events Ti,A for every spanning out-tree are not
independent (which can be fixed with an inclusion-exclusion calculation).
For vi ∈ A′, let Γi = P
Ti,A′∈OTi,A′ w(Ti,A′), let Γ = (Γ1, Γ2, . . . , Γ|A′|), We assume that the
prior probability, P(Ri), is equal for every vi ∈ VN. It is also enough to consider A′ instead of
A since P(Ri, A) ∝ P(Ri, A′) (according to [11]). We get that
v∗ ≈ arg max
vi∈A′ Γi.
(1)
Based on this formulation, a naive approach is to compute for each vi ∈ A′ the set OTi,A′,
(using an algorithm for finding all spanning out-trees, e.g. [4]), and to return the node vi that
maximizes Γi. We refer to this approach as the out-tree counting method. Clearly, the out-
tree counting method is (also) computationally expensive, as the size of OTi,A′ is most likely
exponential in |A′|. We thus propose to use the following theorem [13]:
Given a finite state irreducible Markov chain as a directed graph GM = (SM, EM), Let
w(T) = Q
e∈T pe be the weight of a spanning in-tree T ⊆ EM. Let ITi,SM be the set of all
in-trees in EM that have si as their root and span SM. Let Ψi := P
T ∈ITi,SM w(T), let Ψ =
(Ψ1, Ψ2, . . . , Ψn).
Theorem 1. (Markov chain tree theorem)
Given a finite state irreducible Markov chain, For every si ∈ SM, the unique Stationary Distri-
bution Πi equals to ˆΨi. namely:
∀si ∈ SM, Πi = ˆΨi =
Ψi
Pn
j=1 Ψj
(2)
Our approach is based on exploiting the structural similarity between Γ and Ψ. Indeed, let
GN[A′] be the graph GN induced on the set A′, then for every 1 ≤ i ≤ |A′|, Γi is the summation
of weights of spanning out-trees in GN[A′], and Ψi is the summation of weights of spanning
in-trees in a Markov chain. We thus first convert the social network GN[A′] into a Markov chain
GM. This conversion includes the inversion of all the edges. That is, each node vi ∈ GM is
represented by a state si, and each edge (vi, vj) in GN[A′] is converted to an edge (sj, si) in GM.
Therefore, every spanning out-tree in GN[A′] corresponds to a spanning in-tree in GM. We
then compute the complete stationary distribution Π, of the Markov chain GM, obtaining ˆΨ (by
Theorem 1). We then use ˆΨ to restore ˆΓ. Finally, we output the node with the maximal ˆΓ value.
Observe that converting the social graph into a Markov chain must be performed carefully.
Specifically, it requires that the transition probabilities are valid, i.e., for each state si, Pk
j=1 qij =
1. Moreover, it requires that the ˆΓ values can be efficiently restored from ˆΨ.
The stationary distribution Π can be computed in polynomial time, and so can finding the
set A′ (see for example [18]), and the conversation of the social graph into a Markov chain.
Therefore, our heuristic can be efficiently computed.
6
v1
v2
v3
v4
v5
0.1
0.2
0.6
0.3
0.5
(a)
v1
v2
v3
v4
v5
0.1
0.2
0.6
0.3
0.4
0.5
(b)
Figure 1: Graph examples.
6
Conversion Methods
Now we detail how to produce the Markov chain graph GM = (SM, EM). Each node vi ∈ A′ is
represented by a state si ∈ SM, and each directed edge (vi, vj) ∈ E(A′) is represented by the
reversed edge (sj, si) ∈ EM. We get that in the Markov chain, each edge is pointing from a
node to all its possible activators. Therefore, a naive approach for converting the social graph
into a Markov chain is to divide the weights of each edge of the Markov chain, by the sum of all
weights of the incoming edges of the original node. That is, each node vi ∈ A′ is for each edge
(sj, si) ∈ EM set qji =
pij
win(vj).
However, merely normalizing the edge probabilities is not enough, since we lose the distinction
between nodes with different win(·) values. (And clearly, ceteris paribus, a node with a low win(·)
value is more likely to be the source). For example, consider the social network in Figure 1a. In
this example, the possible sources are A′ = {v1, v2, v3, v4}, and the naive normalization assigns
a weight of 1 to all the edges of the Markov chain. This results with a stationary distribution
in which Π1 = Π2 = Π3 = Π4 = 0.25 2. However, when computing the exact probabilities, we
get that p(R1|A′) = p(A′|R1) · p(R1)/p(A′) = 0.1 · 0.3 · 0.6 · 1
z, where z is the same for every Ri.
Similarly, p(R2|A′) = 0.3 · 0.6 · 0.2 · 1
z, p(R3|A′) = 0.6 · 0.2 · 0.1 · 1
z, p(R4|A′) = 0.2 · 0.1 · 0.3 · 1
z.
Thus, z = 0.072 and we the vector of probabilities is (0.25, 0.5, 0.167, 0.083), in which p(Ri|A′)
is in the i-th position. That is, v2 is much more likely than any other node to be the source, but
the naive approach fails to identify v2 as the most likely source node.
We thus present two methods for converting the social graph into a Markov chain, which
consider (among other things) the difference between the win(·) values.
6.1
The Self-Loops Method
In our first approach, Self-loops, after converting all the edges of GN[A′], we add self-loops to
all states. This allows us to normalize the edge probabilities by dividing all of the weights by
the same number. Specifically, let maxin = maxvi∈A′ win(vi) (We compute win in the graph
GN[A′]). The self-loops methods works as follows;
1. Convert each node vi ∈ Gn[A′] into a state si and each edge (vi, vj) into a reversed edge
(sj, si) with qji =
pij
maxin .
2. For each si, add a self loop (si, si) with qii = maxin−win(vi)
maxin
2The Markov chain is SM = {s1, s2, s3, s4} , EM = {(s1, s4), (s4, s3), (s3, s2), (s2, s1)} and all the transition
probabilities equal 1, therefore the stationary distribution is Π = (0.25, 0.25, 0.25, 0.25).
7
s1
s2
s3
s4
0.1
0.6 = 1
6
0.2
0.6 = 1
3
0.6
0.6 = 1
0.3
0.6 = 1
2
0.4
0.6 = 2
3
0.5
0.6 = 5
6
0.3
0.6 = 1
2
0
0.6 = 0
(a)
s1
s2
s3
s4
0.1
0.6 = 1
6
0.2
0.6 = 1
3
0.6
0.6 = 1
0.3
0.6 = 1
2
0.4
0.6 = 2
3
0.4
0.6 = 2
3
0.1
0.6 = 1
6
0.3
0.6 = 1
2
0
0.6 = 0
(b)
Figure 2: The Markov chains that are obtained by applying the self loops method on the graphs
of Figure 1.
3. Compute the stationary distribution Π.
4. ˆΓ is assigned the values of Π.
Clearly, the transition probabilities are valid. We need to show that ˆΓ is restored correctly.
Theorem 2. (Self-loops method)
For the self-loops method, for every 1 ≤ i ≤ |A′| it holds that Ψi = α·Γi, where α is a constant.
In other words, For every node vi ∈ GN[A′], the sum of weights of all out-trees spanning A′ and
rooted at vi, is proportional to the sum of weight of all in-trees in GM that span all states and
are rooted at the corresponding state si.
Proof. Observe that every spanning out-tree T ⊆ GN[A′], with weight w(T) = Q
e∈T pe has a
corresponding spanning in-tree T ′ ⊆ GM with weight w(T ′). In addition, in-trees do not contain
self loops, and have exactly n − 1 edges (where n = |A′|). Therefore,
w(T ′) =
Y
e∈T ′
qe =
Y
e∈T
pe
maxin
=
1
(maxin)n−1 ·
Y
e∈T
pe = α · w(T).
Thus,
Ψi =
X
T ′∈ITi,SM
w(T ′) = α ·
X
T ∈OTi,A′
w(T) = α · Γi.
Clearly, it can be concluded that ˆΨ = ˆΓ. Note that the stationary distribution Π that is
calculated by the self loops method, is equal to ˆΨ (by Theorem 1), and is also equal to ˆΓ.
8
Therefore, by using the self loops method for the conversion and selecting the node vi with the
maximal ˆΓi, we obtain a good estimation for v∗.
To demonstrate the self-loops method and Theorem 2, we consider the social network given in
Figure 1b, which is slightly more complex than the graph in Figure 1a, as it includes an additional
edge between v4 and v2. Now, assume that the set of active nodes is A = {v1, v2, v3, v4, v5}.
Clearly, A′ = {v1, v2, v3, v4}, The self-loop method computes the Markov chain that is shown in
Figure 2a, and the stationary distribution of this Markov chain is Π = (0.125, 0.25, 0.417, 0.208).
Recall that Π = ˆΨ, (according to Theorem 1), and ˆΨ = ˆΓ (according to Theorem 2). Indeed,
using the out-tree counting method for directly calculating the values of Γ leads to the same
result. Specifically, v1 has one possible spanning out-tree with Γ1 = 0.1 · 0.3 · 0.6 = 0.018. v2
has one possible spanning out-tree with Γ2 = 0.3 · 0.6 · 0.2 = 0.036. v3 has two possible spanning
out-tree with Γ3 = 0.6 · 0.2 · 0.1 + 0.6 · 0.2 · 0.4 = 0.06 and v4 has two possible spanning out-tree
with Γ4 = 0.2 · 0.1 · 0.3 + 0.2 · 0.4 · 0.3 = 0.03 Therefore, Γ = (0.018, 0.036, 0.06, 0.03), and ˆΓ
equals Π. Overall, the self-loops method outputs the vertex v3 as the most likely source node.
Note that the precise brute force calculation outputs the values (0.1315, 0.2631, 0.4035,
0.2017), and thus it also determines that v3 is the most likely source node. Furthermore, the
correlation between the exact probabilities to Π is 0.9966.
Returning to the example in Figure 1a, the corresponding Markov chain that is obtained by
the self loops method is shown in figure 2b, and the stationary distribution for this Markov chain
is Π = (0.25, 0.5, 0.167, 0.083). That is, in this example the self-loops method finds the exact
probabilities, since for every sub-graph of GN[A′] there is at most one spanning out-tree.
6.2
The no-loops Method
Recall that the self-loops method returns the exact values of ˆΓ when Π is computed directly.
However, when Π is estimated by sampling, the addition of the self loops to the graph might
require longer random walks, as many of the random steps are “wasted” on the self loops. This,
in-turn, may affect the efficiency of the sampling. Therefore, we present our second method,
no-loops, which does not add self-loops to the states. Instead, it first converts the graph and
computes the edge probabilities using the naive method. Once the stationary distribution Π is
computed, the no-loops method restores the correct ˆΓ values from Π by dividing each Πi by
win(vi) and normalizing the result.
Specifically, the no-loops method is executed as follows:
1. Convert each node vi ∈ Gn[A′] into a state si and each edge (vi, vj) into a reversed edge
(sj, si) with qji =
pij
win(vj).
2. Compute the corresponding stationary distribution Π.
3. Let Πcorr = (Πcorr
1
, . . . , Πcorr
|A′| ), where for every 1 ≤ i ≤ |A′|, Πcorr
i
=
Πi
win(vi).
4. ˆΓ is assigned the values of ˆΠcorr.
We now show that ˆΓ is restored correctly. Indeed, the no-loops method converts the social
network to a Markov chain using the naive method. We show that with this conversion, the
weight of each spanning out-tree is divided by a value that depends only on the root node.
Therefore, in order to restore ˆΓ we must multiply each Πi by this value. Indeed, as we show,
instead of multiplying by this value, it is sufficient to divide by win(vi).
Theorem 3. (No-loops method)
For the no-loops method, for every 1 ≤ i ≤ |A′| it holds that Πcorr
i
= α · Γi, where α is a
constant.
9
Proof. Let T be a spanning out-tree in GN[A′], rooted at vr with weight w(T) = Q
(vi,vj)∈T pij.
Additionally, let T ′ be the spanning in-tree in GM that corresponds to T. Each edge (sj, si) ∈ T ′
has a weight qji =
pij
win(vj). Therefore, the weight of T ′ is:
w(T ′) =
Y
(sj,si)∈T ′
qji =
Y
(vi,vj)∈T
pij
win(vj)
Since in the out-tree T, the root node vr does not have an in-edge, and each of the other nodes
in the out-tree has exactly one in-edge, the denominator is a multiplication of all the win(vi)
values except for win(vr):
w(T ′) =
1
Q
vi∈A′,i̸=r win(vi) ·
Y
(vi,vj)∈T
pij
=
1
Q
vi∈A′,i̸=r win(vi) · w(T).
Dividing both sides by win(vr) gives:
w(T ′)
win(vr) =
w(T)
Q
vi∈A′ win(vi) = α · w(T),
(3)
where α =
1
Q
vi∈A′ win(vi), a value that does not depend on vr.
Now, for Π that is calculated in stage (2) of the no-loops method, we get that for every
1 ≤ i ≤ |A′|, Πi = P
T ′∈ITi,SM w(T ′), according to Theorem 1. Therefore,
Πcorr
i
=
Πi
win(vi) =
X
T ′∈ITi,SM
w(T ′)
win(vi)
=
X
T ∈OTi,A′
α · w(T) = α · Γi.
It can be concluded that ˆΠcorr = ˆΓ. Therefore, by using the no-loops method for the conver-
sion and selecting the node vi with the maximal ˆΓi, we obtain a good estimation for v∗.
To demonstrate the no-loops method and Theorem 3 we return to the example in Figure
1b.
The Markov chain that is obtained by stage (1) of the no-loops method for the social
network graph in 1b, is shown in Figure 3. The stationary distribution of this Markov chain
is Π = (0.0625, 0.3125, 0.3125, 0.3125). Therefore, Πcorr = ( 0.0625
0.2 , 0.3125
0.5 , 0.3125
0.3 , 0.3125
0.6 ). Finally,
after normalization we obtain ˆΠcorr = (0.125, 0.25, 0.417, 0.208), which is equal to the output
we obtained with the self-loops method.
7
Experiments
For the evaluation of the performance of the self-loops and the no-loops methods, and com-
paring it to other baselines heuristics, we use 14 types of directed random graphs that have
diffusion probabilities on their edges3, as well as 9 real-world directed networks from the Social
3Our code for the experiments is available at: [LINK REMOVED DUE TO ANONYMITY REQUIREMENTS]
10
s1
win(v1) = 0.2
s2
win(v2) = 0.5
s3
win(v3) = 0.3
s4
win(v4) = 0.6
0.1
0.5 = 0.2
0.2
0.2 = 1
0.6
0.6 = 1
0.3
0.3 = 1
0.4
0.5 = 0.8
Figure 3: The Markov chain that is obtained by stage (1) of the no-loops method for the social
network graph in 1b.
category of the Konect database4.
Each of the random graphs is composed using the tuple
(n, Density, prange): n is the number of nodes, Density is the probability that a directed edge
exists between any two nodes (vi, vj), and for every directed edge (vi, vj), pij is a random number
uniformly drawn from the range [0, prange]. Table 1 summarizes the parameters of the 14 random
graph types.
Graphs
n
Density
prange
Average no. of edges
G1
500
0.1
0.0416
24957
G2
1000
0.1
0.0204
99,909
G3
2000
0.1
0.0101
399,785
G4
3000
0.1
0.0071
899,721
G5
4000
0.1
0.0052
1,599,576
G6
5000
0.1
0.0041
2,499,461
G7
500
0.0416
0.1
10,404
G8
1000
0.02
0.1
20,022
G9
2000
0.0101
0.1
40,394
G10
3000
0.0067
0.1
60,392
G11
4000
0.0052
0.1
84,185
G12
5000
0.0041
0.1
104,138
G13
10000
0.002
0.1
204,092
G14
15000
0.0013
0.1
304,001
Table 1: Graphs types.
Note that Density and prange are chosen such that the average weighted out-degree of each
node is slightly greater than 1. This encourages the diffusion not to be too small on the one
hand, but not too large (i.e., including almost the entire graph) on the other. Similarly, for the
real-world networks, we ensured that the average weighted out-degree is slightly greater than 1.
For each type of random graph we sampled 1000 graphs, and for each of these sampled
graphs we simulated a single diffusion according to the IC model from a random source node. If
the diffusion resulted in less than 20 active nodes, or if A′ was a singleton, another graph was
sampled. Table 2 summarizes the number of graphs sampled for each type of random graph.
4http://konect.cc/networks/
11
For the real-world networks, we simulated 1000 diffusions, each starting from a randomly
selected source node. If the diffusion resulted in less than 20 active nodes, or if A′ was a singleton,
another diffusion was simulated. Table 3 summarizes the number of diffusions simulated on each
real-world network. Since in the YouTube friends network all diffusions resulted in either too
small a diffusion or |A′| = 1, this network was removed from all further analysis.
Graph type
Total no.
Less than 20
Diffusions
of samples
active nodes
with |A′| = 1
G1
5,232
4,199
33
G2
5,242
4,223
19
G3
5,392
4,370
22
G4
4,432
3,420
12
G5
4,579
3,562
17
G6
5,133
4,114
19
G7
5,223
4,092
131
G8
7,635
6,201
434
G9
10,681
8,755
926
G10
12,631
10,415
1,216
G11
8,401
6,582
819
G12
11,346
9,022
1,324
G13
22,348
18,306
3,042
G14
41,356
34,575
5,781
Table 2: The number of graphs sampled for each type of random graph. Note that since we
require 1000 graph samples with a diffusion with at least 20 active nodes and |A′| > 1, the
total number of samples equals the number of diffusions with less than 20 active nodes plus the
number of diffusions with |A′| > 1 plus 1000.
We evaluate the performance of the self-loops and the no-loops methods, using a direct
calculation of the stationary distribution. In addition, we evaluated these methods when the
stationary distribution is estimated by random walks with 10, 100, 1000, or 10, 000 steps. Finally,
we evaluate the performance of the following baseline methods:
• Naive: The Markov chain approach with the naive conversion method.
• Random: A random selection of a node in A′.
• Max out-degree: The node with the maximal weighted out-degree is selected.
• Min in-degree: The node with the minimal weighted in-degree is selected.
• Max (out/in) degree: The node with the maximal weighted out-degree divided by its
weighted in-degree is selected.
• IM based: For each node, we simulate 1000 diffusions, and the node with the maximal
average size of the active set is selected.
• Maximum arborescence [2]: The node which is the root of the maximum weight span-
ning out-tree (arborescence) is selected.
12
Network name
Total no.
Less than 20
Diffusions
of diffusions
active nodes
with |A′| = 1
Advogato
6,894
5,211
683
Digg
55,160
47,092
7068
Epinion trust
16,362
14,502
860
Facebook friends
8,803
7,566
237
Google plus
440,477
162,966
276,511
Slashdot
23,374
19,446
292
Twitter
50,174
46,329
3,671
Youtube links
32,473
30,396
1,077
Youtube friends
100,000
20,488
79,512
Table 3: The number of diffusions simulated on each real-world network.
Note that in the
YouTube friends network, due to its structure, all diffusions resulted in either too small a diffusion
or |A′| = 1.
G1
G2
G3
G4
G5
G6
G7
G8
G9
G10
G11
G12
G13
G14
Average
Self-loops (direct calc.)
109
101
90
64
78
79
131
150
156
174
95
114
136
160
116.92
10 steps
46
36
39
22
23
35
44
48
59
63
25
47
59
60
43.28
100 steps
69
80
63
46
51
45
92
111
99
108
54
72
99
120
79.21
1000 steps
97
95
82
45
67
71
124
135
153
154
71
95
118
144
103.64
10000 steps
110
103
90
60
76
72
126
154
155
176
86
114
132
171
116.07
No-loops (direct calc.)
109
101
90
64
78
79
131
150
156
174
95
114
136
160
116.92
10 steps
59
66
66
40
41
48
81
97
93
96
52
69
90
110
72
100 steps
96
89
89
61
67
73
116
133
138
155
80
96
123
146
104.428
1000 steps
102
106
81
62
79
69
129
151
154
171
90
113
135
159
114.35
10000 steps
109
104
90
63
82
77
136
149
158
177
95
114
134
160
117.71
Naive
50
36
52
36
30
39
43
47
57
61
22
39
38
61
43.64
Max weight arbo. [2]
79
83
73
49
65
63
115
127
133
160
88
101
127
152
101.07
Random
22
23
14
15
13
13
22
32
32
54
22
34
31
39
26.14
Max out-deg
33
47
35
17
28
26
47
51
51
61
27
40
32
49
38.85
Min in-deg
69
57
46
33
40
51
44
40
40
58
20
36
33
38
43.21
Max (out/in)-deg
78
69
52
36
44
62
75
76
61
69
33
41
38
50
56
IM based
31
47
38
35
18
25
49
52
48
67
20
29
40
53
39.42
Table 4: The number of times in which each method finds the correct source node in the random
graphs. The values are out of 1000 cases in which the number of active nodes is at least 20 and
|A′| > 1.
13
Advogato
Digg
Epinion
Facebook
Google
Slashdot
Twitter
Youtube
Average
trust
friendships
plus
links
Self-loops (direct calc.)
222
451
428
354
125
471
241
486
347.25
10 steps
68
216
161
146
89
246
167
141
154.25
100 steps
86
237
205
170
98
289
230
168
185.375
1000 steps
111
300
270
233
116
358
230
270
236
10000 steps
175
383
363
308
118
418
247
341
294.125
No-loops (direct calc.)
222
451
428
354
125
471
241
486
347.25
10 steps
88
248
216
179
82
301
167
203
185.5
100 steps
132
311
286
252
121
389
253
287
253.875
1000 steps
191
398
384
307
128
444
236
367
306.875
10000 steps
214
441
423
344
126
468
236
441
336.625
Naive
139
172
146
176
78
174
149
131
145.625
Max weight arbo.[2]
136
353
329
278
125
380
184
358
267.875
Random
52
130
98
89
71
137
115
79
96.375
Max out-deg
39
115
82
76
79
130
132
47
87.5
Min in-deg
70
162
125
117
72
155
115
128
118
Max (out/in)-deg
63
132
115
95
86
141
161
154
118.375
IM based
94
309
230
196
120
302
218
273
217.75
Table 5: The number of times in which each method finds the correct source node in the real-
world networks. The values are out of 1000 cases in which the number of active nodes is at least
20 and |A′| > 1.
Figure 4: The average number of times in which the no-loops and the self-loops methods, using
direct calculation and using random walks with various number of steps, find the correct source
node on the random graphs.
14
Figure 5: The average number of times in which the no-loops and the self-loops methods, using
direct calculation and using random walks, find the correct source node on the real-world net-
works.
15
We also evaluate the performance of the method proposed by [22]. However, unfortunately,
this method takes extensive time to run and does not perform as well as our simple heuristics
(max out-degree and min in-degree). Therefore, we do not report these results.
Our results are presented in Tables 4 and 5. As can be observed, the self-loops and no-loops
methods using a direct calculation of the stationary distribution outperform all other methods
(on average). As expected, these methods achieved the exact same results. We note that, at
times, our methods using random walks may perform slightly better than when using the direct
calculation; however, this is only due to the inherent randomness of the problem. Interestingly,
the average |A′| for the random graphs is 196.2, while the average |A′| for the real-world networks
was lower, 126.2. Therefore, the average number of times the methods found the correct source
(successes) in the random graphs is much lower than in the real-world networks.
In addition, it can be observed that the no-loops method using random walks requires fewer
steps than the self-loops method using random walks to approach the performance of our methods
when using a direct calculation of the stationary distribution. This result is further demonstrated
by Figures 4 and 5. This result is in line with our claim in Section 6.2 that the self-loops method
might require longer walks and will thus be less efficient when the stationary distribution is
estimated by sampling.
8
Conclusions and Future Work
In this paper, we study the problem of identifying the source of a given diffusion on a network. We
use the common IC model, and utilize the MLE principle. Our approach is based on computing
the stationary distribution of a Markov chain. Interestingly, with this approach, rather than
computing the likelihood of every node to be the source separately, the values for all nodes
are derived from the same stationary distribution. We propose two approaches for converting
the network to a Markov chain, and demonstrate the effectiveness of one of them, the no-loops
method, even when using random walks to estimate the stationary distribution.
For future work, we would like to extend our Markov chain approach to settings in which not
all weights, edges, or even nodes are known. We note that if there are missing edges or nodes,
one must consider all active nodes as possible sources rather than only A′. In addition, we would
like to extend our approach to other diffusion models, such as the linear threshold model [9], and
the continuous time independent cascade model [10].
References
[1] Agaskar, A., and Lu, Y. M. A fast monte carlo algorithm for source localization on
graphs. In Wavelets and Sparsity XV (2013), vol. 8858, SPIE, pp. 429–434.
[2] Amoruso, M., Anello, D., Auletta, V., Cerulli, R., Ferraioli, D., and Raiconi,
A. Contrasting the spread of misinformation in online social networks. Journal of Artificial
Intelligence Research 69 (2020), 847–879.
[3] Batabyal, A. A. Markov chains: Models, algorithms and applications. Interfaces 36, 6
(2006), 609.
[4] Gabow, H. N., and Myers, E. W. Finding all spanning trees of directed and undirected
graphs. SIAM Journal on Computing 7, 3 (1978), 280–287.
[5] Goldenberg, J., Libai, B., and Muller, E. Talk of the network: A complex systems
look at the underlying process of word-of-mouth. Marketing letters 12, 3 (2001), 211–223.
16
[6] Gomez-Rodriguez, M., Leskovec, J., and Krause, A. Inferring networks of diffusion
and influence. ACM Transactions on Knowledge Discovery from Data (TKDD) 5, 4 (2012),
1–37.
[7] Jiang, J., Wen, S., Yu, S., Xiang, Y., and Zhou, W. Identifying propagation sources
in networks: State-of-the-art and comparative studies. IEEE Communications Surveys &
Tutorials 19, 1 (2016), 465–481.
[8] Jin, R., and Wu, W. Schemes of propagation models and source estimators for rumor
source detection in online social networks: A short survey of a decade of research. Discrete
Mathematics, Algorithms and Applications (2021), 2130002.
[9] Kempe, D., Kleinberg, J., and Tardos, ´E. Maximizing the spread of influence through
a social network. In Proceedings of the ninth ACM SIGKDD international conference on
Knowledge discovery and data mining (2003), ACM, pp. 137–146.
[10] Kim, J., Lee, W., and Yu, H. Ct-ic: Continuously activated and time-restricted inde-
pendent cascade model for viral marketing. Knowledge-Based Systems 62 (2014), 57–68.
[11] Kumar, A., Borkar, V. S., and Karamchandani, N. Temporally agnostic rumor-
source detection. IEEE Transactions on Signal and Information Processing over Networks
3, 2 (2017), 316–329.
[12] Lappas, T., Terzi, E., Gunopulos, D., and Mannila, H. Finding effectors in social
networks. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge
discovery and data mining (2010), pp. 1059–1068.
[13] Leighton, F., and Rivest, R.
Estimating a probability using finite memory.
IEEE
Transactions on Information Theory 32, 6 (1986), 733–742.
[14] Levin, D. A., and Peres, Y.
Markov chains and mixing times, vol. 107.
American
Mathematical Soc., 2017.
[15] Myung, I. J. Tutorial on maximum likelihood estimation. Journal of mathematical Psy-
chology 47, 1 (2003), 90–100.
[16] Shah, D., and Zaman, T. Detecting sources of computer viruses in networks: theory
and experiment.
In Proceedings of the ACM SIGMETRICS international conference on
Measurement and modeling of computer systems (2010), pp. 203–214.
[17] Shah, D., and Zaman, T. Rumors in a network: Who’s the culprit? IEEE Transactions
on information theory 57, 8 (2011), 5163–5181.
[18] Sharir, M. A strong-connectivity algorithm and its applications in data flow analysis.
Computers & Mathematics with Applications 7, 1 (1981), 67–72.
[19] Shelke, S., and Attar, V. Source detection of rumor in social network–a review. Online
Social Networks and Media 9 (2019), 30–42.
[20] Tong, G. A., Li, S., Wu, W., and Du, D.-Z. Effector detection in social networks.
IEEE Transactions on Computational Social Systems 3, 4 (2016), 151–163.
[21] Wang, Z., Wang, C., Pei, J., and Ye, X. Multiple source detection without knowing
the underlying propagation model. In Proceedings of the AAAI Conference on Artificial
Intelligence (2017), vol. 31.
17
[22] Zhai, X., Wu, W., and Xu, W. Cascade source inference in networks: a markov chain
monte carlo approach. Computational social networks 2, 1 (2015), 1–17.
[23] Zhang, L., Jin, T., Xu, T., Chang, B., Wang, Z., and Chen, E. A markov chain
monte carlo approach for source detection in networks. In Chinese National Conference on
Social Media Processing (2017), Springer, pp. 77–88.
[24] Zhu, K., Chen, Z., and Ying, L. Catch’em all: Locating multiple diffusion sources in
networks with partial observations. In Proceedings of the AAAI Conference on Artificial
Intelligence (2017), vol. 31.
18
","nanThere are many approaches to finding the source of a diffusion in the literature, each assuming different spreading models and various amounts of knowledge of the network parameters (for example, [12, 6, 23, 11]). When the probabilities associated with the connections are known or can easily be estimated, a natural mathematical approach for finding the source of the diffusion is the Maximum Likelihood Estimation (MLE) principle. According to the MLE principle, one should compute the likelihood of each user being a source, and output the user with the maximum likelihood."
"In-context learning (ICL) has emerged as an effective method for few-shot learning in natural language processing. Recent studies have found that ICL can store a task's reasoning procedures in the final prompt token, which guides the language model (LLM) to produce the correct answer. However, these studies primarily focus on a single token or treat the entire demonstration as a single unit, overlooking other individual tokens within it. In this work, we aim to locate additional tokens whose representations store valuable task reasoning procedures. We find that template and stopword tokens are the most likely to encode task reasoning procedures. Our further analyses suggest that lexical cues, repetitions, and text formats are the main distinguishing characteristics of these tokens. With our findings, future ICL methods may save on memory usage during inference and allow LLMs to model longer sequences of text.","In-context learning (ICL) has become a popular technique employed with large language models (LLMs) due to its ease of use. However, this method has been shown to be unstable in that slight changes to the in-context demonstrations (i.e., replacing, or reordering) can lead to substantial differences in the final performance. Hence, to improve its stability, recent research has focused on understanding the mechanisms behind ICL. For instance, Hendel et al. (2023) and Todd et al. (2023) find that LLMs can perform target tasks in a zero-shot manner by utilizing the hidden representations of the last prompt token (e.g., "":"", →"", etc.). These studies claim that the reasoning procedure (i.e., mapping, rules, etc.) required to solve a task is encoded in the representations of the last prompt tokens (Hendel et al., 2023). We refer to tokens whose representations encode a task’s reasoning procedure as task-encoding tokens.","In this section, we aim to find the task-encoding tokens in the ICL prompt. We first categorize all the tokens in the prompt into three types: template tokens, stopword tokens (including punctuation tokens, conjunction tokens, etc), and content tokens. Then, we provide supporting evidence from the views of task performance to show that the task reasoning procedures are the most prone to be stored in the representations of template and stopword tokens.","Overall, these results demonstrate that the task reasoning procedures that influence ICL performance are the most prone to be stored in the representations of template tokens and stopword tokens while the content token representations hardly encode them. On the one hand, if we omit the representation of the content words during the inference of the test sample, performance can be maintained at a relatively high level. On the other hand, the representations of the template tokens hold an important position in providing task reasoning procedures, where LLMs could achieve a high-level performance solely using them. If the representations of a few stopword tokens (refer to Appendix A) are further included, the performance is nearly equivalent to that with all the information in the context.","In this paper, our analysis of ICL pinpoints a more precise location for the task-encoding representations. Through a series of comprehensive experiments, we have examined the influential roles of template tokens and stopword tokens within ICL, whose representations may store task reasoning procedures. Our results show that the behaviors of these tokens are primarily related to their characteristics of lexical cues, repetitive patterns, and structural formats, which allow us to partially explain the presence of task-encoding tokens.",Analyzing Task-Encoding Tokens in Large Language Models,"Yu Bai, Heyan Huang, Cesare Spinoso-Di Piano, Marc-Antoine Rondeau, Sanxing Chen, Yang Gao, Jackie Chi Kit Cheung","Analyzing Task-Encoding Tokens in Large Language Models
Yu Bai1∗, Heyan Huang1, Cesare Spinoso-Di Piano2,3,
Marc-Antoine Rondeau2, Sanxing Chen4, Yang Gao1 †, and Jackie Chi Kit Cheung2,3,5
1Beijing Institute of Technology
2Mila – Quebec Artificial Intelligence Institute
3McGill University, 4Duke University 5Canada CIFAR AI Chair
{yubai,hhy63,gyang}@bit.edu.cn
cesare.spinoso-dipiano@mail.mcgill.ca
jackie.cheung@mcgill.ca
Abstract
In-context learning (ICL) has become an effec-
tive solution for few-shot learning in natural
language processing. Past work has found that,
during this process, representations of the last
prompt token are utilized to store task reason-
ing procedures, thereby explaining the working
mechanism of in-context learning. In this pa-
per, we seek to locate and analyze other task-
encoding tokens whose representations store
task reasoning procedures. Supported by ex-
periments that ablate the representations of dif-
ferent token types, we find that template and
stopword tokens are the most prone to be task-
encoding tokens. In addition, we demonstrate
experimentally that lexical cues, repetition, and
text formats are the main distinguishing charac-
teristics of these tokens. Our work provides ad-
ditional insights into how large language mod-
els (LLMs) leverage task reasoning procedures
in ICL and suggests that future work may in-
volve using task-encoding tokens to improve
the computational efficiency of LLMs at in-
ference time and their ability to handle long
sequences.
1
Introduction
In-context learning (ICL) has become a popular
technique employed with large language models
(LLMs) due to its ease of use (Brown et al., 2020).
However, this method has been shown to be unsta-
ble in that slight changes to the in-context demon-
strations (i.e., replacing, or reordering) can lead to
substantial differences in the final performance (Lu
et al., 2022; Zhang et al., 2022). Hence, to im-
prove its stability, recent research has focused on
understanding the mechanisms behind ICL. For in-
stance, Hendel et al. (2023) and Todd et al. (2023)
find that LLMs can perform target tasks in a zero-
shot manner by utilizing the hidden representations
of the last prompt token (e.g., “:”, “means”, etc.).
∗Work in progress.
†Corresponding author.
Test example
Article: Union bosses owe the player ...
Answer: Sport
Normal ICL
ACC: 85.0%
Test example
Article: Union bosses owe the player ...
Answer: Sport
With template token + stopword token representations
ACC: 82.3%
Test example
Article: Union bosses owe the player ...
Answer: Sport
With content token representations
ACC: 24.4%
Template token
representations
Stopword token
representations
Content token
representations
Figure 1: An illustration of the 4-way text classification
performance of Llama 30B on AGNews with different
parts of its 4-shot ICL demonstrations masked with
respect to the attention of the test example. Masking
the representations of what we call the template tokens
(including the next-line token) leads to a significant drop
in performance while masking the content tokens leaves
the performance relatively unchanged.
These studies claim that the reasoning procedure
(i.e., mapping, rules, etc.) required to solve a task
is encoded in the representations of the last prompt
tokens (Hendel et al., 2023). We refer to tokens
whose representations encode a task’s reasoning
procedure as task-encoding tokens.
In this paper, we seek to locate task-encoding
tokens and analyze their characteristics. The mo-
tivations for our investigation are twofold: 1) The
identification of task-encoding tokens offers new
insights into how large language models analyze
and store the reasoning procedures implied in the
arXiv:2401.11323v1  [cs.CL]  20 Jan 2024
demonstrations and apply them to solve the task.
2) Analyzing the characteristics of task-encoding
tokens helps us understand how they are different
from those mainly encode the demonstration con-
tent rather than the task reasoning procedures.
In order to locate the task encoding tokens, we
first categorize all the tokens into three different cat-
egories: template tokens, stopword tokens (includ-
ing punctuation tokens, conjunction tokens, etc.),
and content tokens. We then study the relationship
between the representations of tokens of different
types and the task performance to determine which
tokens are more likely to be task-encoding tokens.
In particular, we ablate the representations of to-
kens of different types from the attention of the test
example and use the observed change in task per-
formance to make conclusions about which types
of tokens are likely to encode task reasoning proce-
dures, shown in Figure 1.
Results of the aforementioned experiments on
six classification tasks provide evidence that tem-
plate tokens and stopword tokens are the most
prone to be task-encoding tokens. As shown by
the results, ablating the representation of template
tokens substantially decreases performance, sug-
gesting that their presence is critical for LLMs to
solve tasks in an ICL setting. Stopword tokens have
a smaller, yet notable, effect on performance which,
when combined with template tokens, can approach
or even surpass the performance of a LLM with
unaltered ICL demonstrations. In contrast, content
tokens have a negligible impact on performance,
suggesting that their representations are mainly en-
coding the demonstration content.
We provide further analyses on task-encoding
tokens to better understand how these tokens are
formed. Firstly, we ablate the representation of
each token in the ICL template from the test ex-
ample attention and find that most of these to-
kens are necessary for preserving the task perfor-
mance. Thus, their representations are likely to
store the task’s reasoning procedure. Notably, in
some datasets, we find that LLMs can still provide
the correct answer in scenarios where the represen-
tations of label tokens, which we define as being
part of the template tokens, are masked from the
test example, broadening the findings of Wang et al.
(2023). Secondly, we investigate three distinguish-
ing characteristics of task-encoding tokens:
Lexical cues Task-encoding tokens have task-
related lexical meanings.
Repetitions Task-encoding tokens appear multiple
times in the ICL prompt.
Text formats Task-encoding tokens format the
ICL prompt into structured text.
Our research indicates that in smaller models task-
encoding tokens are less characterized by their lex-
ical meaning. However, in larger models, ICL per-
formance may significantly decrease without lexi-
cally meaningful task-encoding tokens. In addition,
both the repetitiveness and the structure brought
by task-encoding tokens contribute to task perfor-
mance across all model sizes.
Our work builds upon previous findings and re-
veals that we can identify and characterize the types
of tokens that are most likely to store the task rea-
soning procedures needed for an LLM to perform
ICL. We investigate the characteristics of lexical
cues, repetitions, and text formats related to task-
encoding tokens which allow us to partially explain
the presence of task-encoding tokens. With our
study of task-encoding tokens, future ICL meth-
ods may save on memory usage during inference
by dropping tokens which do not help task perfor-
mance. Moreover, template and stopword acting
as task-encoding tokens show that some token rep-
resentations processed by LLMs may store higher-
level information about the context, potentially al-
lowing them to model longer sequences of text.
2
Related Work
2.1
Working mechanism of in-context
learning
Since the proposal of in-context learning (Brown
et al., 2020), its working mechanism has been ex-
tensively studied by the research community (Min
et al., 2022; Liu et al., 2021; Olsson et al., 2022;
Bhattamishra et al., 2023). Min et al. (2022) sug-
gest that demonstrations primarily provide the la-
bel space, the distribution of the input text, and the
overall format of the sequence for the test example.
They argue that the precise ground truth labels do
not have significant importance. Conversely, Yoo
et al. (2022) propose a differing view, stating that
the impact of the ground truth labels depends on
the experimental configuration. Order sensitivity
is also identified as a problem of ICL(Lu et al.,
2022). Xie et al. (2021) explain ICL as implicit
Bayesian inference, while Akyürek et al. (2022)
explore the learning algorithm using linear mod-
els. Theoretical explanations (Guo et al., 2023; Bai
Notations
Examples
I
Classify the news articles into the categories of World, Sports, Business, and Technology.\n\n
Tin
Article: {Din}\n
Tout
Answer: {Dout}\n\n
Din
1
Radio veteran Karmazin joins Sirius. Sirius Satellite Radio Inc. named former Viacom Inc. president Mel Karmazin
chief executive Thursday, a month after signing talk-show host Howard Stern to lure listeners.
Dout
1
Business
Din
2
Numbers point to NY. NEW YORK - The New York Yankees can achieve two milestones with one more victory:
clinching their seventh straight AL East title and reaching 100 wins in three straight seasons for the first time.
Dout
2
Sports
Final
ICL
Prompt
Classify the news articles into the categories of World, Sports, Business, and Technology.
Article: Radio veteran Karmazin joins Sirius. Sirius Satellite Radio Inc. named former Viacom Inc. president Mel
Karmazin chief executive Thursday, a month after signing talk-show host Howard Stern to lure listeners.
Answer: Business
Article: Numbers point to NY. NEW YORK - The New York Yankees can achieve two milestones with one more
victory: clinching their seventh straight AL East title and reaching 100 wins in three straight seasons for the first time.
Answer: Sports
Table 1: An example of the components of a 2-shot ICL structured prompt in the AGNews dataset.
et al., 2023; Li et al., 2023) and gradient descent
explanations have been proposed to explain ICL.
Yan et al. (2023) propose that repetitive patterns in
in-context learning lead to the reinforcing of token
co-occurrence, affecting the ICL performance in
positive or negative ways. Pan et al. (2023) analyze
the in-context learning process by disentangling it
into task recognition and task learning.
Our work investigates the inference stages of
the LLMs, demonstrating that specific tokens are
most likely to be utilized to store task reasoning
procedures, thereby aiding the processing of the
final test sample.
2.2
Function vectors of in-context learning
Todd et al. (2023) and Hendel et al. (2023) provide
compelling evidence of function vectors that store
task reasoning procedures (e.g., mapping, rules,
etc.) in in-context learning. They probe and ex-
tract the hidden representations of the final tokens
in the prompt. These vectors can then be added
to, or used to replace, the corresponding vectors
in a zero-shot example, achieving results compa-
rable to those obtained when the model uses all
demonstrations as context. Liu et al. (2023) also
propose using an in-context vector to represent the
target task and applying feature shifting to query
examples. They first feed each input and its cor-
responding target separately into an LLM, then
concatenate all the latent states. A PCA method
is applied to derive a vector that is more closely
aligned with the task. Wang et al. (2023) propose
that label words in the demonstration examples
function as anchors by aggregating the information
from previous demonstrations and providing it to
the test example.
All these previous studies either solely focus on
a single token (i.e., the last prediction prompt token
or label token) of the ICL prompt or treat the entire
demonstration as a single unit, neglecting the other
individual tokens within it. Our research builds
upon their observations and reveals that there are
additional specific tokens whose representations
may store valuable task reasoning procedures for
in-context learning, thereby pinpointing a more
precise location for the functional vectors.
3
Preliminaries
3.1
Notations
In-context learning (ICL) is a technique that en-
ables large language models to perform tasks in a
few-shot manner by placing the demonstrations in
the context fed to a large language model (Brown
et al., 2020). In ICL, these demonstrations are lever-
aged to construct a structured prompt that guides
the model in predicting the final answer. Formally,
the structural prompt comprises the following: in-
struction prompts I, template prompts Tin, Tout,
and demonstration prompts Din
i , Dout
i
, where i de-
notes the ith demonstration. Meanwhile, in and
out represent prompts for the input text and output
labels, respectively. These prompts are concate-
nated to form the final ICL prompt, as shown in
Table 1. During inference, the templated version of
the test example (without an answer) is appended to
the ICL prompt and then sent to the large language
model to predict the corresponding answer.
3.2
Experimental Settings
In this section, we describe the experimental setup
for all of our following experiments.
For the datasets, we consider the most widely
used text classification dataset used by previous
studies (Zhao et al., 2021). For topic classification,
we use the 4-way and 14-way datasets AGNews
and DBPedia (Zhang et al., 2015). For textual
entailment, we use the 3-way CB (De Marneffe
et al., 2019) and 2-way RTE dataset (Dagan et al.,
2005). We also use SST2 (Socher et al., 2013) and
TREC (Voorhees and Tice, 2000) for sentiment and
question classification tasks. For each dataset, we
randomly select 4 training demonstrations from
the training set using 15 different random seeds.
For testing, we evaluate each setting on 500 ran-
domly selected test examples. Instruction prompt
I is included in all the different kinds of prompts
since it is essential for enhancing the classification
performance of the model (Yin et al., 2023).
We utilize the 3B, 7B, 13B, and 30B versions of
the Llama model for the large language models, and
all the experiments are conducted using a single
A100 80G GPU. For the 13B and 30B models, we
apply 8-bit quantization to ensure the model fits
into a single GPU. The results are inferred using
the Huggingface Transformers (Wolf et al., 2020).
4
Methodology
In this section, we aim to find the task-encoding
tokens in the ICL prompt. We first categorize all
the tokens in the prompt into three types: template,
stopword and content tokens. Then, we provide
supporting evidence from the views of task perfor-
mance to show that the task reasoning procedures
are the most prone to be stored in the representa-
tions of template and stopword tokens.
4.1
Token types
Intuitively, we categorize our tokens into these
three different types by the structure of the in-
context learning prompt:
Template tokens (TEMP) In defining template to-
kens, we include all the tokens which serve as
templates for the ICL prompt. This collection
of tokens includes the tokens from Tin and
Tout as well as the ones from Dout.
Stopword tokens (STOP) In defining stopword to-
kens, we include all punctuation and conjunc-
Figure 2: An illustrative example of our proposed
method to test if template and stopword tokens are stor-
ing task reasoning procedures. The test sample can
only access partial information (the green part) from the
demonstrations. The red and green parts will change
when we ablate different kinds of tokens.
tion words, such as [:], [,], [.], etc, in the ICL
prompt. We use stopword tokens that appear
in the instructions for convenience, shown in
Appendix A.
Content tokens (CONT) In defining content to-
kens, we include all the tokens from Din ex-
cept for the ones that are already stopword to-
kens. We name these content tokens because
they convey all of the useful and meaningful
information from the ICL demonstrations.
Given this categorization, we conduct ablation
experiments to determine which tokens are more
like to be task-encoding tokens.
4.2
Ablation on token types
To determine which token type has representations
that are more likely to store task reasoning proce-
dures, we design two experiments. The first in-
volves keeping and masking the different kinds of
token representations from the attention of the test
example. The second involves dropping the various
kinds of tokens (i.e., content, template, and stop-
word tokens) from the input tokens. Illustrations of
these two methods are shown in Figure 2.
4.2.1
Representation level ablation
If the representations of certain types of tokens
are storing task reasoning procedures, the model
Models
Setting
AGNews
SST2
TREC
DBPedia
RTE
CB
OpenLlama
3B
CONT
26.2
52.1
30.1
7.4
51.9
37.9
TEMP
56.5
86.7
27.1
62.2
56.4
52.3
STOP
36.7
82.9
32.0
52.4
58.8
56.2
TEMP + STOP
58.2
86.9
27.6
61.9
56.5
51.7
CONT + STOP
41.9
87.2
26.0
56.3
58.5
57.4
TEMP + CONT
62.3
91.0
24.8
62.9
57.1
51.1
Zero-shot
22.0
20.0
23.6
5.4
44.4
1.8
Normal ICL
63.7
91.2
21.9
61.9
57.4
52.0
Llama
7B
CONT
32.4
57.9
42.5
12.5
55.5
46.1
TEMP
70.8
90.2
58.4
66.2
66.3
73.5
STOP
57.3
83.7
49.8
43.0
55.9
50.7
TEMP + STOP
77.9
91.5
58.5
66.5
67.8
74.4
CONT + STOP
64.5
84.1
54.0
58.0
56.8
54.3
TEMP + CONT
80.4
94.6
61.1
68.0
67.2
72.0
Zero-shot
25.0
29.2
41.4
0.0
54.2
3.6
Normal ICL
82.4
94.3
63.5
68.7
68.6
71.3
Llama
13B
CONT
27.7
52.4
33.5
10.9
61.7
41.7
TEMP
80.0
92.3
58.6
76.9
68.5
47.7
STOP
72.2
73.5
46.8
50.7
58.6
30.6
TEMP + STOP
81.4
93.1
58.9
75.7
69.6
45.1
CONT + STOP
74.1
80.0
46.5
30.6
58.3
25.4
TEMP + CONT
81.2
94.1
59.3
76.9
69.2
40.6
Zero-shot
59.0
18.0
37.0
0.0
0.0
0.0
Normal ICL
81.6
94.3
60.0
76.1
70.6
39.9
Llama
30B
CONT
24.4
61.7
62.1
10.5
65.2
63.6
TEMP
80.5
95.2
65.2
75.2
79.0
80.0
STOP
72.9
92.7
66.7
69.1
69.6
63.0
TEMP + STOP
82.3
95.4
64.9
76.1
80.4
82.0
CONT + STOP
76.6
93.9
61.2
72.7
70.3
59.6
TEMP + CONT
84.3
95.6
65.7
77.6
78.6
81.8
Zero-shot
70.2
88.6
60.6
30.2
58.1
19.6
Normal ICL
85.0
96.5
68.1
78.4
78.5
83.3
Table 2: The accuracy results from the representation
level ablation study. All values are presented as percent-
ages. The best results are bold.
should perform the target task adequately with only
these token representations. In this section, we pro-
cess the entire ICL prompt token sequence, then
allow the test sample to see the representations of
only some specific tokens in the demonstrations to
determine whether these representations are storing
reasoning procedures, illustrated in the upper part
of Figure 2. Specifically, we ablate representations
of all three different kinds of tokens by only retain-
ing or only masking each one of them separately
from the attention of the test sample (e.g., CONT,
TEMP + STOP, and etc). Since Dout is proved to be
important (Wang et al., 2023), we keep the repre-
sentations of Dout for every kind of tokens. Results
are shown in Table 2.
Overall, these results demonstrate that the task
reasoning procedures that influence ICL perfor-
mance are the most prone to be stored in the rep-
resentations of template tokens and stopword to-
kens while the content token representations hardly
encode them. On the one hand, if we omit the
representation of the content words during the in-
ference of the test sample, performance can be
maintained at a relatively high level. On the other
hand, the representations of the template tokens
hold an important position in providing task rea-
soning procedures, where LLMs could achieve a
high-level performance solely using them. If the
Models
Settings
AGNews
SST2
TREC
DBPedia
RTE
CB
OpenLlama
3B
w/o CONT
31.5
63.0
40.6
25.4
56.1
48.9
w/o STOP
64.4
91.5
20.9
62.3
57.8
52.6
Llama
7B
w/o CONT
55.2
67.2
42.6
50.8
57.4
56.3
w/o STOP
82.3
93.8
64.1
69.7
66.5
70.0
Llama
13B
w/o CONT
78.8
81.7
45.3
75.1
55.1
54.5
w/o STOP
82.5
92.5
61.5
76.5
69.6
40.5
Llama
30B
w/o CONT
74.0
89.6
67.0
73.0
69.8
49.0
w/o STOP
85.3
96.4
66.9
77.9
77.7
81.3
Table 3: The token-level ablation study results are dis-
played. Models without template tokens, consistently
yielding an accuracy of 0%, could not predict any cor-
rect answers and are thus omitted from this table.
representations of a few stopword tokens (refer to
Appendix A) are further included, the performance
is nearly equivalent to that with all the information
in the context.
Rare exception cases appear when performance
is relatively poor using normal ICL (e.g., OpenL-
lama 3B in TREC). In some cases, masking the
representations of the content tokens brings even
better performance than the normal ICL method,
which is possibly due to the elimination of noisy
information in the demonstration content. Another
interesting observation is that the results of TEMP
+ STOP and TEMP + CONT are almost at the same
level. This indicates that the representation of stop-
word tokens might contain some information from
their preceding content tokens. We suggest that this
could provide insights into the future direction of
long-sequence modeling and leave the verification
of this hypothesis to future work.
4.2.2
Token level ablation
In this section, we modify the ICL prompt by
removing certain types of tokens from both the
demonstrations and the test example to determine
the extent to which final performance relies on tem-
plate tokens. The method is illustrated in the lower
part of Figure 2. When we ablate the template
tokens, we preserve the answer and next-line to-
kens in the templates to maintain a basic separator
between the articles and answers. Results are pre-
sented in Table 3.
Evidently, if we remove the template tokens, the
model loses its ability to generate an answer, even
if there remain all the demonstration-answer pairs
with a next-line token, resulting in a task accuracy
performance of 0%. This is contrary to what pre-
vious work claims that it is sufficient to place the
LLM in the right space of input text types (Min
et al., 2022). However, if we add back the last
prompt token (the indicator token in a normal tem-
Models
Settings
AGNews
SST2
TREC
DBPedia
RTE
CB
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
OpenLlama
3B
Dout
45.1
34.5
87.2
82.3
32.9
31.3
58.5
50.7
56.6
58.1
55.8
53.6
Tin + Dout
34.6
32.7
86.9
82.3
28.2
31.2
55.5
54.1
58.3
59.2
55.4
58.3
Tout + Dout
50.3
47.1
85.7
84.4
28.9
24.4
57.7
57.7
56.5
56.1
53.2
55.2
Tin + Tout + Dout
56.5
47.4
86.7
83.7
27.1
26.5
62.2
59.8
56.4
56.0
52.3
56.1
Llama
7B
Dout
62.6
48.5
87.9
82.5
48.3
49.4
59.4
52.7
57.5
54.9
62.5
50.8
Tin + Dout
50.8
48.6
84.9
82.8
46.0
50.2
57.9
55.2
56.7
56.7
66.2
64.5
Tout + Dout
62.7
55.1
91.6
87.1
52.8
43.3
61.6
61.8
58.9
56.5
59.2
55.7
Tin + Tout + Dout
70.8
57.3
90.2
87.1
58.4
46.7
66.2
63.8
66.3
59.5
73.5
69.6
Llama
13B
Dout
77.5
72.0
87.8
75.1
56.7
46.0
73.3
31.6
63.4
58.4
38.0
27.5
Tin + Dout
72.0
72.1
81.1
75.9
47.1
48.3
60.3
35.5
61.2
58.4
36.2
36.0
Tout + Dout
79.9
76.3
91.5
88.9
55.1
47.8
75.8
70.7
65.5
59.0
35.7
24.5
Tin + Tout + Dout
80.0
76.2
92.3
89.1
58.6
54.0
76.9
71.4
68.5
59.8
47.7
35.0
Llama
30B
Dout
77.8
65.7
94.2
92.1
63.3
67.1
70.3
68.4
74.7
68.5
69.2
64.6
Tin + Dout
69.2
69.5
93.9
92.9
62.1
66.2
71.3
70.1
72.8
70.0
67.4
63.5
Tout + Dout
78.7
71.5
95.2
92.8
68.1
67.7
75.1
73.8
77.4
75.4
73.3
62.3
Tin + Tout + Dout
80.5
75.0
95.2
93.3
65.2
66.7
75.2
73.5
79.0
77.1
80.0
70.7
Table 4: Ablation results for different template token representations. All values are presented as percentages. Best
results are bold.
Models
Settings
AGNews
SST2
TREC
DBPedia
RTE
CB
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
with “:”
w/o “:”
OpenLlama
3B
Tin
36.3
35.5
83.0
83.4
43.2
41.9
16.3
18.7
54.4
56.8
1.2
4.2
Tout
42.2
52.2
18.5
79.9
39.7
42.2
22.6
22.5
49.8
57.1
3.1
6.5
Tin + Tout
41.5
54.6
14.3
73.2
36.5
42.0
29.4
21.7
24.7
45.7
0.7
3.5
Llama
7B
Tin
21.4
12.7
86.2
66.5
54.4
55.6
0.0
0.0
56.0
55.6
39.4
35.1
Tout
46.1
50.6
61.9
55.1
43.5
44.7
0.0
0.2
43.7
49.9
27.1
26.5
Tin + Tout
50.4
56.6
68.2
56.1
55.3
48.5
0.2
1.3
40.7
42.5
28.5
18.8
Llama
13B
Tin
79.2
77.7
77.5
47.5
56.8
43.2
0.0
0.0
54.8
53.7
4.3
2.4
Tout
72.9
76.6
83.0
89.5
45.5
48.4
0.0
0.0
53.6
52.8
16.0
20.1
Tin + Tout
66.9
77.0
65.6
87.9
51.8
53.1
0.1
0.1
57.5
53.7
16.7
21.9
Llama
30B
Tin
69.5
74.3
92.6
92.8
70.0
70.8
42.0
20.3
67.0
61.3
23.1
18.5
Tout
72.9
72.4
29.2
87.4
65.6
70.9
14.9
37.9
70.6
67.8
19.9
21.1
Tin + Tout
77.3
78.2
17.3
88.9
65.4
69.3
31.0
41.7
71.8
65.8
23.8
23.0
Table 5: Ablation results for different template token representations without the answer label token representations.
All values are presented as percentages. Best results are bold.
plate before producing the answer, e.g., “:”, “→”,
“means”, etc) after the next-line token, the results
would be back to a normal level due to the intro-
duction of a template token. In these experiments,
removing the stopwords does not significantly im-
pact the final performance. These experiments fur-
ther demonstrate the importance of the template
tokens. Notably, even without information from
demonstrations, the model can still acquire limited
predictive ability.
5
Analyses of task-encoding tokens
In this section, we provide analyses of the previ-
ously mentioned task-encoding tokens. We focus
on the template tokens since their representations
are the most prone to storing reasoning procedures
and maintaining task performance. The analyses in-
clude the effects of different task-encoding tokens
on the final performance and the distinguishing
characteristics of the task-encoding tokens.
5.1
Effects of different task-encoding tokens
In Section 4.2.2, we found that for the ICL, the in-
dicator token and Dout are necessary for producing
results. This circumstance raises the question: is
the indicator and the answer token the only active
component for storing information pertaining to the
task reasoning procedures, or do other tokens in the
template also matter? To answer this question, we
examine the performance of the model when the
test example is allowed to attend only to specific
tokens of the ICL template.
5.1.1
Representation ablation with label token
First, we examine the effect on the performance
of Tin, Tout, and Dout along with or without the
indicator token “:” by removing or retaining their
representations from the attention of the test exam-
ple, similar to Section 4.2.1. The results of this
experiment are presented in Table 4.
We find that for most of the cases, the indicator
and the Dout provide the major information for the
final prediction, which is consistent with previous
work (Todd et al., 2023; Wang et al., 2023). More-
over, other parts of the template text, especially
Tout, could also bring a large improvement in per-
formance in most of the cases. This proves that all
of the tokens in the template contribute to the final
performance in most cases.
Settings
Notations
Examples
Randomfixed
Tin
dsafjkldafdsajk: {Din}\n
Tout
reqwiorewsdafjl: {Dout}\n\n
Swap
Tin
Answer: {Din}\n
Tout
Article: {Dout}\n\n
Randomsame
Tin
fdafdasjklfdadf: {Din}\n
Tout
fdafdasjklfdadf: {Dout}\n\n
Randomnonfixed
Tin
1
dsafjkldaasdfjkl: {Din}\n
Tout
1
xiadfjdsalgfweqrjl: {Dout}\n\n
Tin
2
ewqroudajfsdafq: {Din}\n
Tout
2
yufoufgaddavfdnsl: {Dout}\n\n
Tin
3
eqdashcxzlreqguio: {Din}\n
Tout
3
afdgvcxjlzxnvxzla: {Dout}\n\n
Tin
4
cxzvadeqrczxdsa: {Din}\n
Tout
4
fgsgfskjvcdafds: {Dout}\n\n
Tin
t
vcxnkfgahvczxkl: {Din}\n
Tout
t
dafhglajfdvcaol: {Dout}\n\n
Table 6: An example of the random ICL template used
in AGNews. A “:” is attached to each random string
template.
5.1.2
Representation ablation without label
token
To further investigate the influence of the answer
label token Dout while demystifying the effect of
Tin and Tout, we include another set of experi-
ments where all the Dout tokens are removed from
the attention of test examples, shown in Table 5.
In this case, the performance becomes less stable,
where adding a token (e.g., “:”) could not always
bring improvements. However, we find that in AG-
News, TREC, and RTE datasets, the model could
still achieve relatively high performance while the
model outperforms the zero-shot baselines in other
datasets (except in DBPedia). This broadens the
conclusions of previous work where the answer
token is being the information anchor (Wang et al.,
2023), that representations of other template to-
kens could also perform similarly. The result also
emphasizes that representations of tokens besides
Dout and the last prompt token in the ICL template
also have a major impact on the final performance.
5.2
Characteristics of task-encoding tokens
To gain a deeper understanding of the presence
of task-encoding tokens and to use the demonstra-
tions more effectively, we further investigate the
distinguishing characteristics of task-encoding to-
kens. We focus on the characteristics of lexical
cues referring to the task-related lexical meaning
of a task-encoding token, repetitions referring to
the multiple appearances of the task-encoding to-
kens in the prompt, and text formats referring to
how task-encoding tokens format the ICL prompt
Models
Settings
AGNews
SST2
TREC
DBPedia
RTE
CB
OpenLlama
3B
Randomfixed
53.2
71.8
29.7
54.1
53.1
51.3
Swap
64.4
86.8
21.7
58.7
60.6
54.6
Normal ICL
63.7
91.2
21.9
61.9
57.4
52.0
Llama
7B
Randomfixed
21.6
22.1
14.8
5.6
21.1
24.6
Swap
70.2
11.4
44.3
58.2
64.5
50.1
Normal ICL
82.4
94.3
63.5
68.7
68.6
71.3
Llama
13B
Randomfixed
55.9
80.3
24.5
48.0
57.5
36.5
Swap
81.5
67.4
36.4
75.9
69.1
52.1
Normal ICL
81.6
94.3
60.0
76.1
70.6
39.9
Llama
30B
Randomfixed
81.2
93.7
54.1
67.1
69.4
52.7
Swap
84.5
94.9
60.8
75.5
68.0
55.5
Normal ICL
85.0
96.5
68.1
78.4
78.5
83.3
Table 7: Experimental results validating the effect of
lexical cues of template tokens.
into structured text.
We design several experiments to test whether
these characteristics affect the presence of task-
encoding tokens by disrupting each characteristic
in the ICL prompts. A characteristic is related if
there is a performance drop after the disruption.
We examine each characteristic in the following
sections by disrupting an ICL prompt with different
kinds of random string templates. An example of
the templates we used can be seen in Table 6. All
the template we used are attached to Appendix B.
5.2.1
Lexical cues
A token might serve as a task-encoding token de-
pending on its specific lexical meaning. One pos-
sible hypothesis is that if the token carries specific
task-related meanings like “Article”, and “Answer”,
it is more likely to serve as a task-encoding token.
To verify if lexical cues could affect the for-
mation of task-encoding tokens, we 1) Replace
the tokens from Tin and Tout with the same ran-
dom strings across the different demonstrations
(Randomfixed), thus completely disrupting the lex-
ical characteristic of these tokens; 2) Swap Tin
and Tout (Swap), thus partially disrupting the lex-
ical characteristic of these tokens. Through these
experiments shown in Table 7, we observe that
for smaller models (OpenLlama 3B), the lexical
meaning of these tokens impacts the utilization
of task-encoding tokens relatively slightly. For
larger models, lexical cues become more important.
Specifically, Llama 7B is particularly sensitive to
the lexical meaning of tokens and demonstrates sig-
nificantly poorer performance when semantics are
disturbed via random strings or swapping. There-
fore, the lexical cues do play a role in the presence
of task-encoding tokens.
Models
Settings
AGNews
SST2
TREC
DBPedia
RTE
CB
OpenLlama
3B
Randomfixed
53.2
71.8
29.7
54.1
53.1
51.3
Randomnonfixed
29.0
69.8
16.4
20.1
50.1
50.5
Llama
7B
Randomfixed
21.6
22.1
14.8
5.6
21.1
24.6
Randomnonfixed
19.7
3.7
12.6
1.2
6.6
36.8
Llama
13B
Randomfixed
55.9
80.3
24.5
48.0
57.5
36.5
Randomnonfixed
28.3
64.2
17.5
0.3
34.7
32.7
Llama
30B
Randomfixed
81.2
93.7
54.1
67.1
69.4
52.7
Randomnonfixed
73.2
91.0
45.2
54.5
56.9
42.5
Table 8: Experimental results validating the effect of
repetitive patterns.
Models
Settings
AGNews
SST2
TREC
DBPedia
RTE
CB
OpenLlama
3B
Randomfixed
53.2
71.8
29.7
54.1
53.1
51.3
Randomsame
43.8
65.3
23.9
49.7
51.6
51.1
Llama
7B
Randomfixed
21.6
22.1
14.8
5.6
21.1
24.6
Randomsame
18.9
14.8
24.1
24.5
32.9
45.1
Llama
13B
Randomfixed
55.9
80.3
24.5
48.0
57.5
36.5
Randomsame
42.8
77.3
32.3
10.9
49.1
37.5
Llama
30B
Randomfixed
81.2
93.7
54.1
67.1
69.4
52.7
Randomsame
75.5
94.4
57.2
51.6
62.3
50.2
Table 9: Experimental results validating the effect of
text formatting.
5.2.2
Repetitive patterns
The presence of task-encoding tokens could also be
influenced by their repetition throughout the ICL
prompt. In terms of the similarity calculation in
the attention mechanism, the token most similar
to a specific one is either itself or a previously
repeated instance of it. Intuitively, this would make
the model store more information in the tokens of
repetitive patterns during the training since their
representations could transmit more information.
Yan et al. (2023) propose self-reinforcement in in-
context learning, also suggesting that repetition
could be a significant factor in in-context learning.
Regarding repetitive patterns, we focus on the
results of Randomfixed and experiments replacing
Tin and Tout with random strings separately for
each demonstration (Randomnonfixed), breaking
the repetitive patterns. We see from Table 8 that
without consistent repetitions of the task-encoding
tokens, the performance for most models decreases.
This decrease in performance suggests that the task
reasoning procedures may not have been properly
accumulated and stored in the representations of the
task-encoding tokens. These experiments demon-
strate that repetitive patterns significantly influence
the presence of task-encoding tokens.
5.2.3
Text formatting
Beyond lexical cues and repetitive patterns, task-
encoding tokens can also be introduced by the for-
matting process of ICL prompts. The formats of-
ten include structural cues that assist the model
Models
Variants
AGNews
SST2
TREC
DBPedia
RTE
CB
OpenLlama
3B
“:” +Dout
32.3
57.2
29.6
9.9
46.7
41.2
TEMP
43.2
50.4
34.2
22.4
50.9
48.6
Randomfixed
47.7
53.1
35.0
26.1
51.6
48.7
Llama
7B
“:” +Dout
39.6
53.8
31.5
0.8
54.9
41.5
TEMP
42.3
53.3
48.7
19.1
60.4
48.2
Randomfixed
50.5
59.9
49.6
23.9
59.2
48.1
Llama
13B
“:” +Dout
66.4
53.7
55.2
3.2
57.2
65.0
TEMP
82.3
56.6
61.6
44.0
58.8
51.7
Randomfixed
83.9
61.0
60.7
42.1
57.2
49.4
Llama
30B
“:” +Dout
72.7
73.9
65.4
35.2
70.4
60.0
TEMP
76.6
71.5
67.4
54.5
73.4
63.1
Randomfixed
82.3
76.3
64.0
58.3
71.1
59.8
Table 10: One-shot representation masking experiments
conducted to verify if structural template formats could
influence the effectiveness of the task-encoding tokens.
in differentiating between elements with distinct
roles, such as task inputs and target labels, within a
demonstration. Specifically, template tokens (i.e.,
Tin and Tout) format the presentation of demon-
stration examples and labels. These structural cues
are similar to those found in an LLM’s pretraining
data (e.g., column names in SQL tables to distin-
guish different types of data). We suspect that
pretraining on such data enables the structuring na-
ture of the task-encoding tokens to be recognized,
causing its representations to store higher-level in-
formation.
For text formatting, we focus on scenario
Randomfixed and experiment with replacing
Tin and Tout with one same random string
(Randomsame). In Randomsame, the prompt for-
mat of Randomfixed is disrupted by the same pat-
terns before Din and Dout, making it difficult to
distinguish them. As shown in Table 9, the per-
formance drop indicates the importance of the text
formatting.
We further design one-shot Randomfixed exper-
iments to provide a setup controlling for repeti-
tive patterns and lexical meanings. Since the tem-
plate is made of random strings and there is only
one training demonstration, the lexical cues and
repetitions would not affect the token being task-
encoding. This setup could examine whether the
model can store reasoning procedures relying on
just the text formatting that distinguishes the input
and output of a demonstration. The masking abla-
tion method from Section 4.2.1 is further used to
confirm whether these random string tokens can
function effectively. Specifically, we include re-
sults from the “:” +Dout, TEMP scenarios, as well
as the normal results of one-shot Randomfixed, for
a more comprehensive analysis. Results are shown
in Table 10.
We observe that the indicator token and label
token carry the most useful information for perfor-
mance. The random strings also positively impact
the final performance, with the exception of the
SST2 dataset. These random strings occur only
once, and the model can only recognize them by
the formatting of the prompt. This also suggests
that text formatting is a main characteristic of the
task-encoding tokens.
6
Conclusion
In this paper, our analysis of ICL pinpoints a more
precise location for the task-encoding representa-
tions. Through a series of comprehensive experi-
ments, we have examined the influential roles of
template tokens and stopword tokens within ICL,
whose representations may store task reasoning
procedures. Our results show that the behaviors
of these tokens are primarily related to their char-
acteristics of lexical cues, repetitive patterns, and
structural formats, which allow us to partially ex-
plain the presence of task-encoding tokens.
Limitation
In this paper, the categorization of the tokens is set
and verified manually and can still be improved.
Although the results are supportive and comprehen-
sive for the division, the identification itself is not
concise enough. For example, the stopwords could
be just a part of all the in-context task-encoding
tokens. Being limited by the manual categoriza-
tion, we are not able to track all of these tokens.
Meanwhile, our experiments are only conducted in
the classification datasets, the conclusion could be
further verified for more tasks.
References
Ekin Akyürek, D. Schuurmans, Jacob Andreas, Tengyu
Ma, and Denny Zhou. 2022. What learning algo-
rithm is in-context learning? investigations with lin-
ear models. International Conference on Learning
Representations.
Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, and
Song Mei. 2023. Transformers as statisticians: Prov-
able in-context learning with in-context algorithm
selection. arXiv preprint arXiv: 2306.04637.
Satwik Bhattamishra, Arkil Patel, Phil Blunsom, and
Varun Kanade. 2023. Understanding in-context learn-
ing in transformers and llms by learning to learn dis-
crete functions. arXiv preprint arXiv:2310.03016.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot
learners. Advances in neural information processing
systems, 33:1877–1901.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognising textual entailment chal-
lenge. In Machine learning challenges workshop,
pages 177–190. Springer.
Marie-Catherine De Marneffe, Mandy Simons, and Ju-
dith Tonhauser. 2019. The commitmentbank: Inves-
tigating projection in naturally occurring discourse.
In proceedings of Sinn und Bedeutung, volume 23,
pages 107–124.
Tianyu Guo, Wei Hu, Song Mei, Huan Wang, Caiming
Xiong, Silvio Savarese, and Yu Bai. 2023. How do
transformers learn in-context beyond simple func-
tions? a case study on learning with representations.
Roee Hendel, Mor Geva, and Amir Globerson. 2023.
In-context learning creates task vectors.
Yingcong Li, Muhammed Emrullah Ildiz, Dimitris Pa-
pailiopoulos, and Samet Oymak. 2023. Transform-
ers as algorithms: Generalization and stability in
in-context learning. In Proceedings of the 40th Inter-
national Conference on Machine Learning, volume
202 of Proceedings of Machine Learning Research,
pages 19565–19594. PMLR.
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,
L. Carin, and Weizhu Chen. 2021. What makes good
in-context examples for gpt-3? Workshop on Knowl-
edge Extraction and Integration for Deep Learning
Architectures; Deep Learning Inside Out.
Sheng Liu, Lei Xing, and James Zou. 2023. In-context
vectors: Making in context learning more effective
and controllable through latent space steering. arXiv
preprint arXiv: 2311.06668.
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,
and Pontus Stenetorp. 2022. Fantastically ordered
prompts and where to find them: Overcoming few-
shot prompt order sensitivity. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
8086–8098, Dublin, Ireland. Association for Compu-
tational Linguistics.
Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,
Mike Lewis, Hannaneh Hajishirzi, and Luke Zettle-
moyer. 2022.
Rethinking the role of demonstra-
tions: What makes in-context learning work? arXiv
preprint arXiv: 2202.12837.
Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas
Joseph, Nova DasSarma, Tom Henighan, Ben Mann,
Amanda Askell, Yuntao Bai, Anna Chen, Tom Con-
erly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds,
Danny Hernandez, Scott Johnston, Andy Jones, Jack-
son Kernion, Liane Lovitt, Kamal Ndousse, Dario
Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam
McCandlish, and Chris Olah. 2022. In-context learn-
ing and induction heads.
Jane Pan, Tianyu Gao, Howard Chen, and Danqi Chen.
2023. What in-context learning ""learns"" in-context:
Disentangling task recognition and task learning. In
Findings of the Association for Computational Lin-
guistics: ACL 2023, Toronto, Canada, July 9-14,
2023, pages 8298–8319. Association for Computa-
tional Linguistics.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng, and
Christopher Potts. 2013. Recursive deep models for
semantic compositionality over a sentiment treebank.
In Proceedings of the 2013 conference on empiri-
cal methods in natural language processing, pages
1631–1642.
Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron
Mueller, Byron C. Wallace, and David Bau. 2023.
Function vectors in large language models.
Ellen M Voorhees and Dawn M Tice. 2000. Building a
question answering test collection. In Proceedings
of the 23rd annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, pages 200–207.
Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou,
Fandong Meng, Jie Zhou, and Xu Sun. 2023. Label
words are anchors: An information flow perspective
for understanding in-context learning. Conference on
Empirical Methods in Natural Language Processing.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-
icz, Joe Davison, Sam Shleifer, Patrick von Platen,
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, and Alexander Rush. 2020. Trans-
formers: State-of-the-art natural language processing.
In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System
Demonstrations, pages 38–45, Online. Association
for Computational Linguistics.
Sang Michael Xie, Aditi Raghunathan, Percy Liang,
and Tengyu Ma. 2021. An explanation of in-context
learning as implicit bayesian inference. International
Conference on Learning Representations.
Jianhao Yan, Jin Xu, Chiyu Song, Chenming Wu, Yafu
Li, and Yue Zhang. 2023. Understanding in-context
learning from repetitions.
Fan Yin, Jesse Vig, Philippe Laban, Shafiq Joty, Caim-
ing Xiong, and Chien-Sheng Wu. 2023. Did you read
the instructions? rethinking the effectiveness of task
definitions in instruction learning. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 3063–3079, Toronto, Canada. Association for
Computational Linguistics.
Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyun-
soo Cho, Hwiyeol Jo, Sang-Woo Lee, Sang goo Lee,
and Taeuk Kim. 2022. Ground-truth labels matter: A
deeper look into input-label demonstrations. arXiv
preprint arXiv: 2205.12685.
Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-level convolutional networks for text clas-
sification. In Advances in Neural Information Pro-
cessing Systems, volume 28. Curran Associates, Inc.
Yiming Zhang, Shi Feng, and Chenhao Tan. 2022. Ac-
tive example selection for in-context learning. In Pro-
ceedings of the 2022 Conference on Empirical Meth-
ods in Natural Language Processing, pages 9134–
9148.
Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and
Sameer Singh. 2021. Calibrate before use: Improv-
ing few-shot performance of language models. In
Proceedings of the 38th International Conference
on Machine Learning, volume 139 of Proceedings
of Machine Learning Research, pages 12697–12706.
PMLR.
Datasets
Notations
Examples
AGNews
I
Classify the news articles into the categories of
World, Sports, Business, and Technology.\n\n
Tin
Article: {Din}\n
Tout
Answer: {Dout}\n\n
SST2
I
Classify the reviews into the categories of Positive
and Negative.\n\n
Tin
Review: {Din}\n
Tout
Sentiment: {Dout}\n\n
RTE
I
Classify the entailment of the hypothesis and the
premise into the categories of True and False.\n\n
Tin
Hypothesis: {DinA}\n Premise: {DinB}\n
Tout
Answer: {Dout}\n\n
CB
I
Classify the entailment of the hypothesis and the
premise into the categories of true, neither and
false.\n\n
Tin
Hypothesis: {DinA}\n Premise: {DinB}\n
Tout
Answer: {Dout}\n\n
TREC
I
Classify the questions based on whether their answer
type is a Number, Location, Person, Description, En-
tity, or Abbreviation.\n\n
Tin
Question: {Din}\n
Tout
Answer Type: {Dout}\n\n
DBPedia
I
Classify the documents based on whether they are
about a Company, School, Artist, Athlete, Politician,
Transportation, Building, Nature, Village, Animal,
Plant, Album, Film, or Book.\n\n
Tin
Article: {Din}\n
Tout
Answer: {Dout}\n\n
Table 11: An example of the ICL template used in all of
our experiments.
Datasets
Stopwords
AGNews
“the”, “into”, “of”, “and”, “,” , “.”, “\n”
SST2
“the”, “into”, “of”, “and”, “.”, “\n”
RTE
“the”, “of”, “into”, “and”, “into”, “.”, “\n”
CB
“the”, “of”, “and”, “into”, “,” ,“.”, “\n”
TREC
“the”, “based”, “on”, “whether”, “their”, “is”, “a”, “,”, “or”, “.”, “\n”
DBPedia
“the”, “based”, “on”, “whether”, “they”, “are”, “about”, “a”, “,”, “or”, “.”, “\n”
Table 12: The stopwords used in all of our experiments.
Words rarely exist in the task demonstrations are omit-
ted.
A
In-context Learning Templates
In this section, we present all the in-context learn-
ing templates used in this paper. The examples are
provided in Table 1. For the RTE and CB datasets,
there are two distinct inputs in the demonstrations
(i.e., the hypothesis and the premise), which we
denote as DinA and DinB, respectively. We show
the stopword token list we used in Table 12.
B
Template used for the random string
experiments
In this section, we present all the in-context learn-
ing templates used for the random experiments in
Section 5.2. These random templates are displayed
in Table 13. In the Randomfixed scenario, the Tin
and Tout are consistent across all demonstrations.
For the Randomnonfixed scenario, we employ differ-
ent random string templates for each demonstration.
In the Randomsame scenario, all random strings are
Datasets
Notations
Examples
Randomfixed
CB & RTE
Tin
fdafdasjklfdadf: {DinA}\n zcxvnmxcjkfdas: {DinB}\n
Tout
reqwiorewsdafjl: {Dout}\n\n
Other tasks
Tin
dsafjkldafdsajk: {Din}\n
Tout
reqwiorewsdafjl: {Dout}\n\n
Randomsame
CB & RTE
Tin
fdafdasjklfdadf: {DinA}\n fdafdasjklfdadf: {DinB}\n
Tout
fdafdasjklfdadf: {Dout}\n\n
Other tasks
Tin
fdafdasjklfdadf: {Din}\n
Tout
fdafdasjklfdadf: {Dout}\n\n
Randomnonfixed
CB & RTE
Tin
1
fdafdasjklfdadf: {DinA}\n zcxvnmxcjkfdas: {DinB}\n
Tout
1
xiadfjdsalgfweqrjl: {Dout}\n\n
Tin
2
gfhdajkgfhdasfj: {DinA}\n cvxhlkdadsajfk: {DinB}\n
Tout
2
yufoufgaddavfdnsl: {Dout}\n\n
Tin
3
rrqetrizxcsdafq: {DinA}\n vncmxasdgfadsl: {DinB}\n
Tout
3
afdgvcxjlzxnvxzla: {Dout}\n\n
Tin
4
mvfvxadfawewqro: {DinA}\n lkajsdfopsadfp: {DinB}\n
Tout
4
fgsgfskjvcdafds: {Dout}\n\n
Tin
t
sdsajfjdsaczvvv: {DinA}\n hkljfdiabasdfj: {DinB}\n
Tout
t
dafhglajfdvcaol: {Dout}\n\n
Other tasks
Tin
1
dsafjkldaasdfjkl: {Din}\n
Tout
1
xiadfjdsalgfweqrjl: {Dout}\n\n
Tin
2
ewqroudajfsdafq: {Din}\n
Tout
2
yufoufgaddavfdnsl: {Dout}\n\n
Tin
3
eqdashcxzlreqguio: {Din}\n
Tout
3
afdgvcxjlzxnvxzla: {Dout}\n\n
Tin
4
cxzvadeqrczxdsa: {Din}\n
Tout
4
fgsgfskjvcdafds: {Dout}\n\n
Tin
t
vcxnkfgahvczxkl: {Din}\n
Tout
t
dafhglajfdvcaol: {Dout}\n\n
Swap
CB & RTE
Tin
Answer: {DinA}\n Hypothesis: {DinB}\n
Tout
Premise: {Dout}\n\n
Table 13: An example of the ICL template used in all of
our random experiments.
identical.
","Since the proposal of in-context learning (Brown et al., 2020), its working mechanism has been extensively studied by the research community (Min et al., 2022; Liu et al., 2021; Olsson et al., 2022; Bhattamishra et al., 2023). Min et al. (2022) suggest that demonstrations primarily provide the label space, the distribution of the input text, and the overall format of the sequence for the test example. They argue that the precise ground truth labels do not have significant importance. Conversely, Yoo et al. (2022) propose a differing view, stating that the impact of the ground truth labels depends on the experimental configuration. Order sensitivity is also identified as a problem of ICL(Lu et al., 2022). Xie et al. (2021) explain ICL as implicit Bayesian inference, while Akyürek et al. (2022) explore the learning algorithm using linear models. Theoretical explanations (Guo et al., 2023; Bai et al., 2023; Li et al., 2023) and gradient descent explanations have been proposed to explain ICL. Yan et al. (2023) propose that repetitive patterns in in-context learning lead to the reinforcing of token co-occurrence, affecting the ICL performance in positive or negative ways. Pan et al. (2023) analyze the in-context learning process by disentangling it into task recognition and task learning.nan"
"In recent years, fine-tuning all model parameters in pretrained language models has become computationally intensive, especially for numerous downstream applications. Hence, several approaches have been proposed to achieve parameter-efficient fine-tuning (PEFT) with the aim of preserving or improving the performance of full fine-tuning approaches using a fraction of the original model parameters. One such method is LoRA, which employs two low-rank matrices for each linear layer in place of their original weight matrix. However, one limitation of LoRA is that its low-rank is an arbitrarily set parameter, thereby limiting its adaptivity to the layer structure. We alleviate this issue by introducing PRILoRA, which proposes a linearly increasing rank distribution across layers. Additionally, we implement pruning, inspired by Wanda, as a form of dynamic feature selection, to focus on essential inputs for each layer. Our extensive experiments over eight natural language understanding benchmarks demonstrate the effectiveness of PRILoRA, outperforming LoRA and its variants in both performance and training efficiency.","The current paradigm for natural language processing (NLP) tasks involves exploiting pre-trained models that are usually large, leading to a lengthy fine-tuning process and substantial hardware requirements. To address this, several PEFT methods have been developed to maintain or improve the accuracy of full fine-tuning using only a small fraction of parameters. These methods can be classified into two categories: selective and additive PEFT. Selective methods modify a subset of the model's parameters based on a predefined criterion, while additive methods introduce additional trainable modules. Of particular note is LoRA, an archetypal additive PEFT approach that introduces two trainable rank decomposition matrices into each target module. Despite its success, the fixed rank parameter in LoRA is an arbitrary setting. To address this issue, we introduce PRILoRA, a novel approach that incorporates a linearly increasing rank distribution across layers and prunes the rank decomposition matrices using an importance-based strategy.","PRILoRA comprises two main components integrated with the LoRA fine-tuning procedure: (i) a linear distribution of low ranks across the network's layers, and (ii) ongoing importance-based A-weight pruning. The former allocates different low ranks to different layers, with lower ranks for earlier layers and higher ranks for later layers, resulting in a distribution that promotes simplicity while ensuring that higher layers have sufficient capacity for adaptation. The latter employs pruning as a form of dynamic feature selection, focusing the fine-tuning process on important input dimensions at each layer. The pruning strategy is guided by an exponential moving average of the L2 norm of the layer's input, with the aim of removing irrelevant weights and encouraging the low-rank update matrix to concentrate on the most informative input features.","Our experiments on eight natural language understanding benchmarks from the GLUE dataset demonstrate the effectiveness of PRILoRA. Compared to various baselines, including full fine-tuning, several PEFT methods, and recent variants of LoRA, PRILoRA achieves consistently superior results. Notably, PRILoRA outperforms LoRA and its variants in both performance and efficiency, as evidenced by its lower number of trainable parameters and comparable training time. Furthermore, ablation studies confirm the contributions of both the linear rank distribution and the pruning component to PRILoRA's strong performance.",PRILoRA significantly improves the state-of-the-art in PEFT by introducing a linearly increasing rank distribution and an importance-based pruning strategy. It achieves better accuracy compared to existing methods while using the same number of trainable parameters and maintaining similar training efficiency. The success of PRILoRA aligns with our intuition that higher layers in Transformer-based models require more adaptation during fine-tuning and that pruning can facilitate efficient learning by focusing on informative input features. We hope that our work will inspire future research in developing more effective and efficient PEFT methods.,PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation,"Nadav Benedek, Lior Wolf","PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation
Nadav Benedek
Tel Aviv University
nadavbenedek@mail.tau.ac.il
Lior Wolf
Tel Aviv University
wolf@cs.tau.ac.il
Abstract
With the proliferation of large pre-trained lan-
guage models (PLMs), fine-tuning all model pa-
rameters becomes increasingly inefficient, par-
ticularly when dealing with numerous down-
stream tasks that entail substantial training
and storage costs. Several approaches aimed
at achieving parameter-efficient fine-tuning
(PEFT) have been proposed. Among them,
Low-Rank Adaptation (LoRA) stands out as
an archetypal method, incorporating trainable
rank decomposition matrices into each target
module. Nevertheless, LoRA does not consider
the varying importance of each layer. To ad-
dress these challenges, we introduce PRILoRA,
which linearly allocates a different rank for
each layer, in an increasing manner, and per-
forms pruning throughout the training process,
considering both the temporary magnitude of
weights and the accumulated statistics of the
input to any given layer. We validate the effec-
tiveness of PRILoRA through extensive exper-
iments on eight GLUE benchmarks, setting a
new state of the art.
1
Introduction
The current paradigm for natural language process-
ing tasks is to exploit pre-trained models, which
were trained using large amounts of data and ex-
pensive resources, and fine-tune them to various
downstream tasks (Brown et al., 2020; Liu et al.,
2019; Radford et al., 2019; He et al., 2021b; De-
vlin et al., 2019). Such fine-tuning was tradition-
ally conducted by gradient update of all parame-
ters of the model (Dodge et al., 2020; Raffel et al.,
2020; Qiu et al., 2020). With the ever increasing
size of models, such as Llama 7B-65B (Touvron
et al., 2023), Palm 540B (Chowdhery et al., 2022),
and others, trained with resources consisting of
hundreds of GPUs in parallel, which are available
only to some institutions and corporations, full fine-
tuning can become prohibitive, lengthy, and with
high carbon footprint (Luccioni et al., 2022). Addi-
tionally, fully fine-tuning this way requires storing
all parameters of the fine-tuned model for every
downstream task.
To tackle the aforementioned challenges, a few
research directions for Parameter-Efficient Fine-
Tuning (PEFT) were proposed. These directions
aim to maintain or even improve the accuracy of
a full fine-tuning approach, while training only a
small fraction of the parameters. One approach is
to add small modules to the base model, which is
kept frozen throughout the training process. Such
adapter tuning techniques (Rebuffi et al., 2017;
Houlsby et al., 2019; Pfeiffer et al., 2020; He et al.,
2022) add modules between the layers. The im-
plication, due to increased model depth, is longer
training time and higher latency during inference.
Alternatively, prompt and prefix tuning (Lester
et al., 2021; Li and Liang, 2021) attach trainable
tokens to the beginning of layers in the model, thus
potentially reducing its effective maximal token
length.
LoRA (Hu et al., 2022) fine-tunes linear layers
by viewing each layer as a matrix of weights W0,
freezing it, and adding to it a small rank matrix,
with the same shape as the original weight ma-
trix, that is obtained as a product of two low-rank
matrices A and B. The low-rank r is chosen to
be much smaller than the input dimension to the
layer, thereby significantly reducing the number of
trainable parameters. During LoRA training, only
the two low-rank matrices are updated, which are
usually 0.01% to 1.00% of the original parame-
ter count, depending on the low-rank of the two
matrices. In addition to being efficient and often
exceeding the performance of full fine-tuning (Hu
et al., 2022), this method has the advantage of be-
ing able to be merged back to the original matrix
during inference, without increasing latency. LoRA
has been used in various downstream tasks success-
fully (Schwartz et al., 2022; Lawton et al., 2023;
arXiv:2401.11316v1  [cs.CL]  20 Jan 2024
Dettmers et al., 2023)
One limitation of LoRA is that the low-rank r
is an arbitrarily set parameter, and in the original
LoRA it is set to be fixed across layers and weights.
Efforts were made to address the issue of the
fixed rank of LoRA. AdaLoRA (Zhang et al., 2023)
starts from an initial parameter budget, which is
slightly higher than the final budget, and then grad-
ually reduces it until matching the target by remov-
ing weights based on SVD.
In this work, we encourage the usage of linearly
increasing the rank from one layer to the next while
concurrently adhering to the same budget of pa-
rameters. As we show, this strategy provides a
distribution of the learned parameters that is bet-
ter than a uniform placement, or even the learned
alternatives.
A second contribution is obtained by pruning
matrix A. This is done by considering both the
elements of A and an exponential moving average
over the layer’s input. Although we prune, in most
cases, half of the elements of A, the main metric we
seek to improve by pruning is the overall accuracy
obtained after pruning.
We conduct extensive experiments over eight
different General Language Understanding Evalua-
tion (Wang et al., 2019) benchmarks, and present
evidence that the proposed method outperforms
LoRA and its recent variants, that both the linear
distribution of ranks and the specific pruning ap-
proach are beneficial, and that the method does not
require more GPU memory or training time than
the conventional LoRA, unlike recent extensions
of LoRA.
2
Related Work
In recent years, Parameter Efficient Fine-Tuning
(PEFT) has garnered increasing interest among re-
searchers as a means to reduce both the expenses
associated with fine-tuning and storing large-scale
pre-trained models and the time required for train-
ing. Various approaches have emerged, each ex-
hibiting distinct characteristics pertaining to mem-
ory utilization, storage requirements, and com-
putational overhead during inference. These ap-
proaches can be classified into two primary cate-
gories, namely, selective and additive PEFT meth-
ods, based on whether the original model parame-
ters undergo fine-tuning during the training phase.
Selective methods involve the selection and
modification of a model based on its original pa-
rameters. An early instance of this concept was
observed in the fine-tuning of only a subset of the
top layers of a network, as demonstrated by Don-
ahue et al. (2014), and by more recent work (Gheini
et al., 2021). In more recent developments, vari-
ous approaches have been proposed, each targeting
specific layers or internal modules of the model.
For instance, the BitFit method (Zaken et al., 2021)
updates only the bias parameters, resulting in a
substantial reduction in the number of trainable pa-
rameters, but at the cost of suboptimal performance.
Other methods use a scoring function when select-
ing trainable parameters (Guo et al., 2020; Sung
et al., 2021; Vucetic et al., 2022), while others se-
lect top parameters based on a Fisher information
calculation (Sung et al., 2021).
Additive methods represent an alternative to
full-parameter fine-tuning by introducing addi-
tional trainable parameters into the backbone net-
work. Adapters are a type of trainable component
initially applied in the context of multi-domain im-
age categorization by Rebuffi et al. (2017), that
were subsequently integrated into Transformer
networks, specifically in the attention and feed-
forward layers (Houlsby et al., 2019).
Prefix-
Tuning and Prompt-Tuning (Li and Liang, 2021;
Lester et al., 2021) involve the addition of trainable
parameters preceding the sequence of hidden states
across all layers. LST (Ladder Side-Tuning) (Sung
et al., 2022) operates by short-cutting hidden states
from the original network into a compact trainable
side network, eliminating the need for backpropa-
gating gradients through the backbone network.
LoRA (Hu et al., 2022) emulates the adjustment
of the weight matrix in the model through the mul-
tiplication of two low-rank matrices. Notably, the
trained parameters resulting from this process can
be incorporated seamlessly into the original net-
work during the inference phase without incurring
additional computational overhead.
Recently, hybrid approaches have emerged, com-
bining the selective and additive methods and pre-
senting a unified framework (Chen et al., 2023;
He et al., 2022; Mao et al., 2021). Other methods
are based on the hypothesis that parameter redun-
dancy exists in PEFT modules, therefore pruning
the trainable parameters to achieve superior fine-
tuning performance (Bai et al., 2022).
Network pruning methods (Molchanov et al.,
2016; Hassibi et al., 1993; Frankle and Carbin,
2019; Liu et al., 2018; Han et al., 2015b) reduce
the size of the network by removing or shrinking
matrices from the network, which effectively is
equivalent to setting them to zero. Such methods
require further full re-training, or other computa-
tionally intensive iterations.
Magnitude Pruning (Han et al., 2015a; Gale
et al., 2019) removes individual parameter weights
when the magnitude is below a certain threshold.
The threshold is determined either based on the
relative magnitude to other weights in the same
parameter or layer (Zhu and Gupta, 2018), or for
the whole network (Liu et al., 2018).
3
Background
Transformer Models.
Transformer (Vaswani
et al., 2017) is a sequence-to-sequence architec-
ture that makes use of self-attention. Typically,
it consists of several stacked blocks, where each
block contains two sub-modules: a multi-head at-
tention (MultiHead) and a fully connected feed-
forward network (FFN). Given the input sequence
X ∈ Rn×d of n tokens of dimension d, MultiHead
performs the attention function using h heads, al-
lowing each segment of the d space to attend to a
different value projection of another token:
MultiHead (X) = [head1, .., headh]Wo ∈ Rn×d
headi = Softmax
XWqi(XWki)⊤
√dh

(XWvi)
where the square brackets denote a concatenation
along the second dimension, Wo ∈ Rd×d and
Wqi, Wki, Wvi ∈ Rd×dh are parameters of head
i, per block, and the softmax is applied to each
row. dh is typically set to d
h. The output of the
MultiHead is fed into the FFN, consisting of two
linear transformations with a ReLU non-linearity
in between:
FFN(X) = ReLU(XW1 +b1)W2 +b2, where
W1 ∈ Rd×dm and W2 ∈ Rdm×d are parameters of
the block. Lastly, a residual connection is applied
and a layer normalization (Ba et al., 2016).
Adapters.
(Houlsby et al., 2019; Pfeiffer et al.,
2020) The adapter technique injects a module be-
tween the transformer layers, such that the input is
down-projected to a lower-dimensional space using
Wdown ∈ Rd×r, followed by non-linearity σ, and
up-projected using Wup ∈ Rr×d, combined with a
residual connection:
h = x + σ(xWdown)Wup
(1)
Low Rank Adaptation. LoRA (Hu et al., 2022)
freezes the pre-trained model weights and injects
two trainable rank decomposition matrices into
each layer of the Transformer architecture, greatly
reducing the number of trainable parameters for
fine-tuning tasks. For a linear layer h = W0x, the
LoRA-modified forward function is:
h = W0x + ∆W x = W0x + BAx
(2)
where W0, ∆W
∈ Rd1×d2, A ∈ Rr×d2 and
B ∈ Rd1×r with r ≪ {d1, d2}. A is Gaussian
initialized and B is zero initialized, in order to
have ∆W = 0 at the beginning of the fine-tuning
training. Hu et al. (2022) apply LoRA to the query
and value parameters (i.e, Wq and Wv) in the
multi-head attention, without modifying the other
weights. He et al. (2022) extend it to other weight
matrices of the feed-forward network, for an in-
creased performance.
4
Method
Our proposed method, PRILoRA (Pruned and
Rank-Increasing Low-Rank Adaptation), is com-
prised of two main components that integrate with
the LoRA fine-tuning: (i) Linear distribution of low
ranks across the layers in the network, and (ii) On-
going pruning of the A matrix of the LoRA, based
on the layer’s input activations and the weights of
the LoRA A matrix.
4.1
Linear Distribution of Ranks
While LoRA distributes the learned parameters uni-
formly, one can distribute these differently. For
example, one can assign a lower rank to some of
the layers and a higher rank to others.
Recall that the trainable parameters in LoRA are
the matrices A and B. Each has one dimension
that is fixed according to the layer’s structure, and
one dimension that is the low rank r. Since both
the time complexity (train or test) and the memory
complexity of a layer are linear in both the input
and the output dimensions of each layer, and since
only one dimension of A and B depends on r, the
overall complexity of LoRA is linearly dependent
on the sum of the ranks in all modified layers.
The way that we distribute the learned parame-
ters is motivated by the results provided by (Zhang
et al., 2023), which demonstrate that the top lay-
ers require more adaptation. Considering that one
cannot focus only on the top layers, since the other
layers also need to adapt (see Sec. 6), and to pro-
mote simplicity, we employ a linear distribution of
ranks.
In the linear distribution of ranks, we allocate a
different low-rank for every layer in the model, in
a linearly increasing manner. Specifically, for the
DeBERTaV3-base model, we start from the first
layer, applying a low-rank of rs = 4, and growing
linearly, up to the twelfth layer, where we apply
rf = 12, such that the average rank across layers is
8. We allocate the same low-rank to all weights in
a given layer, regardless of the matrix type (query,
key, value, etc.). This makes the total number of
parameters identical to the LoRA method.
4.2
Ongoing Importance-Based A-weight
Pruning
We employ pruning as a form of dynamic feature
selection, which allows the fine-tuning process to
focus on some of the layer’s input at each bottle-
neck index at every pruning iteration. The intuition
is that since the capacity of the update matrix BA
is low, it would be beneficial to attend only to the
important input dimensions.
4.2.1
Importance Matrix
Each transformer layer, whether it is a projection
associated with key, query, or value, or one of the
FFN layers has some weight matrix W . It also has
some input X ∈ Rb×n×d, where b is the batch size,
n is the number of tokens, and d is the dimension.
We abuse the notation slightly and also write X for
the second layer of the FFN, although, in this case,
the dimension is dm, which is typically larger than
d. In our framework we maintain, throughout the
training process, an Exponential Moving Average
of the L2 norm of the rows of each such input X,
as depicted in Figure 1.
For each batch, we consider the tensor that has a
dimension of b × n × d, square all elements, sum
across the first and second dimensions, obtaining
a vector of size d, and take the square root of each
vector element, to get x.
The exponential moving average ¯x is updated
between batches by the following rule
¯x = 0.9¯x + 0.1x
(3)
We next compute, for every weight matrix W ,
or, more specifically, for A ∈ Rr×d2, which is the
associated half-decomposition of ∆W , an impor-
tance matrix S of the same size as A. S is inspired
b,n
X
d
A
low rank
B
L2 Norm
x
S
mask
prune
d
W
Figure 1: The schematics of PRILoRA on a single layer.
The blue path demonstrates a frozen linear layer. We
omitted the bias for simplicity. The yellow path depicts
LoRA; dropout and scaling were omitted for simplicity.
In the green path of PRILoRA, the input tensor X of
the layer is fed into L2 norm calculation. Then, the ex-
ponential moving average vector ¯x is updated and kept
as a state of the layer. When it is time for pruning, the
absolute value of the elements of A is calculated, and
together with ¯x, the importance matrix S is computed.
In every row of S, the lowest elements, as defined by
the prune ratio, are being selected to form the mask.
The mask is used to zero out elements in the A matrix.
by Wanda (Sun et al., 2023), and is the element-
wise multiplication of the absolute value of A with
the relevant moving average vector ¯x (recall that
there is one ¯x to each weight matrix W ):
Sij = |Aij|¯xj
(4)
Note that all values of ¯x are positive, since they
represent a mean norm. Therefore, all elements of
S are positive, too.
4.2.2
Pruning
Every 40 steps in the training process, we prune
each of the A-matrices, in accordance with the
associated importance matrix S. To do so, we
consider the n lowest elements of every row i =
1 . . . r of S and create a binary mask M ∈ Rr×d2.
Each mask element Mij indicates whether Sij is
among the n lowest values of row i of S. n is
determined by the prune ratio; a higher ratio means
more weights are being zeroed out. We then zero
out the elements in A using the mask M.
Note that zeroing out an element of A does not
prevent this element from becoming non-zero im-
mediately in the next training step. However, prun-
ing this way changes the training dynamics and
encourages A to be sparse. Figure 2 shows five ran-
dom weights during training of different datasets. It
can be seen that some weights can survive pruning,
some weights remain in the pruning region since
0
250
500
750
1000
1250
1500
1750
2000
0.04
0.03
0.02
0.01
0.00
0.01
0.02
0.03
0.04
0
250
500
750
1000
1250
1500
1750
2000
0.03
0.02
0.01
0.00
0.01
0.02
(a)
(b)
0
200
400
600
800
1000
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035
0
250
500
750
1000
1250
1500
1750
0.04
0.03
0.02
0.01
0.00
0.01
0.02
(c)
(d)
Figure 2: Five weights values over time on four different GLUE tasks: (a) RTE task, in layer 5, value_proj parameter;
(b) MRPC task, in layer 6, query_proj parameter; (c) SST-2 task, in layer 7, key_proj; (d) CoLA task, in layer 8,
attention.output parameter.
they cannot escape fast enough, and some weights
avoid being pruned completely.
5
Experiments
We apply PRILoRA to DeBERTaV3-base (He et al.,
2021a) (184 million parameters), and evaluate the
method on eight natural language understanding
benchmarks included in the General Language Un-
derstanding Evaluation - GLUE (Wang et al., 2019).
Summary of the GLUE benchmarks can be found
in Table 6. We use PyTorch (Paszke et al., 2019)
and Hugging Face Transformers (Wolf et al., 2019)
to implement the algorithms. All the experiments
are conducted on NVIDIA GeForce RTX 2080 Ti
GPUs. Due to limited GPU memory size, we leave
similar analysis of large-scale models, such as T5-
3B, Llama, and others, to future research.
5.1
Baselines
Full fine-tuning: In the fine-tuning stage, the
model is initialized with the pre-trained parame-
ters, and all model parameters go through gradient
updates.
Bitfit: (Zaken et al., 2021) A sparse fine-tuning
method where only the bias-terms of the model (or
a subset of them) are being modified.
HAdapter:
(Houlsby et al., 2019) Inserts
adapter layers between the self-attention module,
the FFN module, and the subsequent residual con-
nection. There are two fully connected layers with
biases in an adapter layer with a non-linearity in
between.
PAdapter: (Pfeiffer et al., 2020) Inserts the
adapter after the FNN module and LayerNorm.
LoRA: (Hu et al., 2022) Adds trainable pairs of
rank decomposition matrices in parallel to existing
weight matrices. The number of trainable param-
eters is determined by the rank r and the shape of
the original parameters.
AdaLoRA: (Zhang et al., 2023) Parameterizes
the incremental updates in the form of singular
value decomposition, for a given parameter.
5.2
Implementation details
In our research, we experimented with different
distributions while keeping the total number of pa-
rameters invariant and found that the configuration
{rs = 4, rf = 12} was optimal, together with the
hyper-parameters which are specified in Table 7.
The fact that higher layers require more parame-
ters for LoRA fine-tuning may indicate that higher
layers in Transfomer-based models capture deeper
levels of understanding, and therefore when fine-
tuning a pre-trained language model, more focus
must be put on deeper layers than on lower layers
that require less modification or adaptation to the
downstream task in question.
5.3
Main results
We compare PRILoRA with the baseline meth-
ods. Table 1 shows our results on the GLUE de-
velopment set (Appendix A). PRILoRA achieves
best average score, best result in six out of the
eight datasets, and in all datasets better results
than HAdapter, PAdapter and LoRA, with approxi-
mately the same number of parameters.
Note that when counting the number of param-
eters, we do not discount for pruned parameters.
However, with a pruning ratio of 0.5 in most bench-
marks, a quarter of the learned parameters (half the
parameters of the A matrices) are zero. A more
precise count of parameters would, therefore, be
closer to one million parameters and not 1.33M.
5.3.1
Ablation Study
In table 2 we present an ablation study for
PRILoRA, on four GLUE tasks: SST-2, CoLA,
RTE and MRPC. We aim to analyze both the rank
distribution across layers and the pruning method.
For the rank distribution study we: (i) remove
the linear distribution component of our method, re-
taining the pruning component alone with identical
rank at each layer; (ii) replace the 4−→12 distribu-
tion by 12−→4; (iii) attach LoRA adapter to only the
last layer, with a higher rank of 24 (Concentrated
Distribution).
For the pruning method study we: (i) remove the
importance pruning component, retaining increas-
ing rank distribution 4 −→ 12; (ii) prune the rows of
B matrix instead of A, by collecting an exponen-
tial moving average of B input norm, instead of the
input to A (or the layer); (iii) similarly, prune B
columns instead of rows; (iv) prune the columns of
A randomly, instead of PRILoRA method, but with
the same prune ratio. During all ablation tests, per
benchmark, we keep the same hyper-parameters
and change only a single component. For all cells
in the table, the same single seed is used.
Rank Distribution
As can be seen, removing
the linear distribution of the low-rank and fixing a
constant rank across all layers, such that the total
number of parameters stays the same as in LoRA,
but applying pruning, reduces the results in all tests.
Removing the linear distribution nonetheless out-
performs LoRA results, signalling that pruning is
indeed an essential component of the method. For
example, PRILoRA with no linear distribution on
the SST-2 benchmark reaches 96.10, while LoRA
is 94.95, and on CoLA it is 72.17 versus 69.82.
Interestingly, changing the order of the rank allo-
cation, to be 12−→4, reduces the performance signif-
icantly; for example, a decrease of 73.08 −→ 69.73
on the CoLA benchmark, and 93.14 −→ 91.91 on the
MRPC benchmark. Inverting the rank allocation
order diminishes performance below fixed-rank al-
location across layers. This provides additional
support in the need to allocate more parameters to
the top layers.
Lastly, attaching LoRA only to the last layer
yields the lowest average results across the rank
distribution ablation study, for example 89.95 ver-
sus 93.14 on MRPC when the full method is used.
Pruning Method
Ablating pruning completely,
reduces the performance. For instance, on CoLA
it is reduced 73.08 −→ 71.31. This is higher than
LoRA (69.82), pointing to the positive effect of
the rank-increasing distribution. When we prune
matrix B instead of A, we obtain results similar
to no pruning at all, suggesting that pruning B did
not yield any discernible benefits.
A plausible argument is that the input activa-
tion shape of A and B is very different, for ex-
ample 768 versus 8, in the case of most weights
in DeBERTaV3-base model, and a low-rank of 8.
Choosing to row-prune matrix B with a prune ra-
tio of 0.5, essentially means eliminating 4 out of
8 cells in every B row, which can be too aggres-
sive. Additionally, doing the same process on B
columns can create situations where a complete
row of B is zeroed out, which means that the cor-
Table 1: Results with DeBERTaV3-base on GLUE development set. The best results on each dataset are shown in
bold. We report the average correlation for STS-B (Pearson, Spearman). We report matched accuracy for MNLI.
Full FT, HAdapter and PAdapter represent full fine-tuning, Houlsby adapter, and Pfeiffer adapter, respectively. We
report the mean and standard deviation of three runs using different random seeds. We report the baseline results
from Zhang et al. (2023). Higher is better for all metrics.
Method
#Param MNLI SST-2 CoLA QQP
QNLI
RTE
MRPC STS-B
All
Acc
Acc
Mcc
Acc
Acc
Acc
Acc
Corr
Avg.
Full FT
184M
89.90
95.63
69.19
92.40
94.03
83.75
89.46
91.60
88.25
BitFit
0.1M
89.37
94.84
66.96
88.41
92.24
78.70
87.75
91.35
86.20
HAdapter
1.22M
90.13
95.53
68.64
91.91
94.11
84.48
89.95
91.48
88.28
PAdapter
1.18M
90.33
95.61
68.77
92.04
94.29
85.20
89.46
91.54
88.41
LoRAr=8
1.33M
90.65
94.95
69.82
91.99
93.87
85.20
89.95
91.60
88.50
AdaLoRA 1.27M
90.76
96.10
71.45
92.23
94.55
88.09
90.69
91.84
89.46
PRILoRA
1.33M
90.75
96.21
72.79
92.45
94.44
89.05
92.49
91.92
90.01
[PRILoRA SD] ±0.03 ±0.30 ±1.28 ±0.05 ±0.14 ±1.04
±0.57
±0.14
±0.44
Table 2: Ablation study results on the same single seed.
SST-2 CoLA RTE MRPC
PRILoRA
96.44 73.08 90.25 93.14
Fixed distribution
96.10 72.17 88.81 92.16
Inverted distribution 95.99 69.73 88.09 91.91
Concentrated dist.
95.07 69.92 87.73 89.95
No pruning
96.22 71.31 89.89 92.09
Prune B rows
96.10 71.41 89.89 91.67
Prune B cols.
96.22 71.46 88.81 91.42
Prune A rand cols.
94.84 70.75 88.09 89.22
responding output cell of LoRA will be zero as
well. Furthermore, the compressed low-rank la-
tent input to matrix B already encapsulates the
essential information, so pruning it deteriorates the
performance.
Finally,
performing a random pruning of
columns in A with the same prune ratio, produces
the lowest results in the Pruning Method ablation
study.
5.3.2
Pruning Ratio Study for PRILoRA
We would like to learn how aggressive pruning
should be, that is, how much sparsity should be
injected into the LoRA weights in order to reach
peak performance. We chose four GLUE tasks,
and for each task and for each prune ratio in {0.25,
0.50, 0.75} we ran the fine-tuning three times, each
time with a different seed. We report the average
result and standard deviation across the different
seeds.
Table 3 shows that for the selected tasks, the op-
timal pruning ratio is 0.5. However, specifically for
the STS-B task, a random hyper-parameter search
yielded an optimal pruning ratio of 0.75, as can be
seen in Table 7.
5.3.3
Training Cost Study for PRILoRA
We present the training cost comparison between
PRILoRA and LoRA, using the DeBERTaV3-base
model, on NVIDIA GeForce RTX 2080 Ti GPUs.
For the two methods, the batch size is 32.
Table 4 shows that PRILoRA has zero increase
in number of trainable parameters in comparison
to LoRA, and a negligible increase in training time
per epoch.
For comparison, AdaLoRA (Zhang et al., 2023)
speed per batch is 11% slower than LoRA in the
MNLI benchmark and 16% slower in the SST-2
benchmark, and with a slightly larger memory foot-
print.
However, analyzing the training time per batch
does not suffice. Once we know that the training
step time in PRILoRA is similar to LoRA, we want
to delve deeper and analyze the number of steps
required until reaching peak performance on the
evaluation metric.
Table 5 presents the number of steps required
Table 3: Performance vs Pruning Ratio. Each cell in the table shows the average across three different seeds,
together with the standard deviation.
SST-2
CoLA
RTE
MRPC
Prune 0.25
96.10 ± 0.34
71.43 ± 0.30
87.73 ± 1.25
91.34 ± 0.99
Prune 0.50
96.21 ± 0.30
72.79 ± 1.28
89.05 ± 1.04
92.49 ± 0.57
Prune 0.75
95.95 ± 0.17
70.63 ± 1.56
87.73 ± 0.73
90.85 ± 0.51
Table 4: Comparison of memory consumption and time
per epoch in training, between PRILoRA and LoRA on
NVIDIA GeForce RTX 2080 Ti GPU, with a batch size
of 32. All models have 1.33M parameters.
Dataset
Method
GPU Mem
Time/epoch
MNLI
LoRA
9.559 GB
117 min
PRILoRA
9.559 GB
120 min
SST-2
LoRA
9.559 GB
24 min
PRILoRA
9.559 GB
23 min
QQP
LoRA
9.559 GB
109 min
PRILoRA
9.559 GB
110 min
Table 5: Number of steps to evaluation peak point, on
four selected GLUE tasks.
SST-2
CoLA
RTE
MRPC
PRILoRA
9875
12375
1875
1750
LoRA
6500
8000
3250
1250
for each method until reaching its peak evaluation
performance. Evidently, there is no clear winner
with respect to the number of steps or time re-
quired to reach peak performance. Both LoRA
and PRILoRA have the same order of magnitude.
Since one often trains beyond the peak point, the ta-
ble does not indicate that one method is preferable
to the other in this respect.
6
Discussion
Moving from one task to another requires an adap-
tation of both the input and the output domain.
While the input domain of large language mod-
els may be comprehensive enough to support new
downstream tasks, the generation of the output is
very much context-and-task-dependent.
Therefore, it should not come as a surprise that
fine-tuning requires more adaptation of the top lay-
ers, which are closer to the output, than of the
earlier, input-processing, layers.
However, if one is to change only the top layers,
as we showed in the ablation study, there would
not be enough co-adaptation of the earlier layers to
enable the top layers to produce the required out-
put. It seems, therefore, that the gradual increase
in the allocated resources, which we apply, is a
reasonable strategy.
7
Conclusions
In this paper, we introduced PRILoRA, a novel, yet
simple and parameter-efficient method for improv-
ing low-rank adaptation during fine-tuning. Our ex-
tensive experiments encompass eight GLUE bench-
marks across multiple seeds, illustrating the effec-
tiveness of PRILoRA. Notably, we achieve superior
performance compared to state-of-the-art metrics
while maintaining the same number of trainable
parameters, reducing the non-zero parameters by
a quarter on most benchmarks, and adhering to
the same memory constraints and running time per
epoch.
8
Limitations
Our work has some limitations.
We pushed
the limits of our computational resources, utiliz-
ing NVIDIA GeForce RTX 2080 Ti GPUs, to
conduct the experiments presented in this study
across the eight GLUE benchmarks. We employed
the PRILoRA-modified DeBERTaV3-base model,
which consists of 184 million parameters.
These experiments are of the same scale as the
most related work (Zhang et al., 2023). However,
the full potential of the method could be realized on
larger models trained on more extensive datasets,
and by using larger batches that can fit into GPU
memory, allowing examination of the method on
additional downstream tasks, such as question an-
swering and text summarization.
References
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hin-
ton. 2016.
Layer normalization.
arXiv preprint
arXiv:1607.06450.
Yue Bai, Huan Wang, Xu Ma, Yitian Zhang, Zhiqiang
Tao, and Yun Fu. 2022. Parameter-efficient masking
networks. Advances in Neural Information Process-
ing Systems, 35:10217–10229.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Process-
ing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual.
Jiaao Chen, Aston Zhang, Xingjian Shi, Mu Li,
Alex Smola, and Diyi Yang. 2023.
Parameter-
efficient fine-tuning design spaces. arXiv preprint
arXiv:2301.01821.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, et al. 2022. Palm: Scaling
language modeling with pathways. arXiv preprint
arXiv:2204.02311.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
Luke Zettlemoyer. 2023. Qlora: Efficient finetuning
of quantized llms. arXiv preprint arXiv:2305.14314.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), pages
4171–4186, Minneapolis, Minnesota. Association for
Computational Linguistics.
Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali
Farhadi, Hannaneh Hajishirzi, and Noah Smith. 2020.
Fine-tuning pretrained language models: Weight ini-
tializations, data orders, and early stopping. arXiv
preprint arXiv:2002.06305.
Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoff-
man, Ning Zhang, Eric Tzeng, and Trevor Darrell.
2014. Decaf: A deep convolutional activation feature
for generic visual recognition. In International con-
ference on machine learning, pages 647–655. PMLR.
Jonathan Frankle and Michael Carbin. 2019. The lottery
ticket hypothesis: Finding sparse, trainable neural
networks. In 7th International Conference on Learn-
ing Representations, ICLR 2019, New Orleans, LA,
USA, May 6-9, 2019. OpenReview.net.
Trevor Gale, Erich Elsen, and Sara Hooker. 2019. The
state of sparsity in deep neural networks.
arXiv
preprint arXiv:1902.09574.
Mozhdeh Gheini, Xiang Ren, and Jonathan May. 2021.
Cross-attention is all you need: Adapting pretrained
transformers for machine translation. arXiv preprint
arXiv:2104.08771.
Demi Guo, Alexander M Rush, and Yoon Kim. 2020.
Parameter-efficient transfer learning with diff prun-
ing. arXiv preprint arXiv:2012.07463.
Song Han, Huizi Mao, and William J Dally. 2015a.
Deep compression: Compressing deep neural net-
works with pruning, trained quantization and huff-
man coding. arXiv preprint arXiv:1510.00149.
Song Han, Jeff Pool, John Tran, and William J. Dally.
2015b. Learning both weights and connections for
efficient neural network. In Advances in Neural In-
formation Processing Systems 28: Annual Confer-
ence on Neural Information Processing Systems 2015,
December 7-12, 2015, Montreal, Quebec, Canada,
pages 1135–1143.
Babak Hassibi, David G Stork, and Gregory J Wolff.
1993. Optimal brain surgeon and general network
pruning. In IEEE international conference on neural
networks, pages 293–299. IEEE.
Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-
Kirkpatrick, and Graham Neubig. 2022. Towards a
unified view of parameter-efficient transfer learning.
In International Conference on Learning Representa-
tions.
Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2021a.
Debertav3: Improving deberta using electra-style pre-
training with gradient-disentangled embedding shar-
ing. arXiv preprint arXiv:2111.09543.
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and
Weizhu Chen. 2021b. Deberta: Decoding-enhanced
bert with disentangled attention. In International
Conference on Learning Representations.
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
Bruna Morrone, Quentin De Laroussilhe, Andrea
Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019.
Parameter-efficient transfer learning for nlp. In In-
ternational Conference on Machine Learning, pages
2790–2799. PMLR.
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-
Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu
Chen. 2022. LoRA: Low-rank adaptation of large
language models. In International Conference on
Learning Representations.
Neal Lawton, Anoop Kumar, Govind Thattai, Aram
Galstyan, and Greg Ver Steeg. 2023. Neural archi-
tecture search for parameter-efficient fine-tuning of
large pre-trained language models. arXiv preprint
arXiv:2305.16597.
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.
The power of scale for parameter-efficient prompt
tuning. In Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing,
pages 3045–3059, Online and Punta Cana, Domini-
can Republic. Association for Computational Lin-
guistics.
Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:
Optimizing continuous prompts for generation. In
Proceedings of the 59th Annual Meeting of the Asso-
ciation for Computational Linguistics and the 11th
International Joint Conference on Natural Language
Processing, ACL/IJCNLP 2021, (Volume 1: Long
Papers), Virtual Event, August 1-6, 2021, pages 4582–
4597. Association for Computational Linguistics.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692.
Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang,
and Trevor Darrell. 2018. Rethinking the value of
network pruning. arXiv preprint arXiv:1810.05270.
Alexandra Sasha Luccioni, Sylvain Viguier, and Anne-
Laure Ligozat. 2022. Estimating the carbon footprint
of bloom, a 176b parameter language model. arXiv
preprint arXiv:2211.02001.
Yuning Mao, Lambert Mathias, Rui Hou, Amjad Alma-
hairi, Hao Ma, Jiawei Han, Wen-tau Yih, and Madian
Khabsa. 2021. Unipelt: A unified framework for
parameter-efficient language model tuning. arXiv
preprint arXiv:2110.07577.
Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo
Aila, and Jan Kautz. 2016. Pruning convolutional
neural networks for resource efficient inference.
arXiv preprint arXiv:1611.06440.
Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, Alban Desmaison, Andreas Köpf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Te-
jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,
Junjie Bai, and Soumith Chintala. 2019. Pytorch: An
imperative style, high-performance deep learning li-
brary. In Advances in Neural Information Processing
Systems 32: Annual Conference on Neural Informa-
tion Processing Systems 2019, NeurIPS 2019, De-
cember 8-14, 2019, Vancouver, BC, Canada, pages
8024–8035.
Jonas Pfeiffer, Aishwarya Kamath, Andreas Rücklé,
Kyunghyun Cho,
and Iryna Gurevych. 2020.
Adapterfusion: Non-destructive task composition for
transfer learning. arXiv preprint arXiv:2005.00247.
Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao,
Ning Dai, and Xuanjing Huang. 2020. Pre-trained
models for natural language processing: A survey.
Science China Technological Sciences, 63(10):1872–
1897.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever, et al. 2019. Language
models are unsupervised multitask learners. OpenAI
blog, 1(8):9.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, Peter J Liu, et al. 2020. Exploring the limits
of transfer learning with a unified text-to-text trans-
former. J. Mach. Learn. Res., 21(140):1–67.
Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea
Vedaldi. 2017. Learning multiple visual domains
with residual adapters. Advances in neural informa-
tion processing systems, 30.
Eli Schwartz, Assaf Arbelle, Leonid Karlinsky, Sivan
Harary, Florian Scheidegger, Sivan Doveh, and
Raja Giryes. 2022.
Maeday:
Mae for few
and zero shot anomaly-detection.
arXiv preprint
arXiv:2211.14307.
Mingjie Sun, Zhuang Liu, Anna Bair, and J Zico
Kolter. 2023. A simple and effective pruning ap-
proach for large language models. arXiv preprint
arXiv:2306.11695.
Yi-Lin Sung, Jaemin Cho, and Mohit Bansal. 2022.
Lst: Ladder side-tuning for parameter and memory
efficient transfer learning. Advances in Neural Infor-
mation Processing Systems, 35:12991–13005.
Yi-Lin Sung, Varun Nair, and Colin A Raffel. 2021.
Training neural networks with fixed sparse masks.
Advances in Neural Information Processing Systems,
34:24193–24205.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et al. 2023. Llama: Open and effi-
cient foundation language models. arXiv preprint
arXiv:2302.13971.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing
systems, 30.
Danilo Vucetic, Mohammadreza Tayaranian, Maryam
Ziaeefard, James J Clark, Brett H Meyer, and War-
ren J Gross. 2022. Efficient fine-tuning of bert mod-
els on the edge. In 2022 IEEE International Sympo-
sium on Circuits and Systems (ISCAS), pages 1838–
1842. IEEE.
Alex Wang, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel R. Bowman. 2019.
GLUE: A multi-task benchmark and analysis plat-
form for natural language understanding. In 7th In-
ternational Conference on Learning Representations,
ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.
OpenReview.net.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
et al. 2019. Huggingface’s transformers: State-of-
the-art natural language processing. ArXiv preprint,
abs/1910.03771.
Elad Ben Zaken, Shauli Ravfogel, and Yoav Gold-
berg. 2021.
Bitfit:
Simple parameter-efficient
fine-tuning for transformer-based masked language-
models. arXiv preprint arXiv:2106.10199.
Qingru Zhang, Minshuo Chen, Alexander Bukharin,
Pengcheng He, Yu Cheng, Weizhu Chen, and
Tuo Zhao. 2023.
Adaptive budget allocation for
parameter-efficient fine-tuning. In The Eleventh In-
ternational Conference on Learning Representations.
Michael Zhu and Suyog Gupta. 2018. To prune, or
not to prune: Exploring the efficacy of pruning for
model compression. In 6th International Conference
on Learning Representations, ICLR 2018, Vancouver,
BC, Canada, April 30 - May 3, 2018, Workshop Track
Proceedings. OpenReview.net.
A
GLUE Dataset
Here is a summary of the benchmarks and met-
rics we used from the GLUE (Wang et al., 2019)
dataset.
B
PRILoRA GLUE Training Details
For all benchmarks we used a linear rank distri-
bution from 4 to 12 (4,5,6,6,7,8,8,9,10,10,11,12),
such that the average rank is 8 (ranks rounded
to integers). All eight benchmarks were trained
using linear learning-rate scheduling, with the
initial learning rate reported as learning rate,
and the number of epochs for the scheduler
as epochs.
The runs were stopped after stop
epoch epochs. Hyper-parameters: learning rate,
batch size, # epochs, decay and prune ratio
were randomly searched over the space {6 ×
10−5, 1 × 10−4, 2 × 10−4, 6 × 10−4, 1 × 10−3,
1.2 × 10−3, 1.5 × 10−3, 2 × 10−3, 2.3 × 10−3},
{4, 8, 16, 32}, {10, 30, 50, 60, 70}, {0, 0.1, 0.01},
{0.25, 0.50, 0.75} correspondingly. For all bench-
marks and methods the max seq length is 128.
Table 6: Summary of the GLUE dataset
Corpus
Task
#Train
#Dev
#Label
Metrics
Single-Sentence Tasks
CoLA
Grammatical Acceptability
8.5k
1k
2
Matthews corr
SST-2
Sentiment
67.3k
872
2
Accuracy
Pairwise Text Tasks
MNLI
NLI (Entailment)
392k
9.8k
3
Matched Accuracy
RTE
NLI (Entailment)
2.5k
277
2
Accuracy
QQP
Semantic Equivalence
364k
40k
2
Accuracy
MRPC
Semantic Equivalence
3.7k
408
2
Accuracy
QNLI
Question Answering
105k
5.5k
2
Accuracy
STS-B
Similarity
5.7k
1.5k
1
Pearson/Spearman corr
Table 7: Hyper-parameters of PRILoRA for GLUE benchmark.
Dataset
learning rate
batch size
# epochs
stop epoch
decay
prune ratio
MNLI
1 × 10−4
32
70
5
0.01
0.50
RTE
1.2 × 10−3
32
70
25
0.01
0.50
QNLI
1 × 10−4
32
60
3
0.01
0.50
MRPC
1 × 10−3
32
60
15
0.01
0.50
QQP
6 × 10−4
32
10
10
0.01
0.50
SST-2
6 × 10−5
32
60
5
0.01
0.50
CoLA
2 × 10−4
4
70
6
0.01
0.50
STS-B
2.3 × 10−3
32
30
30
0.10
0.75
","nanNumerous PEFT approaches have been proposed, categorized into selective and additive methods. Selective methods, such as fine-tuning only a subset of top layers or employing a scoring function to select trainable parameters, reduce the number of trainable parameters but may compromise performance. Conversely, additive methods, represented by techniques like adapters and prompt/prefix-tuning, introduce additional trainable parameters into the model's architecture, typically increasing the overall complexity of the model. LoRA stands out as an efficient PEFT method that outperforms full fine-tuning in certain scenarios by freezing most model parameters and injecting two trainable low-rank matrices in place of the original weight matrix. However, LoRA's low-rank parameter is fixed and not tailored to specific layers or input characteristics."
"Computer vision has witnessed significant advancements, fueled by the emergence of vision foundation models tailored to specific data types and tasks. Among these models, DINO V2, Segment Anything (SAM), CLIP, and Masked AutoEncoders have gained prominence. However, the optimal choice of foundation model for few-shot semantic segmentation, a challenging task in computer vision, remains unexplored. This study aims to address this gap by introducing a novel benchmark and conducting a comprehensive comparative analysis of the aforementioned foundation models. Our findings reveal that DINO V2 consistently outperforms other models across diverse datasets and adaptation methods. Surprisingly, simple adaptation methods, such as linear heads, exhibit performance comparable to more complex techniques. These insights shed light on the importance of selecting a robust feature extractor and underscore the potential of straightforward adaptation approaches for few-shot semantic segmentation.","Semantic segmentation plays a pivotal role in various computer vision applications, involving the labeling of individual pixels within images. Few-shot semantic segmentation has emerged as a challenging yet crucial frontier, where models are equipped with the ability to adapt to novel object classes with minimal labeled data. Typically, a standard pipeline for few-shot semantic segmentation comprises a pretrained feature extractor and an adaptation method. While extensive discussions have surrounded the selection of feature extractors for few-shot classification, the question of an optimal feature extractor for few-shot semantic segmentation remains largely unaddressed. This study aims to investigate which vision foundation model yields the most effective few-shot semantic segmentation pipeline.","Our research introduces a standardized benchmark for evaluating few-shot semantic segmentation in the context of vision foundation models. This benchmark is constructed using three widely-recognized semantic segmentation datasets. To evaluate the performance of various foundation models and adaptation methods, we employ multiple adaptation methods and conduct comprehensive experiments. The considered foundation models include DINO V2, SAM, CLIP, and Masked AutoEncoders, while the adaptation methods encompass linear, multilayer, Singular Value Fine-tuning (SVF), Low-Rank Adaptation (LoRA), and fine-tuning. Our experimental setup involves training and evaluation on three datasets: Cityscapes, COCO, and PPD. To ensure reproducibility, all experiments are conducted with three fixed random seeds, and the mean Intersection-over-Union (mIoU) is computed across these runs.","Our experiments yield several key findings. Firstly, DINO V2 consistently outperforms other models across various settings, especially on Cityscapes and COCO. Secondly, the SAM encoder exhibits strong performance on average, surpassing CLIP, MAE, and ResNet on both Cityscapes and PPD. However, it shows comparatively poor results on COCO. Thirdly, the multilayer method generally outperforms the linear approach, indicating the benefit of including earlier feature maps for greater segmentation flexibility. Lastly, despite variations in the number of training parameters, the fine-tuning methods (SVF, LoRA, and Fine-tuning) produce comparable results.","In conclusion, our study establishes DINO V2 as the top-performing backbone model for few-shot semantic segmentation, consistently outperforming other foundation models. While SAM shows strong overall results, it exhibits unexpected limitations on certain datasets. Surprisingly, straightforward methods, such as simple linear heads trained on the given few shots, challenge the necessity of complex procedures. Our work not only presents a comparative analysis of techniques but also introduces a practical benchmark. We anticipate that this benchmark will contribute to improving few-shot semantic segmentation methods and provide a solid ground for comparison purposes.",A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models,"Reda Bensaid, Vincent Gripon, François Leduc-Primeau, Lukas Mauch, Ghouthi Boukli Hacene, Fabien Cardinaux","A NOVEL BENCHMARK FOR FEW-SHOT SEMANTIC SEGMENTATION
IN THE ERA OF FOUNDATION MODELS
Reda Bensaid12, Vincent Gripon1, Franc¸ois Leduc-Primeau2, Lukas Mauch3,
Ghouthi Boukli Hacene3, Fabien Cardinaux3
1IMT Atlantique
2Polytechnique Montr´eal
3Sony Europe B.V.
Lab-STICC UMR CNRS 6285
Dept. of Electrical Engineering
Stuttgart Laboratory 1
F-29238, France
Canada
Germany
ABSTRACT
In recent years, the rapid evolution of computer vision has
seen the emergence of various vision foundation models, each
tailored to specific data types and tasks. While large language
models often share a common pretext task, the diversity in
vision foundation models arises from their varying training
objectives. In this study, we delve into the quest for iden-
tifying the most effective vision foundation models for few-
shot semantic segmentation, a critical task in computer vision.
Specifically, we conduct a comprehensive comparative analy-
sis of four prominent foundation models: DINO V2, Segment
Anything, CLIP, Masked AutoEncoders, and a straightfor-
ward ResNet50 pre-trained on the COCO dataset. Our investi-
gation focuses on their adaptability to new semantic segmen-
tation tasks, leveraging only a limited number of segmented
images. Our experimental findings reveal that DINO V2 con-
sistently outperforms the other considered foundation mod-
els across a diverse range of datasets and adaptation meth-
ods. This outcome underscores DINO V2’s superior capa-
bility to adapt to semantic segmentation tasks compared to
its counterparts. Furthermore, our observations indicate that
various adapter methods exhibit similar performance, empha-
sizing the paramount importance of selecting a robust feature
extractor over the intricacies of the adaptation technique it-
self. This insight sheds light on the critical role of feature
extraction in the context of few-shot semantic segmentation.
This research not only contributes valuable insights into the
comparative performance of vision foundation models in the
realm of few-shot semantic segmentation but also highlights
the significance of a robust feature extractor in this domain.
Index Terms— Deep Learning, Foundation models, Se-
mantic Segmentation, Few-Shot Learning
1. INTRODUCTION
Semantic segmentation, the task of pixel-level object classifi-
cation within images, i.e, assigning a class to every pixel in
the image, plays a pivotal role in the landscape of computer
vision applications [1]. In recent years, few-shot semantic
Cityscapes
COCO
PPD
0
20
40
60
80
100
mIoU
DINO V2
SAM
ResNet
CLIP
MAE
Fig. 1. mIoU of various pretrained models when adapted to
3 different 1-shot segmentation tasks (only best performance
achieved out of 5 tested methods is displayed).
segmentation has emerged as a challenging yet essential fron-
tier [2]. This paradigm seeks to equip models with the ability
to adapt to novel object classes with minimal labeled data.
A standard pipeline for few-shot semantic segmentation typ-
ically comprises two key components: a pretrained feature
extractor, often derived from a vision foundation model, and
an adapter method. This setup leverages the knowledge em-
bedded within the feature extractor and adapts it to the limited
labeled data without the risk of overfitting. While extensive
discussions regarding the selection of feature extractors for
few-shot classification have been well-documented [3], the
question of the optimal feature extractor for few-shot seman-
tic segmentation remains largely unaddressed in the literature,
to the best of our knowledge.
The primary objective of our research is to investi-
gate which vision foundation model yields the most effec-
tive few-shot semantic segmentation pipeline. To this end,
we introduce a novel benchmark, constructed using three
widely-recognized semantic segmentation datasets, and sys-
tematically evaluate multiple adaptation methods. The four
foundation models under consideration are DINO V2 [4],
Segment Anything (SAM) [5], CLIP [6], and a Masked Au-
toEncoder [7] pretrained on ImageNet-1K. Our experimental
results consistently demonstrate the superior performance of
DINO V2 across various datasets.
arXiv:2401.11311v1  [cs.CV]  20 Jan 2024
In summary, our study makes the following key contribu-
tions:
• We introduce a standardized benchmark for the evalu-
ation of few-shot semantic segmentation in the context
of vision foundation models.
• Based on this benchmark, we conduct a comprehensive
comparison of five feature extractors (four foundation
models) and five adaptation methods.
Our findings indicate that DINO V2 consistently outper-
forms all other models across multiple datasets and adaptation
methods, with SAM yielding competitive results, particularly
on specific datasets. Additionally, we find that simple and
efficient adaptation methods produce results comparable to
more complex counterparts. We anticipate that our research
will assist newcomers in selecting appropriate solutions for
their few-shot semantic segmentation tasks and contribute to
the rigorous benchmarking of this evolving field.
2. BENCHMARK
2.1. Task Formulation
In accordance with the established terminology of few-shot
classification [8], our benchmark revolves around the con-
cept of a support set S and a query set Q. The support set
S comprises a limited number of images, each accompanied
by their corresponding ground truth segmentation. These sup-
port images are employed for the training or calibration of a
generic semantic segmentation model. In contrast, the query
set Q serves as the evaluation dataset on which we compute
the mean Intersection-over-Union (mIoU). In practical appli-
cations, Q is typically not available and is utilized exclusively
for benchmarking purposes.
To compute the mIoU, we calculate the Intersection-over-
Union (IoU) for each class i and then average these values:
mIoU = 1
n
n
X
i=1
TPi
TPi + FPi + FNi
,
where n represents the total number of classes or objects, TPi
is the true positive count for class i, FPi is the false posi-
tive count for class i, and FNi is the false negative count for
class i. One noteworthy distinction from few-shot classifica-
tion tasks is that individual images typically contain instances
from various classes of interest. As such, it is challenging to
define tasks in the traditional k-shot manner, where each class
is associated with exactly k elements in the support set.
In our proposed framework, we introduce a more practical
approach. We define a k-shot segmentation task as one in
which the support set S contains at least k instances of each
class. In a scenario involving a total of n classes of interest,
a k-shot task mandates the inclusion of precisely nk unique
images within the support set.
2.2. Benchmark Generation
To construct few-shot tasks from readily available semantic
segmentation datasets, we employ the following sampling
procedure:
1. Initialize an empty support set, denoted as S = ∅.
2. For each class i (excluding the background class)
within the chosen training dataset D, we compile a
list of all training images that contain at least one in-
stance of that class. This results in Di = {image ∈ D |
image contains instances of class i}.
3. Following an arbitrary order of classes, we randomly
select k images from Di without replacement to be in-
corporated into the support set S. During this process,
we ensure that images previously selected are excluded
from consideration.
4. In the rare event that there are insufficient remaining
images for a particular class i, we reset the support set
to empty S = ∅ and recommence the procedure from
Step 1. It is important to note that this reset condition
did not occur in the course of our experiments.
2.3. Datasets
In constructing our proposed benchmark, we have selected
three prominent semantic segmentation datasets, each offer-
ing unique characteristics and challenges:
Cityscapes [9] is a large scale dataset on semantic under-
standing of urban scene streets. It contains 2,975 images for
training, 500 for validation and 1,525 for testing. It is anno-
tated using 19 classes (such as “car”, “road”, “building”) and
has input resolution 1024x2048.
COCO (Microsoft Common Objects in Context) [10]
is a large scale dataset used for multiple tasks including se-
mantic segmentation. The 2017 release contains 118k images
for training, 5k for validation and 41k for testing. It is an-
notated using 80 classes (such as “person”, “bicycle”, “ele-
phant”). Images in COCO often exhibit varying input resolu-
tions, commonly falling between 400 and 640 pixels for both
width and height.
PPD (PLANT PHENOTYPING DATASETS) [11] is
a small dataset used for multiple tasks including plant seg-
mentation (foreground to background segmentation) and leaf
segmentation (multi-instance segmentation).
We focus in
our work on the plant segmentation task, where the dataset
contains 783 images, 2 classes (foreground and background).
Typical input resolutions for PPD images hover around 500
pixels for both width and height.
Support Set Mask
Support Set Images
Query Image
Pre-trained 
Backbone
Support Features
Query Features
Output
Batch Norm 
+
 
Conv 1x1
Batch Norm 
+
 
Conv 1x1
Freeze
Inference
Adaptation
Fig. 2. The overall pipeline of the Linear method: we freeze the backbone and train the shallow decoder on support set, and
then we test the encoder+decoder on the query set
3. BACKBONES AND ADAPTATION METHODS
In this section, we introduce the methodologies that form the
basis of our comparative study. Drawing from existing liter-
ature on both few-shot classification [3] and few-shot seman-
tic segmentation [12], we have identified that the majority of
methods rely on a combination of two fundamental compo-
nents.
The first essential component is a pretrained model, typ-
ically a transformer or a convnet. Notably, these pretrained
models are not necessarily designed specifically for semantic
segmentation but offer valuable preexisting knowledge.
The second critical component is an adaptation method,
a mechanism devised to tailor the knowledge encoded within
the pretrained model for effective utilization in the specific
task of interest.
In the upcoming subsections, we provide comprehensive
details on the specific models and adaptation methods that
constitute the experimental foundation of our study.
3.1. Pretrained Models
In our study, we investigate five pretrained models, each of-
fering unique characteristics and advantages:
MAE (Masked AutoEncoder) [7] is pretrained on ImageNet-
1K [13] using a self-supervised technique involving masking
portions of input images and reconstructing them using partial
tokens from the unmasked segments. It comprises a Vision
Transformer (ViT) [14] component that maps observed image
regions into latent representations and a decoder for image re-
construction. Previous research [7] has demonstrated MAE’s
effectiveness in transfer learning for segmentation tasks, par-
ticularly in semantic segmentation.
SAM (Segment Anything Model) [5] is a recent foun-
dation model for segmentation, pretrained on the SA-1B
dataset, which includes 11 million images and 1 billion seg-
mentation masks. SAM exhibits robust generalization capa-
bilities across a broad range of segmentation tasks. It utilizes
a Vision Transformer (ViT) [14] initialized with MAE [7],
a prompt encoder, and a mask decoder. SAM’s image en-
coder generates embeddings from input images, which are
subsequently employed by the mask decoder in conjunction
with the prompt encoder. While SAM’s mask decoder out-
puts class-agnostic masks intended for segmenting instances
or objects at various granularities, our specific task focuses
exclusively on the encoder’s role as a feature extractor and
does not require prompts.
DINO v2 [4] is a foundational vision model trained using
the self-supervised DINO technique [15]. The model com-
prises a ViT trained on a diverse range of datasets, including
notable semantic segmentation datasets like Cityscapes [9],
ADE20k [16, 17], and Pascal VOC 2012 [18]. DINO v2 has
previously been evaluated on semantic segmentation datasets
in [4], utilizing the frozen backbone and a simple segmenta-
tion decoder.
CLIP (Contrastive Language-Image Pre-training) [6]
is a model that consists of two encoders, a vision encoder,
and a text encoder. These encoders are jointly trained using
a contrastive loss to align embeddings of images with their
corresponding captions. The model is pretrained on a private
dataset of 400 million (image, text) pairs and has gained sig-
nificant attention for its utility in zero-shot classification on
downstream tasks. In our study, we exclusively leverage ViT
version of the visual encoder component of CLIP.
FCN (Fully Convolutional Networks) [19] represents a
conventional convolutional architecture extensively used for
semantic segmentation tasks. It comprises an encoder and
a decoder, with the former composed of convolutional lay-
ers and the latter incorporating deconvolutional layers.
In
our configuration, the encoder is based on ResNet50 [20] and
is pretrained on a subset of COCO, specifically using the 20
classes shared with the Pascal VOC dataset. We incorporate
FCN as a convolution-only benchmark for comparison.
3.2. Methods
We then consider five adaptation methods in our study:
Linear: A common approach [4] consists in freezing the
pretrained backbone and adding a segmentation head, called
decoder, consisting of a batch normalization layer followed
by a convolutional 1x1 layer. Figure 2 illustrates the overall
pipeline for this linear adaptation method.
Multilayer: It has been shown in [4] that using a concate-
nation of multiple layers from the pretrained model as output
can boost performance in downstream tasks. We thus pro-
pose to use a linear method on the concatenation of the last 4
blocks of the pretrained model.
Singular Value Fine-tuning [21] (SVF): The SVF
method decomposes parameters into three matrices using
Singular Value Decomposition (SVD) and fine-tunes only the
singular values while keeping the rest frozen. In [21], this ap-
proach demonstrated promising results in few-shot semantic
segmentation tasks, showcasing its ability to specialize the
pretrained model without overfitting. In our study, we ini-
tially apply the linear method and then proceed to fine-tune
the singular values alongside the decoder parameters.
Low-Rank Adaptation [22] (LoRA): In this approach,
we maintain the pretrained backbone’s frozen state and intro-
duce low-rank trainable adapters, as described in [22]. Sim-
ilar to the SVF method, LoRA enables tuning only a limited
number of parameters. Our procedure begins with training the
decoder using the linear method and then introduces LoRA
adapters to the encoder. Subsequently, we fine-tune both the
adapters and decoder parameters.
Fine-tuning: The fine-tuning method, a straightforward
yet effective approach, involves fine-tuning the entire pre-
trained model. This method has demonstrated state-of-the-art
performance in few-shot classification [3]. However, it is sus-
ceptible to overfitting due to the limited number of training
samples compared to the typically extensive parameter pool
in the considered encoders.
4. EXPERIMENTS
4.1. Training procedure
To ensure the reproducibility of our results, we conducted
all experiments with three fixed random seeds and computed
the mean Intersection-over-Union (mIoU) across these runs.
For preprocessing, we followed the approach outlined in [23].
This involved random horizontal flipping, random scaling of
the shorter side within the range of [400, 1600] while pre-
serving the aspect ratio, and random cropping to a size of
1024x1024. We applied a subset of RandAug [24] opera-
tions, including auto contrast, equalize, rotate, color, contrast,
brightness, and sharpness. Subsequently, all images were re-
sized to 1024x1024 resolution, except for CLIP and MAE,
which accepted input sizes of 224x224. We acknowledge that
the resolution variation, depending on the considered model,
may introduce some analysis challenges but was an unavoid-
able aspect of our setup. For the learning rate, we employed
the poly learning rate scheduler with a power of 0.9 for the
linear and multilayer methods. Specifically, we used a learn-
ing rate of 0.2 for Cityscapes, 0.05 for COCO, and 0.001 for
PPD. For fine-tuning methods (SVF, LoRA, and fine-tune)
we did a grid search across models and datasets with values
including 10−2, 10−3, 10−4, 10−5, and 10−6 to determine
the one yielding the best average performance. Linear and
multilayer methods were trained with a batch size of 4. For
the Fine-tuning, SVF, and LoRA methods, we initiated the
training with the linear method and subsequently performed
fine-tuning with the reduced batch size of 2, addressing mem-
ory limitations. Training duration extended to 200 epochs for
Cityscapes and PPD, and 100 epochs for COCO. The query
set consisted of the standard validation sets for Cityscapes and
COCO. For PPD, given the absence of a conventional split,
we performed a fixed 50/50 random split into training and
validation sets. Our models were trained on a combination of
NVIDIA A6000 and NVIDIA RTX3090 GPUs. Runtime var-
ied across datasets and models, ranging from approximately
30 minutes per run for MAE, CLIP, and ResNet on Cityscapes
to approximately 4 hours per run for DINO V2 on COCO.
For the size of the models, we choose the base version of the
vision transformers, leading to a 89M parameter model for
SAM and 86M for DINO V2, CLIP and MAE. For the FCN
we chose a ResNet50 as an encoder, leading to a 23M param-
eter model.
4.2. Main results
In this section, we aim to identify the optimal combination
of pretrained models and adaptation methods based on mIoU.
Table 1 presents the average performance on the three con-
sidered datasets for all possible combinations of pretrained
models and adaptation methods, along with their standard de-
viation, in the context of 1-shot problems.
From this initial experiment, several conclusions can be
drawn:
• DINO V2 consistently outperforms all other models
across various settings. This superiority is especially
notable on Cityscapes and COCO, where DINO V2
surpasses other models by a significant margin (see
Appendix Table 2 for the detailed results). It is worth
Table 1. mIoU averaged over our three considered datasets in 1-shot few-shot semantic segmentation.
Linear
Multilayer
SVF
LoRA
Fine-tuning
SAM
40.66±09.00
43.36±02.52
41.84±16.83
43.10±03.38
42.35±09.91
DINO V2
54.78±03.09
53.51±03.10
57.77±04.20
57.67±02.50
57.21±04.04
CLIP
35.88±10.90
39.57±07.29
40.90±13.93
38.23±04.50
38.69±10.20
MAE
35.50±10.16
36.65±07.38
37.76±08.08
36.37±04.22
36.46±10.28
FCN-ResNet50
37.78±04.17
44.08±02.16
43.40±08.63
41.45±03.70
39.63±06.49
noting that Cityscapes is included in the training im-
ages of DINO V2, although it only had access to the
images and not their associated segmentation masks.
• SAM encoder exhibits strong performance on aver-
age. It outperforms CLIP, MAE, and ResNet on both
Cityscapes and PPD. However, it yields comparatively
poor results on COCO (refer to Appendix Table 2).
This difference is likely attributed to our decision to
retain the SAM image encoder while discarding the
original decoder, which was jointly trained with the
image and prompt encoders.
• The multilayer method outperforms the linear approach
for most models, indicating that including earlier fea-
ture maps, which are more locally focused [25, 14],
provides the decoder with greater segmentation flexi-
bility. Furthermore, it exhibits a lower standard devia-
tion, indicating greater stability across different runs.
• Despite variations in the number of training parameters
(less than 1% for LoRA, around 2% for SVF, and 100%
for finetune), the finetuning methods (SVF, LoRA, and
Finetune) yield comparable results.
5. RELATED WORK
In this section, we discuss related work in the literature in
few-shot classification and semantic segmentation.
5.1. Few-Shot Classification
Few-shot classification initially focused on in-domain tasks,
with benchmarks involving dataset splitting into training, val-
idation, and fake few-shot task generation for evaluation [26,
8, 27, 28]. The introduction of Meta-dataset [29] marked a
shift towards the cross-domain setting, where the dataset used
for model training differs from the tasks evaluated later, align-
ing with more realistic scenarios. More recently, the field
has embraced the use of foundation models, adapting them
to few-shot tasks. Notably, benchmarks such as those in [30]
explore the application of CLIP [6] to 11 downstream tasks.
Methodologically, diverse approaches have emerged,
ranging from hallucination-based [31, 32] to meta-learning
[28, 33, 34, 35]. Straightforward methods have also demon-
strated effectiveness [36, 37, 38]. Recent surveys, such as
[3], suggest that optimal approaches often involve simple
finetuning atop competitive pretrained models, augmented
with an additional linear layer. This observation motivates
the methods introduced in our paper.
5.2. Semantic Segmentation and Few-Shot Semantic Seg-
mentation
Few-shot semantic segmentation is not a recent topic. Ear-
lier works, such as [2] and [39], explored multiple bench-
marks, including PASCAL-5i and COCO-20i, reminiscent of
in-domain benchmarks used in few-shot classification. Subse-
quent research ventured into using pretrained models on Ima-
geNet [40], resembling the Meta-dataset approach in few-shot
classification. Notably, most of these studies assumed binary
labelling for the few-shots, emphasizing a single object of in-
terest.
In contrast, our approach considers that the provided few-
shots are fully labelled, and we leverage pretrained founda-
tion models, not limited to those trained solely on ImageNet.
This approach aligns more closely with contemporary indus-
trial requirements, focusing on the utilization of the most ef-
ficient available models.
6. CONCLUSION
In conclusion, DINO V2 emerges as the top-performing
backbone model, consistently outperforming other founda-
tion models. While SAM exhibits strong overall results, it
presents unexpected limitations on certain datasets. Surpris-
ingly, our experiments underscore the competitive advan-
tages of straightforward methods such as simple linear heads
trained on the few given shots, challenging the necessity of
complex procedures.
This work not only presents a comparison of techniques
but also a practical benchmark.
We hope this benchmark
will contribute to improving few-shot semantic segmentation
methods and will provide a solid ground for comparison pur-
poses.
7. REFERENCES
[1] Shervin Minaee, Yuri Boykov, Fatih Porikli, Antonio
Plaza, Nasser Kehtarnavaz, and Demetri Terzopoulos,
“Image segmentation using deep learning: A survey,”
2020.
[2] Amirreza Shaban, Shray Bansal, Zhen Liu, Irfan Essa,
and Byron Boots, “One-shot learning for semantic seg-
mentation,” 2017.
[3] Xu Luo, Hao Wu, Ji Zhang, Lianli Gao, Jing Xu, and
Jingkuan Song, “A closer look at few-shot classification
again,” 2023.
[4] Maxime Oquab, Timoth´ee Darcet, Th´eo Moutakanni,
Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fer-
nandez, Daniel Haziza, Francisco Massa, Alaaeldin El-
Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech
Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li,
Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel
Synnaeve, Hu Xu, Herv´e Jegou, Julien Mairal, Patrick
Labatut, Armand Joulin, and Piotr Bojanowski,
“Di-
nov2: Learning robust visual features without supervi-
sion,” 2023.
[5] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi
Mao, Chloe Rolland, Laura Gustafson, Tete Xiao,
Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo,
Piotr Doll´ar, and Ross Girshick, “Segment anything,”
2023.
[6] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen
Krueger, and Ilya Sutskever, “Learning transferable vi-
sual models from natural language supervision,” 2021.
[7] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Pi-
otr Doll´ar, and Ross Girshick, “Masked autoencoders
are scalable vision learners,” 2021.
[8] Jake Snell, Kevin Swersky, and Richard S. Zemel, “Pro-
totypical networks for few-shot learning,” 2017.
[9] Marius Cordts, Mohamed Omran, Sebastian Ramos,
Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson,
Uwe Franke, Stefan Roth, and Bernt Schiele,
“The
cityscapes dataset for semantic urban scene understand-
ing,” 2016.
[10] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir
Bourdev, Ross Girshick, James Hays, Pietro Perona,
Deva Ramanan, C. Lawrence Zitnick, and Piotr Doll´ar,
“Microsoft coco: Common objects in context,” 2015.
[11] Massimo Minervini, Andreas Fischbach, Hanno Scharr,
and Sotirios A. Tsaftaris,
“Finely-grained annotated
datasets for image-based plant phenotyping,”
Pattern
Recognition Letters, pp. 1–10, 2015.
[12] Nico Catalano and Matteo Matteucci, “Few shot seman-
tic segmentation: a review of methodologies and open
challenges,” 2023.
[13] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei, “Imagenet: A large-scale hierarchical
image database,” in 2009 IEEE Conference on Com-
puter Vision and Pattern Recognition, 2009, pp. 248–
255.
[14] Alexey
Dosovitskiy,
Lucas
Beyer,
Alexander
Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner, Mostafa Dehghani, Matthias Minderer,
Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and
Neil Houlsby,
“An image is worth 16x16 words:
Transformers for image recognition at scale,” 2021.
[15] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e
J´egou, Julien Mairal, Piotr Bojanowski, and Armand
Joulin, “Emerging properties in self-supervised vision
transformers,” 2021.
[16] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler,
Adela Barriuso, and Antonio Torralba,
“Scene pars-
ing through ade20k dataset,” in 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR),
2017, pp. 5122–5130.
[17] Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja
Fidler, Adela Barriuso, and Antonio Torralba, “Seman-
tic understanding of scenes through the ade20k dataset,”
2018.
[18] M.
Everingham,
L.
Van
Gool,
C.
K.
I.
Williams,
J. Winn,
and A. Zisserman,
“The
PASCAL
Visual
Object
Classes
Challenge
2012
(VOC2012)
Results,”
http://www.pascal-
network.org/challenges/VOC/voc2012/workshop/index.html.
[19] Jonathan Long, Evan Shelhamer, and Trevor Darrell,
“Fully convolutional networks for semantic segmenta-
tion,” 2015.
[20] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun,
“Deep residual learning for image recognition,”
2015.
[21] Yanpeng Sun, Qiang Chen, Xiangyu He, Jian Wang,
Haocheng Feng, Junyu Han, Errui Ding, Jian Cheng,
Zechao Li, and Jingdong Wang, “Singular value fine-
tuning: Few-shot segmentation requires few-parameters
fine-tuning,” 2022.
[22] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and
Weizhu Chen, “Lora: Low-rank adaptation of large lan-
guage models,” 2021.
[23] Roland Gao, “Rethinking dilated convolution for real-
time semantic segmentation,” 2023.
[24] Ekin D. Cubuk, Barret Zoph, Jonathon Shlens, and
Quoc V. Le, “Randaugment: Practical automated data
augmentation with a reduced search space,” 2019.
[25] Maithra Raghu, Thomas Unterthiner, Simon Kornblith,
Chiyuan Zhang, and Alexey Dosovitskiy, “Do vision
transformers see like convolutional neural networks?,”
2022.
[26] Sachin Ravi and Hugo Larochelle, “Optimization as a
model for few-shot learning,” in International Confer-
ence on Learning Representations, 2017.
[27] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Ko-
ray Kavukcuoglu, and Daan Wierstra, “Matching net-
works for one shot learning,” 2017.
[28] Chelsea Finn,
Pieter Abbeel,
and Sergey Levine,
“Model-agnostic meta-learning for fast adaptation of
deep networks,” 2017.
[29] Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pas-
cal Lamblin, Utku Evci, Kelvin Xu, Ross Goroshin, Car-
les Gelada, Kevin Swersky, Pierre-Antoine Manzagol,
and Hugo Larochelle,
“Meta-dataset: A dataset of
datasets for learning to learn from few examples,” 2020.
[30] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and
Ziwei Liu,
“Learning to prompt for vision-language
models,” International Journal of Computer Vision, vol.
130, no. 9, pp. 2337–2348, July 2022.
[31] Kai Li, Yulun Zhang, Kunpeng Li, and Yun Fu, “Adver-
sarial feature hallucination networks for few-shot learn-
ing,” 2020.
[32] Bharath Hariharan and Ross Girshick, “Low-shot visual
recognition by shrinking and hallucinating features,”
2017.
[33] Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri,
and Adam Trischler, “Rapid adaptation with condition-
ally shifted neurons,” 2018.
[34] Chi Zhang, Henghui Ding, Guosheng Lin, Ruibo Li,
Changhu Wang, and Chunhua Shen, “Meta navigator:
Search for a good adaptation policy for few-shot learn-
ing,” 2021.
[35] Tsendsuren Munkhdalai and Hong Yu,
“Meta net-
works,” 2017.
[36] Wei-Hong Li, Xialei Liu, and Hakan Bilen, “Universal
representation learning from multiple domains for few-
shot classification,” 2021.
[37] Yonglong Tian, Yue Wang, Dilip Krishnan, Joshua B.
Tenenbaum, and Phillip Isola, “Rethinking few-shot im-
age classification: a good embedding is all you need?,”
2020.
[38] Wei-Hong Li, Xialei Liu, and Hakan Bilen,
“Cross-
domain few-shot learning with task-specific adapters,”
2022.
[39] Khoi Nguyen and Sinisa Todorovic, “Feature weighting
and boosting for few-shot segmentation,” 2019.
[40] Lihe Yang, Wei Zhuo, Lei Qi, Yinghuan Shi, and Yang
Gao, “Mining latent classes for few-shot segmentation,”
2021.
8. APPENDIX
8.1. Detailed results for every dataset
Table 2 provides detailed results for the three datasets sepa-
rately. Several noteworthy observations can be made:
• Performance Disparity: The performance range across
the three datasets varies significantly, primarily influ-
enced by dataset size and class count. PPD, with only
two classes (foreground and background), presents a
comparatively easier task. However, training on PPD
is more unstable due to the limited number of training
examples—only two images in the support set. Conse-
quently, this instability results in a larger standard devi-
ation for PPD compared to COCO and Cityscapes. The
selection of these two images plays a critical role, and
the images themselves exhibit substantial dissimilari-
ties across the three dataset segments.
• SAM Image Encoder Performance: The performance
of SAM image encoder on COCO is notably poorer
compared to other models, despite its strong perfor-
mance on the other two datasets. This discrepancy may
be attributed to the isolation of the image encoder in our
approach. The adaptation of the entire SAM model for
prompt-free Few-Shot Semantic Segmentation remains
an avenue for future exploration.
8.2. Grid search for learning rate
In this section, we present the best learning rates obtained for
each combination of (model, method) on both Cityscapes and
COCO datasets. The learning rate values explored include
10−2, 10−3, 10−4, 10−5, and 10−6.
Table 2. Detailed results of mIoU on our three considered datasets in 1-shot semantic segmentation.
Linear
Multilayer
SVF
LoRA
Fine-tuning
Cityscapes











SAM
35.72±1.50
39.06±1.97
38.90±0.48
38.50±0.12
38.14±0.40
DINO V2
48.80±1.82
46.77±2.80
51.96±1.37
54.35±1.55
50.87±1.25
CLIP
23.83±1.51
26.10±2.01
28.72±1.06
27.95±1.62
27.74±1.38
MAE
23.63±0.89
23.81±0.76
25.88±0.32
26.10±0.26
25.07±0.64
FCN-ResNet50
32.39±1.79
34.12±2.01
36.14±1.19
35.74±1.41
36.17±1.41
COCO











SAM
03.13±0.0.09
06.21±0.32
05.31±0.09
05.85±0.13
05.16±0.31
DINO V2
23.24±0.38
20.92±0.19
28.30±0.77
28.99±1.33
28.15±1.24
CLIP
11.32±0.31
14.47±0.29
15.70±0.71
13.62±0.78
15.13±0.91
MAE
8.54±0.46
08.60±0.45
10.52±0.45
10.13±0.42
10.71±0.57
FCN-ResNet50
10.08±0.32
08.82±0.88
12.05±0.33
11.71±0.24
11.88±0.38
PPD











SAM
83.14±10.36
84.82±00.43
81.32±17.07
84.94±10.11
83.75±10.01
DINO V2
92.31±01.84
92.85±01.76
93.05±02.57
89.67±06.43
92.61±02.10
CLIP
72.49±10.78
78.14±06.81
78.28±12.63
73.13±11.70
73.19±08.69
MAE
74.34±10.88
77.54±07.95
76.90±07.95
72.87±12.83
73.62±10.59
FCN-ResNet50
70.86±05.91
89.31±01.88
82.01±08.04
76.91±10.29
70.84±06.15
Table 3. Best learning rate value for every experiment
SVF
LoRA
Fine-tuning
Cityscapes











SAM
10−2
10−2
10−4
DINO V2
10−3
10−3
10−6
CLIP
10−4
10−3
10−5
MAE
10−3
10−3
10−4
FCN-ResNet50
10−3
10−2
10−3
COCO











SAM
10−2
10−2
10−3
DINO V2
10−3
10−3
10−6
CLIP
10−4
10−4
10−5
MAE
10−2
10−2
10−3
FCN-ResNet50
10−4
10−3
10−4
Notably, we observe that the optimal learning rates exhibit
a degree of consistency between the two datasets for a given
model and method. While the exact optimal values may not
be identical, the variation in performance remains low. Fur-
thermore, applying the optimal learning rate from one dataset
to the other does not lead to a significant drop in performance.
These findings suggest that the identified learning rate values
can serve as a robust baseline when dealing with new, previ-
ously unseen datasets.
","nanFew-shot semantic segmentation has gained attention in recent years, with studies exploring various benchmarks and methodologies. Earlier works focused on in-domain tasks, while subsequent research ventured into cross-domain settings, aligning with more realistic scenarios. Methodologically, diverse approaches have emerged, ranging from hallucination-based to meta-learning. Regarding few-shot classification, straightforward methods utilizing simple finetuning atop competitive pretrained models have demonstrated effectiveness. However, the landscape for few-shot semantic segmentation differs, as it often involves fully labeled few-shots and the utilization of pretrained foundation models, not limited to those trained solely on ImageNet. This approach mirrors contemporary industry requirements for efficient model selection."
"This survey paper discusses privacy preservation in mobile crowdsourcing, edge computing, and recommender systems. It explores the latest trends, emphasizing the importance of privacy and data security in the increasingly data-driven world. A comprehensive analysis of the literature is presented, covering topics such as identity privacy, data privacy, location privacy, and privacy-preserving techniques. Additionally, the paper discusses research directions and future prospects, including the development of benchmark datasets and context-aware recommender systems. The paper concludes by emphasizing the importance of privacy protection in emerging technologies and the need for ongoing research to address evolving challenges.","The rapid advancement of technology has brought opportunities and challenges in mobile crowdsourcing, edge computing, and recommender systems. This survey paper focuses on these interconnected fields, highlighting the critical need for privacy protection in our data-oriented world. It explores recent developments, emphasizing privacy and data security in these dynamic areas. Our method involves an in-depth analysis of academic works, providing a comprehensive understanding of the sectors and their shifting focus towards privacy concerns.","Our survey explores the convergence of mobile crowdsourcing, edge computing, and recommender systems while emphasizing privacy considerations. We utilized structured search queries from academic databases to identify relevant literature. The search focused on publications from 2012 to 2021, considering both contemporary and seminal works to provide a holistic understanding of the research domains. We analyzed the gathered literature for patterns, approaches, outcomes, and research gaps, employing a thematic synthesis approach to categorize findings according to the survey's objectives.","Our analysis revealed several key findings. Identity privacy is crucial for user privacy protection, encompassing private information like names and addresses. Consolidated Identity Management Systems (CIDM) and Improved Identity Management Protocol (I2DM) were proposed to safeguard user identity. Data privacy in cloud computing is threatened when user data is transferred to distributed servers. Homomorphic encryption and adding noise/perturbation are popular techniques to address this issue. Local Differential Privacy (LDP) has gained attention as a solution for processing data while preserving personal information.","This survey paper provided a comprehensive overview of privacy-preserving techniques in cloud and edge computing, highlighting the ongoing challenges and evolving solutions in the field. We discussed future research directions, including the development of a benchmark dataset, the integration of context-aware recommender systems with local differential privacy techniques, and the exploration of the intersection of Large Language Models (LLMs) and recommender systems with a focus on privacy. The survey concluded by emphasizing the importance of addressing privacy concerns in emerging technologies and the need for continuous research to adapt to changing challenges and opportunities.","Progress in Privacy Protection: A Review of Privacy Preserving Techniques in Recommender Systems, Edge Computing, and Cloud Computing","Syed Raza Bashir, Shaina Raza, Vojislav Misic","Progress in Privacy Protection: A Review of Privacy
Preserving Techniques in Recommender Systems, Edge
Computing, and Cloud Computing
Syed Raza Bashir∗, Shaina Raza†, Vojislav Misic‡
January 23, 2024
Abstract
As digital technology evolves, the increasing use of connected devices brings both challenges
and opportunities in the areas of mobile crowdsourcing, edge computing, and recommender sys-
tems. This survey focuses on these dynamic fields, emphasizing the critical need for privacy
protection in our increasingly data-oriented world. It explores the latest trends in these inter-
connected areas, with a special emphasis on privacy and data security. Our method involves
an in-depth analysis of various academic works, which helps us to gain a comprehensive un-
derstanding of these sectors and their shifting focus towards privacy concerns.
We present
new insights and marks a significant advancement in addressing privacy issues within these
technologies. The survey is a valuable resource for researchers, industry practitioners, and pol-
icy makers, offering an extensive overview of these fields and their related privacy challenges,
catering to a wide audience in the modern digital era.
Keywords: Privacy; Security; Edge Computing, Location, Cloud Computing, Recommender
Systems, Large Language Models.
1
Introduction
The digital age is marked by an extraordinary growth in connected devices, leading to a massive
influx of data through the Internet [12]. This data is primarily managed by cloud infrastruc-
tures.
The proliferation of smart devices such as smartphones, tablets, smartwatches, and
fitness trackers has transformed them into essential aspects of daily life [8]. These devices ac-
cumulate extensive contextual information about users, encompassing their location, activities,
and environmental conditions [5]. This information is crucial for applications in predicting user
behavior and providing personalized experiences.
Mobile crowdsourcing has emerged as a significant phenomenon, where individuals collec-
tively contribute data through various digital channels [32]. Applications in this domain, like
traffic monitoring systems, utilize crowd-sourced data to offer real-time insights. However, the
process often raises concerns about the privacy of individual contributors. The transparency
in data usage and the potential risk of sensitive information being accessed by unauthorized
entities are issues that need addressing [11, 26].
∗Toronto Metropolitan University; syedraza.bashir@torontomu.ca
†University of Toronto; shaina.raza@utoronto.ca
‡Toronto Metropolitan University; vmisic@cs.torontomu.ca
1
arXiv:2401.11305v1  [cs.CR]  20 Jan 2024
The rapid expansion in mobile data traffic has led to information overload, posing challenges
in data management and processing.
Edge computing has been identified as a promising
solution to this problem [78]. It involves shifting data processing from central cloud servers to
the edge of the network, closer to the data sources. This approach not only alleviates network
stress but also raises concerns regarding data privacy and security.
Recommender systems [55] have also gained popularity, especially in mobile navigation, by
suggesting Points of Interest (POIs) based on user preferences [11, 12]. While these systems
enhance user experience, they also collect and process personal user data, leading to potential
privacy breaches. The balance between personalization and privacy protection is a critical issue
that needs to be addressed [44].
In this work, we present a survey on mobile crowdsourcing, edge computing, and recom-
mender systems, with a primary focus on privacy preservation (shown in Figure 1. Our goal is
to analyze and summarize recent advancements and research findings in these fields, providing
valuable insights to researchers, practitioners, and policymakers regarding the intersection of
these technologies and privacy concerns.
Figure 1: Our survey explores the convergence of mobile crowdsourcing, edge computing, and
recommender systems while emphasizing privacy considerations
1.1
Literature Search Strategy
Academic repositories such as ACM Digital Library, IEEE Xplore, Springer, Elsevier, Google
Scholar, DBLP, CiteSeerX, Microsoft Academic Search, Web of Science, and ScienceDirect
were utilized for searching the literature. Publications from 2012 to 2021 were primarily con-
sidered. Besides publications, seminal and highly cited related papers were also included to
ensure a comprehensive understanding of the field’s evolution. Around 150 papers were initially
identified based on their relevance to the topics of mobile crowdsourcing, edge computing, and
recommender systems. Papers from ’grey literature’ (unpublished or non-peer-reviewed papers)
were excluded to maintain the scholarly rigor. This resulted in a final count of approximately
68 peer-reviewed papers. Papers were analyzed for trends, methodologies, findings, and gaps in
research. A thematic synthesis approach was used to categorize findings into coherent themes
2
relevant to the survey’s objectives.
Search Queries: We employed a structured approach to search for relevant literature.
The following queries were used to search from the academic databases:
1. (""Mobile Crowdsourcing"" AND ""Edge Computing"" AND ""Recommender Systems"" AND ""
,→ Privacy Preservation"") AND (""Data Security"" OR ""Real-Time Data Processing
,→ "") AND (2012-2019)
2. (""Mobile Crowdsourcing"" AND ""Edge Computing"" AND ""Recommender Systems"") AND
,→ (""User Context"" OR ""Personalized Services"") AND (""IoT"" OR ""Cloud
,→ Computing"") AND (peer-reviewed)
3. (""Mobile Crowdsourcing"" AND ""Edge Computing"") AND (""Recommender Systems"" AND
,→ ""Privacy"" AND ""Information Overload"") AND (""Smart Devices"" OR ""User
,→ Behavior Prediction"") AND (2012-2019)
1.2
Differentiation from Previous Works
This survey aims to provide a holistic and up-to-date understanding of the intersection of
mobile crowdsourcing, edge computing, and recommender systems, with a special focus on
privacy challenges and solutions. Unlike previous works that typically concentrate on individual
aspects of these domains, this study brings together these interrelated fields under a unified
lens, offering a novel and comprehensive perspective. We present a meta-review of previous
and prominent surveys in these domains.
Edge Computing Literature: A survey [10] contrasts edge computing with cloud com-
puting, underscoring the unique characteristics of edge computing for real-time and local data
processing, along with its recent research and applications. Another study [34] examines the
role of edge computing in the Internet of Things (IoT), particularly in machine signal process-
ing and fault diagnosis, highlighting its efficiency in managing large volumes of IoT-generated
data.
Further, the survey [63] delves into ’Edge AI’, exploring the integration of edge computing
and AI, its applications, and the influence of AI algorithms on decision-making and processing
at the network’s edge.
The security and privacy challenges specific to edge computing are
discussed in [42], noting that traditional cloud computing privacy methods are inadequate. [23]
emphasizes location privacy in edge computing, and [78] lists security and privacy preservation
techniques, with a focus on cloud computing and less emphasis on edge-specific strategies.
Recommender Systems Surveys: Recent surveys in recommender systems have focused
on various aspects such as fairness, trustworthiness, and algorithmic advancements [28], with a
particular emphasis on privacy. The reduction of bias in news recommender systems is discussed
in [53]. An in-depth analysis of privacy-preserving techniques in federated recommendation
systems is presented in [7], covering methods, challenges, and future directions, particularly
in the context of collaborative filtering and personalization. [64] explores how federated rec-
ommendation systems can balance personalization with privacy, discussing key challenges such
as scalability, efficiency, and user privacy preservation. The critical issue of user privacy in
recommender systems, including the tension between personalization and privacy, is examined
in [20].
Mobile Computing Surveys: In mobile computing, recent surveys have focused on secu-
rity trends, healthcare applications during the COVID-19 pandemic, and the integration with
cloud computing. [61] explores evolving security challenges in mobile cloud computing and
strategies for safeguarding these environments. The significant role of mobile computing in
3
Figure 2: Mindmap Diagram of Survey.
healthcare, especially during the pandemic, is highlighted in [6], addressing both challenges
and potential solutions.
We recognize that there are numerous surveys across various individual fields, but our
primary focus is on those that pertain to or have aspects related to privacy.
1.3
Contributions
This work consolidates several key contributions:
1. A novel interdisciplinary exploration integrating mobile crowdsourcing, edge computing,
and recommender systems with a focus on privacy preservation. This approach not only
highlights privacy as a critical, often overlooked aspect but also positions edge computing
as a viable solution for privacy challenges in these domains.
2. A comprehensive analysis of the literature, merging contemporary and seminal academic
sources to provide a thorough understanding of the subjects and a clear picture of the
evolving research trends in these interrelated fields.
The mindmap diagram of our survey theme is shown in Figure 2
4
Figure 3: Anatomy of a mobile crowd-sourcing campaign
2
Comprehensive Overview of Pertinent Research Do-
mains
This section provides a detailed overview of key research areas: (i) mobile crowdsourcing, (ii)
edge computing, (iii) recommender systems, and (iv) privacy preservation techniques relevant
to these domains.
2.1
Overview of Mobile Crowdsourcing
Mobile crowdsourcing represents a dynamic field where collective user contributions, primarily
via mobile devices, drive data collection and service provision [25, 60]. This domain leverages
user-submitted data, ranging from geo-spatial and behavioral data to environmental and health
metrics.
Its applications span diverse sectors including environmental monitoring, disaster
response, urban planning, healthcare, and transportation [31].
A prime example of mobile crowdsourcing’s impact is Waze [1], a navigation app that
amalgamates user-generated traffic data to offer real-time routing guidance and traffic updates.
The data processing occurs on servers, demonstrating a practical implementation of mobile
crowdsourcing.
Key Stages in Mobile Crowdsourcing:
1. Tasking Stage: Defining data collection objectives.
2. Collecting Stage: Acquiring data from users and the environment.
3. Storing Stage: Centralizing data on cloud or edge servers.
4. Mining Stage: Analyzing and extracting insights from the data.
5. Publishing Stage: Disseminating findings to the end-users.
5
Privacy Considerations:
The effectiveness of mobile crowdsourcing hinges on comprehensive data collection, raising sig-
nificant privacy concerns. The transfer of sensitive location data and other personal information
to cloud or edge servers presents privacy and security challenges [2]. This survey addresses such
privacy issues, with a particular emphasis on the use of Edge Computing, which offers benefits
in terms of performance, cost efficiency, and enhanced data security [3].
2.2
Overview of Edge Computing
Edge computing signifies a transformative approach in data processing and management for
intelligent applications, characterized by the decentralization of storage and computational re-
sources. This approach positions these resources at the network’s periphery, closer to data
sources [78]. Though occasionally conflated with fog computing [51], edge computing is dis-
tinct and crucial for numerous real-time, critical applications. These applications encompass a
wide array of sectors including autonomous vehicles, smart homes, emergency response, smart
agriculture, and modernized power grids.
A seminal work in this area is the comprehensive survey by Luo et al. [35], which thor-
oughly investigates the pivotal role of resource scheduling in edge computing. This work pro-
vides insights into various aspects such as architectural design, collaborative strategies, both
centralized and decentralized approaches, diverse application contexts, and outlines emerging
research challenges in the field.
The core purpose of edge computing is to reallocate specific computational tasks, data,
and services from centralized cloud infrastructures to the network edge.
Such reallocation
enables more efficient data processing near user locations by leveraging edge servers, optimally
positioned to bridge the gap between cloud systems and end-users [70, 19]. This architectural
shift is graphically depicted in Figure 4, which elucidates the dual role of edge computing
platforms in data storage and processing at the network edge.
Moreover, Figure 4 elucidates a tripartite architecture encompassing the user, edge, and
cloud layers. At the User layer, data flow originates from smart devices and is directed towards
edge servers situated in the Edge layer.
Here, the servers perform a spectrum of services,
including delivering POI recommendations to the devices. This processed data is subsequently
relayed to the Cloud layer for consolidated storage in cloud servers.
2.3
Comprehensive Analysis of Recommender Systems
This section offers an in-depth exploration of the various methodologies employed in recom-
mender systems, a crucial component of contemporary smart applications.
Fundamentals of Recommender Systems:
Recommender systems, pivotal in the realm of information filtering technology, are instrumen-
tal in delivering relevant information tailored to the unique preferences and needs of users [4].
Serving as a solution to information overload, these systems analyze extensive data, including
signals and sensors, to offer precise recommendations. Broadly categorized into collaborative
and content-based filtering algorithms, these systems are foundational in many smart applica-
tions [57, 54, 52].
Categories of Recommender Systems:
1. Content-Based Filtering: This approach leverages item descriptions and user preferences
to generate recommendations. It builds user and item profiles within a shared feature
space but faces challenges like over-specialization and the need for detailed item/user
features [77].
6
Figure 4: Edge computing architecture
2. Collaborative Filtering: Distinct from content-based systems, collaborative filtering relies
on user behavior patterns, such as ratings and interactions, to identify similarities and
suggest items. Its main challenge is the new item (cold start) problem, where lack of
sufficient user interaction impedes effective recommendations [4].
3. Context-Aware Recommender Systems: These advanced systems provide enhanced recom-
mendations by incorporating the user’s specific contextual situation, like spatio-temporal
context, into the recommendation process [5].
4. Hybrid Filtering: To overcome the limitations of individual methods, hybrid filtering
combines multiple techniques, fusing ratings from various algorithms to produce a cohe-
sive recommendation metric. This method integrates both objective and subjective item
properties to predict recommendation quality.
Deep Learning in Recommender Systems:
Recent advancements have seen the emergence of deep learning-based systems, revolutionizing
the field with their ability to amalgamate diverse recommendation strategies [80, 56, 54]. These
systems utilize sophisticated neural network methodologies to adapt and refine recommendation
processes across varied domains.
Given the critical intersection of mobile crowdsourcing, edge computing, and recommender
systems, and their collective emphasis on user privacy, the subsequent sections will delve into
an array of privacy-preserving techniques. This discussion aims to highlight strategies that
safeguard user privacy while maintaining the efficacy and reliability of recommender systems.
7
3
Overview of Privacy Preserving Techniques
This section delves into the critical aspects of end-user information protection, focusing on
three primary areas: (i) identity privacy, (ii) data privacy, and (iii) location privacy.
3.1
Identity Privacy in Cloud Computing
• Significance and Threats: Identity privacy is crucial for user privacy protection, en-
compassing private information like names, addresses, and phone numbers [75].
• Consolidated Identity Management Systems (CIDM): Proposed by Khalil et al.
[30], CIDM safeguards user identity by separating authorization credentials, adding an
extra authentication layer, and securing communication links with cloud service providers.
• Improved Identity Management Protocol (I2DM): Jeong et al. introduced I2DM
[27], utilizing pretty good privacy encryption for cryptographic privacy through public
key infrastructure.
• Public Auditing Protocols: Yu et al. designed protocols [75] for maintaining data
integrity and user anonymity in cloud storage using asymmetric group key agreement and
proxy re-signature.
• Chameleon Hash Signature Algorithm: Zhang et al. proposed a protocol [79] based
on this algorithm for identity privacy, allowing users to generate pseudo-key pairs to
anonymize identity.
• Anonymous Data Reporting Protocol: Yao et al. [74] proposed a two-stage protocol
for user privacy protection, using public key encryption and XOR operations. However,
it’s limited by its scalability.
• Task Recommendation Framework: Gong et al.
[22] developed a framework for
mobile crowdsourcing tasks that preserves identity privacy through a privacy-aware opti-
mization model and statistics collection.
• Hybrid Privacy-Preserving Mechanism: Vergara et al. [67] combined anonymization
and data obfuscation, though not efficiently practical for real-world applications.
• Privacy-Preserving Mobile Crowdsourcing (PPMC): Introduced by Ni et al. [45],
PPMC extends BBS+ signature and proxy encryption but is limited by its computational
demands.
• Edge Computing and Identity Privacy: Several studies [37, 68, 33] have explored
pseudonym technology, cryptographic methods, and data aggregation schemes in edge
computing environments to preserve identity privacy. However, these methods are chal-
lenged by de-anonymization attacks [21, 43, 46] and limited data integrity [68].
3.2
Data Privacy in Cloud Computing
• Challenges and Techniques: Data privacy is threatened when user data is transferred
to distributed servers. Popular techniques include homomorphic encryption [14, 24, 40, 82]
and adding noise/perturbation [16, 29, 66, 69].
• Homomorphic Encryption and Its Limitations: While providing strong privacy,
homomorphic encryption-based solutions often introduce significant computational and
communication overheads.
• Differential Privacy and Local Perturbation: These approaches enhance data pri-
vacy but may impact data utility and are subject to challenges in large-scale applications.
8
3.3
Data Privacy in Edge Computing
• Privacy Challenges and Technologies: In edge computing, unique challenges arise
due to the sensitivity of data and diverse technologies involved [50].
• Local Differential Privacy (LDP): LDP has gained attention as a solution that pro-
cesses data while preserving personal information. However, it can reduce data utility
due to noise addition [62].
• Local Differential Privacy Obfuscation (LDPO): The LDPO framework aggregates
and distills data at the edge, maintaining privacy for sensitive user data [71]. However,
implementing LDPO effectively requires balancing between privacy and data utility.
3.4
Location Privacy
• Rise of Location-Based Services (LBS): With the increasing popularity of LBS,
preserving location privacy has become a major concern.
• Techniques in Cloud Computing: Various techniques [17, 38, 49, 65, 76] aim to
enhance privacy through data sanitization, often trading data utility for privacy.
• Participatory Mechanisms and Reputation Systems: These systems, like PRI-
VASENSE [41], focus on building trust and anonymizing user data but face limitations
in practical implementation.
• Peer-to-Peer Approaches: Techniques like Sprinkler [36] and Cascade [15] offer de-
centralized protocols for privacy-preserving communication, focusing on proactive session
handoffs and data retention on personal devices.
3.5
Location Privacy in Edge Computing
• Edge Computing and User Location Privacy: Edge computing poses unique loca-
tion privacy challenges due to its architecture and frequent user location checks by edge
servers [45].
• Fog-based Vehicular Crowdsourcing: Ni et al.
proposed a fog-based application
for vehicular crowdsourcing, focusing on preserving driver privacy while using real-time
navigation and parking assistance [45].
• Certificateless Aggregate Signcryption: Basudan et al. designed a protocol for ve-
hicular crowdsensing in a fog framework, combining pseudonym and mix-zone techniques
for enhanced location privacy [13].
• Pseudonym Technology for Location Privacy: Pseudonym technology is used for
anonymizing service requests, but it is challenged by de-anonymization techniques based
on user behavior analysis [21, 43, 46].
This comprehensive survey highlights the multifaceted nature of privacy-preserving tech-
niques in cloud and edge computing, underscoring the ongoing challenges and evolving solutions
in the field.
9
4
Discussion, Future Prospects, and Research Direc-
tions
4.1
Discussion and Future Prospects
This section elaborates on the current discussions, envisages future prospects, and suggests
potential research directions in the fields of mobile crowdsourcing, recommender systems, and
edge computing.
4.2
Benchmark Dataset Development
A pivotal future direction is the creation of a benchmark dataset encompassing data from mobile
crowdsourcing, recommender systems, and edge computing, with a primary focus on preserving
user privacy. This entails constructing a dataset where user identities are anonymized [59].
Potential sources for dataset compilation include well-known APIs such as Foursquare1 and
the NYC Restaurant Rich Dataset2, alongside Check-ins, Tips, Tags, routes, etc. [73]. The
Global-scale Check-in Dataset [72] also offers valuable data. The goal is to anonymize user
identities in the dataset and release it under an appropriate license. Data from sources like the
Foursquare API should be longitudinal, covering a broad spectrum (e.g., various IoT sensor
check-in information) across different time frames (years, months, days). This approach will
encourage researchers to delve deeper into the intersection of these fields.
4.3
Context-Aware Recommender Systems
For capturing sensor data, a context-aware recommender system is an optimal choice. Such a
system would not only consider users-items as primary entities but also integrate contextual
features like time, location, temperature, and finer details like time of day, week, or month
[55, 54, 9]. This contextual information can be extracted from the aforementioned dataset or
elicited through additional data gathering techniques. Incorporating these contextual details
into the 2D (users-items) matrix of the dataset can significantly enhance the recommendation
process [39].
4.4
Privacy Protection in Edge Computing
In terms of privacy, local differential privacy is a suitable method for safeguarding data on
edge servers [82]. This technique involves injecting Laplacian noise into the source data [18],
which, while enhancing privacy, may adversely affect data utility. Future research could focus
on designing local differential privacy algorithms specifically for edge computing, aiming to
strike a balance between privacy protection and data utility.
4.5
Proposed System Design
The proposed system design for our research includes developing algorithms and frameworks
that effectively combine context-aware recommender systems with local differential privacy
techniques. This integration aims to provide robust privacy protection while maintaining the
quality and utility of the recommendations made in an edge computing environment.
1https://foursquare.com/
2https://www.kaggle.com/danofer/foursquare-nyc-rest
10
4.6
Large Language Models (LLMs) and Recommender Sys-
tems: A Focus on Privacy
With the rising prominence of Large Language Models (LLMs) [81] and their integration into
various technological spheres, including recommender systems, a significant area of concern and
research interest is the safeguarding of privacy [58]. LLMs, with their extensive data processing
capabilities, can enhance the personalization and efficiency of recommender systems. However,
they also pose substantial privacy risks due to the sensitivity of the data they handle and their
potential to inadvertently reveal personal information.
The incorporation of LLMs into recommender systems necessitates the development of ro-
bust privacy-preserving mechanisms [48]. This can include the application of techniques such
as federated learning, where LLMs are trained across multiple decentralized devices while keep-
ing the training data localized, thereby minimizing data exposure. Additionally, incorporating
differential privacy into the training process of LLMs can further protect user data by adding
noise to the datasets, making it difficult to trace back to individual users.
Future research directions could explore the balance between the enhanced capabilities of
LLMs in recommender systems and the imperative of protecting user privacy. This includes
the development of algorithms that optimize the trade-off between data utility and privacy
protection [47]. Further, ethical guidelines and regulatory frameworks need to evolve alongside
these technological advancements to ensure responsible use of LLMs in recommender systems,
prioritizing user consent and transparency in data usage. The intersection of LLMs, recom-
mender systems, and privacy protection presents a fertile ground for innovative research and
technological advancement, aiming to harness the benefits of AI while upholding individual
privacy rights.
5
Conclusion
In this survey paper, we presented an overview of mobile crowdsourcing, edge computing, rec-
ommender systems. We presented various privacy techniques used to protect the privacy of the
users. We discussed the identity, data and location privacy techniques used in cloud comput-
ing as well as in edge computing. We also include the privacy techniques that applied mobile
crowdsourcing and recommender systems both in cloud computing and edge computing. We
present research directions on how to preserve the privacy of the users (using the smart devices)
and to give them the POIs recommendations that relies on the edge computing architecture.
References
[1] Driving directions, live traffic & road conditions updates - waze. https://www.waze.com/
live-map/, 2024. Accessed on 01/20/2024.
[2] Zahrah A. Almusaylim and NZ Jhanjhi. Comprehensive review: Privacy protection of user
in location-aware services of mobile cloud computing. Wireless Personal Communications,
111:541–564, 2020.
[3] Nasir Abbas, Yan Zhang, Amir Taherkordi, and Tor Skeie. Mobile edge computing: A
survey. IEEE Internet of Things Journal, 5(1):450–465, 2017.
[4] Gediminas Adomavicius and Alexander Tuzhilin. Toward the next generation of recom-
mender systems: A survey of the state-of-the-art and possible extensions. IEEE transac-
tions on knowledge and data engineering, 17(6):734–749, 2005.
11
[5] Gediminas Adomavicius and Alexander Tuzhilin. Context-aware recommender systems.
In Recommender systems handbook, pages 217–253. Springer, 2010.
[6] Yasir Ali and Habib Ullah Khan. A survey on harnessing the applications of mobile com-
puting in healthcare during the covid-19 pandemic: Challenges and solutions. Computer
Networks, 224:109605, 2023.
[7] Muhammad Asad, Saima Shaukat, Ehsan Javanmardi, Jin Nakazato, and Manabu
Tsukada. A comprehensive survey on privacy-preserving techniques in federated recom-
mendation systems. Applied Sciences, 13(10):6201, 2023.
[8] Hans Asenbaum. The Politics of Becoming: Anonymity and Democracy in the Digital
Age. Oxford University Press, 2023.
[9] Matthias Baldauf, Schahram Dustdar, and Florian Rosenberg. A survey on context-aware
systems. International Journal of ad Hoc and ubiquitous Computing, 2(4):263–277, 2007.
[10] Mohammed Barakat, Rashid A. Saeed, and Salaheldin Edam. A comparative study on
cloud and edgeb computing: A survey on current research activities and applications. In
2023 IEEE 3rd International Maghreb Meeting of the Conference on Sciences and Tech-
niques of Automatic Control and Computer Engineering (MI-STA), pages 679–684, 2023.
[11] Syed Raza Bashir and Vojislav B Miˇsi´c. Improving rating and relevance with point-of-
interest recommender system. In ICC 2022-IEEE International Conference on Commu-
nications, pages 1734–1739. IEEE, 2022.
[12] Syed Raza Bashir, Shaina Raza, and Vojislav B Misic. Bert4loc: Bert for location—poi
recommender system. Future Internet, 15(6):213, 2023.
[13] Sultan Basudan, Xiaodong Lin, and Karthik Sankaranarayanan. A privacy-preserving ve-
hicular crowdsensing-based road surface condition monitoring system using fog computing.
IEEE Internet of Things Journal, 4(3):772–782, 2017.
[14] Sebastian Blasco, Javier Bustos-Jimenez, Giselle Font, Alejandro Hevia, and Marfa Grazia
Prato.
A three-layer approach for protecting smart-citizens privacy in crowdsensing
projects. In 2015 34th International Conference of the Chilean Computer Science Society
(SCCC), pages 1–5. IEEE, 2015.
[15] Y´erom-David Bromberg, Adrien Luxey, and Fran¸cois Ta¨ıani. Cascade: Reliable distributed
session handoff for continuous interaction across devices. In 2018 IEEE 38th International
Conference on Distributed Computing Systems (ICDCS), pages 244–254. IEEE, 2018.
[16] Jianwei Chen, Huadong Ma, and Dong Zhao.
Private data aggregation with integrity
assurance and fault tolerance for mobile crowd-sensing. Wireless Networks, 23:131–144,
2017.
[17] Rui Chen, Benjamin CM Fung, Noman Mohammed, Bipin C Desai, and Ke Wang. Privacy-
preserving trajectory data publishing by local suppression. Information Sciences, 231:83–
97, 2013.
[18] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to
sensitivity in private data analysis. In Theory of Cryptography: Third Theory of Cryp-
tography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3,
pages 265–284. Springer, 2006.
[19] Abderrahime Filali, Amine Abouaomar, Soumaya Cherkaoui, Abdellatif Kobbane, and
Mohsen Guizani. Multi-access edge computing: A survey. IEEE Access, 8:197017–197046,
2020.
12
[20] Arik Friedman, Bart P Knijnenburg, Kris Vanhecke, Luc Martens, and Shlomo Berkovsky.
Privacy aspects of recommender systems. Recommender systems handbook, pages 649–688,
2015.
[21] S´ebastien Gambs, Marc-Olivier Killijian, and Miguel N´u˜nez del Prado Cortez.
De-
anonymization attack on geolocated data.
Journal of Computer and System Sciences,
80(8):1597–1614, 2014.
[22] Yanmin Gong, Lingbo Wei, Yuanxiong Guo, Chi Zhang, and Yuguang Fang. Optimal task
recommendation for mobile crowdsourcing with privacy control. IEEE Internet of Things
Journal, 3(5):745–756, 2015.
[23] Yunguo Guan, Jun Shao, Guiyi Wei, and Mande Xie. Data security and privacy in fog
computing. IEEE Network, 32(5):106–111, 2018.
[24] Felix G¨unther, Mark Manulis, and Andreas Peter. Privacy-enhanced participatory sensing
with collusion resistance and data aggregation. In Cryptology and Network Security: 13th
International Conference, CANS 2014, Heraklion, Crete, Greece, October 22-24, 2014.
Proceedings 13, pages 321–336. Springer, 2014.
[25] Bin Guo, Zhu Wang, Zhiwen Yu, Yu Wang, Neil Y Yen, Runhe Huang, and Xingshe Zhou.
Mobile crowd sensing and computing: The review of an emerging human-powered sensing
paradigm. ACM computing surveys (CSUR), 48(1):1–31, 2015.
[26] Ling Hu and Cyrus Shahabi. Privacy assurance in mobile sensing networks: Go beyond
trusted servers. In 2010 8th IEEE International Conference on Pervasive Computing and
Communications Workshops (PERCOM Workshops), pages 613–619. IEEE, 2010.
[27] Young-Sik Jeong, Ji Soo Park, and Jong Hyuk Park. An efficient authentication system
of smart device using multi factors in mobile cloud service architecture.
International
Journal of Communication Systems, 28(4):659–674, 2015.
[28] Di Jin, Luzhi Wang, He Zhang, Yizhen Zheng, Weiping Ding, Feng Xia, and Shirui Pan.
A survey on fairness-aware recommender systems. Information Fusion, 100:101906, 2023.
[29] Haiming Jin, Lu Su, Houping Xiao, and Klara Nahrstedt. Inception: Incentivizing privacy-
preserving data aggregation for mobile crowd sensing systems. In Proceedings of the 17th
ACM International Symposium on Mobile Ad Hoc Networking and Computing, pages 341–
350, 2016.
[30] Issa Khalil, Abdallah Khreishah, and Muhammad Azeem. Consolidated identity manage-
ment system for secure mobile cloud computing. Computer Networks, 65:99–110, 2014.
[31] Xiangjie Kong, Xiaoteng Liu, Behrouz Jedari, Menglin Li, Liangtian Wan, and Feng Xia.
Mobile crowdsourcing in smart cities: Technologies, applications, and future challenges.
IEEE Internet of Things Journal, 6(5):8095–8113, 2019.
[32] Zhidan Liu, Zhenjiang Li, and Kaishun Wu. Unitask: A unified task assignment design for
mobile crowdsourcing-based urban sensing. IEEE Internet of Things Journal, 6(4):6629–
6641, 2019.
[33] Rongxing Lu, Xiaodong Lin, Tom H Luan, Xiaohui Liang, and Xuemin Shen. Pseudonym
changing at social spots: An effective strategy for location privacy in vanets. IEEE trans-
actions on vehicular technology, 61(1):86–96, 2011.
[34] Siliang Lu, Jingfeng Lu, Kang An, Xiaoxian Wang, and Qingbo He. Edge computing on
iot for machine signal processing and fault diagnosis: A review. IEEE Internet of Things
Journal, 10(13):11093–11116, 2023.
13
[35] Quyuan Luo, Shihong Hu, Changle Li, Guanghui Li, and Weisong Shi. Resource scheduling
in edge computing: A survey. IEEE Communications Surveys and Tutorials, 23(4):2131–
2165, 2021.
[36] Adrien Luxey, Y´erom-David Bromberg, F´abio M Costa, Vin´ıcius Lima, Ricardo CA
da Rocha, and Fran¸cois Ta¨ıani.
Sprinkler:
A probabilistic dissemination protocol to
provide fluid user interaction in multi-device ecosystems.
In 2018 IEEE International
Conference on Pervasive Computing and Communications (PerCom), pages 1–10. IEEE,
2018.
[37] Anna Lysyanskaya, Ronald L Rivest, Amit Sahai, and Stefan Wolf. Pseudonym systems.
In Selected Areas in Cryptography: 6th Annual International Workshop, SAC’99 Kingston,
Ontario, Canada, August 9–10, 1999 Proceedings 6, pages 184–199. Springer, 2000.
[38] Mohamed Maouche, Sonia Ben Mokhtar, and Sara Bouchenak.
Hmc: Robust privacy
protection of mobility data against multiple re-identification attacks. Proceedings of the
ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(3):1–25, 2018.
[39] Christos Mettouris and George A Papadopoulos. Contextual modelling in context-aware
recommender systems: A generic approach. In International Conference on Web Infor-
mation Systems Engineering, pages 41–52. Springer, 2011.
[40] Chenglin Miao, Wenjun Jiang, Lu Su, Yaliang Li, Suxin Guo, Zhan Qin, Houping Xiao,
Jing Gao, and Kui Ren. Cloud-enabled privacy-preserving truth discovery in crowd sensing
systems.
In Proceedings of the 13th ACM Conference on Embedded Networked Sensor
Systems, pages 183–196, 2015.
[41] Hayam Mousa, Sonia Ben Mokhtar, Omar Hasan, Lionel Brunie, Osama Younes, and Mo-
hiy Hadhoud. Privasense: Privacy-preserving and reputation-aware mobile participatory
sensing. In Proceedings of the 14th EAI International Conference on Mobile and Ubiquitous
Systems: Computing, Networking and Services, pages 38–47, 2017.
[42] Mithun Mukherjee, Rakesh Matam, Lei Shu, Leandros Maglaras, Mohamed Amine Fer-
rag, Nikumani Choudhury, and Vikas Kumar. Security and privacy in fog computing:
Challenges. IEEE Access, 5:19293–19304, 2017.
[43] Arvind Narayanan and Vitaly Shmatikov.
Robust de-anonymization of large sparse
datasets. In 2008 IEEE Symposium on Security and Privacy (sp 2008), pages 111–125.
IEEE, 2008.
[44] Jianbing Ni, Xiaodong Lin, Kuan Zhang, and Xuemin Shen. Privacy-preserving real-time
navigation system using vehicular crowdsourcing. In 2016 IEEE 84th vehicular technology
Conference (VTC-Fall), pages 1–5. IEEE, 2016.
[45] Jianbing Ni, Kuan Zhang, Xiaodong Lin, Qi Xia, and Xuemin Sherman Shen. Privacy-
preserving mobile crowdsensing for located-based applications. In 2017 IEEE International
Conference on Communications (ICC), pages 1–6. IEEE, 2017.
[46] Shirin Nilizadeh,
Apu Kapadia,
and Yong-Yeol Ahn.
Community-enhanced de-
anonymization of online social networks. In Proceedings of the 2014 acm sigsac conference
on computer and communications security, pages 537–548, 2014.
[47] Xudong Pan, Mi Zhang, Shouling Ji, and Min Yang. Privacy risks of general-purpose
language models. In 2020 IEEE Symposium on Security and Privacy (SP), pages 1314–
1331. IEEE, 2020.
[48] Charith Peris, Christophe Dupuy, Jimit Majmudar, Rahil Parikh, Sami Smaili, Richard
Zemel, and Rahul Gupta. Privacy in the time of language models. In Proceedings of the
Sixteenth ACM International Conference on Web Search and Data Mining, pages 1291–
1292, 2023.
14
[49] Vincent Primault, Antoine Boutet, Sonia Ben Mokhtar, and Lionel Brunie.
The long
road to computational location privacy: A survey. IEEE Communications Surveys and
Tutorials, 21(3):2772–2793, 2018.
[50] Fang-Yu Rao and Elisa Bertino. Privacy techniques for edge computing systems. Proceed-
ings of the IEEE, 107(8):1632–1654, 2019.
[51] Abdul Rauf, Riaz Ahmed Shaikh, and Asadullah Shah. Security and privacy for iot and
fog computing paradigm. In 2018 15th Learning and Technology Conference (L&T), pages
96–101. IEEE, 2018.
[52] Shaina Raza. A covid-19 search engine (co-se) with transformer-based architecture. Health-
care Analytics, 2:100068, 2022.
[53] Shaina Raza. Bias reduction news recommendation system. Digital, 4(1):92–103, 2023.
[54] Shaina Raza and Chen Ding. News recommender system considering temporal dynamics
and news taxonomy. In 2019 IEEE international conference on big data (big data), pages
920–929. IEEE, 2019.
[55] Shaina Raza and Chen Ding.
Progress in context-aware recommender systems—an
overview. Computer Science Review, 31:84–97, 2019.
[56] Shaina Raza and Chen Ding.
Deep neural network to tradeoff between accuracy and
diversity in a news recommender system. In 2021 IEEE International Conference on Big
Data (Big Data), pages 5246–5256. IEEE, 2021.
[57] Shaina Raza and Chen Ding. News recommender system: a review of recent progress,
challenges, and opportunities. Artificial Intelligence Review, pages 1–52, 2022.
[58] Shaina Raza and Chen Ding. Improving clinical decision making with a two-stage recom-
mender system. IEEE/ACM Transactions on Computational Biology and Bioinformatics,
2023.
[59] Shaina Raza and Brian Schwartz.
Constructing a disease database and using natural
language processing to capture and standardize free text clinical information. Scientific
Reports, 13(1):8591, 2023.
[60] Ju Ren, Yaoxue Zhang, Kuan Zhang, and Xuemin Shen. Exploiting mobile crowdsourcing
for pervasive cloud services: challenges and solutions. IEEE Communications Magazine,
53(3):98–105, 2015.
[61] Bisma Sheikh, Ayesha Butt, and Javeria Hanif. Mobile cloud computing: A survey on
current security trends and future directions. Engineering Proceedings, 32(1), 2023.
[62] Hyejin Shin, Sungwook Kim, Junbum Shin, and Xiaokui Xiao. Privacy enhanced matrix
factorization for recommendation with local differential privacy. IEEE Transactions on
Knowledge and Data Engineering, 30(9):1770–1782, 2018.
[63] Raghubir Singh and Sukhpal Singh Gill. Edge ai: A survey. Internet of things and cyber-
physical systems, 2023.
[64] Zehua Sun, Yonghui Xu, Yong Liu, Wei He, Lanju Kong, Fangzhao Wu, Yali Jiang,
and Lizhen Cui.
A survey on federated recommendation systems.
arXiv preprint
arXiv:2301.00767, 2022.
[65] Manolis Terrovitis and Nikos Mamoulis. Privacy preservation in the publication of trajec-
tories. In The Ninth international conference on mobile data management (mdm 2008),
pages 65–72. IEEE, 2008.
[66] Lav R Varshney, Aditya Vempaty, and Pramod K Varshney. Assuring privacy and reliabil-
ity in crowdsourcing with coding. In 2014 Information Theory and Applications Workshop
(ITA), pages 1–6. IEEE, 2014.
15
[67] Idalides J Vergara-Laurens, Diego Mendez, and Miguel A Labrador. Privacy, quality of
information, and energy consumption in participatory sensing systems.
In 2014 IEEE
international conference on pervasive computing and communications (PerCom), pages
199–207. IEEE, 2014.
[68] Lingling Wang, Guozhu Liu, and Lijun Sun. A secure and privacy-preserving navigation
scheme using spatial crowdsourcing in fog-based vanets. Sensors, 17(4):668, 2017.
[69] Shaowei Wang, Liusheng Huang, Miaomiao Tian, Wei Yang, Hongli Xu, and Hansong
Guo. Personalized privacy-preserving data aggregation for histogram estimation. In 2015
IEEE Global Communications Conference (GLOBECOM), pages 1–6. IEEE, 2015.
[70] Xiaofei Wang, Yiwen Han, Victor C. M. Leung, Dusit Niyato, Xueqiang Yan, and Xu Chen.
Convergence of edge computing and deep learning: A comprehensive survey. IEEE Com-
munications Surveys and Tutorials, 22(2):869–904, 2020.
[71] Chugui Xu, Ju Ren, Deyu Zhang, and Yaoxue Zhang. Distilling at the edge: A local
differential privacy obfuscation framework for iot data analytics. IEEE Communications
Magazine, 56(8):20–25, 2018.
[72] Dingqi Yang, Daqing Zhang, and Bingqing Qu. Participatory cultural mapping based on
collective behavior data in location-based social networks. ACM Transactions on Intelli-
gent Systems and Technology (TIST), 7(3):1–23, 2016.
[73] Dingqi Yang, Daqing Zhang, Zhiyong Yu, and Zhiwen Yu. Fine-grained preference-aware
location search leveraging crowdsourced digital footprints from lbsns. In Proceedings of the
2013 ACM international joint conference on Pervasive and ubiquitous computing, pages
479–488, 2013.
[74] Yonglei Yao, Laurence T Yang, and Neal N Xiong. Anonymity-based privacy-preserving
data reporting for participatory sensing. IEEE Internet of Things Journal, 2(5):381–390,
2015.
[75] Yong Yu, Yi Mu, Jianbing Ni, Jiang Deng, and Ke Huang. Identity privacy-preserving
public auditing with dynamic group for secure mobile cloud storage.
In Network and
System Security: 8th International Conference, NSS 2014, Xi’an, China, October 15-17,
2014, Proceedings 8, pages 28–40. Springer, 2014.
[76] Bin Zan, Zhanbo Sun, Macro Gruteser, and Xuegang Ban. Linking anonymous location
traces through driving characteristics. In Proceedings of the third ACM conference on Data
and application security and privacy, pages 293–300, 2013.
[77] Eva Zangerle and Christine Bauer. Evaluating recommender systems: survey and frame-
work. ACM Computing Surveys, 55(8):1–38, 2022.
[78] Jiale Zhang, Bing Chen, Yanchao Zhao, Xiang Cheng, and Feng Hu. Data security and
privacy-preserving in edge computing paradigm: Survey and open issues. IEEE access,
6:18209–18237, 2018.
[79] Jianhong Zhang and Xubing Zhao. Efficient chameleon hashing-based privacy-preserving
auditing in cloud storage. Cluster Computing, 19(1):47–56, 2016.
[80] Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. Deep learning based recommender system:
A survey and new perspectives. ACM computing surveys (CSUR), 52(1):1–38, 2019.
[81] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian
Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models.
arXiv preprint arXiv:2303.18223, 2023.
16
[82] Gaoqiang Zhuo, Qi Jia, Linke Guo, Ming Li, and Pan Li. Privacy-preserving verifiable data
aggregation and analysis for cloud-assisted mobile crowdsourcing. In IEEE INFOCOM
2016-The 35th Annual IEEE International Conference on Computer Communications,
pages 1–9. IEEE, 2016.
17
","nanThis survey presents a comprehensive literature review, encompassing seminal and highly cited related papers, to ensure a thorough understanding of the field's evolution. Around 150 papers were initially identified based on their relevance to mobile crowdsourcing, edge computing, and recommender systems. After excluding papers from 'grey literature' (unpublished or non-peer-reviewed papers), approximately 68 peer-reviewed papers were analyzed for trends, methodologies, findings, and gaps in research."
"Given a Linear Temporal Logic (LTL) formula over input and output variables, reactive synthesis requires us to design a deterministic Mealy machine that gives the values of outputs at every time step for every sequence of inputs, such that the LTL formula is satisfied. In this paper, we investigate the notion of dependent variables in the context of reactive synthesis. Inspired by successful pre-processing steps in Boolean functional synthesis, we define dependent variables as output variables that are uniquely assigned, given an assignment, to all other variables and the history so far. We describe an automata-based approach for finding a set of dependent variables. Using this, we show that dependent variables are surprisingly common in reactive synthesis benchmarks. Next, we develop a novel synthesis framework that exploits dependent variables to construct an overall synthesis solution. By implementing this framework using the widely used library Spot, we show that reactive synthesis using dependent variables can solve some problems beyond the reach of several existing techniques. Further, among benchmarks with dependent variables, if the number of non-dependent variables is low (≤ 3 in our experiments), our method is able outperform all state-of-the-art tools for synthesis.","Reactive synthesis concerns the design of deterministic transducers (often Mealy or Moore machines) that generate a sequence of outputs in response to a sequence of inputs such that a given temporal logic specification is satisfied. Ever since Church introduced the problem [11] in 1962, there has been a rich and storied history of work in this area over the past six decades. Recently, it was shown that a form of pre-processing, viz. decomposing a Linear Temporal Logic (LTL) specification, can lead to significant performance gains in downstream synthesis steps [14]. The general idea of pre-processing a specification to simplify synthesis has also been used very effectively in the context of Boolean functional synthesis [3, 4, 16, 23]. Motivated by the success of one such pre-processing step, viz. identification of uniquely defined outputs, in Boolean functional synthesis, we introduce the notion of dependent outputs in the context of reactive synthesis in this paper. We develop its theory and show by means of extensive experiments that dependent outputs abound in reactive synthesis benchmarks, and can be effectively exploited to obtain synthesis techniques with orthogonal strengths vis-a-vis existing state-of-the-art techniques.","We start by first defining the notion of dependent variables in LTL specifications for reactive synthesis. Specifically, given an LTL formula ϕ over a set of input variables I and output variables O, a set of variables X ⊂ O is said to be dependent on a set of variables Y ⊂ I ∪ (O\X) in ϕ, if at every step of every infinite sequence of inputs and outputs satisfying ϕ, the finite history of the sequence together with the current assignment for Y uniquely defines the current assignment for X. The above notion of dependency generalizes the notion of uniquely defined variables in Boolean functional synthesis, where the value of a uniquely defined output at any time is completely determined by the values of inputs and (possibly other) outputs at that time. We show that our generalization of dependency in the context of reactive synthesis is useful enough to yield a synthesis procedure with improved performance vis-a-vis competition winning tools, for a non-trivial number of reactive synthesis benchmarks.","We present a novel automata-based technique for identifying a subset-maximal set of dependent variables in an LTL specification ϕ. Specifically, we convert ϕ to a language-equivalent non-deterministic Büchi automaton (NBA) Aϕ, and then deploy efficient path-finding techniques to identify a subset-maximal set of outputs X that are dependent on Y = I ∪(O \X). We implemented our method to determine the prevalence of dependent variables in existing reactive synthesis benchmarks. Our finding shows that out of 1141 benchmarks taken from the SYNTCOMP [19] competition, 300 had at least one dependent output variable and 26 had all output variables dependent.Once a subset-maximal set, say X, of dependent variables is identified, we proceed with the synthesis process as follows. Referring to the NBA Aϕ alluded to above, we first transform it to an NBA A′ϕ that accepts the language L′ obtained from L(Aϕ) after removing (or projecting out) the X variables. Our experiments show that A′ϕ is more compactly representable compared to Aϕ, when using BDD-based representations of transitions (as is done in state-of-the-art tools like Spot [6]). Viewing A′ϕ as a new (automata-based) specification with output variables O \ X, we now synthesize a transducer TY from A′ϕ using standard reactive synthesis techniques. This gives us a strategy f Y : Σ⋅I → Σ⋅O\X for each non-dependent variable in O \ X. Next, we use a novel technique based on Boolean functional synthesis to directly construct a circuit that implements a transducer TX that gives a strategy f X : Σ⋅Y → Σ⋅X for the dependent variables.","We implemented our approach in a tool called DepSynt. Our tool was developed in C++ using APIs from the widely used library Spot for representing and manipulating non-deterministic Büchi automata. We performed a comparative analysis of our tool with winning entries of the SYNTCOMP [19] competition to evaluate how knowledge of dependent variables helps reactive synthesis. Our experimental results show that identifying and utilizing dependent variables results in improved synthesis performance when the count of non-dependent variables is low. Specifically, our tool outperforms state-of-the-art and highly optimized synthesis tools on benchmarks that have at least one dependent variable and at most 3 non-dependent variables. This leads us to hypothesize that exploiting dependent variables benefits synthesis when the count of non-dependent variables is below a threshold. Given the preliminary and un-optimized nature of our implementation, we believe there is significant scope for improvement of our results.",On Dependent Variables in Reactive Synthesis,"S. Akshay, Eliyahu Basa, Supratik Chakraborty, Dror Fried","On Dependent Variables in Reactive Synthesis⋆
S. Akshay1, Eliyahu Basa2, Supratik Chakraborty1, and Dror Fried2
1 Indian Institute of Technology Bombay, Mumbai, India
2 The Open University of Israel, Israel
Abstract. Given a Linear Temporal Logic (LTL) formula over input
and output variables, reactive synthesis requires us to design a deter-
ministic Mealy machine that gives the values of outputs at every time
step for every sequence of inputs, such that the LTL formula is satis-
fied. In this paper, we investigate the notion of dependent variables in
the context of reactive synthesis. Inspired by successful pre-processing
steps in Boolean functional synthesis, we define dependent variables as
output variables that are uniquely assigned, given an assignment, to all
other variables and the history so far. We describe an automata-based
approach for finding a set of dependent variables. Using this, we show
that dependent variables are surprisingly common in reactive synthesis
benchmarks. Next, we develop a novel synthesis framework that exploits
dependent variables to construct an overall synthesis solution. By im-
plementing this framework using the widely used library Spot, we show
that reactive synthesis using dependent variables can solve some prob-
lems beyond the reach of several existing techniques. Further, among
benchmarks with dependent variables, if the number of non-dependent
variables is low (≤ 3 in our experiments), our method is able outperform
all state-of-the-art tools for synthesis.
Keywords: Reactive synthesis · Functionally dependent variables· BDDs
1
Introduction
Reactive synthesis concerns the design of deterministic transducers (often Mealy
or Moore machines) that generate a sequence of outputs in response to a sequence
of inputs such that a given temporal logic specification is satisfied. Ever since
Church introduced the problem [11] in 1962, there has been a rich and storied
history of work in this area over the past six decades. Recently, it was shown
that a form of pre-processing, viz. decomposing a Linear Temporal Logic (LTL)
specification, can lead to significant performance gains in downstream synthesis
steps [14]. The general idea of pre-processing a specification to simplify synthesis
has also been used very effectively in the context of Boolean functional synthe-
sis [3, 4, 16, 23]. Motivated by the success of one such pre-processing step, viz.
identification of uniquely defined outputs, in Boolean functional synthesis, we
introduce the notion of dependent outputs in the context of reactive synthesis in
⋆ This is the full version of a conference paper published in TACAS 2024.
arXiv:2401.11290v1  [cs.LO]  20 Jan 2024
2
S. Akshay, E. Basa, S. Chakraborty, D. Fried
this paper. We develop its theory and show by means of extensive experiments
that dependent outputs abound in reactive synthesis benchmarks, and can be
effectively exploited to obtain synthesis techniques with orthogonal strengths
vis-a-vis existing state-of-the-art techniques.
In the context of propositional specifications, it is not uncommon for a spec-
ification to uniquely define an output variable in terms of the input variables
and other output variables. A common example of this arises when auxiliary
variables, called Tseitin variables, are introduced to efficiently convert a specifi-
cation not in conjunctive normal form (CNF) to one that is in CNF [26]. Being
able to identify such uniquely defined variables efficiently can be very helpful,
whether it be for checking satisfiability, for model counting or synthesis. This
is because these variables do not alter the basic structure or cardinality of the
solution space of a specification regardless of whether they are projected out
or not. Hence, one can often simplify the reasoning about the specification by
ignoring (or projecting out) these variables. In fact, the remarkable practical suc-
cess of Boolean functional synthesis tools such as Manthan [16] and BFSS [3,4]
can be partly attributed to efficient techniques for identifying a large number of
uniquely defined variables. We draw inspiration from these works and embark
on an investigation into the role of uniquely defined variables, or dependent vari-
ables, in the context of reactive synthesis. To the best of our knowledge, this is
the first attempt at directly using dependent variables for reactive synthesis.
We start by first defining the notion of dependent variables in LTL specifi-
cations for reactive synthesis. Specifically, given an LTL formula φ over a set of
input variables I and output variables O, a set of variables X ⊆ O is said to be
dependent on a set of variables Y ⊆ I ∪ (O\X) in φ, if at every step of every
infinite sequence of inputs and outputs satisfying φ, the finite history of the se-
quence together with the current assignment for Y uniquely defines the current
assignment for X. The above notion of dependency generalizes the notion of
uniquely defined variables in Boolean functional synthesis, where the value of a
uniquely defined output at any time is completely determined by the values of
inputs and (possibly other) outputs at that time. We show that our generaliza-
tion of dependency in the context of reactive synthesis is useful enough to yield
a synthesis procedure with improved performance vis-a-vis competition winning
tools, for a non-trivial number of reactive synthesis benchmarks.
We present a novel automata-based technique for identifying a subset-maximal
set of dependent variables in an LTL specification φ. Specifically, we convert φ
to a language-equivalent non-deterministic B¨uchi automaton (NBA) Aφ, and
then deploy efficient path-finding techniques to identify a subset-maximal set of
outputs X that are dependent on Y = I ∪(O \X). We implemented our method
to determine the prevalence of dependent variables in existing reactive synthesis
benchmarks. Our finding shows that out of 1141 benchmarks taken from the
SYNTCOMP [19] competition, 300 had at least one dependent output variable
and 26 had all output variables dependent.
Once a subset-maximal set, say X, of dependent variables is identified, we
proceed with the synthesis process as follows. Referring to the NBA Aφ alluded
On Dependent Variables in Reactive Synthesis
3
to above, we first transform it to an NBA A′
φ that accepts the language L′
obtained from L(φ) after removing (or projecting out) the X variables. Our
experiments show that A′
φ is more compactly representable compared to Aφ,
when using BDD-based representations of transitions (as is done in state-of-the-
art tools like Spot [6]). Viewing A′
φ as a new (automata-based) specification
with output variables O \ X, we now synthesize a transducer TY from A′ using
standard reactive synthesis techniques. This gives us a strategy f Y : Σ∗
I → ΣO\X
for each non-dependent variable in O \ X. Next, we use a novel technique based
on Boolean functional synthesis to directly construct a circuit that implements a
transducer TX that gives a strategy fX : Σ∗
Y → ΣX for the dependent variables.
Significantly, this circuit can be constructed in time polynomial in the size of
the (BDD-based) representation of Aφ. The transducers TY and TX are finally
merged to yield an overall transducer T that describes a strategy f : Σ∗
I → ΣO
solving the synthesis problem for φ.
We implemented our approach in a tool called DepSynt. Our tool was devel-
oped in C++ using APIs from the widely used library Spot for representing and
manipulating non-deterministic B¨uchi automata. We performed a comparative
analysis of our tool with winning entries of the SYNTCOMP [19] competition to
evaluate how knowledge of dependent variables helps reactive synthesis. Our ex-
perimental results show that identifying and utilizing dependent variables results
in improved synthesis performance when the count of non-dependent variables
is low. Specifically, our tool outperforms state-of-the-art and highly optimized
synthesis tools on benchmarks that have at least one dependent variable and
at most 3 non-dependent variables. This leads us to hypothesize that exploiting
dependent variables benefits synthesis when the count of non-dependent vari-
ables is below a threshold. Given the preliminary and un-optimized nature of
our implementation, we believe there is significant scope for improvement of our
results.
Related work Reactive Synthesis has been an extremely active research area for
the last several decades (see e.g. [8, 11, 14, 15, 22]). Not only is the theoretical
investigation of the problem rich, there are also several tools that are available
to solve synthesis problems in practice. These include solutions like ltlsynt [21]
based on Spot [6], Strix [20] and BoSY [13]. Our tool relies heavily on Spot and its
APIs, which we use liberally to manipulate non-deterministic B¨uchi automata.
Our synthesis approach is based on the standard conversion of the converted
NBA to a deterministic parity automata (DPA) (see [7] for an overview of the
challenges of reactive synthesis).
Our work may be viewed as lifting the idea of uniquely defined variables in
Boolean functional synthesis to the context of reactive synthesis. Viewed from
this perspective, our work is not the first to lift ideas from Boolean functional
Synthesis. Following a framework called ”back-and-forth” for Boolean functional
synthesis that uses a decomposition of a specification into separate formulas
on input variables and on output variables [10], the work in [5] constructed a
reactive synthesis tool for specific benchmarks that admit a separation of the
specification into formulas for only the environment variables and formulas for
4
S. Akshay, E. Basa, S. Chakraborty, D. Fried
only the system variables. In this sense, this current work of ours is another step
in bridging the gap between the Boolean functional synthesis and the reactive
synthesis communities.
The remainder of the paper is structured as follows. We introduce definitions
and notations in Section 2. In Section 3 we define dependent variables for LTL
formulas, and describe our framework to find it. In Section 4 we describe our
automata-based synthesis framework and discuss some of its implementation
details in Section 5. We describe our evaluation in Section 6 and conclude in
Section 7.
2
Preliminaries
Given a finite alphabet Σ, an infinite word w is a sequence w0w1w2 · · · where
for every i, the ith letter of w, wi ∈ Σ. The prefix w0 · · · wi of size i + 1 of w
is denoted by w[0, i]. Then w[0, 0] = w0. We denote w[0, −1] to be the empty
word. The set of all infinite words over Σ is denoted by Σω. We call L ⊆ Σω
a language over infinite words in ω. When the alphabet Σ is combined from
two distinct alphabets, Σ = ΣX × ΣY for some sets of variables X, Y , we abuse
notation and for a letter a = (a1, a2) ∈ Σ, denote by a.X the projection of a
on ΣX, that is, the letter a1 ∈ ΣX. Similarly, a.Y denotes the projection of a
on ΣY , that is the letter a2 ∈ ΣY . We define by w.X the word obtained from a
word w ∈ Σ on ΣX i.e. w.X = w0.X · · · .
Linear Temporal Logic. A Linear Temporal Logic (LTL) formula is constructed
with a finite set of propositional variables V , using Boolean operators such as
∨, ∧, and ¬, and temporal operators such as next X, until U, etc. The set V
induces an alphabet ΣV = 2V of all possible assignments (true/false) to the
variables of V . The language of an LTL formula φ, denoted L(φ) is the set of
all words in Σω
V . The semantics of the operators and satisfiability relation is
defined as usual [18]. We denote the number of variables V by |V |, and size of
formula φ, i.e., number of its subformulas by |φ|. We sometimes abuse notation
and identify the singleton set of a variable {z} with the variable z, and denote
EV by E when V is clear from the context.
Nondeterministic B¨uchi Automata. A Nondeterministic B¨uchi Automaton (NBA)
is a tuple A = (Σ, Q, δ, q0, F) where Σ is the alphabet, Q is a finite set of states,
δ : Q × Σ → 2Q is a non-deterministic transition function, q0 is the initial state
and F ⊆ Q is a set of accepting states. A can be seen as a directed labeled
graph with vertices Q and an edge (q, q′) exists with a label a if q′ ∈ δ(q, a).
We denote the set of incoming edges to q by in(q) and the set of outgoing edges
from q by out(q). A path in A is then a (possibly infinite) sequence of states
ρ = (qi0, qi1, · · · ) in which for every j > 0, (qij, qij+1) is an edge in A. A run is a
path that starts in q0, and is accepting if it visits a state in F infinitely often. A
word of the run ρ is the sequence of labels seen along ρ, i.e., w = σi0σi1 · · · where
for every j ≥ 0, qij+1 ∈ δ(qij, σij). As A is nondeterministic a word can have
On Dependent Variables in Reactive Synthesis
5
many runs, although every run has a single word. A word is accepting if it has
an accepting run in A. The language L(A) is the set of all accepting words in A.
Wlog, we assume that all states and edges that are not a part of an accepting run
are removed. Finally, every LTL formula φ can be transformed in exponential
time in the length of φ, to an NBA Aφ for which L(φ) = L(Aφ) [18,27]. When φ
is clear from the context we omit the subscript and refer to Aφ as A. We denote
by |A| the size of an automaton, i.e., its number of states and transitions.
Reactive Synthesis. A reactive LTL formula is an LTL formula φ over a set of
input variables I and output variables O, with I ∩ O = ∅. In reactive synthesis
we are given a reactive LTL formula φ, and the challenge is to synthesize a
function, called strategy, f : Σ∗
I → ΣO such that every word w ∈ (ΣI × ΣO)ω
obtained by using this strategy is in L(φ). If such a strategy exists we say that
φ is realizable. Otherwise, we say that φ is unrealizable. In what follows, we
always consider only reactive LTL formulas and hence often omit the prefix
reactive while referring to them. The synthesized strategy f : Σ∗
I → ΣO that is
given as output is typically described (explicitly or symbolically) in a form of a
transducer T = (ΣI, ΣO, S, s0, δ, λ) in which ΣI and ΣO are input and output
alphabet respectively, S is a set of states with an initial state s0, δ : S×ΣI → S is
a deterministic transition function, and λ : S ×ΣI → ΣO is the output function.
A standard procedure in solving reactive synthesis is to transform the given
LTL formula φ to an NBA Aφ for which L(Aφ) = L(φ). Then transform Aφ
to a Deterministic Parity Automata (DPA) that turns to a parity game, which
solution is described as a transducer TAφ. It is known that this approach cannot
escape exponential blowups. More precisely,
Theorem 1.
1. Reactive synthesis can be solved in O(2n·2n), where n is the
size of the LTL formula.
2. Given an NBA A with n states, computing transducer TA takes Ω(2n log n).
3
Dependent variables in reactive LTL
In this section, we define dependent variables for (reactive) LTL formulas and
suggest a framework for finding a maximal set of dependent variables. Our notion
of dependent variables for LTL formulas, specifically suited to reactive synthesis,
asks that the dependency be maintained at every step of the word satisfying the
formula. While there are several notions of dependency that can be considered,
we describe the one that we use throughout the paper. As mentioned earlier, our
definition of dependency is restricted to output variables, since having depen-
dent input variables would imply that not all input values are possible for these
variables, which makes the formula unrealizable.
Definition 1 (Variable Dependency in LTL). Let φ be an LTL formula
over V with input variables I ⊆ V and output variables O = V \I. Let X, Y
be sets of variables where X ⊆ O. We say that X is dependent on Y in φ if
for every pair of words w, w′ ∈ L(φ) and i ≥ 0 if w[0, i − 1] = w′[0, i − 1] and
6
S. Akshay, E. Basa, S. Chakraborty, D. Fried
wi.Y = w′
i.Y , then we have wi.X = w′
i.X. Further, we say that X is dependent
in φ if X is dependent on V \ X in φ, i.e., it is dependent on all the remaining
variables.
Note that two words in L(φ) with different prefixes can still have different values
for X for the same values for Y , and X can still be defined dependent on Y .
As an example, consider an LTL formula φ with an input variable y, an
output variable x and a language L = {w1, w2, w3} where w1 = (y, x)ω, w2 =
(¬y, x)ω and w3 = (y, x)(¬y, x)(y, ¬x)ω. Then x is dependent on y in φ. Specif-
ically note that w1[0, 1] ̸= w3[0, 1] and thus the dependency of x is not violated,
although w1
2.y = w3
2.y and w1
2.x ̸= w3
2.x. Observe that, if X is dependent on Y
in φ for some Y , then it is also dependent in φ. We next show how to find a
maximal set of dependent variables.
3.1
Maximally dependent sets of variables
Definition 2. Given an LTL formula φ(I, O), we say that a set X ⊆ O is a
maximal dependent set in φ if X is dependent in φ and every set that strictly
contains X is not dependent in φ.
As in the propositional case [25], finding maximum or minimum dependent sets
is intractable, hence we focus on subset-maximality. Given a variable z and
set Y , checking whether z is dependent on Y , can easily be used to finding a
maximal dependent set. Indeed, we would just need to start from the empty
set and iterate over output variables, checking for each if it is dependent on
the remaining variables. For completeness, we give the pseudocode for this in
Appendix A.
Note that when all output variables are not dependent, the order in which
output variables are chosen may play a significant role in the size of the maximal
set obtained. We currently use a naive ordering (first appearance), and leave the
problem of better heuristics for getting larger maximal independent sets to future
work.
3.2
Finding dependent variables via automata
As explained above, the heart of the dependency check is to check if a given
output variable is dependent on a set of variables. We now develop an approach
for doing so based on the nondeterministic B¨uchi automaton Aφ of the original
LTL formula φ. Our framework uses the notion of compatible pairs of states of
the automaton defined as follows.
Definition 3. Let A = (Σ, Q, δ, q0, F) be an NBA with states s, s′ in Q. Then
the pair (s, s′) is compatible in A if there are runs from q0 to s and from q0 to
s′ with the same word w ∈ Σ∗.
Recall that in our definition, only states and edges that are part of an accepting
run exist in A. Then we have the following definition.
On Dependent Variables in Reactive Synthesis
7
Definition 4. Let φ be an LTL formula over V with input variables I ⊆ V and
output variables O = V \I. Let X, Y be sets of variables where X ⊆ O. Let Aφ be
an NBA that describes φ. We say that X is automata dependent on Y in Aφ,
if for every pair of compatible states s, s′ and assignments σ, σ′ for V , where
σ.Y = σ′.Y and σ.X ̸= σ′.X, δ(s, σ) and δ(s, σ′) cannot both exist in Aφ. We
say that X is automata dependent in Aφ if X is automata dependent on Y in
Aφ and Y = V \X.
As an example, consider NBA A1 from adjoining Figure 1, constructed from
some LTL formula with input I = {i} and outputs O = {o1, o2}. Here ΣI =
{0, 1}, ΣO = {0, 1}2 and edges are labeled by values of (i, o1o2). It is immedi-
ate that, (q0, q0), (q1, q1) are compatible pairs but so are (q0, q1), (q1, q0) since
they can both be reached from the initial state on reading the length 2 word
(0, 00)(0, 00). Now consider output o1. It is not dependent on {i}, i.e., only the
input, since from q0 with i = 0, we can go to different states with different values
of o1. But o1 is indeed dependent on {i, o2}. To see this consider every pair of
compatible states – in this case all pairs. Then we can see that if we fix the
values of i and o2, there is a unique value of o1 that permits state transitions to
happen from the compatible pair. For example, regardless of which state we are
in, if i = 0, o2 = 0, o1 must be 0 for a state transition to happen. On the other
hand, o2 is not dependent on either {i} or {i, o1} (as can be seen from (q0, q1)
with i = 1, o1 = 1).
q0
q1
0,11
0,00
1,11
1,10
0,11
0,00
1,11
0,00
Fig. 1. An Example NBA A1
The following shows us the relation between
automata dependency and dependency in LTL as
defined earlier.
Theorem 2. Let φ be an LTL formula with V =
I ∪ O variables, where X ⊆ O and Y ⊆ I ∪ O.
Let Aφ be an NBA that describes φ. Then X is
dependent on Y in φ if and only if X is automata
dependent on Y in Aφ.
Proof. Assume that X is dependent in φ and let
s, s′ be two compatible states in A with a joint
history w∗. Assume for contradiction that there is an assignment y for Y , for
which there are distinct assignments x, x′ for X for which both δ(s, xy) exists
and δ(s′, x′y) exist. Then this means that δ(s, xy) and δ(s′, x′y) both continue to
some accepting runs r, r respectively in A. Let w be the label of the r and w′ the
label of r′. Then w, w′ are in L(φ) with a prefix w∗, but x = wi.x¬ = w′
i.x = x′
contradicting X being relaxed dependent in φ.
Next, assume that X is automata dependent on Y in Aφ. Let w, w′ be two
words in L(φ), and thus in L(Aφ). Assume that there is i ≥ 0 for which u =
w[0, i] = w′[0, i]. Let r, r′ be accepting runs of w, w′ respectively and let s1, s2 be
the states respectively in the run r, r′ that has the same history w[0, i − 1]. Note
that this makes s1, s2 compatible. Next assume e1 = (s1, s′
1) with a label σ1 is
on r , and e2 = (s2, s′
2) with a label σ2 is on r′. Further, assume σ1.y = σ2.y.
8
S. Akshay, E. Basa, S. Chakraborty, D. Fried
Note that it means that wi+1.Y = w′
i+1.Y . Then since X is automata dependent
in Y , we have that σ1.X = σ2.X as well, hence wi+1.X = w′
i+1.X.
⊓⊔
Thus, we can focus on algorithms for finding automata dependency. We start
by describing how to find compatible states.
Finding Compatible States We find all compatible states in an automaton in
Algorithm 1 as follows. We maintain a list of in-process compatible pairs C to
which we start by adding the initial pair (q0, q0), which is of course compatible.
At each step, until C becomes empty, for each pair (si, qj) ∈ C, we add it to the
compatible pair set P, and remove it from C (in line 4). Then (in lines 5-8), we
check (in line 6) if outgoing transitions from (si, sj) lead to a new pair (s′
i, s′
j) not
already in P or C, which can be reached on reading the same letter σ and if so,
we add this pair to the in-process set C. All pairs that we put in P, C are indeed
compatible, nothing is removed from P. And when the algorithm terminates,
C is empty, which means all possible ways (from initial state pair) to reach a
possible compatible pair have been explored, thus showing correctness.
Algorithm 1 Find All Compatible States in NBA
Input NBA Aφ = (Σ, Q, δ, q0, F) of φ.
Output Set P ⊆ Q × Q of all compatible state pairs in Aφ
1: P ← ∅; C ← {(q0, q0)}
2: while C ̸= ∅ do
3:
Let (si, sj) ∈ C
4:
P ← P ∪ {(si, sj)}; C ← C \ {(si, sj)}
5:
for (s′
i, s′
j) ∈ out(s1) × out(s2) do
6:
if (s′
i, s′
j) /∈ P ∪ C and ∃σ ∈ 2Σ s.t. s′
i ∈ δ(si, σ) ∧ s′
j ∈ δ(sj, σ) then
7:
C ← C ∪ {(s′
i, s′
j)}
8:
end if
9:
end for
10: end while
11: return P
Finally, we show how to check dependency using automata, by implementing
the following procedure isAutomataDependent, described in Algorithm 2.
isAutomataDependent works by trying to find a witness to {z} being not
dependent on Y . If no such witness exists then it means that {z} is dependent
on Y . Given a variable x and a set Y = V \{z},isAutomataDependent first
uses Algorithm 1 to construct a list P of all compatible pairs in A (line 4).
Then for every pair (s, s′) ∈ P the algorithm checks through the procedure
AreStatesColliding (lines 1-2) whether there exists an assignment σ, σ′ for which
both δ(s, σ) and δ(s′, σ′) exist, σ.Y = σ′.Y and σ.{z} ̸= σ′.{z}. If so, then
the algorithm returns false: {z} is not dependent on Y (line 7). At the end of
checking all the pairs, the algorithm returns true.
On Dependent Variables in Reactive Synthesis
9
Algorithm 2 Check Dependency Based Automaton
Input
NBA Aφ = (Σ, Q, δ, q0, F) from φ, Candidate dependent variable {z},
Candidate dependency set Y .
Output Is {z} dependent on Y by Definition 4
1: procedure AreStateColliding(p, q)
2:
return ∃σp, σq ∈ 2Σ s.t. δ(p, σp) ̸= ∅ ∧ δ(q, σq) ̸= ∅ ∧ σp.Y = σq.Y ∧ σp.{z} ̸=
σq.{z}
3: end procedure
4: P ← FindAllCompatibleStates(Aφ)
5: for (s1, s2) ∈ P do
6:
if AreStateColliding(s1, s2) then
7:
return False
8:
end if
9: end for
10: return True
φ
1. LTL to NBA
Aφ
2. Identify Dep
3. Projdep
4. Syn-Nondep TY
5. Syn-Dep TX
6. Syn-Comb T
f
Aφ, X, Y
A′
φ, Y
Aφ, X
fY
fX
Fig. 2. Synthesis using dependencies
Lemma 1. Algorithm 2 returns True if and only if {z} is automata-dependent
on V \{z} in Aφ.
Thus using the above algorithm to perform dependency check we can compute
maximal sets of dependent variables (as explained earlier), which we will use next
to improve synthesis. Note that all the above algorithms run in time polynomial
(in fact, quadratic) in size of the NBA.
Corollary 1. Given NBA Aφ, computing compatible pairs, checking dependency,
building maximal dependent sets can be done in time polynomial in the size of
Aφ.
Note that if all output variables are dependent, then regardless of the order
in which the outputs are considered, for every finite history of inputs, there is
a unique value for each output that can cause the specification to be satisfied.
Therefore, there is a unique winning strategy for the specification, assuming it
is realizable.
10
S. Akshay, E. Basa, S. Chakraborty, D. Fried
4
Exploiting Dependency in Reactive Synthesis
In this section, we explain how dependencies can be beneficially exploited in a
reactive synthesis pipeline. Our approach can be described at a high level as
shown in Figure 4. This flow-chart has the following 6 steps:
1. Given an LTL formula φ over a set of variables V with input variables I ⊆ V
and output variables O = V \I, we first construct a language-equivalent NBA
Aφ = (ΣI ∪ ΣO, S, s0, δ, F) by standard means, e.g [27].
2. Then, as described in Section 3, we find in Aφ a maximal set of output
variables X that are dependent in φ. For notational convenience, in the
remainder of the discussion, we use Y for I ∪(O\X) and ΣY for ΣI ×ΣO\X.
3. Next, we construct an NBA A′
φ from Aφ by projecting out (or eliminating)
all X variables from labels of transitions. Thus, A′
φ has the same sets of
states and transitions as Aφ. We simply remove valuations of variables in X
from the label of every state transition in Aφ to obtain A′
φ. Note that after
this step, L(A′
φ) = {w | ∃u ∈ L(Aφ) s.t. w = u.Y } ⊆ Σω
Y .
4. Treating A′
φ as a (automata-based) specification with inputs I and outputs
O \ X, we next use existing reactive synthesis techniques (e.g., [7]) to obtain
a transducer TY that describes a strategy fY : Σ∗
I → ΣO\X for L(A′
φ).
5. We also construct a transducer TX that describes a function fX : (Σ∗
Y →
ΣX) with the following property: for every word w′ ∈ L(A′
φ) there exists a
unique word w ∈ L(φ) such that w.Y = w′ and for all i, wi.X = fX(w′[0, i]).
6. Finally, we compose TX and TY to construct a transducer T that defines the
final strategy f : Σ∗
I → ΣO. Recall that transducer TY has I as inputs and
O \ X as outputs, while transducer TX has I and O \ X as inputs and X as
outputs. Composing TX and TY is done by simply connecting the outputs
O \ X of TY to the corresponding inputs of TX.
In the above synthesis flow, we use standard techniques from the literature
for Steps 1 and 4, as explained above. Hence we do not dwell on these steps in
detail. Step 2 was already described in detail in Section 3. Step 3 is easy when we
have an explicit representation of the automata. As we will discuss in the next
section, it has interesting consequences when we use symbolic representations of
automata. Step 6, as explained above, is also easy to implement. Hence, in the
remainder of this section, we focus on Step 5, which is also a key contribution
of this paper. In the next section, we will discuss how steps 2, 3 and 5 are
implemented using symbolic representations (viz. ROBDDs).
Constructing transducer TX Let A = (ΣI ×ΣO, Q, δ, q0, F) be the NBA Aφ
obtained in step 1 of the pipeline shown above. Since each letter in ΣO can be
thought of as a pair (σ, σ′), where σ ∈ ΣO\X and σ′ ∈ ΣX, the transition function
δ can be viewed as a map from Q × (ΣI × ΣO\X × ΣX) to 2Q. The transducer
TX we wish to construct is a deterministic Mealy machine described by the 6-
tuple (ΣY , ΣX ∪ {⊥}, QX, qX
0 , δX, λX), where ΣY = ΣI × Σ(O\X) is the input
alphabet, ΣX is the output alphabet with ⊥ ̸∈ ΣX being a special symbol that is
On Dependent Variables in Reactive Synthesis
11
output when no symbol of ΣX suffices, QX = 2Q, that is the powerset of Q is the
set of states of TX, qX
0 = {q0} is the initial state, δX : QX ×ΣI ×Σ(O\X) → QX
is the state transition function, and λX : QX ×ΣI ×Σ(O\X) → ΣX is the output
function. The state transition function δX is defined by the Rabin-Scott subset
construction applied to the automaton Aφ [17]. Formally, for every U ⊆ Q,
σI ∈ ΣI and σ ∈ Σ(O\X), we define δX12
S. Akshay, E. Basa, S. Chakraborty, D. Fried
note on the representation of NBAs is relevant. We use the same representation
as used in Spot [6] – a state-of-the-art platform for representing and manipulating
LTL formulas and ω-automata. Specifically, the transition structure of an NBA
A is represented as a directed graph, with nodes representing states of A, and
directed edges representing state transitions. Furthermore, every edge from state
s to state s′ is labeled by a Boolean function B(s,s′) over I ∪ O. The Boolean
function can itself be represented in several forms. We assume it is represented
as a Reduced Ordered Binary Decision Diagram (ROBDD) [9], as is done in
Spot. Each such labeled edge represents a set of state transitions from s to s′,
with one transition for each satisfying assignment of B(s,s′).
Implementing Algorithms 1 and 2: Since states of the NBA Aφ are explic-
itly represented as nodes of a graph, it is straightforward to implement Algo-
rithms 1 and 2. The check in line 6 of Algorithm 1 is implemented by checking the
satisfiability of B(si,s′
i)(I, O) ∧ B(sj,s′
j)(I, O) using ROBDD operations. Similarly,
the check in line 2 of Algorithm 2 is implemented by checking the satisfiability
of W
(s,s′)∈out(p)×out(q) B(p,s)(I, O) ∧ B(q,s′)(I′, O′) ∧ V
y∈Y (y ↔ y′) ∧ (z ↔ ¬z′)
using ROBDD operations. In the above formula, I′ (resp. O′) denotes a set of
fresh, primed copies of variables in I (resp. O).
Implementing transformation of Aφ to A′
φ: To obtain A′
φ, we simply re-
place the ROBDD for B(s,s′) on every edge (s, s′) of the NBA Aφ by an ROBDD
for ∃X B(s,s′). While the worst-case complexity of computing ∃X B(s,s′) using
ROBDDs is exponential in |X|, this doesn’t lead to inefficiencies in practice be-
cause |X| is typically small. Indeed, our experiments reveal that the total size
of ROBDDs in the representation of A′
φ is invariably smaller, sometimes sig-
nificantly, compared to the total size of ROBDDs in the representation of Aφ.
Indeed, this reduction can be significant in some cases, as the following propo-
sition shows.
Proposition 1. There exists an NBA Aφ with a single dependent output such
that the ROBDD labeling its edge is exponentially (in number of inputs and
outputs) larger than that labeling the edge of A′
φ.
Proof. Let I = {i1, . . . in} and O = {o1, . . . on+1} be sets of input and output
variables. Consider the LTL formula G
On Dependent Variables in Reactive Synthesis
13
Implementing transducer TX: We now describe how to construct a Mealy
machine corresponding to the transducer TX. As explained in the previous sec-
tion, the transition structure of the Mealy machine is obtained by applying
the subset construction to Aφ. While this requires O(2|Aφ|) time if states and
transitions are explicitly represented, we show below that a sequential circuit
implementing the Mealy machine can be constructed directly from Aφ in time
polynomial in |X| and |Aφ|. This reduction in construction complexity crucially
relies on the fact that all variables in X are dependent on I ∪ (O \ X).
Let S = {s0, . . . sk−1} be the set of states of Aφ, and let in(si) denote the set
of states that have an outgoing transition to si in Aφ. To implement the desired
Mealy machine, we construct a sequential circuit with k state-holding flip-flops.
Every state U (⊆ S) of the Mealy machine is represented by the state of these k
flip-flops, i.e. by a k-dimensional Boolean vector. Specifically, the ith component
is set to 1 iff si ∈ U. For example, if S = {s0, s1, s2} and U = {s0, s2}, then U is
represented by the vector ⟨1, 0, 1⟩. Let ni and pi denote the next-state input and
present-state output of the ith flip-flop. The next-state function δX of the Mealy
machine is implemented by a circuit, say ∆X, with inputs {p0, . . . pk−1} ∪ I ∪
(O\X) and outputs {n0, . . . nk−1}. For i ∈ {0, . . . k−1}, output ni of this circuit
implements the Boolean function W
sj ∈ in(si)
14
S. Akshay, E. Basa, S. Chakraborty, D. Fried
task effectively reduces to synthesizing an |X|-dimensional vector of Boolean
functions F (s,s′) s.t. ∀I ∪ (O \ X)
On Dependent Variables in Reactive Synthesis
15
out of 1,141 SYNTCOMP benchmarks, that had at least 1 dependent output
variable (as per Definition 4). Out of the 1,141 benchmarks, 260 had either
timeout (41 total) or out-of-memory (219 total), out of which 227 failed because
of the NBA construction (adapted from Spot), i.e, Step 1 in our pipeline, did
not terminate. We found that all the benchmarks with at least 1 dependent
variable in fact belong to one of 5 benchmark families, as seen in Table 1. In
order to measure the prevalence of dependency we evaluated (1) the number of
dependent variables and (2) the dependency ratio = Total dependent vars
Total output vars . Out of
Benchmark Family Total Completed Found Dep Avg Dep Ratio
ltl2dpa
24
24
24
.434
mux
12
12
4
1
shift
11
4
4
1
tsl-paper
118
117
115
.46
tsl-smart-home-jarvis
189
167
153
.33
Table 1. Summary for 5 benchmark families, indicating the no. of benchmarks, where
the dependency-finding process was completed, the total count of benchmarks with
dependent variables, and the average dependency ratio among those with dependencies.
those depicted, Mux (for multiplexer) and shift (for shift-operator operator) were
two benchmark families where dependency ratio was 1. In total, among all those
where our dependency checking algorithm terminated, we found 26 benchmarks
with all the output variables dependent. Of these 4 benchmarks were from Shift,
4 benchmarks from mux, 14 benchmarks from tsl-paper, and 4 from tsl-smart-
home-jarvis. Note that in Mux, total dependency was found only for 4 out of
11, where the input was a power of 2. Looking beyond total dependency, among
the 300 benchmarks with at least 1 dependent variable, we found a diverse
distribution of dependent variables and ratio as shown in Figure 3.
6.2
Utilizing Dependency for Reactive Synthesis: Comparison with
other tools
Despite a large 1 hr time out, we noticed that most dependent variables were
found within 10-12 seconds. Hence, in our tool DepSynt, we limited the time
for dependency-check to an empirically determined 12 seconds, and declared
unchecked variables after this time as non-dependent. Since synthesis of non-
dependents TY (Step 5. of the pipeline) is implemented directly using Spot APIs,
the difference between our approach and Spot is minimal when there are a large
number of non-dependent variables. This motivated us to divide our experi-
mental comparison, among the 300 benchmarks where at least one dependent
variables was found, into benchmarks with at most 3 non-dependent variables
(162 benchmarks) and more than 3 non-dependent variables (138 benchmarks).
We compared DepSynt with two state-of-the-art synthesis tools, that won in
different tracks of SYNTCOMP23’ [19]: (i) Ltlsynt (based on Spot) [6] with
16
S. Akshay, E. Basa, S. Chakraborty, D. Fried
Fig. 3.
Cumulative count of benchmarks for each unique value of Total Dependent
Variables (left plot) and Dependency Ratio (right plot). The value of F(x) on y-
axis represents how many benchmarks have at most x (on x-axis) dependent vari-
ables/dependency ratio.
different configurations ACD, SD, DS, LAR, and (ii) Strix [20] with the con-
figuration of BFS for exploration and FPI as parity game solver (the overall
winning configuration/tool in SYNTCOMP’23). All the tools had a total time-
out of 3 hours per benchmark. As can be seen from Figure 4, indeed for the
case of ≤ 3 non-dependent variables, DepSynt outperforms the highly optimized
competition-winning tools. Even for > 3 case, as shown in Figure 5, the perfor-
mance of DepSynt is comparable to other tools, only beaten eventually by Strix.
DepSynt uniquely solved 2 specifications for which both Strix and Ltlsynt timed
out after 3600s, the benchmarks are mux32, and mux64, and solved in 2ms, and
4ms respectively.
6.3
Analyzing time taken by different parts of the pipeline
In order to better understand where DepSynt spends its time, we plotted in Fig-
ure 6 the normalized time distribution of DepSynt. We can see that synthesizing
a strategy for dependent variables is very fast (the gray portion)- justifying its
theoretical linear complexity bound, and so is the red-region depicting search-
ing for dependency (again, a poly-time algorithm), especially compared to the
white region synthesizing a strategy for the non-dependent variables. This also
explains why having high dependency ratio alone does not help our approach,
since even with high ratio, number of non-dependent variables could be large,
resulting in worse performance overall.
6.4
Analysis of the Projection step (Step 3.) of Pipeline
The rationale for projecting variables from the NBA is to reduce the number
of output non-dependent variables in the synthesis of the NBA, which is the
most expensive phase as Figure 6 shows. To see if this indeed contributes to
our better performance, we asked if projecting the dependent variables reduces
On Dependent Variables in Reactive Synthesis
17
Fig. 4. Cactus plot comparing DepSynt, LtlSynt, and Strix on
162 benchmarks with at most 3 non-dependent variables.
Fig. 5. Cactus plot comparing DepSynt, LtlSynt, and Strix on
138 benchmarks with more than 3 non-dependent variables.
the BDDs’ sizes, in terms of total nodes, (the BDD represents the transitions).
Figure 7 shows that the BDDs’ sizes are reduced significantly where the total
of non-dependent variables is at most 3, in cases of total dependency, the BDD
just vanishes and is replaced by the constant true/false. For the case of total
non-dependent is 4 or more, the BDD size is reduced as well.
6.5
An ablation experiment with Spot
As a final check, that dependency was causing the improvements seen, we con-
ducted a control/ablation experiment where in DepSynt we gave zero-timeout
18
S. Akshay, E. Basa, S. Chakraborty, D. Fried
Fig. 6. Normalized time distribution of DepSynt sorted by total duration over bench-
marks that could be solved successfully by DepSynt. Each color represents a different
phase of DepSynt. The pink is searching for dependency, the green is the NBA build,
the blue is the non-dependent variables and the yellow is the dependent variables syn-
thesis.
to find dependency, and classifies all output variables are classified as non-
dependent, and called this SpotModular. As can be seen in Figure 8, in the
left plot, for the case of benchmarks with at least 1 dependent and at most 3
non-dependent variables, the benefit of dependency-checking, while the plot on
the right, shows that for the remaining cases we do not see this.
6.6
Summary
Overall, we answered both the research questions we started with. Indeed there
are several benchmarks with dependent variables, and using our pipeline does
give performance benefits when no. of non-dependent variables is low. Our recipe
would be to first run our poly-time check to see if there are dependents and if
there aren’t too many non-dependents, use our approach and otherwise switch
to any existing method.
To summarize our comparison against other tools, we state the following.
When comparing with Strix, we found 252 benchmarks that had dependent vari-
ables in which DepSynt took less time than Strix. Out of which, in 126 bench-
marks DepSynt took at least 1 second less than Strix. Among these, there are
10 benchmarks (shift16, LightsTotal d65ed84e, LightsTotal 9cbf2546, LightsTo-
tal 06e9cad4, Lights2 f3987563, Lights2 0f5381e9, FelixSpecFixed3.core b209ff21,
Lights2 b02056d6, Lights2 06e9cad4, LightsTotal 2c5b09da) for which the time
taken by DepSynt was at least 10 seconds less than that taken by Strix. These
are the examples that are easier to solve by DepSynt than by Strix. For shift16,
the difference was more than 1056 seconds in favor of DepSynt. Interestingly,
shift16 also has all output variables dependent.
When comparing with Ltlsynt, we found 193 benchmarks that had dependent
variables in which DepSynt took less time than Ltlsynt. Among these, in 27
On Dependent Variables in Reactive Synthesis
19
Fig. 7. This figure illustrates the total BDD sizes of the NBA edges before and after
the projection of the dependent variables from the NBA edges, the left figure is over
the benchmark with at most 3 non-dependent variables and the right figure is over
the benchmarks with 4 or more non-dependent variables. The solid line presents the
projected BDD size and the dotted line presents the original BDD size. The y-axis is
presented in a symmetric log-scale. The benchmarks are sorted by the projected NBA’s
BDD total size.
Fig. 8. Cactus plot comparing DepSynt and SpotModular on 162 benchmarks with
at most 3 non-dependent variables (left) and 138 benchmarks with more than 3 non-
dependent variables (right).
benchmarks DepSynt took at least 1 second less than Ltlsynt. Of these, there is
one benchmark (ModifiedLedMatrix5X) for which the time taken by DepSynt
was at least 10 seconds less than that taken by Ltlsynt. Specifically, DepSynt
took 5 seconds and Ltlsynt took 55 seconds.
7
Conclusion
In this work, we have introduced the notion of dependent variables in the con-
text of reactive synthesis. We showed that dependent variables are prevalent
in reactive synthesis benchmarks and suggested a synthesis approach that may
utilize these dependency for better synthesis. As part of future work, we wish to
explore heuristics for choosing ”good” maximal subsets of dependent variables.
20
S. Akshay, E. Basa, S. Chakraborty, D. Fried
We also wish to explore integration of our method in other reactive synthesis
tools such as Strix.
References
1. Akshay, S., Arora, J., Chakraborty, S., Krishna, S.N., Raghunathan, D., Shah, S.:
Knowledge compilation for boolean functional synthesis. In: Barrett, C.W., Yang,
J. (eds.) 2019 Formal Methods in Computer Aided Design, FMCAD 2019, San
Jose, CA, USA, October 22-25, 2019. pp. 161–169. IEEE (2019)
2. Akshay, S., Chakraborty, S.: Synthesizing skolem functions: A view from theory and
practice. In: Sarukkai, S., Chakraborty, M. (eds.) Handbook of Logical Thought in
India, pp. 1–36. Springer (2022)
3. Akshay, S., Chakraborty, S., Goel, S., Kulal, S., Shah, S.: What’s hard about
boolean functional synthesis? In: Computer Aided Verification - 30th International
Conference, CAV 2018, Held as Part of the Federated Logic Conference, FloC 2018,
Oxford, UK, July 14-17, 2018, Proceedings, Part I. Lecture Notes in Computer
Science, vol. 10981, pp. 251–269. Springer (2018)
4. Akshay, S., Chakraborty, S., Goel, S., Kulal, S., Shah, S.: Boolean functional syn-
thesis: hardness and practical algorithms. Formal Methods Syst. Des. 57(1), 53–86
(2021). https://doi.org/10.1007/s10703-020-00352-2, https://doi.org/10.1007/
s10703-020-00352-2
5. Amram, G., Bansal, S., Fried, D., Tabajara, L.M., Vardi, M.Y., Weiss, G.: Adapting
behaviors via reactive synthesis. In: Silva, A., Leino, K.R.M. (eds.) Computer Aided
Verification - 33rd International Conference, CAV 2021, Virtual Event, July 20-
23, 2021, Proceedings, Part I. Lecture Notes in Computer Science, vol. 12759, pp.
870–893. Springer (2021)
6. Blahoudek, F., Duret-Lutz, A., Strejˇcek, J.: Seminator 2 can complement gener-
alized B¨uchi automata via improved semi-determinization. In: Proceedings of the
32nd International Conference on Computer-Aided Verification (CAV’20). Lecture
Notes in Computer Science, vol. 12225, pp. 15–27. Springer (Jul 2020)
7. Bloem, R., Chatterjee, K., Jobstmann, B.: Graph games and reactive synthesis.
In: Clarke, E.M., Henzinger, T.A., Veith, H., Bloem, R. (eds.) Handbook of Model
Checking, pp. 921–962. Springer (2018)
8. Bloem, R., Jobstmann, B., Piterman, N., Pnueli, A., Sa’ar, Y.: Synthesis of reac-
tive(1) designs. J. Comput. Syst. Sci. 78(3), 911–938 (2012)
9. Bryant, R.E.: Binary decision diagrams and beyond: Enabling technologies for
formal verification. In: Proceedings of IEEE International Conference on Computer
Aided Design (ICCAD). pp. 236–243. IEEE (1995)
10. Chakraborty, S., Fried, D., Tabajara, L.M., Vardi, M.Y.: Functional synthesis via
input-output separation. Formal Methods Syst. Des. 60(2), 228–258 (2022)
11. Church, A.: Logic, arithmetic, and automata. In: International Congress of Math-
ematicians. p. 23–35 (1962)
12. Darwiche, A.: Decomposable negation normal form. J. ACM 48(4), 608–647 (2001)
13. Faymonville, P., Finkbeiner, B., Tentrup, L.: Bosy: An experimentation framework
for bounded synthesis. In: Computer Aided Verification: 29th International Con-
ference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part II.
pp. 325–332. Springer (2017)
14. Finkbeiner, B., Geier, G., Passing, N.: Specification decomposition for reactive
synthesis. In: NASA Formal Methods - 13th International Symposium, NFM 2021,
On Dependent Variables in Reactive Synthesis
21
Virtual Event, May 24-28, 2021, Proceedings. Lecture Notes in Computer Science,
vol. 12673, pp. 113–130. Springer (2021)
15. Finkbeiner, B., Schewe, S.: Bounded synthesis. Int. J. Softw. Tools Technol. Transf.
15(5-6), 519–539 (2013)
16. Golia, P., Slivovsky, F., Roy, S., Meel, K.S.: Engineering an efficient boolean func-
tional synthesis engine. 2021 IEEE/ACM International Conference On Computer
Aided Design (ICCAD) pp. 1–9 (2021)
17. Hopcroft, J.E., Ullman, J.D.: Introduction to Automata Theory, Languages, and
Computation. Addison-Wesley Publishing Company (1979)
18. Huth, M., Ryan, M.: Logic in Computer Science: Modelling and Reasoning about
Systems. Cambridge University Press, USA (2004)
19. Jacobs, S., Perez, G.A., Abraham, R., Bruyere, V., Cadilhac, M., Colange, M.,
Delfosse, C., van Dijk, T., Duret-Lutz, A., Faymonville, P., Finkbeiner, B., Khal-
imov, A., Klein, F., Luttenberger, M., Meyer, K., Michaud, T., Pommellet, A.,
Renkin, F., Schlehuber-Caissier, P., Sakr, M., Sickert, S., Staquet, G., Tamines,
C., Tentrup, L., Walker, A.: The reactive synthesis competition (syntcomp): 2018-
2021 (2022)
20. Meyer, P.J., Sickert, S., Luttenberger, M.: Strix: Explicit reactive synthesis strikes
back! In: Computer Aided Verification: 30th International Conference, CAV 2018,
Held as Part of the Federated Logic Conference, FloC 2018, Oxford, UK, July
14-17, 2018, Proceedings, Part I. pp. 578–586. Springer (2018)
21. Michaud, T., Colange, M.: Reactive synthesis from ltl specification with spot. In:
Proceedings of the 7th Workshop on Synthesis, SYNT@ CAV (2018)
22. Pnueli, A., Rosner, R.: On the synthesis of a reactive module. In: Proceedings
of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming
languages. pp. 179–190 (1989)
23. Rabe, M.N., Seshia, S.A.: Incremental determinization. In: Theory and Applica-
tions of Satisfiability Testing - SAT 2016 - 19th International Conference, Bor-
deaux, France, July 5-8, 2016, Proceedings. pp. 375–392 (2016)
24. Shah, P., Bansal, A., Akshay, S., Chakraborty, S.: A normal form characteriza-
tion for efficient boolean skolem function synthesis. In: 36th Annual ACM/IEEE
Symposium on Logic in Computer Science, LICS 2021, Rome, Italy, June 29 - July
2, 2021. pp. 1–13. IEEE (2021). https://doi.org/10.1109/LICS52264.2021.9470741,
https://doi.org/10.1109/LICS52264.2021.9470741
25. Soos, M., Meel, K.S.: Arjun: An efficient independent support computation tech-
nique and its applications to counting and sampling. In: ICCAD (Nov 2022)
26. Tseitin, G.S.: On the complexity of derivation in propositional calculus. Automa-
tion of reasoning: 2: Classical papers on computational logic 1967–1970 pp. 466–483
(1983)
27. Vardi,
M.,
Wolper,
P.:
Reasoning
about
infinite
computa-
tions.
Information
and
Computation
115(1),
1–37
(1994).
https://doi.org/https://doi.org/10.1006/inco.1994.1092,
https://www.
sciencedirect.com/science/article/pii/S0890540184710923
22
S. Akshay, E. Basa, S. Chakraborty, D. Fried
A
Additional material for defining dependency
To find a maximal dependent set of variables we describe Algorithm 3 called
FindDependent as follows. FindDependent gets as input an LTL formula φ
over the set of variables V = I ∪ O, and initializes the set X that includes the
dependent variables found so far to be empty (line 1). Then at every step (line 2)
we choose a variable z ∈ O that was not tested before and check if z is dependent
of the remaining variables, excluding those that were already found dependent
(line 3). This is done through a procedure called isDependent() which we discuss
next. If so then x is added X (line 4). At the end of the process, we have that
X is returned as an output of FindDependent. The heart of the framework
is naturally in the procedure isDependent that takes a variable z and a set Y
and returns true iff {z} is dependent on Y in φ according to definition 1.
To prove that FindDependent returns a maximal dependent set, we as-
sume that isDependent is well defined. That is, for a variable z and a set Y
isDependent returns true if and only if {z} is dependent on Y in φ. The au-
tomata variant of FindDependent, that we use in this paper, makes use of the
automata variant of isDependent, called isAutomataDependent, in which this
assumption is verified.
Theorem 5. Given an LTL formula φ over the set of variables V , FindDe-
pendent returns a maximal dependent set in φ.
Algorithm 3 Find Dependent Variables
Input LTL Formula φ with variables V = I ∪ O
Output A set X ⊆ O which is maximal dependent in φ
1: X ← ∅
2: for z ∈ O do
3:
if isDependent(z, V \(X ∪ {z})) then
4:
X ← X ∪ {z}
5:
end if
6: end for
7: return X
To prove Theorem 5, we first make the following claim.
Claim. Let X′ be a set of output variables and X ⊆ X′. If X′ is dependent in
φ, then so is X.
Proof. Set w, w′ ∈ L(φ) with the same prefix w[0, i] = w′[0, i] for some i ≥
0. Assume wi.(V \X) = w′
i.(V \X). Then since V \X′ ⊆ V \X we have that
wi.V \X′ = w′
i.V \X′. Therefore wi.X′ = wi.X′, which means that wi.X = wi.X
as well.
We now provide the proof for Theorem 5.
On Dependent Variables in Reactive Synthesis
23
Proof (Proof of Theorem 5). Denote by Xi the set X in the i’th step of the loop
obtained in line 5. We show by induction that Xi is dependent on V \Xi in φ.
For step 0, we have that the empty set is naturally dependent on V . Assume
by induction that Xi−1 is dependent on V \Xi−1. Then at step i, if no element
was added to Xi−1 then Xi = Xi−1 and we are done. Otherwise, we have
Xi = Xi−1 ∪ {z}. Then let j ≥ 0 be such that for two words w, w′ in L(φ),
w[0, j −1] = w′[0, j −1] and wj.V \Xi = w′
j.V \Xi. Then since z was just added,
it follows that wj.{z} = w′
j.{z}. But then since Xi = Xi−1 ∪ {z} is follows that
wj.V \Xi−1 = w′
j.V \Xi−1 and by induction w′
j.Xi−1 = w′
j.Xi−1. hence in total
wj.Xi = w′
j.Xi. Note that it also follows that at the end of the algorithm X is
dependent on V \X in φ and hence X is dependent in φ.
To see that X is maximal, assume for contradiction that it is not and let
X′ ⊆ O be a dependent set that strictly contains X. Let z ∈ X′\X. Then
{z} ⊆ X′ hence, from the Claim above we have that z is dependent in V \{z}.
So z should have been picked up as a member of Xi and therefore in X in some
round i of the algorithm, a contradiction.
⊓⊔
","nanIn the context of propositional specifications, it is not uncommon for a specification to uniquely define an output variable in terms of the input variables and other output variables. A common example of this arises when auxiliary variables, called Tseitin variables, are introduced to efficiently convert a specification not in conjunctive normal form (CNF) to one that is in CNF [26]. Being able to identify such uniquely defined variables efficiently can be very helpful, whether it be for checking satisfiability, for model counting or synthesis. This is because these variables do not alter the basic structure or cardinality of the solution space of a specification regardless of whether they are projected out or not. Hence, one can often simplify the reasoning about the specification by ignoring (or projecting out) these variables. In fact, the remarkable practical success of Boolean functional synthesis tools such as Manthan [16] and BFSS [3,4] can be partly attributed to efficient techniques for identifying a large number of uniquely defined variables. We draw inspiration from these works and embark on an investigation into the role of uniquely defined variables, or dependent variables, in the context of reactive synthesis. To the best of our knowledge, this is the first attempt at directly using dependent variables for reactive synthesis."
"This research addresses long-term fair decision-making in a sequential decision-making system where each choice impacts the system's future state. The objective is to minimize group disparity over time while considering the feedback loop between selections and data distribution shifts.A three-stage learning framework is proposed.In the first stage, a decision model is trained without fairness considerations.In the second stage, a generative adversarial network is trained using observational and interventional data for high-fidelity time series generation.In the third stage, a fair decision model is trained using generated time series.Empirical evaluation using synthetic and semi-synthetic datasets demonstrates the framework's effectiveness in balancing fairness, utility, and system dynamics.","Machine learning models are extensively used in significant decision-making scenarios such as college admissions, bank loans, job placements, and recidivism risk evaluations, where fair decision-making is crucial for broad societal acceptance.Despite efforts to address fairness in machine learning, most studies focus on one-shot decision-making, which may not effectively mitigate group disparities in sequential decision-making systems due to feedback loops and data distribution shifts.This study aims to tackle long-term fairness by focusing on disparity reduction rather than making fair decisions at a single time step, which is more challenging due to the complex system dynamics.Affirmative action policies, such as expanded outreach and top X-percent plans, are also discussed as potential approaches to address group disparity.The research seeks to explore a data-driven approach to mitigate group disparity solely through learning and deploying appropriate decision-making models, taking into account the system dynamics.","The research proposes a three-phase learning framework to achieve long-term fairness.Phase 1 involves training a base decision model without fairness requirements.Phase 2 focuses on training a recurrent conditional generative adversarial network (RCGAN) to capture the system dynamics and generate high-fidelity time series.In Phase 3, a fair decision model is trained on the generated time series by considering both long-term fairness at a specified time step and local fairness requirements at each time step.The optimization problem is formulated as performative risk minimization and solved using the repeated gradient descent algorithm.The evaluation of the proposed method employs synthetic and semi-synthetic time series datasets.Baseline algorithms include a standard multi-layer perceptron (MLP), MLP with demographic parity or equal opportunity constraints, and a method based on path-specific effects and repeated risk minimization (LRLF).The performance of the algorithms is assessed based on accuracy, local fairness, and long-term fairness.","The experimental results demonstrate that the proposed method outperforms baseline algorithms in achieving a favorable balance between long-term fairness, local fairness, and utility.Both local and long-term fairness produced by the method are comparable or better than those of LRLF, and they markedly outperform other baselines.The method effectively strikes a balance between fairness and utility, requiring only information from historical data.T-SNE visualization of qualification distribution produced by the method shows a more even mix of samples from different groups compared to traditional decision-making models, indicating fairer outcomes.","The research proposes a data-driven approach to achieving long-term fairness in sequential decision-making systems.The method utilizes a three-phase learning framework that leverages a deep generative model to simulate system dynamics and generate high-fidelity time series data.Empirical evaluation demonstrates the method's effectiveness in balancing long-term fairness, local fairness, and utility, outperforming traditional fairness notions.The research contributes to the broader effort to develop fair and responsible decision-making models that mitigate group disparities and promote social equity.",Long-Term Fair Decision Making through Deep Generative Models,"Yaowei Hu, Yongkai Wu, Lu Zhang","Long-Term Fair Decision Making through Deep Generative Models
Yaowei Hu1, Yongkai Wu2, Lu Zhang1
1 University of Arkansas
2 Clemson University
yaoweihu@uark.edu, yongkaw@clemson.edu, lz006@uark.edu
Abstract
This paper studies long-term fair machine learning which
aims to mitigate group disparity over the long term in se-
quential decision-making systems. To define long-term fair-
ness, we leverage the temporal causal graph and use the 1-
Wasserstein distance between the interventional distributions
of different demographic groups at a sufficiently large time
step as the quantitative metric. Then, we propose a three-
phase learning framework where the decision model is trained
on high-fidelity data generated by a deep generative model.
We formulate the optimization problem as a performative risk
minimization and adopt the repeated gradient descent algo-
rithm for learning. The empirical evaluation shows the effi-
cacy of the proposed method using both synthetic and semi-
synthetic datasets.
Introduction
Machine learning models are extensively utilized for sig-
nificant decision-making scenarios, like college admissions
(Baker and Hawn 2021), banking loans (Lee and Floridi
2021), job placements (Schumann et al. 2020), and eval-
uations of recidivism risks (Berk et al. 2021). Fair ma-
chine learning, which aims to reduce discrimination and
bias in machine-automated decisions, is one of the keys to
enabling broad societal acceptance of large-scale deploy-
ments of decision-making models. In the past decade, var-
ious notions, metrics, and techniques have emerged to ad-
dress fairness in machine learning. For an overview of fair
machine learning studies, readers are directed to recent sur-
veys (Tang, Zhang, and Zhang 2022; Alves et al. 2023).
However, our society is marked by pervasive group dis-
parities. For example, in the context of bank loans, dispar-
ities in creditworthiness may be observed among different
racial groups. These disparities can arise from systemic or
historic factors that influence variables like credit score, em-
ployment history, and income. As another example, dispari-
ties may be observed in the qualification of students for col-
lege admission which could be influenced by factors such as
the availability of higher education institutions in rural ar-
eas, the economic capacity of families, exposure to college
preparatory resources, etc. Currently, the majority of stud-
ies in fair machine learning are focused on the problem of
Copyright © 2024, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
building decision models for fair one-shot decision-making
(Mehrabi et al. 2021; Caton and Haas 2020). However, it
has been shown that algorithms based on traditional fairness
notions, such as demographic parity (DP) and equal oppor-
tunity (EO), cannot efficiently mitigate group disparities and
could even exacerbate the gap (Liu et al. 2018; Zhang et al.
2020). The challenges lie in the sequential nature of real-
world decision-making systems, where each decision may
shift the underlying distribution of features or user behavior,
which in turn affects the subsequent decisions. For exam-
ple, a bank loan decision can have an impact on an individ-
ual’s credit score, income, etc., which may influence his/her
future loan application. As a result, long-term fairness has
been proposed to focus on the mitigation of group dispari-
ties rather than making fair decisions in a single time step,
which is more challenging to achieve than traditional fair-
ness notions due to the feedback loops between the decisions
and features as well as the data distribution shift during the
sequential decision-making process. Please refer to the tech-
nical appendix for a literature review.
In political and social science, affirmative action has been
implemented as a practice to pursue the goal of group par-
ity (Crosby, Iyer, and Sincharoen 2006). For example, for
promoting group diversity, affirmative action has been used
in higher education allowing universities to consider race as
a factor in admissions. However, affirmative action is con-
troversial and has been criticized on the grounds that race-
conscious decisions might lead to reverse discrimination
against other groups or stigmatize all members of the target
group as unqualified. (Fischer and Massey 2007). Recently,
the US Supreme Court ruled that affirmative action policies
are unconstitutional and race can no longer be regarded as a
factor in admissions to US universities (har 2023).
Given the context, we ask whether we can mitigate group
disparity and achieve long-term fairness while limiting the
use of the sensitive attribute in decision-making models.
Although policies such as expanded outreach or ”top X-
percent” plans are worth investigating in practice, in this
paper, we explore the data-driven prospect of mitigating
group disparity only through learning and deploying ap-
propriate decision-making models, taking into account the
system dynamics. In other words, we aim to learn a deci-
sion model that, once deployed, can lead to group parity by
properly reshaping the distribution. To this end, we lever-
arXiv:2401.11288v1  [cs.LG]  20 Jan 2024
age Pearl’s structural causal model (SCM) and causal graph
(Pearl 2009) for modeling the system dynamics and defining
long-term fairness. Formally, we treat longitudinal features
and decisions in the sequential decision-making process as
temporal variables. Then, we model the system using tem-
poral causal graphs (Pamfil et al. 2020) which are graphical
representations that can depict causal relationships between
features and decisions over time (see Figure 1 for an exam-
ple). The deployment of a decision-making model is simu-
lated as soft interventions on the graph so that the influence
of feedback can be inferred as the interventional distribu-
tion. Thus, group disparity produced by the decision-making
model at any time step T can be considered as the causal ef-
fect of the sensitive attribute on the features at time T. Mean-
while, sensitive attribute unconsciousness can be formulated
as a local requirement that restricts the direct causal effect of
the sensitive attribute on the decision at each time step. As a
result, we show that our goal can be formulated as the trade-
off between two conflicting causal effect objectives.
To strike a balance for the trade-off, we leverage deep
generative models to devise a regularized learning problem.
Specifically, given the observed time series within the time
range [1, l], we train a deep generative model to generate
the interventional distribution for the range [1, T] as well
as the observational distribution if T > l. Then, we inte-
grate the deep generative model and decision-making model
into a collaborative training framework so that the predicted
data could be used as reliable data for training the deci-
sion model. We propose a three-phase training framework.
In Phase 1, given the training time series, we first train a
base decision model without considering any fairness re-
quirements. In Phase 2, we train a recurrent conditional gen-
erative adversarial network (RCGAN) inspired by (Esteban,
Hyland, and R¨atsch 2017) to fit the training time series in
order to generate high-fidelity time series. Finally, in Phase
3, we train a fair decision model on the generated time series
within the time range [1, T] by considering both long-term
fairness at time T as well as the local fairness requirement
at each time step. The optimization problem is treated as
performative risk minimization and solved by using the re-
peated gradient descent algorithm (Perdomo et al. 2020).
To derive the quantitative long-term fairness metric, we
consider the interventional distribution of features at time
step T and adopt the 1-Wasserstein distance between the in-
terventional distributions of different demographic groups as
the measure of the group disparity. We substantiate our met-
ric by demonstrating that a small distance enables reconcili-
ation to occur between DP and EO for any decision models
that are unconscious of sensitive attributes, provided the nec-
essary conditions from (Kim, Chen, and Talwalkar 2020) are
met, and hence implying systemic equality and group parity.
Our experiments demonstrate that the proposed frame-
work can effectively balance various fairness requirements
and utility, while methods based on traditional fairness no-
tions cannot effectively achieve long-term fairness.
Background
Throughout this paper, single variables and their values are
denoted by the uppercase letter X and the lowercase letter x.
Corresponding bold letters X and x denote the sets of vari-
ables and their values respectively. We utilize Pearl’s struc-
tural causal model (SCM) and causal graph (Pearl 2009) for
defining the long-term fairness metric and designing the ar-
chitecture of the deep generative model. For a gentle intro-
duction to SCM please refer to (Pearl 2010). In this paper,
we assume the Markovian SCM such that the exogenous
variables are mutually independent.
Causal inference in the SCM is facilitated with the in-
terventions (Pearl 2009). The hard intervention forces some
variables to take certain constant. The soft intervention, on
the other hand, forces some variables to take certain func-
tional relationship in responding to some other variables
(Correa and Bareinboim 2020). Symbolicly, the soft inter-
vention that substitutes equation X = fX(PaX, UX) with
a new equation X = g(Z) is denoted as σX=g(Z). The dis-
tribution of another variable Y after performing the soft in-
tervention is denoted as P(Y (σX=g(Z))).
Formulating Long-term Fairness
Problem Setting
We start by modeling the system dynamics and formu-
lating a long-term fairness metric that permits continuous
optimization. To ease the representation, we assume a bi-
nary sensitive attribute for indicating different demographic
groups denoted by S ∈ S = {s+, s−}, as well as a binary
decision denoted by Y ∈ Y = {y+, y−}. The profile fea-
tures other than the sensitive feature are denoted by X ∈ X.
In a sequential decision-making system, if a feature is time-
dependent, it means that its value may change from one time
step to another. We assume that X and Y are time-dependent
and use the superscript to denote their variants at different
time steps, leading to Xt and Y t. Many sensitive attributes
like gender and race are naturally time-independent. Some
sensitive attributes may change over time, but the relative
order of individuals in the data does not change, like age.
Thus, we treat S as being time-independent in this paper.
Suppose that we have access to a time series D =
{(S, Xt, Y t)}l
t=1. We assume an SCM for describing the
data generation mechanism and leverage a temporal causal
graph for describing the causal relation among S, Xt, Y t in
the SCM. We make the stationarity assumption such that
data distribution may shift over time but the data genera-
tion mechanism behind it does not change. Figure 1 gives
an example which shows that at each time step the deci-
sion Y t is made based on the value of Xt and S. Mean-
while, the value of Xt is affected by the values of Xt−1,
Y t−1 and S. We will use this graph as a running example
throughout the remaining of this paper. In practice, the tem-
poral causal graph can be obtained from the domain knowl-
edge or learned from data using structure learning algo-
rithms (e.g., (Vowels, Camgoz, and Bowden 2021; Runge
2020; Pamfil et al. 2020)). Our goal is to learn a decision
model hθ : S × X 7→ Y such that when deployed at every
time step, certain fairness requirements can be achieved.
To illustrate our problem setting in a real-world scenario,
consider an example of a bank loan system. When people
apply for bank loans, their personal information (e.g., race,
S
X1
X2
X3
...
XT
Y 1
Y 2
Y 3
...
Y T
Figure 1: A temporal causal graph for sequential decision
making.
job, assets, credit score, etc.) is used by the bank’s decision
model to decide whether to grant the loans. Except for race,
which is a sensitive feature S, other profile features Xt rep-
resent an applicant’s qualification at time step t. The bank’s
decision Y t can have impacts on the applicants’ profile fea-
tures in Xt+1 such as the credit score, which in turn affect
the outcomes of their subsequent loans.
Long-term Fairness Metric
To formulate long-term fairness under the decision model
deployment, (Hu and Zhang 2022) has proposed to mathe-
matically simulate the model deployment by soft interven-
tions on Y at all time steps. That is, given a decision model
hθ, it replaces the original structural equation of Y in the
SCM. We denote the soft intervention by σY t=hθ(S,Xt) and
abbreviate it as σθ. Then, the influence of the model deploy-
ment on feature Xt can be described by its interventional
distribution, denoted by P(Xt(σθ)). With this formulation,
we treat group disparity at time step T as the causal effect
of S on XT , i.e., group parity is achieved when there is no
such causal effect and the interventional distribution of XT
will be equal across demographic groups {s+, s−}.
It is worth noting that, the causal effect of S on XT is
transmitted through multiple causal paths. These paths can
be categorized into two sets: those that intersect with deci-
sion nodes on the graph (e.g., S → X1 → Y 1 → X2 →
· · · ), and those that bypass these nodes (e.g., S → X1 →
X2 → · · · ). The causal effect transmitted through the for-
mer set is influenced by updates to the decision model,
whereas the effect via the latter remains unchanged. Hence,
eliminating the causal effect of S on XT via updating the
decision model means learning the decision model hθ such
that the causal effects transmitted through the two sets of
paths are cancelled out. Consequently, we can formulate the
problem of mitigating group disparity as a learning problem.
We note that the causal effect transmitted through hθ will
be limited by the requirement of sensitive attribute uncon-
sciousness that restricts the direct causal effect of S on hθ at
each time step. The formulation of the metric of sensitive at-
tribute unconsciousness will be detailed in the next section.
As a result, long-term fairness may not always be achievable
only through updating the decision model. In this paper, we
aim to develop and conduct the best practices for mitigat-
ing group disparity using learning algorithms. The theoreti-
cal analysis of the feasibility of long-term fairness will be a
valuable direction for future research.
Next, we present the quantitative metric of long-term fair-
ness. We use the 1-Wasserstein distance to measure the dif-
ference between the two interventional distributions, defined
as follows.
Definition 1. Given a sequential decision making system,
a decision model hθ : S × X 7→ Y, and a time step T,
the metric for measuring the long-term fairness produced by
deploying hθ is given by
JT
1 (θ) ≜ W(P(XT (σθ)|S = s+), P(XT (σθ)|S = s−)),
(1)
where W is the 1-Wasserstein distance and σθ is the soft
intervention.
We substantiate our metric and the choice of the 1-
Wasserstein distance with the following proposition.
Proposition 1. Let d be the 1-Wasserstein distance given in
Definition 1. For any sensitive attribute-unconscious deci-
sion model f : X 7→ A that is Lipschitz continuous, its DP
is bounded by lf ·d where lf is the Lipschitz constant of f. If
we assume that the true label Y is given by a decision model
g : X 7→ A that is Lipschitz continuous and satisfies the
equal base rate condition, then the EO of f is bounded by
(lf + lg)/P(y) · d where lg is the Lipschitz constant of g.
Please refer to the technical appendix for the proof.
Proposition 1 implies that when the 1-Wasserstein distance
is minimized, both DP and EO are mitigated at time T for
any sensitive attribute-unconscious decision model that is
Lipschitz continuous. As shown in (Kim, Chen, and Tal-
walkar 2020), the equal base rate condition is the neces-
sary condition for DP and EO to be compatible. Proposition
1 means that minimizing the 1-Wasserstein distance trans-
forms the necessary condition into both a necessary and
sufficient condition. This demonstrates a reconciliation be-
tween the previously incompatible fairness notions of DP
and EO, thereby suggesting group parity and system equity.
In the experiments, to reduce computational complexity,
we use the Sinkhorn distance (Cuturi 2013) to approximate
the 1-Wasserstein distance. Note that although Proposition
1 applies for sensitive attribute-unconscious decision mod-
els, we do allow the decision model hθ to take the sensitive
feature as input. Meanwhile, we impose local fairness con-
straints to restrict the direct causal effect of S on the deci-
sion, as shall be shown in the next section.
Learning Framework for Long-term Fairness
In this section, we introduce the learning framework for
achieving long-term fairness.
Problem Formulation
We start by formulating the objective function for the de-
cision model hθ. In addition to long-term fairness outlined
in Definition 1, additional factors must also be taken into ac-
count during optimization. The first factor is the utility of the
decision model to ensure good prediction performance. We
adopt the traditional definitions of the loss function given
as follows. In practice, loss functions such as cross-entropy
loss can be used to penalize inaccurate predictions.
Definition 2. Given a time series D = {(S, Xt, Y t)}l
t=1, the
loss for the decision model hθ is given by
J2(θ) ≜ 1
l
l
X
t=1
E[L(hθ(S, Xt), Y t)],
(2)
where L is any loss function.
The second factor is the local fairness constraint for ensur-
ing sensitive attribute-unconsciousness as mentioned above.
In this paper, we adopt direct discrimination proposed in
(Zhang, Wu, and Wu 2016) as the metric for formulating
the local fairness constraint, as defined below.
Definition 3. The local fairness constraint for each time
step t ∈ [1, T] is given by direct discrimination at t, i.e.,
Jt
3(θ) ≜ |E[hθ(S = s+, Xt(σθ))|S = s−]−
E[hθ(S = s−, Xt(σθ))|S = s−]|.
(3)
We note the trade-off between the three factors. The lo-
cal fairness and utility trade-off has been studied in previous
works (Bakker et al. 2019; Corbett-Davies et al. 2017). What
we are more interested is the trade-off between long-term
and local fairness. As discussed, mitigating group disparity
requires a non-zero causal effect to be transmitted through
decision nodes so that the causal effects transmitted through
the two sets of paths can be canceled out. However, sensi-
tive attribute unconsciousness requires eliminating the direct
causal effect to be transmitted through decision nodes. As a
concrete example, making loan decisions exactly according
to the credit score is reasonable in terms of local fairness,
but might not help in narrowing the gap in credit scores be-
tween advantaged and disadvantaged groups. On the other
hand, reducing the gap by favoring the disadvantaged group
can raise the potential issue of reverse discrimination, which
may violate the local fairness constraint.
In this paper, rather than delving into a theoretical analy-
sis of the trade-off between long-term and local fairness, we
utilize the learning algorithm to achieve a balance between
them. We formulate a regularized learning problem, leading
to the problem formulation below.
Problem Formulation 1. The problem of long-term fair
decision-making is to solve the optimization problem:
min
θ
L(θ) = λ1JT
1 (θ) + λ2J2(θ) + λ3
T
T
X
t=1
Jt
3(θ),
(4)
where λ1, λ2 and λ3 are weight parameters.
Overview of Learning Framework
There are two main challenges in solving Problem Formula-
tion 1. First, as shown in Eqs. (1) and (3), the computation of
JT
1 (θ) and Jt
3(θ) are based on the interventional variants of
features Xt(σθ) whose values in turn depend on the model
parameter θ. Second, if T > l, then JT
1 (θ) and PT
t=1 Jt
3(θ)
will be computed on time steps that are beyond the range
of the training data. Thus, Problem Formulation 1 cannot be
solved by traditional machine learning algorithms.
Figure 2: The overview of the proposed framework. Solid
arrows represent input, and the dashed arrow represents pa-
rameter sharing. For Phase 3 only one generator is shown.
We propose a novel three-phase framework based on
causal inference techniques and deep generative networks.
The core idea is to use a deep generative network to simulate
an SCM for generating both observational and interventional
distributions. Our method rests on two theoretical founda-
tions: 1) (Kocaoglu et al. 2018) shows that if the structure of
a generative network is arranged to reflect the causal struc-
ture, then it can be trained with the observational data such
that it will agree with the same SCM in terms of any identi-
fiable interventional distributions; 2) (Kocaoglu et al. 2019)
shows that the interventional distribution produced by any
soft intervention is identifiable in a Markovian SCM.
Inspired by these prior results, we design the architecture
of the deep generative network following the causal struc-
ture. We illustrate our framework using the example shown
in Figure 1. In this example, the causal structure at each
time step can be mathematically described by two structural
equations of the SCM:
Y t = fY
Algorithm 1: DeepLF
Input : Dataset D = {(S, Xt, Y t)}l
t=1, time-lagged
causal graph G, parameters λ1, λ2 and λ3
Output: The fair model hθ
1 Train a classifier hω by minimizing Eq. (8) on D;
2 repeat
3
Update the discriminator Dϕ according to Eq. (13);
4
Update the generator Gψ,ω with the classifier hω as
one of its components according to Eq. (14);
5 until convergence;
6 i ← 0;
7 Initialize hθ0 according to hω;
8 repeat
9
Generate time series using generator Gψ,ω;
10
Compute ∇θLl(θ) according to Eq. (5) using the
generated data;
11
θi+1 ← θi − ηi∇θLl(θi), i ← i + 1;
12 until convergence;
13 return hθi;
Figure 3: The architecture of the RCGAN.
phase, we train the classifier by maximizing the accuracy
without considering any fairness requirement. Since fY does
not change with time, we aggregate the losses at all time
steps in the loss function. Specifically, if the cross-entropy
loss is used, then the loss function for training hω on time
series D is given by
min
ω Lc(ω) = −1
l
l
X
t=1
E

Y t log hω(S, Xt)

.
(7)
Phase 2: Train an RCGAN
We then train an RCGAN to simulate the system dynamics
and generate values of features X by taking the predictions
of hω as the input. Our purpose is to generate both obser-
vational and intervention distributions of X, so it is impor-
tant to design the architecture of the RCGAN following the
causal structure.
The architecture of the RCGAN is illustrated in Figure
3, which consists of one generator and one discriminator.
We use the gated recurrent unit (GRU) (Cho et al. 2014)
as the core structure of the generator and discriminator. For
the generator, it takes the sensitive feature S, a set of noise
vectors Z, as well as the features at the first time step X1 as
the input. The hidden state is then initialized by a non-linear
transformation (e.g., a multi-layer perceptron) of X1 as:
h1 = MLP
time steps from 1 to T for computing JT
1 (θ) in Eq. (1) and
Jt
3(θ) in Eq. (3). In other words, we use Gψ,θ to generate the
interventional data Xt(σθ). Finally, the loss L(θ) is com-
puted and hθ is updated accordingly. Note that the RCGAN
trained in Phase 2 will not be updated in this phase.
It is important to note that when we use the RCGAN to
generate data samples for computing L(θ), those data sam-
ples are affected by hθ as well, due to the fact that hθ is
trained on the interventional distribution after performing
soft intervention σθ. This optimization problem is different
from the traditional empirical risk minimization and is called
the performative risk minimization (Perdomo et al. 2020). In
our work, we adopt the repeated gradient descent algorithm
(RGD) (Perdomo et al. 2020) which is an iterative training
approach to address this problem. In the training process of
Phase 3, we first initialize hθ according to hω. Then, in each
iteration, we use the current version of hθ for generating data
and computing the empirical loss, and hθ is updated based
on the empirical gradient ∇θL(θ). After that, we replace
hθ with its updated version and conduct another iteration
of training. This process is repeated until the parameters of
hθ converge.
Experiments
In this section, we conduct empirical evaluations of our
method1. We refer to our method as deep long-term fair de-
cision making (DeepLF). We use a multi-layer perceptron
for both hω and hθ in our method.
Datasets
Many commonly used datasets in fair machine learning
(Le Quy et al. 2022) are not for dynamic fairness research.
In (Ding et al. 2021), the authors construct a dataset that
spans multiple years and allows researchers to study tempo-
ral shifts in the distribution level. However, our study re-
quires the longitudinal data that track each instance over
time, other than multiple datasets with temporal distribution
shifts. Thus, following (Hu and Zhang 2022), we generate
synthetic and semi-synthetic time series datasets as follows.
Synthetic Dataset. We generate the synthetic time series
dataset based on the temporal causal graph shown in Fig-
ure 1. Each sample at each time step in the time series
includes a sensitive feature S, profile features Xt and a
decision Y t. The samples at the initial time step X1, Y 1
are generated by calling the data generation function (i.e.,
make classification) of scikit-learn package. Then, we clus-
ter the generated samples into two groups and assign S to
each sample according to the cluster it belongs to. To gener-
ate the data samples in the remaining time steps, we design
a procedure by simulating the bank loan system in the real
world. Please refer to the technical appendix for the detailed
generation rules, following which we generate a 10-step syn-
thetic time series dataset with 10000 instances where Xt is a
6-dimensional vector. We refer to this dataset SimLoan.
Semi-Synthetic Dataset. We also generate semi-synthetic
data by leveraging the real-world Taiwan dataset (Yeh and
1The code and hyperparameter settings are available online:
https://github.com/yaoweihu/Generative-Models-for-Fairness.
Lien 2009) as the initial data at t = 1. A ground-truth clas-
sifier and similar generation rules of change are used to gen-
erate subsequent decisions Y 1, ..., Y l and profile features
X2, ..., Xl. There are 10000 instances in the initial data and
they are randomly and equally sampled from groups by S
and Y for balance. Like the SimLoan dataset, this dataset is
also made up of 10 steps. We refer to this dataset Taiwan.
Experimental Setting
Baselines. A multi-layer perceptron with the same number
of layers as hω and hθ that is trained on the training time se-
ries D without any fairness constraints is used as the first
baseline, denoted as (MLP). Two common static fairness
constraints, i.e., demographic parity and equal opportunity,
are applied to the MLP model as fairness constraints respec-
tively, referred to as MLP-DP and MLP-EO. We also im-
plement the method proposed in (Hu and Zhang 2022) that
formulates long-term fairness as path-specific effects and
trains the model using repeated risk minimization, referred
to as LRLF. It requires the true causal structure equations
for training, so we provide it with the true data generation
rules. Implementing details are included in the appendix.
Evaluation. To evaluate the performance of models after de-
ployment, the RCGAN trained in Phase 2 and the decision
models that we evaluate are used together to generate inter-
ventional data on which the local and long-term fairness are
computed. The long-term fairness is measured by Eq. (1)
computed on the evaluated decision model; the local fair-
ness is measured by direct discrimination Eq. (3) at each
time step; and the accuracy of predictions is evaluated based
on the ground-truth classifier hω at each time step.
Results
To evaluate the performance of our algorithm and baselines,
we conduct experiments with two settings on both SimLoan
and Taiwan datasets for 5 times and calculate their mean
and std. In the first setting, the time step T for achieving
long-term fairness is set to 10. We train the models on the
10-step training data (i.e., within the time range [1, 10]) and
evaluate the models on the 10-step generated datasets with
X1 as input (i.e., also within the time range [1, 10]). The re-
sults of accuracy and unfairness of all algorithms on the two
datasets are shown in Figures 4 (a) and (c). As can be seen,
both the local and long-term fairness produced by DeepLF
are comparable with or better than those of LRLF, and they
markedly outperform other baselines. For LRLF, although
it also produces relatively small local and long-term unfair-
ness, it requires true causal structure equations for training
which may not be available in practice. For the other three
baselines, there is no clear decreasing trend in both local
and long-term unfairness, although a relatively higher level
of accuracy is achieved. The results demonstrate that our
method strikes an effective balance between long-term fair-
ness, local fairness, and utility, and it requires only the infor-
mation from the historical data.
To illustrate the difference in the qualification distribution
produced by different methods, we adopt T-SNE to visualize
the distribution of X10 produced by MLP and DeepLF, as
Figure 4: Accuracy (↑), local and long-term unfairness (↓) of different algorithms on SimLoan ((a) and (b)) and Taiwan ((c) and
(d)) datasets. The decision models are trained on generated data within the time range [1, 10]. (a) and (c): Results of evaluation
on generated data within time range [1, 10]. (b) and (d): Results of evaluation on generated data within the time range [10, 19].
(a) SimLoan Dataset
(b) Taiwan Dataset
Figure 5: T-SNE of generated data distributions at time step
t = 10 produced by MLP (left) and DeepLF (right).
shown in Figure 5. It can be seen that compared with the dis-
tribution obtained by using the MLP as the decision model
(left figures), the data samples of two groups (s = 0, 1) pro-
duced by DeepLF (right figures) are more evenly mixed to-
gether which implies a fairer qualification distribution.
In the second setting, the time step T for achieving long-
term fairness is set to 19. We train the decision models on
the same training data as in the first setting but evaluate the
models on the 10-step generated data with X10 as the input,
i.e., the generated data within the time range [10, 19]. The
difference in the second setting is that we only modify the
decision model that will be deployed in the future (i.e., start-
ing from t = 10). The results are shown in Figures 4 (c) and
(d). In general, we observe similar results to the first setting
where our algorithm outperforms all the baseline methods in
achieving the best trade-off.
Conclusions
In this paper, we studied the problem of mitigating group
disparity and achieving long-term fairness while limiting the
use of sensitive attribute in decision-making. We proposed a
data-driven method that requires only the information from
the historical data. Leveraging the temporal causal graph, we
formulated long-term fairness as the 1-Wasserstein distance
between the interventional distributions of different demo-
graphic groups. Then, we proposed a three-phase learning
framework to achieve long-term fairness by training an RC-
GAN to predictively generate observational and interven-
tional data and then training a classifier upon the generated
data. Experiments on both synthetic and semi-synthetic data
show that our method can achieve a more effective balance
between long-term fairness, local fairness, and utility com-
pared with methods based on traditional fairness notions.
Acknowledgments
This work was supported in part by NSF 1910284, 1946391,
and 2142725.
References
2023. Students for Fair Admissions v. Harvard. https://www.
supremecourt.gov/opinions/22pdf/20-1199 hgdj.pdf.
Alves, G.; Bernier, F.; Couceiro, M.; Makhlouf, K.;
Palamidessi, C.; and Zhioua, S. 2023. Survey on fairness
notions and related tensions. EURO Journal on Decision
Processes, 100033.
Baker, R. S.; and Hawn, A. 2021. Algorithmic bias in ed-
ucation. International Journal of Artificial Intelligence in
Education, 1–41.
Bakker, M. A.; Noriega-Campero, A.; Tu, D. P.; Sattigeri,
P.; Varshney, K. R.; and Pentland, A. 2019. On fairness in
budget-constrained decision making. In Proceedings of the
KDD Workshop on Explainable Artificial Intelligence.
Berk, R.; Heidari, H.; Jabbari, S.; Kearns, M.; and Roth, A.
2021. Fairness in criminal justice risk assessments: The state
of the art. Sociological Methods & Research, 50(1): 3–44.
Caton, S.; and Haas, C. 2020. Fairness in machine learning:
A survey. arXiv preprint arXiv:2010.04053.
Cho, K.; Van Merri¨enboer, B.; Bahdanau, D.; and Ben-
gio, Y. 2014.
On the properties of neural machine
translation: Encoder-decoder approaches.
arXiv preprint
arXiv:1409.1259.
Corbett-Davies, S.; Pierson, E.; Feller, A.; Goel, S.; and
Huq, A. 2017. Algorithmic decision making and the cost
of fairness. In Proceedings of the 23rd acm sigkdd interna-
tional conference on knowledge discovery and data mining,
797–806.
Correa, J.; and Bareinboim, E. 2020. A calculus for stochas-
tic interventions: Causal effect identification and surrogate
experiments. In Proceedings of the AAAI Conference on Ar-
tificial Intelligence, volume 34, 10093–10100.
Crosby, F. J.; Iyer, A.; and Sincharoen, S. 2006. Understand-
ing affirmative action. Annu. Rev. Psychol., 57: 585–611.
Cuturi, M. 2013. Sinkhorn distances: Lightspeed computa-
tion of optimal transport. Advances in neural information
processing systems, 26.
Ding, F.; Hardt, M.; Miller, J.; and Schmidt, L. 2021. Retir-
ing adult: New datasets for fair machine learning. Advances
in Neural Information Processing Systems, 34: 6478–6490.
Esteban, C.; Hyland, S. L.; and R¨atsch, G. 2017.
Real-
valued (medical) time series generation with recurrent con-
ditional gans. arXiv preprint arXiv:1706.02633.
Fischer, M. J.; and Massey, D. S. 2007. The effects of affir-
mative action in higher education. Social Science Research,
36(2): 531–549.
Gretton, A.; Borgwardt, K.; Rasch, M.; Sch¨olkopf, B.; and
Smola, A. 2006.
A kernel method for the two-sample-
problem. Advances in neural information processing sys-
tems, 19.
Hu, Y.; and Zhang, L. 2022.
Achieving long-term fair-
ness in sequential decision making.
In Proceedings of
the AAAI Conference on Artificial Intelligence, volume 36,
9549–9557.
Kim, J. S.; Chen, J.; and Talwalkar, A. 2020. FACT: A di-
agnostic for group fairness trade-offs. In International Con-
ference on Machine Learning, 5264–5274. PMLR.
Kocaoglu, M.; Jaber, A.; Shanmugam, K.; and Bareinboim,
E. 2019. Characterization and learning of causal graphs with
latent variables from soft interventions. Advances in Neural
Information Processing Systems, 32.
Kocaoglu, M.; Snyder, C.; Dimakis, A. G.; and Vishwanath,
S. 2018. CausalGAN: Learning Causal Implicit Generative
Models with Adversarial Training. In International Confer-
ence on Learning Representations.
Le Quy, T.; Roy, A.; Iosifidis, V.; Zhang, W.; and Ntoutsi,
E. 2022. A survey on datasets for fairness-aware machine
learning. Wiley Interdisciplinary Reviews: Data Mining and
Knowledge Discovery, e1452.
Lee, M. S. A.; and Floridi, L. 2021. Algorithmic fairness
in mortgage lending: from absolute conditions to relational
trade-offs. Minds and Machines, 31(1): 165–191.
Liu, L. T.; Dean, S.; Rolf, E.; Simchowitz, M.; and Hardt,
M. 2018. Delayed impact of fair machine learning. In In-
ternational Conference on Machine Learning, 3150–3158.
PMLR.
Mehrabi, N.; Morstatter, F.; Saxena, N.; Lerman, K.; and
Galstyan, A. 2021. A survey on bias and fairness in machine
learning. ACM Computing Surveys (CSUR), 54(6): 1–35.
Pamfil, R.; Sriwattanaworachai, N.; Desai, S.; Pilgerstor-
fer, P.; Georgatzis, K.; Beaumont, P.; and Aragam, B. 2020.
Dynotears: Structure learning from time-series data. In In-
ternational Conference on Artificial Intelligence and Statis-
tics, 1595–1605. PMLR.
Pearl, J. 2009. Causality. Cambridge university press.
Pearl, J. 2010. Causal inference. NIPS Causality: Objectives
and Assessment, 39–58.
Perdomo, J.; Zrnic, T.; Mendler-D¨unner, C.; and Hardt, M.
2020. Performative prediction. In International Conference
on Machine Learning, 7599–7609. PMLR.
Peters, J.; Janzing, D.; and Sch¨olkopf, B. 2017. Elements of
causal inference: foundations and learning algorithms. The
MIT Press.
Runge, J. 2020. Discovering contemporaneous and lagged
causal relations in autocorrelated nonlinear time series
datasets. In Conference on Uncertainty in Artificial Intel-
ligence, 1388–1397. PMLR.
Schumann, C.; Foster, J.; Mattei, N.; and Dickerson, J. 2020.
We need fairness and explainability in algorithmic hiring. In
International Conference on Autonomous Agents and Multi-
Agent Systems (AAMAS).
Tang, Z.; Zhang, J.; and Zhang, K. 2022. What-Is and How-
To for Fairness in Machine Learning: A Survey, Reflection,
and Perspective. arXiv preprint arXiv:2206.04101.
Vowels, M. J.; Camgoz, N. C.; and Bowden, R. 2021. D’ya
like dags? a survey on structure learning and causal discov-
ery. arXiv preprint arXiv:2103.02582.
Yeh, I.-C.; and Lien, C.-h. 2009. The comparisons of data
mining techniques for the predictive accuracy of probability
of default of credit card clients. Expert systems with appli-
cations, 36(2): 2473–2480.
Zhang, L.; Wu, Y.; and Wu, X. 2016. A causal framework for
discovering and removing direct and indirect discrimination.
arXiv preprint arXiv:1611.07509.
Zhang, X.; Tu, R.; Liu, Y.; Liu, M.; Kjellstrom, H.; Zhang,
K.; and Zhang, C. 2020. How do fair decisions fare in long-
term qualification? Advances in Neural Information Pro-
cessing Systems, 33: 18457–18469.
","nanThe technical appendix provides a comprehensive literature review covering notions, metrics, and techniques for addressing fairness in machine learning.It also discusses affirmative action policies in the context of group disparity and the deployment of decision-making models.Previous studies on fairness in machine learning have focused on traditional fairness notions such as demographic parity and equal opportunity, which may not effectively mitigate group disparities in sequential decision-making systems.The research builds upon the literature on structural causal models, causal inference, and deep generative models to develop a novel approach for achieving long-term fairness."
"The writer, Neil Immerman, explains how his experience with Juris Hartmanis at Cornell University helped shape his understanding of reductions and led him to significant discoveries in computational complexity. Hartmanis believed in studying restricted reductions, and this perspective influenced Immerman's work on nondeterministic space and his proof of its closure under complementation.","Neil Immerman reflects on the pivotal role Juris Hartmanis played in his academic journey, particularly during his time as a student at Cornell University. He acknowledges the immense impact Hartmanis's teaching and encouragement had on transforming his thinking about computation and complexity theory, ultimately changing his life's course.","A brief explanation of the main idea of reductions in computational complexity is given, with a distinction between standard reductions and projections, a weaker form of reduction introduced by Valiant. The purpose is to understand how the computational complexity of one problem relates to another and how reductions allow for such comparisons.","Immerman presents two key results that showcase the potential of restricted reductions: the first-order projections (fops) and quantifier-free projections (qfps). He demonstrates how natural computability problems remain complete via fops and qfps, establishing the strength of these weaker reduction types. These reductions allow for complexity characterizations of various problems, such as the NP-completeness of 3-SAT via qfps.","The paper highlights the influence of Hartmanis's research on Immerman and how his perspective on reductions led to Immerman's discovery of the closure of nondeterministic space under complementation. Immerman acknowledges the significance of this finding, which Hartmanis was particularly pleased with. The mathematical result not only reflects the elegance of the theory of computation but also serves as a testament to the enduring impact of Hartmanis's teachings and guidance.",What Juris Hartmanis taught me about Reductions,Neil Immerman,"What Juris Hartmanis taught me about
Reductions
Neil Immerman
https://people.cs.umass.edu/˜immerman/
January 23, 2024
Abstract
I was a student of Juris Hartmanis at Cornell in the late 1970’s. He
believed that there was great potential in studying restricted reductions. I
describe here some of his influences on me and, in particular, how his in-
sights concerning reductions helped me to prove that nondeterministic space
is closed under complementation.
1
Introduction
I arrived in Ithaca in August 1975, a twenty-one-year old PhD student in the Cor-
nell Math Department. My plan was to study recursive function theory, a branch
of logic that examines which mathematical problems are solvable, in principle, by
computer. Yet, the most interesting – and also the most challenging – course I
took that first fall was CS 681, the graduate algorithms course. This was taught
by John Hopcroft using the first modern algorithms text [AHU74]. I knew how to
program, having worked the previous year as a software engineer for GTE Sylva-
nia, but Hopcroft introduced me to a new world, and he taught me a new way to
think.
I promptly enrolled in the next semester’s course, CS 682, graduate theory of
computation, taught by Juris Hartmanis. If Hopcroft challenged my thinking of
computer science, Hartmanis completely transformed my thinking about compu-
tation. Had Hartmanis known how dramatically his course had changed me that
semester, he would have smiled and said, “Wow!” It is no exaggeration to say that
1
arXiv:2401.11282v1  [cs.CC]  20 Jan 2024
in introducing me to the subject that I have studied ever since, this course changed
my life.
With his colleague Dick Stearns, Hartmanis had recently helped create the
field of computational complexity. The picture Hartmanis drew in the theory of
computation course was of a new field built on clear and beautiful mathematical
principles. Hartmanis and Stearns had worked out some of the relationships be-
tween the important new computational classes they defined. However, unlike the
more mature field of recursive function theory, in 1976, many of the basic and
fundamental questions in computational complexity were open. This was particu-
larly exciting to me. No one realized at the time how hard these problems actually
were.
2
Reductions
The story I tell here focuses on reductions, a favorite tool of Hartmanis. I will
explain how the understanding of reductions I gained from Hartmanis helped me
give a simple solution to a problem in computational complexity that had eluded
reseachers for twenty-five years.
I assume that the reader is familiar with standard definitions in computational
complexity, such as for reductions and completeness [Sip12]. As I go further into
definitions from Descriptive Complexity, I hope the reader will enjoy just reading
on and seeing the general ideas. Additional definitions and background can be
found in [Imm99].
A reduction is the way we compare the computational complexity of two prob-
lems, A and B. We write A ≤ B to mean that there is a reduction from A to B.
The problems A and B are decision problems, meaning on input w, we answer
“1” if w ∈ A and “0” otherwise. A reduction from A to B is a transformation, t,
taking any such input w, to an input t(w) to the decision problem B in such a way
that the answer to the question, “Is t(w) ∈ B?” is always exactly the same as the
answer to the question, “Is w ∈ A?”. Furthermore, the mapping t must have much
lower computational complexity than the complexity of the problems A and B.
When A ≤ B, it follows that the computational complexity of A is less than or
equal to the computational complexity of B. Richard Ladner proved that this less-
than-or-equal-to relation on the computational complexity of problems is dense,
i.e., if A < B, then there is an intermediate problem, I, and A < I < B [Lad75].
Thomas Schaefer pointed out that for many natural classes of problems, however,
these intermediate problems do not occur. Instead, there is a dichotomy, that is,
2
every problem in such a class is either NP complete, i.e., a hardest problem in
NP, or it is easy, i.e., in P [Sch78]. Schaefer’s paper has lead to a great deal of
important and fascinating explorations of such complexity dichotomies, includ-
ing the recent proof of the Feder-Vardi dichotomy conjecture for all constraint
satisfaction problems over finite domains [FV99, Bul17, Zhu20].
Hartmanis was interested in the fact that complete problems tend to remain
complete via surprisingly weak reductions. Steve Cook proved that SAT is NP
complete via ptime Turing reductions [Coo71]. When Dick Karp produced many
other important NP-complete problems, he used ptime, many-one reductions [Kar72].
Jones showed that these problems stay complete via logspace reductions [Jon73].
Hartmanis, Steve Mahaney and I showed that one-way logspace reductions suffice
[HIM78]; in this model the transducer reads its input once from left to right.
When I introduced Descriptive Complexity, I was pleased to see that first-order
reductions – which are the natural way to translate one logical problem to another
– preserve completeness properties for all natural complete problems and all com-
plexity classes that I examined [Imm99]. Les Valiant had defined a reduction that
is even weaker than first-order reductions, however, and yet still preserves natural
complete problems [Val82]. Valiant called his reductions projections: they are
non-uniform and can perform no computations except negation (Def. 4.4).
I was pleased to observe that there is a natural restriction of first-order reduc-
tions making them (first-order uniform) projections. I call these first-order pro-
jections (fops) and observe that natural problems stay complete via fops [Imm99].
The weakness of fops is their strength as a measuring tool; fops are the electron
microscopes of computational complexity.
In the next section, I sketch relevant information from Descriptive Complexity.
In the following section I define uniform versions of Valiant’s projections, namely
first-order projections (fop) and quantifier-free projections (qfp). The standard
complexity problems for important complexity classes remain complete for fops
and sometimes even for qfps. I will explain why this is remarkable and how it fits
in well with the research directions that Hartmanis pursued with reductions.
Finally, I will show how the completness of graph reachability (REACH) for
NL via qfps, led directly to my proof that nondeterministic space is closed under
complementation. This was a surprising result and a proof that Hartmanis was
particulary pleased with.
3
3
Descriptive Complexity
Descriptive Complexity began with Fagin’s Theorem, which gives a logical char-
acterization of NP. We think of decision problems as sets of finite structures of a
given finite vocabulary. A structure, A = (A, R1, . . . , Rk) consists of a universe
and a set of relations over that universe, for example, a graph, G = (V, E), has
universe, V , the set of vertices, and the binary edge relation, E. Two examples
of decision problems are MAJ, the set of binary strings, a majority of whose bits
are “1” and 3-COLOR, the set of finite 3-colorable graphs. Inputs to computers
are always binary strings, but we can think of them as encodings of other objects,
e.g., structures encoding binary strings, graphs, etc. In this framework, the in-
put is a finite structure. Thus, Descriptive Complexity is aligned with a part of
Mathematical Logic called Finite Model Theory in which only finite structures
are considered.
3.1
Ordered Structures and Numeric Formulas
When an input, w, is presented to a Turing Machine (TM) or other computer, it is
in the form of a binary string, i.e., w ∈ {0, 1}n is a binary string of length n. The
number n is always used to denote the length of the input. The input w may be
encoded or thought of as a structure, Aw, which is also ordered, because a binary
string is a finite ordered sequence of bits. Without the ordering, Aw would just be
a bag of bits, losing almost all of its meaning.
However, suppose the input is a directed graph, G = (V, E), i.e., a set of
vertices, V , some ordered pairs of which have an edge between them, E ⊆ V ×V .
It may seem easy to understand the mathematical concept of an unordered graph.
However, no matter how you encode a graph as a binary string, wG, for example
this could be a ∣V ∣2-bit adjacency matrix for G, the string imposes an ordering
on V : there is an explicitly named first vertex, second vertex, and so on. This
is unavoidable. Thus, for all structures considered in descriptive complexity, the
logics considered have access to an explicit total ordering on the universe.
Here we assume throughout that the structures under consideration are or-
dered. We have constant symbols min, max referring the the first and last ele-
ments in the ordering and relation symbol Suc referring to the successor relation
of the ordering. The symbols min, max, Suc are called numeric symbols and any
formula using only logical or numeric symbols and no input symbols, such as E,
are called numeric formulas because their meaning only depends on the size of the
input structure, not which structure of that size it is. It is crucial that the languages
4
under consideration have access to the total ordering of the universe, in this case
via the above numeric symbols.
3.2
Second-Order Logic and Fagin’s Theorem
Second-order logic consists of first-order logic plus relation variables over which
we may quantify. Any second-order formula may be transformed into an equiv-
alent formula with all second-order quantifiers in front. If all these second-order
quantifiers are existential, then we have a second-order existential formula. Let
SO∃ be the set of decision problems expressible by second-order existential sen-
tences.
As an example, let 3-COLOR be the NP-complete problem of deciding whether
the vertices of an input graph can be colored with three colors in a way that no
two adjacent vertices have the same color. How easy is it to express 3-COLOR
in SO∃? Very easy! Let R, Y, and B be unary relation variables. These represent
three subsets of the universe, i.e., the red, yellow and blue vertices. The following
SO∃ formula expresses 3-COLOR.
Φ3-color
≡
∃R Y B ∀xy ((R(x) ∨ Y (x) ∨ B(x)) ∧ (E(x, y) →
¬(R(x) ∧ R(y)) ∧ ¬(Y (x) ∧ Y (y)) ∧ ¬(B(x) ∧ B(y))))
This is an example of Fagin’s Theorem – a completetly logical characterization of
the complexity class NP. A property is expressible in SO∃ iff it is in NP:
Theorem 3.1 (Fagin’s Theorem) [Fag74] NP is equal to the set of decision prob-
lems expressible by existential, second-order sentences, in symbols, NP = SO∃.
4
First-Order Reductions
We now explain reductions appropriate for Descriptive Complexity. Here is a
simplified definition.
Definition 4.1 (First-Order Reduction) Let σ and τ be vocabularies where τ =
⟨R
a1
1 , . . . , Rar
r ⟩, and let k be a fixed natural number. A k-ary first order mapping,
I ∶ STRUC[σ] → STRUC[τ] is given by r first-order formulas of vocabulary σ,
I = ⟨φ1, . . . , φr⟩. Given a structure A ∈ STRUC[σ] with universe A, I maps A
to
I(A)
def=
(A
k, R
I(A)
1
, . . . , R
I(A)
r
)
5
where the universe of I(A) is the set of k-tuples from the universe of A, and the
relation R
I(A)
i
is defined by the formula φi as follows.
R
I(A)
i
def= {(⟨b
1
1, . . . , b
k
1⟩, . . . , ⟨b
1
ai, . . . , b
k
ai⟩) ∈ ∣I(A)∣
ai ∣ A ⊧ φi(b
1
1, . . . , b
k
ai)}
We define a first-order reduction as a many-one reduction computed by a first-
order mapping and we write A ≤fo B to mean that A is reducible to B via a
first-order reduction.
2
Let 3-SAT be the set of satisfiable propositional formulas in conjunctive nor-
mal form, with at most 3 literals per clause. (A literal is a variable or its negation.)
It follows from Fagin’s Theorem that 3-SAT is NP complete viat first-order re-
ductions [Imm99].
To illustrate the concept of first-order reductions we present a reduction from
3-SAT to 3-COLOR:
Proposition 4.2 3-COLOR is NP-complete via first-order reductions.
Proof: We show that 3-SAT ≤fo 3-COLOR. We are given a structure A encoding
a 3-CNF formula and we must produce a graph f(A) that is three colorable iff
A ∈ 3-SAT. Let n = ∣∣A∣∣, so A is a boolean formula with at most n variables
and n clauses.
The construction of f(A) is shown in Figure 4.3. Notice the triangle, with
vertices labeled T, F, R. Any three-coloring of the graph must color these three
vertices distinct colors. We may assume without loss of generality that the colors
used to color T, F, R are true, false, and red, respectively.
Graph f(A) also contains a ladder each rung of which is a variable xi and its
negation xi. Each of these is connected to R, meaning that one of xi, xi must be
colored true and the other false.
Finally, for each clause Ci = ℓ1 ∨ ℓ2 ∨ ℓ3, f(A) contains the gadget Gi con-
sisting of six vertices. Gi has three inputs ai, bi, ci, connected to literals ℓ1, ℓ2, ℓ3,
respectively, and it has one output, fi. See Figure 4.3 where gadget G1 encodes
clause C1 = x1 ∨ x2 ∨ x3.
Observe that the triangle a1, b1, d1 serves as an “or”-gate in that d1 may be
colored true iff at least one of its inputs x1, x2 is colored true. Similarly, output f1
may be colored true iff at least one of d1 and the third input, x3, is colored true.
Since fi is connected to both F and R, fi can only be colored true. It follows that
a three coloring of the literals can be extended to color Gi iff the corresponding
truth assignment makes Ci true. Thus, f(A) ∈ 3-COLOR iff A ∈ 3-SAT.
6
x
x
x
G
a1
d1
x
e1
c1
f1
n
x
x
x
x
b
G
1
b
T
F
R
1
2
n
3
n
1
n
1
2
3
a
d
e
c
f
n
n
n
n
n
Figure 4.3: 3-SAT ≤fo 3-COLOR; G1 encodes clause C1 = (x1 ∨ x2 ∨ x3)
The details of first-order reduction f are easy to fill in. f(A) consists of one
triangle, a ladder with n rungs, and n copies of the gadget. The only dependency
on the input A — as opposed to its size — is that there is an edge from literal ℓ to
input j of gadget Gi iff ℓ is the jth literal occurring in Ci.
2
4.1
Projections
Projections are not-necessarily uniform reductions such that each bit of the output
depends on at most one bit of the input.
Definition 4.4 (Projection) [Val82]
A k-ary projection, f, is a function from
binary strings to binary strings, f(w) = f∣w∣(w), determined by a family of func-
tions, fn ∶ {0, 1}n → {0, 1}nk
, having the following property. There is a function
t such that for each n, each w ∈ {0, 1}n and each j ≤ nk, bit j of fn(w) is one of
the following, and the same choice is made for all w ∈ {0, 1}n:
• bit j of fn(w) is 0 for all w ∈ {0, 1}n, or,
• bit j of fn(w) is 1 for all w ∈ {0, 1}n, or,
7
• bit j of fn(w) is wt(n,j) for all w ∈ {0, 1}n, i.e. bit t(n, j) of the input, w,
or
• bit j of fn(w) is ¬wt(n,j) for all w ∈ {0, 1}n, i.e. the negation of bit t(n, j)
of the input, w.
Equivalently, k-ary projections are the set of functions computed by a family
of circuits where the nth circuit computes fn, and consists of nk wires – one for
each output bit – each coming from a constant, 0 gate or a single input gate; with
no computatiion gates except at most one “not” gate per wire.
2
As an example, the reduction 3-SAT ≤fo 3-COLOR we gave in Proposition
4.2 is a projection. On input A, the first-order reduction produces a binary string
encoding the adjacency matrix of the graph f(A). Each particular bit of this
adjacency matrix is 1 if the corresponding edge is present in f(A). Look at Figure
4.3 and note that all of the drawn edges are the constant “1”, all the non-drawn
edges are the constant “0” with the exception of the edges (ℓ, ai), (ℓ, bi), (ℓ, ci)
for literal ℓ. Each of these comes from a single bit of the input, A. For example,
the output bit E(x7, a1), saying that there is an edge from literal x7 to vertex a1 in
f(A) is equal to the input bit of A which says whether x7 is the first literal of C1
in A, Similarly, output bit E(x7, b1) is equal to the input bit determining whether
x7 is the second literal of C1 in A.
We now define first-order projections. These are simply projections that are
also first-order reductions. We syntacticly restrict the formulas defining the reduc-
tion to force them to be projections.
Definition 4.5 (First-Order Projection and Quantifier-Free Projection): Let
I = ⟨φ1, . . . , φr⟩ be a k-ary first-order reduction from S to T (Definition 4.1).
Suppose that for i ≥ 1, φi satisfies the following projection condition.
φi ≡ α1 ∨ (α2 ∧ λ2) ∨ ⋯ ∨ (αe ∧ λe)
(4.6)
where the αj’s are mutually exclusive numeric formulas, i.e., no input relations
occur, and each λj is a literal, i.e. an atomic formula P(xj1, . . . xja) or its nega-
tion.
In this case, predicate Ri(⟨u1, . . . , uk⟩, . . . , ⟨. . . , ukai⟩) holds in I(A) if α1(¯u)
is true or if αj(¯u) is true for some 1 < j ≤ e and if the corresponding literal λj(¯u)
holds in A. Thus, each bit in the binary representation of I(A) is determined by
at most one bit in the binary representation of A. We say that I is a first-order
projection (fop). Write S ≤fop T to mean that S is reducible to T via a first-order
projection.
8
If I is a fop whose defining formulas are quantifier-free, then I is a quantifier-
free projection (qfp). Write S ≤qfp T to mean that S is reducible to T via a qfp.2
The key features of a fop I are (1) I is a projection (each bit of I(A) is
determined by at most one bit of A) and (2) the first-order numeric formulas αi in
Equation (4.6) tell us which bit of the input to copy and whether or not to negate
it.
The difference between a qfp and a fop is that in a qfp, the numeric formulas αi
are actually quantifier-free. From Fagin’s Theorem, we have that SAT and 3-SAT
are complete via qfps. Furthermore, the reader should check1 that the reduction
we gave in Proposition 4.2 can be written as a qfp2.
Proposition 4.7 3-SAT ≤qfp 3-COLOR and thus 3-COLOR is NP-complete via
qfp’s.
5
Transitive Closure
Let REACH be the set of directed graphs having a path from min to max. Let
REACHd be the subset of REACH whose graphs have outdegree at most 1. In
[Imm87], I introduced a transitive closure operator. Let φ(x1, . . . , xk, x′
1 . . . x′
k)
be a formula of vocabulary τ with 2k free variables. For any A ∈ STRUC[τ], φ
expresses a binary relation on k-tuples from A,
φ
A
=
{(a, a′) ∣ (A, a, a′) ⊧ φ} .
The transitive closure operator, TC, denotes the reflexive, transitive closure of
such relations. Thus, for example, REACH = {G ∣ G ⊧ TC(E)(min, max)}.
I also introduced a deterministic version of transitive closure, DTC. Given a
first order relation, φ(x, y), define its deterministic reduct,
φd(x, y)
≡
φ(x, y) ∧ (∀z)(¬φ(x, z) ∨ (y = z))
1The best way to understand this is to write it out for yourself. For other examples of fops and
qfps, see [Imm99].
2In a paper exploring first-order and quantifier-free reductions, Elias Dahlhaus correctly proves
using his definition that 3-COLOR is NP complete via first-order reductions but not via quantifier-
free reductions [Dah83]. The crucial difference is that in his definitions, Dahlhaus did not allow
numeric relations such as Suc.
9
That is, φd(x, y) is true just if the unique φd edge from x is to y. Now define:
(DTC φ)
≡
(TC φd) .
Thus, for example,
REACHd = {G ∣ G ⊧ (DTC(E)(min, max) ∧ outdegree(G) ≤ 1)} .
The operators TC and DTC capture the power of nondeterministic and deter-
ministic logspace. (I also introduced an alternating transitive closure operator,
ATC, capturing the power of ASPACE[log n] = P [Imm87].)
Theorem 5.1 [Imm87]
FO(DTC) = L
and
FO(pos TC) = NL
and
FO(ATC) = P .
In the following, REACHa is an alternating version of REACH.
Theorem 5.2 [Imm87]
REACHd
is qfp complete for
L,
and
REACH
is qfp complete for
NL,
and
REACHa
is qfp complete for
P.
Hartmanis advocated trying to prove that certain very weak reductions do not
exist, as a way to separate complexity classes. Here are four enticing examples.
For example, to prove that P ≠ NP it is necessary and sufficent to show that there is
no qfp from 3-COLOR to REACHa. The problem QSAT is a PSPACE-complete
problem.
Corollary 5.3 [Imm87]
L = NP
⇔
3-COLOR ≤qfp REACHd
NL = NP
⇔
3-COLOR ≤qfp REACH
P = NP
⇔
3-COLOR ≤qfp REACHa
P = PSPACE
⇔
QSAT ≤qfp REACHa
10
6
NSPACE[s(n)] = co-NSPACE[s(n)]
In the summer of 1987, I proved the following theorem, which was also indepen-
dently proved by R´obert Szelepcs´enyi.
Theorem 6.1 [Imm88, Sze88] For any s(n) ≥ log n,
NSPACE[s(n)]
=
co-NSPACE[s(n)] .
This had been a long-standing open problem [Kur64]. Everyone I discussed it
with had conjectured the negation of Theorem 6.1. Nondeterministic space cor-
responds to an existential search, and it seemed natural — based on our intuition
concerning existential quantification — that this class would not be closed under
complementation.
I was looking at the relationship between NL and co-NL because of a sur-
prising new result, namely that the alternating logspace hierarchy collapses at the
second level, i.e., ΣL
2 = ΠL
2 [JKL89]. Like everyone else, I still believed that
NL ≠ co-NL and I knew that by Theorem 5.2, this would be true iff REACH
/
≤qfp
REACH.
So, I tried to prove that REACH
/
≤qfp REACH. My proof idea, was, suppose
there is a reduction REACH ≤qfp REACH, what would it look like? I knew from
the definition of qfps (Definition 4.5) and the proof of Theorem 5.2 that there is
very little flexibility concerning what such a qfp would look like. Trying to show
exactly what it would have to look like if it existed, I built it:
Theorem 6.2
REACH ≤qfp REACH.
The proof of Theorem 6.2 is easily translated to a counting argument on Turing
Machines. The night I proved this, I wrote it up that way because it was more
accessible to general theoreticians, who are not familiar with qfps. The following
is a version of the proof. I think it is a sufficient guide for any reader who wants
to explicitly write out the qfp of Theorem 6.2.
Theorem 6.3 [Imm99] For finite, ordered structures,
FO(pos TC)
=
FO(TC) .
Proof: It suffices to show that the relation ¬TC(E)(min, max) meaning that there
is no path from min to max, is expressible in FO(pos TC).
11
To do this, we count the number of reachable vertices. Consider an input
graph, G. As usual, we consider the elements of G as numbers as well as vertices.
In one setting, as distances, we think of these numbers as ranging from 0 to n − 1.
In another setting, as counts of the number of reachable vertices, we have numbers
ranging from 1 to n. Writing these two sets of numbers as numbers rather than as
vertices makes our notation simpler to understand.
Define nd to be the number of vertices in G that are reachable from min in
a path of length at most d. Given number nd, we show how to compute number
nd+1. As a first step, we show that nd allows us to say in FO(pos TC) that there is
not a path of length at most d from min to a given vertex.
Claim 6.4 The following formulas are expressible in FO(pos TC):
1. DIST(x, d), meaning that there is a path of length at most d from min to x
2. NDIST(x, d; m), which — when m = nd — means that there is no path of
length at most d from min to x.
Proof: There is no trouble writing DIST(x, d) positively,
DIST(x, d)
≡
TC(α)(min, 0, x, d),
where
α(a, i, b, j)
≡
(E(a, b) ∨ a = b) ∧ Suc(i, j)
We write the formula, NDIST(x, d; m) ∈ FO(pos TC) to mean the following:
NDIST(x, d; m) ≡ (There are at least m vertices v)(v ≠ x ∧ DIST(x, d)) .
It follows that when m = nd, we have that NDIST(x, d; m) is equivalent to
¬DIST(x, d).
Define edge relation β on pairs of vertices as follows,
β(v, c, v
′, c
′)
≡
min ≠ x ∧ Suc(v, v
′)
∧
(c = c
′ ∨ (Suc(c, c
′) ∧ DIST(v
′, d) ∧ v
′ ≠ x)) .
Suppose that c is the number of vertices — not including x — that are at most v
and reachable from 0 in at most d steps. Then we can take a β-step from ⟨v, c⟩ to
⟨v + 1, c⟩ guessing that v + 1 is not reachable from 0 in d steps; or, we may take
a β-step to ⟨v + 1, c + 1⟩ if we prove that v + 1 is not equal to x and is reachable
from 0 in d steps.
12
Thus, there is a path from ⟨0, 1⟩ to ⟨v, c⟩ iff there are at least c vertices not
equal to x and at most v such that DIST(v, d):
TC(β)(0, 1, v, c)
⇔
c ≤ ∣{w ∣ w ≤ v ∧ DIST(w, d)}∣ .
NDIST can now be defined as follows,
NDIST(x, d; m)
≡
TC(β)(min, 1, max, m) .
2
Using Claim 6.4, we now define the relation δ(d, m, d′, m′) so that if m = nd,
then m′ = nd+1. We simply cycle through all the vertices, counting how many of
them are reachable in d + 1 steps:
δ(d, m, d
′, m
′)
≡
Suc(d, d
′) ∧ TC(γ)(min, 1, max, m
′)
γ(v, c, v
′, c
′)
≡
Suc(v, v
′) ∧ ([Suc(c, c
′) ∧ DIST(v
′, d + 1)]
∨
[c = c
′ ∧ (∀z)(NDIST(z, d; m) ∨ (z ≠ v
′ ∧ ¬E(z, v
′)))])
It follows that formula TC(δ)(0, 1, n − 1, m) holds iff m = nn−1 is the number
of vertices in G that are reachable from min. As claimed, using this m, we can
express the nonexistence of a path,
¬TC(E)(min, x)
≡
(∃m)(TC(δ)(0, 1, n − 1, m) ∧ NDIST(x, n − 1; m))2
7
Concluding Comments
Inspired by my adviser, and thinking about Theorem 6.2 and Corollary 5.3, I
believe that fops and qfps have great potential for answering complexity questions.
For a certain qfp to exist between given problems, there is very little flexibility
concerning what it would have to look like. And very little flexibilty in what you
are searching for can be a good thing.
As I was leaving Cornell after my Ph.D. defense, Hartmanis said to me, “You
might wonder how you will find time to do research as a professor when you have
to prepare classes, teach, hold office hours, grade, write letters of recommendation
for your students, serve on university and department committees, interview and
13
hire new faculty, and so on.” I asked how he did it and he said, “I take long
showers” [Lan91].
It is common experience that creative works come together at surprising times.
For Hartmanis, it was showers. For me it’s walking with dogs. I completed the
qfp reducing REACH to REACH, and thus the proof that nondeterministic space
is closed under complementation, while I was giving my Irish Setter, Molly, her
evening walk.
Fran, Geoff Kozen, Neil, Daniel Immerman, Juris Hartmanis, Scott Drysdale
Acknowledgements:
The above photograph was taken by Susan Landau. Much
thanks to Eric Allender and Phokion Koklaitis for very helpful comments on a
previous draft.
References
[AHU74]
A.V. Aho, J.E. Hopcroft and J.D. Ullman, The Design and Analysis
of Computer Algorithms, Addison- Wesley (1974).
[Bul17]
Andrei Bulatov, “A dichotomy theorem for nonuniform csps, “ IEEE
Found. of Comp. Sci. Symp. (2017), 319-330.
14
[Coo71]
Stephen Cook, “The Complexity of Theorem Proving Procedures,”
Proc. Third Annual ACM STOC Symp. (1971), 151-158.
[Dah83]
Elias Dahlhaus, “Reduction to NP-Complete Problems by Interpre-
tations” in: B¨o¨oger, E., Hasenjaeger, G., R¨odding, D., eds., Logic
and Machines: Decision Problems and Complexity (1983), Lec-
ture Notes in Computer Science, vol 171. Springer.
[Fag74]
Ron Fagin, “Generalized First-Order Spectra and Polynomial-Time
Recognizable Sets,” in Complexity of Computation, (ed. R. Karp),
SIAM-AMS Proc. 7, 1974, 27-41.
[FV99]
Thomas Feder and Moshe Vardi, The computational structure of
monotone monadic SNP and constraint satisfaction: a study through
Datalog and group theory,” SIAM J. Comput. 28 (1999) 57 - 104.
[HIM78]
Juris Hartmanis, Neil Immerman, and Stephen Mahaney, “One-Way
Log Tape Reductions,” IEEE Found. of Comp. Sci. Symp. (1978), 65-
72.
[Imm87]
Neil Immerman, “Languages That Capture Complexity Classes,”
SIAM J. Comput. 16, No. 4 (1987), 760-778.
[Imm88]
Neil Immerman, “Nondeterministic Space is Closed Under Comple-
mentation,” SIAM J. Comput. 17(5) (1988), 935-938. Also appeared
in Third Structure in Complexity Theory Conf. (1988), 112-115.
[Imm99]
Neil Immerman, Descriptive Complexity, 1999, Springer Graduate
Texts in Computer Science, New York.
[JKL89]
Birgit Jenner, Bernd Kirsig, and Klaus-J¨orn Lange, “The Logarithmic
Hierarchy Collapses: AΣL
2 = AΠL
2 ,” Information and Computation
80 (1989), 269-288.
[Jon73]
Neil Jones, “Reducibility Among Combinatorial Problems in Log n
Space,” Proc. Seventh Annual Princeton Conf. Info. Sci. and Systems
(1973), 547-551.
[Kar72]
Richard Karp, “Reducibility Among Combinatorial Problems,” in
Complexity of Computations, R.E.Miller and J.W.Thatcher, eds.
(1972), Plenum Press, 85-104.
15
[Kur64]
S.Y. Kuroda, “Classes of Languages and Linear-Bounded Automata,”
Information and Control 7 (1964), 207-233.
[Lad75]
Richard Ladner, ”On the structure of polynomial time reducibility,”
J. Assoc. Comput. Mach. 2(1) (1975), 155-171.
[Lan91]
Susan Landau, “Tenure Track, Mommy Track” Association for
Women in Mathematics Newsletter, May-June, 1991.
[Sch78]
Thomas Schaefer, “The Complexity of Satisfiability Problems,” ACM
Symp. Theory Of Comput. (1978), 216 - 226.
[Sip12]
Michael Sipser, Introduction to the Theory of Computation, Third
Edition, Cengage Learning, (2012).PWS, 1997.
[Sze88]
R´obert Szelepcs´enyi, “The Method of Forced Enumeration for Non-
deterministic Automata,” Acta Informatica 26 (1988), 279-284.
[Val82]
Leslie Valiant, “Reducibility By Algebraic Projections,” L’Enseigne-
ment math´ematique, T. XXVIII, 3-4 (1982), 253-268.
[Zhu20]
Dmitriy Zhuk, “A Proof of the CSP Dichotomy Conjecture”, J. As-
soc. Comput. Mach. 67(5), (2020), 1-78, https://doi.org/10.
1145/3402029
16
","Immerman provides a concise overview of fundamental concepts and prior research in computational complexity, including Hartmanis's contributions with Dick Stearns in establishing the field. The focus is on the role of reductions in comparing the complexity of problems and the work of Ladner, Schaefer, Hartmanis, Valiant, and himself in defining and evaluating various types of reductions, from p-time Turing reductions to projections.nan"
"The paper provides a lower bound of ∇√(n/∛) on the unambiguous randomized parity-query complexity of the approximate majority problem, which is a problem that asks if the Hamming weight of a given binary string is at most n/3, at least 2n/3, or in between. The result shows that, under the parity-query model, requiring a function to have a unique answer for all inputs makes it harder to compute it efficiently. This highlights a fundamental difference between deterministic, randomized, and unambiguous randomized algorithms.","The paper introduces the concept of unambiguous complexity as a new way to measure the difficulty of a computational problem. It highlights the fact that there are problems that are easy for randomized algorithms but hard for unambiguous randomized algorithms, even if the randomized algorithm is allowed to have a very small error probability. This challenges the traditional view that randomized algorithms are always more powerful than deterministic algorithms.","The paper uses a minimax principle to derive a lower bound on the randomized complexity of the approximate majority problem. The idea is to first guess a hard input distribution for the problem, and then show that any deterministic algorithm that performs well on this distribution must have high complexity. This approach is then extended to the case of unambiguous randomized algorithms.",The paper proves that the unambiguous randomized parity-query complexity of the approximate majority problem is ∇√(n/∛). This means that there is no unambiguous randomized parity-query algorithm that can solve the problem with constant error probability in time polynomial in n. The result holds even if the algorithm is allowed to make a small number of queries to the input.,"The paper concludes by discussing the implications of the result for our understanding of randomized computation. The authors point out that the result highlights the limitations of existing techniques for proving lower bounds on the unambiguous complexity of randomized algorithms, and they call for new approaches to this problem.",Unambiguous parity-query complexity,Dmytro Gavinsky,"arXiv:2401.11274v1  [cs.CC]  20 Jan 2024
Unambiguous parity-query complexity*
Dmytro Gavinsky†‡
January 23, 2024
Abstract
We give a lower bound of Ω
`√n
´
on the unambiguous randomised parity-query complexity
of the approximate majority problem – that is, on the lowest randomised parity-query complexity
of any function over {0; 1}n whose value is “0” if the Hamming weight of the input is at most n=3,
is “1” if the weight is at least 2n=3, and may be arbitrary otherwise.
1
Introduction
The computational model of parity queries is a well-known natural strengthening of the (more
common) bit-wise query model: in both models the input is x ∈ {0; 1}n, in the bit-query model a
protocol can get the value of a single bit of x at each step, while in the parity-query model it can, for
any s ⊆ {1; : : : ; n}, obtain the value of L
i∈s xi via a single query. Alternatively, one may view a
parity-query protocol as receiving its input x from the binary linear space GFn
2 and being able to make
an arbitrary linear query to the coordinates of x at each step.
From the combinatorial standpoint, in the standard bit-query model a deterministic protocol
partitions its input space {0; 1}n into same-answer sub-cubes, while a deterministic parity-query
protocol partitions its input space GFn
2 ≃ {0; 1}n into same-answer aﬃne subspaces, and so, the
parity-query model is a linear closure of the bit-query one. The corresponding randomised models
are the convex closures of their deterministic counterparts. The parity-query model is, obviously, at
least as strong as the bit-query one, and it is not hard to see that it can be much stronger (e.g., both
deterministic and randomised bit-query complexity of computing x1 ⊕ x2 ⊕ : : : ⊕ xn is n).
Let g be a relational computational problem – that is, one that admits non-unique correct answers
for some input values. Let C be a complexity measure that is applicable to g. We will denote by C the
unambiguous-C – that is, let C(g) be the minimum of C(fg) over all functions fg that have the same
domain as g and values that are consistent with g (that is, fg(x) is a correct answer to g(x) for every
x in the domain).
Our notion of unambiguous algorithms (or protocols) was studied in other computational regimes
under the names of Bellagio algorithms and pseudo-deterministic algorithms.
Italophile himself,
the author would happily accept the former term, but unfortunately it is not commonly used and
the connotation might not be obvious. As for the latter, it perfectly ﬁts models like bit-wise query
complexity, where randomised algorithms cannot outperform qualitatively the deterministic ones in
*This is a preliminary version...
†In 2022 the author changed his ﬁrst name, as explained on his Internet page.
‡Institute of Mathematics of the Czech Academy of Sciences, ˇZitna 25, Praha 1, Czech Republic.
Partially funded by the grant 19-27871X of GA ˇCR and by RVO: 67985840.
computing functional problems: in that case forcing unambiguous answers – that is, turning the
original relational problem into a functional one – means depriving the computing algorithms of
its “randomised privileges”. On the other hand, for structurally richer settings like parity queries
or communication complexity, the requirement of unambiguity is unrelated to the protocol’s being
deterministic, as the qualitative superiority of randomness in those models can be manifested in solving
functional problems as well. We will use the term unambiguity with respect to all computational
settings considered in this work.
The concept of unambiguity highlights some alluring gaps in the current understanding of ran-
domised computation. For instance, consider the approximate majority relation – one of the simplest
examples that demonstrate the “power of randomness” – here the answer must be “0” if the Hamming
weight of the input x ∈ {0; 1}n is at most n=3, “1” if the weight is at least 2n=3 and may be arbitrary
otherwise.
• In the standard bit-query model both the deterministic (Ω(n)) and the randomised (O(1))
complexities of approximate majority can be established via nearly trivial arguments;
• the unambiguous randomised query complexity (Ω(n)) demands a somewhat more involved
proof;
• if we strengthen the model slightly by admitting parity queries, then bounding the unambiguous
randomised complexity becomes even more challenging (as witnessed by this work), while both
the deterministic and the randomised cases remain trivial;
• similar situation can be expected in other “rich enough” models, like communication complex-
ity.1
The intricacy of analysing the unambiguous complexity can be reﬂected by the “added universal
quantiﬁer” in the corresponding formal statement. Say, a usual claim of intractability of a relational
task g can be interpreted as
for any eﬃcient protocol Π there exists input x, such that Π(x) disagrees with g(x);
(1)
while a claim of its unambiguous intractability would stand for
for any function fg that is consistent with g
and any eﬃcient protocol Π there exists input x, such that Π(x) ̸= fg(x):
(2)
The former statement implies the latter, which is not surprising: if g admits no eﬃcient randomised
protocol, then it admits no eﬃcient unambiguous randomised protocol either. If, on the other hand,
a relational problem does have an eﬃcient randomised protocol – which is the case, in particular,
for approximate majority in the parity-query model – then arguing its unambiguous randomised
intractability requires distinguishing between statements (1) and (2) in the analysis, which may require
rather ﬁne tuning of the argument.
The state of aﬀairs when one seems to understand well why approximate majority is hard for
deterministic protocols, as well as why the problem is easy for randomised protocols, but not why any
function that computes approximate majority is hard for randomised protocols seems to imply that
one does not understand well the role of randomness in computing approximate majority – one of the
“most canonical” problems demonstrating the utility of randomness in query protocols.
1 To the best of our knowledge, no non-trivial lower bound on the unambiguous complexity is known in communication
complexity and this paper presents the ﬁrst such example in the parity-query model.
2
1.1
Technical challenges
And so, for this work we picked the setting of parity queries – a model where determining the
unambiguous randomised complexity of approximate majority looks challenging, but not hopeless.
This choice can be further justiﬁed via observing that three approaches that may look very natural at
ﬁrst glance are inherently incapable of providing a non-trivial lower bound on the quantity that we
are interested in. The ﬁrst two of them are “tactical” approaches that work in the case of the standard
bit-query model.
The most straightforward way of arguing the hardness of unambiguity in the bit-query model
is to apply the result of [Nis91] stating that the randomised and the deterministic complexities of
a function in that model are qualitatively the same (they can diﬀer at most polynomially). As the
deterministic complexity of approximate majority is high, every function consistent with this relation is
hard for deterministic bit-query protocols, and therefore for the randomised ones also. Obviously, this
approach is unsuitable for parity queries, as here the gap between the randomised and the deterministic
complexity of a function can be as wide as O(1) vs. Ω(n) (cf. Claim 1).
The second approach that works well for the same case of the standard query model is even “more
ad hoc”, but also quantitatively tighter than the ﬁrst one (it leads to the optimal bound of Ω(n), while
the previous argument can only give Ω
`
n
1=3´
). Let f be a function consistent with g
Maj and computed
by a randomised bit-query protocol, and let x ∈ {0; 1}n be a point of (globally) maximal Hamming
weight for which f (x) = 0. Such x ∈ {0; 1}n must have Hamming weight less than 2n=3, that is,
s def
=
˘
i
˛˛xi = 0
¯
contains at least n=3 elements. By the assumption, if x′ diﬀers from x only at some
non-empty subset of bits whose indices are in s, then f (x′) = 1 – that is, a protocol for f makes
enough queries, at least in some cases, in order to solve the or function on |s| bits, and the randomised
bit-query complexity of that task is, trivially, in Ω(|s|) = Ω(n). This argument cannot handle the case
of parity-queries, as here the randomised complexity of the or function is in O(1) (again, cf. Claim 1).
The third approach is one of the most eﬃcient and widely applicable known strategies for analysing
randomised complexity and, as such, is entitled to a section of its own.
1.2
The minimax principle
To prove a lower bound on the randomised complexity of certain task, one can start by guessing a
“hard” input distribution — and then prove that any deterministic protocol errs very often with respect
to —. On the one hand, as long as the family of randomised solutions in the considered computational
model is the convex closure of the family of deterministic ones (which is the case not for all, but
for most of natural computational models, in particular, for all those of interest to us in this work),
Von Neumann’s minimax principle [vN28] implies that such hard distribution necessarily exists, so
this approach can be viewed as universal.2 On the other hand, the simpler structure of deterministic
protocols usually makes their computational potential much easier to understand and to analyse than
that of their “convex generalisation”: the randomised protocols.
The regime of unambiguous complexity, on the other hand, is certainly not a “mere convex
combinations” of deterministic protocols.
Recall that a relation g has an eﬃcient unambiguous
solution if there exists some function f that both agrees with g and has an eﬃcient solution. Suppose
that g is hard, then any f that agrees with g is hard too, that is – here applies the minimax principle
2 There are interesting models of computation where the randomised regime is not closed with respect to convex
combinations of protocols: e.g., such is the case for the communication-complexity model of simultaneous message passing
with private randomness, where the minimax principle in the above form doesn’t hold (equality with constant error is hard
in the worst-case regime but easy deterministically with respect to any ﬁxed distribution).
3
principle in the above form – for any f that agrees with g there is a hard distribution —f . These
—f , however, may be diﬀerent for diﬀerent functions f , not corresponding to any “universally hard”
distribution for the relation g itself.
What is more, these —f not only can but actually must disagree with one another, allowing for no
single hard distribution for the relation g – at least, in all the qualitatively interesting cases, that is, as
long as the gap between the deterministic and the randomised complexities of g is signiﬁcant.
Consider, for instance, a “structurally meaningful” case where R⊕(g) is at most poly-logarithmic
but both D⊕(g) and R⊕(g) are beyond that. Then for any "" > 0 and distribution — there exists
a deterministic protocol Π—;"" of complexity in O(R⊕(g)= log "") that solves g with error at most ""
with respect to — – denote by f—;"" the actual function computed by Π—;"" (it is well-deﬁned, as Π—;""
is deterministic). This f—;"" disagrees with the relation g with probability at most "" with respect to —.
Let f ′
—;""(·) be an arbitrary function with value f—;""(x) when (x; f—;""(x)) ∈ g and some value from
˘
a
˛˛(x; a) ∈ g
¯
otherwise. Note that f ′
—;"" perfectly agrees with g and D⊕
—;""(f ′
—;"") ∈ O(R⊕(g)= log ""),
as witnessed by the protocol Π—;"" (here “D⊕
—;""” stands for the deterministic complexity of solving the
task with error at most "" with respect to —).
In other words, for every — and "" > 0, there always is a function f ′
—;"" that perfectly agrees with g and
for which there exists an eﬃcient deterministic protocol with error at most "" with respect to — – in spite
of the assumed intractability of the relation g itself for unambiguous randomised protocols.3 Therefore,
the concept of unambiguous complexity can be viewed not only as “computational randomness without
the minimax principle” (which by itself would likely be very interesting, although not unique), but
as “computational randomness against the minimax principle” since the setting guarantees that either
the considered case is structurally trivial or for every distribution — the problem is easy.
This work
To illustrate the structural richness of unambiguity, we present a lower bound of Ω
`√n
´
on the
unambiguous randomised parity-query complexity of the approximate majority problem. It follows
that with respect to parity queries there exist:
• a problem that is intractable deterministically but easy for protocols with randomness, even
under the requirement of unambiguity;
• a problem that is intractable deterministically, easy with randomness but becomes intractable
for randomised protocols if the requirement of unambiguity is imposed.
Prior work
The concept of unambiguous complexity was introduced under the name of Bellagio algorithms by
Gat and Goldwasser [GG11] and ﬁrst studied in the context of the bit-wise query model under the
name of pseudo-determinism by Goldreich, Goldwasser and Ron [GGR13].
2
Preliminaries and deﬁnitions
By default the logarithms are base-2. We will write [n] to denote the set {1; : : : ; n} ⊂ N for n ∈ N∪{0}
and let [a] def
= [min{0; ⌊a⌋}] for a ∈ R. Let (a; b), [a; b], [a; b) and (a; b] denote the corresponding
3 The above argument readily adapts to virtually every reasonable model of computation with natural notions of
determinism, randomness and unambiguity.
4
open, closed and half-open intervals in R. Towards readability, we will allow both
˘
·
˛˛·
¯
and
˘
· : ·
¯
to
denote sets with conditions (preferring the former). Let ⊥ and ⊤ denote, respectively, the false and
the true values.
For a linear space S, we will write “≤ S”, “< S”, “⪯ S” and “≺ S” to denote, respectively, its
subspaces, proper subspaces, aﬃne subspaces and proper aﬃne subspaces:
A + b ⪯ S
for any A ≤ S and b ∈ S (and similarly for “≺” and “<”). The zero element will be denoted by ¯0.
For any set S, we will denote by pow(S) the family of all its subsets and by
`S
t
´
the family of its
size-t subsets. We will write US to denote the uniform distribution over the elements of S and use the
notation “X ∼ US” and “X ⊂∼ S” interchangeably. For a ﬁnite S ⊂ N, we will write S(i) to address
the i’th element of S in natural ordering.
For x ∈ {0; 1}n, we let |x| denote its Hamming weight. For i ∈ [n], we will write either xi or x(i)
to address the i’th bit of x (preferring “xi” unless it causes ambiguity) and for any s ⊆ [n] both xs and
x(s) will stand for xs(1) : : : xs(|s|) ∈ {0; 1}|s|.
At times we will assume the following trivial isomorphism:
• between the bit-strings x ∈ {0; 1}n and the subsets
˘
i
˛˛xi = 1
¯
⊆ [n] (in particular, the notation
`[n]
k
´
will stand for
˘
x ∈ {0; 1}n˛˛|x| = k
¯
, and x ∩y will address the set
˘
i ∈ [n]
˛˛xi = yi = 1
¯
);
• between the n-bit strings and the elements of GFn
2 (in particular, the answer to the linear query
represented by s ⊆ [n] will be the parity L
i∈s xi for x ∈ {0; 1}n).
For i ∈ [n], we will denote by ei both the unit vector in GFn
2 and the weight-1 bit string in {0; 1}n that
correspond to {i}.
We will use the following notation for affine subspaces of GFn
2: If C ⪯ GFn
2, then
C′ ≤ GFn
2 is the “supporting” subspace for C, deﬁned as
C′ def
= C + C = C + c0
for any c0 ∈ C and C ≤ GFn
2 is the dual subspace (sometimes called the annihilator) of either C or
C′, deﬁned as
C = C′ def
=
n
x ∈ GFn
2
˛˛˛∀ y ∈ C′ : ⟨x ; y⟩ = 0
o
=
n
x ∈ GFn
2
˛˛˛∃ cx ∈ GF2 : ∀ y ∈ C : ⟨x ; y⟩ = cx
o
;
where “⟨· ; ·⟩” stands for the inner product in GFn
2. 4 The co-dimension of C equals n − log|C| =
dim
`
C
´
.
2.1
Query complexity and unambiguity
The standard model of query complexity is among the simplest and the most natural settings for
analysing the computational complexity of a Boolean function.
Deﬁnition 1 (Rq and Dq, (standard) query complexity).
Let x ∈ {0; 1}n and Π be a deterministic
protocol that queries individual bits of x and outputs a value denoted by Π(x). The complexity of Π
is the maximum possible number of queries that it makes.
4 As GFn
2 is not an inner product space for n ≥ 2, the intersection of a linear subspace with its own dual can be a
non-trivial linear subspace. On the other hand, A = A and dim(A) + dim
`
A
´
= n for any linear subspace A ⊆ GFn
2.
5
P A randomised query protocol is a convex combination of deterministic protocols: (Πi; ¸i)i with
i ¸i = 1 outputs Πi(x) with probability ¸i for every i and x. The complexity of such protocol is the
maximum complexity of an individual Πi.
The deterministic (randomised) query complexity of a function f , denoted by Dq(f ) (Rq(f )), is at
most the complexity of a deterministic (randomised) query protocol that outputs f (x) (with probability
at least 2=3) for every input value x.
A query protocol is called eﬃcient if its complexity is at most poly-log(()n).
Obviously, every Dq-protocol of complexity k partitions the input space {0; 1}n into at most 2k
monochromatic (with respect to the computed function) sub-cubes of co-dimension at most k.
The setting of parity query complexity is a natural strengthening of the standard model.
Deﬁnition 2 (R⊕ and D⊕, parity query complexity). Let x ∈ GFn
2 and Π be a deterministic protocol
that makes linear queries (or parity queries) to the bits of x, that is, for the query represented by
s ⊆ [n] the protocol receives the response L
i∈s xi. Denote the output of the protocol by Π(x). The
complexity of Π is the maximum possible number of linear queries that it makes.
A randomised parity-query protocol is a convex combination of deterministic protocols (cf. Deﬁ-
nition 1).
The deterministic (randomised) parity-query complexity of a function f , denoted by D⊕(f )
(R⊕(f )), is at most the complexity of a deterministic (randomised) parity-query protocol that out-
puts f (x) (with probability at least 2=3) for every input value x.
A parity-query protocol is called eﬃcient if its complexity is at most poly-log(()n).
We will see in Section 3 that every D⊕-protocol of complexity k partitions the input space GFn
2 into
at most 2k monochromatic (with respect to the computed function) aﬃne subspaces of co-dimension
at most k.
The primary context of this work is structural complexity and we will ask whether one compu-
tational setting can “qualitatively outperform” the other, that is, whether there is a computational
problem that has an eﬃcient solution in the model M1, thought not in M2. In other words, compu-
tational problems are tools for separating computational models, and there is a class of problems that
generalises the class of functions and, in some cases, give rise to model separations that wouldn’t be
possible via functions alone.
Deﬁnition 3 (relational problems). Let X be the domain, that is, the set of possible input values to a
computational problem, and let A be the range, that is, the set of possible answers. Then a relation
g ⊆ X × A deﬁnes the following computational problem: “a” is a correct answer with respect to the
input value x ∈ X if (x; a) ∈ g and it is wrong otherwise.
A relation is called partial if for some input values there is no correct answer, that is, ∃ x ∈ X :
∀ a ∈ A : (x; a) ̸∈ g; otherwise the relation is total.
A function f : X → A is said to be consistent with g if all its answers are consistent with those of
the relation, that is, ∀ x ∈ X : (x; f (x)) ∈ g.
In other words, relations admit ambiguous answers or no answer at all for some input values, while
the functional problems are a special case with exactly one correct answer being assigned to every
x ∈ X. All relations considered in this work are total.5
5 Partial relations are usually interpreted as “guarantees” that only the input values for which there is a correct answer
are to be expected: otherwise a protocol is allowed to answer “anything”. This is useful in the context of partial functions
(or promise functions): these are relational problems with at most one correct answer corresponding to every x ∈ X (as
6
In Deﬁnitions 1 and 2 we have addressed the complexity of functional problems only. There are
at least two natural ways to generalise it for a relation g ⊆ X × A:
• the complexity of a g can be deﬁned as the smallest complexity of a protocol that produces
answers that are correct with respect to g;
• alternatively, it can be deﬁned as the smallest complexity of a function f that has the same
domain as g and “agrees” with it answer-wise, that is, ∀ x ∈ X : (x; f (x)) ∈ g.
The corresponding pair of deﬁnitions are equivalent for the deterministic models Dq and D⊕; on the
other hand, for both Rq and R⊕ the ﬁrst version is the standard notion of relational complexity, while
the second one is the unambiguous complexity.
Deﬁnition 4 (deterministic complexity of relations).
Let g ⊆ X × A be a relational problem and C
be either Dq or D⊕.
The C-complexity of g, denoted by C(g), is at most C(f ) for any f : X → A such that ∀ x ∈ X :
(x; f (x)) ∈ g.
Deﬁnition 5 (randomised complexity of relations; unambiguity).
Let g ⊆ X × A be a relational
problem and C be either Rq or R⊕.
The C-complexity of g, denoted by C(g), is at most the C-complexity of a randomised pro-
tocol from the corresponding query model that outputs with probability at least 2=3 a value from
˘
a ∈ A
˛˛(x; a) ∈ g
¯
for every x ∈ X.
The unambiguous C-complexity, denoted by C(g), is at most C(f ) for any f : X → A such that
∀ x ∈ X : (x; f (x)) ∈ g.
2.2
Tasks to consider
It follows readily from the deﬁnitions that
Dq(g) ≥ D⊕(g); Rq(g) ≥ R⊕(g) and Rq(g) ≥ R⊕(g);
Rq(g) ≤ Rq(g) ≤ Dq(g) and R⊕(g) ≤ R⊕(g) ≤ D⊕(g)
(3)
for any relation g. The inequalities in the ﬁrst line of (3) can correspond to separations of O(1) vs.
Ω(n): this is witnessed, in particular, by the parity function L
i∈[n] xi.
The ﬁrst inequality chain of the second line of (3) can correspond to at most polynomial gaps:
it is known [Nis91] that Dq(g) ∈ O
`
(Rq(g))3´
, and therefore from the standpoint of structural
complexity all the considered regimes of (standard) query complexity are equivalent. This leaves us
with the second chain, namely R⊕(g) ≤ R⊕(g) ≤ D⊕(g): As we are going to study the eﬀect of the
unambiguity upon the eﬃcient computability of tasks, we shall only consider those relations g for
which R⊕(g) ∈ poly-log(()n) and D⊕(g) is much higher, preferably in nΩ(1).
Our example of g1 such that R⊕(g1) = R⊕(g1) ≪ D⊕(g1) is fairly simple: it is the or function.
Claim 1. Let X = {0; 1}n and g1 : X → {0; 1} be the or function:
g1(x) = ∨(x)
def
=
_
i∈[n]
xi:
a class of computational problems, it is intermediate between functions and relations). On the other hand, in the case of
relational problems one may consider, instead of a partial relation g, the total one g ′ def
= g ∪
˘
x
˛˛∀ a ∈ A : (x; a) ̸∈ g
¯
× A,
as g and g ′ are describing the same computational problem.
7
Then
R⊕(g1) = R⊕(g1) ∈ O(1) and D⊕(g1) = n:
Proof. As g1 is a function, R⊕(g1) = R⊕(g1).
To compute ∨(x), a protocol must check whether x = 0n and output “0” if that is the case and “1”
otherwise.
If x ̸= 0n, then more than half of non-empty s ⊆ [n] satisfy L
i∈s xi = 1 (let xi0 = 1, then
L
i∈s′ xi ̸= L
i∈s′∪{i0} xi for each s′ ⊆ [n] \ {i0} and L
i∈∅ xi = 0). Accordingly, a single parity-
query with uniformly random non-empty s ⊆ [n] will return “1” with probability greater than 1=2 if
x ̸= 0n and “0” with certainty if x = 0n. A constant number of independent random parity-queries
allows solving ∨(x) with arbitrarily small constant error probability.
On the other hand, if a deterministic protocol that has asked at most n − 1 parity-queries answers
“0”, then, obviously, there is some x ̸= 0n that is consistent with all the answers received protocol;
accordingly, this protocol does not compute ∨(x).
¨Claim 1
A very similar behaviour with respect to unambiguity is demonstrated by the search relation,
which can be viewed as a natural relational version of the function ∨(x).
Corollary 1.
Let X = {0; 1}n and Search ⊆ X × [n] be the search relation:
g′
1 = Search
def
=
n
(x; i)
˛˛˛x = 0n ∨ xi = 1
o
:
Then
R⊕(g′
1); R⊕(g′
1) ∈ O(log n · log log n) and D⊕(g′
1) = n:
Proof. Solving Search is at least as hard as solving the or function and D⊕(Search) = n follows from
Claim 1.
To solve Search in the model of R⊕ (as well as in R⊕), we perform a binary search for the
smallest non-zero coordinate of x and output it if x ̸= 0n. This requires solving log n instances of
the ∨ function with error probability O(1=log n), which can be achieved via solving O(log n · log log n)
instances with error O(1) and the statement follows, again, from Claim 1.
¨Corollary 1
Next we deﬁne the relational problem whose analysis will be the primary technical concern of this
work – the approximate majority relation, which is our example of g2 such that R⊕(g2) ≪ R⊕(g2).
Deﬁnition 6 (g
Maj, approximate majority problem).
Let X = {0; 1}n. The following relational
problem is called approximate majority:
g
Maj
def
=

x ∈ X
˛˛˛˛|x| ≤ n
3
ﬀ
× {0}
∪

x ∈ X
˛˛˛˛
n
3 < |x| < 2n
3
ﬀ
× {0; 1}
∪

x ∈ X
˛˛˛˛
2n
3 ≤ |x|
ﬀ
× {1}:
8
3
Some properties of aﬃne subspaces in GFn
2
Parity-query protocols are naturally viewed as partitions of GFn
2 into aﬃne subspaces.
Recall Deﬁnition 2 and assume that Π is a D⊕-protocol of complexity k.
It has a natural
representation as a binary tree TΠ of depth k: execution starts from the root, every non-leave vertex is
marked with a parity query, the two edges leaving a node are marked by the complementary possible
answers to the node’s query and the leaves are marked with the answers that the protocol returns when
reaching it.
The state of Π at every moment – that is, at each vertex of TΠ (either a leaf or not) – corresponds
to an aﬃne subspace of GFn
2: Let C ⊆ {0; 1}n be the set of input values corresponding to a vertex in
TΠ at depth d ≤ k, that is, for some
(s1; a1); : : : ; (sd; ad) ∈ pow
`
[n]
´
× {0; 1}
it holds that
C =
n
x ∈ {0; 1}n˛˛˛∀ j ∈ [d] : ⊕i∈sjxi = aj
o
=
8
<
:x ∈ GFn
2
˛˛˛˛˛˛
∀ j ∈ [d] :
X
i∈sj
xi = aj
9
=
;:
As a valid protocol state, C must be non-empty.
Assume that the sequence (s1; a1); : : : ; (sd; ad) is a shortest among those that deﬁne our C
in the above sense.
Then s1; : : : ; sd ∈ GFn
2 must be linearly independent, as if, say, s1 + · · · +
st−1 = st for some t ≤ d, then
ˆ
⊕i∈s1xi = a1; : : : ; ⊕i∈st−1xi = at−1
˜
implies [⊕i∈stxi = at] or
its negation (or both), which contradicts at least one of the above assumptions.
Accordingly,
C′ def
=
n
x ∈ GFn
2
˛˛˛ P
i∈s1 xi = 0; : : : ; P
i∈sd xd = 0
o
is a subspace of GFn
2 of co-dimension d and
C = C′ + x0 for any x0 ∈ C, i.e., C ⪯ GFn
2.
The leaves of the protocol tree TΠ correspond to disjoint monochromatic (with respect to the com-
puted function) aﬃne subspaces of GFn
2 of co-dimension at most k, together forming a monochromatic
partition of GFn
2 of size at most 2k (attained if and only if TΠ is complete).
In this work we will investigate some properties of aﬃne subspaces in GFn
2.
Lemma 1 (Likely unﬁxed coordinates).
Let n ≥ 14 and C ⪯ GFn
2, dim(C) ≥ 2n=3. Then there exists
J ⊂ [n], |J| = ⌊n=3⌋, such that for every j ∈ J, Xj is unbiased when X ∼ UC and
∀ D ⪯ GFn
2 : Pr
Pr
Pr
j⊂∼J
ˆ
xj is ﬁxed for all x ∈ C ∩ D
˜
≤ 7 · dim(C) − dim(C ∩ D)
n
:
The claim is non-trivial owing to the universal quantiﬁer in front of “D”: that is, J can depend
only on C and must be universal with respect to D. 6 The claim is useful, as it will be applied later in
the argument. Finally, the claim is interesting, as it highlights a structural property that is special to
aﬃne spaces: if C were allowed to be any large subset of GFn
2, then the analogous statement would be
false (even if we drop the requirement for every Xj to be unbiased under X ∼ UC). 7
Let us have a closer look at the linear structure underlying the lemma.
6 If D were known, then C ∩ D would be known too, in which case letting J contain as many as possible indices of
non-ﬁxed coordinates for x ⊂∼ C ∩ D and the rest of indices non-ﬁxed for x ⊂∼ C would satisfy the lemma promise.
7 For suﬃciently large m ∈ Θ(n) with log m ∈ N, pick s1; : : : ; sm ∈
`[n−log m]
⌊n=4⌋
´
uniformly at random and let
C
def
=
m
[
i=1
n
x ∈ GFn
2
˛˛˛xsi = ¯0; x{n−log m+1;:::;n} = bin(i − 1)
o
;
where bin(i − 1) ∈ {0; 1}log m is the binary representation of i − 1, then |C| ≈ 2
3n=4.
For large enough n with
9
Think about aﬃne spaces in GFn
2 as being “parametrised” (and therefore represented) by the
corresponding dual spaces.8 On the one hand,
C ∩ D = span
`
C ∪ D
´
= C + D;
where “+” stands for element-wise addition (and the equality holds as we are working in GFn
2, where
a linear combination is determined by the set of summands with non-zero coeﬃcients). On the other
hand, xj is ﬁxed for all x ∈ C ∩D if and only if ej ∈ C ∩ D. That is, the probability in the formulation
of Lemma 1 can be rewritten as
Pr
Pr
Pr
j⊂∼J
ˆ
ej ∈ C + D
˜
(4)
and the lemma claims a rather strong upper bound on it (again, for any D).
Note that even though the set J ⊂ [n] in the statement can be made a function of the aﬃne
space C (the corresponding statement would be logically equivalent to our lemma), constructing
J explicitly may be somewhat challenging: e.g., choosing any J consisting of such j that ej ̸∈ C
(that is, Xj is unbiased in X ⊂∼ C) is unsuitable, as shown by letting C be the linear span of
˘
e1 + e2; e1 + e3; : : : ; e1 + en=3+1
¯
and considering J def
=
˘
e2; e3; : : : ; en=3+1
¯
and any D with D
containing e1: in this case (4) equals 1 as ej ∈ C + D for every j ∈ J. 9
Proof of Lemma 1. Towards contradiction, assume the opposite, that is, let ∀J ∈
` [n]
⌊n=3⌋
´
: ∃DJ ⪯ GFn
2,
such that
Pr
Pr
Pr
j⊂∼J
ˆ
xj is ﬁxed for all x ∈ C ∩ DJ
˜
> 7 · dim(C) − dim(C ∩ D)
n
:
Based on (4) and the surrounding discussion, the above implies that for any such J there exists
DJ ≤ GFn
2 such that
˛˛˛
˘
ej
˛˛j ∈ J
¯
∩
`
C + DJ
´˛˛˛
|J|
> 7 · dim(C) − dim(C ∩ DJ)
n
= 7 · dim
`
C + DJ
´
− dim
`
C
´
n
;
that is,
˛˛˛˛
n
ej
˛˛˛j ∈ J
o
∩
`
C + DJ
´˛˛˛˛ > 2 ·
“
dim
`
C + DJ
´
− dim
`
C
´”
;
as |J| = ⌊n=3⌋ and n ≥ 14. As we can take such DJ = span
“
w1; : : : ; wdim( DJ)
”
that C ∩ DJ = ¯0,
∀J ∈
„ [n]
¨
n=3
˝
«
: ∃ w1; : : : ; wk ∈ GFn
2 :
˛˛˛˛
n
ej
˛˛˛j ∈ J
o
∩
`
C + span(w1; : : : ; wk)
´˛˛˛˛ > 2 · k:
(5)
Consider the following recursion, indexed by i ≥ 0. Let
C0
def
= C;
high probability it will be the case that for every J ∈
` [n]
⌊n=3⌋
´
there is some iJ ∈ [m], such that |J ∩ siJ | ≥
|J|=5.
Let DJ
def
=
˘
x ∈ GFn
2
˛˛x{n−log m+1;:::;n} = bin(iJ − 1)
¯
– clearly, this is an aﬃne space of co-dimension log m and
P r
P r
P r j⊂
∼J[xj is ﬁxed for all x ∈ C ∩ D] ≥ 1=5.
8 The dual linear space consists, precisely, of the “known parities” for the full set of elements of the corresponding
primary aﬃne space – that is, in the context of a parity-query protocol Π, the dual space of (the aﬃne subspace corresponding
to) a vertex in TΠ is the linear span of the queries marking the path from the root of the tree to that vertex.
9 This example can be easily generalised: e.g., allowing non-unique distances from C to a very large set of weight-1
vectors that are nevertheless “cancellable” by some D of small co-dimension. Although in this work we do not need an
explicit construction of J in the statement of Lemma 1, obtaining it might be interesting for its own sake.
10
then dim(C0) ≤ n=3 by the lemma assumption. As long as dim(Ci) ≤ 2n=3, let Ji ∈
` [n]
⌊n=3⌋
´
be arbitrary,
subject to
n
ej
˛˛˛j ∈ Ji
o
∩ Ci = ∅ :
such Ji necessarily exists, as otherwise dim(Ci) ≥ dim
`
span
`˘
ej
˛˛j ∈ Ci
¯´´
> 2n=3. Apply (5) with
Ji taking place of J, then let
Ci+1
def
= Ci + span
`
w1; : : : ; wki
´
;
where w1; : : : ; wki are those guaranteed by (5). Then by the trivial induction,
dim(Ci+1) ≤ dim(Ci) + ki ≤ n
3 +
iX
j=0
kj:
(6)
Let Γi
def
=
˘
ej
˛˛j ∈ Ji
¯
∩ Ci+1 and ∆i
def
= span(w1; : : : ; wki ) (in the earlier notation this is DJi).
Then (5) guarantees that
|Γi| =
˛˛˛˛
n
ej
˛˛˛j ∈ Ji
o
∩ (Ci + ∆i)
˛˛˛˛ ≥
˛˛˛˛
n
ej
˛˛˛j ∈ Ji
o
∩
`
C + ∆i
´˛˛˛˛ > 2 · ki;
where the ﬁrst inequality reﬂects the relation C = C0 ⊆ C1 ⊆ : : : ⊆ Ci. Trivially,
Γ0; : : : ; Γi−1 ⊆ Ci
but
Γi ∩ Ci = ∅;
as Γi ⊆
˘
ej
˛˛j ∈ Ji
¯
while
˘
ej
˛˛j ∈ Ji
¯
∩ Ci = ∅. Accordingly, Γi-s are pairwise disjoint and
dim(Ci) ≥ dim
`
span(Γ0 ∪ · · · ∪ Γi−1)
´
=
i−1
X
j=0
˛˛Γj
˛˛ > 2 ·
i−1
X
j=0
kj;
(7)
as Γi-s consist of unit vectors from GFn
2.
Evidently, (6) and (7) disagree. Indeed, let i0 be the index of the last round in the above recursion,
then it follows from the halting condition [dim(Ci0) > 2n=3] and (6):
2n
3 < dim
`
Ci0
´
≤ n
3 +
i0−1
X
j=0
kj;
that is,
dim
`
Ci0
´
< 2 ·
i0−1
X
j=0
kj;
which is in contradiction with (7), as required.
Finally, if J ⊂ [n] is such that for one or more indices j ∈ J the coordinate Xj is not unbiased
when X ∼ UC but the set J satisﬁes the rest of lemma guarantees, then every such j can be replaced
by a coordinate that is “free” in C without breaking the guarantees (note that a coordinate Xi can only
be either unbiased or ﬁxed when X ∼ UC for C ⪯ GFn
2).
¨Lemma 1
We will often consider the behaviour of deterministic parity-query protocols (that is, of D⊕-
protocols) with respect to random inputs coming from a known distribution of the following form.
11
Deﬁnition 7 (Distribution —(t)
C ). Assume that C ⪯ GFn
2 and 0 ≤ t ≤ dim(C) − 2n=3. Denote by —(t)
C
the following distribution of X ∈ C.
• Choose i1 uniformly at random from the set J guaranteed by Lemma 1 with respect to C. Let
C1
def
=
˘
x ∈ C
˛˛xi1 = 1
¯
.
• For each 2 ≤ j ≤ t consecutively choose ij uniformly at random from the set J guaranteed by
Lemma 1 with respect to Cj−1 taking place of C and let Cj
def
=
˘
x ∈ Cj−1
˛˛xij = 1
¯
.
• Output X ∼ UCt.
In other words, X ∼ —(t)
C corresponds choosing X ∈ C at uniform, subject to consecutive ﬁxing
t random coordinates of the elements in C to “1”, each time selecting a “likely unﬁxed” coordinates
according to Lemma 1.
We will be arguing that a parity-query protocol Π cannot distinguish well between the input
distributions UC and —(t)
C , as long as t is not too large with respect to the complexity of Π. To that end
we will use the following facts concerning a pair of aﬃne spaces.
Lemma 2.
Let C; D ⪯ GFn
2, dim(C) ≥ 3n=4 and t ≤
n
14 dim( D). Then
—(t)
C (D) ≥ 1
2 · UC(D):
The claim is non-trivial as the distribution —(t)
C doesn’t depend on D.
Proof of Lemma 2. Assume that C∩D ̸= ∅ and dim
`
D
´
≥ 1 (otherwise the statement holds trivially),
then t ≤ n=14. Also assume n ≥ 14 (otherwise t = 0 and the statement holds trivially). Note that for
any C′ it holds that
dim
`
C′´
− dim
`
C′ ∩ D
´
= dim
`
C′ + D
´
− dim
`
C′´
≤ dim
`
D
´
:
Let us look at the procedure for generating X ∼ —(t)
C , as given by Deﬁnition 7. Denote C0
def
= C,
then the requirements of Lemma 1 are satisﬁed with respect to C0 taking place of C and it holds with
respect to the choice of i1 (from Deﬁnition 7) that
Pr
Pr
Pr
i1
ˆ
xi1 is ﬁxed for all x ∈ C0 ∩ D
˜
≤ 7 · dim
`
D
´
n
;
where we view i1 as a random variable. For 2 ≤ j ≤ t, let Cj
def
=
˘
x ∈ Cj−1
˛˛xij = 1
¯
, then the
requirements of Lemma 1 are satisﬁed with respect to Cj, and so,
Pr
Pr
Pr
ij
h
xij is ﬁxed for all x ∈ Cj−1 ∩ D
i
≤ 7 · dim
`
D
´
n
:
By the union bound,
Pr
Pr
Pr
i1;:::;it
h
any of xij is ﬁxed for x ∈ Cj−1 ∩ D, 1 ≤ j ≤ t
i
≤ 7t · dim
`
D
´
n
≤ 1
2;
(8)
viewing i1; : : : ; it as random variables that are distributed according to the procedure for generating
X ∼ —(t)
C from Deﬁnition 7.
Now let us compare UC(D) to —(t)
C (D). The former is the probability that X ∈ D when X ∼ UC,
which equals
2dim(C∩D)−dim(C):
12
The latter is the probability that X ∈ D when X ∼ UCt with respect to Ct constructed in Deﬁnition 7,
which equals
2dim(Ct∩D)−dim(Ct); 10
where [dim(Ct) = dim(C) − t] always (by the construction). Accordingly, for a tuple i′
1; : : : ; i′
t ∈ [n]t
it can be the case that
Pr
Pr
Pr
X∼—(t)
C
h
X ∈ D
˛˛˛i1 = i′
1; : : : ; it = i′
t
i
< UC(D)
only if at least one of the (consecutive) choices “ij = i′
j” ﬁxes the corresponding coordinate in
x ∈ Cj−1 ∩ D. The probability of the latter is, according to (8), at most 1/2, and therefore
—(t)
C (D) ≥ 1
2 · UC(D);
as required.
¨Lemma 2
4
Unambiguous parity-query complexity of approximate majority
Theorem 1 (Unambiguous parity-query complexity of g
Maj).
R⊕(g
Maj) ∈ Ω
“√n
”
:
Obviously, R⊕(g
Maj) ∈ O(1), so the statement is interesting: As we discussed earlier, the
unambiguous regime in the model of parity queries deﬁes some of the “most intuitive” lower-bound
approaches, so the proof of Theorem 1 will implement its own ad hoc strategy.
The analysis must distinguish between the cases of relational and functional problems, so we will
investigate the behaviour of our f in the region where g
Maj would allow uncertainty: that is, on the
input values of Hamming weight between n=3 and 2n=3. Intuitively, the transition from the “0”-region
to the “1”-region of g
Maj is hard to handle for an unambiguous protocol – as opposed to an arbitrary
randomised one. An unambiguous protocol has to “adhere to” its own choices of the answers in the
uncertainty region, while usual randomised protocols may answer inconsistently there.
As R⊕-protocols of complexity k are convex combinations of D⊕-protocols, which, in turn,
partition the input space GFn
2 into at most 2k aﬃne subspaces whose elements receive the same
answer, our proof will be based technically on bounding the ability of large aﬃne subspaces to
discriminate input values, based on their Hamming weight.
Proof of Theorem 1. Let k(n) ∈ O
“
R⊕(g
Maj)
”
be the parity-query complexity of unambiguously
solving g
Maj with error at most 1=20 and denote by f : {0; 1}n → {0; 1} some g
Maj-consistent function
of that complexity – that is, f takes value “0” on the inputs of Hamming weight at most n=3 and value
“1” on the inputs of Hamming weight at least 2n=3. Assume without loss of generality that k(n) is
monotone non-decreasing and
Pr
Pr
Pr
U{0;1}n
ˆ
f (X) = 0
˜
≥ 1
2
10 Let dim(∅)
def
= −∞ (note that aﬃne spaces do not need any “special element”, like ¯0 for linear spaces, so empty aﬃne
spaces may be consistently allowed, thus making the whole concept closed under intersection).
13
(otherwise replace f (x) by 1 − f (¬x), where “¬” stands for the bit-wise negation).
Let n0
def
= n, C0
def
= GFn0
2 , f0
def
= f and consider the following recursion, indexed by j ≥ 0.
We will make sure that for every j throughout the recursion: nj ≤ nj−1, Cj ⪯ GFnj
2 , fj : Cj → {0; 1}
is a sub-function of f (namely, a restriction of f to certain aﬃne subspace of dimension nj) and
Pr
Pr
PrUCj [fj(X) = 0] ≥ 1=2. Let tj
def
=
j
nj
14·k(nj )
k
, —j be the distribution —(tj)
Cj and ‌j
def
=
UCj +—j
2
.
As long as dim(Cj) ≥ 3nj=4 and P
‘<j t‘ < 2n=3, let Πj be a parity-query deterministic protocol
of complexity at most k(nj) that computes fj with error at most 1=20 with respect to the distribution
‌j. Then it has error at most 1=10 with respect to both UCj and —j. As Pr
Pr
PrUCj [fj(X) = 0] ≥ 1=2, the
protocol answers “0” with probability at least 1=2 − 1=10 = 2=5 with respect to X ∼ UCj.
Denote by Dj the family of aﬃne subspaces of GFnj
2 corresponding to the “0”-marked leaves of
Πj (D ∈ Dj are pairwise disjoint, each of co-dimension at most k(nj)). Then by Lemma 2:
X
D∈Dj
—j(D) ≥ 1
2 ·
X
D∈Dj
UCj(D) ≥ 1
5:
Accordingly,
Pr
Pr
Pr
X∼—j
h
fj(X) = 1
˛˛˛X ∈ ∪D∈DjD
i
=
Pr
Pr
Pr—j
h
Πj errs and X ∈ ∪D∈DjD
i
P
D∈Dj —j(D)
≤ 5 · Pr
Pr
Pr
—j
ˆ
Πj errs
˜
≤ 1
2
and there must exist some Dj ∈ Dj, such that Cj ∩ Dj ̸= ∅ and
Pr
Pr
Pr
X∼—j
h
fj(X) = 1
˛˛˛X ∈ Dj
i
≤ 1
2:
(9)
Here again (like in the proof of Lemma 2), let us view i1; : : : ; itj as random variables that
accompany the generation of X ∼ —j = —(tj)
Cj according to Deﬁnition 7. Then
Pr
Pr
Pr
X∼—j
h
fj(X) = 1
˛˛˛X ∈ Dj
i
=
X
i′
1;:::;i′
tj
Pr
Pr
Pr
h
i1 = i′
1; : : : ; itj = i′
tj
i
· Pr
Pr
Pr
X∼UCj
»
fj(X) = 1
˛˛˛˛X ∈ Dj; Xi′
1 = · · · = Xi′
tj = 1
–
;
and therefore for some values i′
1; : : : ; i′
tj ∈ [nj] it holds that Pr
Pr
Pr
h
i1 = i′
1; : : : ; itj = i′
tj
i
> 0 and
Pr
Pr
Pr
X∼UCj
»
fj(X) = 1
˛˛˛˛X ∈ Dj; Xi′
1 = · · · = Xi′
tj = 1
–
≤ Pr
Pr
Pr
X∼—j
h
fj(X) = 1
˛˛˛X ∈ Dj
i
≤ 1
2;
(10)
where the last inequality is (9). These i′
1; : : : ; i′
tj are distinct and every Xi′
by the construction of —j (Deﬁnition 7) and the guarantees of Lemma 1.‘ is unbiased under X ∼ UCj
Let
Lj
def
=
n
i′
1; : : : ; i′
tj
o
;
Lj
def
= [nj] \ Lj;
bCj
def
=

x ∈ Cj ∩ Dj
˛˛˛˛xi′
1 = · · · = xi′
tj = 1
ﬀ
;
nj+1
def
= nj − tj;
Cj+1
def
=
n
x Lj
˛˛˛x ∈ bCj
o
(the element-wise projection of bCj on Lj);
14
∀ x ∈ bCj : fj+1(x Lj) def
= fj(x) (this deﬁnes fj+1 : Cj+1 → {0; 1}):
As Cj ⪯ GFnj
2 by the induction hypothesis, bCj ⪯ GFnj
2 too and Cj+1 ⪯ GFnj+1
2
. Obviously, fj+1 is a
sub-function of fj (and therefore of f ) and
Pr
Pr
Pr
X∼UCj+1
ˆ
fj+1(X) = 0
˜
= 1 − Pr
Pr
Pr
X∼UCj
»
fj(X) = 1
˛˛˛˛X ∈ Dj; Xi′
1 = · · · = Xi′
tj = 1
–
≥ 1
2;
(11)
according to (10). So, the conditions that we assumed to hold in the beginning of the j’th iteration
will also hold for j + 1, and thus our recursion can sustain itself.
Let j0 be the index of the last protocol Πj considered in the recursion, then it follows from the
halting condition that either
dim
`
Cj0+1
´
< 3nj0+1
4
(12)
or
j0
X
‘=0
t‘ ≥ 2n
3 :
(13)
By (11) with respect to round j0 of the recursion, Pr
Pr
PrUCj0+1[fj0+1(X) = 0] ≥ 1=2. On the other
hand, the aﬃne subspace Cj0+1 is the outcome of a series of restrictions imposed upon C0 = GFn0
2 ,
which, in particular, have constrained to “1” the values of Pj0
‘=0 t‘ previously unﬁxed coordinates.
Then (13) would imply that fj0+1 : Cj0+1 → {0; 1} is a restriction of f to input values of Hamming
weight at least 2n=3, and fj0+1 ≡ 1 would follow, as f is assumed to be a g
Maj-consistent function.
Accordingly, (12) holds and (13) doesn’t, that is, P
‘≤j0 t‘ < 2n=3 and dim(Cj0+1) <
3nj0+1
4
.
By construction, ∀ j ≤ j0 it holds that nj+1 = n − Pj
‘=0 t‘ and
dim
`
Cj+1
´
≥ dim
`
Cj
´
− dim
`
Dj
´
− tj
≥ dim
`
Cj
´
− k(nj) − tj
≥ n −
jX
‘=0
k(n‘) −
jX
‘=0
t‘ = nj+1 −
j
X
‘=0
k(n‘);
and so,
j0
X
‘=0
k(n‘) ≥ nj0+1 − dim
`
Cj0+1
´
> nj0+1
4
:
On the other hand,
nj0+1 = n −
j0
X
‘=0
t‘ > n
3;
therefore,
j0
X
‘=0
k(n‘) > n
12 > 1
8 ·
j0
X
‘=0
t‘
and there exists ‘0 ≤ j0 such that
k(n‘0) > 1
8 · t‘0 = 1
8 ·
—
n‘0
14 · k(n‘0)
‌
:
15
Therefore, k(n‘0) ∈ Ω
`√n‘0
´
= Ω
`√n
´
and the result follows.
¨Theorem 1
That is, imposing the restriction of unambiguity can turn a problem that is easy for parity queries
with randomness into a hard problem.
Corollary 2.
R⊕(g
Maj) ∈ O(1) and
R⊕(g
Maj); D⊕(g
Maj) ∈ Ω
“√n
”
:
Proof. An R⊕-protocol that queries constant number of bits at random locations can answer g
Maj with
arbitrarily small constant-bounded error probability.
¨Corollary 2
It is, in fact, not hard to see that D⊕(g
Maj) ∈ Ω(n).
5
Conclusions
We believe that further investigation of the concept of unambiguity is likely to oﬀer a peerless insight
into the phenomenon of computational randomness in itself. As discussed in Section 1, restricting
one’s curiosity to the deterministic and the randomised regimes alone may be insuﬃcient for an
adequate understanding of computational randomness.
For the sake of speculation, next we pose two questions related to computational randomness and
then use them as a basis for a hypothetical “road map” from the results of this work towards better
understanding of randomness.
Eﬃcient deterministic parity-query protocols arepartitions of the input space GF n
2 intoa (relatively)
small number of same-answer aﬃne subspaces; accordingly, a function with an eﬃcient deterministic
parity-query protocol must be constant on some large aﬃne subspaces of GFn
2. Randomised protocols
are convex combinations of deterministic ones, so there seems to be no need for a function with
an eﬃcient randomised parity-query protocol to be constant on a large aﬃne subspace of GFn
2.
Nevertheless, in all known cases a function over GFn
2 with an eﬃcient randomised parity-query
protocol is constant over some large aﬃne subspace.
Question 1 ([KLMY21]). Is every f : GFn
2 → {0; 1} with an eﬃcient randomised parity-query
protocol constant on a large aﬃne subspace of GFn
2?
Similarly, while every deterministic bipartite protocol with small communication cost corresponds
to a partition of the input space {0; 1}n × {0; 1}n into a small number of same-answer combinatorial
rectangles, there seems to be no immediate reason for a function with an eﬃcient randomised protocol
to be constant on a large sub-rectangle of {0; 1}n × {0; 1}n. Nevertheless, all known examples of
such functions do have a large rectangle over which they are constant.
Question 2 ([CLV19]). Is every f :
{0; 1}n × {0; 1}n → {0; 1} with an eﬃcient randomised
communication protocol constant on a large combinatorial rectangle?
If the answer to Question 1 were aﬃrmative, this would imply some variation of Theorem 1, as
it is easy to see that every large aﬃne subspace of GFn
2 contains both elements of Hamming weight
less that n=3 and those of Hamming weight more than 2n=3. Accordingly, this work is a step towards
answering Question 1.
16
Any R⊕-protocol for a function f : GFn
2 → {0; 1} can be emulated by a bipartite randomised
communication protocol of roughly the same complexity for the function F(x; y) def
= f (x ⊕ y) –
obviously, only requires a very special and rather restricted (but well-deﬁned) type of randomised
bipartite communication protocols. Any function F(·; ·) that can be solved eﬃciently by one of such
restricted protocols necessarily corresponds, in the above sense, to some f : GFn
2 → {0; 1} with an
eﬃcient randomised parity-query protocol; the aﬃrmative answer to Question 1 would imply that f is
constant on a large aﬃne subspace C ⪯ GFn
2. A large same-answer aﬃne subspace for f corresponds
to a large same-answer combinatorial rectangle for F itself:
C = C′ + c0 = C′ +
`
C′ + c0
´
for any c0 ∈ C, thus the rectangle rC
def
= C′ × (C′ + c0) satisﬁes
˘
x ⊕ y
˛˛(x; y) ∈ rC
¯
= C and is
monochromatic with respect to F. That is, the aﬃrmative answer to Question 1 could be reinterpreted
as aﬃrming a special case of Question 2.
A well-known structural question is this:
Is BPP inside PNP in communication complexity?
Here “BPP” stands for the family of all bipartite functions (with product domains) that are eﬃ-
ciently computable by randomised communication protocols and “PNP” is the natural communication-
complexity analogue of the corresponding class in computational complexity. It is known [IW10]
that every function with an eﬃcient PNP-protocol is constant on a large combinatorial rectangle, so
“BPP ⊆ PNP” would imply the aﬃrmative answer to Question 2.
And so on. . .
Acknowledgements
I am indebted to Shalev Ben-David, who ﬁrst presented to me the thrilling idea of unambiguous
complexity, and to Alex Samorodnitsky, who helped me to gain some familiarity with the fanciful
realm of binary linear spaces.
References
[CLV19]
A. Chattopadhyay, S. Lovett, and M. Vinyals. Equality Alone Does not Simulate Ran-
domness. Proceedings of the 34th IEEE Conference on Computational Complexity, pages
1–11, 2019.
[GG11]
E. Gat and S. Goldwasser. Probabilistic Search Algorithms with Unique Answers and
Their Cryptographic Applications. Electronic Colloquium on Computational Complexity
18, 136, 2011.
[GGR13]
O. Goldreich, S. Goldwasser, and D. Ron.
On the Possibilities and Limitations of
Pseudodeterministic Algorithms. Proceedings of the 4th Conference on Innovations in
Theoretical Computer Science, pages 127–138, 2013.
[IW10]
R. Impagliazzo and R. Williams. Communication complexity with synchronized clocks.
Proceedings of the 25th IEEE Conference on Computational Complexity, pages 259–269,
2010.
17
[KLMY21] A. Knop, S. Lovett, S. McGuire, and W. Yuan. Models of Computation Between Decision
Trees and Communication. SIGACT News 52(2), pages 46–70, 2021.
[Nis91]
N. Nisan. CREW PRAMs and Decision Trees. SIAM Journal on Computing 20(6), pages
999–1007, 1991.
[vN28]
J. von Neumann. Zur Theorie der Gesellschaftsspiele. Mathematische Annalen 100(1),
pages 295–320, 1928.
18
",The paper reviews previous work on the complexity of the approximate majority problem and discusses the limitations of existing techniques for proving lower bounds on the unambiguous complexity of randomized algorithms. It identifies the key challenges that need to be addressed in order to make progress in this area.nan
"Anomaly detection in time series data is vital for identifying faults, failures, threats, and outliers across various applications. Deep learning techniques have been used to analyze this topic, but they struggle in complex and highly dynamic real-world scenarios. DACR is a novel approach to combat these challenges. DACR leverages VAE with random noise to generate extra data for contrastive learning to improve feature extraction. It also uses an attention mechanism for semantic dependencies in multivariate time series. Extensive experiments on nine benchmark datasets demonstrate DACR's effectiveness in achieving new state-of-the-art time-series anomaly detection.","Anomaly detection in time series data is essential for monitoring potential faults, threats, and risks in systems. Data-driven methods have gained prominence, and deep learning algorithms perform exceptionally well. However, addressing complex and highly dynamic real-world scenarios poses challenges, including multiple distributions in normal data and different degrees of anomalies from normal data. Existing deep anomaly detection methods struggle in these scenarios due to shortcomings in performance and suitability.","DACR consists of three stages: VAE training, distribution-augmented contrastive learning, and intrinsic dependency-aware reconstruction. VAE reconstructs normal data. Distribution augmentation introduces random noise to generate extra data from a different distribution. Contrastive learning with simple feature extractors captures intrinsic semantics. Finally, a transformer models inter-feature semantic dependencies, enabling robust reconstruction for anomaly detection.","Experiments demonstrate the effectiveness of DACR. DACR achieves new state-of-the-art performance on nine benchmark datasets, outperforming existing baselines substantially in various anomaly detection scenarios. Ablation studies confirm the necessity of DACR modules, and analysis shows its stability to noise degrees and history time length.","DACR, a distribution-augmented contrastive reconstruction approach, enhances time-series anomaly detection by leveraging VAE for distribution augmentation, contrastive learning for intrinsic semantics extraction, and attention mechanism for multivariate feature dependency modeling. Extensive experiments validate DACR's superiority and establish new state-of-the-art results in a variety of anomaly detection scenarios.",DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series Anomaly Detection,"Lixu Wang, Shichao Xu, Xinyu Du, Qi Zhu","DACR: DISTRIBUTION-AUGMENTED CONTRASTIVE RECONSTRUCTION FOR
TIME-SERIES ANOMALY DETECTION
Lixu Wang1, Shichao Xu1, Xinyu Du2, Qi Zhu1
1Northwestern University, IL, USA
2General Motors Global R&D, MI, USA
ABSTRACT
Anomaly detection in time-series data is crucial for identi-
fying faults, failures, threats, and outliers across a range of
applications. Recently, deep learning techniques have been
applied to this topic, but they often struggle in real-world sce-
narios that are complex and highly dynamic, e.g., the normal
data may consist of multiple distributions, and various types
of anomalies may differ from the normal data to different de-
grees. In this work, to tackle these challenges, we propose
Distribution-Augmented Contrastive Reconstruction (DACR).
DACR generates extra data disjoint from the normal data dis-
tribution to compress the normal data’s representation space,
and enhances the feature extractor through contrastive learn-
ing to better capture the intrinsic semantics from time-series
data. Furthermore, DACR employs an attention mechanism to
model the semantic dependencies among multivariate time-
series features, thereby achieving more robust reconstruction
for anomaly detection. Extensive experiments conducted on
nine benchmark datasets in various anomaly detection scenar-
ios demonstrate the effectiveness of DACR in achieving new
state-of-the-art time-series anomaly detection.
Index Terms— Anomaly Detection, Time-Series Data
1. INTRODUCTION
System malfunctions and anomalies are unavoidable in many
real-world applications across various fields [1].
Accurate
anomaly detection is critically important for monitoring
and alarming potential faults, threats, and risks in these
systems [2].
Recently, data-driven methods have become
the mainstream for anomaly detection, among which algo-
rithms based on deep learning perform the best and can
be divided into three categories:
reconstruction predic-
tion [3, 4], anomaly exposure [5, 6], and self-supervised
learning (SSL) [7, 8]. Reconstruction prediction utilizes the
difference between the reconstruction outputs for normal and
abnormal data. Anomaly exposure synthesizes extra data that
is different from the normal data to better model the nor-
We gratefully acknowledge the support from the NSF awards 1834701,
1724341, 2038853, and a grant from General Motors.
mal data distribution. SSL leverages auxiliary tasks to help
models extract the intrinsic semantics of normal data.
However, anomaly detection scenarios in the real world
are often very complex and highly dynamic. For example,
normal data may consist of multiple distributions, and vari-
ous types of anomalies may differ from normal data to dif-
ferent degrees. When faced with these challenging scenarios,
the aforementioned deep anomaly detection methods expose a
number of shortcomings. For instance, reconstruction predic-
tion [3, 4] performs poorly when the normal data consists of
multiple distributions that have different learning difficulties.
The performance of anomaly exposure [5, 6] depends on the
similarity between ground-truth anomaly data and simulated
extra data. SSL [7, 8] performs better when dealing with the
above scenarios, but has its own challenges. For example, the
feature extractor trained with contrastive learning [9] eventu-
ally converges to a uniform hyperspherical space [10] that is
not suitable for anomaly detection [11].
To address the aforementioned challenges, we propose a
novel method called Distribution-Augmented Contrastive Re-
construction (DACR), which comprises three stages. Specif-
ically, in the first stage, we train a variational auto-encoder
(VAE) to reconstruct normal data. In the second stage, we in-
troduce random noise into the latent space when applying the
trained VAE to generate extra data from a different distribu-
tion, a process we refer to as distribution augmentation. With
the extra data, a series of simple feature extractors are trained
with contrastive learning, enabling them to extract intrinsic
semantics from each univariate time-series feature. In the fi-
nal stage, DACR employs a transformer to model the inter-
feature semantic dependency. This allows DACR to recon-
struct time series on the basis of intrinsic semantics rather
than overfitting to artificial features that are only specific
to the reconstruction task, with such being highly gener-
alizable to more anomalies. The overall workflow of DACR
is depicted in Fig. 1. Extensive experiments on nine bench-
mark datasets, which encompass various anomaly detection
scenarios, demonstrate that our methods outperform existing
state-of-the-art baseline methods substantially. In summary,
the main contributions include:
1.
We address practical anomaly detection scenarios
where the normal data or the anomalies consist of multiple
arXiv:2401.11271v1  [cs.LG]  20 Jan 2024
VAE
VAE Noisy Data
Data Union
Overlapping Slicing
Feature Extractor
Training Data
𝒛𝒕−𝒎,𝟏
…
𝒛𝒕−𝟏,𝟏
𝒛𝒕,𝟏
𝒛𝒕−𝒎,𝒇
…
𝒛𝒕−𝟏,𝒇
0
𝒛𝒕−𝒎,𝑭
…
𝒛𝒕−𝟏,𝑭
𝒛𝒕,𝑭
…
…
…
…
Multivariate Features
Feature Extractors
Extracted Embeddings
Reconstruction Transformer
Reconstructed Time Stamp
Training Data
Distribution-Augmented Contrastive Learning
Intrinsic Dependency-Aware Reconstruction
VAE Training
noise
VAE
Training Data
VAE Data
Fig. 1: Overall workflow of Distribution-Augmented Contrastive Reconstruction (DACR) for time-series anomaly detection.
distributions. The challenge is to model the implicit discrep-
ancies between these normal and anomaly distributions.
2. We develop DACR, which combines the strengths of
self-supervised learning and attention-based reconstruction
prediction. By capturing the intrinsic semantic dependency
between multivariate features of time series, DACR is signifi-
cantly more sensitive to potential anomalies.
3. We conduct extensive experiments on nine benchmark
datasets, covering scenarios with varying degrees of discrep-
ancies between normal and anomalous data. Experiment re-
sults demonstrate that DACR consistently and substantially
outperforms existing state-of-the-art baselines.
Related Work: For reconstruction prediction, anomaly de-
tectors are strongly over-fitted to normal data. Recent stud-
ies apply convolution neural networks [12], LSTM [13],
and transformers [14] to build such reconstruction models.
Anomaly exposure usually relies on extra data generation,
and by training the model in supervised learning [5, 6, 15] to
distinguish extra data from normal data, the distribution of
normal data can be better modeled. SSL-based methods rely
on various auxiliary tasks, such as rotation prediction [16] and
data augmentation [11, 7, 17, 8, 18, 19]. While these methods
are designed for image data, no study explores whether SSL
can work on time-series anomaly detection. Other anomaly
detection works include graph neural network [20] and en-
semble learning [21].
2. METHODOLOGY
Problem Formulation: Suppose an unlabeled dataset with N
time-series samples X = {xi∥xi ∼ PX }N
i=1 is given, where
PX is the input feature distribution. Each sample xi can be re-
garded as an observation of a matrix-valued random variable
with dimensions T×F, where T is the sequence length and F
is the feature dimension, i.e., xi = {xt,f
i }T,F
t=1,f=1. Following
standard anomaly detection assumptions [22, 23], dataset X
is considered as being full of normal data. The objective is to
learn a model based on X to accurately infer each time stamp
of each testing sample as either normal or anomaly.
2.1. Distribution-Augmented Contrastive Learning
Time Series Contrastive Learning
Different from contrastive learning on visual data [11, 7],
it is not yet straightforward to find suitable augmentation
techniques for producing positive pairs of time-series data.
Inspired by TS2Vec [17], we extend overlapping slicing to our
problem. More specifically, overlapping slicing here means
randomly cutting out two fragments (ˆxi, ˆx+
i ) from a given
time-series instance xi while ensuring that there is an over-
lapping part between them, i.e., ˆxi ={xt
i}b
t=a, ˆx+
i ={xt
i}d
t=c,
where 1 ≤ a < c < b < d ≤ T. The instance-wise contrastive
comparison between positive pairs (ˆzt
i & ˆzt+
i ) is constructed
as comparing representations of fragments from the same data
instance, while that of negative pairs (ˆzt
i & ˆzt+
j , and ˆzt
i & ˆzt
j
where i ̸= j) is constructed as comparing representations of
fragments from different data instances.
Lt
In,i = − log
exp(ˆzt
i · ˆzt+
i )
P
j
sequence as in TS2Vec [17]. The positive pairs (ˆzt
i & ˆzt+
i )
of temporal CL are constructed as the representations of aug-
mented fragments at the same time stamp, while the negative
pairs (ˆzt
i & ˆzt′+
i
, and ˆzt
i & ˆzt′
i where t ̸= t′) are the repre-
sentations of augmented fragments at different time stamps.
Lt
Te,i = − log
exp(ˆzt
i · ˆzt+
i )
P
t′
Table 2: Performance comparison between DACR and baselines in the set-
tings of both EAD (n=NC−1) and IAD. AUC±standard deviation is used to eval-
uate the performance. DACR significantly outperforms the second-best by
2.8-8.2% on EAD, and 0.4-3.3% on IAD.
Baseline
EAD
IAD
SAD
CT
RS
PCoE
NAT
ASD
SWaT
WaQ
SMD
DROCC
58.8±0.5 57.6±1.5 60.9±0.2 69.7±1.1 60.7±1.6 69.3±1.9 83.3±0.9 68.9±3.4 86.6±0.9
TS2Vec
62.7±0.6 62.4±1.0 67.6±0.6 72.4±1.5 66.6±1.8 78.9±2.3 86.0±1.8 67.8±3.5 89.9±0.9
DROC
63.5±0.7 63.0±0.7 68.9±0.9 75.0±1.1 69.2±1.3 75.1±1.5 84.9±1.1 68.4±2.2 86.6±0.8
MSC
55.7±2.0 58.0±1.5 61.4±1.0 65.0±0.7 61.5±0.9 80.0±2.8 85.4±0.9 70.6±0.8 90.2±1.3
NTL
85.1±0.3 87.4±0.2 80.0±0.4 75.5±1.1 74.8±0.9 59.2±4.5 85.0±2.6 61.6±9.1 74.6±6.7
GDN
74.9±2.1 66.4±0.7 69.6±0.9 73.8±2.5 71.1±1.3 77.9±4.2 88.5±3.6 65.9±4.3 95.9±1.6
TranAD
64.4±1.1 61.3±0.9 70.9±0.6 72.7±0.5 66.0±1.0 91.5±1.8 81.0±0.7 72.9±1.7 66.2±0.3
COUTA
65.0±1.1 65.5±0.8 72.2±0.2 75.0±0.9 68.0±1.1 95.5±3.0 90.0±1.7 71.4±0.6 98.4±1.5
UMS
68.0±3.0 71.5±0.6 75.2±0.9 77.3±1.4 69.7±2.1 91.0±2.5 86.6±2.0 69.9±1.6 96.5±1.2
DACR-ab1 68.3±3.3 82.0±0.9 75.9±0.5 78.5±0.9 69.8±2.0 82.0±1.1 87.1±0.9 68.2±1.3 87.0±2.2
DACR-ab2 75.0±2.2 66.9±3.8 71.0±0.7 74.5±1.9 75.1±1.0 88.0±2.5 86.4±0.8 72.0±1.9 94.5±0.6
DACR
90.7±0.3 91.9±1.5 88.2±3.2 81.3±0.7 81.5±1.6 96.2±2.1 93.3±0.9 75.9±0.9 98.8±1.0
0.01 0.05
0.1
0.5
1.0
Injected Noise Variance
70
75
80
85
90
95
100
AUC(%)
10
20
30
40
50
History Time Length
70
75
80
85
90
95
100
SAD
CT
RS
PCoE
NAT
ASD
SWaT
WaQ
SMD
Fig. 2: Sensitivity analysis of various VAE in-
jected noise degrees and different history time
lengths of reconstruction transformer input.
data. We follow COUTA [26] to build the IAD setting. Please
refer to Table 1 for dataset details.
Implementation Details. The batch size is set as 8. The
learning rate of the Adam optimizer for training the feature
extractor is 0.001, while that for VAE is 0.0001. For the EAD
datasets, the default number of training iterations for the fea-
ture extractor is 200. For the IAD datasets, given the larger
data size, we train 1000 iterations. We follow NTL [8] to
conduct EAD based on the entire sequence of time-series in-
stances and follow COUTA [26] to adopt a window sliding
mode for IAD. The backbone architecture of feature extrac-
tors is a dilated CNN [17], and the VAE consists of 4 LSTM
layers. We repeat our experiments 3 times with different seeds
and report the average value and standard deviation for AUC.
Baseline Methods for Comparison. We compare DACR
with DROCC [6], TS2Vec [17], DROC [11], MSC [18],
NTL [8], GDN [23], TranAD [14], COUTA [26], UMS [21].
3.2. Performance Comparison
Table 2 presents experiment results of both EAD and IAD.
From the results, we can see that DACR achieves the best
performance for all cases in EAD and IAD, clearly out-
performing baselines. In addition, we also carry out experi-
ments in setting different normal class numbers for EAD, and
the results of the SAD dataset are shown in Fig. 3. The figure
shows that DACR always performs the best, demonstrating its
effectiveness under challenging scenarios where the normal
and abnormal data consist of multiple different distributions.
The results on other datasets show similar trends.
3.3. Ablation Study and Sensitivity Analysis
We conducted an ablation study by modifying DACR in two
ways: 1) removing the VAE-based Distribution Augmenta-
tion (DACR-ab1), or 2) replacing the DACL feature extractor
with that trained by GDN [23] (DACR-ab2). The results in Ta-
ble 2 show that the performance of DACR-ab1 and DACR-ab2
are significantly worse than DACR, showing that all modules
in DACR are essential and complement each other well. We
1
3
5
7
9
Class Number of Normal Data
40
50
60
70
80
90
100
AUC(%)
DACR
DROCC
TS2Vec
DROC
MSC
NTL
GDN
TranAD
COUTA
UMS
Fig. 3: Performance comparison in EAD with different nor-
mal class numbers on the SAD dataset.
conducted a sensitivity analysis on the noise degree (α, β in
Eq. (5)) with different variances (0.01, 0.05, 0.1, 0.5, 1.0).
According to Fig. 2, we can observe that our method is not
very sensitive to noise degrees larger than 0.05.
The per-
formance at 0.01 is poor because VAE cannot generate suffi-
ciently diverse data at that moment. We also conducted a sen-
sitivity analysis on the history time length of the transformer
input, setting it from 10 to 50 with a stride of 10. Fig. 2 shows
that DACR performs stably when the length exceeds 20.
4. CONCLUSION
We present Distribution-Augmented Contrastive Reconstruc-
tion (DACR) for time-series anomaly detection. DACR lever-
ages a VAE to conduct distribution augmentation, which
helps extract intrinsic semantics from univariate time-series
features through contrastive learning. Then DACR applies the
attention mechanism to model the semantic dependency be-
tween multivariate features and achieve reconstruction-based
anomaly detection.
Extensive experiments on nine bench-
mark datasets in various scenarios demonstrate that DACR
achieves new state-of-the-art performance.
5. REFERENCES
[1] Ane Bl´azquez-Garc´ıa, Angel Conde, Usue Mori, and
Jose A Lozano, “A review on outlier/anomaly detection
in time series data,” ACM Computing Surveys, 2021.
[2] Jining Chen, Weitu Chong, Siyu Yu, Zhun Xu, Chao-
hong Tan, and Ningjiang Chen, “Tcn-based lightweight
log anomaly detection in cloud-edge collaborative en-
vironment,” in Tenth International Conference on Ad-
vanced Cloud and Big Data, 2022.
[3] Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun,
and Dan Pei, “Robust anomaly detection for multivari-
ate time series through stochastic recurrent neural net-
work,” in ACM KDD, 2019.
[4] Zhihan Li, Youjian Zhao, Jiaqi Han, Ya Su, Rui Jiao,
Xidao Wen, and Dan Pei,
“Multivariate time series
anomaly detection and interpretation using hierarchical
inter-metric and temporal embedding,” in ACM KDD,
2021.
[5] Dan Hendrycks, Mantas Mazeika, and Thomas Diet-
terich, “Deep anomaly detection with outlier exposure,”
in ICLR, 2018.
[6] Sachin Goyal, Aditi Raghunathan, Moksh Jain, Har-
sha Vardhan Simhadri, and Prateek Jain, “Drocc: Deep
robust one-class classification,” in ICML, 2020.
[7] Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo
Shin, “Csi: Novelty detection via contrastive learning
on distributionally shifted instances,” NeurIPS, 2020.
[8] Chen Qiu, Timo Pfrommer, Marius Kloft, Stephan
Mandt, and Maja Rudolph,
“Neural transformation
learning for deep anomaly detection beyond images,” in
ICML, 2021.
[9] R Devon Hjelm,
Alex Fedorov,
Samuel Lavoie-
Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio, “Learning deep repre-
sentations by mutual information estimation and maxi-
mization,” in ICLR, 2018.
[10] Tongzhou Wang and Phillip Isola, “Understanding con-
trastive representation learning through alignment and
uniformity on the hypersphere,” in ICML, 2020.
[11] Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin,
and Tomas Pfister, “Learning and evaluating representa-
tions for deep one-class classification,” in ICLR, 2020.
[12] Kushal Chauhan, Pradeep Shenoy, Manish Gupta, De-
varajan Sridharan, et al., “Robust outlier detection by
de-biasing vae likelihoods,” in CVPR, 2022.
[13] Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi
Anand, Lovekesh Vig, Puneet Agarwal, and Gautam
Shroff, “Lstm-based encoder-decoder for multi-sensor
anomaly detection,” arXiv:1607.00148, 2016.
[14] Shreshth Tuli, Giuliano Casale, and Nicholas R Jen-
nings,
“Tranad:
Deep transformer networks for
anomaly detection in multivariate time series data,”
arXiv:2201.07284, 2022.
[15] Lixu Wang, Shichao Xu, Ruiqi Xu, Xiao Wang, and
Qi Zhu, “Non-transferable learning: A new approach
for model ownership verification and applicability au-
thorization,” in ICLR, 2021.
[16] Nikos Komodakis and Spyros Gidaris, “Unsupervised
representation learning by predicting image rotations,”
in ICLR, 2018.
[17] Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng
Yang, Congrui Huang, Yunhai Tong, and Bixiong Xu,
“Ts2vec: Towards universal representation of time se-
ries,” in AAAI, 2022.
[18] Tal Reiss and Yedid Hoshen, “Mean-shifted contrastive
loss for anomaly detection,” arXiv:2106.03844, 2021.
[19] Payal Mohapatra, Bashima Islam, Md Tamzeed Islam,
Ruochen Jiao, and Qi Zhu, “Efficient stuttering event
detection using siamese networks,” in ICASSP, 2023.
[20] Ailin Deng and Bryan Hooi, “Graph neural network-
based anomaly detection in multivariate time series,” in
AAAI, 2021.
[21] Mononito Goswami, Cristian Ignacio Challu, Laurent
Callot, Lenon Minorics, and Andrey Kan, “Unsuper-
vised model selection for time series anomaly detec-
tion,” in ICLR, 2023.
[22] Nikolay Laptev,
Saeed Amizadeh,
and Ian Flint,
“Generic and scalable framework for automated time-
series anomaly detection,” in ACM KDD, 2015.
[23] Ailin Deng and Bryan Hooi, “Graph neural network-
based anomaly detection in multivariate time series,” in
AAAI, 2021.
[24] Chenxi Liu, Lixu Wang, Lingjuan Lyu, Chen Sun, Xiao
Wang, and Qi Zhu, “Deja vu: Continual model general-
ization for unseen domains,” in ICLR, 2022.
[25] B Saha and K Goebel,
“Nasa ames prognostics data
repository,” NASA Ames, Moffett Field, CA, USA, 2007.
[26] Hongzuo Xu, Yijie Wang, Songlei Jian, Qing Liao,
Yongjun Wang, and Guansong Pang, “Calibrated one-
class classification for unsupervised time series anomaly
detection,” arXiv:2207.12201, 2022.
","nanFor reconstruction prediction, anomaly detectors overfit to normal data. Convolution neural networks, LSTMs, and transformers are applied to build such models. Anomaly exposure utilizes extra data generation with supervised learning for better normal data modeling. SSL methods, initially designed for image data, have not been explored for time-series anomaly detection. Attention-based reconstruction prediction also exists."
"This paper emphasizes the need for explainable artificial intelligence (XAI) in automatic speech recognition (ASR) systems, particularly in scenarios where understanding the reasoning behind a model's decisions is vital. The proposed NoRefER (No Reference Error Rate) metric is introduced and explored as a tool for identifying word-level errors to assist post-editors and enhance ASR system performance. The research investigates NoRefER's applicability in corpus building, demonstrating its potential in augmenting datasets with insightful annotations, and further examines its utility in improving ASR models through efficient error detection and fine-tuning. The key findings suggest that NoRefER goes beyond mere error detection, serving as a comprehensive framework for enhancing ASR systems' transparency, efficiency, and effectiveness.","Automatic speech recognition (ASR) systems have witnessed remarkable advancements, yet the quest for models that offer both high accuracy and transparent decision-making processes remains an ongoing challenge. This paper addresses the deficiency of clarity in commercial ASR models, commonly referred to as ""black boxes,"" by exploring the potential of quality estimation (QE) metrics, specifically the NoRefER metric, as a novel tool to enhance explainability in ASR systems. The research focuses on identifying word-level errors to aid post-editors and augmenting datasets with valuable insights, aiming to bridge the gap between ASR systems' capabilities and their explainability.","The research method involves analyzing the attention distribution of the NoRefER model at both word and token levels, paying special attention to sentences with varying Word Error Rate (WER). This analysis aims to uncover patterns that can improve the model's performance and inform more effective training strategies. The NoRefER architecture is centered around a pre-trained cross-lingual language model (LM), MiniLMv2, with the addition of linear layers, dropout, and a non-linear activation function. The attention scores from the encoder layers before the linear layers are collected and processed to extract token-level and word-level attention. The investigation proceeds to correlate attention scores with transcription errors and compares the effectiveness of NoRefER's error detection with conventional approaches using confidence scores from open-source ASR models.","The findings reveal that the NoRefER model's attention values effectively distinguish faulty words, demonstrating superior performance compared to traditional ASR confidence scores. Furthermore, the analysis shows that word-level errors can be ranked based on the frequency of their occurrences and high error rates correlate with higher attention scores. This correlation provides valuable insights for corpus building, enabling the identification and quantification of error-prone words. Additionally, the study demonstrates the robustness of the NoRefER metric across different datasets and the utility of scaling attention scores with the norm of value vectors to enhance word-level error detection.","The study concludes that the NoRefER tool significantly advances XAI in ASR systems. Its strength lies in identifying word-level errors, refining ASR outputs, and enhancing model interpretability. The dataset-level analysis showcases the potential of NoRefER in improving model training and data augmentation strategies. The findings establish NoRefER as a powerful tool for ASR error detection, explainability, and efficacy, marking a notable advancement in the field of XAI.",Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric,"Golara Javadi, Kamer Ali Yuksel, Yunsu Kim, Thiago Castro Ferreira, Mohamed Al-Badrashiny","WORD-LEVEL ASR QUALITY ESTIMATION FOR EFFICIENT CORPUS SAMPLING AND
POST-EDITING THROUGH ANALYZING ATTENTIONS OF A REFERENCE-FREE METRIC
Golara Javadi, Kamer Ali Yuksel, Yunsu Kim, Thiago Castro Ferreira, Mohamed Al-Badrashiny
aiXplain Inc., Los Gatos, CA, USA
ABSTRACT
In the realm of automatic speech recognition (ASR), the quest
for models that not only perform with high accuracy but also
offer transparency in their decision-making processes is cru-
cial. The potential of quality estimation (QE) metrics is in-
troduced and evaluated as a novel tool to enhance explain-
able artificial intelligence (XAI) in ASR systems. Through
experiments and analyses, the capabilities of the NoRefER
(No Reference Error Rate) metric are explored in identifying
word-level errors to aid post-editors in refining ASR hypothe-
ses. The investigation also extends to the utility of NoRefER
in the corpus-building process, demonstrating its effective-
ness in augmenting datasets with insightful annotations. The
diagnostic aspects of NoRefER are examined, revealing its
ability to provide valuable insights into model behaviors and
decision patterns. This has proven beneficial for prioritizing
hypotheses in post-editing workflows and fine-tuning ASR
models. The findings suggest that NoRefER is not merely
a tool for error detection but also a comprehensive framework
for enhancing ASR systems’ transparency, efficiency, and ef-
fectiveness. To ensure the reproducibility of the results, all
source codes of this study are made publicly available1.
Index Terms— Automatic Speech Recognition, Explain-
ability, Reference-less Metric, Quality Estimation
1. INTRODUCTION
The quest for explainability in automatic speech recogni-
tion (ASR) systems has grown increasingly complex, mainly
when dealing with commercial ASR models that often oper-
ate as “black boxes”. While delivering high accuracy, these
complex models typically lack transparency in their decision-
making processes.
This lack of clarity poses significant
challenges, especially in scenarios where understanding the
rationale behind a model’s decisions is equally as critical as
the decisions themselves. Such scenarios include (but are not
limited to) medical transcription, emergency response sys-
tems, accessibility services, and automotive systems, where
the accurate processing of voice commands is essential for
ensuring driver safety and vehicle functionality.
1GitHub:https://github.com/aixplain/NoRefER/tree/main/icassp-xai
Addressing this need, this paper explores the utility of to-
ken or word attention mechanisms of QE metrics for ASR
explainability. The aim is to unravel the intricacies of these
models, shedding light on how they process and interpret lin-
guistic information. In recent years, attention mechanisms
have become a cornerstone in the architecture of deep neu-
ral networks, especially in natural language processing (NLP)
and ASR tasks. These mechanisms provide a means to in-
terpret model decisions by assigning weights to different in-
put parts. However, the direct interpretation of these atten-
tion weights is often misleading due to factors like entan-
gled representations and the inherent instability of attention
distributions [1, 2]. An approach is employed in which at-
tention weights are scaled with the norm of value vectors in
transformer-based ASR models [3]. This method addresses
raw attention weights’ limitations, offering a more stable and
reliable measure for identifying word-level errors (Figure 1).
The implications of this research extend to various as-
pects of ASR system deployment and improvement. By high-
lighting word-level errors through enhanced attention mech-
anisms, NoRefER can significantly aid post-editors and con-
tribute to the corpus-building process for ASR systems. Tra-
ditional approaches to identifying inaccuracies in ASR out-
puts often require listening to entire audio files, which is time-
consuming and labor-intensive. This method introduces a sig-
nificant efficiency boost by pinpointing potential erroneous
segments in the transcription. Such a targeted approach al-
lows post-editors to focus their efforts directly on the prob-
lematic areas, dramatically reducing the time and effort in-
volved in the correction process. This study aims to bridge
the gap between the advanced capabilities of ASR systems
and the need for their explainability. The key contributions of
this research are three-fold:
• NoRefER is introduced as a tool for enhancing ASR
model interpretability by identifying word-level errors
without reference transcriptions.
• NoRefER’s role in assisting post-editors and improv-
ing ASR system quality through refined outputs and
corpus-building is demonstrated.
• The application of NoRefER to commercial (black-
box) models is showcased, enabling error identification
and enhancing transparency without confidence scores.
arXiv:2401.11268v1  [cs.CL]  20 Jan 2024
Fig. 1. NoRefER attention for Error Identification in token
and word level. Attention scores (with the L2 norm scaling)
are averaged across all model layers for interpretability.
2. RELATED WORKS
QE in ASR is identified as a critical aspect of evaluating and
enhancing the performance of ASR systems without refer-
ences.
Traditionally, evaluation has been centered around
reference-based metrics –like Word Error Rate (WER)–
which compare ASR outputs with ground-truth transcripts.
However, obtaining these transcripts is often time-consuming
and costly.
A novel approach to QE is the reference-less
metrics [4, 5, 6, 7].
One of these metrics is NoRefER, a
multi-language reference-free quality metric for ASR sys-
tems [7, 8]. The innovation in NoRefER lies in its ability to
provide an evaluation metric that overcomes the limitations of
traditional reference-based metrics, enabling its application
to speech datasets lacking ground truth. The fine-tuned model
demonstrated a high correlation with WER scores and ranks.
In ASR and language technologies, explainability be-
comes crucial for identifying the reasons behind a model’s
predictions, enhancing transparency, and building trust.
Explainability methods can be broadly categorized into
simplification-based, perturbation-based, and gradient-based
approaches. One key approach is feature attribution meth-
ods, which assign relevance scores to inputs to explain model
predictions.
These methods include techniques like local
interpretable model-agnostic explanations (LIME) [9], gra-
dients, and attention mechanisms [10, 11]. An exciting ap-
plication of explainability in ASR is observed in QE, where
feature attribution methods are employed to understand how
QE models make predictions.
[12] discusses how feature
attribution methods can derive information on translation er-
rors from sentence-level models in QE. [13] also highlights
the role of layer-wise token representation in Transformers,
which is key to using NoRefER attention for explainability.
3. METHODOLOGY
In this work, the attention distribution of the NoRefER model
is closely examined, focusing mainly on its behavior at both
word and token levels. This analysis targets sentences with
varying WER. The aim is to identify critical patterns or ten-
dencies that could enhance the model’s performance and
inform more effective training strategies.
The NoRefER
architecture is centered around a pre-trained cross-lingual
language model (LM), MiniLMv2, a compact and efficient
XLM-RoBERTa-Large [14] derivative containing only 117
million parameters with the addition of two linear layers, a
dropout, and a non-linear activation function in-between [7].
Initially, attention scores from the NoRefER model’s lay-
ers of the encoder before the linear layers are collected. These
scores represent the degree of focus each token places on
other tokens within a sentence batch. Structured as tensors,
these scores require aggregation for interpretation in ASR-
QE. First, attention scores are averaged across all layers and
heads [13]. Then, the token-level attention is calculated by
averaging scores directed by each token toward others, as-
sessing their contextual significance. Lastly, the interpretabil-
ity of attention values is further refined by scaling the atten-
tion probabilities with the L2 norm of value vectors. This ap-
proach, reflecting the strategies in [3], merges the magnitude
of value vectors with attention probabilities, improving the
performance of word-level models. Such scaling is demon-
strated to yield superior results in experiments, surpassing
other methods in accuracy and correlation metrics.
In transitioning from token-level to word-level attention
within the analysis, max-pooling is adopted to aggregate the
attention scores effectively. This pinpoints the most impact-
ful token within a word, thereby reflecting the word’s overall
significance or emphasis in the model’s attention mechanism.
Following the aggregation of attention scores, the next step
involves a detailed investigation of the relationship between
these attention scores and the actual transcription errors. This
analysis aims to ascertain whether the attention mechanism,
as interpreted through the method, aligns with the occurrence
of errors in transcriptions. Insights into the model’s error de-
tection capabilities are intended to be unveiled by correlating
attention scores with error patterns.
The study sets to compare the effectiveness of the NoRe-
fER’s attention-based error detection with the conventional
approach of using confidence scores from open-source ASR
models, such as CTC and Whisper [15, 16]. This compari-
son is particularly pertinent in cases where ASR confidence
scores are unavailable, highlighting the NoRefER’s utility in
practical, real-world ASR applications.
4. DATASET AND METRICS
For evaluation, the referenceless metric, NoRefER, is applied
to Common Voice (in English, French, Spanish) [17] and Lib-
riSpeech (English) [18] test datasets. Transcription hypothe-
ses for these test datasets are sourced from leading commer-
cial ASR engines (AWS, AppTek, Azure, Deepgram, Google,
and OpenAI’s Whisper-Large), ensuring a thorough evalua-
tion of each speech segment within the datasets. The median
sentence length and the median of faulty words per sentence
in each dataset are as follows:
Table 1. Sentence Length and Error Statistics in Datasets
Dataset
Median length Median errors/sent
LibriSpeech (En)
17
3
Common Voice
10
1
All Datasets
11
2
In assessing the performance of the NoRefER metric’s at-
tention mechanism, the below suite of metrics is applied, de-
signed to evaluate both continuous and binary scoring meth-
ods. These metrics are calculated for each instance in the test
set and then averaged. This approach aligns with established
practices in [19] for robustly assessing word-level outputs.
Area Under the Curve (AUC): Each transcription in-
stance is evaluated by computing the AUC score, which mea-
sures the model’s ability to distinguish between correctly tran-
scribed words and errors based on continuous attention scores
against binary error labels from ground-truth references.
Average Precision (AP): Recognizing the limitations of
AUC in the context of imbalanced datasets, Average Precision
is also employed as a metric. AP provides a more detailed as-
sessment by summarizing the precision-recall curve through
the weighted mean of precision at successive thresholds, with
weights derived from the increase in recall.
Top-K classification metrics: These metrics (Precision,
Recall, F1, Accuracy), commonly utilized in ranking, calcu-
late the fraction of words with the highest attention scores
corresponding to actual transcription errors relative to the to-
tal number of errors present in the output. They measure the
capability of NoRefER to prioritize words for post-editing or
further scrutiny. Here, the weighted versions of those metrics
are always employed to account for the class imbalance.
5. EXPERIMENTS
Using max-pooling and attention scaled by the norm of value
vectors as the chosen method for aggregating attention scores,
the metrics outlined in Section 4 are calculated to evaluate
the attention scores as a QE measure. As a reference, atten-
tion values are compared with the binary scores obtained us-
ing the JiWER library [20], which labels faulty words in the
transcription, such as those that are deleted, inserted, or sub-
stituted. This comparison is crucial in assessing the effective-
ness of the attention scores in identifying errors within refer-
enceless transcription hypotheses. As a baseline for this eval-
uation, confidence scores from publicly available ASR mod-
els, including Whisper and CTC, are utilized (Table 2).
Two distinct approaches are investigated when selecting
the optimal value for k in the classification metrics. The first
approach involves fixing k to a constant value ranging from 1
to 5. This range is visually explored through a plot, as seen
in Figure 2, showing performance metrics across different k
values. Since the median number of faulty words per sen-
tence in the datasets is 2, setting k to 2 is identified as a log-
ical choice. Furthermore, analysis reveals that the metrics at
k = 1 yield promising results, suggesting that even the most
highly weighted words in a sentence offer significant informa-
tion about potential errors. The second method adopts a dy-
namic approach, setting k to 10 percent of the length of each
sentence. This adaptive strategy considers the variability in
sentence lengths across the dataset, thus providing a tailored
evaluation for each transcription. The results of this dynamic
k selection method are detailed in Table 2, demonstrating its
robustness in assessing the ASR quality.
Fig. 2. Variation of Weighted Precision, Recall, and F1-Score
with increasing k in the evaluation of word-level attention.
For the ablation study, two strategies for explainability
are explored to understand the model’s behavior comprehen-
sively. These include using raw attention values, attention
scaled by the norm of value vectors and on top that multi-
plying with gradients. By scaling attention with the norm of
value vectors, deeper insights are gained into how the model
weights and prioritizes different tokens and words in a sen-
tence. In transitioning from token-level to word-level atten-
tion, three aggregation methods are examined: Average At-
tention, which calculates the mean of all constituent token
scores for each word; Max Attention, identifying the highest
attention score within a word’s tokens; and Q3 Attention, fo-
cusing on the third quartile value among token scores to mit-
igate the impact of outliers. Max Attention is ultimately se-
lected for its efficacy in pinpointing the most influential parts
of a word according to the model’s attention. Table 3 com-
pares all settings, demonstrating the rationale behind choos-
ing Max Attention and scaling by the norm of value vectors.
Table 2. The comparative analysis of attention impact on word-level error-ranking metrics using the NoRefER metric, and
comparison of the best result with several baseline methods, incorporating gradients or confidence, as an alternative to attention.
Dataset
Variant
Recall
@k
Precision
@k
F1
@k
Accuracy
@k
Balanced
Acc @k
AP
AUC
en-librispeech
k = 2
0.80
0.81
0.79
0.80
0.66
0.62
0.78
dyn
0.81
0.82
0.80
0.81
0.68
en-common
k = 2
0.71
0.81
0.74
0.71
0.63
0.36
0.63
dyn
0.75
0.82
0.76
0.75
0.65
es-common
k = 2
0.71
0.81
0.73
0.71
0.64
0.38
0.66
dyn
0.75
0.81
0.76
0.75
0.66
fr-common
k = 2
0.65
0.72
0.65
0.65
0.59
0.57
0.68
dyn
0.68
0.75
0.66
0.68
0.61
all-datasets (proposed)
k = 2
0.72
0.79
0.73
0.72
0.63
0.48
0.69
dyn
0.75
0.80
0.75
0.75
0.65
gradient
0.72
0.77
0.72
0.72
0.60
0.31
0.62
all-datasets (baselines)
whisper
0.65
0.73
0.64
0.65
0.56
0.49
0.62
ctc-conf
0.52
0.91
0.57
0.52
0.51
0.52
0.74
random
0.12
0.23
0.14
0.70
0.56
0.31
0.50
Table 3. Ablation studies on attention aggregation and nor-
malization methods for the NoRefER metric over all datasets.
Aggregation
Scaling
F1@k
avg
att ∗ value norm
0.70
q3
att ∗ value norm
0.73
max
att ∗ value norm
0.75
max
att ∗ norm ∗ grad
0.70
max
raw attention (att)
0.70
6. DISCUSSION
Remarkably, the findings reveal that the attention values gen-
erated by the NoRefER model are adept at distinguishing
faulty words. This is significant, as it demonstrates the met-
ric’s capability to identify potential errors in the transcriptions
without needing reference transcriptions. These results are
found to be even superior to those obtained using traditional
ASR confidence scores. This superiority not only reinforces
the effectiveness of the NoRefER model in error detection
but also underscores its advantage in scenarios where ASR
confidence scores are either unavailable or unreliable.
In the dataset-level analysis, words are ranked based on
the frequency of their erroneous occurrences across the en-
tire dataset. The average attention score is calculated for each
word, aggregating across all instances of its appearance. This
process allows for an evaluation of how the model’s attention
correlates with the rate of errors associated with each word
throughout the dataset. The high correlation between atten-
tion scores and word error frequencies (Table 4) highlights the
corpus-building potential of the NoRefER model. The ability
to identify and quantify error-prone words based on attention
provides valuable insights and guidelines for potential adjust-
Table 4. Correlation calculated between NoRefER attention
scores and actual word error frequencies in various datasets.
Dataset
Pearson
Kendall
Spearman
en-librispeech
0.87
0.68
0.82
en-common
0.87
0.68
0.82
es-common
0.91
0.73
0.86
fr-common
0.74
0.60
0.74
all-datasets
0.80
0.65
0.79
ments in model training and data augmentation.
To actualize this, data augmentation can be strategically
implemented by introducing variations of the identified error-
prone words in diverse linguistic contexts. This process en-
riches the training dataset, allowing the ASR system to learn
from a broader spectrum of scenarios where these specific er-
rors may occur. Additionally, targeted post-editing and fine-
tuning can be applied, wherein the model is repeatedly ex-
posed to and corrected for these particular errors. This itera-
tive process sharpens the model’s understanding of language
patterns and reinforces its ability to interpret and transcribe
speech accurately in complex or ambiguous situations.
7. CONCLUSIONS
In conclusion, the NoRefER tool significantly advances XAI
in ASR systems, excelling in identifying word-level errors
and refining ASR outputs. Furthermore, its dataset-level anal-
ysis, correlating attention scores with error rates, showcases
its potential to enhance model training and data augmentation
strategies. The findings establish NoRefER as a robust tool
for ASR error detection, as well as interpretability and effi-
cacy; marking a notable advancement in the field of XAI.
8. REFERENCES
[1] Matteo Lugli, Paolo Perinotti, and Alessandro Tosini,
“Fermionic state discrimination by local operations and
classical communication,” Physical Review Letters, vol.
125, no. 11, pp. 110403, 2020.
[2] Elena Voita, David Talbot, Fedor Moiseev, Rico Sen-
nrich, and Ivan Titov,
“Analyzing multi-head self-
attention: Specialized heads do the heavy lifting, the rest
can be pruned,” arXiv preprint arXiv:1905.09418, 2019.
[3] Marina Fomicheva, Piyawat Lertvittayakumjorn, Wei
Zhao, Steffen Eger, and Yang Gao,
“The Eval4NLP
shared task on explainable quality estimation: Overview
and results,” in Proceedings of the 2nd Workshop on
Evaluation and Comparison of NLP Systems. 2021, pp.
165–178, Association for Computational Linguistics.
[4] Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon
Lavie, “Unbabel’s participation in the WMT20 metrics
shared task,” in Proceedings of the Fifth Conference on
Machine Translation, 2020, pp. 911–920.
[5] Kamer Ali Yuksel, Ahmet Gunduz, Mohamed Al-
Badrashiny, and Hassan Sawaf, “Evolvemt: an ensem-
ble mt engine improving itself with usage only,” in The
61st Annual Meeting Of The Association For Computa-
tional Linguistics, 2023.
[6] Shammur Absar Chowdhury and Ahmed Ali, “Multi-
lingual word error rate estimation: E-wer3,” in ICASSP
2023-2023 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP). IEEE,
2023, pp. 1–5.
[7] Kamer Ali Yuksel, Thiago Castro Ferreira, Ahmet
Gunduz, Mohamed Al-Badrashiny, and Golara Javadi,
“A reference-less quality metric for automatic speech
recognition via contrastive-learning of a multi-language
model with self-supervision,”
in IEEE International
Conference on Acoustics, Speech, and Signal Process-
ing (ICASSP). 2023, pp. 1–5, IEEE.
[8] Kamer Ali Yuksel, Thiago Castro Ferreira, Golara
Javadi, Mohamed Al-Badrashiny, and Ahmet Gunduz,
“Norefer: a referenceless quality metric for automatic
speech recognition via semi-supervised language model
fine-tuning with contrastive learning,” in Proc. INTER-
SPEECH 2023, 2023, pp. 466–470.
[9] Marco Tulio Ribeiro,
Sameer Singh,
and Carlos
Guestrin, “Why should I trust you? explaining the pre-
dictions of any classifier,” in Proceedings of the 22nd
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, 2016, pp. 1135–1144.
[10] Marcos Treviso, Nuno M Guerreiro, Ricardo Rei, and
Andr´e FT Martins, “Ist-unbabel 2021 submission for
the explainable quality estimation shared task,” in Pro-
ceedings of the 2nd Workshop on Evaluation and Com-
parison of NLP Systems, 2021, pp. 133–145.
[11] Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, and
Kentaro Inui, “Attention is not only a weight: Analyzing
transformers with vector norms,” in Proceedings of the
2020 Conference on Empirical Methods in Natural Lan-
guage Processing. Association for Computational Lin-
guistics, 2020, pp. 7057–7075.
[12] Marina Fomicheva, Lucia Specia, and Nikolaos Ale-
tras,
“Translation error detection as rationale extrac-
tion,” arXiv preprint arXiv:2108.12197, 2021.
[13] Elena Voita, Rico Sennrich, and Ivan Titov,
“The
bottom-up evolution of representations in the trans-
former: A study with machine translation and language
modeling objectives,” arXiv preprint arXiv:1909.01380,
2019.
[14] Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong,
and Furu Wei, “Minilmv2: Multi-head self-attention re-
lation distillation for compressing pretrained transform-
ers,” arXiv preprint arXiv:2012.15828, 2020.
[15] Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki
Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang,
Zhengdong Zhang, Yonghui Wu, and Ruoming Pang,
“Conformer: Convolution-augmented transformer for
speech recognition,” in Proc. INTERSPEECH, 2020.
[16] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brock-
man, Christine McLeavey, and Ilya Sutskever, “Robust
speech recognition via large-scale weak supervision,” in
International Conference on Machine Learning. PMLR,
2023, pp. 28492–28518.
[17] Rosana Ardila, Megan Branson, Kelly Davis, Michael
Henretty, Michael Kohler, Josh Meyer, Reuben Morais,
Lindsay Saunders, Francis M Tyers, and Gregor Weber,
“Common voice: A massively-multilingual speech cor-
pus,” arXiv preprint arXiv:1912.06670, 2019.
[18] Vassil Panayotov, Guoguo Chen, Daniel Povey, and San-
jeev Khudanpur,
“Librispeech: an asr corpus based
on public domain audio books,” in International Con-
ference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, 2015, pp. 5206–5210.
[19] Pepa Atanasova, Jakob Grue Simonsen, Christina Li-
oma, and Isabelle Augenstein, “A diagnostic study of
explainability techniques for text classification,” arXiv
preprint arXiv:2009.13295, 2020.
[20] JiWER, “JiWER: Evaluation metrics for asr,” 2023.
","The study acknowledges the significance of reference-based metrics in evaluating ASR performance. However, it emphasizes the limitations of these metrics, particularly the dependency on ground-truth transcripts. The research explores the alternative approach of reference-less metrics, highlighting their advantages and introducing NoRefER as a state-of-the-art reference-less quality metric. Furthermore, the work delves into the emerging field of explainability in ASR and language technologies, reviewing various approaches, including simplification-based, perturbation-based, and gradient-based methods. It identifies feature attribution methods as a key technique for understanding how QE models make predictions and discusses their application in NoRefER.nan"
"Diffusion models have demonstrated impressive results in image synthesis and beyond. A common way to control the generation of these models is to provide various conditioning inputs, such as text or bounding boxes. This paper presents a conditioning mechanism utilizing Gaussian mixture models (GMMs) for feature conditioning to guide the denoising process. Instead of embedding text into a fixed value, GMM is designed to represent distributions which better aligns with our model assumption. This distributional embedding of features with multiple GMMs enables us to recover a more refined subset of the data distribution during training. When comparing two diffusion models with different conditioning mechanisms trained with similar model sizes and training methods, we found that the model trained with a conditioning mechanism utilizing GMMs consistently outperforms the other. A novel gradient function called the negative Gaussian mixture gradient (NGMG) is also introduced and applied in diffusion model training with an additional classifier. The NGMG gradient function shares properties with the Earth Mover distance and is theoretically proven to be a more sensible cost function when learning distributions supported by low-dimensional manifolds. Experiments demonstrate that NGMG improves model stability in training.","Generative models have become increasingly spectacular in recent neural network development. Diffusion models (DMs) in particular have achieved impressive results in image synthesis, audio generation, and super-resolution. Conditioning mechanisms, such as text or bounding boxes, are commonly used to control the model's generation. This work proposes a conditioning mechanism utilizing Gaussian mixture models (GMMs) for feature conditioning to guide the denoising process. Unlike class information, which splits data into certain classes, feature information provides distributional characteristics that lead to less defected generations. Theoretical analysis based on set theory supports this finding. Two diffusion models incorporating different conditioning mechanisms are trained separately. Despite having a smaller model size and lower-resolution images, the model trained with the GMM-based conditioning mechanism outperforms the other model trained with the CelebA dataset. Additionally, a novel gradient function called the negative Gaussian mixture gradient (NGMG) is introduced and applied in diffusion model training with an additional classifier. NGMG, which shares properties with the Earth Mover distance, is theoretically shown to be a more sensible cost function when learning distributions supported by low-dimensional manifolds. Experiments confirm that NGMG improves model stability during training.","The proposed diffusion model utilizes a Gaussian mixture model (GMM) to construct latent distributions. Latent distributions built by classes or features significantly impact the model's performance. Latent distribution constructed by features result in refined conditional event spaces, leading to fewer defected generations compared to latent distribution built by classes. Two separate models are trained using the same method and similar model sizes, one with Cifar10 images and the other with CelebA images. Even with a larger model size and smaller images, the model trained with Cifar10 still performs worse than the model trained with Celeb. This highlights the relationship between feature information and recovering the data distribution event space. An additional classifier is introduced in the diffusion model to provide guidance during training. This classifier utilizes a novel distance function based on the Gaussian mixture model for training. The proposed negative Gaussian mixture gradient (NGMG) function is introduced and applied to various distance functions. Theoretically, NGMG is a linear transform of the Wasserstein distance, sharing the same benefit as the Wasserstein distance as a cost function compared to many likelihood-based methods.","The proposed diffusion model with the GMM-based conditioning mechanism outperforms the other model trained with the CelebA dataset, despite having a smaller model size and lower-resolution images. This indicates that feature information is crucial for recovering the data distribution event space. Experiments with NGMG demonstrate that it improves model stability during training and works better than the classic binary cross-entropy loss.",This work introduces a conditioning mechanism utilizing Gaussian mixture models (GMMs) for diffusion models. The proposed model is trained with the CelebA dataset and outperforms a model trained with a different conditioning mechanism under similar training conditions. The results suggest that feature information is essential for recovering the data distribution event space. A novel gradient function called the negative Gaussian mixture gradient (NGMG) is also proposed and applied in diffusion model training with an additional classifier. NGMG is theoretically shown to be a more sensible cost function when learning distributions supported by low-dimensional manifolds. Experiments confirm that NGMG improves model stability during training.,Diffusion Model Conditioning on Gaussian Mixture Model and Negative Gaussian Mixture Gradient,"Weiguo Lu, Xuan Wu, Deng Ding, Jinqiao Duan, Jirong Zhuang, Gangnan Yuan","DIFFUSION MODEL CONDITIONING ON GAUSSIAN MIXTURE
MODEL AND NEGATIVE GAUSSIAN MIXTURE GRADIENT
Weiguo Lu
Department of Mathematics
University of Macau
Macau
yc07476@um.edu.mo
Xuan Wu
Department of Mathematics
University of Macau
Macau
yc27937@um.edu.mo
Deng Ding
Department of Mathematics
University of Macau
Macau
dding@um.edu.mo
Jinqiao Duan
School of Sciences
Great Bay University
China
duan@gbu.edu.cn
Jirong Zhuang
Department of Mathematics
University of Macau
Macau
yc27478@um.edu.mo
Gangnan Yuan
School of Sciences
Great Bay University
China
gnyuan@gbu.edu.cn
ABSTRACT
Distribution of  {Faces | Arched Eyebrows, Attractive, Brown Hair, Heavy Makeup, 
      High Cheekbones, Smiling, Young,…}
Real Images: CelebA
Fake Images
Figure 1: Real vs. Fake
Diffusion models (DMs) are a type of generative model that has a huge impact on image synthesis and
beyond. They achieve state-of-the-art generation results in various generative tasks. A great diversity
of conditioning inputs, such as text or bounding boxes, are accessible to control the generation. In
this work, we propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) as
arXiv:2401.11261v1  [cs.LG]  20 Jan 2024
W.Lu et al.
feature conditioning to guide the denoising process. Based on set theory, we provide a comprehensive
theoretical analysis that conditional latent distribution based on feature and classes are significantly
different so that conditional latent distribution on features produce less defect generations than
conditioning on classes. Two diffusion models conditioning on Gaussian mixture model are trained
separately for comparison. Experiments result support our findings. A novel gradient function
called the negative Gaussian mixture gradient (NGMG) is proposed and applied in diffusion model
training with an additional classifier. Training stability is improved. We also theoretically prove that
NGMG shares the same benefit as the Earth Mover distance (Wasserstein)[44] as a more sensible
cost function when learning distributions supported by low dimensional manifolds.
Keywords Gaussian Mixture Model (GMM) · Neural Network · Diffusion Model · Latent Variable · Earth Mover
Distance · Wasserstein Distance
1
Introduction
Generative models are one of the most spectacular fields in recent neural network development. Diffusion models (DM)s
[1, 2, 8, 4, 10, 12, 5] achieve impressive results in image synthesis, audio generation [3, 13, 14], and super-resolution[7].
In general, DMs have several benefits compared to GANS, where GANs are commonly known to have mode-collapse
and training instabilities. Generally, DMs’ underlying model is UNet[5, 2, 10][15]. U-net is a variation of auto-encoder
[16]. Whereas classic auto-encoders decode the information from the latent variables in the bottleneck layer, U-net
integrates information from each encoder layer for decoding.
Latent diffusion models[12] train an autoencoder that produces a lower-dimensional latent space to reconstruct data
space[46][47]. Various image-to-image, text-to-image, and token-based conditioning mechanisms are able to apply
in Latent diffusion models. Text-to-image task takes text information and tokenizes it as conditional input. In [12],
BERT-tokenizer[31] is being used to infer latent code. Put it in a distributional perspective, describing a dataset by text
is similarly splitting data distribution event space into various subsets. If given information about subsets, we can design
a token-based method to condition our generation. Attributes of the CelebA dataset[32] give a good example. Unlike
class information, CelebA does not split data into certain classes but rather gives each image a set of features. CelebA
has features such as ’Arched Eyebrows’, ’Brown Hair’, ’Young’, etc. At first glance, feature (attribute) information is
similar to text-to-image conditioning, except sentences have time information. But in fact, there are subtle differences.
In a language model, word embedding usually assigns words a fixed value, but in this work, we begin with a different
assumption, which is that features are following some form of distribution. A feature is a direct reflection of a concept.
For example, smiling is not a specific angle of mouth posture. While we think of ’Beautiful starry night’, it represents a
concept that is constructed by almost infinite variations with different conditional scenarios. For short, ’Beautiful starry
night’ is a distribution rather than a fixed value. In this work, we propose a variation of the token-based conditioning
mechanism using Gaussian mixture model to represent this distributional conditioning mechanism. Fig.1 shows an
example of our proposed method. Given the concept of ’Arched Eyebrows, Attractive, Brown Hair...’, our generation
should follow a conditional distribution. Training neural networks with proposed conditioning mechanisms can be
considered a method to recover the data distribution’s event space. Given any set of features, a conditional distribution
is formed, and fake images can be randomly sampled from the conditional distribution. Under this idea, a model
assumption between data distribution and latent distribution is presented based on set theory. Studies[29, 30, 50, 51]
show that the Gaussian mixture model works better than the Gaussian distribution in various neural network models.
Following these works, we build latent distributions using the Gaussian mixture model. Technical detail is shown in
Section 3.
Based on the analysis in set theory, we also discover that latent distributions are built by classes or features that
can significantly change the model’s performance. Latent distribution constructed by features can result in refined
conditional event spaces, which produce less defected generation than latent distribution built by classes. Experimentally,
two separate models are trained using the same method and similar model sizes. One model is trained under Cifar10
[33] with an image size of 32x32x3. Another is trained under CelebA with an image size of 64x64x3. Even given the
larger model size and small images, the model trained with Cifar10 still performs worse than the model trained with
Celeb. It reveals how feature information is related to recovering the data distribution event space. Further discussion
will be given in Section 3.
Additional guidance to train a generator has shown a significant improvement in model performance. GANs [40] makes
use of an additional neural network as a discriminator to train the generation in an adversarial way. Many branches and
variations show great generation quality and become the state-of-the-art in many image generation tasks[41, 42, 43, 48].
Classification can also be used to increase model performance in terms of generation quality and, as reported, improve
the feasibility of trained latent variables[34, 35, 36, 37, 38, 39, 29, 5]. In order to harvest these benefits, we introduce a
2
W.Lu et al.
variation of the proposed diffusion model that integrates a classifier in training. A novel distance function based on
Gaussian mixture model is developed for training this classifier. Generally, the answer to unsupervised learning is to
learn a probability mass/density. Likelihood-based methods such as KL divergence and Jensen-Shannon divergence
are the two most common methods. These likelihood-based methods are reported to be unstable during the training
process. Studies from M.Arjovsky et al.[45, 44] discuss that predict distribution and true distribution are commonly
supported by low-dimensional manifolds and unlikely to share a non-negligible intersection between those supports.
This leads to KL distance becoming infinite and making training unstable. Wasserstein GAN[44] makes significant
improvements by minimizing an approximation of the Wasserstein distance. Similarly, by drawing inspiration from
theories of Wasserstein distance and some physical concepts, together with functions such as the Gaussian kernel
covariance matrix and the Gaussian mixture model, we introduce a novel gradient approximation function named
Negative Gaussian Mixture Gradinet (NGMG). This gradient approximation function can easily apply to various
distance functions. Theoretically, NGMG is a linear transform of Wasserstein distance, which shares the same benefit
as Wasserstein distance as a cost function compared to a lot of likelihood-based methods. A distribution learning
algorithm based on NGMG is provided. Experiments with density learning and neural network training are carried
out. We observed that the proposed Negative Gaussian Mixture Gradinet (NGMG) works better than classic binary
cross-entrophy loss and provides better stability in our proposed diffusion model.
Section 2 provides preliminary and general notation. Section 3 provides proposed diffusion model conditioning on the
Gaussian mixture model with experiments and comprehensive theoretical analysis in set theory. Section 4 provides our
Negative Gaussian Mixture Gradient (NGMG) function with methodology as well as theoretical comparison between
the Wasserstein distance and NGMG. Experiments are carried out to test the efficacy of NGMG. The final section
provides a conclusions.
2
Preliminary
2.1
Gaussian Mixture Model (GMM)
A mixture distribution, also referred to as a mixture model, is the probability distribution of a convex combination
of some distributions. The probability density function, or mixture density, is usually a weighted sum of the set of
distributions, and the cumulative distribution function is strictly with non-negative weights that sum to one. The
Gaussian mixture model (GMM) is one of the subsets of mixture distribution that assumes all the data points are
generated from a mixture of a finite number of Gaussian distributions. The probability density function of GMM Eq.(1)
is a linear combination of a set of Gaussian distributions. For each weight πn ≥ 0,
N
X
n=1
πn = 1.
G(x) =
N
X
n=1
πnϕ(x; Mn, Σn),
(1)
where ϕ is density function of Gaussian distributions, x ∈ RD, mean vector Mn ∈ RD, covariance matrix Σn ∈
R+D × R+D and N, D ∈ N+.
2.2
GMM Expansion and Learning Algorithm for Density Estimation
The Gaussian mixture model is a distribution, but it can also be used as a model. The weights {πn}, mean vector Mn
and covariance matrix Σn can be parameterized so that we can apply learning or optimization methods to accomplish
various tasks, such as modeling. The classic learning algorithm for GMM is the expectation-maximization algorithm. It
is a likelihood-based method that introduces latent variables to group the observed data points for the estimation of
parameters at each iteration step. Many downsides of this algorithm are discussed in plenty of literature, such as being
sensitive to parameter initialization and stuck in local minimum [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]. When
we compare the distances of two distributions, if they are from totally different distributions, a lot of methods become
undesirable for utilising the distance function to achieve learning. For instance, we simply cannot achieve a good
approximation by learning a normal distribution to approximate a mixture distribution. A simple method is introduced
[29, 30] to solve these problems and make GMM comparatively easy to learn and more adaptable in the latest machine
learning models, such as neural networks. This method includes two key components: GMM expansion and a learning
algorithm. GMM expansion has similarities to the Fourier series. It assumes that every density may be approximately
expanded by a Gaussian mixture model. This assumption results in the component Gaussian distributions having
3
W.Lu et al.
predetermined Mn and Σn as base distributions that do not need to be parameterized. {πn} are the only parameters
that need to be learned from the dataset. This not only makes density easy to learn but also gives distance functions
comparable in the same base. An one-iteration learning algorithm is provided in [30]. The method is briefly summarised
as follows:
1. Define N Gaussian distributions and evenly spread {Mn} across dataset max (x) , min (x),
2. Define hyper parameters {Σn},
3. Initialize π1 = π2... = πN = 1/N,
4. Calculate ln = PD
d=1 ϕ(xd; Mn, Σn) = PD
d=1 ϕn(xd),
5. π+1
n
=
ln
PN
n=1 ln .
Based on above studies, any two distributions, g1 and g2 can be approximated by two categorical distribution pi1 and
pi2. The difference between g1 and g2 is equivalent to the difference between pi1 and pi2. In this work, GMM is used
to construct latent distributions and is also used as a cost function. Our work is based on the setting of GMM expansion,
and further explanation will be given in Section 2.4 and 4.
2.3
Distance Function
Consider a measurable space (Ω, F), P and Q are probability measure defined on (Ω, F).
The Kullback-Leibler (KL) divergence
Continuous:
DKL(P||Q) =
Z ∞
−∞
P(x) log(P(x)
Q(x))dx.
Discrete define on sample space X:
DKL(P||Q) =
X
x∈X
P(x) log(P(x)
Q(x))
Jensen-Shannon (JS) divergence
DJS(P||Q) = 1/2(DKL(P||M) + DKL(Q||M)),
where M = 1/2(P + Q), a mixture of P and Q.
Total variation (TV) distance
δ(P, Q) = sup
A∈F
| P(A) − Q(A) |
Earth-Mover distance or Wasserstein (W) distance
n-Wasserstein distance:
Wn(P, Q) = (
inf
γ∈Γ(P,Q) E(x,y)∼γd(x, y)n)1/n,
Z
γ(x, y)dy = P,
Z
γ(x, y)dx = Q.
1-Wasserstein distance for 1 dimensional distribution:
W1(P, Q) =
Z 1
0
| F −1
p
(z) − F −1
q
(z) | dz,
Where z is the quantile and F −1 is the inverse cumulative distribution function.
4
W.Lu et al.
2.4
Wasserstein-Distance and GMM Expansion
The p-Wasserstein distance between g1 and g2 is regarded as
Wp(g1, g2) =
Z 1
0
| G−1
1 (q) − G−1
2 (q) |p dq
1/p
,
(2)
where g1 and g2 are both one-dimensional distributions and G1, G2 are distribution functions, respectively. Consider
G1 and G2 have bounded support M. When P = 1 in Eq.(2), the scheme of transportation x = G−1
2
◦ G1 leads to
W1(g1, g2) =
Z
M
| G1(x) − G2(x) | dx,
(3)
where Continuous Gi : Lipz(Gi) ≤ 1, i = 1, 2. Gi is satisfy Lipschitz continuity and Lipz(Gi) is the Lipschitz
constant. Based on duality theorem of Kantorovich and Rubinstein (1958), W1(g1, g2) is bounded because | G1(x) −
G2(x) | is bounded.
Substitute the GMM expansion by our method described above in (3) into the two distribution functions separately, and
we have
Gi(x) =
Z x
−∞
N
X
n=1
π(i)
n ϕn(s)ds =
N
X
n=1
π(i)
n
Z x
−∞
ϕn(s)ds =
N
X
n=1
π(i)
n Fn(x),
i = 1, 2.
Then
W1(g1, g2) =
Z
M
|
N
X
n=1
(π(1)
n Fn(x) − π(2)
n Fn(x)) | dx
=
Z
M
|
N
X
n=1
(π(1)
n
− π(2)
n )Fn(x) | dx.
(4)
Under GMM expansion, the Wassertein distance between g1 and g2 becomes a function of π(1)
n
and π(2)
n .
Let π(i) = [π(i)
1 , . . . π(i)
N ]T , i = 1, 2, W1(g1, g2) = W1(π(1), π(2)),
B =


b1
. . .
0
...
...
...
0
· · ·
bn

 , bn =
(
1
π(1)
n
− π(2)
n
≥ 0
0
π(1)
n
− π(2)
n
< 0 ,
W1(π(1), π(2))+ =
Z
M
N
X
n=1
bn(π(1)
n
− π(2)
n )Fn(x) dx,
W1(π(1), π(2))− =
Z
M
N
X
n=1
(1 − bn)(π(1)
n
− π(2)
n )Fn(x) dx,
W1(π(1), π(2)) =| W1(π(1), π(2))+ + W1(π(1), π(2))− | .
(5)
Next, we can vectorize Eq.(5) and get the following presentation:
−→
W1(π(1), π(2))+ =


b1(π(1)
1
− π(2)
1 )
R
M F1(x) dx
...
bN(π(1)
N − π(2)
N )
R
M FN(x) dx

 = F


b1(π(1)
1
− π(2)
1 )
...
bN(π(1)
N − π(2)
N )

 = FB · (π(1) − π(2)),
−→
W1(π(1), π(2))− =


(−b1)(π(1)
1
− π(2)
1 )
R
M F1(x) dx
...
(1 − bN)(π(1)
N − π(2)
N )
R
M FN(x) dx

 = F(I − B) · (π(1) − π(2)),
F =


R
M F1(x) dx
· · ·
0
...
...
...
0
· · ·
R
M FN(x) dx

 ,
I is the identity matrix.
5
W.Lu et al.
Under GMM expansion, we can rewrite Eq.(4) as follows:
W1(π(1), π(2)) =|∥ −→
W1(π(1), π(2))+ ∥1 − ∥ −→
W1(π(1), π(2))− ∥1|
=|∥ FB · (π(1) − π(2)) ∥1 − ∥ F(I − B) · (π(1) − π(2)) ∥1|
(6)
Eq.(6) shows a vectorized representation of Wasserstein distance under GMM expansion in bounded support M. This
will be used in Section 4 to show that the proposed negative Gaussian mixture gradient function is strongly related to
Wasserstein distance.
3
Diffusion Model Conditioning on Gaussian Mixture Model
Some studies experimentally report that [50, 51, 29, 30] GMMs is beneficial for various tasks compared with conven-
tional methods such as embedding and learning latent distributions. In this work, we build a conditioning mechanism
for the diffusion model that utilizes GMM. The neural network itself is a deterministic system. In most latent models,
it takes the event space of latent variables and turns it into the target we want, such as images or audio. In brief, our
ultimate goal is to recover a subset of true distributions through our latent distribution together with a neural network,
such that the event space is compact and stays inside the event space of true distribution. One of the keys is how to
correctly map the conditional distribution. In terms of conditioning, information about either classes or features is
usually obtainable. Class information is usually mutually exclusive or disjoint, but features are not. For example, text
can be seen as some kind of feature information. We discover that using feature information instead of class will
significantly improve model performance. A theoretical explanation through set theory is given in the next subsection.
3.1
Real distribution and Latent Distribution
Conditioning mechanisms in neural networks are directly related to latent distribution. A change in latent distribution
could cause performance to be drastically different under the same model specifications. Classification information
shows significant improvement in model performance[48, 43, 34, 36, 5] even with synthetic labels[37].
Denote that the event space of data distribution is Sd and it is a subset of our real target distribution event space SR.
Data distribution may be conditional based on some rules, but it is not always necessary. The event space of the
data distribution could be just random samples. Consider we have latent variables SZ. If all the data is given class
information, which consists of M1 independent classes, we will split SZ into {SZm}m=1,2,...,M1. If a dataset is labeled
with features of size N, the situation becomes more complex. The dataset is not categorized into N features; instead,
it is split into fine sub-spaces, which are defined by the intersection of certain features. Assume there are M2 sets of
intersection subsets, and elements in each subset are {Zn,m}n∈N+,m=1,2,...,M2. In other words, latent event spaces for
features are as follows:
Z1,m ∩ Z2,m ∩ · · · ∩ Zn,m ∩ · · · = Z∗
m.
These defined spaces also imply that:
M2
[
1
SZ∗
m ⊆ SZ,
M1
[
1
SZm ⊆ SZ
Neural network is the objective function that takes latent space SZm, SZ∗
m to {SNN(Zm)}m=1,2,...,M1,
{SNN(Z∗
m)}m=1,2,...,M2. It is reasonable to assume that a neural network has some high-dimensional error ϵ. We can
define that SNN(•)+ϵ is a direct sum of two subsets:
SNN(•)+ϵ = SNN(•)+ϵ
R
⊕ SNN(•)+ϵ
D
,
where SNN(•)+ϵ
R
is the subset of generations that are considered within the event space in real distribution. SNN(•)+ϵ
D
is the subset of bad generation that is out of the real space. They satisfy
SNN(•)+ϵ
D
∩ SR = ∅
Assuming that the neural network is well trained, we obtain the following relationship:
Sd ⊂
M2
[
m=1
SNN(Z∗
m)+ϵ
R
⊆
M1
[
m=1
SNN(Zm)+ϵ
R
⊂ SR.
6
W.Lu et al.
Furthermore,
M1
[
m=1
SNN(Zm)+ϵ − SR =
M1
[
m=1
SNN(Zm)+ϵ
D
= SNN(Z)+ϵ
D
,
M2
[
m=1
SNN(Z∗
m)+ϵ − SR =
M2
[
m=1
SNN(Z∗
m)+ϵ
D
= SNN(Z∗)+ϵ
D
.
Given card(SZ∗) = card(SZ), cardinality of SNN(Z)+ϵ
D
and SNN(Z∗)+ϵ
D
have the following property:
card(SNN(Z∗)+ϵ
D
) ≤ card(SNN(Z)+ϵ
D
),
card(SNN(Z∗)+ϵ
R
)
card(SNN(Z∗)+ϵ) ≥ card(SNN(Z)+ϵ
R
)
card(SNN(Z)+ϵ)
(7)
The deduction above shows that there are fundamental differences in class and feature information. Fig.2 shows a
simple graphic explanation of Eq.(7). This mock example showcases a simple scenario with four classes and four
features. Red boxes represent the input domain of the neural network. Although each subset of Z∗
m is significantly
smaller than Zm, when the size of Z∗
m gets larger and larger, we can recover more and more event space from the real
distribution. Intuitively, generations’ quality is improved by limiting training within many refined subsets. Hence, based
on set theory, we conclude that the subset of defect generation with latent distribution and features is smaller or at least
equal to the subset of classes. In addition, the deduction above also provides an explanation of why GANs usually
report having mode-collapse. The latent variables of GAN usually normally distributed. Normal distributions are too
centred and possibly cause models to converge into a fine subset.
���(�1)+� = ��1
�ℛ
��
��(�1)+�
�ℛ
��(�1)+�
��1
�ℛ
��2
��3
��4
��
��(�1⋂�2)+�
�ℛ
��(�1⋂�2)+�
=���(�1⋂�2)+�
��
∪
(1) Classes
(2) Features
Inside Real Space
Outside Real Space
Inside Real Space
Outside Real Space
Total Space of ��(�1⋂�2) 
��
��2
��3
��4
Figure 2: Class space vs. Feature space
From the above analysis, it suggests that features are intrinsically distributional, which leads to our model assumption.
Let D(·) denote the distribution, the mathematical representation of our model assumption based on feature distribution
is as follows:
7
W.Lu et al.
Target = NN(Z) + ϵ, Z = (Z1, Z2, Z3, ...)T ,
Zi = Yi(Y i
1 , Y i
2 , Y i
3 , ...),
Y i
j = Qi
j(Qi,j
1 . . . ),
...
Ai,j,...
m
= X i,j,...
m
(Xi,j,...m
1
, . . . ),
Xi,j,... ∼ D(θi,j,...),
(8)
where Yi, Qi, . . . , Xi are functions.
The model assumption implies that if the lower-level features Xi,j,... is sampled from Gaussian, features of data
distribution need to be normally distributed. This not sensible intuitively. The model assumption also suggests a
hierarchical feature reconstruction that aligns with the fundamentals of neural networks. For demonstration purposes, a
simplify conceptual explanation of face generation with the CelebA dataset is as follows:
• Face ∼ NN(Z) and Z = (’Brown Hair’, ’Chubby’, ’Big Lips’, ’Arched Eyebrows’, . . . )T .
• ’Brown Hair’ ∼ D1(Y1).
• ’Chubby’ ∼ D2(Y2)
• ...
In a text-to-image model, text information naturally provides information about how we humans interpret images. In
other words, images are featured by text, and text is embedded as a variable in a neural network to control generation.
But under our assumption, each text (feature) is suggested to be distributed instead of a certain value. For example, if
input ’A human with glasses.’ is given to a language model, it will return a certain output because a neural network is a
certainty function. But intuitively, ’A human with glasses.’ represents a concept or a distribution, so to speak. If we
embed text with a fixed value, the latent variable is not recover the real distribution. The diffusion model does give latent
value to a Gaussian process to recover the data distribution, but it is a questionable assumption and counter-intuitive.
Image distribution of ’A human with glasses.’ may not be centered on any mean image. It is diverse, spread out, and
approximately with infinite variations.
Generally, the latent variables are the set of variables over which we have control. In auto-encoders and most of their’
variations, latent variables usually refer to the encoder output, also known as the bottleneck layer. An interesting
example is VQ-VAEs. It maps latent variables into a discrete set of values. It does reveal some interesting properties of
neural networks. If we try to apply a neural network for dimension reduction, the latent of this dimension is very likely
and not necessarily continuous. This finding motivates us to use GMM to embed latent variables. GMM can be seen as
a combination of discrete and continuous GMM not only has all of the properties of a normal distribution but also has
the properties of a discrete distribution. Our model assumption Eq.(8) suggests that instead of embedding text into a
fixed value, distribution is a preferable option. For n = 1, 2, . . . , N and k ∈ [1, K] ∩ N,
A = [A1, A2, . . . , AK]T
and
Ak =
1
if image has feature k
0
otherwise
.
Zk =


z1
.
.
.
zN

 ,
zn ∼ GMM(π, µ, σ).
(9)
Latent variable vector Z is defined as follows:
Z = [Z1A1, Z2A2, Z3A3, . . . , ZKAK].
8
W.Lu et al.
Under this setup, Z is following a conditional distribution by being given a set of features. The indicator function A
controls whether a feature is activated or deactivated. In practice, zns are sampled from the Gaussian mixture model and
assigned to pair with each data image to perform supervised learning. Studies show that the Gaussian mixture model
[29, 30] performs better than a single Gaussian. Unfortunately, we are not able to provide a mathematical explanation
for this matter. Intuitively, based on our model assumption Eq.(8), lower level features, for instance, hair length
[’Long’, ’Short’, ’Median’] are likely to be discretely distributed [46, 47] or distributed with continuous multi-modal
distribution. Classic GAN uses Gaussian, but under our assumption, Gaussian mixture is suggested. Eq.9 shows the
representation for each feature. There are 3 Gaussian components with uniform πs. Variance σ is a constant for all
Gaussian components and distance between µ is larger than σ. Takes the concept above, a diffusion model is presented
and trained with the CelebA [32] dataset.
3.2
Model Architecture
Compared with the text-to-image model, we do not apply the language encoder for the conditioning. Instead, we apply
our design of latent variables; Z directly controls the denosing process so that Z can be trained to recover a subset
of the real distribution. The uncertainty is given by the noising process as well as our latent distribution. Graphical
illustrations are given in Fig.1, 3, 4, 5. Fig.1 shows the comparison of real faces and faces generated by our model
through random samples from Z. Appendix A shows randomly generated images based on different conditional
distributions. It shows that our latent distributions are able to approximate a subset of the real distribution through the
diffusion model. Generations correctly match our conditioning features. Also, there are no generated images that are
clearly unrecognizable, and face features are well assembled.
U-net
Text Conditioning
Noise Image Input
Encoder
(Image)
Noise
Encoder
(Language)
Text Input
Noise
GMM Random Sample
ℤ = [�1�1, �2�2, …, �40�40]
Noise Image Input
Proposed GMM Conditioning
Encoder
U-net
Figure 3: Diffusion Model Architecture Comparison
By our design, neural network becomes a uncertain model which we can assemble images taking random features from
both latent distribution and denosing process. This is demonstrated in Fig.4, 5. When generating images from specific
feature categories, we randomly samples the conditional Z. Each image is assigned with a fix latent sample from the
conditional distribution. When a certain latent value of Z is given, we can generate a set of samples close to target
images but with fine detail variations. Examples are shown in Fig.5. The generations are in very subtle detail variations
such as hair texture, earring, skin color, etc. They are akin to Gaussian distribution with a mean and small variance.
9
W.Lu et al.
Fine Feature
Variation:
Hair texture
Earring,
Eye size,
Skin tone,
…
Images Generated From GMM Samples
ℤ ～
(Uncertain)
Noise Input
(Uncertain)
(Uncertain)
Distribution{
Faces| 
Arched Eyebrows, 
Attractive, 
Brown Hair, Heavy 
Makeup, 
High Cheekbones, 
Smiling, 
Young,…}
Random Sample
Faces| 
Arched Eyebrows, 
Attractive, 
Brown Hair, 
Heavy Makeup, 
High Cheekbones, 
Smiling,
Young,…
Figure 4: Faces generation from conditional feature distribution
In our experiments, a simple strategy for forward diffusion process as well as denoising process is applied. For Gaussian
noise β1, β2, . . . we using the notation follow [2]
αt = 1 − βt,
αt :=
tY
s=1
αs,
For ϵ ∼ ϕ(0, I),
xt = √αtx0 +
p
(1 − αt)ϵ.
Sampling process in [2] is given by following equation:
xt−1 =
1
√αt

xt − 1 − αt
√1 − αt
ϵθ (xt, t)

+ σtz,
where z ∼ ϕ(0, I). Denoising process is taking the same path that we use in training Eq.(10) which we calculate x0 at
every steps and noise up to xt−1 autoregressively.
x∗
0 = xt −
p
(1 − α)ϵθ (xt, t)
√
α
,
xt−1 =
√
αx∗
0 +
p
(1 − α)ϵ
(10)
Fig.6 shows the generating result at each steps. Total steps of forward diffusion process in our experiment for CelebA is
100. Backward autoregressive denosing process is start at a step 100 with complete Gaussian noise. It shows that our
model quickly find our target images and making detail refinement at each sampling steps. The predicted x∗
0 from steps
80-100 reach similar generation quality. We apply the same simple loss function for model training[2, 12].
Lsimple(θ) := Et,x0,ϵ
h
∥ ϵ − ϵθ(
√
αx0 +
p
(1 − α)ϵ, t) ∥
i
10
W.Lu et al.
Fine Feature 
Variations:
Hair texture,
Earring,
Eye size,
Skin tone,
…
Distribution{
 }
ℤ
Assigned 
(Certain)
Noise Input
(Uncertain)
(Uncertain)
Diffusion Process
Figure 5: Faces generation from a certain value of conditional feature distribution
3.3
Conditioning on features vs. Conditioning on classes
Through the analysis based on set theory, the addressed issue of features and classes also needed to be experimentally
tested. Cifar10[33] is used to train the diffusion model to carry out the experimental comparison. Fig.7 shows our
results and model specifications. With similar model sizes and the same training method, the model trained on Cifar
clearly underperformed the model trained on CelebA. Lost from Cifar10 is also larger than CelebA. The only difference
between these two models is our latent distributions. Latent distributions of CelabA consist of features defined by the
intersection of smaller subsets. In contrast, Cifar10 only provides independent class information, so latent spaces are
disjoint from each other. Orange square boxes in Fig.7 are original images, and other subplots are image reconstruction
by diffusion model. Noting that the model trained on CelebA is built with fewer parameters and fewer diffusion steps.
The diffusion model output for CelebA has a higher image dimension of 64x64x3 compared to 32x32x3 in Cifar10. In
summary, latent distribution built by features shows a capability that uses less but produces more.
One additional variation also carried out in our experiment. A classifier is introduced in the diffusion model. From our
past experiments, binding a classification network to a generative model usually brings benefits to the network, especially
in latent space. Models such as GANs make heavy use of classification to gain model performance [48, 43, 34, 36, 37].
Dhariwal et al.[5] introduce two classifier guide sampling techniques in their diffusion model. For these reasons,
classifiers are introduced in the bottleneck later in our diffusion model.
Fig.8 shows our model architecture with classifier. By taking the same approach in our GMM conditioning diffusion
model, a classifier is introduced after the encoding process. Fig.9 shows our average training loss through out the
training process. Orange line is trained without classifier, and blue line is trained with classifier. Models are both
trained in total 200 thousand steps with batch size 16. The diffusion model with classifier has lower loss and converge
faster than the model without classifier. Our experiment shows that with a additional classifier, training is more stable.
Additionally, in terms of classifier training, instead of binary cross entropy, we purposed a novel distance function to
train this classifier called Negative Gaussian Mixture Gradient(NGMG).
4
Negative Gaussian Mixture Gradient (NGMG)
NGMG is inspired by the Wasserstein distance, the Gaussian kernel, and some concepts in physics, such as gravitational
force. In the physical world, while moving earth from A to B, earth has to travel in space and time between A and B,
11
W.Lu et al.
�0
∗  at sampling steps :1-10
�0
∗  at sampling steps :50-60
�0
∗  at sampling steps :80-100
Figure 6: x∗
0 at each sampling step
and the cost is more than just the difference; it also involves the cost of time and travel distance. For two distributions A
and B, likelihood-based functions such as KL-divergence and Jensen-Shannon divergence can be applied to move A
to B. But these learning processes do not travel in space. For example, if A and B are two categorical distributions
with [π1, ...π9]. When we move a certain proportion from π1 to π9, this moving action does not travel any distance
in between. One of the key assumptions of NGMG is that the moving object has a physical position. Based on the
distance, we assume that each position has a certain correlation to other positions. Based on these assumptions, a
modified Gaussian kernel is applied to define a covariance matrix. Finally, by pairing it with the Gaussian mixture
model, we obtain a function that can be applied as a gradient function.
4.1
Methodology
Let’s start by specifying our notations and problems.
• π: π = [π1, π2, ...πn] is the vector, which represents the earth in the moving problem and probability in
distribution. π(1)
i
= [π(1)
1 , π(1)
2 , ...π(1)
n ] is the distribution we starting with and π(2)
i
= [π(2)
1 , π(2)
2 , ...π(2)
n ] is
the target distribution.
• For most distribution, GMM expansion method which shows in Section 2.2 can be applied to approximate it
with a set of {πi}.
• µ, σ, ϕn(x) are set-up by GMM expansion in Eq.(1). Each πi is assigned a µi which gives the object a distance.
Each µi is assigned a ϕi which is applied to calculate a modified Gaussian kernel covariance matrix.
Define a function L = π(1) − π(2) and only take the negative value of the function.
Li =
(
π(1)
i
− π(2)
i
π(1)
i
− π(2)
i
< 0
0
π(1)
i
− π(2)
i
≥ 0 .
(11)
Because
X
i
πi = 1,
MIN(π(1)) − MAX(π(2)) = −1,
(12)
12
W.Lu et al.
Cifar10: Condition on Categories
Image Size: 32x32x3
Parameters: 70Millions
Train Steps: 400,000
Batch Size: 16 
Diffusion Steps T: 1000
�: Linear
CelebA: Condition on Features
Image Size: 64x64x3
Parameters: 60Millions
Train Steps: 400,000
Batch Size: 16 
Diffusion Steps T: 100
�: Constant
Figure 7: Features vs.Classes
we have
−1 ≤
n
X
i=1
Li ≤ 0.
The NGMG for πj is:
ngmg(π(1)
j , π(2)
j ) =
n
X
i̸=j
Liϕi(µj; µi, σ), i ̸= j
(13)
where i = 1, 2, 3...n, and i ̸= j, σ is a hyperparameter. Rewrite Eq.(13) as matrix multiplication:
M =


0
ϕ2(µ1; µ2, σ)
ϕ3(µ1; µ3, σ)
...ϕn(µ1; µn, σ)
ϕ1(µ2; µ1, σ)
0
ϕ3(µ2; µ3, σ)
...ϕn(µ2; µn, σ)
.
.
.
.
.
.
.
.
.
.
.
.
ϕ1(µn; µ1, σ)
ϕ2(µn; µ2, σ)
ϕ3(µn; µ3, σ)
...0


,
NGMG(L) = −ML
(14)
where L is the vector of Li. M (σ) is a Gaussian kernel with diagonal entries set to be zeros. Setting diagonal entries to
zeros because we want the gradient of πi does not depend on Li. The essence of Eq.(14) is energy and gravitation. Li
is the value of the energy at position i and spread out by a Guassian kernel. This energy is negative and attracts other
positive value to fill in. σ controls how far the Li could affect. At each position i, it moves (gradient) based on the sum
of all negative energy generated by other positions and is not affected by its’ own. When all negative energy is filled, no
gradient will be produced. This gradient function is bounded by:
sup(NGMG(L)) = 0,
inf(NGMG(L)) = −1.0 ∗ max(ϕ(µj; µi, σ)),
13
W.Lu et al.
Noise
Image
Encoder
Decoder
Noise
Classifier
MSE Loss
Classes
Negative GMM Gradient
GMM Random Sample
ℤ = [�1�1, �2�2…�40�40]
U-net
Figure 8: Proposed model with with Classifier
Fig.10 gives a stepwise demonstration to Eq.(14). Subplot (1) is the graph of π(1)
i
− π(2)
i
and subplot (2) is the graph
taking only the negative part of (π(1)
i
−π(2)
i
)−, Eq.(11). By assigning each π a Gaussian distribution, a mixture negative
mixture density like function is produce which shows in subplot(4). Our method utilize this negative mixture density
like function as a kernel function smooth function L and gives the gradient for each π.
4.2
NGMG and Wasserstein Distance
Arjovsky et al. [44] shows that Wasserstein distance in terms of cost function provides better stability and is more
sensible for training, especially in neural networks. NGMG is not a likelihood-based function by design. It is close to
the Wasserstein distance and shares similar qualities in terms of cost function. In [44], They have proven the Wasserstein
distance is more sensible than JS, KL, and TV in several aspects. In this work, we shows that Wasserstein distance can
be structured by NGMG and NGMG share the same benefit in terms of cost function. Noticing that In Section 2.3, we
have shown that under our GMM expansion system, any distribution g is approximated by a categorical distribution.
Let πθ, π(2) be the categorical distribution of

πθ
i
	
i∈N and
n
π(2)
i
o
i∈N respectively.
The following statements are proven in [44]:
1. By the bounded convergence theorem, | W1(πθ, π(2)) − W1(πθ′, π(2)) |≤ W1(πθ, πθ′) ≤ L(θ) ∥ θ −
θ′ ∥→θ→θ′ 0
2. if πθ is locally Lipschitz and the expectation of Lipschitz constant Lipz(θ, z) over θ and z is less than infinity,
Ez∼p[L(θ, z)] < +∞, W(Pπθ, Pπ(2)) is continuous everywhere and differentiable almost everywhere.
3. Statements 1-2 are false for the Jensen-Shannon divergence and all the KLs.
4. The following statements are equivalent
• δ(πθ, π(2)) → 0 with δ the total variation distance.
• JS(πθ, π(2)) → 0 with JS the Jensen-Shannon divergence.
5. The following statements are equivalent
14
W.Lu et al.
Figure 9: Training with and without classifier
• W(πθ, π(2)) → 0.
• πθ → π(2) where → represents convergence in variables.
6. KL(πθ||π(2)) → 0 or KL(π(2)||πθ) → 0 imply the statements in 4.
7. The statements in 5 imply the statements in 4.
The statements 1–3 show how Wasserstein distance is more sensible than JS, TV, and KLs in terms of differentiable
and continuity. According to the definition of NGMG, NGMG is continuous everywhere and differentiable almost
everywhere. Because NGMG Eq.(14) is a vector of linear transformation of (πθ − π(2))− and all elements in the vector
are strictly positive, so that ∥ ML(πθ, π(2)) ∥ − ∥ ML(πθ′, π(2)) ∥=∥ ML(πθ, πθ′) ∥. It proves that:
|∥ NGMG(L(πθ, π(2))) ∥ − ∥ NGMG(L(πθ′, π(2))) ∥|=∥ NGMG(L(πθ, πθ′)) ∥≤ Lipz(θ, z) ∥ θ − θ′ ∥,
The statement 4–7 shows the convergence in JS, TV, and KLs, which implies the convergence of the Wasserstein
distance. NGMG has a strong connection with the Wassersetein distance. The convergence of the Wasserstein distance
also implies the convergence of NGMG and vice versa. NGMG is a linear function related to Wasserstein distance,
which has the following representations:
W1(πθ, π(2)) =|∥ FM −1NGMG(L+(πθ, π(2))) ∥1 − ∥ FM −1NGMG(L−(πθ, π(2))) ∥1|
(15)
Proof Eq.(15). Based on Eq.(6), we have:
−→
W1(πθ, π(2))+ = FB · (πθ − π(2)), −→
W1(πθ, π(2))− = F(1 − B) · (πθ − π(2))
Let: L+(πθ, π(2)) = −B · (πθ − π(2)), L−(πθ, π(2)) = (1 − B) · (πθ − π(2))
−→
W1(πθ, π(2))+ = FM −1NGMG(L+(πθ, π(2)))), −→
W1(πθ, π(2))− = FM −1NGMG(L−(πθ, π(2)))),
Together with Eq.(6), we prove Eq.(15).
The following statements can be proved equivalent:
(a) W(πθ, π(2)) → 0.
(b) ∥ NGMG(πθ, π(2)) ∥→ 0.
15
W.Lu et al.
(1)
(2)
(3)
(4)
Figure 10: Negative Gaussian Mixture Gradient(NGMG)
Proof. (a) to (b). If ∥ NGMG(L−(πθ, π(2))) ∥→ 0,
n
X
j
| ngmg(πθ
j , π(2)
j ) |= 0.
And because | ngmg(πθ
j , π(2)
j ) |≥ 0, for all j,
πθ
j − π(2)
j
= 0,
W(πθ, π(2)) = 0.
Vice versa for
∥ NGMG(L+(πθ, π(2))) ∥→ 0.
Proof. (b) to (a). If W(πθ, π(2)) → 0, from Jensen Inequality:
W(πθ, π(2)) =
Z
M
|
N
X
n=1
(πθ
n − π(2)
n )Fn(x) | dx
≥|
N
X
n=1
(πθ
n − π(2)
n )
Z
M
Fn(x)dx |= 0.
Based on GMM expansion setting
Z
M
Fn(x)dx = An, A1 > A2 > A3.... > 0.
We have
πθ
n − π(2)
n
= 0,
n ∈ [1, N],
and
NGMG(L−(πθ
n, π(2)
n )) = NGMG(L+(πθ
n, π(2)
n )) = 0.
16
W.Lu et al.
We can come to the following conclusion: We can find that NGMG has the same properties of Wasserstein distance,
which is continuous and differentiable almost everywhere under the same assumption provided in statement 2. On
the assumption that KL divergence, Total Variation (TV) distances,JS distances, and Wasserstein distances converge,
NGMG likewise converges. Both NGMG and Wasserstein distances are sensitive cost functions to achieve convergence
in low-dimensional manifold cases where KL divergence, Total-Variation (TV) distances, and JS distances are not
sensitive.
4.3
Numerical Experiments
We run various experiments to test our method of learning. The first experiment is learning to move distribution A to B.
The second one is a direct comparison with binary cross-entropy in neural network training.
4.3.1
Learning Density
Moving between the two distributions involves parametrization. If A is a Gaussian distribution but B is not, no matter
how hard we try, we cannot perfectly move A to B because the geometry of A is limited. In our solution, density is
approximated by a mixture Gaussian with fixed means and variances. Section 2.3 shows that the Wasserstein distance
of any two distributions under Gaussian mixture expansion is Eq.(5). In this case, parametrization of our model only
related πs and NGMG is applied to move pis.
Algorithm 1: Simple Learning Algorithm
Requires: σ, {µi}N
i=1, ϵ, Use Gaussian mixture expansion method find π.
Initialise: bπ
While L > ϵ do
1.Calculate L(π, bπ)
2.Calculate NGMG(L, σ)
3.Update bπ = bπ − NGMG(L, bπ, σ)
4.Normalisebπ.
return bπ
Figure 11: Learning two distribution
17
W.Lu et al.
Fig.11 shows the learning process by NGMG. Orange curve is the target πs and blue curve is bπ. After 10 steps, bπ
already relatively close to πs. Because L function becomes smaller and smaller, the learning process in the latter steps
moves less aggressively.
4.3.2
Learning in Neural Network
NGMG is a function provide a gradient for learning. In above density learning experiment, normalisation is applied to
ensure the probability condition so that the sum of πs are one. But in neural network, normalisation for each training
steps is not a option. Instead of training with binary cross entropy, we introduce negative Gaussian mixture gradient
entropy.
Shannon entropy:
H(x) = −
X
x∈X
p(x)ln(p(x)).
(16)
State of art method training categorical distribution for classification is binary cross entropy:
H(x) = − 1
N
N
X
i
(yiln(p(yi)) + (1 − yi)ln(1 − p(yi))).
(17)
Negative Gaussian mixture gradient entropy:
H(x) = − 1
N
N
X
i
NGMG(L(pi, pθ(xi)), σ) · ln(pθ(xi)).
(18)
Figure 12: NGMG Entropy vs. BCE
In this experiment, a simple neural network with single input is tested to fit the feature attributes of the CelebA dataset.
In Fig.12, it shows a direct sum of square error between prediction probability and feature attributes in batch on test
dataset. Blue line is the performance of NGMG entropy and the orange line is the performance of binary cross entropy.
NGMG entropy clearly shows better performance than binary-cross entropy.
18
W.Lu et al.
5
Conclusions
We have presented a distributional conditioning mechanism that the event space of latent distribution is trained to
recover a subset of real event space. Gaussian mixture model is used to construct the latent distribution. Diffusion
model is trained on CelebA to demonstrate this conditioning mechanism. Our generations results show promising for
further development. Condition on feature or class can have seriously effect model performance. We theoretically and
experimentally shows that model condition on feature will produce less defected generations than class. Additionally, a
novel distance function Negative Gaussian Mixture Gradient is proposed and theoretically shows our method share the
same benefit as Wasserstein distance. It is more sensible than KL-divergence, Jensen-Shannon divergence, and Total
Variation when learning distributions supported by low dimensional manifolds. Our experiments could demonstrate
favorable results compared to binary-cross entropy.
19
W.Lu et al.
A
Sheets Of Samples
Figure 13: Random samples condition on: Bushy Eyebrows, Male, Pointy Nose, Straight Hair, Young, Attractive...
Figure 14: Random samples condition on: 5 o’Clock Shadow, Arched Eyebrows, Bags Under Eyes, Male, Black Hair. . .
Figure 15: Random samples condition on: Arched Eyebrows, Attractive, Bangs, Big Lips, Heavy Makeup, High
Cheekbones, ...
20
W.Lu et al.
Figure 16: Random samples condition on: Arched Eyebrows, Attractive, Brown Hair, Heavy Makeup, Smiling, Young
. . .
References
[1] Sohl-Dickstein J., Weiss E., Maheswaranathan N., Ganguli S., Deep unsupervised learning using nonequilibrium
thermodynamics. International conference on machine learning, pp.2256-2265 PMLR. 2015.
[2] Ho J., Jain A., Abbeel P., Denoising diffusion probabilistic models. NeurIPS, 2020.
[3] Chen N., Zhang Y., Zen H., Weiss R., Norouzi M., Chan W., Wavegrad: Estimating gradients for waveform
generation. ICLR, 2021, OpenReview.net.
[4] Kingma D., Salimans T., Poole B., Ho J., Variational diffusion models. CoRR, abs/2107.00630, 2021.
[5]
Dhariwal P., Nichol A., Diffusion models beat gans on image synthesis, Advances in neural information
processing systems,34 , pp.8780-8794, 2021.
[6] Ho, J., Saharia, C., Chan, W., Fleet, D.J., Norouzi, M. and Salimans, T., Cascaded diffusion models for high
fidelity image generation. The Journal of Machine Learning Research, 23(1), pp.2249-2281, 2022.
[7] Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D.J. and Norouzi, M., Image super-resolution via iterative
refinement. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(4), pp.4713-4726, 2022.
[8] Song Y., Ermon S., Generative modeling by estimating gradients of the data distribution. Advances in neural
information processing systems, 32, 2019.
[9] Nichol AQ, Dhariwal P., Improved denoising diffusion probabilistic models. International Conference on Machine
Learning, PMLR, pp.8162-8171, 2021.
[10]
Song Y, Ermon S., Improved techniques for training score-based generative models. Advances in neural
information processing systems, 33, pp.12438-12448, 2020.
[11] Song, Y., Sohl-Dickstein, J., Kingma, D.P., Kumar, A., Ermon, S. and Poole, B., Score-based generative modeling
through stochastic differential equations. arXiv preprint arXiv:2011.13456., 2020.
[12] Rombach R, Blattmann A, Lorenz D, Esser P, Ommer B., High-resolution image synthesis with latent diffusion
models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684-
10695. 2022.
[13] Kong, Z., Ping, W., Huang, J., Zhao, K. and Catanzaro, B., Diffwave: A versatile diffusion model for audio
synthesis. arXiv preprint arXiv:2009.09761, 2020.
[14] Mittal, G., Engel, J., Hawthorne, C. and Simon, I., Symbolic music generation with diffusion models. arXiv
preprint arXiv:2103.16091, 2021.
[15] Ronneberger, O., Fischer, P. and Brox, T., U-net: Convolutional networks for biomedical image segmentation. In
Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference,
pp. 234-241, Springer International Publishing, 2015.
[16] Kingma D., Welling M., Auto-encoding variational bayes in 2nd international conference on learning representa-
tions, ICLR., 2014.
[17] C. Améndola, M. Drton, B. Sturmfels, Maximum likelihood estimates for Gaussian mixtures are transcendental,
MACIS., (2015), 579–590.
21
W.Lu et al.
[18] R. Abbi, E. El-Darzi, C. Vasilakis, P. Millard, Analysis of stopping criteria for the EM algorithm in the context of
patient grouping according to length of stay, IEEE Intell Syst., 1(2008), 3-9.
[19] C. Biernackia, G. Celeuxb, G. Govaertc, Choosing starting values for the EM algorithm for getting the highest
likelihood in multivariate Gaussian mixture models, Comput. Stat. Data. Anal., 41(2003), 561-575.
[20] J. Blömer, K. Bujna, Simple methods for initializing the em algorithm for Gaussian mixture models, CoRR.,
2013.
[21] J. Chi, Y. Zhang, S. Balakrishnan, M. Wainwright, M. Jordan, Local maxima in the likelihood of Gaussian mixture
models: Structural results and algorithmic consequences, NIPS., 29(2016).
[22] G. Kontaxakis, G. Tzanakos, Study of the convergence properties of the EM algorithm-a new stopping rule, IEEE
NSS/MIC., (1992), 1163-1165.
[23] G. Kontaxakis, G. Tzanakos, Further study of a stopping rule for the EM algorithm, NEBEC., (1993), 52-53.
[24] W. Kwedlo, A new method for random initialization of the EM algorithm for multivariate Gaussian mixture
learning, CORES., (2013), 81-90.
[25] P. McKenzie, M. Alder, Initializing the EM algorithm for use in Gaussian mixture modelling, Pattern Recognit.,
(1994), pp. 91-105.
[26] P. Paclík, J. Novoviˇcová, A new method for random initialization of the EM algorithm for multivariate Gaussian
mixture learning, ANNs/GAs, (2001), pp. 406-409.
[27] E. Shireman, D. Steinley, M. Brusco, Examining the effect of initialization strategies on the performance of
Gaussian mixture modeling, Behav. Res. Methods., 49(2017), 1:282-293.
[28] N. Srebro, Are there local maxima in the infinite-sample likelihood of Gaussian mixture estimation?, COLT.,
(2007), 628–629.
[29] Lu W., Ding D., Wu F.,Yuan G., An efficient Gaussian mixture model and its application to neural network.
Preprint:202302.0275.v2, 2023.
[30] Lu W., Wu X., Ding D., Yuan G., An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And
Gaussian Mixture Embedding For Neural Network. arXiv preprint arXiv:2308.09444, 2023.
[31] Devlin J., Chang M., Lee K., Toutanova K., BERT: pre-training of deep bidirec- tional transformers for language
understanding. In Proceedings of naacL-HLT (Vol. 1, p. 2)., 2019.
[32] Liu, Z., Luo P., and Wang X.; Tang, X., Deep Learning Face Attributes in the Wild. Proceedings of International
Conference on Computer Vision (ICCV), 2015.
[33] Krizhevsky, A. and Hinton, G., Learning multiple layers of features from tiny images. 2009.
[34]
Dumoulin, V., Shlens, J. and Kudlur, M.,
A learned representation for artistic style.
arXiv preprint
arXiv:1610.07629., 2017.
[35] De Vries, H., Strub, F., Mary, J., Larochelle, H., Pietquin, O. and Courville, A.C., Modulating early visual
processing by language. Advances in Neural Information Processing Systems, 30., 2017.
[36] Miyato, T. and Koyama, M., cGANs with projection discriminator. arXiv preprint arXiv:1802.05637., 2018.
[37] Lucic, M., Tschannen, M., Ritter, M., Zhai, X., Bachem, O. and Gelly, S., High-fidelity image generation with
fewer labels. In International conference on machine learning (pp. 4183-4192). PMLR., 2019.
[38] Dash, A., Gamboa, J.C.B., Ahmed, S., Liwicki, M. and Afzal, M.Z., Tac-gan-text conditioned auxiliary classifier
generative adversarial network. arXiv preprint arXiv:1703.06412., 2017.
[39] Lang, O., Gandelsman, Y., Yarom, M., Wald, Y., Elidan, G., Hassidim, A., Freeman, W.T., Isola, P., Globerson, A.,
Irani, M. and Mosseri, I., Explaining in style: Training a gan to explain a classifier in stylespace. In Proceedings
of the IEEE/CVF International Conference on Computer Vision (pp. 693-702)., 2021.
[40] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative
adversarial networks, ACM 63 11:139-144, 2020, .
[41] Wu, Y., Donahue, J., Balduzzi, D., Simonyan, K. and Lillicrap, T., Logan: Latent optimisation for generative
adversarial networks. arXiv preprint arXiv:1912.00953., 2019
[42] Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J. and Aila, T., Analyzing and improving the image
quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp.
8110-8119)., 2020
[43] Brock, A., Donahue, J. and Simonyan, K., Large scale GAN training for high fidelity natural image synthesis.
arXiv preprint arXiv:1809.11096., 2018
22
W.Lu et al.
[44]
Arjovsky, M., Chintala, S. and Bottou, L., Wasserstein generative adversarial networks. In International
conference on machine learning (pp. 214-223). PMLR., 2017
[45] Arjovsky, M. and Bottou, L., Towards principled methods for training generative adversarial networks. arXiv
preprint arXiv:1701.04862., 2017
[46] A. Razavi, A. Van den Oord, O. Vinyals, Generating diverse high-fidelity images with vq-vae-2, Adv. Neural Inf.
Process. Syst. 32, 2019.
[47] Van Den Oord, A. and Vinyals, O., Neural discrete representation learning. Advances in neural information
processing systems, 30., 2017.
[48] Mirza, M. and Osindero, S., Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784., 2014.
[49] Villani, C., Optimal transport: old and new. Berlin: springer., 2009.
[50]
Nachmani, E., Roman, R.S. and Wolf, L.,
Non gaussian denoising diffusion models.
arXiv preprint
arXiv:2106.07582., 2021.
[51] Kolouri, S., Rohde, G.K. and Hoffmann, H., Sliced wasserstein distance for learning gaussian mixture models. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 3427-3436)., 2018.
23
","nanLatent diffusion models train an autoencoder that produces a lower-dimensional latent space to reconstruct data space. Various image-to-image, text-to-image, and token-based conditioning mechanisms can be applied to latent diffusion models. In the context of text-to-image tasks, text information is tokenized and used as conditional input. This process, however, assumes that sentences have time information, which is not always the case. In contrast, features are direct reflections of concepts and do not have specific angle or posture information. For example, 'smiling' represents a concept constructed by almost infinite variations with different conditional scenarios. Hence, features are more appropriately considered as distributions rather than fixed values. Motivated by this idea, this work proposes a variation of the token-based conditioning mechanism using a Gaussian mixture model to represent this distributional conditioning mechanism."
"Prototype-based clustering algorithms are initialized with random centroid points for clustering and this random selection of centroids can lead to slower convergence times. Quantum annealing can provide a solution to these problems by mapping the initial centroid problem to an Ising Hamiltonian where the lowest energy in the spectrum correlates to a valid, but better solution. This research paper proposes Adaptive Quantum Optimized Centroid Initialization (AQOCI), a modification of QOCI, to address several limitations in QOCI.","Clustering algorithms group related data for classification and other purposes. Prototype-based clustering, a specific type of clustering algorithm, relies on creating a prototype of what a cluster could look like. Traditionally, these prototype-based clustering algorithms initialize with random centroids, which can be detrimental and computationally expensive. This paper explores how to utilize quantum computing, specifically quantum annealing, to compute better centroids before the clustering algorithm begins, potentially leading to performance gains.","The proposed approach, Adaptive Quantum Optimized Centroid Initialization (AQOCI), is an attempt to address the shortcomings of QOCI. AQOCI allows results to be interpreted in R2, accommodates larger sample sizes, and utilizes an adaptive and iterative approach inspired by iterative methods for solving linear equations. A quadratic unconstrained binary optimization (QUBO) formulation is utilized and scaled to represent real values, allowing for more precise centroid determination. The paper also reviews cluster analysis metrics such as inertia, silhouette score, homogeneity, completeness, and v-measure.","The paper presents experimental results using AQOCI in comparison with classical techniques and QOCI. The experiments utilize random Gaussian blobs and random samples from a malware research data set known as MOTIF. The evaluation metrics include inertia, silhouette score, homogeneity, completeness, v-measure, and the number of iterations required for k-means convergence. The results demonstrate that AQOCI outperforms random centroid selection and QOCI in terms of cluster quality, often producing higher silhouette scores, homogeneity, completeness, and v-measure values. AQOCI also reduces the number of iterations required for k-means to converge, indicating faster convergence times.","The paper concludes that AQOCI is an effective approach for determining better initial centroids for prototype-based clusters, potentially leading to improved cluster quality and faster convergence times. It emphasizes the ongoing evolution of quantum computing and the importance of re-evaluating existing methods to identify new opportunities for improvement.",Adaptive Quantum Optimized Centroid Initialization,"Nicholas R. Allgood, Ajinkya Borle, Charles K. Nicholas","Submitted to:
QPL 2024
© Allgood, Borle, and Nicholas
This work is licensed under the
Creative Commons Attribution License.
Adaptive Quantum Optimized Centroid Initialization
Nicholas R. Allgood
University of Maryland Baltimore County
Baltimore, Maryland USA
allgood1@umbc.edu
Ajinkya Borle
University of Maryland Baltimore County
Baltimore, Maryland USA
aborle1@umbc.edu
Charles K. Nicholas
University of Maryland Baltimore County
Baltimore, Maryland USA
nicholas@umbc.edu
One of the major benefits of quantum computing is the potential to resolve complex computational
problems faster than can be done by classical methods. There are many prototype-based clustering
methods in use today, and selection of the starting nodes for the center points is often done randomly.
For prototype-based clustering algorithms, this could lead to much slower convergence times. One
of the causes of this may be prototype-based clustering accepting a local minima as a valid solution
when there are possibly better solutions. Quantum computing, specifically quantum annealing, of-
fers a solution to these problems by mapping the initial centroid problem to an Ising Hamiltonian
where over time the lowest energy in the spectrum correlates to a valid, but better solution. A first
approach to this problem utilizing quantum annealing was known as Quantum Optimized Centroid
Initialization (QOCI), but this approach has some limitations both in results and performance. We
will present a modification of QOCI known as Adaptive Quantum Optimized Centroid Initialization
(AQOCI) which addresses many of the limitations in QOCI. The results presented are comparable
to those obtained using classical techniques as well as being superior to those results found using
QOCI.
1
Introduction
Cluster analysis is the study of grouping related data together for classification and other purposes.
There are many types of algorithms to cluster data, but we will be specifically focusing on prototype-
based clustering. Prototype-based clustering relies on creating a prototype of what a cluster could look
like, and then proceeding to converge until a final cluster is created. All clustering algorithms must
start from somewhere, and one of the key differences in prototype-based clustering is they start from a
given center point or centroid and proceed to cluster and update the centroid and the surrounding data
incrementally. Well-known clustering algorithms such as k-means and k-medoids are prototype-based
clustering algorithms and have been used with great success across multiple domains. In a detailed lit-
erature review on prototype-based clustering we have found that the largest majority of these algorithms
are initialized with a random centroid. Sometimes a random centroid can be ideal but other times it is
detrimental to the performance and accuracy of the clustering algorithm. To get the best and most accu-
rate groups of related data, we must have accurate center points to formulate a cluster, whether it be a
computed mean or a sample from the data. Many clustering methods employ an iterative verification of
the selected center point to confirm it is the best candidate to be the centroid. [10]
We could perhaps save some computational overhead if we begin the clustering algorithm with the
better possible centroids computed prior to forming the cluster. In classical cases, this would be computa-
tionally expensive, more so than using a random process to select the starting nodes. With a superposition
arXiv:2401.11258v1  [quant-ph]  20 Jan 2024
2
Adaptive Quantum Optimized Centroid Initialization
of states in a quantum computer, we could offload this computationally expensive procedure to calculate
a better set of centroids. One hidden benefit is that even if a performance increase is not gained, knowing
that our computation is in the ground energy state we avoid being stuck in a local minima.
Outline of the paper We will first review the related work to provide a brief foundation of cluster
analysis and quantum annealing. We then discuss the authors’ previous work and touch on its advantages
and disadvantages. Next we will introduce our contribution based off of QOCI, known as AQOCI, and
explore how it addresses the disadvantages of QOCI. We then show our empirical results with both
simulation of AQOCI as well as running the formulation on the D-Wave Hybrid BQM solver. In the final
section we summarize our findings and offer thoughts for improvement.
1.1
Cluster Analysis Metrics
Inertia:
Sum of squared errors that pertains to the cluster. One generally wants this value to be as low
possible.
Silhouette Score:
Also known as the Silhouette Coefficient, a metric used to calculate the qualify of a
clustering algorithm. Uses values ranged from −1 to +1.
Homogeneity:
Used to measure how similar each of the samples are in a cluster. Uses values −1 to 1.
Completeness:
Measures how similar samples are placed together by the clustering algorithm. Uses
values −1 to 1.
V-Measure:
Also known as the Normalised Mutual Information Score, is the average of homogeneity
and completeness scores.
2
Related Work
Cluster analysis is a class of algorithms that group a set of related objects together where items are
closer together the more strongly they are related. These groups are formally known as clusters and there
are a wide variety of metrics that can be used to determine object similarity. Cluster analysis is widely
used in many domains for a variety of uses such as classification and machine learning.
2.1
K-Means
k-means clustering is a prototype-based clustering algorithm that is widely used and researched
where n observations are partitioned into k clusters where each observation belongs the cluster with
the closest mean. Prototype-based clustering all start with a center point known as the centroid and k-
means this is the mean of the entire grouping of data. This centroid is used and updated as the k-means
algorithm converges and the initial centroid of all clusters are random. The n partitions are partitioned
in such a way that the variance inside of each cluster is minimized. By default, k-means uses squared
Euclidean distances in lieu of non-squared Euclidean distances.
Allgood, Borle, and Nicholas
3
While there are many variants and formulations of k-means, we will be discussing only the standard
version known as naive k-means. Mathematically, k-means is defined as follows: given a set of observa-
tions (x1, x2, ..., xn), we partition the n observations into k ≤ n sets S = {S1,S2,...,Sk} so to minimize the
variance within each of the sets Si. Formally:
min
s
k
∑
i=1 ∑
x∈Si
||x− µi||2 = min
s
k
∑
i=1
|Si|Var(Si)
(1)
where µi is the mean of the points in Si.
The full algorithm consists of three pieces, namely initialization, assignment, and update.
1. Initialization
Let us randomly choose k observations from our data sets and use these as our initial centroids
m(1)
1 ,...,m(1)
k
2. Assignment Given our initial centroids m(1)
1 ,...,m(1)
k , assign each observation to the cluster with
the nearest centroid in terms of least squared Euclidean distance.
S(t)
i
=

xp : ||xp −m(t)
i ||2 ≤ ||xp −m(t)
j ||2 ∀ j,1 ≤ j,≤ k
	
,
(2)
where every xp is assigned to exactly one S(t), even when the possibility of being assigned to
multiple S(t) exists.
3. Update
This step recalculates the centroids (means) for observations to each cluster:
m(t+1)
i
=
1
|S(t)
i | ∑
x j∈S(t)
i xj
(3)
The algorithm has fully converged when the assignments no longer change. While there are variants
that address this, one major shortcoming of naive k-means is there is no guarantee of finding a global
optimum. There are a variety of heuristics that can quickly find a local-minima for k-means, however this
is only a minima when compared to neighboring candidate solutions that are not over the entire problem
space. As such k-means falls victim to a local-minima problem where the data plateaus which can give
less than optimal clustering results. [15].
2.2
Quantum Annealing
Quantum annealing is a method of quantum computing that relies on the adiabatic principle of the
evolution of a quantum state over time. This is formally expressed as:
iℏd |ψ⟩
dt
= H |ψ⟩
(4)
where t is time, ψ is the state of the system, and ℏ is Planck’s constant for which the exact value is not
known, but for many practical purposes ℏ = 1 suffices.
A Hamiltonian is a mathematical model for expressing the total energy of a system and quantum
annealing problems are expressed as a Hamiltonian with a minimization of energy as Hp. Once processed
over time, our solution is an eigenvector with the lowest energy in Hp. The adiabatic principle states that
4
Adaptive Quantum Optimized Centroid Initialization
as our time T tends towards inf, we will be very close to the ground state of energy in Hp. Specifically
we will be referencing an Ising Hamiltonian which (at the time of this writing) is the only Hamiltonian
supported by D-Wave quantum annealers. Specifically the Ising Hamiltonian is defined as:
E = −J∑
⟨i j⟩
sisj
(5)
where E is the sum over nearest neighbors ⟨ij⟩ and J is an exchange constant that is positive.
2.3
Quadratic Unconstrained Binary Optimization
Quadratic unconstrained binary optimization (QUBO) is a combinatorial optimization problem that
is functionally equivalent to an Ising Hamiltonian. The set of binary vectors of a fixed length n > 0 is
denoted by Bn, where B = {0,1} is a set of binary values. Given a real upper triangular matrix Q ∈ Rnxn
whose entries Qij define a weight for a pair of indices i, j ∈ {1,...,n} within a binary vector. A function
fQ : Bn 7→ R assigns a value to each binary vector:
fQ(x) = xTQx =
n
∑
i=1
n
∑
j=1
Qi jxixj
(6)
With a QUBO problem, we wish to find a binary vector x∗ that is minimal to fQ such that:
x∗ = argmin
x∈Bn fQ(x)
(7)
While the D-Wave quantum annealers support both Ising and QUBO formulations, for this work we
chose to utilize a QUBO formulation.
2.4
Non-Negative Matrix Factorization
Non-negative matrix factorization (NMF) are a group of algorithms where a matrix V is factorized
to two matrices W and H where all three matrices have no negative elements. Non-ngeative matrix
factorization is often numerically approximated and utilized in a wide variety of domains. Matrix multi-
plication is implemented by computing the columns of vectors V as a linear combination of the column
vectors in W with the coefficients supplied by the columns in matrix H. We are then able to state that
each column of V can be computed as vi = Whi where vi is the i-th column vector of the product matrix
V and hi is the i-th column vector of the matrix H. The multiplication of the matrices will often result
in dimensions of W and H being much lower than those of the product matrix. This property is founda-
tional for how NMF works and the dimensions are much smaller than the original matrix V. Computing
matrices W and H can be done in a variety of ways with a popular method being a multiplicative update
method [13].
2.5
Quantum Optimized Centroid Initialization
Quantum Optimized Centroid Initialization (QOCI) utilizes many ideas from non-negative matrix
factorization but allows both positive and negative real numbers. Similar to non-negative matrix factor-
ization, we utilize V = WH where V is the approximation of our data computed from the product of
matrices W and H. Each column in matrix W represents cluster membership and matrix H is a binary
matrix where a 1 in a single column is then multiplied with W resulting in WH where every column is a
Allgood, Borle, and Nicholas
5
cluster and the entries in the matrix column are the centroids. It is through quadratic expansion we can
derive our linear coefficients and our quadratic coefficients. Any constants that are created as part of the
expansion are simply ignored in this formulation. The linear coefficients are those that correspond to a
single variable and the quadratic coefficients are those that are paired along side multiple variables.
To get the correct centroids consistently a penalty function was introduced that made heavy use of
LaGrange Multipliers in addition to relying on an implicit penalty applied when a quadratic equation was
expanded. As a the annealing process happens, the penalty function puts extra weight on a solution that
is determined to be less than optimal. Utilizing a QUBO formulation, we relied on a predictable style of
quadratic expansion similar to (a+b)2 = a2 +2ab+b2. This penalty is first applied to only the matrix
W and known as a linearization penalty. A second penalty function is also introduced for the matrix H
to ensure that a single 1 was in each column. For each penalty function, we have δ1 and δ2 where δ1 is
our linearization penalty function and δ2 is our penalty function for matrix H.
The results are binary values read together are the result with the left most qubit being designated the
sign qubit and the remaining qubits used to represent the value [3]. It will be assumed that the endianess
for this part of the formulation will be from right to left, with the most significant qubit the left. The
importance of this is that these will act as multipliers for the coefficients that are determined through
quantum annealing.
An example using 4 qubits including the most significant as our sign bit, our expanded form would
look similar to −8q8 +4q4 +2q2 +q1 where n in qn refers to having n power of 2 as a label to our qubits.
We can then express this more concisely:
ϑqjθ + ∑
θ∈Θ
θqjθ = ∑
θ∈Θ
2θqjθ
(8)
where
ϑ =
(
−2p+1,
two′s complement
−2p+1 +2Θ
one′s complement
and Θ is the maximum power of 2 based on the number of qubits necessary. As an example, if [o, p] =
[0,2] and we need to represent 3, then qj4 = 0,qj2 = 1,qj1 = 1 which gives us w = 22qj4+21qj2+20qj1 =
3.
3
Contribution
Adaptive Quantum Optimized Centroid Initialization (AQOCI) is an attempt to address a few of the
shortcomings of Quantum Optimized Centroid Initialization. AQOCI allows results to be interpreted as
results in R2 in addition to allowing larger sample sizes to able to be accommodated. D-Wave limits how
much time one gets on their quantum annealers using a free account which is still a major limitation,
however, by utilizing an adaptive and iterative approach we were able to break the problem into smaller
blocks of execution. Primary inspiration for this method came from reviewing the Gauss-Seidel and
Jacobi methods for iteratively solving a system of linear equations. A similar iterative approach has
been utilized to solve the heat equation [18]. The formulation we are proposing takes inspiration from
Pollachini’s work, especially when they discuss scaling of the solution.
We start with our initial QUBO in a similar fashion to the QOCI formulation and then define a range
of scaling values for our solution to be computed between. We manually define an upper limit and lower
limit for this range and identify how many qubits will be used for represent these values. Scaling in
6
Adaptive Quantum Optimized Centroid Initialization
itself is not sufficient as it does not address only having a result represented as an integer. To get a real
value result a manual offset real value which is added to the polynomial expansion along to be utilized
in conjunction with the scaling values. With the mentioned improvements, this changes our equation
slightly as follows:
λ
Allgood, Borle, and Nicholas
7
scale value by the scale factor, and for the offset we adjust it by performing (binstr ∗scale)+of fset −
(binstr)∗newScale. More explicitly, we can express this as follows:





α = α/β,o = o
if binstr = 0,o = ll
α = α/β,o = b∗α +o−b∗o
if b = 2bits −1,ul = 2bits −1∗α +ll
α = α/β,o = b∗α +o−3∗α
otherwise
(12)
where ll is our lower limit, ul is our upper limit, o is our offset list, α is our scale value, β is our scale
factor, and b is our binary string returned by the solver.
4
Results
Our experiments utilized random Gaussian blobs and random samples from a malware research data
set known as MOTIF [9]. The Gaussian blobs were generated in two dimensions and the MOTIF data
was processed with Principal Component Analysis to reduce the dimensional to two-dimensional. ALl
experiments were computed utilizing D-Wave software and hardware platforms [7]. The experiments
were computed using three different methods of computation:
1. TABU A quantum inspired heuristic algorithm based on the Multistart TABU Search algorithm
[17]. This is a local search method that attempts to avoid the local minima problem by keeping
a list of candidate solutions that are temporarily not allowed. This allows the search space to be
exhausted more thoroughly.
2. Simulated Annealing A quantum inspired algorithm inspired by metallurgy that starts with a
random solution and then makes small changes to it. At each step, the algorithm decides whether
to accept the new solution based on a probability that depends on the difference in the cost function
and a temperature parameter. As the process continues, the temperature is gradually lowered,
reducing the likelihood of accepting worse solutions, thus allowing the system to stabilize into a
solution.
3. Hybrid BQM D-Wave’s Hybrid Binary Quadratic Model that utilizes a combination of a classi-
cal annealer and a quantum annealer. This solver has a proprietary process that takes submitted
quantum programs and splits the computational blocks between the classical and quantum CPU.
To use each computational process, no change in the formulation was required. The TABU solver and
simulated annealer were provided by D-Wave’s Ocean software. These processes were used to generate
our centroids and then utilized as starting centroids for k-means to form clusters. As a control we com-
puted the same number of clusters utilizing the same data letting k-means randomly select the starting
centroids. In addition to the previously mentioned cluster analysis metrics, we also kept track of the
number of iterations required for k-means to converge. It is worth noting again the way the maximum
sample size was determined was through empirical means and limitations imposed by D-Wave’s free
account.
The following images outline our results using the aforementioned computational processes using
the random Gaussian blobs with the number of clusters being 3, a seed of 0, and number of samples
being 250. For the inertia and number of iterations we desired a lower value, where the silhouette,
homogeneity, completeness and v-measure we desire a higher value.
8
Adaptive Quantum Optimized Centroid Initialization
Figure 1: Gaussian: Inertia
Figure 2: Gaussian: Iterations
Figure 3: Gaussian: Silhouette
Figure 4: Gaussian: Homogeneity
Figure 5: Gaussian: Completeness
Figure 6: Gaussian: V-Measure
For the Gaussian blobs our inertia score was nearly identical across all processes and the same holds
true for the silhouette score. For homogeneity the TABU solver seems to provide the higher score
over the other processes but the difference is fairly minimal. The completeness score all processes are
nearly identical with the HybridBQM having a slightly higher score which is also true for v-measure.
Interestingly enough, simulated annealing eventually had the lowest number of iterations required for
k-means where random centroid selection is shown to have many more iterations.
The following images outline our results using the aforementioned computational processes using
the random MOTIF data with the number of clusters being 3, a random seed of 0, and a sample size of
250.
Allgood, Borle, and Nicholas
9
Figure 7: MOTIF: Inertia
Figure 8: MOTIF: Iterations
Figure 9: MOTIF: Silhouette
Figure 10: MOTIF: Homogeneity
Figure 11: MOTIF: Completeness
Figure 12: MOTIF: V-Measure
The inertia values for the MOTIF data have shown to be nearly identical across all processes. The
silhouette score only the random centroid selection via k-means appeared to have the worst score while
the remaining three processes were nearly identical. Homogeneity the random centroid selection via k-
means had the higher score with the remaining three processes all being nearly identical. Completeness
all processes were nearly identical with the higher scores and the random selection via k-means had
a significantly lower score. It’s worth noting that completeness for MOTIF was significantly higher
compared to Gaussian blobs due to completeness being a measure of data similarity. Each of the samples
came from the same data set so this was expected behavior. The v-measure score was higher with random
centroid selection via k-means and the remaining three processes were nearly identical approaching the
maximum number of samples. The number of iterations was the lowest by a significant amount using
10
Adaptive Quantum Optimized Centroid Initialization
random centroid selection via k-means. The highest number of iterations occurred with the HybridBQM
process but as we approached the maximum sample size, there was was a sharp decline in the number
of iterations required. Simulated annealing and TABU were less than HybridBQM, however, as we
approached out maximum sample size we observed a sharp increase in the number of iterations for both
of those processes.
5
Conclusion
In this work we have addressed many of the shortcomings by our previous algorithm QOCI and have
provided a novel quantum algorithm for selecting better initial centroids for prototype-based clusters
instead of relying on a random selection of centroids. Quantum computing has evolved by leaps and
bounds within the past two decades and there are countless domains to where quantum computing is
being explored. Despite the exciting new territory one must also remember to take a step back and re-
evaluate existing methods. For the time being many are good enough, but there will always come a time
when good enough is no longer acceptable.
References
[1] Nicholas R. Allgood, Ajinkya Borle & Charles K. Nicholas (2023): Quantum Optimized Centroid Initial-
ization. In Kohei Arai, editor: Proceedings of the Future Technologies Conference (FTC) 2023, Volume 2,
Springer Nature Switzerland, Cham, pp. 71–85.
[2] Christian Bauckhage (2015): k-Means Clustering Is Matrix Factorization, doi:10.48550/ARXIV.1512.07548.
[3] Ajinkya Borle & Samuel J. Lomonaco (2018): Analyzing the Quantum Annealing Approach for Solving
Linear Least Squares Problems. arXiv 1809.07649.
[4] El˙zbieta Burek, Michał Misztal & Michał Wro´nski (2021): Algebraic attacks on block ciphers using quantum
annealing. Cryptology ePrint Archive, Report 2021/620. https://ia.cr/2021/620.
[5] Raúl V. Casaña-Eslava, Paulo J.G. Lisboa, Sandra Ortega-Martorell, Ian H. Jarman & José D. Martín-
Guerrero (2020):
Probabilistic quantum clustering.
Knowledge-Based Systems 194, p. 105567,
doi:https://doi.org/10.1016/j.knosys.2020.105567.
Available at https://www.sciencedirect.com/
science/article/pii/S0950705120300587.
[6] Chia Cheng Chang, Arjun Gambhir, Travis S. Humble & Shigetoshi Sota (2019): Quantum annealing for sys-
tems of polynomial equations. Scientific Reports 9(1), p. 10258, doi:10.1038/s41598-019-46729-0. Available
at https://doi.org/10.1038/s41598-019-46729-0.
[7] D-Wave: D-wave. Available at https://www.dwave.com.
[8] Edward W. Forgy (1965): Cluster analysis of multivariate data: efficiency versus interpretability of classifi-
cations. Biometrics 21(3), pp. 768–769.
[9] Robert J. Joyce, Dev Amlani, Charles Nicholas & Edward Raff (2023): MOTIF: A Large Malware Reference
Dataset with Ground Truth Family Labels. Computers and Security 124, Issue C.
[10] Jain A. K. & Dubes R. C. (1988): Algorithms for Clustering Data. Prentice-Hall.
[11] Rousseeuw PJ Kaufman L (1987): Clustering by means of medoids. Proc. Statistical Data Analysis Based on
the L1 Norm Conference, Neuchatel, 1987, pp. 405–416.
[12] Jingu Kim & Haesun Park (2008): Sparse Nonnegative Matrix Factorization for Clustering. Technical Report
GT-CSE-08-01, Georgia Institute of Technology. Available at https://smartech.gatech.edu/handle/
1853/20058.
Allgood, Borle, and Nicholas
11
[13] Daniel D. Lee & H. Sebastian Seung (2000): Algorithms for Non-Negative Matrix Factorization. In: Pro-
ceedings of the 13th International Conference on Neural Information Processing Systems, NIPS’00, MIT
Press, Cambridge, MA, USA, p. 535–541.
[14] S Lloyd (1982): Least squares quantization in PCM. IEEE Transactions on Information Theory 28(2), pp.
129–137.
[15] J. B. MacQueen (1967): Some Methods for classification and Analysis of Multivariate Observations. In:
Proceedings of 5th Berkeley Symposium on Mathematical Statistics and Probability: 281-297, University of
California Press.
[16] Michael A. Nielsen & Isaac L. Chuang (2000): Quantum Computation and Quantum Information. Cambridge
University Press.
[17] Gintaras Palubeckis (2004): Multistart Tabu Search Strategies for the Unconstrained Binary Quadratic Op-
timization Problem. In: Annals of Operations Research. Available at https://doi.org/10.1023/B:
ANOR.0000039522.58036.68.
[18] Giovani G. Pollachini, Juan P. L. C. Salazar, Caio B. D. Goes, Thiago O. Maciel & Eduardo I. Duzzioni
(2021): Hybrid classical-quantum approach to solve the heat equation using quantum annealers. Phys-
ical Review A 104(3), doi:10.1103/physreva.104.032426.
Available at https://doi.org/10.1103%
2Fphysreva.104.032426.
[19] Jing Xiao,
YuPing Yan,
Jun Zhang & Yong Tang (2010):
A quantum-inspired genetic al-
gorithm
for
k-means
clustering.
Expert
Systems
with
Applications
37(7),
pp.
4966–4973,
doi:https://doi.org/10.1016/j.eswa.2009.12.017.
Available
at
https://www.sciencedirect.com/
science/article/pii/S095741740901063X.
","The paper reviews related work in cluster analysis, including k-means and quantum annealing, as well as previous work on quantum optimized centroid initialization (QOCI). K-means, a widely used prototype-based clustering algorithm, is detailed along with its drawbacks, such as the local minima problem. Quantum annealing is introduced as a method to find the ground energy state and avoid local minima. Previous work on QOCI is discussed, highlighting its advantages and disadvantages.nan"
"Diversity plays a central part in enhancing the effectiveness of multi-agent reinforcement learning (MARL). Recently, numerous diversity-based methodologies have been introduced to resolve the problems brought on by excessive parameter sharing in typical MARL. However, there is still no established metric for quantifying policy differences among agents. Such a metric would not only streamline the monitoring of diversity change in multi-agent systems but also offer guidance for creating diversity-based MARL algorithms. In this article, we present Multi-Agent Policy Distance (MAPD), a comprehensive tool for gauging policy differences in MARL. MAPD computes the policy distance between any pair of agents by learning the conditional representations of agents' choices. We also provide a customizable version of MAPD that assesses policy discrepancies in certain areas. Based on the online implementation of MAPD, we create the Multi-Agent Dynamic Parameter Sharing (MADPS) algorithm to show how MAPD can be used. Comprehensive experiments demonstrate the efficacy of our methodology in gauging distinctions in agent policies and specific behavioral tendencies. Additionally, MADPS outperforms other parameter-sharing algorithms.","Multi-agent reinforcement learning (MARL) has seen substantial progress in practical applications, such as multiplayer gaming, multi-robot system controlling, sensor networks, and autonomous driving. However, excessive use of parameter sharing can restrict the multi-agent system to fully shared policies, thus limiting their adaptability to complex tasks. The lack of policy diversity in multi-agent systems is the fundamental cause of this issue, which hinders both the adaptability of these systems to complex tasks and the overall exploration during learning. Consequently, diversity-based MARL approaches have emerged. One of the classic approaches to achieving policy diversity is to directly incorporate agent indices into the observations. Other intuitive approaches involve grouping the agents based on prior knowledge or learned information, and only sharing parameters within each group. Additionally, some methods introduce the concept of roles into MARL, controlling the parameters of the agents based on their roles. Despite the contributions of these methods in enabling agents to develop policy diversity, there is currently a lack of a general metric that can quantify the differences in agent policies and be applicable in various types of multi-agent systems. Such differences between agent policies are valuable because they can help us analyze the diversity evolution in multi-agent systems during learning, and gain a deeper understanding of how MARL can benefit from diversity.","We aim to develop a generalized tool for measuring policy difference among agents. This tool not only allows us to gain a deeper understanding of the impact of diversity in MARL, but also provides guidance for the design of diversity-based algorithms. We model agent policies as action distributions conditioned on observations, and discuss the limitations of directly using action distributions for measuring. Our key insight, is to learn latent conditional representations of agents’ decisions under each observation, and measure the accumulation of differences between these representations. Additionally, we extend MAPD to a customizable version, to quantify policy differences on specific aspects which the users are interest in. Based on the online deployment of MAPD, we design multi-agent dynamic parameter sharing (MADPS) as a paradigm for the utilization of MAPD. MADPS is an algorithm that can automatically adjust the parameter sharing scheme of agents during training, helping multi-agent systems find the appropriate balance between policy diversity and parameter sharing.","We evaluate the proposed method by implementing it in the multi-agent particle environment (MPE) and StarCraft II micromanagement environment. In the MPE, the customized policy distance accurately captures the differences between agents on two aspects of policy: (1) the tendency of moving towards a same landmark, and (2) the tendency of moving towards the matching landmark. In the StarCraft II micromanagement environment, MADPS outperforms other methods of parameter sharing in terms of learning effectiveness and final performance, demonstrating the superiority of our method in quantifying policy diversity and dynamically adjusting parameter sharing.","This paper proposes MAPD, a general tool for quantifying differences in policies of MARL. Instead of directly measuring the polices, MAPD learns conditional representations of agents’ decisions, and computes the policy distance by integrating the distances of the latent distributions. This approach is applicable to various policy forms of multi-agent systems. The variant of MAPD, customized policy distance, allows for measuring the behavioral differences between agents on specific aspects of policy. Based on MAPD, we design a dynamic parameter sharing algorithm, which can achieve a dynamic fusion and division of agents’ policies during the MARL training. Experimental results demonstrate that our method can accurately quantifiy the diversity in agent policies, and MADPS outperforms other baseline methods of parameter sharing. We believe that MAPD can serve as an important tool for studying and leveraging behavioral diversity in multi-agent systems, ultimately promoting the advancement of MARL.",Measuring Policy Distance for Multi-Agent Reinforcement Learning,"Tianyi Hu, Zhiqiang Pu, Xiaolin Ai, Tenghai Qiu, Jianqiang Yi","Measuring Policy Distance for Multi-Agent Reinforcement
Learning
Tianyi Hu
Institute of Automation, CAS
School of Artificial Intelligence, UCAS
Beijing, China
hutianyi2021@ia.ac.cn
Zhiqiang Pu
Institute of Automation, CAS
School of Artificial Intelligence, UCAS
Beijing, China
zhiqiang.pu@ia.ac.cn
Xiaolin Ai
Institute of Automation, CAS
Beijing, China
xiaolin.ai@ia.ac.cn
Tenghai Qiu
Institute of Automation, CAS
Beijing, China
tenghai.qiu@ia.ac.cn
Jiangqiang Yi
Institute of Automation, CAS
School of Artificial Intelligence, UCAS
Beijing, China
jianqiang.yi@ia.ac.cn
ABSTRACT
Diversity plays a crucial role in improving the performance of multi-
agent reinforcement learning (MARL). Currently, many diversity-
based methods have been developed to overcome the drawbacks of
excessive parameter sharing in traditional MARL. However, there
remains a lack of a general metric to quantify policy differences
among agents. Such a metric would not only facilitate the evaluation
of the diversity evolution in multi-agent systems, but also provide
guidance for the design of diversity-based MARL algorithms. In this
paper, we propose the multi-agent policy distance (MAPD), a gen-
eral tool for measuring policy differences in MARL. By learning the
conditional representations of agents’ decisions, MAPD can com-
putes the policy distance between any pair of agents. Furthermore,
we extend MAPD to a customizable version, which can quantify
differences among agent policies on specified aspects. Based on the
online deployment of MAPD, we design a multi-agent dynamic pa-
rameter sharing (MADPS) algorithm as an example of the MAPD’s
applications. Extensive experiments demonstrate that our method
is effective in measuring differences in agent policies and specific
behavioral tendencies. Moreover, in comparison to other methods
of parameter sharing, MADPS exhibits superior performance.
KEYWORDS
Multi-Agent System; Reinforcement Learning; Diversity Measure
ACM Reference Format:
Tianyi Hu, Zhiqiang Pu, Xiaolin Ai, Tenghai Qiu, and Jiangqiang Yi. 2024.
Measuring Policy Distance for Multi-Agent Reinforcement Learning. In Proc.
of the 23rd International Conference on Autonomous Agents and Multiagent
Systems (AAMAS 2024), Auckland, New Zealand, May 6 – 10, 2024, IFAAMAS,
9 pages.
1
INTRODUCTION
Multi-agent reinforcement learning (MARL) has achieved signif-
icant success in practical applications, such as multiplayer gam-
ing [23], multi-robot system controlling [5], sensor networks [29]
Proc. of the 23rd International Conference on Autonomous Agents and Multiagent Systems
(AAMAS 2024), N. Alechina, V. Dignum, M. Dastani, J.S. Sichman (eds.), May 6 – 10, 2024,
Auckland, New Zealand. © 2024 International Foundation for Autonomous Agents
and Multiagent Systems (www.ifaamas.org). This work is licenced under the Creative
Commons Attribution 4.0 International (CC-BY 4.0) licence.
and autonomous driving [13]. Traditional MARL approaches com-
monly employ parameter sharing techniques to enhance sample
efficiency [21, 25] and algorithm scalability [1]. Although parameter
sharing has been shown to be useful for accelerating training [4],
its excessive use can restrict the multi-agent system to fully shared
policies, thus limiting their adaptability to complex tasks [12].
Overall
Customized Policy Distance
Applications
Measurement
Multi-agent
Policy Distance
Dynamic
Parameter Sharing
MARL
Diversity-based
MARL
Figure 1: The relationship between our work and MARL. Our
contributions are highlighted in bold and italicized.
The fundamental cause of this issue lies in the lack of policy
diversity in multi-agent systems. This lack of diversity not only
hinders the adaptability of multi-agent systems to complex tasks,
but also weakens the overall exploration during learning. To ad-
dress this problem, diversity-based MARL methods have emerged.
One of the classic approaches to achieving policy diversity is to
directly incorporate agent indices into the observations [6, 8]. This
allows the agents to exhibit different behaviors while sharing net-
work parameters. Other intuitive approaches involve grouping the
agents based on prior knowledge or learned information, and only
sharing parameters within each group. For instance, [2] leverages
the heterogeneous characteristics of agents for grouping, [4] uti-
lizes supervised learning and clustering to group the agents before
training. Additionally, some methods introduce the concept of roles
into MARL, controlling the parameters of the agents based on
their roles. [27] captures emergent roles from agents’ local obser-
vations, [28] learns roles by embedding decomposed action spaces
in the initial training phase, and [15] learns roles during training
and updates the role clusters at fixed time steps.
arXiv:2401.11257v1  [cs.MA]  20 Jan 2024
Although the above methods allow agents to emerge policy di-
versity, there is currently a lack of a general metric that can quantify
the differences in agent policies and be applicable in various types
of multi-agent systems. It is meaningful to measure such differences
between agent policies, as it can help us analyze the diversity evo-
lution in multi-agent systems during learning, and gain a deeper
understanding of how MARL can benefit from diversity.
There have been previous attempts at measuring policy differ-
ences in MARL. [19] introduces a ""policy distance"" by sampling
states and recording the ratio of different actions selected by the
population. [9] employs KL divergence to measure the distances
between action-based roles, [18] uses the maximum mean discrep-
ancy to compare distributions over trajectories under different poli-
cies. [14] formulates the concept of behavioral diversity as the dis-
crepancies of occupancy measures and utilizes f-divergence. Such
methods based on divergence metrics fail to satisfy the triangle
inequality. This results in increased challenges in analyzing multi-
agent policies and complicates further applications. Some research
has delved into the representations of policies. In [7], episodes gen-
erated by agent policies are mapped to real-valued vectors, and
the Euclidean distances between these vectors is utilized as the
policy distances. [10] maps agent policies to a distribution, and em-
ploys KL divergence and one-dimensional Wasserstein distance to
handle discrete and continuous action spaces, respectively. These
approaches, which map the overall policies to low-dimensional
vectors or distributions, inevitably result in significant information
loss. The state-of-the-art method for measuring behavioral diver-
sity at a system level is presented in [3]. This method calculates the
behavioral distance between pairs of agents, and employs the aver-
age of these distances as an indicator of system diversity. However,
this approach requires assumptions about the type of agent policies
and presumes that the observation and action spaces of agents are
identical, limiting its generality.
We are desired to develop a general tool for measuring policy dif-
ference among agents. This tool not only allows us to gain a deeper
understanding of the impact of diversity in MARL, but also provides
guidance for the design of diversity-based algorithms. We model
agent policies as action distributions conditioned on observations,
and discuss the limitations of directly using action distributions for
measuring. Our key insight, is to learn latent conditional represen-
tations of agents’ decisions under each observation, and measure
the accumulation of differences between these representations. Ad-
ditionally, we extend MAPD to a customizable version, to quantify
policy differences on specific aspects which the users are interest in.
Based on the online deployment of MAPD, we design multi-agent
dynamic parameter sharing (MADPS) as a paradigm for the uti-
lization of MAPD. MADPS is an algorithm that can automatically
adjust the parameter sharing scheme of agents during training,
helping multi-agent systems find the appropriate balance between
policy diversity and parameter sharing. The relationship between
our work and MARL is illustrated in Figure 1.
Our contributions can be summarized as follows:
(1) Proposing MAPD, a generalized measure of policy differ-
ences for multi-agent reinforcement learning.
(2) Developing a customizable version of MAPD for measuring
policy differences on specific aspects.
(3) Designing MADPS, a multi-agent dynamic parameter shar-
ing algorithm based on the online deployment of MAPD.
(4) Demonstrating the utilization of MAPD through cases in the
multi-agent particle environment (MPE) [16], and applying
MADPS on both MPE and StarCraft II micromanagement
environment [22] to showcase its superior performance.
2
BACKGROUND
In this section, we introduce partially observable markov game
(POMG) [2], and give a general mathematical definition of agent
policies to establish the foundation of policy distance measurement.
A partially observable markov game can be represented by a
8-tuple:
⟨N, S, {Ω𝑖}𝑖∈N, {𝑂𝑖}𝑖∈N, {𝐴𝑖}𝑖∈N, {𝑅𝑖}𝑖∈N, T,𝛾⟩,
where N = {1, · · · ,𝑛} defines the set of all agents, S is the global
state space. For an agent 𝑖 ∈ N, Ω𝑖 denotes the observation space,
𝑂𝑖 denotes the corresponding observation function, 𝐴𝑖 is the action
space and 𝑅𝑖 : S × {𝐴𝑖}𝑖∈N × S ↦→ R is the reward function. T :
S × {𝐴𝑖}𝑖∈N ↦→ S represents the global state transition function,
and 𝛾 refers to the discount factor.
At each time 𝑡, an agent 𝑖 receives a partial observation 𝑜𝑡
𝑖 ∼
𝑂𝑖 (𝑠𝑡) from the environment, and takes an action 𝑎𝑡
𝑖 ∈ 𝐴𝑖 according
to its policy, where 𝑠𝑡 ∈ S is the global state of the environment.
Each agent in a POMG aims to learn an optimal policy 𝜋∗
𝑖 that,
given an observation at a specific time step, outputs the optimal
action. The optimal policy can be learned by maximizing the total
expected reward accumulated by the agent.
In order to establish a general agent policy difference metric, the
first thing we need to do is to give a general definition of agent pol-
icy. An agent’s policy can always be represented as a conditional
probability distribution of actions under condition 𝑜, that is,
𝜋𝑖 ≔ 𝜋𝑖 (𝑎|𝑜). This definition naturally holds when agents adopt
stochastic policies and take actions based on policy-based MARL
methods. In the case of value-based approaches, the action-values
can be converted into a probability distribution across all actions,
e.g., through softmax. Even when deterministic policies are utilized,
actions can still be represented as a probability distribution, with a
100% probability assigned to the chosen action. According to this
definition, the policies of agents with discrete actions are discrete
conditional distributions, while those corresponding to continuous
actions are continuous distributions.
3
MEASURING POLICY DISTANCE BETWEEN
AGENTS
In this section, we present the desired input-output format and
properties of MAPD. Following that, we discuss the reasons and
methods for learning a conditional representation for the agent
decision-making. Finally, we show how to utilize this representation
to compute a policy distance.
3.1
Analysis
Our Objective. This work aims to develop a general tool, termed
multi-agent policy distance (MAPD), to measure the policy differ-
ence between any two agents in a multi-agent system,
𝑀𝐴𝑃𝐷 : {(𝜋𝑖, 𝜋𝑗)}𝑖,𝑗 ∈N ↦→ R≥0,
where 𝜋𝑖, 𝜋𝑗 represent the policies of two agents in a multi-agent
system. When the policies 𝜋𝑖, 𝜋𝑗 are given, MAPD can output a
non-negative scale value, indicating the degree of difference be-
tween these two policies. And we hope this computed scale value
to possess some distance-like properties.
Properties of MAPD. For ease of exposition, we use 𝜋𝑖 and 𝜃𝑖
to denote the policy and the network parameters of an agent 𝑖, re-
spectively. The policy distance between agent 𝑖 and 𝑗 is represented
by 𝑑𝑖𝑗, and the properties of MAPD are as follows:
• Symmetry:
𝑑𝑖𝑗 = 𝑑𝑗𝑖.
• Non-negativity:
𝑑𝑖𝑗 ≥ 0.
• Identicals of indiscernibility (policies): 𝑑𝑖𝑗 = 0 ⇐⇒ 𝜋𝑖 = 𝜋𝑗.
• Identicals of indiscernibility (parameters): 𝑑𝑖𝑗 = 0 ⇒ 𝜃𝑖 = 𝜃 𝑗.
• Triangle inequality: 𝑑𝑖𝑗 ≤ 𝑑𝑖𝑘 + 𝑑𝑘 𝑗.
Among the above properties, symmetry implies that the policy
distance between two agents is not affected by their order. Non-
negativity specifies that the minimum policy distance is 0, indicating
that two policies are identical, which corresponds to identicals
of indiscernibility. In order to emphasize the distinction between
the policies and parameters of agents, we divide the concept of
identicals of indiscernibility into two aspects: one relating to the
policies and the other to the parameters. A policy distance of 0
implies that the policies of two agents are identical, and thus their
parameters are also the same, the reverse is not true because the
output of the agent’s network may not equal to that of the policy.
Therefore, directly comparing parameters of the neural network
won’t necessarily indicate policy similarity [11, 24].
The triangle inequality is applicable in comparing the policies of
multiple agents. We consider this property to be of great importance,
since it determines that MAPD is not isolated between two agents,
but also considers the influence of other agents. This property
allows us not only to estimate other policy distances based on a
given set of distances, but also to guide the design of dynamic
parameter sharing in Section 5.1.
According to Prop. 2 and Prop. 3, a policy distance equals to 0
when the agent policies are identical, whereas a policy distance
bigger than 0 when there are differences in policies. Thus, we need
to think about what would cause an increase in the differences of
policies, or in other words, an increase in policy distance between
two agents. A straightforward approach is to compare the action
distributions under the same observations, and accumulate the dif-
ferences between these distributions. To capture even the slightest
differences related to the overall policy, these calculations need
to be conducted across the entire observation space. Therefore, a
vanilla method [3] of measuring policy distance can be obtained as
follows:
𝑑𝑉𝑎𝑛𝑖𝑙𝑙𝑎
𝑖𝑗
=
∫
O
𝑓

𝜋𝑖 (𝑎|𝑜), 𝜋𝑗 (𝑎|𝑜)

𝑑𝑜,
(1)
where 𝜋𝑖 (𝑎|𝑜) denotes the action distribution of an agent 𝑖, 𝑓 is a
certain metric for measuring the distance between two distributions,
O is the observation space.
However, directly measuring the action distributions may
not be an ideal approach due to certain requirements related
to the type of distribution. Experiments in [3] assume Gaussian-
distributed actions in all continuous settings. Contrarily, agents
might take actions under different distributions, such as a bimodal
one. When the action distributions between two agents exhibit
diverse forms or correspond to different action spaces, measuring
the distance between these distributions becomes unfeasible.
Things may get worse in scenarios where agents take discrete
actions. Consider a scenario with five discrete actions: given the
same observation, an agent A outputs an action distribution of
[1.0, 0, 0, 0, 0], indicating a 100% preference for action No.1. Agent
B and C have distributions [0, 0, 0, 1.0, 0] and [0, 0, 0, 0, 1.0], respec-
tively. According to the definition of Wasserstein distance (WD) [26]
and Hellinger distance (HD) [20], the WD between A-B is three
times as big as that between B-C (3 and 1), while both A-B and
B-C have identical HD of 1. The crux of this matter lies in the non-
sequential nature of action indices, where index-close actions can
denote either closely related or vastly different operations.
Hence, our idea is to identify a distribution 𝑝𝑖 (𝑧|𝑜) in a latent
space to represent the agent’s action distribution 𝜋𝑖 (𝑎|𝑜). Within
this designated latent space, the inherent non-sequential nature can
be eradicated, and the types of distributions can also be standardized.
This can be achieved by assuming the latent variables following
to a certain multi-dimensional prior distribution. We can measure
distances between these distributions as an alternative to measuring
action distributions, while the semantics of each dimension within
this distribution is not of concern to us.
3.2
Learning the conditional representations of
agents’ decisions
We hope to find a mapping function, which can output a latent
distribution when the observation 𝑜 and an agent 𝑖’s decision 𝑎𝑖 ∼
𝜋𝑖 (𝑎|𝑜) are given. Thus, this latent distribution can be presented as
a posterior 𝑞(𝑧|𝑎𝑖,𝑜) under 𝑜 and 𝑎𝑖, where 𝑞 denotes the desired
mapping function.
In order to ensure the representational capability of 𝑞(𝑧|𝑎𝑖,𝑜),
we employ an auto-encoder architecture to learn 𝑞. The encoder,
which approximates the posterior distribution, takes 𝑎𝑖 and 𝑜 as
input and outputs a distribution of the latent variable𝑧. On the other
hand, the decoder tries to reconstruct 𝑎𝑖 by drawing samples 𝑧 from
𝑞(𝑧|𝑎𝑖,𝑜). Solely using 𝑧 as input is insufficient since the agent’s
actions inherently depend on 𝑜, so the decoder also incorporates 𝑜
to reconstruct the action.
However, the auto-encoder framework is widely used as a gen-
erative model [17], which predicts the underlying distribution of
sample data (in our case 𝑎 ∼ 𝜋𝑖 (𝑎|𝑜)). Since the input action 𝑎 is
sampled from the agent’s action distribution, it requires an ample
amount of data to fit the action distribution 𝜋𝑖 (𝑎|𝑜𝑥) for agent 𝑖
under all possible observations 𝑜𝑥, where 𝑥 denotes the index of
observation.
Fortunately, the agent’s policy is fixed during the training of the
auto-encoder, meaning the action distributions for each observation
is known. Thus, we directly use 𝜋𝑖 (𝑎|𝑜) as the encoder’s input and
explicitly incorporate agent’s observation 𝑜. The decoder no longer
reconstructs the action codes but the action distribution. In this case,
the conditional latent variable distribution changes from 𝑞(𝑧|𝑎𝑖,𝑜)
to a posterior 𝑞[𝑧|𝜋𝑖 (𝑎|𝑜),𝑜].
Encoder
Action Probability
Distribution
!!(#|%)
'"" # (, %)
No
Sample
Conditional
Representation
Environment
Agent
Decoder
!
Sample
Observation
""~$!(&)
Reconstructed
Distribution
*#[(|!!(#|%), %]
*#
'""
Figure 2: Learning the conditional representation of an agent’s decision.
The architecture for learning this conditional representation is
illustrated in Figure 2. An agent 𝑖 receives observation 𝑜 ∼ 𝑂𝑖 (𝑠)
through its observation function and outputs the corresponding
action distribution 𝜋𝑖 (𝑎|𝑜), where 𝑂𝑖 (𝑠) represents the observation
function, 𝑠 is the global state. The encoder 𝑓 , parameterized by 𝜙,
accepts inputs 𝜋𝑖 (𝑎|𝑜) and 𝑜, and produces the parameters of the
latent variable’s posterior probability distribution. The decoder 𝑔
uses the sampled 𝑧 and 𝑜 to yield the reconstructed action distribu-
tion, with its parameters denoted by 𝜔. This auto-encoder model is
trained by minimizing the following loss function:
L (𝜙,𝜔) = E𝑧∼𝑓𝜙 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜] [𝐷Π (𝑔𝜔 (𝑎|𝑧,𝑜)||𝜋𝑖 (𝑎|𝑜))]
+ 𝐷𝐾𝐿

𝑓𝜙 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]||𝑝(𝑧|𝑜)

,
(2)
where the first term is the reconstruction loss, and the second term is
the KL loss for bring generated latent distribution 𝑓𝜙 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]
closer to the prior 𝑝(𝑧|𝑜). In our experiments, 𝑝(𝑧|𝑜) is a multi-
dimensional Gaussian distribution.
In the reconstruction loss term, 𝐷Π(𝑥||𝑦) is a generalized dis-
tribution distance which measures the similarity between two dis-
tributions 𝑥 and 𝑦. In Equation 2, 𝑥 refers to the reconstructed
action distribution 𝑔𝜔 (𝑎|𝑧,𝑜) and 𝑦 is the original action distri-
bution 𝜋𝑖 (𝑎|𝑜). The specific form of 𝐷Π depends on the form of
𝜋𝑖 (𝑎|𝑜). A question may arise: since learning this representation is
to avoid directly measuring the distance between agents’ action dis-
tributions, why the (action distribution) distance reoccurs here? In
fact, this measurement only ensures a close alignment of the recon-
structed action distribution with the original one, without requiring
the various properties necessary for MAPD. Therefore, 𝐷Π can be
a WD (standard distance metrics), a KL divergence (f-divergences),
or even the MSE Loss of the action distribution vectors.
3.3
Multi-Agent Policy Distance
After obtaining the conditional representations of an agent’s deci-
sions, MAPD uses these learned distributions to replace the action
distributions under each observation. Since the action distributions
are mapped into a latent distribution in a same feature space, we
are able to measure the policy distance between a pair of agents
which have different types of actions. Considering that the obser-
vation spaces may also be different, MAPD measures the policy
differences between two agents on a common space O𝑃, which
is a set formed by padding the observations of these two agents.
The policy distance between two agents following MAPD can be
computed as follows:
𝑑𝑖𝑗 =
∫
O′⊆O𝑃
𝑊

𝑝𝑖 (𝑧|𝑜), 𝑝𝑗 (𝑧|𝑜)

𝑑𝑜,
(3)
where 𝑝𝑖 (𝑧|𝑜) = 𝑓𝜙 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜], denotes the latent distribution of
agent𝑖 under observation𝑜,𝑊 denotes a distribution distance, O′ is
a subset of the observation space O𝑃. More details about Equation 3
can be found in Appendix 1.1.
In practical applications, it is intractable to compute the integral
by traversing the observation space. In fact, the set of observations
involved in multi-agent tasks (determined by the initial state and
the state transition function) may only constitute a small portion of
the entire observation space. Hence, we focus only on the relevant
observations 𝑜 ∈ O′, specifically those that occur in the actual
tasks. In experiments, we use Monte Carlo sampling to estimate the
integral and employ multi-rollout to reduce estimation variance.
3.4
Case Study of MAPD
In this section, we use a multi-agent spread task [16] as a case study
to demonstrate the effectiveness of MAPD. In this scenario, there
are 15 agents with 3 colors: the first 5 agents are assigned color No.1,
the next 5 and last 5 are assigned color No.2 and No.3, respectively.
Each agent must move exclusively towards the landmark matching
its assigned color. The positions of the agents and landmarks are
randomly initialized, and the agents need to avoid collisions with
other agents, while moving towards the corresponding landmarks.
The neural networks of all agents are set to be independent, and
the parameters are initialized as the same.
Figure 3 shows parts of the policy distance matrices in two
scenarios. In scenario (a), the observation spaces of agents are the
same, while in scenario (b), the observations are randomly shuffled,
resulting in different observation spaces. Both matrices are obtained
at 10000 steps during training over 4 random seeds, with only 100
steps of data used for auto-encoder training and policy distance
computation. We can observe that each agent has a policy distance
of 0 with itself, corresponding to Prop. 3 of MAPD. Agents of the
same color should move to the same landmark (similar policies), as
indicated by their policy distances being less than 1.1.
14
(a) 15 agents with 3 colors and identical observation spaces
Policy Distance
Policy Distance
(a) Agents 3 colors
(b) 15 agents with 3 colors and different observation spaces
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
SQL Diﬃculty Level in Pre-training
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
Question Diﬃculty Level in Downstream
0.0000
0.8373
2.1499
2.2891
2.8368
2.8584
0.8373
0.0000
2.1667
2.2847
2.8554
2.8511
2.1499
2.1667
0.0000
0.9678
2.8113
2.7612
2.2891
2.2847
0.9678
0.0000
2.8588
2.7991
2.8368
2.8554
2.8113
2.8588
0.0000
0.8366
2.8584
2.8511
2.7612
2.7991
0.8366
0.0000
0
1
2
3
4
5
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
SQL Diﬃculty Level in Pre-training
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
Question Diﬃculty Level in Downstream
0.0000
0.7414
2.6132
2.6262
2.5764
2.6179
0.7414
0.0000
2.5839
2.6146
2.5994
2.6051
2.6132
2.5839
0.0000
1.0180
2.5917
2.5169
2.6262
2.6146
1.0180
0.0000
2.6783
2.6509
2.5764
2.5994
2.5917
2.6783
0.0000
0.8652
2.6179
2.6051
2.5169
2.6509
0.8652
0.0000
0
1
2
3
4
5
Figure 3: Policy distance matrices in multi-agent spread tasks. In this scenario, there are 15 agents with 3 colors: agents
numbered 1-5, 6-10, and 11-15 are each given the colors No.1, No.2, and No.3. The agents must move to the specific landmarks
that matches their color. Theses matrices show the policy distances just for the first two agents in each of colored groups.
On the other hand, agents of different colors, due to their different
tasks, need to move to different landmarks even under the same
observation, resulting in their policy distances all bigger than 2.1.
Furthermore, this phenomenon exists regardless of whether the
agents have the same observation space. This indicates that the
proposed MAPD is able to effectively capture and quantify the
differences in agent policies.
4
MEASURING CUSTOMIZED POLICY
DISTANCE
In some cases, beyond identifying the overall difference between
two agent policies, we may also be curious about their differences
in certain aspects. Agents might have distinct patterns in some
aspects of policy, while exhibiting similar patterns in others. Mea-
suring the policy distance in certain aspects can help us determine in
which areas the agents truly differ, and in which they show similar
inclinations.
We refer to this special policy distance as the customized policy
distance. In this section, we will introduce our method of measur-
ing customized policy distance, and give a case study to illustrate
its application.
4.1
Learning customized representations
In fact, it is challenging to define and quantify certain aspects of
policies. This is because this abstract concept is manually defined,
rather than just being a part of the action or the policy. However,
these manually defined aspects can be linked to feedback from en-
vironments or agents in MARL. For example, if we want to measure
the differences in aggressive and defensive aspects of units’ poli-
cies in StarcraftII [22], we can find the underlying bonds between
their actions and the ""killing reward"" and ""defensing reward"" in the
environment, and then use these bonds to measure the differences.
We refer to such information from environments or agents as
customized features, and the bond as customized representa-
tions. Customized features possess the following properties:
• Customized features can be modeled as stochastic variables.
• Customized features follow a conditional probability distri-
bution based on observations.
The process of measuring the customized policy distance is sim-
ilar to the methodology of measuring policy distance in Section 3.
Both need to learn a conditional representation of agent’s decisions,
but the customized one no longer reconstruct the policy itself, but
to predict the conditional distribution of the customized features.
For a clearer exposition of customized feature and customized pol-
icy distance, we denote the customized feature as 𝒄, which follows
some probability distribution 𝑝(𝒄|𝑜) conditioned on observation.
In order to learn a meaningful latents representing the customized
feature, our objective is to maximize the likelihood log𝑝(𝒄|𝑜) of all
observed 𝒄 under condition 𝑜 [17].
To optimize the log𝑝(𝒄|𝑜), an Evidence Lower Bound (ELBO) of
the likelihood can be derived as follows:
log𝑝(𝒄|𝑜) ≥ E𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]
""
log
𝑝(𝒄,𝑧|𝑜)
𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]
#
,
(4)
where 𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜] represents the posterior probability distri-
bution of the latent variable generated by the encoder, and 𝑝(𝒄,𝑧|𝑜)
denotes a joint probability distribution concerning the customized
feature and latent variable, conditioned on 𝑜.
Considering that the ELBO includes an unknown joint probabil-
ity distribution, we can further decompose it by using the posterior
probability distributions from the encoder and decoder:
E𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]
""
log
𝑝(𝒄,𝑧|𝑜)
𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]
#
= E𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜] [log𝑔𝜔 (𝒄|𝑧,𝑜)]
|                                    {z                                    }
reconstruction term
− 𝐷KL

𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜]∥𝑝(𝑧|𝑜)

|                                   {z                                   }
prior matching term
.
(5)
In Equation 5, 𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜] and 𝑔𝜔 (𝒄|𝑧,𝑜) are the posteriors
from the encoder and decoder, respectively. The detailed derivation
can be found in Appendix 1.2. Thus, the ELBO can be decomposed
into a reconstruction term of the customized feature, and a prior
matching term of the posterior and the prior. For the training of
the auto-encoder, we utilize both the reconstruction and matching
components as loss functions.
It is not difficult to notice that the form of Equation 5 is very
similar to that of Equation 2. As a matter of fact, the normal policy
distance is a special case of the customized distance when 𝒄 is
the action, as the actions follow a conditional distribution based
on observations. Furthermore, the theory of customized distance
demonstrates the rationality of the loss design in Section 3.2. Similar
to MAPD, the customized distance between agents can be computed
as follows:
𝑑𝑐
𝑖𝑗 =
∫
O′⊆O𝑃
𝑊
h
𝑝𝑐
𝑖 (𝑧|𝑜), 𝑝𝑐
𝑗 (𝑧|𝑜)
i
𝑑𝑜,
(6)
where 𝑑𝑐
𝑖𝑗 denotes the customized policy distance between agent
𝑖 and agent 𝑗, 𝑝𝑐
𝑖 (𝑧|𝑜) = 𝑓𝜙𝑐 [𝑧|𝜋𝑖 (𝑎|𝑜),𝑜] is the customized repre-
sentations of agent 𝑖’s decisions.
4.2
Case Study of Customized MAPD
To give an example of measuring the customized policy distance,
we refer to the multi-agent spread scenarios in Section 3.4. In this
section, we measure the policy distances of the multi-agent system
based on two aspects: 1) The tendency of moving towards a same
landmark and 2) The tendency of moving towards the matching
landmark.
In this case, we choose the distance 𝑑𝑖𝑠𝑖 between an agent 𝑖 and
the landmark as the customized feature, to link agent’s decisions
and the specific aspects. This distance is sampled at step 𝑡 + 1
corresponding to the observation 𝑜𝑡
𝑖 . Thus, the likelihood term in
Equation 4 corresponds to 𝑝(𝒄|𝑜) = 𝑝(𝑑𝑖𝑠𝑡+1
𝑖
|𝑜𝑡
𝑖 ).
As for the experiments, we use the same parameter settings in
Section 3.4, and record customized policy distances of the multi-
agent system trained for 10000 steps (only 100 steps of data for
auto-encoder training and policy distance computation), the results
are shown in Figure 4.
It can be observed that, when considering the tendency of mov-
ing towards a same landmark (in our experiments the landmark
No.1), the customized policy distances varies significantly depend-
ing on the colors of agents. The customized policy distances among
agents with different colors are three times as big as that among
agents with the same colors. This ratio is similar to the ratio of
policy distances shown in Figure 3, indicating that the tendency of
spreading towards landmark No.1 is one of the factors contributing
to the differences in agent policies.
As for the tendency of moving towards the matching landmarks,
all the customized policy distances become extremely small (all
less than 0.01). This result is reasonable because all agents have the
same goal of moving towards landmarks of their own color, thus
they are consistent in this aspect. These results demonstrate the
effectiveness of our proposed method, in quantifying the differences
in certain aspects of agent policies.
5
DYNAMIC PARAMETER SHARING: AN
APPLICATION OF MAPD FOR MARL
Thanks to the low data requirement of MAPD, it becomes possible
to deploy MAPD online during the training of multi-agent systems.
Having a precise online measurement will enable a real-time evalua-
tion of the policy diversity evolution within the multi-agent system,
and such evolution can be intervened if needed. This section pro-
vides an application of online deployment of MAPD, multi-agent
dynamic parameter sharing (MADPS).
5.1
Multi Agent Dynamic Parameter Sharing
The motivation of MADPS comes from the need for a balance
between policy diversity and parameter sharing in multi-agent
systems. As parameter sharing can improve the efficiency of MARL,
it can also constrain the policy diversity of multi-agent systems,
and consequently affect the performance of MARL. If a dynamic
parameter sharing can be accomplished during training and agents’
policies are appropriately shared when necessary, the multi-agent
system can not only adapt to tasks with emergent diversity, but
also benefit from the sample efficiency of parameter sharing.
The basic idea of MADPS is to fuse the policies of closely re-
lated agents while dividing the policies of agents with significant
differences. We employ the normal/customized policy distance to
measure the similarity between agent policies, and conduct a dy-
namic fusion and division of agent policies. During each fusion
operation, only a portion of the network parameters is shared, to
prevent multi-agent policies from getting stuck in local optima.
Similarly, during each division operation, we only split a portion
of the network parameters. MADPS uses a fusion threshold 𝜖1 and
a division threshold 𝜖2 to determine whether fusion or separation
should be conducted, as shown in Figure 5.
However, when addressing parameter sharing among multiple
agents, the interrelationship between 𝜖1 and 𝜖2 and the order of
fusion and division should be considered carefully. Based on the
triangular inequality property of MAPD, we indicate that the di-
vision threshold should satisfy 𝜖2 ≥ 2𝜖1. In the experiments, we
directly set 𝜖2 = 2𝜖1 to reduce the number of hyperparameters. Ad-
ditionally, an algorithm for the fusion and division of multi-agent
policies is developed, in order to avoid various corresponding con-
tradictions (refer to Appendix 2 for algorithm details and relevant
explanations).
Thus, we introduce this algorithm of multi-agent policy fusion
and division in MARL, resulting in MADPS. MADPS allows a multi-
agent system to begin training with flexible forms of parameter
sharing initialization (e.g., fully shared policies, independent poli-
cies, or selective parameter sharing [4].) In every 𝑇 time steps,
MADPS computes a policy distance matrix of the multi-agent sys-
tem. By comparing the policy distances with predefined thresholds,
MADPS conducts appropriate fusion and division of policies, until
a stable parameter sharing structure is achieved, striking a balance
between parameter sharing and policy diversity.
6
EXPERIMENTS
In Section 3.4 and Section 4.2, we employ a toy environment to
demonstrate the effectiveness of MAPD. In this section, the online
deployment of MAPD and MADPS are applied to more challenging
15
(a) Tendency of moving towards a same landmark
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
SQL Diﬃculty Level in Pre-training
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
Question Diﬃculty Level in Downstream
0.0000
0.0564
0.1796
0.1789
0.1735
0.1731
0.0564
0.0000
0.1804
0.1759
0.1622
0.1678
0.1796
0.1804
0.0000
0.0621
0.1909
0.1900
0.1789
0.1759
0.0621
0.0000
0.1873
0.1857
0.1735
0.1622
0.1909
0.1873
0.0000
0.0508
0.1731
0.1678
0.1900
0.1857
0.0508
0.0000
0.0
0.1
0.2
0.3
0.4
0.5
(b) Tendency of moving towards the correct landmark
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
SQL Diﬃculty Level in Pre-training
Agent1
Agent2
Agent6
Agent7
Agent11
Agent12
Question Diﬃculty Level in Downstream
0.0000
0.0065
0.0072
0.0061
0.0071
0.0071
0.0065
0.0000
0.0076
0.0071
0.0077
0.0063
0.0072
0.0076
0.0000
0.0068
0.0086
0.0078
0.0061
0.0071
0.0068
0.0000
0.0069
0.0060
0.0071
0.0077
0.0086
0.0069
0.0000
0.0068
0.0071
0.0063
0.0078
0.0060
0.0068
0.0000
0.0
0.1
0.2
0.3
0.4
0.5
Figure 4: Customized policy distance matrices in multi-agent spread tasks. Figure (a) demonstrates the policy distances between
agents on the tendency of moving towards a same colored landmark, figure (b) demonstrates the policy distances on the tendency
of moving towards the matching landmark.
We should try fusing
We have to break up
Let’s remain unchanged
% < '""
'"" ≤ % ≤ '#
% > '#
Figure 5: The basic idea of dynamic parameter sharing.
multi-agent spread tasks and StarCraft II micromanagement envi-
ronment (SMAC). By comparing MADPS with other methods of
parameter sharing, we analyze the performance improvement of
MARL algorithms through appropriate policy diversity and param-
eter sharing, and demonstrate the superior performance of MADPS
based on MAPD. The code is available here1.
6.1
Experiment Settings
Multi-agent environments. This part introduces the testing envi-
ronment for our methods. We increase the difficulty of the original
multi-agent spread task, by requiring the agents not only to spread
towards corresponding landmarks, but also to gather as closely
as possible once they reach the landmarks. Besides the original
penalties for collisions and guidance, a sparse reward for encour-
age agents moving closely is added in the overall rewards. This
sparse reward is only given to agents when the distance between
the agents and the landmark is smaller than a threshold, increases
as the distance between the agents decreases, and decreases with
the number of agents (which meeting the threshold condition) de-
creases. Another testing environment used in this study is SMAC.
All the testing methods are evaluated on four super-hard maps in
SMAC, namely, corridor, 6h_vs_8z, 3s5z_vs_3s6z and MMM2. The
first two maps involve homogeneous agent scenarios, while the last
two represent scenarios with heterogeneous agents.
1https://github.com/Harry67Hu/MADPS
Baselines. We compare the proposed dynamic parameter shar-
ing with other methods of parameter sharing. To ensure fairness,
all methods employ the same actor-critic architecture for training,
and the network structures and hyperparameter settings are kept
identical. (More details can be found in Appendix 3.2). The baselines
can be summarized as follows:
• No parameter sharing (NPS): each agent has an independent
network with no parameter sharing.
• Fully parameter sharing (FPS): all agents fully share the same
network parameters.
• Fully parameter sharing with index (FPS-id): all agents share
the network parameters, but a unique index is attached to
each agent’s observation.
• Selective parameter sharing (SePS): before training, agents
are clustered according to learned latent representations,
and parameter sharing is restricted to each agent cluster [4].
6.2
Superior Performance of Our Methods
Our methods and the baselines are tested on four super-hard maps
in SMAC and a series of harder multi-agent spread tasks. The varia-
tions in multi-agent spread tasks include the number of agents, the
number of agent colors, the allocation of agent colors, and the struc-
ture of agent observations. We represent a scene with 𝑥 agents and𝑦
colors as xa_yc , and use super to denote scenes where agent colors
are not evenly allocated, and shuffle to indicate scenes where agent
observations are randomly shuffled. For example, 15a_3c_shuffle
represents a scene with 15 agents, where the agents are evenly
allocated among 3 colors based on their indices (the agents num-
bered 1-5, 6-10, and 11-15 are given the colors No.1, No.2, and No.3,
respectively), and the agent observations are shuffled.
Figure 6 illustrates the performance of all methods on a selection
of the above environments. More experimental results can be found
in Appendix 3.2. It can be observed that FPS cannot learn effective
policies in all multi-agent spread tasks. Because in these scenarios,
agents of different colors move in different directions due to guided
penalties, but these experiences are inappropriately used in the
6. Experiments(正文版本）
FPS
NPS
SePS
MDPS (Ours)
FPS-id
(b) 30a_3c
(a) 15a_3c
(c) 30a_5c_super
(e) MMM2 (SMAC)
(f) 3s5z_vs_3s6z (SMAC)
(d) 15a_3c_shuffle
Figure 6: Performance comparison with baselines on a series of multi-agent spread tasks and super-hard tasks in SMAC.
training of the shared network, causing the policy to fluctuate
between different goals and leading to training failure. The curves of
FPS-id can converge to a value close to 0 in scenarios (a) and (b), but
they still fail to trigger the designed sparse rewards. Additionally,
in the shuffle scenario (d), the shared network cannot effectively
recognize the types of agents due to the shuffled observations, thus
preventing the learning of effective policies.
On the other hand, NPS can achieve a mediocre performance on
all tasks. In multi-agent spread tasks, this approach actually allows
agents to learn unique policies, thus achieving a overall behavior
diversity in multi-agent systems. But in other tasks such as MMM2,
the training of NPS is slow due to its independent network setting,
and it cannot use the experience of other agents to train networks.
By analyzing the curves of NPS, FPS, and FPS-id on different
tasks, we can gain a rough understanding of how important policy
diversity is in each task. For instance, in all multi-agent spread tasks,
policy diversity is crucial for improving algorithm performance, but
excessive policy diversity can hinder agents from achieving higher
rewards. Additionally, the performance difference between FPS and
FPS-id is much smaller in MMM2 compared to 3s5z_vs_3s6z. This
indicates that although the both are heterogeneous scenarios, the
task of 3s5z_vs_3s6z requires more policy diversity for agents than
MMM2.
Both MADPS and SePS encourage policy diversity among agents,
but our MADPS uses a smarter approach. SePS utilizes each agent’s
trajectory to learn a latent representation of its index, and employs
this representation for clustering, thus dividing agent network pa-
rameters based on groups. However, such grouping is fixed during
training, and may be overly deliberate, resulting in less favorable
experimental performance in some scenarios. To ensure a good
performance, SePS requires prior knowledge of each scenario, ne-
cessitating a setting of unique hyperparameters for each scenario.
On the other hand, MADPS only employs one hyperparameter
across a series of scenarios, and can automatically adjust the pa-
rameter sharing scheme during training.
These experimental results demonstrate the effectiveness of the
idea, i.e., dynamically adjusting parameter sharing in MARL. The
essence behind this idea is the indispensable need for appropriate
policy diversity as well as parameter sharing techniques in MARL.
Thanks to our proposed MAPD, we are able to accurately capture
the differences in policies between agents. This enabling a fur-
ther understand of policy diversity for specific tasks, and provides
valuable guidance for the design of MARL algorithms in practical
applications.
7
CONCLUSION
This paper proposes MAPD, a method of quantifying differences in
policies of MARL. Instead of directly measuring the polices, MAPD
learns conditional representations of agents’ decisions, and com-
putes the policy distance by integrating the distances of the latent
distributions. This approach is applicable to various policy forms
of multi-agent systems. The variant of MAPD, customized policy
distance, allows for measuring the behavioral differences between
agents on specific aspects of policy. Based on MAPD, we design
a dynamic parameter sharing algorithm, which can achieve a dy-
namic fusion and division of agents’ policies during the MARL
training. Experimental results demonstrate that our method can
accurately quantifiy the diversity in agent policies, and MADPS
outperforms other baseline methods of parameter sharing. We be-
lieve that MAPD can serve as an important tool for studying and
leveraging behavioral diversity in multi-agent systems, ultimately
promoting the advancement of MARL.
ACKNOWLEDGMENTS
This work was supported by the Strategic Priority Research Pro-
gram of Chinese Academy of Sciences under Grant XDA27030204,
the National Natural Science Foundation of China under Grant
62322316, and the Beijing Nova Program under Grant 20220484077.
REFERENCES
[1] Akshat Agarwal, Sumit Kumar, and Katia Sycara. 2019. Learning transferable
cooperative behavior in multi-agent teams. arXiv preprint arXiv:1906.01202
(2019).
[2] Matteo Bettini, Ajay Shankar, and Amanda Prorok. 2023. Heterogeneous Multi-
Robot Reinforcement Learning. arXiv preprint arXiv:2301.07137 (2023).
[3] Matteo Bettini, Ajay Shankar, and Amanda Prorok. 2023. System Neural Diversity:
Measuring Behavioral Heterogeneity in Multi-Agent Learning. arXiv preprint
arXiv:2305.02128 (2023).
[4] Filippos Christianos, Georgios Papoudakis, Muhammad A Rahman, and Stefano V
Albrecht. 2021. Scaling multi-agent reinforcement learning with selective param-
eter sharing. In International Conference on Machine Learning. PMLR, 1989–1998.
[5] Yan Duan, Xi Chen, Rein Houthooft, John Schulman, and Pieter Abbeel. 2016.
Benchmarking deep reinforcement learning for continuous control. In Interna-
tional conference on machine learning. PMLR, 1329–1338.
[6] Jakob Foerster, Ioannis Alexandros Assael, Nando De Freitas, and Shimon White-
son. 2016. Learning to communicate with deep multi-agent reinforcement learn-
ing. Advances in neural information processing systems 29 (2016).
[7] Aditya Grover, Maruan Al-Shedivat, Jayesh Gupta, Yuri Burda, and Harrison
Edwards. 2018. Learning policy representations in multiagent systems. In Inter-
national conference on machine learning. PMLR, 1802–1811.
[8] Jayesh K Gupta, Maxim Egorov, and Mykel Kochenderfer. 2017. Cooperative
multi-agent control using deep reinforcement learning. In Autonomous Agents
and Multiagent Systems: AAMAS 2017 Workshops, Best Papers, São Paulo, Brazil,
May 8-12, 2017, Revised Selected Papers 16. Springer, 66–83.
[9] Siyi Hu, Chuanlong Xie, Xiaodan Liang, and Xiaojun Chang. 2022. Policy diag-
nosis via measuring role diversity in cooperative multi-agent rl. In International
Conference on Machine Learning. PMLR, 9041–9071.
[10] Haobin Jiang, Yifan Yu, and Zongqing Lu. 2021. Metric Policy Representations
for Opponent Modeling. arXiv preprint arXiv:2106.05802 (2021).
[11] Christos Kaplanis, Murray Shanahan, and Claudia Clopath. 2019. Policy con-
solidation for continual reinforcement learning. arXiv preprint arXiv:1902.00255
(2019).
[12] Chenghao Li, Tonghan Wang, Chengjie Wu, Qianchuan Zhao, Jun Yang, and
Chongjie Zhang. 2021. Celebrating diversity in shared multi-agent reinforcement
learning. Advances in Neural Information Processing Systems 34 (2021), 3991–4002.
[13] Dong Li, Dongbin Zhao, Qichao Zhang, and Yaran Chen. 2019. Reinforcement
learning and deep learning based lateral control for autonomous driving [appli-
cation notes]. IEEE Computational Intelligence Magazine 14, 2 (2019), 83–98.
[14] Xiangyu Liu, Hangtian Jia, Ying Wen, Yujing Hu, Yingfeng Chen, Changjie
Fan, Zhipeng Hu, and Yaodong Yang. 2021. Towards unifying behavioral and
response diversity for open-ended learning in zero-sum games. Advances in
Neural Information Processing Systems 34 (2021), 941–952.
[15] Yuntao Liu, Yuan Li, Xinhai Xu, Donghong Liu, and Yong Dou. 2022. ROGC:
Role-Oriented Graph Convolution Based Multi-Agent Reinforcement Learning.
In 2022 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 1–6.
[16] Ryan Lowe, Yi I Wu, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor
Mordatch. 2017. Multi-agent actor-critic for mixed cooperative-competitive
environments. Advances in neural information processing systems 30 (2017).
[17] Calvin Luo. 2022. Understanding diffusion models: A unified perspective. arXiv
preprint arXiv:2208.11970 (2022).
[18] Muhammad A Masood and Finale Doshi-Velez. 2019. Diversity-inducing policy
gradient: Using maximum mean discrepancy to find a set of diverse policies.
arXiv preprint arXiv:1906.00088 (2019).
[19] Kevin R McKee, Joel Z Leibo, Charlie Beattie, and Richard Everett. 2022. Quanti-
fying the effects of environment and population diversity in multi-agent rein-
forcement learning. Autonomous Agents and Multi-Agent Systems 36, 1 (2022),
21.
[20] Frank Nielsen and Sylvain Boltz. 2011. The burbea-rao and bhattacharyya cen-
troids. IEEE Transactions on Information Theory 57, 8 (2011), 5455–5466.
[21] Tabish Rashid, Mikayel Samvelyan, Christian Schroeder De Witt, Gregory Far-
quhar, Jakob Foerster, and Shimon Whiteson. 2020. Monotonic value function
factorisation for deep multi-agent reinforcement learning. The Journal of Machine
Learning Research 21, 1 (2020), 7234–7284.
[22] Mikayel Samvelyan, Tabish Rashid, Christian Schroeder De Witt, Gregory Far-
quhar, Nantas Nardelli, Tim GJ Rudner, Chia-Man Hung, Philip HS Torr, Jakob
Foerster, and Shimon Whiteson. 2019. The starcraft multi-agent challenge. arXiv
preprint arXiv:1902.04043 (2019).
[23] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George
Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershel-
vam, Marc Lanctot, et al. 2016. Mastering the game of Go with deep neural
networks and tree search. nature 529, 7587 (2016), 484–489.
[24] Kenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. 2019. De-
signing neural networks through neuroevolution. Nature Machine Intelligence 1,
1 (2019), 24–35.
[25] Sainbayar Sukhbaatar, Rob Fergus, et al. 2016. Learning multiagent communica-
tion with backpropagation. Advances in neural information processing systems 29
(2016).
[26] Cédric Villani et al. 2009. Optimal transport: old and new. Vol. 338. Springer.
[27] Tonghan Wang, Heng Dong, Victor Lesser, and Chongjie Zhang. 2020. Roma:
Multi-agent reinforcement learning with emergent roles.
arXiv preprint
arXiv:2003.08039 (2020).
[28] Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson, and
Chongjie Zhang. 2020. Rode: Learning roles to decompose multi-agent tasks.
arXiv preprint arXiv:2010.01523 (2020).
[29] Chongjie Zhang and Victor Lesser. 2013. Coordinating multi-agent reinforcement
learning with limited communication. In Proceedings of the 2013 international
conference on Autonomous agents and multi-agent systems. 1101–1108.
","nanNumerous attempts have been made to measure policy differences in MARL. Some approaches focus on sampling states and recording the ratio of different actions selected by the population, while others employ KL divergence to measure the distances between action-based roles. Furthermore, certain methods utilize the maximum mean discrepancy to compare distributions over trajectories under different policies, whereas others formulate the concept of behavioral diversity as the discrepancies of occupancy measures and utilize f-divergence. However, these approaches suffer from limitations such as failing to satisfy the triangle inequality, which complicates further applications. Some research has delved into the representations of policies. Episodes generated by agent policies are mapped to real-valued vectors, and the Euclidean distances between these vectors are utilized as the policy distances. Other approaches map agent policies to a distribution, and employ KL divergence and one-dimensional Wasserstein distance to handle discrete and continuous action spaces, respectively. These approaches, which map the overall policies to low-dimensional vectors or distributions, inevitably result in significant information loss. The state-of-the-art method for measuring behavioral diversity at a system level calculates the behavioral distance between pairs of agents, and employs the average of these distances as an indicator of system diversity. However, this approach requires assumptions about the type of agent policies and presumes that the observation and action spaces of agents are identical, limiting its generality."
"Deep learning reconstruction methods have emerged as a promising alternative to classical iterative reconstruction methods, but applying such methods to CBCT is often difficult due to memory limitations and the need for fast inference at clinically-relevant resolutions. We propose LIRE+, a learned iterative scheme for fast and memory-efficient CBCT reconstruction, which is a substantially faster and more parameter-efficient alternative to the recently proposed LIRE method.","Computed Tomography (CT) is one of the most used medical imaging modalities nowadays. Similar to many other modern imaging modalities such as MRI, the measurements acquired by a CT scanner - i.e., X-ray projection images taken from a multitude of angles - are not immediately usable in clinic and instead need to undergo the process of reconstruction, wherein they are processed by a reconstruction algorithm and combined into a three-dimensional volume.
An important variation of CT is Cone Beam Computed Tomography (CBCT), where the X-ray source emits rays in a wide cone-shaped beam and the detector is a large flat panel array. In CBCT, both the X-ray source and the detector typically follow circular trajectories around the isocenter, and the detector is sometimes offset to give a larger field of view1. CBCT has applications in interventional radiology2, dentistry3 and image-guided radiation therapy4, however, CBCT image quality remains poor compared to classical CT with helical trajectory for a few reasons. CBCT reconstruction is inherently harder since the data completeness condition for exact reconstruction of the whole volume is not satisfied for circular source/detector orbits5,6. Photon starvation, particularly in highly attenuated areas and in lower-dose scans, results in strong streaking artifacts. Scattering becomes a bigger issue as well, since a large detector panel captures more scattered photons from a wide cone beam of X-rays. Resulting poor Hounsfield Unit (HU) calibration is a limitating factor for applications in e.g. adaptive radiotherapy, where a daily CBCT scan for treatment plan adjustment without the need for registration to a prior CT scan7 would be very desirable.","In order to have a direct comparison for the novel method on the same dataset, we follow the experimental setup of LIRE21, which we briefly recollect in Sections 2.1, 2.2 and 2.3.","On the straight data, we observe that LIRE and LIRE+ noticeably outperform all the baselines. LIRE+ is able to achieve LIRE level of performance using only 9 iterations out of 12.
Full version of LIRE+ with 12 iterations gives a small performance improvement over LIRE.","Multiscale reconstruction can be naturally integrated into invertible learned primal-dual scheme and can accelerate CBCT reconstruction without loss of image quality. Rotational equivariance in a learned primal-dual iterative scheme can be enforced by making the primal components of the network rotationally equivariant, improving robustness of the network to unusual patient orientation.",Equivariant Multiscale Learned Invertible Reconstruction for Cone Beam CT,"Nikita Moriakov, Jan-Jakob Sonke, Jonas Teuwen","Equivariant Multiscale Learned Invertible
Reconstruction for Cone Beam CT
Nikita Moriakov
Jan-Jakob Sonke
Jonas Teuwen
Department of Radiation Oncology, Netherlands Cancer Institute,
the Netherlands
January 23, 2024
Abstract
Background: Cone Beam CT (CBCT) is an essential imaging modality nowadays, but
the image quality of CBCT still lags behind the high quality standards established by
the conventional Computed Tomography (CT). Deep learning reconstruction methods
have emerged as a promising alternative to classical iterative reconstruction methods,
but applying such methods to CBCT is often difficult due to memory limitations and
the need for fast inference at clinically-relevant resolutions.
Purpose: We propose LIRE+, a learned iterative scheme for fast and memory-efficient
CBCT reconstruction, which is a substantially faster and more parameter-efficient al-
ternative to the recently proposed LIRE method.
Methods: LIRE+ is a rotationally-equivariant multiscale learned invertible primal-
dual iterative scheme for CBCT reconstruction. Memory usage is optimized by relying
on simple reversible residual networks in primal/dual cells and patch-wise computa-
tions inside the cells during forward and backward passes, while increased inference
speed is achieved by making the primal-dual scheme multiscale so that the reconstruc-
tion process starts at low resolution and with low resolution primal/dual latent vectors.
Transitions to higher resolutions are performed with nearest upsampling operations,
whose injectivity allows to reverse the operation unambiguously during the backward
pass. Rotational equivariance is accomplished with group equivariant convolutions in-
side the primal cells.
Results: A LIRE+ model was trained and validated on a set of 260 + 22 thorax CT
scans and tested using a set of 142 thorax CT scans with additional evaluation with
and without finetuning on an out-of-distribution set of 79 Head and Neck (HN) CT
scans. Our method surpasses classical and deep learning baselines, including LIRE, on
the thorax test set. For a similar inference time and with only 37 % of the parameter
budget, LIRE+ achieves a +0.2 dB Peak Signal-to-Noise Ratio (PSNR) improvement
over LIRE, while being able to match the performance of LIRE in 45 % less inference
i
arXiv:2401.11256v1  [physics.med-ph]  20 Jan 2024
time and with 28 % of the parameter budget. Rotational equivariance ensures robust-
ness of LIRE+ to patient orientation, while LIRE and other deep learning baselines
suffer from substantial performance degradation when patient orientation is unusual.
On the HN dataset in the absence of finetuning, LIRE+ is generally comparable to
LIRE in performance apart from a few outlier cases, whereas after identical finetuning
LIRE+ demonstrates a +1.02 dB PSNR improvement over LIRE.
Conclusions: Multiscale reconstruction can be naturally integrated into invertible
learned primal-dual scheme and can accelerate CBCT reconstruction without loss of
image quality. Rotational equivariance in a learned primal-dual iterative scheme can
be enforced by making the primal components of the network rotationally equivariant,
improving robustness of the network to unusual patient orientation.
Contents
1
Introduction
1
2
Methods
3
2.1
Tomography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
2.2
Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
2.3
Baseline methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.4
LIRE+ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
3
Results
7
3.1
Memory usage, parameter count, inference speeds . . . . . . . . . . . . . . .
7
3.2
Image quality: thorax CT
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
3.3
Image quality: head & neck CT . . . . . . . . . . . . . . . . . . . . . . . . .
10
4
Discussion
12
ii
1
INTRODUCTION
1
Introduction
Computed Tomography (CT) is one of the most used medical imaging modalities nowadays.
Similar to many other modern imaging modalities such as MRI, the measurements acquired
by a CT scanner - i.e., X-ray projection images taken from a multitude of angles - are not im-
mediately usable in clinic and instead need to undergo the process of reconstruction, wherein
they are processed by a reconstruction algorithm and combined into a three-dimensional
volume.
An important variation of CT is Cone Beam Computed Tomography (CBCT),
where the X-ray source emits rays in a wide cone-shaped beam and the detector is a large
flat panel array. In CBCT, both the X-ray source and the detector typically follow circular
trajectories around the isocenter, and the detector is sometimes offset to give a larger field
of view1. CBCT has applications in interventional radiology2, dentistry3 and image-guided
radiation therapy4, however, CBCT image quality remains poor compared to classical CT
with helical trajectory for a few reasons. CBCT reconstruction is inherently harder since the
data completeness condition for exact reconstruction of the whole volume is not satisfied for
circular source/detector orbits5,6. Photon starvation, particularly in highly attenuated areas
and in lower-dose scans, results in strong streaking artifacts. Scattering becomes a bigger
issue as well, since a large detector panel captures more scattered photons from a wide cone
beam of X-rays. Resulting poor Hounsfield Unit (HU) calibration is a limitating factor for
applications in e.g. adaptive radiotherapy, where a daily CBCT scan for treatment plan
adjustment without the need for registration to a prior CT scan7 would be very desirable.
Deep learning reconstruction methods have drawn a lot interest from the medical imag-
ing community by achieving remarkable results in public reconstruction challenges such as
FastMRI8,9. Reconstruction methods in the learned post-processing family apply a neural
network as a learned operator on top of a classical reconstruction method such as filtered
back-projection (FBP)10,11. Despite the advantages such as typically fast inference, learned
post-processing methods do not provide the neural network with direct access to the under-
lying measurement data, thus some imaging artifacts might be hard to fix. For example,
removing streaks due to photon starvation in CBCT in image domain would require a neural
network with large receptive field due to the size of the streaks. Learned iterative schemes,
on the other hand, are inspired by classical iterative methods such as Landweber iteration,
and embed the forward operator directly in the neural network architecture. Intuitively, this
allows to draw on the theoretical guarantees given by iterative methods but use more flexible
‘neural network prior’ instead of an explicit regularization. Learned Primal-Dual (LPD) al-
gorithm12 is a prominent example of a learned iterative scheme inspired by the Primal-Dual
Hybrid Gradient (PDHG) method13, which combines both image-space and projection-space
operations in an end-to-end trainable network. Image-space computations are performed
by primal blocks and projection-space computations are performed by dual blocks, all pri-
mal/blocks being small convolutional neural networks. LPD framework has been extended
to other modalities as well, such as Digital Breast Tomosynthesis14 and MRI15, but there
are also recent examples of learned iterative schemes for CT16 or MRI17 reconstruction that
work in image domain only.
However, learned iterative schemes and LPD in particular can be hard to scale up to a
1
1
INTRODUCTION
fully three-dimensional modality such as CBCT due to memory limitations. For example,
given a 256 × 256 × 256 FP32 tensor a single convolution layer with 64 features would
already require 8 GB memory to perform the backpropagation operation. One of the first
memory-efficient alternatives is ∂U-Net18, which is a simpler scheme that does not operate
in the projection space.
Memory usage is reduced by relying on a multiscale approach,
where reconstructions obtained at different resolutions are merged together by a final U-
net. iLPD, or invertible learned primal-dual method, has been considered19, where it was
shown that it substantially reduces memory requirements and allows to use longer learned
iterative schemes. For a 3D helical CT setting, iLPD has been combined20 with splitting
the scanning geometry in chunks of data that can be processed independently, however, such
geometry splitting is not possible for CBCT. To address this issue, LIRE21 method was
recently proposed, where a learned invertible primal-dual scheme was augmented with tiling
computation mechanism inside the primal/dual blocks during both training and inference,
allowing to use higher filter counts as well more complex U-net cells inside primal blocks.
LIRE inference takes around 30 seconds on NVIDIA A100 accelerator with clinically relevant
geometry and resolution, and it is desirable to speed it up for future clinical application. A
logical step would be to try to combine learned invertible primal-dual scheme and multiscale
reconstruction1, but it has not been done in literature at the moment, even though invertible
flows that incorporate multiscale latent codes are well known in generative modeling22.
Parallel to the development of new learned iterative schemes for reconstruction, the study
of natural symmetries of learning tasks and the means of building these symmetries into
neural network architectures has been a fruitful recent research direction in inverse problems
and deep learning in general. For instance, when a patient is rotated we expect the new
reconstruction to be a rotated version of the original reconstruction. For convolutional neural
networks, this problem is addressed with group equivariant convolutions23, which often allow
to achieve state of the art results at reduced parameter cost on image classification tasks.
Group equivariant convolutional neural networks have been applied to inverse problems
with learned iterative schemes as well24, but not in the context of CBCT and learned-primal
dual family of methods. Additionally, even though group equivariant convolutional neural
networks allow to reduce the parameter cost, the dimensionality of internal representations
is typically increased2 resulting in increased inference times. Therefore, including group-
equivariant operations in CBCT reconstruction further necessitates the search for fast and
memory efficient learned iterative schemes.
In this work, we address these research questions and improve upon the LIRE method
for CBCT reconstruction by designing LIRE+, a faster and more parameter-efficient learned
primal-dual scheme yielding similar or better reconstruction quality, which additionally en-
joys rotational equivariance for improved robustness to unusual patient orientation.
We
perform extensive evaluation of LIRE+ and the baselines using image quality metrics such
as PSNR and Structural Similarity Index Measure (SSIM), as well as HU Mean Absolute
1It might appear counterintuitive, since the input and the output in a reversible neural network have the
same dimensionality, but will be explained in Section 2.4.
2This is the consequence of a rule of thumb23, where the number of filters is reduced by the square root
of the group size to approximately match the total parameter count.
2
2
METHODS
Error (MAE).
2
Methods
In order to have a direct comparison for the novel method on the same dataset, we follow
the experimental setup of LIRE21, which we briefly recollect in Sections 2.1, 2.2 and 2.3.
2.1
Tomography
The cone-beam transform operator, or simply the projection operator, is defined as an integral
operator
P(x)(t, u) =
Z
Lt,u
x(z)dz,
(1)
where x : ΩX → R is a function specifying attenuation coefficients in the spatial domain
ΩX ⊂ R3 and Lt,u is a line from the source to the detector element u at time t. P is a linear
operator, and Hermitian3 adjoint P∗ of P is called the backprojection operator. Using the
projection operator P, we model noisy CBCT acquisition as
y = Poisson(I0 · e−Px),
(2)
where I0 is the unattenuated X-ray photon count. The inverse problem of CBCT reconstruc-
tion is then to determine the tissue attenuation coefficients x from the noisy projection data
y.
We will approach the inverse problem in (2) by finding a Bayes estimator parametrized
by a neural network. The goal for the Bayes estimator ˆxBayes in general is to minimize the
expected cost
L(ˆx) = E(x,y)∼π L(x, ˆx(y))
(3)
over all estimators ˆx, where π is the distribution of pairs (x, y) of tomographic volumes x
with the corresponding projection images y, and L is a fixed cost function. In this work,
a sum of mean absolute error and a Structural Similarity loss will play the role of the cost
function L, the optimal estimator in (3) will be chosen from a certain class of neural networks,
and minimization of the cost in (3) with respect to the parameters of the network will be
carried out via minibatch stochastic gradient descent. We refer to Section 5.1.225 for more
information on Bayes estimators.
2.2
Data
In this work we simulate a common clinical acquisition geometry for a Linac-integrated
CBCT scanner from Elekta1 with a medium field-of-view setting, offset detector, a full 2π
scanning trajectory and 720 projections. The source-isocenter distance is 1000 mm and the
3For suitably defined L2 function spaces.
3
2.3
Baseline methods
2
METHODS
isocenter-detector plane distance is 536 mm. The detector is offset by 115 mm to the side
in the direction of rotation to give an increased Field of View. Square detector panel with a
side of 409.6 mm and 256 × 256 pixel array was used.
To train and evaluate our model, we used the same thorax CT and head & neck CT
data as LIRE21, consisting of a dataset of 424 thorax CT scans with isotropic spacing of
1 mm and a dataset of 79 head & neck CT scans with anisotropic spacing of between 0.9
mm and 1.0 mm for axial plane and between 1.0 mm and 1.6 mm for the perpendicular
direction. Both datasets had axial slice of 512 × 512 voxels. All data was downsampled to
2 mm isotropic resolution, resulting in volumes with 2563 voxels. No denoising was applied
to the CT scans, since unsupervised denoising could blur very fine details such as fissures
leading to over-optimistic image quality metrics. Study approval was granted by the IRB of
our institute, IRBd20-008.
The thorax CT dataset was split into a training set of 260 scans, a validation set of 22
scans and a test set of 142 scans. The additional head & neck dataset was used in two
regimes: for testing the models on out-of-distribution data and for additional finetuning
experiment, where 79 volumes were randomly partitioned into a finetuning set of 8 volumes,
2 volumes for validation and 69 for testing4. To simulate noisy projection data from the
CT scans, Hounsfield units were converted into attenuation coefficients using µ = 0.2 cm−1
as the water linear attenuation coefficient. Attenuated projection data was corrupted by
Poisson noise with I0 = 30000 photons in (2).
2.3
Baseline methods
We provide a direct comparison with LIRE given that we are using the same dataset, and to
add context to this comparison we will cite the following baselines from the original work21:
FBP26, PDHG13 with Total Variation (TV) regularisation, U-net27 and Uformer28,29,30 with
FBP input, as well as LIRE itself. A new additional baseline is ∂U-Net18, which plays the
role of an alternative memory efficient and fast learned iterative scheme. Our implementation
of ∂U-Net relies on the open-source implementation5 from the author, where the base filter
count was increased from 12 to 32 in order to get closer to the filter counts used by LIRE and
LIRE+ to make the comparison fair but fit into memory budget. We switched from batch
normalization to instance normalization in our version of ∂U-Net, since batch normalization
resulted in unstable convergence, presumably, because of very small batch size. As input
to ∂U-net, we provided the FBP reconstruction and the field-of-view tensor V defined later
in Section 2.4. The same augmentation strategy as LIRE+ and the same loss function (see
Section 2.4) were used. To train ∂U-net, Adam optimizer31 was employed with batch size of
8 on two NVIDIA Quadro RTX 8000 cards via gradient accumulation, initial learning rate
of 0.0001 and a plateau scheduler with linear warm-up and 10 epoch patience. The best-
performing model on the validation set was chosen for testing. For the finetuning experiment
4Four outlier head & neck cases, discussed in Section 3, were used as test data.
5Adapted to 3D and our projector/backprojector code from https://github.com/asHauptmann/
multiscale
4
2.4
LIRE+
2
METHODS
on HN data, the corresponding pretrained ∂U-net or LIRE model was taken and finetuned
for 50 epochs with a quarter of the initial learning rate using a combined dataset of 8 HN
CT volumes and 8 randomly chosen thorax CT volumes; best performing model on HN
validation set was picked for the final testing on HN test data.
2.4
LIRE+
Algorithm 1 LIRE+
1: procedure reconstruct(y, P, P∗, θ, V )
2:
α ← 50%
▷ Set resolution to 50%
3:
y ← ProjDown(y)
▷ Downsample & subsample projections
4:
x ← P∗
α(y)
▷ Normalized backprojection initialization
5:
V ← Downsample(V )
▷ Downsample FoV tensor
6:
I ← []
▷ Initialize output list
7:
f ← x⊗8 ∈ X8
▷ Initialize primal vector
8:
h ← y⊗8 ∈ U 8
▷ Initialize dual vector
9:
for i ← 1, . . . , 12 do
10:
d1, d2 ← Splt(h)
▷ Split dual channels
11:
p1, p2 ← Splt(f)
▷ Split prime channels
12:
pop ← Pα([p2, x]⊕)
▷ Project p2 and x
13:
d2 ← d2 + Γθd
i ([pop, d1, y]⊕)
▷ Upd. d2
14:
bop ← P∗
α(d2)
▷ Backproject d2
15:
LW ← P∗
α(Pα(x) − y)
▷ Landweber term
16:
p2 ← p2 + Λθp
i ([bop, p1, x, LW , V ]⊕)
▷ Upd. p2
17:
h ← [d1, d2]⊕
▷ Combine new dual
18:
f ← [p1, p2]⊕
▷ Combine new primal
19:
x ← x + Conv3d(f, θo
i )
▷ Update reconstruction
20:
I ← I + [x]
▷ Append x to output list
21:
h ← Perm(h, θm
i )
▷ Permute dual channels w. θm
i
22:
f ← Perm(f, θm
i )
▷ Permute prim. channels w. θm
i
23:
if i == 6 then
24:
f, h ← Upsample(f), Upsample(h)
▷ Upsample latent vectors
25:
x ← Upsample(x)
▷ Upsample reconstruction
26:
y, V , α ← y, V, 100%
▷ Switch to full resolution
27:
end if
28:
end for
29:
return I
30: end procedure
LIRE+ method is an unrolled learned iterative scheme, which extends LIRE by relying on
multiscale reconstruction strategy to improve the inference speed, equivariant primal cells for
5
2.4
LIRE+
2
METHODS
higher parameter efficiency and robustness to orientation, as well as centered weight normal-
ization to improve convergence stability. Similar to LIRE, the memory footprint of LIRE+ is
reduced by combining invertibility for the network as a whole and patch-wise computations
for local operations. An optional CPU-GPU memory streaming mechanism is implemented,
which would keep entire primal/dual vectors in CPU memory and only send the patch re-
quired for computing the primal/dual updates or gradients into the GPU. We refer the reader
to the original work21 for the discussion on invertibility and patch-wise computations. To
justify the combination of multiscale reconstruction and invertibility, we make the following
observation: if Λ : Rn → Rn is an invertible neural network and ι : Rn → Rm, m ≥ n is some
fixed injective differentiable mapping such as nearest upsampling operation, then the input
x ∈ Rn can be restored from the output ι(Λ(x)) ∈ Rm unambigously by first inverting ι and
then Λ, so the gradients for the parameters of Λ can be computed without storing the activa-
tions during the forward pass. The algorithm was implemented as a C++/CUDA extension
for PyTorch32 in order to maximize memory efficiency, training and inference speed.
LIRE+, given by function RECONSTRUCT(y, P, P∗, θ, V ) in Algorithm 1, consists of 12
iterations and uses primal/dual latent vectors with 8 channels. Here y is log-transformed
and scaled projection data, P and P∗ are normalized projection and backprojection operators
respectively, θ is a list of parameters and V is an auxiliary Field-of-View tensor defined as
V (p) =





1
p is seen from all projection angles
0.5
p is seen from half of the proj. angles
0
otherwise.
The parameters θ are partitioned into 4 parameter groups, where {θp
i }12
i=1 are the primal
block parameters, {θd
i }12
i=1 are the dual block parameters, {θo
i }12
i=1 are the output convolution
parameters and {θm
i }12
i=1 are the permutation parameters.
For every i, the permutation
θm
i
is some fixed permutation of [1, 2, . . . , 8] which is randomly initialized during model
initialization and stored as a model parameter; we require that θm
i
mixes the first and the
second half of [1, 2, . . . , 8]. Channel-wise concatenation of tensors z1, z2, . . . , zk is denoted
by [z1, z2, . . . , zk]⊕, conversely, function Splt(z) splits tensor z with 2n channels into two
halves along the channel dimension. Function Perm(z, ρ) permutes tensor z with n channels
along the channel dimension with the permutation ρ ∈ Sym(n).
Function Upsample(z)
performs nearest upsampling of z to twice the resolution, Downsample(z) downsamples tensor
z to half the resolution with linear interpolation and function ProjDown(z) downsamples
projection tensor z to half the resolution and drops every second projection. For resolution
α ∈ [50%, 100%], we write Pα, P∗
α for the projection and backprojection operator respectively
at α resolution, where for half resolution only every second projection from the original data
is computed.
LIRE+ uses a number of convolutional blocks. Conv3d(·, θo
i ) denotes a 1×1×1 convolution
with parameters θo
i . Γθd
i denotes i-th dual block with parameters θd
i comprised of 3 layers of
3 × 3 × 3 convolutions with 96, 96 and 4 filters respectively and LeakyReLU activation after
the first and the second convolution layers. i-th primal block with parameters θp
i is denoted
by Λθp
i , which is comprised of 3 layers of 3×3×3 P4-equivariant convolutions with 64, 64 and
6
3
RESULTS
4 filters respectively and LeakyReLU activation after the first and the second convolution
layers. That is, input to a primal block has 8 channels and no ‘group dimension’, the first
and the second convolution layers in a primal block return tensors with 64 × 4 channels
(number of filters × group size), while output of the last convolution has 4 × 4 channels.
This output is then averaged over the group dimension, making the primal block equivariant
w.r.t. the action of P4 (i.e., 90-degree rotations along the z-axis). We used centered weight
normalization33 for the primal/dual block parameters to improve training stability.
LIRE+ training procedure is identical to LIRE, importantly, the loss function is a
weighted sum of L1 norm ∥ · ∥ and SSIM loss, taken separately over the full field of view
region (i.e., voxels present in at least half of the projections) and the partial field of view
region (i.e., voxels present in at least one projection). Mathematically,
L(x, y) = ∥x − y∥FullFoV + α1 · (1.0 − SSIMFullFoV(x, y))+
+ α2 · ∥x − y∥PartFoV + α2 · α1 · (1.0 − SSIMPartFoV(x, y)),
where α1 = 0.5 and α2 was set to 0.1 initially and then reduced to 0.01 after first learning rate
decay step. The algorithm returns a list I = [x1, x2, . . . , x12] of reconstructions where the
first 6 elements have half the resolution and the last 6 elements have full resolution. Recon-
struction losses for all x ∈ I are computed and summed, the ground truth is downsampled to
compute the loss for the half-resolution reconstructions x1, . . . , x6. As a data augmentation
strategy, we randomply flipped along the left-right and the head-foot axes. Isocenter was
chosen by adding a random offset sampled from an isotropic Gaussian distribution with 0
mm mean and a standard deviation of 100 mm to the volume center.
LIRE+ was trained to reconstruct complete volumes. Two NVIDIA A100 GPUs with
gradient accumulation were used with gradient accumulation enabled to achieve effective
batch size of 8. Adam optimizer31 was employed with an initial learning rate of 0.001 and
a plateau scheduler with linear warm-up and 10 epoch patience. At the end of each epoch
models were evaluated, the best model was picked for testing. For the finetuning experiment
on HN data, LIRE+ was finetuned for 50 epochs with a quarter of the initial learning rate
using a combined dataset of 8 HN CT volumes and 8 randomly chosen thorax CT volumes;
best performing model on HN validation set was picked for the final testing on HN test data.
3
Results
3.1
Memory usage, parameter count, inference speeds
For the internal patch-based computations inside LIRE+ we set the patch size to 128×128×
128, resulting in roughly 30 GB VRAM usage per single volume during training. Reducing
the patch size to 32 × 32 × 32 and enabling CPU-GPU streaming decreased the usage to
roughly 12 GB VRAM per single volume. For ∂U-net, GPU memory usage during training
was around 48 GB per volume.
The total parameter counts are: 24M parameters for LIRE, 7M for LIRE+ with 9 iter-
ations, 9M for LIRE+ with 12 iterations and 27M for ∂U-net. We measured the following
7
3.2
Image quality: thorax CT
3
RESULTS
per-volume inference times on NVIDIA A100 accelerator: 31 seconds for LIRE, 32 seconds
for LIRE+ with 12 iterations, 17 seconds for LIRE+ with 9 iterations and 4 seconds for
∂U-net.
3.2
Image quality: thorax CT
Table 1: Test results on thorax CT (best result in bold), mean ± std.dev.
Method
PSNR
SSIM
MAE 2mm (HU)
MAE 4mm (HU)
FBP
20.05 ± 2.30
0.66 ± 0.07
270.70 ± 19.78
261.29 ± 21.36
TV
29.23 ± 2.87
0.79 ± 0.09
85.07 ± 24.10
35.26 ± 8.32
Uformer
31.62 ± 2.44
0.81 ± 0.06
62.91 ± 7.44
43.66 ± 5.74
U-Net
34.29 ± 2.71
0.84 ± 0.06
47.86 ± 7.34
21.70 ± 3.56
∂U-Net
34.55 ± 2.72
0.90 ± 0.05
46.14 ± 7.01
15.71 ± 2.71
LIRE
35.14 ± 2.76
0.91 ± 0.04
43.02 ± 6.88
13.20 ± 2.64
LIRE+ 9 it.
35.15 ± 2.79
0.91 ± 0.05
42.89 ± 6.99
13.58 ± 2.66
LIRE+ 12 it.
35.38 ± 2.82
0.91 ± 0.04
41.86 ± 7.01
13.11 ± 2.64
Table 2: Test results on rotated thorax CT (best result in bold), mean ± std.dev.
Method
PSNR
SSIM
MAE 2mm (HU)
MAE 4mm (HU)
Uformer
29.53 ± 2.58
0.80 ± 0.06
70.70 ± 8.83
49.06 ± 6.64
U-Net
29.98 ± 2.62
0.83 ± 0.06
60.48 ± 8.55
27.99 ± 3.73
∂U-Net
33.64 ± 2.66
0.89 ± 0.05
49.65 ± 6.95
17.50 ± 2.82
LIRE
34.71 ± 2.72
0.91 ± 0.05
44.60 ± 6.85
14.17 ± 2.78
LIRE+ 9 it.
35.15 ± 2.79
0.91 ± 0.05
42.89 ± 6.99
13.58 ± 2.66
LIRE+ 12 it.
35.38 ± 2.82
0.91 ± 0.04
41.86 ± 7.01
13.12 ± 2.64
We perform extensive evaluation of LIRE+ and the baselines using image quality met-
rics such as PSNR and SSIM, which are computed for the reconstructed and the ground
truth attenuation values, as well as MAE in Hounsfield Units. MAE is computed at 2 mm
resolution as well as at the reduced resolution of 4 mm, where both the ground truth and
the reconstruction are binned. The additional MAE computation on downsampled data is
designed to provide more insight about HU calibration for radiotherapy applications, since
the ‘ground truth’ CT scans were not denoised and thus remain quite noisy as can be seen
from the difference maps.
In Tables 1 and 2 we report these metrics on thorax CT data for straight and rotated pa-
tient orientation respectively, and the corresponding box plots are provided in Figures 1 and
2. Since the classical reconstruction methods such as FBP and TV are not trained on specific
patient orientation, they are robust to rotations by design and are ommited in the second
comparison. On the straight data, we observe that LIRE and LIRE+ noticeably outperform
all the baselines. LIRE+ is able to achieve LIRE level of performance using only 9 iterations
8
3.3
Image quality: head & neck CT
3
RESULTS
out of 12. Full version of LIRE+ with 12 iterations gives a small performance improvement
over LIRE. ∂U-net, while being fast, cannot match the reconstruction quality achieved by
LIRE/LIRE+, even though it has more parameters. On the rotated data, we note that only
LIRE+ is able to maintain the reconstruction quality thanks to the rotationally-equivariant
primal cells, while all alternative models suffer from various amounts of performance degra-
dation. It is wothwhile to note that the performance degradation is more pronounced in the
learned post-processing baselines (Uformer and U-net), while learned iterative schemes seem
to be more robust.
Examples of axial image slices of a ground truth image and the corresponding reconstruc-
tions with ∂U-net, LIRE and LIRE+ are presented in Fig. 3 with the respective difference
maps in Fig. 4. Coronal view is provided in Fig. 5 and Fig. 6. For the image samples the
HU range equals (-1000, 800) and (-1350, 150) for the ROI, while for the difference maps
HU range equals (-1000, 800) and (-200, 200) for the ROI. From these examples we can
see that LIRE+ gives sharper images with better HU calibration, while ∂U-net appears to
slightly blur lung fissures. The difference maps suggest that particularly for LIRE+ image
noise plays a large role in the image quality metrics.
FBP
TV
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
20
25
30
35
40
PSNR
FBP
TV
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
0.5
0.6
0.7
0.8
0.9
1.0
SSIM
FBP
TV
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
50
100
150
200
250
300
MAE 2mm
FBP
TV
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
0
50
100
150
200
250
300
MAE 4mm
Figure 1: Thorax CT image quality metrics, straight orientation
9
3.3
Image quality: head & neck CT
3
RESULTS
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
26
28
30
32
34
36
38
40
PSNR
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
0.70
0.75
0.80
0.85
0.90
0.95
1.00
SSIM
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
30
40
50
60
70
80
90
MAE 2mm
Uformer
U-Net
U-Net
LIRE
LIRE+ 9it
LIRE+ 12it
10
20
30
40
50
60
MAE 4mm
Figure 2: Thorax CT image quality metrics, rotated orientation
(a)
(b)
(c)
(d)
Figure 3: (a) Axial slice of Thorax CT, HU range=(-1000, 800) and (-1350, 150) for ROI,
(b) ∂U-net, (c) LIRE, and (d) LIRE+ 12 it.
3.3
Image quality: head & neck CT
We perform evaluation on the out-of-distribution HN dataset in two regimes. Firstly, we
evaluate the reconstruction performance of LIRE+, LIRE and ∂U-net without any finetuning
and provide the metrics in Table 3 in normal font. Inspection of the metrics and the images
10
3.3
Image quality: head & neck CT
3
RESULTS
(a)
(b)
(c)
(d)
Figure 4: (a) Axial slice of Thorax CT, (b) ∂U-net error, HU range=(-1000, 800) and (-200,
200) for ROI, (c) LIRE error, and (d) LIRE+ 12 it. error
(a)
(b)
(c)
(d)
Figure 5: (a) Coronal slice of Thorax CT, HU range=(-1000, 800) and (-1350, 150) for ROI,
(b) ∂U-net, (c) LIRE, and (d) LIRE+ 12 it.
(a)
(b)
(c)
(d)
Figure 6: (a) Coronal slice of Thorax CT, (b) ∂U-net error, HU range=(-1000, 800) and
(-200, 200) for ROI, (c) LIRE error, and (d) LIRE+ 12 it. error
revealed that there are 4 outlier cases6 on which LIRE+ performs poorly, while on the
majority of cases LIRE+ is comparable to LIRE. Reconstruction metrics on the HN set
with the outlier cases excluded are provided in Table 3 in italic font, indicating that LIRE+
might actually outperform LIRE on a majority of HN cases.
For comparison, iterative
reconstruction baseline is provided as well.
6The outliers are all very big or tiny patients.
11
4
DISCUSSION
Table 3: Test results on Head & Neck CT without finetuning, mean ± std.dev. Results on
test excluding the outliers given in italic.
Method
PSNR
SSIM
MAE 2mm (HU)
MAE 4mm (HU)
TV
37.86 ± 1.36
37.92 ± 1.33
0.94 ± 0.02
0.94 ± 0.02
30.72 ± 5.63
30.46 ± 5.37
15.48 ± 3.20
15.25 ± 2.74
∂U-net
40.24 ± 1.57
40.47 ± 1.18
0.97 ± 0.01
0.98 ± 0.01
17.81 ± 4.33
17.00 ± 2.11
9.20 ± 2.51
8.74 ± 1.31
LIRE
41.21 ± 1.41
41.43 ± 1.22
0.97 ± 0.01
0.97 ± 0.01
17.75 ± 2.90
17.23 ± 1.87
10.33 ± 1.57
10.07 ± 1.08
LIRE+ 9 it.
39.66 ± 9.52
41.78 ± 1.66
0.95 ± 0.15
0.98 ± 0.01
203.32 ± 1028.00
15.68 ± 2.68
245.77 ± 1288.28
7.81 ± 1.27
LIRE+ 12 it.
40.52 ± 8.66
42.45 ± 1.76
0.95 ± 0.15
0.98 ± 0.01
119.90 ± 548.44
14.09 ± 2.82
139.62 ± 675.60
6.96 ± 1.51
Table 4: Test results on Head & Neck CT with finetuning (best result in bold), mean ±
std.dev.
Method
PSNR
SSIM
MAE 2mm (HU)
MAE 4mm (HU)
∂U-Net
41.57 ± 1.33
0.98 ± 0.01
14.72 ± 2.87
7.31 ± 1.80
LIRE
42.76 ± 1.52
0.99 ± 0.01
13.02 ± 2.14
5.77 ± 1.00
LIRE+ 9 it.
43.17 ± 1.83
0.99 ± 0.01
12.54 ± 2.25
5.34 ± 1.01
LIRE+ 12 it.
43.82 ± 1.93
0.99 ± 0.01
11.50 ± 2.21
4.82 ± 1.02
Secondly, to further investigate the generalization behaviour of LIRE+, we report the
results of the finetuning experiment in Table 4. Interestingly, after identical finetuning, both
full LIRE+ and LIRE+ with only 9 iterations demonstrate substantially better performance
compared to LIRE and ∂U-net. The better generalization of LIRE+ after finetuning on a
limited amount of data is in agreement with the lower parameter count of the new model.
Axial image slices from finetuned HN models are provided in Figure 7, where HU range is
set to (-1000, 1000).
4
Discussion
We have presented LIRE+, a fast, compact and memory-efficient multiscale equivariant
learned iterative scheme for CBCT reconstruction. Compared to LIRE21, LIRE+ has sub-
stantially lower parameter count, similar inference time for better image quality or twice
faster inference for similar image quality, and enjoys additional robustness to patient orien-
tation, which we achieve by using rotationally-equivairant primal blocks. It is noteworthy
that LIRE+ is the smallest deep learning reconstruction model in our comparison, but it
still gives the best image quality. On the out-of-distribution head & neck dataset, we have
observed that LIRE+ is generally comparable to LIRE but has some outlier cases, how-
12
REFERENCES
REFERENCES
(a)
(b)
(c)
(d)
Figure 7: (a) Axial slice of HN CT, HU range=(-1000, 1000), (b) ∂U-net, (c) LIRE, and (d)
LIRE+ 12 it.
ever, after identical finetuning on a limited amount of head & neck data LIRE+ strongly
outperforms LIRE and ∂U-net.
The authors would like to acknowledge the Research High Performance Computing
(RHPC) facility of the Netherlands Cancer Institute (NKI).
References
[1] D. L´etourneau, J. W. Wong, M. Oldham, M. Gulam, L. Watt, D. A. Jaffray, J. H.
Siewerdsen, and A. A. Martinez, Cone-beam-CT guided radiation therapy: technical
implementation, Radiother Oncol 75, 279–286 (2005).
[2] C. Floridi, A. Radaelli, N. Abi-Jaoudeh, M. Grass, M. Lin, M. Chiaradia, J. F.
Geschwind, H. Kobeiter, E. Squillaci, G. Maleux, A. Giovagnoni, L. Brunese, B. Wood,
G. Carrafiello, and A. Rotondo, C-arm cone-beam computed tomography in interven-
tional oncology: technical aspects and clinical applications, La Radiologia medica 119,
521–532 (2014).
[3] A. Dawood, S. Patel, and J. Brown, Cone beam CT in dental practice, Br Dent J 207,
23–28 (2009).
[4] D. A. Jaffray, J. H. Siewerdsen, J. W. Wong, and M. A. A,
Flat-panel cone-beam
computed tomography for image-guided radiation therapy,
Int J Radiat Oncol Biol
Phys 53, 1337–1349 (2002).
[5] C. Maaß, F. Dennerlein, F. Noo, and M. Kachelrieß, Comparing short scan CT re-
construction algorithms regarding cone-beam artifact performance, in IEEE Nuclear
Science Symposuim Medical Imaging Conference, pages 2188–2193, 2010.
[6] H. K. Tuy, An Inversion Formula for Cone-Beam Reconstruction, SIAM Journal on
Applied Mathematics 43, 546–552 (1983).
13
REFERENCES
REFERENCES
[7] J. J. Sonke, M. Aznar, and C. Rasch, Adaptive Radiotherapy for Anatomical Changes,
Semin Radiat Oncol 29, 245–257 (2019).
[8] M. J. Muckley et al., Results of the 2020 fastMRI Challenge for Machine Learning MR
Image Reconstruction, arXiv e-prints , arXiv:2012.06318 (2020).
[9] Y. Beauferris, J. Teuwen, D. Karkalousos, N. Moriakov, M. Caan, L. Rodrigues,
A. Lopes, H. Pedrini, L. Rittner, M. Dannecker, V. Studenyak, F. Gr¨oger, D. Vyas,
S. Faghih-Roohi, A. K. Jethi, J. C. Raju, M. Sivaprakasam, W. Loos, R. Frayne, and
R. Souza, Multi-channel MR Reconstruction (MC-MRRec) Challenge – Comparing Ac-
celerated MR Reconstruction Models and Assessing Their Genereralizability to Datasets
Collected with Different Coils, 2020.
[10] K. H. Jin, M. T. McCann, E. Froustey, and M. Unser,
Deep Convolutional Neural
Network for Inverse Problems in Imaging, IEEE Transactions on Image Processing 26,
4509–4522 (2017).
[11] S. Zhi, M. Kachelrieß, F. Pan, and X. Mou, CycN-Net: A Convolutional Neural Network
Specialized for 4D CBCT Images Refinement, IEEE Transactions on Medical Imaging
40, 3054–3064 (2021).
[12] J. Adler and O. ¨Oktem, Learned Primal-Dual Reconstruction, IEEE Transactions on
Medical Imaging 37, 1322–1332 (2018).
[13] A. Chambolle and T. Pock, A First-Order Primal-Dual Algorithm for Convex Problems
with Applications to Imaging, J. Math. Imaging Vis. 40, 120–145 (2011).
[14] J. Teuwen, N. Moriakov, C. Fedon, M. Caballo, I. Reiser, P. Bakic, E. Garc´ıa, O. Diaz,
K. Michielsen, and I. Sechopoulos, Deep learning reconstruction of digital breast to-
mosynthesis images for accurate breast density and patient-specific radiation dose esti-
mation, Medical Image Analysis 71, 102061 (2021).
[15] Z. Ramzi, P. Ciuciu, and J.-L. Starck,
Benchmarking MRI Reconstruction Neural
Networks on Large Public Datasets, Applied Sciences (2020), A short version of this
work has been accepted to the 17th International Symposium on Biomedical Imaging
(ISBI 2020), April 3-7 2020, Iowa City, IO, USA.
[16] G. Chen, X. Hong, Q. Ding, Y. Zhang, H. Chen, S. Fu, Y. Zhao, X. Zhang, H. Ji,
G. Wang, Q. Huang, and H. Gao, AirNet: Fused analytical and iterative reconstruction
with deep neural network regularization for sparse-data CT, Medical Physics 47, 2916–
2930 (2020).
[17] G. Yiasemis, J.-J. Sonke, C. S´anchez, and J. Teuwen, Recurrent Variational Network:
A Deep Learning Inverse Problem Solver Applied to the Task of Accelerated MRI Re-
construction, in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), pages 732–741, 2022.
14
REFERENCES
REFERENCES
[18] A. Hauptmann, J. Adler, S. Arridge, and O. ¨Oktem,
Multi-Scale Learned Iterative
Reconstruction, IEEE Transactions on Computational Imaging 6, 843–856 (2020).
[19] J. Rudzusika, B. Baji´c, O. ¨Oktem, C.-B. Sch¨onlieb, and C. Etmann, Invertible Learned
Primal-Dual, 2021.
[20] B. Baji´c, O. ¨Oktem, and J. Rudzusika, 3D helical CT reconstruction with memory
efficient invertible Learned Primal-Dual method, 2022.
[21] N. Moriakov, J.-J. Sonke, and J. Teuwen, End-to-end memory-efficient reconstruction
for cone beam CT, Medical Physics 50, 7579–7593 (2023).
[22] D. P. Kingma and P. Dhariwal, Glow: Generative Flow with Invertible 1x1 Convo-
lutions, in Advances in Neural Information Processing Systems, edited by S. Bengio,
H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, volume 31,
Curran Associates, Inc., 2018.
[23] T. Cohen and M. Welling, Group Equivariant Convolutional Networks, in Proceedings
of The 33rd International Conference on Machine Learning, edited by M. F. Balcan
and K. Q. Weinberger, volume 48 of Proceedings of Machine Learning Research, pages
2990–2999, New York, New York, USA, 2016, PMLR.
[24] E. Celledoni, M. J. Ehrhardt, C. Etmann, B. Owren, C.-B. Sch¨onlieb, and F. Sherry,
Equivariant neural networks for inverse problems, Inverse Problems 37, 085006 (2021).
[25] J. Kaipio and E. Somersalo, Statistical and Computational Inverse Problems, volume
160 of Applied Mathematical Sciences, Springer-Verlag, New York, 2005.
[26] L. A. Feldkamp, L. C. Davis, and J. W. Kress, Practical cone-beam algorithm, J. Opt.
Soc. Am. A 1, 612–619 (1984).
[27] ¨O. C¸i¸cek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger, 3D U-Net:
Learning Dense Volumetric Segmentation from Sparse Annotation, in Medical Image
Computing and Computer-Assisted Intervention – MICCAI 2016, edited by S. Ourselin,
L. Joskowicz, M. R. Sabuncu, G. Unal, and W. Wells, pages 424–432, Cham, 2016,
Springer International Publishing.
[28] Z. Wang, X. Cun, J. Bao, W. Zhou, J. Liu, and H. Li, Uformer: A General U-Shaped
Transformer for Image Restoration, in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), pages 17683–17693, 2022.
[29] B. Yang, Y. Liu, J. Zhu, J. Dai, and K. Men, Deep learning framework to improve
the quality of cone-beam computed tomography for radiotherapy scenarios, Medical
Physics 50, 7641–7653 (2023).
15
REFERENCES
REFERENCES
[30] X. Chen, Y. Liu, B. Yang, J. Zhu, S. Yuan, X. Xie, Y. Liu, J. Dai, and K. Men, A
more effective CT synthesizer using transformers for cone-beam CT-guided adaptive
radiotherapy, Frontiers in Oncology 12 (2022).
[31] D. P. Kingma and J. Ba, Adam: A Method for Stochastic Optimization, arXiv e-prints
, arXiv:1412.6980 (2014).
[32] A. Paszke et al.,
PyTorch: An Imperative Style, High-Performance Deep Learning
Library, in Advances in Neural Information Processing Systems 32, edited by H. Wal-
lach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, and R. Garnett, pages
8024–8035, Curran Associates, Inc., 2019.
[33] L. Huang, X. Liu, Y. Liu, B. Lang, and D. Tao, Centered Weight Normalization in
Accelerating Training of Deep Neural Networks, in 2017 IEEE International Conference
on Computer Vision (ICCV), pages 2822–2830, 2017.
16
","nanDeep learning reconstruction methods have drawn a lot interest from the medical imaging community by achieving remarkable results in public reconstruction challenges such as FastMRI8,9. Reconstruction methods in the learned post-processing family apply a neural network as a learned operator on top of a classical reconstruction method such as filtered back-projection (FBP)10,11. Despite the advantages such as typically fast inference, learned post-processing methods do not provide the neural network with direct access to the underlying measurement data, thus some imaging artifacts might be hard to fix. For example, removing streaks due to photon starvation in CBCT in image domain would require a neural network with large receptive field due to the size of the streaks. Learned iterative schemes, on the other hand, are inspired by classical iterative methods such as Landweber iteration, and embed the forward operator directly in the neural network architecture. Intuitively, this allows to draw on the theoretical guarantees given by iterative methods but use more flexible ‘neural network prior’ instead of an explicit regularization. Learned Primal-Dual (LPD) algorithm12 is a prominent example of a learned iterative scheme inspired by the Primal-Dual Hybrid Gradient (PDHG) method13, which combines both image-space and projection-space operations in an end-to-end trainable network. Image-space computations are performed by primal blocks and projection-space computations are performed by dual blocks, all pri-mal/blocks being small convolutional neural networks. LPD framework has been extended to other modalities as well, such as Digital Breast Tomosynthesis14 and MRI15, but there are also recent examples of learned iterative schemes for CT16 or MRI17 reconstruction that work in image domain only.
However, learned iterative schemes and LPD in particular can be hard to scale up to a fully three-dimensional modality such as CBCT due to memory limitations. For example, given a 256 × 256 × 256 FP32 tensor a single convolution layer with 64 features would already require 8 GB memory to perform the backpropagation operation. One of the first memory-efficient alternatives is ϵU-Net18, which is a simpler scheme that does not operate in the projection space.
Memory usage is reduced by relying on a multiscale approach, where reconstructions obtained at different resolutions are merged together by a final U-net. iLPD, or invertible learned primal-dual method, has been considered19, where it was shown that it substantially reduces memory requirements and allows to use longer learned iterative schemes. For a 3D helical CT setting, iLPD has been combined20 with splitting the scanning geometry in chunks of data that can be processed independently, however, such geometry splitting is not possible for CBCT. To address this issue, LIRE21 method was recently proposed, where a learned invertible primal-dual scheme was augmented with tiling computation mechanism inside the primal/dual blocks during both training and inference, allowing to use higher filter counts as well more complex U-net cells inside primal blocks."
"In the current landscape of online abuses and harms, effective content moderation is necessary to cultivate safe and inclusive online spaces. Despite the growing reliance on content moderation, there remains a limited understanding of the effects of many moderation interventions. We assess the effectiveness of The Great Ban, a massive deplatforming operation that affected nearly 2,000 communities on Reddit. By analyzing 16M comments posted by 17K users during 14 months, we provide nuanced results on the effects – both desired and otherwise – of the ban. Our findings can inform the development of future moderation interventions and the policing of online platforms.","Content moderation is needed to maintain safe and inclusive social environments by mitigating the spread of problematic content and harmful behavior. It fosters user trust and safety, thereby upholding ethical standards and contributing to the overall flourishing of healthy online communities. However, in spite of the growing reliance on content moderation, there remains a limited understanding of the effects of many moderation interventions, which impairs the efficacy of current regulatory efforts. Indeed, recent research has shown that some interventions yielded mixed or no effects at all, and in some cases, some even resulted in unintended and undesired consequences.","We initially collected all comments posted between December 2019 and June 2020 in each of the 15 popular subreddits, resulting in 8M comments shared by 194K distinct users. The data covers 30 weeks (i.e., 7 months) prior to The Great Ban, and allows for establishing a suitable baseline for the activity of the affected users before the moderation intervention. Notably, we could not collect any data between May and June 2020, due to several subreddits having halted their activity, or being banned, before Reddit’s public announcement of The Great Ban on June 29, 2020. We defined core users as those who posted at least one comment each month between December 2019 and March 2020.2 Additionally, we filtered out bots (i.e., clearly automated accounts) by discarding all accounts that posted at least two different comments at the exact same time. After these filtering steps, we ended up with 2.2M comments by 16,828 core users. Hereafter, we refer to this portion of our dataset as IN-BEFORE since it involves activity within the banned subreddits before the ban.","Table 2 shows that users who abandoned the platform were more toxic than those who remained after the ban. In 12 out of 15 subreddits, abandoning users have larger mean absolute deviation (MAD) scores than remaining users, indicating greater variability in toxicity among the former user group. Figure 3 presents a slope chart of all user-level toxicity changes, independently of the subreddit in which users participated. Each line corresponds to a single user. Line slopes encode the amount of toxicity reduction or increment. Rising lines are colored with different shades of red depending on their slope, and denote users who increased their toxicity after the ban. Contrarily, decreasing lines are blue-colored and denote users who decreased their toxicity.","To evaluate its effectiveness, we analyzed 16M comments shared over the course of 14 months by 17K users affected by the ban. Our results reveal that 15.6% of the affected users abandoned Reddit after the ban and that those who remained reduced their toxicity by 6.6% on average. Despite this modest toxicity reduction, 5% of users increased their toxicity by more than 70% of their pre-ban level. The presence of such resentful users was widespread across the analyzed subreddits. However, these users likely had little impact on the platform given that only 16% of users increased both toxicity and activity. Likewise, only 21% users increased toxicity and also obtained positive engagement from the community. Overall, our study provides new and nuanced insights into the effectiveness of The Great Ban, including its undesired consequences.",The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit,"Lorenzo Cima, Amaury Trujillo Larios, Marco Avvenuti, Stefano Cresci","The Great Ban: Efficacy and Unintended Consequences
of a Massive Deplatforming Operation on Reddit
Lorenzo Cima,1,2* Amaury Trujillo,1 Marco Avvenuti,2 Stefano Cresci1
1IIT-CNR, Italy, [name.surname]@iit.cnr.it
2University of Pisa, Italy, marco.avvenuti@unipi.it
Abstract
In the current landscape of online abuses and harms, effective
content moderation is necessary to cultivate safe and inclu-
sive online spaces. Yet, the effectiveness of many moderation
interventions is still unclear. Here, we assess the effectiveness
of The Great Ban, a massive deplatforming operation that
affected nearly 2,000 communities on Reddit. By analyzing
16M comments posted by 17K users during 14 months, we
provide nuanced results on the effects – both desired and oth-
erwise – of the ban. Among our main findings is that 15.6% of
the affected users left Reddit and that those who remained re-
duced their toxicity by 6.6% on average. The ban also caused
5% users to increase their toxicity by more than 70% of their
pre-ban level. However, these resentful users likely had lim-
ited impact on Reddit due to low activity and little support by
peers. Overall, our multifaceted results provide new insights
into the efficacy of deplatforming. Our findings can inform
the development of future moderation interventions and the
policing of online platforms.
Introduction
Within online platforms, content moderation is needed to
maintain safe and inclusive social environments by miti-
gating the spread of problematic content and harmful be-
havior. It fosters user trust and safety, thereby upholding
ethical standards and contributing to the overall flourishing
of healthy online communities (Gillespie 2018). In content
moderation, platform policies are enforced through modera-
tion interventions (Trujillo, Fagni, and Cresci 2023). There
exist many possible interventions to be applied by platform
administrators, ranging from the delivery of short warning
messages (Katsaros, Yang, and Fratamico 2022) and the use
of informative labels (Zannettou 2021; Papakyriakopoulos
and Goodman 2022), up to the removal of large amounts
of content or users (Trujillo and Cresci 2022; Jhaver et al.
2021). However, in spite of the growing reliance on con-
tent moderation, there remains a limited understanding of
the effects of many moderation interventions, which im-
pair the efficacy of current regulatory efforts. Indeed, re-
cent research has shown that some interventions yielded
mixed (Horta Ribeiro et al. 2021; Trujillo and Cresci 2023)
*Corresponding author.
Copyright © 2024, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
or no effects at all (Dias, Pennycook, and Rand 2020), and in
some cases, some even resulted in unintended and undesired
consequences (Bail et al. 2018; Pennycook et al. 2020). For
these reasons, it is paramount to conduct thorough assess-
ments of the outcomes of recent moderation interventions as
a fundamental preliminary step to the planning and develop-
ment of future effective solutions.
Out of all the possible interventions, the removal (i.e.,
banning) of users, communities, and content – a moder-
ation practice dubbed deplatforming – is by far the most
frequently adopted (Horta Ribeiro et al. 2024). A famous
example is the banishment of Donald Trump from Face-
book and X (formerly Twitter) in 2021 (Seeliger and Baum
2023). Other notable examples are the deplatforming of
some toxic influencers on X (Jhaver et al. 2021) and the
permanent shut of racist, sexist, and generally hateful com-
munities on Reddit (Chandrasekharan et al. 2017; Habib
et al. 2022). In 2020 Reddit hosted a massive deplatform-
ing operation that involved the ban of around 2,000 sub-
reddits on the grounds of their promotion of identity- and
vulnerability-based hate.1 Among the banned communities
were some very popular subreddits such as r/The Donald
and r/ChapoTrapHouse. This event is commonly referred
to as The Great Ban and is currently one of the biggest bans
in the history of social media. Despite its impact on mul-
tiple communities and on a large number of users within
and beyond Reddit, its effects remain underexplored. Ex-
isting studies on The Great Ban have primarily focused on
assessing writing style changes (Trujillo et al. 2021), which
do not answer the fundamental question as to whether the
ban was effective at curbing toxic behavior. The few studies
that sought to analyze the degree of toxicity after the ban
did so only for a few of the affected subreddits (Trujillo and
Cresci 2022). Moreover, the majority of such studies inves-
tigated community-level effects, overlooking user-level re-
actions that are however clearly relevant with respect to the
moderation goal of thwarting particularly problematic be-
haviors (Trujillo and Cresci 2023).
Research questions. Here, we contribute to filling these
knowledge gaps by carrying out a large-scale quantitative
analysis of the changes in toxic behavior exhibited by those
1https://www.reddit.com/r/announcements/comments/hi3oht/
update to our content policy/ (accessed: 12/15/2023)
arXiv:2401.11254v1  [cs.SI]  20 Jan 2024
users who participated in the 15 most popular subreddits
shut during The Great Ban. We analyze 16M comments
shared by almost 17K users over 14 months, answering to
the following research questions.
• RQ1: Was The Great Ban effective at reducing toxicity?
The affected subreddits were banned due to hateful and toxic
speech. However, previous studies showed that botched in-
terventions can exacerbate – rather than mitigate – toxic be-
haviors. Here we evaluate the effectiveness of The Great Ban
at reducing user toxicity.
• RQ2: Did The Great Ban cause any undesired side ef-
fects to some users? In other words, were there users who
became much more toxic after the intervention? When eval-
uating the outcomes of a moderation action, it is important to
consider whether the action made a subset of users resentful
or vindictive, thus leading to marked increases in their tox-
icity. Such extreme reactions can occur also in the presence
of an overall (i.e., platform- or community-level) reduction
in total toxicity, which mandates analyses at the user level.
Here we investigate the presence and quantify the extent of
toxic reactions to The Great Ban, as an indicator of potential
shortcomings in the intervention.
• RQ3: What were the behavioral dynamics of toxic users,
in terms of their activity and generated engagement? To
deepen our analysis, we examine further behavioral dimen-
sions of those users who became much more toxic after The
Great Ban. We specifically focus on their degree of activ-
ity on the platform and the engagement they receive from
other users. Conjointly analyzing the dynamics of toxicity
and activity is important as it can allow to identify users who
are both very active and very toxic. Additionally, investigat-
ing the social feedback they receive may reveal the degree
to which highly toxic behaviors are tolerated, and possibly
even encouraged, by other users (Jiang et al. 2023).
Main findings. Based on our answers to the above RQs,
our study yields the following novel findings:
• Overall, The Great Ban caused 15.6% of the affected
users to abandon Reddit. Those who remained decreased
their toxicity by 6.6%, on average.
• Despite this modest overall reduction in toxicity, a non-
negligible fraction of users became much more toxic. For
example, 5% users increased their toxicity by more than
70% of their pre-ban level.
• The presence of resentful users who increased their toxi-
city was widespread across the analyzed subreddits.
• However, their impact was likely minimal due to low ac-
tivity levels and little support from other Reddit users.
Overall, our study provides a comprehensive account of the
effects of The Great Ban. It surfaces and describes an un-
desired side effect of the intervention, drawing attention on
the delicate balance entailed by the moderation of heteroge-
neous communities. As such, our results can inform future
moderation strategies and the development of effective in-
terventions.
Related Work
We summarize and critically discuss recent literature on the
evaluation of moderation interventions, starting from those
works that are most similar to our present study.
Deplatforming
Despite the relevance and the extent of The Great Ban, few
works delved into a systematic evaluation of its effects.
Among them is the study by Milo Trujillo et al. (2021)
that analyzed activity and linguistic changes in the 15 most
popular subreddits affected by the ban. They found that
top users suffered the largest decreases in activity and that
community response was heterogeneous between subred-
dits, and even between users of a subreddit (Trujillo et al.
2021). Here we complement this work by assessing effects
in terms of toxicity, rather than activity and language. Other
works evaluated deplatforming effects in a subset of the
subreddits affected by The Great Ban, or in other subred-
dits altogether. Chandrasekharan et al. (2017) and Saleem
and Ruths (2018) examined the repercussions of the bans
on r/fatpeoplehate and r/coontown, revealing that a
substantial number of users departed from Reddit follow-
ing the interventions. Among those who stayed, a notable
reduction in hate speech was observed. However, they also
found a considerable portion of users who migrated to other
subreddits, doubling their posting activity (Chandrasekha-
ran et al. 2022). Instead, Horta Ribeiro et al. (2021) as-
sessed the impact of deplatforming across multiple plat-
forms, concentrating on the migration of users from banned
subreddits to newly established platforms. Their findings
indicated a significant decline in user activity on the new
platforms. However, they also found a subset of users who
increased their toxicity and radicalization. Deplatforming
was also studied on platforms other than Reddit. For ex-
ample, Mekacher, Falkenberg, and Baronchelli (2023) stud-
ied ban-induced migrations from Twitter to Gettr, finding
that politically polarized users are less toxic on fringe plat-
forms as they are exposed to less out-group interactions. Fi-
nally, Jhaver et al. (2021) examined Twitter’s ban on multi-
ple toxic influencers, revealing a general reduction in con-
versations about these figures, accompanied by decreased
activity and toxicity among their supporters. Nonetheless,
they also found a fraction of users who greatly increased ac-
tivity and toxicity.
Overall, this body of work shows that moderation inter-
ventions frequently cause a combination of desired and un-
desired effects, and that effects vary between different inter-
ventions and types of users. To this end, our work leverages
and extends previous knowledge by evaluating the effects
of The Great Ban – a massive, yet essentially unexplored,
moderation event – across the main dimensions of user be-
havior: toxicity, activity, and engagement. Our results pro-
vide a complete picture of the effectiveness of the ban on
the 15 most popular affected subreddits.
Soft moderation
So-called soft interventions emerged as an alternative to
deplatforming, addressing the concerns about censorship
and the loss of free speech that often accompany con-
tent and user removals (Zannettou 2021). Amaury Tru-
jillo and Cresci (2022; 2023) studied quarantines and re-
strictions: soft interventions that often precede commu-
IN-BEFORE
OUT-BEFORE
OUT-AFTER
subreddit
subscribers
core users comments
users comments
users comments
r/chapotraphouse
159,185
9,295 1,368,874
9,205 3,947,894
8,319 3,157,462
r/the donald
792,050
4,262
619,434
4,132 2,578,026
3,145 1,434,008
r/darkhumorandmemes
421,506
1,632
35,561
1,617 1,246,399
1,392
689,079
r/consumeproduct
64,937
1,730
60,073
1,719 1,209,933
1,275
594,349
r/gendercritical
64,772
1,091
94,735
1,039
511,173
706
287,877
r/thenewright
41,230
729
5,792
726
600,057
575
308,584
r/soyboys
17,578
596
5,102
594
454,659
432
190,570
r/shitneoconssay
8,701
559
9,178
555
338,218
384
140,619
r/debatealtright
7,381
488
27,814
476
274,600
328
117,281
r/darkjokecentral
185,399
316
3,214
308
307,876
270
179,067
r/wojak
26,816
244
1,666
240
210,249
170
81,142
r/hatecrimehoaxes
20,111
189
775
188
185,379
143
96,457
r/ccj2
11,834
150
9,785
145
101,165
119
63,393
r/imgoingtohellforthis2
47,363
93
376
92
74,664
72
43,018
r/oandaexclusiveforum
2,389
60
1,313
59
48,774
55
35,853
total (unique)
16,828 2,243,692
16,540 8,235,086
13,963 5,592,321
Table 1: Dataset composition. Rows are ordered by number of active users after the ban. Data in IN-BEFORE is related to
user activities within the banned subreddits before the ban took place. Data in OUT-BEFORE and OUT-AFTER are related
to user activities outside of the banned subreddits, respectively before and after the ban. OUT-BEFORE contains 288 less
users than IN-BEFORE, who had no activity outside of the banned subreddits. OUT-AFTER contains 2,577 less users than
OUT-BEFORE, who abandoned the platform after The Great Ban.
nity bans on Reddit. They studied moderation outcomes
on r/the donald, revealing a general reduction in activ-
ity and toxicity, at the cost of an increased political polar-
ization and decreased factuality of shared news (Trujillo and
Cresci 2022, 2023). Reddit’s quarantine of r/the donald
was also studied by Chandrasekharan et al. (2022) and Shen
and Ros´e (2022), who concluded that the intervention did
not produce meaningful changes, nor in terms of misogyny
and racist comments, neither regarding engagement and in-
ternal dynamics. Other types of soft interventions are the at-
tachment of warning labels to disputed posts, whose effects
were assessed in terms of perceived credibility and obtained
engagement. In detail, Pennycook et al. (2020) found that
the presence of some posts with warning labels increases
the perceived credibility of all posts without labels, includ-
ing false ones not yet debunked. Zannettou (2021) found in-
stead that tweets with warning labels were often replied to,
to further debunk the claims. However, this resulted in the
flagged tweets circulating more and obtaining more engage-
ment than the undisputed ones. Finally, Katsaros, Yang, and
Fratamico (2022) carried out an A/B test on Twitter to eval-
uate the effectiveness of using warning messages to prompt
users that are about to post toxic tweets. Their results show
that the intervention was overall effective at reducing the
posting of toxic tweets. Nonetheless, a small minority of
users edited their tweet to make it more toxic after being
exposed to the warning message.
The above literature on soft moderation interventions cor-
roborates that on deplatforming, confirming that each inter-
vention can elicit both desired and undesired effects. Over-
all, this body of work underscores the need for further re-
search to evaluate the impact of little-studied interventions.
IN-BEFORE
OUT-BEFORE
OUT-AFTER
Dec 2019
May 2020
Feb 2021
Jul 2020
The Great Ban
(29 June 2020)
15 banned subreddits
rest of Reddit
Figure 1: Timeline depicting the periods of data collection
and analysis. Collected data spans two time periods of 7
months each, centered around The Great Ban. It is notewor-
thy that the IN-BEFORE dataset has no content since May
2020, indicating that the activity in the banned subreddits
halted before the official intervention date.
Dataset
Our dataset for this study comprises 16M Reddit comments
shared by 16,828 distinct users who participated in at least
one of the 15 popular subreddits shut during The Great
Ban (Trujillo et al. 2021), as reported in Table 1. The com-
position of our dataset is illustrated in Figure 1 and the pro-
cedure adopted to build it is described in the following.
Dataset construction. We initially collected all com-
ments posted between December 2019 and June 2020 in
each of the 15 popular subreddits, resulting in 8M comments
shared by 194K distinct users. The data covers 30 weeks
(i.e., 7 months) prior to The Great Ban, and allows for es-
tablishing a suitable baseline for the activity of the affected
users before the moderation intervention (Trujillo and Cresci
2023). Notably, we could not collect any data between May
and June 2020, due to several subreddits having halted their
activity, or being banned, before Reddit’s public announce-
ment of The Great Ban on June 29, 2020.
0.0
0.2
0.4
0.6
0.8
1.0
perspective (toxicity)
0.0
0.2
0.4
0.6
0.8
1.0
detoxify (toxicity)
r: 0.872
0.0
0.2
0.4
0.6
0.8
perspective (severe toxicity)
0.0
0.2
0.4
0.6
0.8
detoxify (severe toxicity)
r: 0.796
Figure 2: Comparison between the toxicity (left panel) and
severe toxicity (right panel) indicators provided by Perspec-
tive API (x axis) and Detoxify (y axis). Overall, we report
a strong Pearson correlation between the two methods, and
particularly so for the toxicity indicator (r = 0.872).
As commonly done in literature, we obtained a represen-
tative set of users for the considered subreddits by constrain-
ing our analysis to core users – namely, users who partici-
pated regularly in at least one subreddit (Trujillo and Cresci
2022; Bouleimen et al. 2023). We defined core users as those
who posted at least one comment each month between De-
cember 2019 and March 2020.2 Additionally, we filtered out
bots (i.e., clearly automated accounts) by discarding all ac-
counts that posted at least two different comments at the ex-
act same time. After these filtering steps, we ended up with
2.2M comments by 16,828 core users. Hereafter, we refer to
this portion of our dataset as IN-BEFORE since it involves
activity within the banned subreddits before the ban.
Providing a fair evaluation of the effects of The Great
Ban involves matching comparable datasets before and af-
ter the intervention. However, no activity exists within the
banned subreddits after the intervention, since the subreddits
were permanently shut. Therefore, evaluating the effects of
the intervention must involve the analysis of user activities
outside of the banned subreddits. For this reason, we col-
lected all comments made by the 16,828 core users outside
of the 15 banned subreddits across a wide time frame span-
ning 7 months before and after The Great Ban, as shown in
Figure 1. We obtained around 13.8M comments by 16,540
distinct users. We labeled data related to user activities be-
fore the ban as OUT-BEFORE and that after the ban as
OUT-AFTER, as reported in Table 1. Estimates of the effects
of the ban are obtained by comparing the OUT-BEFORE and
OUT-AFTER datasets. Lastly, we enriched our dataset by
computing a toxicity score for each collected comment.
Annotating toxicity: Detoxify vs Perspective API.
Google’s Perspective API and Detoxify are among the state-
of-the-art and most widely used methods for computing tox-
icity scores for texts. Perspective API3 was developed by
the Jigsaw team at Google and currently represents the de
facto standard for toxicity detection, both in production con-
tent moderation environments and in academia (Rieder and
Skop 2021; Nogara et al. 2023). The service is offered as a
2April 2020 was excluded from this analysis due to the limited
number of collected comments. It is likely that the activity within
the subreddits halted in the initial days of that month.
3https://perspectiveapi.com/ (accessed: 01/01/2024)
Web API that, given a piece of text, outputs several scores
of offensiveness, including two indicators of toxicity and
severe toxicity defined in the [0, 1] range. Detoxify is an
open source deep learning toxicity classifier that also out-
puts the toxicity and severe toxicity indicators (Hanu and
Unitary team 2020). Due to its convenience and competitive
performance, it has recently seen frequent use (Chang, May,
and Lerman 2023; Noor and Ahmed 2023). The advantage
of Detoxify over Perspective API lies in the possibility to in-
stall and run it locally, without incurring in the limitations of
a Web API (i.e., rate limits or quotas). Given the large num-
ber of comments to annotate in our dataset, we computed
toxicity scores with Detoxify. Nonetheless, we first validated
our choice by comparing the outputs of Perspective API and
Detoxify on a stratified random sample of 10K comments
extracted from the IN-BEFORE portion of our dataset. Fig-
ure 2 presents the results of this comparison, for both the
toxicity and severe toxicity indicators. As shown, we found
a strong positive Pearson correlation between the two meth-
ods, which supports the use of Detoxify. Then, with respect
to the two provided indicators, for our subsequent analyses
we relied on the toxicity indicator because it is the one on
which the two methods agree the most, with r = 0.872 vs
r = 0.796 for severe toxicity.
Analyses and Results
RQ1: Effectiveness of The Great Ban
In this section, we assess the effectiveness of The Great Ban
at reducing toxic behaviors.
Abandoning users. Table 1 highlights a difference
of 2,577 users (15.6%) between the OUT-BEFORE and
OUT-AFTER datasets, corresponding to users who became
inactive on Reddit after The Great Ban. Given that such
users were consistently active before the ban, but did not
post a single comment in the 7 months following it, we
conclude that they abandoned Reddit, possibly migrating to
other platforms (Horta Ribeiro et al. 2021). This result thus
highlights a first straightforward effect of The Great Ban. In
order to draw more insights into this finding, we compare
the pre-ban subreddit-wise toxicity of the abandoning users
with that of the users who remained active on the platform.
Table 2 shows that in 14 out of 15 subreddits, users who
later abandoned the platform were more toxic than those
who remained after the ban. In other words, toxic users were
more likely to abandon the platform after the intervention
than less toxic ones. For 12 subreddits the difference in tox-
icity between abandoning and remaining users is statisti-
cally significant (p < 0.05), according to a non-parametric
Mann-Whitney test for unpaired data. Moreover, in 12 sub-
reddits, abandoning users have larger mean absolute devia-
tion (MAD) scores than remaining users, indicating greater
variability in toxicity among the former user group.
Remaining users. In addition to causing some users to
abandon the platform, the ban might also have caused tox-
icity changes in those users who remained. Table 2 reports
subreddit-wise toxicity scores for the matched set of remain-
ing users, before and after the ban. As shown, the remaining
users were on average less toxic after the ban. Specifically,
aband. before (ABA)
remain. before (BEF)
remain. after (AFT)
subreddit
users median
MAD
users median MAD
median
MAD
ABA vs BEF
BEF vs AFT
r/chapotraphouse
886
0.142
0.062
8,319
0.134 0.050
0.126
0.052
−0.008 ***
−0.008 ***
r/the donald
987
0.148
0.072
3,145
0.134 0.051
0.127
0.058
−0.014 ***
−0.007 ***
r/darkhumorandmemes
225
0.169
0.050
1,392
0.152 0.044
0.142
0.048
−0.017 ***
−0.010 ***
r/consumeproduct
444
0.179
0.053
1,275
0.158 0.045
0.146
0.048
−0.021 ***
−0.012 ***
r/gendercritical
333
0.175
0.075
706
0.145 0.061
0.122
0.062
−0.030 ***
−0.023 ***
r/thenewright
151
0.169
0.057
575
0.143 0.043
0.132
0.045
−0.026 ***
−0.011 ***
r/soyboys
162
0.194
0.050
432
0.165 0.041
0.150
0.044
−0.029 ***
−0.015 ***
r/shitneoconssay
171
0.178
0.044
384
0.157 0.044
0.146
0.048
−0.021 ***
−0.011 ***
r/debatealtright
148
0.166
0.054
328
0.149 0.047
0.139
0.051
−0.017 **
−0.010
r/darkjokecentral
38
0.190
0.040
270
0.138 0.045
0.150
0.039
−0.040 ***
−0.012 ***
r/wojak
70
0.190
0.045
170
0.154 0.041
0.143
0.044
−0.036 ***
−0.011 ***
r/hatecrimehoaxes
45
0.177
0.042
143
0.161 0.047
0.155
0.058
−0.016
−0.006
r/ccj2
26
0.185
0.056
119
0.123 0.036
0.114
0.045
−0.062 ***
−0.009
*
r/imgoingtohellforthis2
20
0.172
0.048
72
0.157 0.047
0.155
0.052
−0.015
−0.002
r/oandaexclusiveforum
4
0.128
0.079
55
0.189 0.064
0.182
0.063
+0.061
−0.007
overall
2,577
0.153
0.067
13,963
0.137 0.050
0.128
0.053
−0.016 ***
−0.009 ***
*: p < 0.1; **: p < 0.05; ***: p < 0.01
Table 2: Subreddit-wise median toxicity scores for users who abandoned Reddit after the ban (ABA) and for those who re-
mained. For the latter, toxicity scores are computed both before (BEF) and after (AFT) the ban. The ABA vs BEF column
shows that users who abandoned the platform were more toxic than those who remained. The BEF vs AFT column shows that
users who remained active experienced a modest toxicity reduction after the ban.
when aggregating results for each subreddit, users from all
15 subreddits slightly decreased their toxicity. The decrease
is statistically significant for 11 subreddits (p < 0.1), ac-
cording to a non-parametric Wilcoxon test for paired data.
Notably, effect sizes for the comparison between remaining
users before vs after the ban are smaller than those of the
comparison between abandoning vs remaining users. In fact,
after The Great Ban, the overall toxicity decreased by 6.57%
on average – a modest amount. Moreover, for 13 out of 15
subreddits, toxicity MAD values are larger after the ban than
before. This result suggests that the ban increased the degree
of variability in the behavior of the remaining users, which
we further investigate in the following.
User-level effects. So far, we provided platform- and
community-level results, finding that The Great Ban caused
15.6% of core users to abandon the platform. Furthermore,
those who remained exhibited a modest average toxicity re-
duction of 6.57%. To provide a thorough assessment of the
intervention, here we also investigate user-level effects by
computing the toxicity changes experienced by each of the
13,963 users who remained active on Reddit after the ban.
The central panel of Figure 3 presents a slope chart of all
user-level toxicity changes, independently of the subreddit
in which users participated. Each line corresponds to a sin-
gle user. Line slopes encode the amount of toxicity reduction
or increment. Rising lines are colored with different shades
of red depending on their slope, and denote users who in-
creased their toxicity after the ban. Contrarily, decreasing
lines are blue-colored and denote users who decreased their
toxicity. Figure 3 also includes marginal boxplot toxicity
distributions for remaining users before (left-hand side of
the slope chart) and after (right-hand side) the ban. The left-
most boxplot presents the toxicity distribution for users who
abandoned the platform. Finally, the bottom panel shows
the distribution of user-level toxicity changes as a beeswarm
plot. This latter plot is useful for highlighting outliers and for
studying the two tails of the distribution – i.e., those related
to marked toxicity increases (red dots, right-hand side of the
beeswarm plot) and decreases (blue dots, left-hand side).
The three boxplots of Figure 3 confirm the overall tox-
icity trends observed in Table 2. Abandoning users have
the largest median toxicity, followed by remaining users be-
fore the ban. Out of the three user groups, the remaining
users after the ban have the lowest median toxicity. The
slope chart in Figure 3 depicts a majority of lines with rela-
tively small positive or negative slopes. These correspond to
users who exhibited small toxicity changes – either increases
or decreases – after the ban. At the same time, however,
the slope chart also features a remarkable number of steep
lines, which are related to users who exhibited large toxicity
changes. Specifically, we note an overwhelming majority of
red-colored steep lines. This implies that, among users who
exhibited large toxicity changes, the vast majority increased
their toxicity. This result qualitatively describes an undesired
effect of The Great Ban, which caused a non-negligible mi-
nority of users to become resentful or vindictive, thus ex-
hibiting much more toxic behaviors. The points where the
lines of the slope chart intersect the y axis on the right-hand
side of the plot represent the toxicity of the users after the
ban. The distribution of the post-ban toxicity scores is also
depicted in the right-hand side boxplot. As shown in Fig-
ure 3 and as anticipated from the MAD values in Table 2,
there is more variability in user toxicity after the ban. Fig-
ure 3 clarifies that this increased variability is caused by the
increased toxicity of the resentful users.
Figure 3 provides aggregated results for all subreddits.
TOXICITY BEFORE
TOXICITY AFTER
CHANGE IN TOXICITY
Figure 3: User-level toxicity change after The Great Ban,
for each active user. The slope chart in the central panel re-
veals a majority of red-colored rising lines, corresponding to
a large number of users who drastically increased their tox-
icity. The beeswarm plot in the bottom panel confirms this
effect, presenting more users in the right red-colored tail of
the distribution than in the left blue-colored one. Boxplots
present marginal distributions for abandoning and remain-
ing user, before and after the intervention.
However, the same set of visualizations can also be used
to assess the consequences of The Great Ban among the
users of a single subreddit. In turn, this is valuable for iden-
tifying common patterns and possible differences between
the subreddits. We thus repeated the analysis for users of
each individual subreddit. The comparison between the dif-
ferent subreddits confirmed previous results, according to
which the majority of users who underwent substantial toxi-
city changes after the ban, increased their toxicity. Nonethe-
less, this behavior was more pronounced in certain subred-
dits while lacking in others. Among the subreddits where the
effect was particularly pronounced are r/the donald and
r/consumeproduct, as visible from the large majority of
steep red lines in the slope charts of Figure 4, and from the
long right tails of the corresponding beeswarm plots. Con-
versely, r/soyboys and r/hatecrimehoaxes are subred-
dits whose participants did not experience marked toxic-
ity changes and for which no extremely toxic behavior was
measured post-ban.
RQ2: Extreme user reactions to The Great Ban
In answering RQ1 we found that The Great Ban caused a
modest overall reduction in toxicity. At the same time, how-
ever, we also qualitatively discovered a fraction of users who
became resentful and greatly increased their toxicity after
the ban. We are now interested in quantitatively assessing
the extent of this issue across the different subreddits.
Let t(i)BEF, t(i)AFT be the toxicity of the i-th user be-
fore and after the ban. Then, ∆t(i) = t(i)AFT − t(i)BEF
is the change in toxicity for the same user. For clarity, the
beeswarm plot in Figure 3 shows the distribution of ∆t(i)
for all users. In detail, we measured that 5% of all users
exhibited a ∆t(i) > 0.1. This result is particularly rel-
TOXICITY AFTER
TOXICITY BEFORE
r/the_donald
CHANGE IN TOXICITY
r/consumeproduct
Figure 4: User-level toxicity changes for participants in
r/the donald (top) and r/consumeproduct (bottom).
evant in light of the median toxicity pre-ban, which was
0.137 as reported in Table 2. In other words, this result im-
plies that 5% of users increased their toxicity by more than
70% of their pre-ban level. The overall change in toxicity
in a given subreddit with N participants can be computed
as ∆t = PN
i=1 ∆t(i). Then, in order to separately weigh
the contribution of the two tails of the beeswarm plots, we
compute summations that only consider positive or negative
∆t(i). For example, we quantify the contribution of the right
tail (i.e., the one related to toxicity increases) of the distri-
bution of toxicity changes in a subreddit as:
∆t+ =
XN
i=1 ∆t(i)
with ∆t(i) > 0
Similarly, we quantify the contribution of the left tail as
∆t− = PN
i=1 |∆t(i)|, with ∆t(i) < 0. The left panel of
Figure 5 shows the balance between the contributions to the
overall toxicity change in each subreddit brought by users
who increased (∆t+, red-colored) vs those who decreased
(∆t−, blue-colored) their toxicity. As shown, the contribu-
tions of the two tails are relatively balanced for the major-
ity of subreddits. In 12 out of 15 subreddits, the decreases
in toxicity slightly outweigh the increases, which results
in the modest overall decrease in toxicity that we already
noted in RQ1. Toxicity increases outweigh decreases in
r/debatealtright and r/imgoingtohellforthis2,
while r/the donald has perfectly balanced contributions.
In order to specifically investigate the behavior of outlier
users – those who experienced marked changes in toxic-
ity – we recompute the previous summations by only con-
57%
50%
57%
57%
64%
60%
65%
55%
48%
60%
52%
54%
58%
34%
57%
43%
50%
43%
43%
36%
40%
35%
45%
52%
40%
48%
46%
42%
66%
43%
increased toxicity
decreased toxicity
chapotraphouse
the donald
darkhumorandmemes
consumeproduct
gendercritical
thenewright
soyboys
shitneoconssay
debatealtright
darkjokecentral
wojak
hatecrimehoaxes
ccj2
imgoingtohellforthis2
oandaexclusiveforum
100
50
0
50
100
%
All users
41%
20%
36%
24%
55%
24%
75%
23%
20%
40%
13%
32%
0%
100%
59%
80%
64%
76%
45%
76%
25%
77%
80%
60%
87%
68%
100%
0%
increased toxicity
decreased toxicity
chapotraphouse
the donald
darkhumorandmemes
consumeproduct
gendercritical
thenewright
soyboys
shitneoconssay
debatealtright
darkjokecentral
wojak
ccj2
imgoingtohellforthis2
oandaexclusiveforum
100
50
0
50
100
%
Outlier users
Figure 5: Subreddit-wise changes in toxicity obtained by summing all individual decreasing and increasing contributions, for
all users (left panel) and outlier users (right panel). Outlier users are those whose change in toxicity exceeds the threshold
k = 0.25. Based on this criterion, we found no outliers for r/hatecrimehoaxes, which is thus omitted from the right panel
figure.
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
threshold k
-100
-75
-50
-25
+0
+25
+50
+75
+100
% change in toxicity by outlier users
chapotraphouse
oandaexclusiveforum
hatecrimehoaxes
imgoingtohellforthis2
wojak
Figure 6: Contribution of the outlier users to the increase/de-
crease of toxicity in each subreddit. Outlier users are de-
fined as those whose individual change in toxicity exceeds
the threshold k. As shown, in 12 out of 15 subreddits the
outlier users caused large toxicity increases.
sidering users whose change in toxicity exceeds a given
threshold k: |∆t(i)| > k. This allows us to focus on those
users who experienced extreme behavioral changes, be them
increases or decreases in toxicity. For example, the right
panel of Figure 5 repeats the previous analysis by apply-
ing the threshold k = 0.25. As shown, we obtain strik-
ingly different results. When only considering outlier users,
in 13 out of 15 subreddits the contributions of those who
increased or decreased their toxicity to the overall sub-
reddit toxicity are very imbalanced. The only exceptions
are r/gendercritical who presents relatively balanced
contributions (55% vs 45%) and r/hatecrimehoaxes for
which no user experienced a change in toxicity exceeding
the threshold k = 0.25. Moreover, in 11 subreddits toxic-
ity increases greatly outweigh decreases. To generalize these
1
2
3
4
5
6
7
8
9
number of subreddits
-1.00
-0.75
-0.50
-0.25
+0.00
+0.25
+0.50
+0.75
+1.00
change in toxicity
Figure 7: Relationship between user participation in the 15
banned subreddits and change in toxicity. The vast majority
of users only participated in one or two subreddits. More-
over, participation in more/less subreddits is unrelated to
changes in toxicity.
findings, we repeated the analysis by varying the value of
k from 0 to 1, with a step of 0.01. Results are shown in
Figure 6 where each line corresponds to a subreddit and
reports the % difference ∆t+ − ∆t− between the contri-
butions of the two tails, for each value of k. In the figure,
only a few notable subreddits are highlighted, while the rest
are grey-colored so as to reveal the overall trend. As shown,
even for small values of the threshold k, the vast majority
of lines rise steeply. In particular, in 12 out of 15 subred-
dits the outlier users exhibit large increases in toxicity. The
subreddits r/imgoingtohellforthis2 and r/wojak are
those featuring the largest toxicity contributions by outlier
users. On the contrary, outliers in r/hatecrimehoaxes
and r/oandaexclusiveforum show marked toxicity re-
ductions, while r/chapotraphouse remains overall sta-
tionary. In summary, the results presented in this section
highlight that the presence of resentful users who became
much more toxic after The Great Ban was not localized
within a single or a few subreddits. On the contrary, despite
the fact that only a minority of users experienced marked
toxicity increases, such adverse reactions were pervasive
-1.0
-0.8
-0.6
-0.4
-0.2
+0.0
+0.2
+0.4
+0.6
+0.8
+1.0
change in toxicity
-8000
-6000
-4000
-2000
+0
+2000
+4000
+6000
+8000
change in activity
Q1
Q4
Q3
Q2
density
Q1
Q2
Q3
Q4
0
2000
4000
Figure 8: Density scatterplot of the relationship between
changes in toxicity and changes in activity, for each user.
The inset provides counts of the number of users in each
quadrant of the scatterplot. Only 16% of all users simultane-
ously exhibited increases in toxicity and activity, as shown
by the low number of users in Q1.
across most of the analyzed subreddits, which is indicative
of a systemic phenomenon.
RQ3: Behavioral dynamics of extremely toxic users
Our analyses in RQ2 revealed the widespread presence of
extremely toxic users and quantified the extent of the issue
across the subreddits. Here we move forward by providing
additional information on their behavior in order to draw in-
sights into their possible impact on the platform.
Subreddits participation. Initially, we explore the sub-
reddit participation habits of these users as a function of their
change in toxicity. This analysis aims to ascertain whether
each of the most toxic users engaged in a few or many of
the banned subreddits. Figure 7 suggests that only a small
number of users participated in multiple subreddits. Instead,
the vast majority of users participated only in a few sub-
reddits, typically ranging between one and three. Moreover,
user toxicity changes do not depend on the number of sub-
reddits in which the user participated.
Activity. Next, we look into the relationship between
changes in toxicity and activity. We measure user activity as
the number of posted comments. Conjointly studying user
activity and toxicity is important since toxic users pose a
meaningful threat only when high toxicity coincides with
elevated activity, which holds the potential to cause a sub-
stantial impact on the platform. This joint analysis also en-
ables the identification of those users who are both highly
toxic and remarkably active, allowing to prioritize modera-
tion interventions towards them. Figure 8 presents a density
scatterplot of the changes in toxicity and activity for each
considered user. The plot area is divided into four quadrants,
corresponding to the combinations of increase/decrease in
toxicity/activity. As shown, the bulk of the distribution lies
close to the plot origin, meaning that the ban caused mi-
nor changes in both toxicity and activity. Moreover, those
users who experienced marked changes in toxicity only had
-1.0
-0.8
-0.6
-0.4
-0.2
+0.0
+0.2
+0.4
+0.6
+0.8
+1.0
change in toxicity
-800
-600
-400
-200
+0
+200
+400
+600
+800
change in score
Q1
Q4
Q3
Q2
density
Q1
Q2
Q3
Q4
0
2000
4000
Figure 9: Density scatterplot of the relationship between
changes in toxicity and changes in score, for each user. The
score measures the difference between the total number of
upvotes and downvotes received by a user. The inset pro-
vides counts of the number of users in each quadrant of the
scatterplot. Similarly to Figure 8, only 21% of all users si-
multaneously exhibited increases in toxicity and score.
negligible changes in activity, and vice versa. The inset in
Figure 8 shows the number of users laying in each quad-
rant of the scatterplot. The most frequent reaction to the ban
was a reduction in both toxicity and activity (38% users are
in Q3). The opposite behavior is instead the least frequent
(16% users are in Q1). Overall this analysis suggests that
the resentful users might have had a limited impact on the
platform due to their low activity.
Engagement. Finally, we examine the relationship be-
tween changes in toxicity and obtained engagement. We
measure the engagement obtained by each comment as its
Reddit score, computed as the difference between the up-
votes and downvotes to that comment. Positive scores de-
note a positive engagement of the community with a com-
ment, while negative scores generally denote disagreement.
The engagement of a user is the mean engagement obtained
by its comments. This joint analysis of toxicity and engage-
ment is relevant as it allows an understanding of whether
post-ban toxic comments are tolerated, and possibly even
encouraged, on Reddit. Figure 9 shows the density scatter-
plot of this relationship. Similarly to Figure 8, we found that
the vast majority of users experienced small changes in toxi-
city and engagement. Again, the most frequent reaction was
a simultaneous reduction of both toxicity and obtained en-
gagement (31% users are in Q3) and the least frequent one
was a simultaneous increase of both (21% users are in Q1).
Lastly, we analyze the relationship between toxicity and
engagement also before the ban, by investigating differences
between the engagement obtained within vs outside of the
15 banned subreddits. Figure 10 provides the results of this
comparison, highlighting that toxic comments received sig-
nificantly more engagement within the banned subreddits
rather than outside of them (i.e., in the rest of Reddit). This
result corroborates that of Figure 9 in that it reinforces the
idea that toxicity is not encouraged on Reddit, with the ex-
[0.0,0.1)
[0.1,0.2)
[0.2,0.3)
[0.3,0.4)
[0.4,0.5)
[0.5,0.6)
[0.6,0.7)
[0.7,0.8)
[0.8,0.9)
[0.9,1.0]
mean toxicity
-10²
-10
0
+10
+10²
+10³
mean score
***
***
***
***
***
***
 
**
 
*
within the 15 banned subreddits
rest of Reddit
Figure 10: Difference between the score obtained by toxic comments within and outside of the 15 banned subreddits, as a
function of comment toxicity. Significance levels of the differences are obtained with non-parametric Mann-Whitney tests for
unpaired data: *: p < 0.1; **: p < 0.05; ***: p < 0.01.
ception of a few toxic subreddits.
Discussion
Our results shed light on the complex effects of The Great
Ban, a paramount example of deplatforming that involved
around 2,000 subreddits. Among our main findings is that
15.6% of the affected users abandoned Reddit after the ban.
Those who remained on the platform reduced their toxic-
ity by 6.6% on average. At the same time however, around
5% of all users markedly increased their toxicity. The pres-
ence of such resentful users was widespread across the ana-
lyzed subreddits. However, only 16% of users increased both
their toxicity and their activity. Similarly, only 21% of users
increased their toxicity and also obtained stronger positive
feedback from other users. These nuanced results cover new
ground on the effects of The Great Ban and, more broadly,
on adverse reactions to moderation interventions. Our re-
sults also lend themselves to multiple considerations about
the design and deployment of effective moderation as well
as about the challenges of regulating online platforms.
Effectiveness of the moderation. In literature, the effec-
tiveness of content moderation actions has been primarily
assessed in terms of changes that the moderation caused to
the activity and toxicity of the affected users (Chandrasekha-
ran et al. 2017; Jhaver et al. 2021). To this regard, our study
revealed that a considerable share of toxic users abandoned
the platform while the others exhibited a modest reduc-
tion in toxicity and a marked reduction in activity. At first
glance, these results appear to be indicative of a success-
ful moderation. However, it is necessary to deeply scrutinize
these findings in light of potential unintended consequences.
For example, the departure of some of the most toxic users
from the platform suggests a form of displacement rather
than a resolution of the toxicity issue. As recent research
pointed out, these users have likely migrated to other online
spaces (Horta Ribeiro et al. 2021), raising concerns about
the displacement of their toxic interactions instead of their
mitigation. These worries are emphasized by the knowledge
that users who migrate after facing restrictions on a plat-
form, subsequently engage in even more toxic and aggres-
sive behavior (Horta Ribeiro et al. 2021). In addition, user
churn and diminished activity levels post-ban might pose
challenges for Reddit, as online platforms thrive on user
engagement and interactions for generating revenues (Tru-
jillo and Cresci 2022). Consequently, the apparent success
of The Great Ban in mitigating toxicity must be interpreted
with caution, considering the potential negative impact on
the broader online ecosystem – due to user migrations – and
on the platform’s economic model – due to user churn and
reduced activity. Future endeavors should aim to strike a bal-
ance, devising strategies to curb toxicity without inducing
abandonment or substantial decreases in user activity. The
quest for effective moderation should align with the overar-
ching goal of cultivating healthier online communities with-
out compromising the safety of other platforms or economic
viability, which could otherwise disincentivize platforms to
carry out scrupulous moderation.
Divergent reactions to moderation. Our analysis also re-
vealed that, in spite of a modest overall reduction in toxic-
ity, a non-negligible minority of users exhibited large toxic-
ity increases. This result has important implications for the
assessment and development of moderation interventions.
First, it sheds light on the complexity of user reactions to
content moderation, which is a largely underexplored area
that requires further investigation (Jhaver et al. 2023). In ad-
dition, it surfaces the need for a more nuanced and personal-
ized approach to content moderation. A generic intervention
such as The Great Ban – which involved thousands of sub-
reddits and tens of thousands of users – may not effectively
address the diverse motivations and behaviors exhibited by
the affected users. In our work, this was exemplified by the
minority of resentful users who greatly increased their toxic-
ity. Understanding the factors contributing to such divergent
responses is paramount for developing effective moderation
strategies. Future research and practical applications should
delve into user profiling, considering individual characteris-
tics, past behavior, and contextual factors to effectively tailor
moderation interventions (Cresci, Trujillo, and Fagni 2022).
Moreover, the migration of a subset of toxic users and the
widespread presence of users experiencing heightened toxi-
city raises questions about the potential radicalization effect
of moderation and its unintended contribution to the ampli-
fication of echo chambers (Horta Ribeiro et al. 2021). It sug-
gests that some users may react negatively to certain mod-
eration actions, possibly leading to more extreme behaviors.
These observations highlight the delicate balance required in
content moderation, where the aim should not only be that
of reducing toxicity locally, but also preventing inadvertent
consequences that might exacerbate polarization or radical-
ization in some user groups.
Impact of resentful users. The finding that the vast ma-
jority of resentful users – who exhibited increased toxicity
following the ban – did not concurrently escalate their activ-
ity offers a novel perspective on the little-studied interplay
of toxicity and user activity. Contrary to the suspicion that
highly toxic users might also be highly active, our results
underscore a limited overlap between these two dimensions
of user behavior. This suggests that a considerable portion of
users expressing heightened toxicity post-ban did not trans-
late their resentment into increased participation on the plat-
form. In turn, this result partly mitigates the previous con-
cerns about the divergent and adverse reactions to The Great
Ban. Furthermore, the observation that users who intensi-
fied their toxic behaviors did not receive heightened posi-
tive social feedback from their peers resonates with some
recent research on the drivers of online hateful and toxic
speech. The latter posits that online toxicity may be driven
by the pursuit of social approval rather than by a desire to
harm (Jiang et al. 2023). To this end, our results demon-
strate that the Reddit community did not endorse or support
the increased toxicity exhibited by these users. According
to the aforementioned theories, toxic users who do not re-
ceive the expected levels of social approval should decrease
their toxicity over time (Jiang et al. 2023). However, we
measured overall stationary toxicity trends over the course
of the 7 months after the ban. Our results thus apparently
challenge the social approval theory, in support of compet-
ing theories according to which at least a subset of toxic
and hateful users seek amusement by harassing others, as in
trolling behavior (Chandrasekharan et al. 2022). On the one
hand, these results call for additional research to identify the
types and characteristics of toxic users. On the other hand,
they reinforce the need for nuanced and diversified modera-
tion strategies that are capable of addressing the complexity
and multiplicity of online user behavior.
Limitations. Our study is based on a large historical
dataset of Reddit comments shared by 17K users during a
long observation window of 14 months centered around The
Great Ban. Due to the nature of our dataset, our findings
may be specific to Reddit and the context of The Great Ban.
Therefore, caution is needed in generalizing the results to
other online platforms or different moderation interventions.
Similarly, online platforms are dynamic environments that
are subject to continuous changes in user behavior, commu-
nity norms, and platform policies. Our study covers a spe-
cific snapshot in time, albeit relatively long, which nonethe-
less limits the possibility to carry over our results to differ-
ent time periods and, partially, also to account for long-term
or evolving trends. Another limitation of our work lies in
its observational nature, which hinders the possibility of ac-
counting for external events or changes in the broader online
ecosystem that may have influenced user behavior indepen-
dently of The Great Ban. For this reason, care is needed in
establishing causal relationships from the findings presented
herein. Finally, our dataset lacks comprehensive information
about user demographics, motivations, or contextual factors.
Accounting for these aspects could provide a more nuanced
and actionable interpretation of our results. In this regard,
future research could investigate the unexplored interplay
between user characteristics and the outcomes of modera-
tion, also as a preliminary step towards the development of
targeted and personalized moderation interventions.
Ethical considerations. This research contributes to a
deeper understanding of the impact of content moderation,
shedding new light on the complexities of user reactions to
moderation interventions. This knowledge can inform future
developments of effective and nuanced moderation strate-
gies aimed at curbing online toxicity while minimizing un-
intended consequences. To this end, our work draws atten-
tion on the trade off between common versus minority good.
In our work this is exemplified by the ethical dilemma faced
by moderators who must decide whether to enforce interven-
tions that could possibly harm a minority of users by making
them resentful and vindictive, in order to provide a modest
benefit to the broader community.
Conclusions
The Great Ban was a massive deplatforming operation en-
forced to shut toxic communities on Reddit. To evaluate its
effectiveness, we analyzed 16M comments shared over the
course of 14 months by 17K users affected by the ban. Our
results reveal that 15.6% of the affected users abandoned
Reddit after the ban and that those who remained reduced
their toxicity by 6.6% on average. Despite this modest toxi-
city reduction, 5% of users increased their toxicity by more
than 70% of their pre-ban level. The presence of such re-
sentful users was widespread across the analyzed subreddits.
However, these users likely had little impact on the platform
given that only 16% of users increased both toxicity and ac-
tivity. Likewise, only 21% users increased toxicity and also
obtained positive engagement from the community.
Overall, our study provides new and nuanced insights into
the effectiveness of The Great Ban, including its undesired
consequences. As such, it can inform the development of
future and more effective moderation interventions and the
policing of online platforms. Specifically, future work could
extend our present results by delving deeper into the re-
lationship between user characteristics and the outcome of
moderation interventions. In turn, this would pave the way
to the development of targeted or personalized interventions
that could mitigate the undesired effects of moderation ac-
tions, such as those discussed in this work. Other promising
avenues of future research are the development of predictive
models for the outcome of moderation interventions. These
would allow to estimate the likely effects of an intervention
in advance of its application, enhancing the possibility to
plan the strategic enforcement of moderation actions.
Acknowledgments
This work is partially supported by the European Union
– Next Generation EU within the PRIN 2022 framework
project PIANO (Personalized Interventions Against Online
Toxicity) and by the Italian Ministry of Education and Re-
search (MIUR) in the framework of the CrossLab and the
FoReLab projects (Departments of Excellence).
References
Bail, C. A.; Argyle, L. P.; Brown, T. W.; Bumpus, J. P.; Chen,
H.; Hunzaker, M. F.; Lee, J.; Mann, M.; Merhout, F.; and
Volfovsky, A. 2018. Exposure to opposing views on social
media can increase political polarization. Proceedings of the
National Academy of Sciences, 115(37): 9216–9221.
Bouleimen, A.; Pagan, N.; Cresci, S.; Urman, A.; and Gior-
dano, S. 2023. Dynamics of toxic behavior in the Covid-19
vaccination debate. In CNA’23.
Chandrasekharan, E.; Jhaver, S.; Bruckman, A.; and Gilbert,
E. 2022.
Quarantined! Examining the effects of a
community-wide moderation intervention on Reddit. ACM
Transactions on Computer-Human Interaction (TOCHI),
29(4): 1–26.
Chandrasekharan, E.; Pavalanathan, U.; Srinivasan, A.;
Glynn, A.; Eisenstein, J.; and Gilbert, E. 2017. You can’t
stay here: The efficacy of Reddit’s 2015 ban examined
through hate speech. In ACM CSCW, 1–22.
Chang, R.-C.; May, J.; and Lerman, K. 2023.
Feedback
Loops and Complex Dynamics of Harmful Speech in On-
line Discussions. In SBP-BRiMS, 85–94.
Cresci, S.; Trujillo, A.; and Fagni, T. 2022. Personalized
interventions for online moderation. In ACM HT, 248–251.
Dias, N.; Pennycook, G.; and Rand, D. G. 2020. Emphasiz-
ing publishers does not effectively reduce susceptibility to
misinformation on social media. HKS Misinformation Re-
view, 1(1).
Gillespie, T. 2018. Custodians of the Internet: Platforms,
content moderation, and the hidden decisions that shape so-
cial media. Yale University Press.
Habib, H.; Musa, M. B.; Zaffar, M. F.; and Nithyanand, R.
2022. Are proactive interventions for Reddit communities
feasible? In AAAI ICWSM, 264–274.
Hanu, L.; and Unitary team. 2020.
Detoxify.
Github.
https://github.com/unitaryai/detoxify.
Horta Ribeiro, M.; Jhaver, S.; Reignier-Tayar, M.; West,
R.; et al. 2024. Deplatforming Norm-Violating Influencers
on Social Media Reduces Overall Online Attention Toward
Them. arXiv:2401.01253.
Horta Ribeiro, M.; Jhaver, S.; Zannettou, S.; Blackburn, J.;
Stringhini, G.; De Cristofaro, E.; and West, R. 2021. Do
platform migrations compromise content moderation? Evi-
dence from r/The Donald and r/Incels. In ACM CSCW.
Jhaver, S.; Boylston, C.; Yang, D.; and Bruckman, A. 2021.
Evaluating the effectiveness of deplatforming as a modera-
tion strategy on Twitter. In ACM CSCW, 1–30.
Jhaver, S.; Zhang, A. Q.; Chen, Q. Z.; Natarajan, N.; Wang,
R.; and Zhang, A. X. 2023.
Personalizing content mod-
eration on social media: User perspectives on moderation
choices, interface design, and labor. In ACM CSCW, 1–33.
Jiang, J.; Luceri, L.; Walther, J. B.; and Ferrara, E. 2023.
Social Approval and Network Homophily as Motivators of
Online Toxicity. arXiv:2310.07779.
Katsaros, M.; Yang, K.; and Fratamico, L. 2022. Recon-
sidering tweets: Intervening during tweet creation decreases
offensive content. In AAAI ICWSM.
Mekacher, A.; Falkenberg, M.; and Baronchelli, A. 2023.
The systemic impact of deplatforming on social media.
PNAS Nexus, 2(11).
Nogara, G.; Pierri, F.; Cresci, S.; Luceri, L.; T¨ornberg, P.;
and Giordano, S. 2023. Toxic Bias: Perspective API mis-
reads German as more toxic. arXiv:2312.12651.
Noor, N. B.; and Ahmed, I. 2023. An efficient technique
of predicting toxicity on music lyrics machine learning. In
IEEE ECCE, 1–5.
Papakyriakopoulos, O.; and Goodman, E. 2022. The impact
of Twitter labels on misinformation spread and user engage-
ment: Lessons from Trump’s election tweets. In The ACM
Web Conf, 2541–2551.
Pennycook, G.; Bear, A.; Collins, E. T.; and Rand, D. G.
2020. The implied truth effect: Attaching warnings to a sub-
set of fake news headlines increases perceived accuracy of
headlines without warnings. Management Science, 66(11).
Rieder, B.; and Skop, Y. 2021.
The fabrics of machine
moderation: Studying the technical, normative, and organi-
zational structure of Perspective API. Big Data & Society,
8(2).
Saleem, H. M.; and Ruths, D. 2018. The aftermath of dis-
banding an online hateful community. arXiv:1804.07354.
Seeliger, M.; and Baum, M. 2023. When Twitter blocked
Trump: The paradox, ambivalence and dialectic of digital-
ized publics. Philosophy & Social Criticism.
Shen, Q.; and Ros´e, C. P. 2022. A tale of two subreddits:
Measuring the impacts of quarantines on political engage-
ment on Reddit. In AAAI ICWSM, 932–943.
Trujillo, A.; and Cresci, S. 2022. Make Reddit Great Again:
Assessing community effects of moderation interventions on
r/The Donald. In ACM CSCW, 1–28.
Trujillo, A.; and Cresci, S. 2023.
One of many: As-
sessing user-level effects of moderation interventions on
r/The Donald. In ACM WebSci, 55–64.
Trujillo, A.; Fagni, T.; and Cresci, S. 2023.
The DSA
Transparency Database: Auditing self-reported moderation
actions by social media. arXiv:2312.10269.
Trujillo, M. Z.; Rosenblatt, S. F.; Jauregui, G. D. A.; Moog,
E.; Samson, B. P. V.; H´ebert-Dufresne, L.; and Roth, A. M.
2021. When the echo chamber shatters: Examining the use
of community-specific language post-subreddit ban. In ACL
WOAH.
Zannettou, S. 2021. “I Won the Election!”: An empirical
analysis of soft moderation interventions on Twitter. In AAAI
ICWSM.
","Deplatforming—a moderation practice dubbed deplatforming—is by far the most frequently adopted. A famous example is the banishment of Donald Trump from Facebook and X (formerly Twitter) in 2021. Other notable examples are the deplatforming of some toxic influencers on X and the permanent shut of racist, sexist, and generally hateful communities on Reddit. In 2020 Reddit hosted a massive deplatforming operation that involved the ban of around 2,000 subreddits on the grounds of their promotion of identity- and vulnerability-based hate. Among the banned communities were some very popular subreddits such as r/The Donald and r/ChapoTrapHouse. This event is commonly referred to as The Great Ban and is currently one of the biggest bans in the history of social media. Despite its impact on multiple communities and on a large number of users within and beyond Reddit, its effects remain underexplored.nan"
"Electronic Health Record (EHR) systems have generated vast amounts of medical data, offering opportunities for healthcare services improvement through deep learning. Although, the diverse modalities and feature structures in EHR data bring challenges to deep learning models. Many current approaches mainly rely on hand-crafted model architectures, resulting in sub-optimal model architectures and limited performance. Therefore, AutoFM is proposed to automate the process of model design for mining EHR data, searching for the optimal model architectures. Experiments show that AutoFM not only achieves significant performance improvement over existing methods but also discovers meaningful network architectures effectively.","The growing use of Electronic Health Record (EHR) systems has resulted in substantial patient EHR data, creating opportunities for healthcare service improvement using deep learning methods. However, the complex and diverse modalities in EHR data pose challenges for effective deep predictive model design. Numerous existing studies primarily focus on designing hand-crafted model architectures for integrating multimodal EHR data, requiring considerable domain expertise. To address these issues, recent research has explored the use of neural architecture search (NAS) techniques to automatically search for suitable architectures, eliminating human intervention. Although these methods exhibit advantages over hand-crafted approaches, they still face limitations such as diversifying the search space, customizing the search optimization, and deriving the optimal architecture. To tackle these challenges, AutoFM, a novel NAS framework, is proposed, which introduces a two-stage search space, a customized loss term within the bi-level optimization formulation, and a pruning-based algorithm.","AutoFM proposes a comprehensive approach for discovering optimal model architectures for multimodal EHR data. At its core, it involves a two-stage search space that addresses modality-specific and multi-modal fusion architecture optimization. The first stage focuses on designing specialized encoding modules for each modality, incorporating feature encoding and interaction operations for early fusion strategies. The second stage involves searching for multi-modal fusion architectures, including a feature selector and a searchable fusion module that identify the optimal modalities and fusion operations. To address challenges in optimizing the search algorithm, AutoFM introduces a customized loss term within the bi-level optimization formulation, promoting diversity in feature selection. Additionally, a pruning-based algorithm is employed to select the optimal architectures after training the supernet, maintaining the performance of the derived architecture.","The effectiveness of AutoFM is demonstrated through extensive evaluations on real-world multi-modal EHR data. It achieves significant performance improvements over existing state-of-the-art methods across four prediction tasks: ARF 12h, Shock 12h, Mortality 48h, and Diagnoses 48h. AutoFM consistently outperforms baselines in terms of AUROC, AUPR, and R@K metrics. Ablation studies confirm the importance of each modality in the final prediction and the effectiveness of the proposed penalty term in guiding feature selection during the fusion process. Additionally, a comparison with other discretization methods shows that AutoFM's pruning-based approach outperforms DARTS and DARTS-PT in deriving the optimal architecture.","AutoFM, a novel NAS framework, is proposed for automating the fusion of multi-modal EHR data. The framework introduces a two-stage search space, a customized loss term, and a pruning-based architecture selection method. Experimental results demonstrate the superiority of AutoFM over existing methods, achieving significant performance improvements across various prediction tasks. AutoFM offers a powerful tool for automated model design and effective mining of EHR data.",Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions,"Suhan Cui, Jiaqi Wang, Yuan Zhong, Han Liu, Ting Wang, Fenglong Ma","Automated Fusion of Multimodal Electronic Health Records for Better
Medical Predictions
Suhan Cui1, Jiaqi Wang1, Yuan Zhong1, Han Liu2, Ting Wang3, Fenglong Ma1∗
1Pennsylvania State University, 2Dalian University of Technology, 3Stony Brook University
1{suhan, jqwang, yfz5556, fenglong}@psu.edu, 2liu.han.dut@gmail.com, 3twang@cs.stonybrook.edu
Abstract
The widespread adoption of Electronic Health Record
(EHR) systems in healthcare institutes has generated
vast amounts of medical data, offering significant op-
portunities for improving healthcare services through
deep learning techniques.
However, the complex and
diverse modalities and feature structures in real-world
EHR data pose great challenges for deep learning model
design. To address the multi-modality challenge in EHR
data, current approaches primarily rely on hand-crafted
model architectures based on intuition and empirical
experiences, leading to sub-optimal model architectures
and limited performance. Therefore, to automate the
process of model design for mining EHR data, we pro-
pose a novel neural architecture search (NAS) frame-
work named AutoFM, which can automatically search
for the optimal model architectures for encoding di-
verse input modalities and fusion strategies. We con-
duct thorough experiments on real-world multi-modal
EHR data and prediction tasks, and the results demon-
strate that our framework not only achieves significant
performance improvement over existing state-of-the-art
methods but also discovers meaningful network archi-
tectures effectively1.
Keywords: Electronic Health Records, Neural Archi-
tecture Search, Multimodal Fusion
1
Introduction
Electronic Health Record (EHR) systems have been ex-
tensively adopted in numerous hospitals and healthcare
institutions, resulting in the generation of vast amounts
of patient EHR data on a daily basis. This data holds
significant potential for various predictive tasks, includ-
ing but not limited to diagnosis prediction [1,16], med-
ical recommendation [22], health risk prediction [2,17],
and hospital readmission [10]. However, the heteroge-
neous and multimodal nature of EHR data poses signifi-
∗Corresponding author.
1Source code can be found via the link: https://github.com/
SH-Src/AUTOMF
cant challenges in the design of effective deep predictive
models.
Most existing studies [6,19,26,28] primarily focus on
the design of hand-crafted model architectures for inte-
grating multimodal EHR data. However, this approach
necessitates considerable domain expertise, which may
introduce the potential for human bias.
To address
these concerns, recent research [4,27] has proposed the
utilization of neural architecture search (NAS) tech-
niques [5] to automatically search for suitable architec-
tures for modeling multimodal EHR data, thereby elim-
inate the need for human intervention. Although these
methods demonstrate improved performance compared
to hand-crafted approaches, they still encounter certain
issues:
C1 – Diversifying the Search Space Current
approaches [4, 27] typically employ a uniform search
space across all modalities when conducting neural ar-
chitecture search (NAS). However, EHR data encom-
passes diverse modalities, including tabular demograph-
ics, discrete medical codes, continuous monitoring data
from ICU stays, and unstructured clinical notes. A uni-
form search space fails to adequately capture the het-
erogeneity of these modalities.
Furthermore, existing
methods primarily utilize simple operations like con-
catenation and addition within the fusion search space,
which may not effectively capture the complex interac-
tions among different EHR modalities. Therefore, it is
crucial to explore more suitable search spaces for mul-
timodal feature encoding and fusion that can better ac-
commodate the diverse nature of EHR modalities.
C2 – Customizing the Search Optimization
Existing approaches utilize either evolutionary NAS [21]
or differentiable architecture search (DARTS) [15] to
find the optimal architecture within the defined search
space.
Although DARTS represents a significant effi-
ciency improvement compared to evolutionary NAS, it
often encounters issues of robustness [29] and may strug-
gle to identify suitable architectures. Given the com-
plexity of the search space in our specific task, directly
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
arXiv:2401.11252v1  [cs.LG]  20 Jan 2024
applying DARTS may result in poor performance for
the searched architectures. Consequently, a customized
search algorithm is necessary to discover meaningful ar-
chitectures for effectively fusing multimodal EHR data.
C3 – Deriving the Optimal Architecture
DARTS-based methods, such as AutoMed [4], deter-
mine the final architecture by selecting operations based
on the magnitudes of architecture weights obtained
from the trained supernet.
However, it has been ob-
served that the operation with the highest architectural
weight on the supernet does not necessarily correspond
to its actual contribution to the generalization perfor-
mance [25]. This arbitrary discretization approach can
result in a significant drop in performance, a concern
that becomes more pronounced when modeling multi-
modal EHR data due to the complexity of the search
space. Thus, the development of a new discretization
technique tailored to our specific task is necessary to
derive an optimal architecture.
Our Approach To overcome the aforementioned
challenges,
we
propose
a
novel
neural
architec-
ture search (NAS) framework called AutoFM for
Automatically Fusing Multi-modal EHR data. Aut-
oFM addresses C1 by introducing a new two-stage
search space.
The first stage, called modality-specific
search, focuses on designing specialized encoding mod-
ules for each input modality, incorporating feature en-
coding and feature interaction operations to explore po-
tential early fusion strategies. The second stage, known
as multi-modal fusion search, focuses on creating late
fusion architectures.
This involves a feature selector
component to determine the selected modalities and a
searchable fusion component to identify the optimal fu-
sion operation.
To tackle C2, we introduce a customized loss term
within the original bi-level optimization formulation of
DARTS. This customized loss promotes diversity within
the feature selector, guiding the search algorithm to-
ward discovering more meaningful architectures. To ad-
dress C3, we devise a novel pruning-based algorithm to
select the optimal architectures after training the su-
pernet. This algorithm effectively preserves the perfor-
mance of the derived architecture during the discretiza-
tion process.
We extensively evaluate our proposed
method on real-world multi-modal EHR data, show-
ing its superiority over existing state-of-the-art models.
Through these experiments, we demonstrate the effec-
tiveness and advantages of our approach.
2
Related Work
2.1
Modeling Multi-modal EHR data Several
approaches have been proposed to leverage multi-modal
electronic health record (EHR) data for enhanced pre-
dictive modeling [28, 30]. For instance, studies such as
RAIM [26], DCMN [6], and MNN [19] integrate var-
ious data sources, including patient monitoring data
and clinical events, to predict outcomes such as ICU
stay length, mortality, and diagnoses. However, these
approaches rely on hand-crafted neural networks, lim-
iting their applicability to pre-defined modalities and
tasks. In contrast, MUFASA [27] and AutoMed [4] em-
ploy neural architecture search (NAS) methods to dis-
cover more suitable model architectures for multi-modal
EHR data. However, these methods either come with
high computational costs or impose constraints on input
features and fusion strategies.
Our work distinguishes itself by introducing a com-
prehensive search space encompassing modality-specific
architectures and diverse multi-modal fusion strategies.
Besides, we propose a new optimization loss on top of
the more efficient DARTS [15] algorithm, enabling the
discovery of more reasonable and advantageous archi-
tectures for multi-modal EHR data.
2.2
Neural Architecture Search Neural architec-
ture search (NAS) [5] automates the process of find-
ing optimal deep neural network architectures. Differ-
ent approaches such as reinforcement learning [31] and
evolutionary search [21] have been used, but they re-
quire significant computational costs. To improve effi-
ciency, more advanced techniques have been employed,
such as weight sharing [18], sequential model-based op-
timization [14], and Bayesian optimization [12]. A re-
cent approach called differentiable architecture search
(DARTS) [15] has emerged, which achieves high search
efficiency by using a continuous relaxation of the dis-
crete architecture. This work addresses the limitations
of DARTS when applied to multi-modal EHR data. It
introduces an additional penalty during supernet train-
ing to encourage the selection of more meaningful ar-
chitectures. Additionally, a new pruning-based archi-
tecture selection method is proposed to maintain the
supernet’s performance during discretization.
3
Methodology
As depicted in Figure 1, our proposed AutoFM frame-
work takes multiple heterogeneous EHR data as input.
To effectively handle this diverse data, we introduce
a novel multimodal search space that enables the au-
tomatic search for optimal architectures for modality
representation and fusion strategies. This search space
allows our framework to discover the most suitable ap-
proaches for representing each modality and effectively
fuse them together for improved predictive modeling.
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Patient 
Demographic
Clinical 
Notes
Continuous 
Events
Discrete 
Events
Prune
Layer 1
Layer 1
Layer 1
Layer 1
. . . 
Layer K
. . . 
. . . 
Layer K
. . . Layer K
. . . 
Layer K
. . . 
. . . 
Modality Specific Search
(Sec 3.2.1)
. . . 
Multi-modal Fusion Search
(Sec 3.2.2)
Prediction
(Sec 3.3)
Derived 
Architecture 
Supernet
Bi-level Optimization
Optimization
(Sec 3.4)
(Sec 3.4.1)
(Sec 3.4.2)
Figure 1: Overview of the proposed AutoFM.
3.1
Multimodal
EHR
Data
Embedding Our
model takes four modalities as the input, including
two types of sequential data – (1) continuous events
M = [m1, · · · , mT ] ∈ Rd1×T and (2) discrete events
E = [e1, · · · , eT ] ∈ Rd2×T and two types of static data
– (3) patient demographics p ∈ Rd3 and (4) the corre-
sponding clinical note n ∈ Rd4, where T is the number
of time slots and n is the output of [CLS] from the
pre-trained language model - ClinicalBERT [10]. The
details of data processing can be found in Section 4.1.
We first map these features into the same latent
space by a fully connected layer:
Rm = W⊤
m[m1, · · · , mT ] + bm,
(3.1)
Re = W⊤
e [e1, · · · , eT ] + be,
(3.2)
sp = W⊤
p p + bp,
(3.3)
sn = W⊤
n n + bn,
(3.4)
where Wm ∈ Rd1×de, We ∈ Rd2×de, Wp ∈ Rd3×de,
Wn ∈ Rd4×de, be ∈ Rde, bm ∈ Rde, bp ∈ Rde, and
bn ∈ Rde are learnable parameters.
3.2
Multi-Modal Search Space Design Our ap-
proach incorporates two stages of searchable modules:
(1) modality-specific search and (2)
multimodal
fusion search. In the first stage, we focus on designing
modality-specific search spaces tailored to each individ-
ual modality. These search spaces take into account not
only the encoding of the current feature within a modal-
ity but also the potential early interactions between dif-
ferent modalities.
This allows for the exploration of
various encoding strategies and fusion techniques at the
modality level.
Moving to the second stage, our approach encom-
passes a search space specifically designed for late fu-
sion architectures.
This search space consists of two
crucial modules: the feature selector and the searchable
fusion module. The feature selector component deter-
mines which modalities should be selected and incor-
porated into the fusion process. The searchable fusion
module then identifies the optimal fusion operation to
be applied. By jointly optimizing the feature selection
and fusion operation within this search space, we en-
able the framework to automatically discover effective
strategies for multi-modal feature fusion.
In the following sections, we will provide more
detailed explanations of each stage, highlighting their
respective contributions and functionalities.
3.2.1
Modality Specific Search To facilitate the
search process using differentiable methods, we assume
that the architecture for each modality type consists of
a network comprising K sequentially connected layers,
as illustrated in Figure 1. Consequently, our objective
is to search for the optimal operation for each layer k.
To make the search space compatible with differentiable
search methods, we define a mixed operation at each
layer. This mixed operation is a weighted sum of all
operations within a predefined set O. The formulation
can be expressed as follows:
(3.5)
xk =
X
o∈O
exp(α(k)
o )
P
o′∈O exp(α(k)
o′ )
o(xk−1),
k = 1, · · · , K,
where xk represents the feature of layer k.
x0 can
be any of the input features [Rm, Re, sp, sn]. α’s are
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Table 1: Modality-specific operations.
Feature
Operation
Operation Description
Static
(Ost)
Identity
This is a default operation that does not transform the input feature.
Linear Layer
Apply linear transformation with ReLU activation, where W1 ∈ Rde×de and b1 ∈ Rde:
o(x) = ReLU(W1x + b1)
Static-Static
Feature Interaction
Apply concatenation and feed-forward layer to model the interaction between the current
feature and the other static feature, where W2 ∈ R2de×de, b2 ∈ Rde and x′ is the input feature
of the other static modality sp or sn: o(x) = W2[x; x′] + b2
Static-Sequential
Feature Interaction
Apply the attention mechanism to model the interaction with the current feature as the query
and the other features as the keys. Since we have two sequence features, we then have two
interaction operations, where Wq, Wk, Wv ∈ Rde×de:
o(x) = Softmax

(Wqx)⊤·(Wkx′)
√de

· (Wvx′), x′ ∈ {Rm, Re}
Sequential
(Osq)
Identity
This is a default operation that does not transform the input feature.
Recurrent Layer
Apply Recurrent Neural Network(RNN) to process the input feature, which is able to capture
the temporal patterns. In our model, we use Gated Recurrent Unit (GRU) [3]
as the basic operation.
Self-Attention Layer
Apply self-attention mechanism [24] to model the long-term dependencies
of the sequence feature.
1-D Convolution
Apply 1-D convolution operation to process the feature and capture the local correlations. We
use the padding and strides that can maintain the same shape as the input tensor.
Feed-forward Layer
Apply a linear layer to all positions of the sequence feature.
Sequential-Sequential
Feature Interaction
Apply cross-modal attention mechanism to model the interaction between two sequence
features. The current feature will serve as the queries, and the other feature will serve as the keys.
The formulation is the same as Static-Sequential Feature Interaction except that the queries
become sequential features this time.
architecture parameters that measure the weights for
candidate operations, and we have four groups of α’s in
total for different modalities.
Next, we list the candidate operation sets for each
modality in Table 1.
As we have two types of input
modalities, we design two distinct modality-specific
search spaces to cater to their specific characteristics.
For both types of features, in addition to the feature
encoding operations, we also incorporate interaction
operations. These interaction operations handle the
interactions between the current modality and other
modalities, both within the same category and across
different categories.
By including these interaction
operations, our method is capable of exploring how to
effectively process all the input features and discover
fine-grained early fusion operations among different
modalities. This allows for comprehensive modeling and
integration of the various modalities present in the EHR
data.
3.2.2
Multimodal Fusion Search Once we obtain
the output features for all modalities from the first
stage, we apply a fixed max pooling operation to
the encodings of sequence features over the sequence
length dimension.
This step ensures that we have
encodings of the same shape for all modalities, denoted
as [z1, z2, z3, z4] ∈ Rde. Next, we will discuss how to
effectively fuse these features using searchable modules.
Our fusion module follows a directed acyclic graph
(DAG) design.
Given the input features [z1, · · · , z4],
we add one computation node at each step, and the
newly added nodes can connect to all previous nodes
and features, as shown in Figure 1.
Assuming
we
have
a
total
of
C
nodes,
at
node c, we have the following features as inputs:
[z1, · · · , z4, g1, · · · , gc−1], where the g’s represent the
output features for the corresponding nodes. Our goal
is to search for two operations: (1) selecting the pre-
vious features that should be taken as inputs to the
current node, and (2) determining the fusion operation
for the selected inputs. To accomplish these steps, we
design two searchable modules: the feature selector and
the searchable fusion module. These modules enable us
to dynamically and adaptively determine the most rele-
vant features and fusion operations at each node of the
fusion module.
Feature Selector To handle the feature selection
at each node c, we define an operation set Oa that con-
sists of only two operations: Identity and Zero. These
operations determine whether to select the correspond-
ing feature or not. Similar to Eq. (3.5), we apply the
mixed operation over Oa to each input feature for node
c. As a result, at node c, we obtain a list of (4 + c − 1)
features, denoted as uc = [u(c)
1 , · · · , u(c)
4+c−1], where the
values of these features can be either 0 or the original
values. This process allows us to dynamically select rel-
evant features based on the search algorithm’s decisions
at each node.
Searchable Fusion To determine the fusion oper-
ation for the selected features at each node c, we define
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Table 2: Fusion operations.
Operation
Operation Description
Sum
This operation sums all the input features together to fuse them: o(uc) = u(c)
1
+ u(c)
2
+ · · · + u(c)
4+c−1
MLP
This operation applies a multi-layer perceptron to the sum of all input features, where W3 ∈ Rde×de
and b3 ∈ Rde: o(uc) = ReLU(W3u′(c) + b3), and u′(c) = u(c)
1
+ u(c)
2
+ · · · + u(c)
4+c−1
Attentive
Sum
This operation first uses linear projection to generate weights for all features and then applies
a weighted sum to aggregate all features, where Wϕ ∈ Rde and bϕ ∈ R: o(uc) = P4+c−1
i=1
ϕiu(c)
i ,
[ϕ1, · · · , ϕ4+c−1] = Softmax(l1, · · · , l4+c−1), and li = Wϕu(c)
i
+ bϕ, i = 1, · · · , 4 + c − 1
a candidate set Ob that contains different fusion strate-
gies, as listed in Table 2. These fusion strategies repre-
sent different ways of combining the selected features.
Similar to the feature selection step, we apply mixed op-
erations over Ob at each node to determine the fusion
operation. This process allows us to explore and search
for the optimal fusion strategy that effectively combines
the selected features.
3.3
Prediction To obtain a comprehensive represen-
tation of the entire EHR data, we linearly combine all
the node features from the multi-modal fusion module
[g1, · · · , gC], i.e., h = PC
c=1 wcgc, where wc ∈ R is the
learned weight.
For the binary classification problem, we use sig-
moid as the activation function to calculate the predic-
tion probability as follows:
(3.6)
ˆy = sigmoid(Wyh + by).
For the multi-label classification problem, we use soft-
max to generate the probability score for all classes as
follow:
(3.7)
ˆy = softmax(Wyh + by),
where ˆy ∈ RP and P is the number of classes.
3.4
Optimization
3.4.1
Supernet Training We use the bi-level op-
timization technique as DARTS [15] to optimize the
model architecture weights and all other learnable pa-
rameters simultaneously:
(3.8)
min
α Lval(W∗(α, β, γ), α, β, γ) + λ · Penalty(β)
s.t. W∗(α, β, γ) = argminWLtrain(W, α, β, γ)
where α, β, and γ are the architecture weights involved
in the modality-specific search, feature selector, and
searchable fusion, respectively.
W denotes all other
learnable parameters in the network, and Lval and
Ltrain mean the validation loss and training loss.
Additionally,
we
add
one
more
penalty
term
Penalty(β) to the architecture weights of the feature
Algorithm 1 Pruning Supernet
Input: A pretrained supernet S, Set of mixed operations
E from S
Output:
Set of selected operations {o∗
e}e∈E, Pruned
supernet S′
while True do
randomly select a mixed operation e ∈ E
for all operation o on e do
evaluate the validation performance of S when o is
removed (S\o)
end for
remove
the
worst
operation
for
e:
o′
e
←
arg maxo Evaluate(S\o)
re-normalize architecture weights on e for remaining
operations
finetune the remaining supernet S′ for a few steps
if ∀e ∈ E, |{o|o ∈ e}| = 1 then
break
end if
end while
selector β in order to make the feature selector select
diverse modalities at different step nodes. We achieve
that by maximizing the cross entropy of any two differ-
ent steps of β:
(3.9)
Penalty(β) = −
C
X
c1=1
C
X
c2=1
CrossEntropy(β[c1][: 4], β[c2][: 4])
Note that we only take the first four values of β at
each step, which indicates the selection of input modal-
ities [z1, · · · , z4].
In this way, the penalty term will
lead the feature selector to select different combina-
tions of input modalities for fusion at different steps.
However, the selection of the following computation
nodes [g1, · · · , gC] will not be affected, which enables
the model to search for more complex fusion strategies
without any constraints.
3.4.2
Deriving the Optimal Architecture After
the supernet training, we propose a new way to derive
the final architecture that gradually prunes operations
from the supernet. We introduce the process of pruning
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Table 3: Statistics of the four datasets.
Task
ARF
Shock
Mortality
Diagnoses
# data samples
9,393
12,289
7,440
7,440
Dimension of p
96
97
96
96
Dimension of E
680
739
1,001
1,001
Dimension of M
4,452
5,056
6,726
6,726
Recorded hours T
12
12
48
48
in Algorithm 1.
Specifically, we denote the trained
supernet as S and the set of all mixed operations as
E.
The goal is to prune the supernet until only one
operation o∗
e is left for each mixed operation e ∈ E. In
order to achieve that without too much performance
drop from the supernet, we propose to gradually prune
unimportant operations from the supernet, where the
importance of each operation is determined by its
contribution to the validation performance.
For each iteration, we first sample a mixed opera-
tion from the supernet and then prune the worst oper-
ation from it if removing the operation brings the best
validation performance. Then, we will fine-tune the re-
maining architecture until it converges again. The prun-
ing will stop when all mixed operations from the super-
net only have one optimal operation remaining. In this
way, we can observe how the performance drops during
the whole process, and select the relatively better archi-
tecture before it drops too much. In this way, we can get
the final architecture with nearly the same performance
as the trained supernet without training from scratch.
4
Experiments
4.1
Experimental Setups Data Processing. Fol-
lowing FIDDLE [23], we extract data from the MIMIC-
III dataset [11] and specifically focus on the 17,710
patients (23,620 ICU visits) recorded from 2008 to
2012. We extract the structured features within 48/12
hours using FIDDLE. These features are randomly di-
vided into the training, validation, and testing sets in
a 7:1.5:1.5 ratio. The unstructured texts within 48/12
hours are obtained by consolidating the latest notes of
each category into one document and aligning them with
the other structured features. The data statistics can be
found in Table 3.
Prediction Tasks. We aim to address four prediction
tasks: (1) Acute Respiratory Failure at 12 hours (ARF
12h), (2) Shock at 12 hours (Shock 12h), (3) Mortality
at 48 hours (Mortality 48h), and (4) Diagnoses at 48
hours (Diagnoses 48h). The first three tasks involve bi-
nary classification, aiming to predict whether patients
will experience these severe conditions during their ICU
stays based on the initial 12/48 hours of data. The last
task focuses on predicting diagnosis codes upon hospital
discharge based on the initial 48 hours of data, consti-
tuting a multi-label classification problem. After ex-
tracting the top three digits of ICD-9 codes2, we have
1,025 disease labels for predictions.
Baselines.
We include both handcrafted and auto-
mated models as our baselines. Handcrafted mod-
els: we include vanilla LSTM [9] and CNN [7] models
as baselines. Following the settings in [28], we combine
LSTM, CNN, Transformer [24], and Star-Transformer
[8] with ClinicalBERT using Multimodal Adaptation
Gate (MAG) [20], resulting in eight baseline models
as shown in Table 4. Automated models: we also
apply MUFASA [27] to our prediction tasks as a NAS
baseline for multi-modal EHR data.
Implementation. During the supernet training stage,
we employ the Adam optimizer [13] with a learning rate
of 1e−4 for the network parameter W and 1e−5 for the
architecture parameters α, β, and γ. The loss function
is cross entropy. The batch size for all tasks is set to 64,
and the hidden dimension de is set to 256. To balance
the bi-level optimization, the penalty term weight λ is
set to 0.1. In the first stage, the number of layers K
is set to 2, while in the second stage, the number of
step nodes C is set to 3. The entire supernet training
takes less than one hour on an NVIDIA A100 GPU,
demonstrating the efficiency of the search algorithm.
During the pruning of the trained supernet, we utilize
the same settings, except for the fine-tuning phase,
where we use a learning rate of 2e − 6.
Evaluation Metrics. Following [28], for three binary
classification tasks, we use AUROC (Area Under the
Receiver Operating Characteristic curve) and AUPR
(Area Under the Precision-Recall curve) to evaluate
the performance. For the diagnosis prediction task, we
use Top-K Recall (R@K) instead and separately set
K to be 10, 20, or 30.
For all methods, we run the
experiments for five times and report the mean values
for a fair comparison.
4.2
Performance Evaluation The results of the
four tasks are presented in Table 4, where it can be ob-
served that our method achieves the best performance
across all metrics compared to the baseline approaches.
These results demonstrate the superiority of our pro-
posed method over existing state-of-the-art baselines.
For the three binary classification tasks aiming to
predict emergent conditions within a short time win-
dow, real-time time-series data, such as vital signs, play
a crucial role in achieving high performance. This im-
portance of real-time data is further confirmed by our
2https://www.cdc.gov/nchs/icd/icd9.htm
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Table 4: Performance comparison on four tasks. The second-best results are marked by underline.
Tasks
ARF 12h
Shock 12h
Mortality 48h
Diagnoses 48h
Metrics
AUROC
AUPR
AUROC
AUPR
AUROC
AUPR
R@10
R@20
R@30
LSTM
0.7377
0.3268
0.7364
0.2940
0.8827
0.5427
0.1516
0.1932
0.2224
CNN
0.7348
0.3214
0.7356
0.2775
0.8876
0.5479
0.1670
0.2501
0.2990
LstmBert
0.7310
0.3086
0.7403
0.2852
0.8755
0.5362
0.2299
0.3320
0.3994
BertLstm
0.7441
0.3200
0.7391
0.2912
0.8811
0.5409
0.2170
0.3298
0.4086
CnnBert
0.7201
0.2925
0.7348
0.2891
0.8853
0.5447
0.2206
0.3110
0.3693
BertCnn
0.7389
0.3292
0.7268
0.2776
0.8777
0.5450
0.2250
0.3346
0.4072
EncoderBert
0.7350
0.3117
0.7377
0.2857
0.8800
0.5296
0.1985
0.2459
0.2825
BertEncoder
0.6893
0.2633
0.7164
0.2818
0.8663
0.5183
0.2198
0.3366
0.4108
StarBert
0.7238
0.3194
0.7110
0.2869
0.8729
0.4878
0.2265
0.3305
0.3996
BertStar
0.6824
0.2641
0.7044
0.2825
0.8644
0.4724
0.2215
0.3173
0.4026
MUFASA
0.7362
0.3088
0.7295
0.2735
0.8812
0.5436
0.0903
0.1156
0.1296
AutoFM
0.7565
0.3593
0.7463
0.3039
0.8900
0.5514
0.3338
0.4780
0.5658
Table 5: Ablation study on input modalities
Task
ARF
Shock
Mortality
Diagnoses
Metrics
AUPR
AUPR
AUPR
R@10
AutoFM
0.3593
0.3039
0.5514
0.3338
- Demographic
0.3376
0.2822
0.5553
0.3310
- Continuous Events
0.2966
0.2310
0.4010
0.3074
- Discrete Events
0.3551
0.3027
0.5336
0.3294
- Clinical Notes
0.3362
0.2773
0.5501
0.3265
ablation study in Section 4.3.
However, existing ap-
proaches fail to adequately distinguish the significance
of such modalities and treat all modalities equally in the
input, leading to subpar performance.
In the case of the multi-label diagnosis prediction
task, where the model is required to predict from a
vast set of 1,025 disease groups, the task complexity
is higher compared to the other tasks. Consequently,
models employing advanced fusion techniques outper-
form those using simple fusion methods. Notably, MU-
FASA performs significantly worse than other baselines
in this task.
This can be attributed to the large la-
bel space, which makes it challenging for MUFASA to
converge to a favorable local optimum.
4.3
Ablation Study on Input Modalities In this
ablation study, our objective is to assess the importance
of each modality in the final prediction by systematically
removing them from the model input alternatively. The
experimental results are presented in Table 5. It can
be observed that removing any modality leads to a
drop in performance, highlighting the significance of
considering multimodal EHR data as input for the
model. Notably, the time series modality predominantly
encompasses vital signs information, which is a strong
indicator of emergency conditions occurring during ICU
stays and aids in accurate diagnoses.
Consequently,
removing continuous event features from the input
Table 6: Results on different optimization methods.
Tasks
ARF
Shock
Mortality
Diagnoses
Metrics
AUPR
AUPR
AUPR
R@10
Supernet
0.3565
0.3053
0.5549
0.3251
Supernet⊖
0.3445
0.3027
0.5473
0.3257
AutoFM
0.3593
0.3039
0.5514
0.3338
AutoFM⊖
0.3410
0.3031
0.5471
0.3316
leads to the largest performance drop compared to the
original framework.
4.4
Effect of Feature Selection Penalty We in-
troduce a new loss term in the optimization process
to guide the selection of optimal modalities in the fu-
sion stage. To assess the effectiveness of this designed
penalty term (Eq.(3.9)), we conducted a study, and the
results are presented in Table 6.
“Supernet” refers to the learned supernet using our
proposed AutoFM with Eq. (3.8), while “Supernet⊖”
indicates the supernet without the penalty term defined
in Eq. (3.9).
We observe that the inclusion of the
penalty term improves the performance of the supernet
across all three binary classification tasks.
For the
diagnoses prediction task, comparable performance is
still achieved even without the penalty term.
These
results confirm the term’s ability to ensure the diversity
of feature selection in the multi-modal fusion process.
We
also
compare
the
derived
model
from
Supernet⊖, denoted as “AutoFM⊖”, which still em-
ploys the proposed pruning-based architecture dis-
cretization outlined in Algorithm 1. Notably, without
the designed penalty, the derived model AutoFM⊖ ex-
hibits inferior performance compared to our proposed
AutoFM. This comparison further demonstrates the
necessity and effectiveness of the penalty term in the
optimization process.
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Table 7: Results on different discretization methods.
Tasks
ARF
Shock
Mortality
Diagnoses
Metrics
AUPR
AUPR
AUPR
R@10
DARTS
0.3124
0.2891
0.5536
0.3332
DARTS-PT
0.3433
0.2986
0.5444
0.3268
AutoFM
0.3593
0.3039
0.5514
0.3338
Modality Specfic Search
Multimodal Fusion
M
R_m
E
R_e
p
s_p
n
s_n
layer 1
interact(M)
interact(E)
interact(n)
layer 1
1D conv
SelfAttention
interact(E)
layer 1
Identity
FFN
interact(M)
layer 1
interact(M)
interact(p)
layer 2
interact(M)
interact(n)
z_3
layer 2
interact(E)
z_1
layer 2
SelfAttention
RNN
interact(M)
z_2
layer 2
interact(E)
interact(p)
z_4
sum+att
att+mlp
att
h
Figure 2:
Searched architecture.
The blue arrows
represent fixed operations, while the other black arrows
are all searched operations. The interact(·) means the
interaction operation with the corresponding feature.
For the steps nodes [g1, g2, g3], we omit the notations
in the figure and fill the node with the selected fusion
operations like (sum+att).
4.5
Pruning-based
Architecture
Selection In
Section 3.4.2, we present a pruning-based discretization
method to derive the optimal architecture. To evaluate
the effectiveness of this approach, we derive two models
from the same supernet trained using Eq. (3.8), employ-
ing the approaches used in DARTS [15] and DARTS-
PT [25]. The results are shown in Table 7. The perfor-
mance of the derived models using our pruning-based
approach is significantly better compared to the models
derived using DARTS and DARTS-PT. This indicates
that our method effectively captures the optimal archi-
tecture from the supernet and achieves superior per-
formance. These results provide strong evidence sup-
porting the effectiveness of our proposed discretization
method.
4.6
Architecture Study Figure 2 provides an ex-
ample of the searched architecture for the ARF task. It
demonstrates the effectiveness of our approach in cap-
turing the interactions between different modalities dur-
ing the modality-specific search stage. Furthermore, in
the second stage of multi-modal fusion, our method is
able to explore different combinations of input modal-
ities [z1, · · · , z4] at different steps.
This is achieved
through the penalty imposed by the additional loss
term, which encourages diversity in the feature selec-
tion process.
As a result, our fusion module can ef-
fectively determine the optimal fusion strategy, leading
to improved performance in capturing the underlying
patterns and relationships within the multi-modal EHR
data.
5
Conclusion
In this paper, we introduced AutoFM, a novel Neu-
ral Architecture Search (NAS) framework designed for
automatically fusing multi-modal EHR data. Our ex-
perimental results demonstrated the superior perfor-
mance of our method compared to existing state-of-the-
art baselines across various tasks.
Acknowledgement
This work is partially supported by the National Sci-
ence Foundation (NSF) under Grant No.
1951729,
1953813, 2119331, 2333790, 2212323, and 2238275, and
the National Institutes of Health (NIH) under Grant
No. R01AG077016.
References
[1] Edward Choi,
Mohammad Taha Bahadori,
Andy
Schuetz, Walter F Stewart, and Jimeng Sun. Doctor
ai: Predicting clinical events via recurrent neural net-
works. In Machine learning for healthcare conference,
pages 301–318. PMLR, 2016.
[2] Edward Choi, Mohammad Taha Bahadori, Jimeng
Sun, Joshua Kulas, Andy Schuetz, and Walter Stew-
art.
Retain:
An interpretable predictive model for
healthcare using reverse time attention mechanism. In
Advances in Neural Information Processing Systems,
pages 3504–3512, 2016.
[3] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio.
Empirical evaluation of gated
recurrent neural networks on sequence modeling. arXiv
preprint arXiv:1412.3555, 2014.
[4] Suhan Cui, Jiaqi Wang, Xinning Gui, Ting Wang, and
Fenglong Ma. Automed: Automated medical risk pre-
dictive modeling on electronic health records. In 2022
IEEE International Conference on Bioinformatics and
Biomedicine (BIBM), pages 948–953. IEEE, 2022.
[5] Thomas Elsken, Jan Hendrik Metzen, and Frank Hut-
ter. Neural architecture search: A survey. The Journal
of Machine Learning Research, 20(1):1997–2017, 2019.
[6] Yujuan Feng, Zhenxing Xu, Lin Gan, Ning Chen,
Bin Yu, Ting Chen, and Fei Wang.
Dcmn: Double
core memory network for patient outcome prediction
with multimodal data.
In 2019 IEEE International
Conference on Data Mining (ICDM), pages 200–209.
IEEE, 2019.
[7] Jiuxiang Gu, Zhenhua Wang, Jason Kuen, Lianyang
Ma, Amir Shahroudy, Bing Shuai, Ting Liu, Xingxing
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
Wang, Gang Wang, Jianfei Cai, et al. Recent advances
in convolutional neural networks. Pattern recognition,
77:354–377, 2018.
[8] Qipeng Guo, Xipeng Qiu, Pengfei Liu, Yunfan Shao,
Xiangyang Xue, and Zheng Zhang. Star-transformer.
In Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics:
Human Language Technologies,
Volume 1 (Long and Short Papers), pages 1315–1325,
Minneapolis, Minnesota, June 2019. Association for
Computational Linguistics.
[9] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-
term memory.
Neural computation, 9(8):1735–1780,
1997.
[10] Kexin
Huang,
Jaan
Altosaar,
and
Rajesh
Ran-
ganath.
Clinicalbert:
Modeling clinical notes and
predicting
hospital
readmission.
arXiv
preprint
arXiv:1904.05342, 2019.
[11] Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-
wei H Lehman, Mengling Feng, Mohammad Ghassemi,
Benjamin Moody, Peter Szolovits, Leo Anthony Celi,
and Roger G Mark.
Mimic-iii, a freely accessible
critical care database. Scientific data, 3(1):1–9, 2016.
[12] Kirthevasan
Kandasamy,
Willie
Neiswanger,
Jeff
Schneider, Barnabas Poczos, and Eric P Xing. Neural
architecture search with bayesian optimisation and op-
timal transport. Advances in neural information pro-
cessing systems, 31, 2018.
[13] Diederik P Kingma and Jimmy Ba.
Adam:
A
method for stochastic optimization.
arXiv preprint
arXiv:1412.6980, 2014.
[14] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon
Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille,
Jonathan Huang, and Kevin Murphy. Progressive neu-
ral architecture search. In Proceedings of the European
conference on computer vision (ECCV), pages 19–34,
2018.
[15] Hanxiao Liu, Karen Simonyan, and Yiming Yang.
Darts: Differentiable architecture search. In Interna-
tional Conference on Learning Representations, 2019.
[16] Fenglong Ma, Radha Chitta, Jing Zhou, Quanzeng
You, Tong Sun, and Jing Gao. Dipole: Diagnosis pre-
diction in healthcare via attention-based bidirectional
recurrent neural networks. In Proceedings of the 23rd
ACM SIGKDD international conference on knowledge
discovery and data mining, pages 1903–1911, 2017.
[17] Fenglong Ma, Jing Gao, Qiuling Suo, Quanzeng You,
Jing Zhou, and Aidong Zhang.
Risk prediction on
electronic health records with prior medical knowledge.
In Proceedings of the 24th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining,
pages 1910–1919, 2018.
[18] Hieu Pham, Melody Guan, Barret Zoph, Quoc Le,
and Jeff Dean.
Efficient neural architecture search
via parameters sharing. In International conference on
machine learning, pages 4095–4104. PMLR, 2018.
[19] Zhi Qiao, Xian Wu, Shen Ge, and Wei Fan.
Mnn:
multimodal attentional neural networks for diagnosis
prediction. Extraction, 1:A1, 2019.
[20] Wasifur Rahman, Md Kamrul Hasan, Sangwu Lee,
Amir Zadeh, Chengfeng Mao, Louis-Philippe Morency,
and Ehsan Hoque. Integrating multimodal information
in large pretrained transformers. In Proceedings of the
conference. Association for Computational Linguistics.
Meeting, volume 2020, page 2359. NIH Public Access,
2020.
[21] Esteban Real, Alok Aggarwal, Yanping Huang, and
Quoc V Le. Regularized evolution for image classifier
architecture search. In Proceedings of the aaai confer-
ence on artificial intelligence, volume 33, pages 4780–
4789, 2019.
[22] Junyuan Shang, Cao Xiao, Tengfei Ma, Hongyan Li,
and Jimeng Sun. Gamenet: Graph augmented memory
networks for recommending medication combination.
In proceedings of the AAAI Conference on Artificial
Intelligence, volume 33, pages 1126–1133, 2019.
[23] Shengpu Tang, Parmida Davarmanesh, Yanmeng Song,
Danai Koutra, Michael W Sjoding, and Jenna Wiens.
Democratizing ehr analyses with fiddle: a flexible data-
driven preprocessing pipeline for structured clinical
data.
Journal of the American Medical Informatics
Association, 27(12):1921–1934, 2020.
[24] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez,  Lukasz Kaiser,
and Illia Polosukhin.
Attention is all you need.
In
Advances in neural information processing systems,
pages 5998–6008, 2017.
[25] Ruochen Wang, Minhao Cheng, Xiangning Chen, Xi-
aocheng Tang, and Cho-Jui Hsieh. Rethinking archi-
tecture selection in differentiable nas. arXiv preprint
arXiv:2108.04392, 2021.
[26] Yanbo Xu, Siddharth Biswal, Shriprasad R Deshpande,
Kevin O Maher, and Jimeng Sun. Raim: Recurrent
attentive and intensive model of multimodal patient
monitoring data.
In Proceedings of the 24th ACM
SIGKDD international conference on Knowledge Dis-
covery & Data Mining, pages 2565–2573, 2018.
[27] Zhen Xu, David R So, and Andrew M Dai. Mufasa:
Multimodal fusion architecture search for electronic
health records. In Proceedings of the AAAI Conference
on Artificial Intelligence, volume 35, pages 10532–
10540, 2021.
[28] Bo Yang and Lijun Wu. How to leverage multimodal
ehr data for better medical predictions? arXiv preprint
arXiv:2110.15763, 2021.
[29] Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine
Marrakchi, Thomas Brox, and Frank Hutter. Under-
standing and robustifying differentiable architecture
search. arXiv preprint arXiv:1909.09656, 2019.
[30] Xinlu Zhang, Shiyang Li, Zhiyu Chen, Xifeng Yan, and
Linda Petzold.
Improving medical predictions by ir-
regular multimodal electronic health records modeling.
arXiv preprint arXiv:2210.12156, 2022.
[31] Barret Zoph and Quoc V Le.
Neural architecture
search with reinforcement learning.
arXiv preprint
arXiv:1611.01578, 2016.
Copyright © 2024 by SIAM
Unauthorized reproduction of this article is prohibited
","nanTo promote the automated EHR data modeling and prediction tasks, researchers have developed diverse approaches:

1. Modeling Multi-modal EHR data: These studies integrate different data sources such as patient monitoring and clinical events, leveraging neural networks to predict outcomes. RAIM, DCMN, and MNN are examples of such approaches.

2. Neural Architecture Search: NAS methods have gained popularity for automating the process of finding deep neural network architectures. Reinforcement learning, evolutionary search, weight sharing, and differentiable architecture search are commonly used techniques in NAS.
"
"Concerns over trust and personal information privacy are significant in online transactions, particularly when sharing health information for purchasing and utilizing health insurance.

Emerging artificial intelligence (AI) technologies are changing the dynamics of trust and privacy in online health insurance transactions.

Research explores the role of trust and privacy concerns as barriers to using health insurance that explicitly utilizes AI.

It compares two scenarios - one with limited, hidden AI and another with visible AI and comprehensive evaluation.","Artificial intelligence (AI), particularly machine learning and deep learning is disrupting insurance and health.

AI creates value by offering insight and turning insight into action. This happens for several services across several channels and across the whole value chain.

The use of AI creates challenges related to implementation, information system integration, and context.

AI technologies such as big data, internet of things, increased computing capabilities, and blockchain enhance AI capabilities and influence consumer attitudes.","Two consumer journeys were used: one with AI explicitly revealed to the consumer, and the other without. Participants completed a survey after the journey covering trust, privacy, perceived usefulness and ease of use.

Structural equation modeling (SEM) with the partial least squares (PLS) method tested the model and hypotheses. The PLS multigroup analysis (MGA) evaluated the effect of the moderator variable (visible human involvement).","Descriptive statistics show small differences between groups. Trust is marginally positive and PIPC marginally negative in the first scenario, conducive to purchase. In the second scenario, trust and PIPC are not conducive to purchase.

The hypotheses H1 and H3-H7 are supported by PLS-MGA. There was a significant difference between T-UI (Hypothesis H1) and PU-UI (Hypothesis H6). There was also a significant difference expected for PIPC-UI but none was found. Hypotheses H2 and H6 are not supported by the analysis.","Trust is significantly lower in the scenario with explicit AI. The difference in PIPC is not statistically significant.

Findings can be used to mitigate lower trust and higher PIPC in explicit AI scenarios.

Trust can be enhanced by acknowledging and understanding the challenge, providing assurances about AI, and promoting a positive narrative on AI trustworthiness.

PIPC can be mitigated through assurances about AI's use of personal data, making relevant regulations clear, and offering privacy seals.

Future research can explore the model across different cultures, delve further into PIPC, and examine limitations and value of SEM PLS-MGA.",Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI,"Alex Zarifis, Peter Kawalek, Aida Azadegan","Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=wico20
Journal of Internet Commerce
ISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/wico20
Evaluating If Trust and Personal Information
Privacy Concerns Are Barriers to Using Health
Insurance That Explicitly Utilizes AI
Alex Zarifis , Peter Kawalek & Aida Azadegan
To cite this article: Alex Zarifis , Peter Kawalek & Aida Azadegan (2021) Evaluating If Trust and
Personal Information Privacy Concerns Are Barriers to Using Health Insurance That Explicitly
Utilizes AI, Journal of Internet Commerce, 20:1, 66-83, DOI: 10.1080/15332861.2020.1832817
To link to this article:  https://doi.org/10.1080/15332861.2020.1832817
© 2020 The Author(s). Published with
license by Taylor & Francis Group, LLC.
Published online: 19 Oct 2020.
Submit your article to this journal 
Article views: 444
View related articles 
View Crossmark data
Evaluating If Trust and Personal Information Privacy
Concerns Are Barriers to Using Health Insurance That
Explicitly Utilizes AI
Alex Zarifisa
, Peter Kawaleka
, and Aida Azadeganb
aSchool of Business and Economics, Loughborough University, Loughborough, UK; bIntelligent
Systems Research Laboratory, University of Reading, Reading, UK
ABSTRACT
Trust and privacy have emerged as significant concerns in
online transactions. Sharing information on health is especially
sensitive but it is necessary for purchasing and utilizing health
insurance. Evidence shows that consumers are increasingly
comfortable with technology in place of humans, but the
expanding use of AI potentially changes this. This research
explores whether trust and privacy concern are barriers to the
adoption of AI in health insurance. Two scenarios are com-
pared: The first scenario has limited AI that is not in the inter-
face and its presence is not explicitly revealed to the
consumer. In the second scenario there is an AI interface and
AI evaluation, and this is explicitly revealed to the consumer.
The two scenarios were modeled and compared using SEM
PLS-MGA. The findings show that trust is significantly lower in
the second scenario where AI is visible. Privacy concerns are
higher with AI but the difference is not statistically significant
within the model.
KEYWORDS
Artificial Intelligence; health;
information privacy;
insurance; trust
Introduction
Artificial intelligence (AI), particularly machine learning and deep learning
is disrupting insurance and health. In insurance natural language process-
ing is utilized extensively by virtual agents interacting with the consumer
and AI is also used to detect fraudulent claims (Wang and Xu 2018). In
health it is used to make a diagnosis and treatment (He et al. 2019). The
use of AI creates value by offering insight and turning insight into action.
This happens for several services across several channels and across the
whole value chain. Humans still have an important role, but they need sup-
port to be able to utilize vast amounts of data and respond quickly. AI is
broad
and
immature
in
relation
to
its
potential,
so
this
is
a
CONTACT Alex Zarifis
a.zarfis@lboro.ac.uk
School of Business and Economics, Loughborough University,
Loughborough, UK.
 2020 The Author(s). Published with license by Taylor & Francis Group, LLC.
This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives
License (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial re-use, distribution, and reproduction
in any medium, provided the original work is properly cited, and is not altered, transformed, or built upon in any way.
JOURNAL OF INTERNET COMMERCE
2021, VOL. 20, NO. 1, 66–83
https://doi.org/10.1080/15332861.2020.1832817
challenging area. This is an interdisciplinary topic that goes beyond the
narrow focus of developing the necessary technology and testing the usabil-
ity. Its interdisciplinary nature is comparable to the emergence of other
technologies, such as blockchain. There are many questions that need
answers, but these questions are heavily influenced by the present capability
and the extant diffusion of the technology. The benefits of AI for the con-
sumer in health insurance include customized offers and real-time adapta-
tion of fees. Currently the interface between the consumer purchasing
health insurance and AI raises some barriers such as trust and Personal
Information Privacy Concern (PIPC) (Gulati, Sousa, and Lamas 2019). The
consumer is not a passive recipient of the increasing role of AI. Many con-
sumers have beliefs on what this technology should do. Furthermore, regu-
lation is moving toward making it necessary for the use of AI to be
explicitly
revealed
to
the
consumer
(European
Commission
2019).
Therefore, the consumer is an important stakeholder and their perspective
should be understood and incorporated into future AI solutions in health
insurance. This research identified two scenarios, one with limited AI that
is not in the interface, whose presence is not explicitly revealed to the con-
sumer and a second scenario where there is an AI interface and AI evalu-
ation, and this is explicitly revealed to the consumer.
The insights AI offers can be summarized into optimization, search and
recommendation, and diagnosis and prediction. In addition to the improv-
ing technology of AI, the capabilities are also increasing because of the
technologies it interacts with. These technologies include big data, internet
of things, increased computing capabilities and blockchain (Riikkinen et al.
2018). In general, there is far more data and more capabilities to analyze it.
This raises the question whether the impact of AI can be evaluated and
guided in isolation or if all these technologies should be evaluated as a new
context. Blockchain technology can support the internet of things in terms
of security and integrity of the data, the internet of things creates far more
data, big data and AI need to analyze it and they need more computing
capabilities.
The challenges to AI depend on the specific implementation, the infor-
mation system it is part of and the specific context. One challenge is imple-
mentations of AI that have negative impacts, for example on individuals’
health (He et al. 2019). The risks caused by AI seem to come from either
using its capabilities to do something harmful more effectively or by AI
making incorrect evaluations. In a fully automated system, mistakes will be
implemented directly. If AI is working with humans, the humans may act
based on the incorrect evaluation. As AI can be unpredictable this raises
some questions in terms of control and how to manage the risks. Society,
governments and other institutions like the European Union are attempting
JOURNAL OF INTERNET COMMERCE
67
to regulate and offer guidelines on how to move forward with AI in an eth-
ical way reducing the risks to the u consumer (European Commission
2019). This research focuses on the barriers from the consumer’s perspec-
tive when they are purchasing health insurance online.
AI offers some unique capabilities but most of the impact is as a part of
a wave of innovation that will optimize and create new products, services,
business models and business ecosystems. AI can be seen as the catalyst
because it can harness the breadth of hardware and software in a way that
was not possible before: It can mask the complexity and provide the value
to the health insurance consumer. This increased role of AI, and the eco-
system of technologies it utilizes, influence the consumer’s attitude. The
consumer will interpret some capabilities AI offers as enablers and some as
risks and concerns. For example, limited trust and PIPC may be barriers.
The change from related technologies and other trends in society like
greener living mean people want to see different principles and values from
their insurers. Therefore, the new ethical, privacy and trust challenges AI
brings can be approached as part of a holistic reevaluation of the relation-
ship between a consumer and their health insurer. New business models
may require a new ethical perspective. Ethics and regulation are evolving as
the uses and business models of AI evolve. The new way of interacting
with the consumer, the new interfaces or even business models must con-
sider the enablers and barriers to AI in health insurance from the consum-
er’s perspective.
The next section will review health insurance, trust and PIPC to provide
the theoretic foundation. This will be followed by the methodology that
explains how the model is tested in the two scenarios, with and without
visible AI. Finally, the analysis and the conclusion are presented.
Theoretical background
AI in health insurance raises many new issues grounded in the existing,
and widely validated, constructs of ease of use, usefulness, trust and
Personal Information Privacy Concern (PIPC).
Perceived ease of use and usefulness in health insurance with AI
Information systems have been divided into hedonic and utilitarian
(van der Heijden 2004). Purchasing health insurance is mostly utilitarian as
it is something useful but not necessarily an enjoyable process and the
motivation to do it is not enjoyment. Adoption and attitude toward the use
of a technology is influenced by some factors that are similar across
different contexts and some that are different depending on the context.
68
A. ZARIFIS ET AL.
Perceived ease of use and perceived usefulness (Davis 1989; Venkatesh,
Thong, and Xu 2016) have been found to influence adoption and use
across several contexts such as adopting insurance (Lee, Tsao, and Chang
2015). In systems that are more focused on hedonism, a construct for
enjoyment could be included along with ease of use and usefulness, but
here it is not included. While these measures have been validated in the
insurance sector the items used to operationalize them need to be adapted
to capture the increased role of AI in health insurance. AI in health insur-
ance can influence perceived ease of use with a personal assistant in several
ways. Personal assistants are used in the interaction with the consumer and
utilize machine learning for natural language processing and analyzing the
consumer request. Firstly, the system using AI and a personal assistant can
keep a constant state across many consumer queries. This means the sys-
tem will keep all the relevant information together and utilize it for each
query, so the consumer needs to make less effort. A second example is that
AI can interpret unstructured data like pictures and emails from the con-
sumer, so that information does not need to be reentered manually. AI in
health insurance can influence perceived usefulness positively by processing
applications fast and making customized offers. Some insurers offer cus-
tomized quotes in minutes (Baloise 2019).
Trust in health insurance with AI
Trust is important where there is an exchange of value that involves some
risk. The higher the risk the more important trust becomes. Making a pur-
chase online is perceived to have higher risk compared to face to face and
therefore the role of trust is more significant (McKnight and Chervany
2001). There is an additional risk in purchasing health insurance online
because the consumer is taking a risk that the insurer will fulfill their duty
and cover the consumer if they make a claim. Insurance companies and
the information systems they use have developed sufficiently to build trust
in the typical current scenario with limited AI that is not visible to the con-
sumer. The increasing role of AI across the health insurance supply-chain
brings new sources of distrust that come from the lack of human attributes
in more stages of the supply chain, both front-end and back-end and the
real or perceived unpredictability of AI. The consumer’s trust in a virtual
agent they are interacting with can be reduced by the lack of human factors
like visual and auditory emotions (Torre, Goslin, and White 2020). As
Figure 1 illustrates the interaction of the consumer can be divided into
three scenarios: Firstly, a traditional face to face interaction without utiliz-
ing technology. Secondly, a digital interaction online that still utilizes
human logic primarily and uses AI in a limited way that is not visible to
JOURNAL OF INTERNET COMMERCE
69
the consumer. Lastly, the third scenario involves the consumer interacting
purely with an AI interface and with the underlying logic and decision
making also based on AI.
The consumer’s trust online is influenced by the psychology of the con-
sumer and sociological influences. The psychology of the individual con-
sumer may give them a propensity to trust (Kim and Prabhakar 2004)
which is similar to a disposition to trust (Zarifis et al. 2014) and a trusting
stance (McKnight et al. 2011). The social dimension of trust includes insti-
tution based trust that covers structural assurance and situational normality
(McKnight and Chervany 2001). Structural assurance refers to guarantees,
seals of approval and protection from the bank or card used to make the
transaction (Sha 2009). Situational normality can include reviews and con-
forming to social norms.
The risk the consumer perceives from AI having a significant and
decisive role in every aspect of their health insurance can lower trust.
There is limited familiarity with this level of AI, the ethics of AI are
unclear, AI can be unpredictable, the transparency can be limited and the
control the humans in the insurance company have over AI is unclear.
Personal information privacy concerns (PIPC) from threats by AI in
health insurance
When a consumer enters personal information such as their date of birth,
their bank account details and medical information on their health to
acquire health insurance online there is a concern in how this information
is used, shared and stored securely. For a consumer to purchase health
insurance they need to provide an extensive amount of information;
Figure 1. Trust face to face, online, online with AI.
70
A. ZARIFIS ET AL.
enough for a criminal to commit fraud. Even if misuse or a security breach
is revealed to the consumer, they cannot change their health information
like they can change their bank account details to protect their privacy.
Therefore, sharing this health information causes privacy concerns (Bansal,
Zahedi, and Gefen 2010). These privacy concerns can be a key predictor of
using health services online (Park and Shin 2020). Privacy concerns can be
divided into perceived privacy control and perceived privacy risks (Dinev
et al. 2013). Perceived privacy control can include confidentiality, secrecy
and anonymity. Perceived privacy risks can include the sensitivity of the
information and the level of regulation (Dinev et al. 2013).
Using AI in healthcare insurance can reduce the perceived information
control and increase the perceived risk. The lack of understanding of the
role of AI in this context, the unpredictability of AI, the low transparency
on the algorithms, the lack of humanness and the unclear ethics may
increase the concerns over personal information privacy. Furthermore, AI
is part of an ecosystem of technologies such as big data that enhance each
other’s capabilities and pervasiveness. These increased capabilities and per-
vasiveness can elevate privacy concerns. When a consumer enters their per-
sonal information during the process of acquiring health insurance, they
may be thinking about how this personal information could be used against
them in the future. Currently, insurance companies offer privacy assurances
and privacy seals that can reduce privacy concern (Hui, Teo, and Sang-
Yong 2007) however these do not explicitly cover the role of AI.
Research model and hypotheses
The online consumer evaluates the advantages and disadvantages of pur-
chasing a product or service online before moving forward. Some weak-
nesses, or even threats, can be overlooked if the advantages are enough. An
example of this is the privacy paradox (Norberg, Horne, and Horne 2007)
where consumers still give their personal information despite their con-
cerns. Therefore, it is necessary to identify all the relevant factors and
model their relationship. The literature review identified two enablers and
two barriers to the use of AI in insurance from the consumer’s perspective.
The previous section on trust also identified how trust is influenced by the
humanness of the interface with the insurer, and the humanness of the
logic that leads to the evaluation of the insurance offered. As the consumer
will be explicitly informed about their interaction with AI (European
Commission 2019) this may influence their attitude and raise the barriers
of insufficient trust and information privacy concerns. To better under-
stand the scenario where the consumer purchases health insurance with an
AI interface and AI logic and decision-making, this new scenario needs to
JOURNAL OF INTERNET COMMERCE
71
be contrasted with the typical existing scenario. In the existing scenario
there is limited AI, that is not in the interface, and its presence is not expli-
citly revealed to the consumer. Therefore, as illustrated in Figure 2, two
scenarios are contrasted, ß1, with limited AI, not explicitly revealed to the
consumer and ß2 with an AI interface and AI evaluation explicitly revealed
to the consumer.
For these scenarios to be tested they are modeled as illustrated in Figure 3.
The seven hypotheses proposed cover the relationships between the five con-
structs. The first two constructs are the enablers, firstly the additional ease of
use offered by AI and secondly the additional usefulness offered by AI. The
second two constructs are the two barriers of trust and privacy concern. The
final construct is the decision to purchase health insurance online.
The literature suggests that additional layers of technology, additional
capabilities of technology and a reduction in the role of humans in a pro-
cess can be perceived as an increase in the risk and therefore a reduction
in trust and an increase in information privacy concern (McKnight et al.
2011). Therefore, the first and second hypotheses are the following:
H1: The consumer will have lower trust if the use of AI is visible to them during the
process of purchasing health insurance online.
H2: The consumer will have higher Perceived Information Privacy Concern if the
use of AI is visible to them during the process of purchasing health insurance online.
The literature suggests that perceived ease of use has a positive influence
on perceived usefulness, trust, privacy concern and the purchase of health
Figure 2. Research approach.
72
A. ZARIFIS ET AL.
insurance in both scenarios (Gefen, Karahanna, and Straub 2003; Al-Khalaf
and Choe 2020). Similarly, perceived usefulness has a positive influence on
the purchase in both scenarios. Therefore, the final five hypotheses are
the following:
H3: Perceived ease of use will have the same influence on trust in AI if AI is visible
during the purchase of health insurance online.
H4: Perceived ease of use will have the same influence on Personal Information
Privacy
Concern
from
AI
if
AI
is
visible
during
the
purchase
of
health
insurance online.
H5: Perceived ease of use will have the same influence on perceived usefulness of AI
if AI is visible during the purchase of health insurance online.
H6: Perceived usefulness will have the same influence on the purchase of health
insurance online if AI is visible.
H7: Perceived ease of use will have the same influence on the purchase of health
insurance online if AI is visible.
Research methodology
Measures
While the five constructs of the model have been widely utilized and vali-
dated, the items applied to measure them need to be adapted to the context
Figure 3. Research model and hypotheses.
JOURNAL OF INTERNET COMMERCE
73
of purchasing health insurance online with AI. Table 1 illustrates the five
constructs and the sources of the items that were adapted. Each question
has a seven-point Likert for the participant to give their feedback from
strongly disagree (1) to strongly agree (7).
Data collection
This research evaluates whether a consumer purchasing health insurance
without visible AI will have higher trust and lower PIPC compared to
when there is visible AI in the interaction. As this is evaluated from the
consumer’s perspective, two consumer journeys are used with two separate
groups of participants. The two journeys used are based on the process a
consumer goes through in five insurers that were evaluated. The first
group, ß1, are given a consumer journey for purchasing insurance in a pro-
cess where AI is not visible and there is human participation from the
insurance company. The second group ß2 are given a consumer journey for
purchasing health insurance in a process where AI is used at every step
and this role of AI is made clear to the consumer. The participants then
completed a survey that covers the seven hypotheses. The survey was disse-
minated using the SoSci Survey platform that meets GDPR requirements
and stores the data within the EU. The minimum sample size for a statis-
tical power of 80% and a significance level of 1% for the model of five
latent variables with three indicators each was calculated to be 176 (Hair
et al. 2014). For the first group 248 participants completed the first survey
and for the second group 237 completed the second survey. After incom-
plete and unreliable surveys were taken out 221 were left for the first sur-
vey and 217 for the second. The participants were UK residents. The
demographic information for both groups is presented in Table 2.
Data analysis technique
The model was tested with Structural Equation Modeling (SEM) with the
Partial Least Squares method (PLS). The relationships between the five
Table 1. Constructs and their indicators.
Role
Construct
Item
Source of construct items
Enablers
Perceived Ease of Use
PEOU1B1/ PEOU1B2
(Davis 1989)
Perceived Usefulness
PU1B1/ PU1B2
(Davis 1989)
Barriers
Trust in AI
T1B1/T1B2
(McKnight, Choudhury,
and Kacmar 2002;
McKnight et al. 2011)
Personal Information
Privacy Concerns
from AI
PIPC1B1/PIPC1B2
(Dinev et al. 2013; Xu
et al. 2008)
Outcome
Usage of insurance
utilizing AI
UI1B1/UI1B2
(Zhao, Ni, and Zhou 2018;
Wu, Li, and Fu 2011;
Hoque and
Sorwar 2017)
74
A. ZARIFIS ET AL.
variables was tested for each of the two groups separately and then the two
groups were compared between themselves across the seven hypotheses.
The two groups were compared by applying PLS multigroup analysis
(MGA) and bootstrapping with Smart PLS. First the measurement model is
evaluated, followed by the structural model.
Data analysis and results
The purpose of the multigroup analysis was to evaluate the effect of the
moderator variable, in this case having visible human involvement, between
the two groups. The Smart PLS-MGA will show whether the difference is
statistically significant. The null hypothesis H0 is that there is no difference
between the two groups and the alternative hypothesis H1 is that there is a
difference. As PLS-MGA is a new and evolving analysis method, simpler
descriptive statistics were also implemented.
Descriptive statistics
The differences between the mean values of the two groups are not large as
illustrated in Table 3. However, two points about the difference between
the scenarios must be highlighted: Firstly, they are consistent across the six
items forming the two constructs of trust and PIPC. Secondly, in the first
scenario, trust is marginally above 4, so marginally positive, and PIPC is
marginally below 4. This positive trust and negative PIPC is conducive to a
purchase. In the second scenario, despite the small difference this is
reversed and therefore trust and PIPC are not conducive toward a
Table 2. Demographic information for both groups.
AI not visible (ß1)
AI visible (ß2)
Gender
Female
98
106
Male
123
111
Age
Under 18
11
14
18–24
96
92
25–39
80
74
40–59
26
18
60 or older
8
19
Education level
Without educational level
8
12
High school
77
81
Undergraduate university degree
80
94
Post-graduate university degree
56
30
Income (in British Pounds)
No regular income
13
15
400–1200
26
16
1201–3000
71
85
3001–5000
84
81
> 5000
27
20
Total
221
217
JOURNAL OF INTERNET COMMERCE
75
purchase. This illustrates how small changes in perceptions on trust and
PIPC can nevertheless be decisive.
Measurement model
The reflective measurement model was evaluated in several ways. Table 4
shows the results of the measurement model analysis. The factor loadings
are over 0.7 so the indicators appear to be sufficiently reliable. The
Composite Reliability (CR) is above 0.7 so the construct reliability between
the items and the latent variable is sufficient (Hair et al. 2014). The conver-
gent validity is evaluated by the Average Variance Extracted (AVE) AVE is
above the required minimum of 0.5. The discriminant validity is below the
0.85 threshold (Hair et al. 2014).
The tests for measurement invariance are illustrated in Table 5. There is
some invariance for two of the fifteen indicators, PEOU-3 and UI-1. Each
variable has three reflective items which reduce the influence of each item
with some invariance. The influence of a small degree of measurement
invariance of an item in PLS-MGA is a topic of debate (Sarstedt, Henseler,
and Ringle 2011) with some considered acceptable in multigroup analysis,
as different groups may have some difference in their understanding of the
measurement model (Rigdon, Ringle, and Sarstedt 2010).
Structural model
The coefficient of determination R2 for endogenous latent variables is
‘weak’ for P (0.004, 0.018) and T (0.004, 0.026) ‘moderate’ for PU (0.339,
0.419) and UI (0.562, 0.633) (Chin 1998). This was the same across both
groups. The path coefficients are presented in Table 6. The final column
evaluates the difference between the two models and whether the hypothe-
ses are supported. Values below 0.05 or above 0.95 are significant in the
PLS-MGA analysis. The paths T-UI (H1) and PU-UI (H6) have a signifi-
cant difference. There was a difference expected for H1 which is supported.
The difference for H6 was not expected. There was also a difference
expected for PIPC-UI but none was found. The remaining hypotheses had
no differences as expected. Therefore, the hypotheses H1, H3, H4, H5, H7
are supported by PLS-MGA and the hypotheses H2, H6 are not supported.
Table 3. Mean values for both groups.
Perceived Ease
of Use
Perceived
Usefulness
Trust
Perceived Info.
Privacy Concern
Use of
Health Insurance
AI not visible (ß1)
3.891
3.910
4.017
3.879
3.561
AI visible (ß2)
3.739
4.000
3.704
4.158
3.670
76
A. ZARIFIS ET AL.
Table 4. Results of the measurement model analysis.
Items
AI not visible/AI visible
Loadings
CR
AVE
Discriminant validity heterogeneity
PU
PEOU
U
T
PIPC
Perceived
Usefulness
PU-1
0.836/0.818
0.899/0.882
0.748/0.714
PU-2
0.877/0.827
PU-3
0.881/0.889
Perceived Ease
of Use
PEOU-1 0.782/0.735
0.862/0.838
0.676/0.633
0.720/0.833
PEOU-2 0.803/0.857
PEOU-3 0.879/0.792
Use of
Health
Insurance
UI-1
0.861/0.773
0.874/0.869
0.698/0.690
0.416/0.759
0.215/0.189
UI-2
0.804/0.851
UI-3
0.840/0.865
Trust
T-1
0.842/0.891
0.896/0.898
0.741/0.747
0.243/0.402
0.084/0.189
0.842/0.819
T-2
0.840/0.827
T-3
0.899/0.873
Perceived Info.
Privacy Concern
PIPC-1
0.879/0.896
0.914/0.923
0.779/0.798
0.004/0.184
0.064/0.189
0.592/0.587
0.576/0.573
PIPC-2
0.881/0.916
PIPC-3
0.888/0.868
JOURNAL OF INTERNET COMMERCE
77
Discussion
Theoretical contributions
AI is having an increasing influence and the health insurance sector is both
intrinsically important and likely to be an important benchmark for the
satisfactory exchange of sensitive information with AI. This research
brought together the literature of AI, insurance, health, e-commerce, trust
and Personal Information Privacy Concerns (PIPC). It is important to
understand the consumer’s perspective as they have beliefs on what the
role AI should be. Furthermore, the insurer must explicitly inform them if
they are using AI when communicating with them in the interface
(European-Commission 2019). This research identified two scenarios, one
with limited AI that is not in the interface, whose presence is not explicitly
revealed to the consumer and a second scenario where there is an AI inter-
face and AI evaluation, and this is explicitly revealed to the consumer.
The two scenarios were modeled and compared using SEM PLS-MGA.
Both models were similar in terms of which paths were strong and which
Table 5. Test for measurement invariance.
Items
Outer Loadings-diff (AI not visible-AI visible)p-Value
Perceived Usefulness
PU-1
0.019
.294
PU-2
0.050
.064
PU-3
0.008
.639
Perceived Ease of Use
PEOU-1
0.047
.225
PEOU-2
0.053
.886
PEOU-3
0.087
.010
Use of Health Insurance
UI-1
0.087
.008
UI-2
0.045
.850
UI-3
0.026
.829
Trust
T-1
0.048
.969
T-2
0.013
.358
T-3
0.025
.128
Perceived Info. Privacy Concern
PIPC-1
0.016
.789
PIPC-2
0.035
.909
PIPC-3
0.019
.227
Table 6. Multi-group comparison test results.
Path
Coefficients
Hypotheses
PLS-MGA: p-value (ß1vs ß2)
AI not visible
AI visible
T-UI
0.536
0.414
H1: ß1 > ß2
.048
PIPC-UI
0.221
0.205
H2: ß1 < ß2
.576
PEOU-T
0.066
0.163
H3: ß1 ¼ ß2
.827
PEOU-PIPC
0.060
0.135
H4: ß1 ¼ ß2
.762
PEOU-PU
0.582
0.647
H5: ß1 ¼ ß2
.858
PU-UI
0.237
0.443
H6: ß1 ¼ ß2
.994
PEOU-UI
0.010
0.019
H7: ß1 ¼ ß2
.372
78
A. ZARIFIS ET AL.
were weak. The pathways from PEOU to PU, PU to UI, T to UI and PIPC
to UI were strong while the paths from PEOU to UI, T and PIPC were
weak. This indicates that the model captures most relationships well apart
from PEOU which only has a strong influence on PU.
The analysis gives further support to the hypotheses H1, H3, H4, H5,
H7. However, hypotheses H2, H6 are not supported. Therefore, both
descriptive and PLS-MGA, support the different level of trust with and
without visible AI involvement. Furthermore, it is also supported that trust
is higher without visible AI involvement. This extends literature on how
trust is lower in certain contexts (Thatcher et al. 2011) to the context of
health insurance with AI. Our findings also extend the literature on how
different forms of AI interaction influence trust (Torre, Goslin, and White
2020). Most of the current literature is focused on the use of language by
clearly visible AI so it is beneficial that this research also evaluated the less
visible AI. While the mean of PIPC was lower without visible AI involve-
ment, PLS-MGA did not identify this as statistically significant within the
model. Therefore, there is some support that privacy concerns that were
validated to be stronger in other contexts (Dinev et al. 2015) are also stron-
ger in this context with AI (Park and Shin 2020). More specifically, there is
some support that privacy concerns influence the sharing of personal infor-
mation on health (Park and Shin 2020; Chen, Zarifis, and Kroenung 2017).
Implications for practice
The implications for practice are related to how the reduced trust and
increased privacy concern with visible AI are mitigated.
Avoid being explicit about the use of AI
In some parts of the world the use of AI must be stated and visible so
there is no choice for health insurers. If there is no legal requirement to be
explicit about the use of AI, then the insurer may decide not to be explicit
about its use. This strategy has the limitation that several uses of AI such
as chatbots and natural language processing are hard to conceal.
Mitigate the lower trust with explicit AI
The first step to mitigating the lower trust caused by the explicit use of AI
is to acknowledge this challenge and the second step is to understand it.
The quantitative analysis supports the existence of this challenge and the
literature review indicates what causes it. The causes are the reduced trans-
parency and explainability. A statement at the start of the consumer jour-
ney about the role AI will play and how it works may reinforce
JOURNAL OF INTERNET COMMERCE
79
transparency and help to explain it, which will then reinforce trust.
Secondly, the level of the importance of trust is increased as the perceived
risk is increased. Therefore, the risks should be reduced. Thirdly, it should
be illustrated that the increased use of AI does not reduce the inherent
humanness. For example, it can be shown how humans train AI and how
AI adopts human values. Alternatively, as it has been proven that trust
building can focus on human (benevolence, integrity and ability) or system
characteristics
(helpfulness
reliability
and
functionality)
(Lankton,
McKnight,
and
Tripp
2015),
trust
building
can
focus
on
system
characteristics.
Lastly, beyond the specific consumer and their journey, society can be
influenced to build trust toward AI. In addition to the psychological
responses to the specific consumer journey, there are also the social influ-
ences. Therefore, society in general can be offered a positive narrative on
the trustworthiness of AI and share positive experiences in social learning.
Mitigate the higher personal information privacy concern (PIPC) with explicit AI
The consumer is concerned about how AI will utilize their financial, health
and other personal information. Health insurance providers offer privacy
assurances and privacy seals, but these do not explicitly refer to the role of
AI. Assurances can be provided about how AI will use, share and securely
store the information. These assurances can include some explanation of
the role of AI and cover confidentiality, secrecy and anonymity. For
example, while the consumer’s information may be used to train machine
learning it can be made clear that it will be anonymized first. The consum-
er’s perceived privacy risks can be mitigated by making the regulation that
protects them clear.
Limitations and future research direction
Many theories and models of trust have been found to be valid across dif-
ferent cultures, however, it has also been proven that there can be some
variation across cultures (Connolly 2013). Therefore, the model developed
here could be further explored in different cultures.
While it was shown that trust is different with and without visible AI the
role of PIPC should be explored further. The differences identified offer
new avenues for further exploration. Furthermore, the value and limitations
of SEM PLS-MGA were visible in this type of methodology.
Conclusion
This research identified two consumer journeys for purchasing health
insurance: The first has limited AI that is not visible in the interface and
80
A. ZARIFIS ET AL.
its presence is not explicitly revealed to the consumer. The second has AI
in the interface and the evaluation, and its presence is explicitly revealed to
the consumer.
The two scenarios were modeled and compared using SEM PLS-MGA.
For both models Perceived Usefulness, Trust and Personal Information
Privacy Concern (PIPC) influenced the use of health insurance. Both
descriptive analysis and PLS-MGA, support the lower level of trust with
visible AI involvement in comparison to when AI is not visible. The mean
of PIPC was higher with visible AI but this was not statistically significant
within the model. These contributions clarify the relationship between the
consumer, AI and the health insurance provider and set an agenda for
future research on this topic. This agenda might be extended beyond health
insurance to other transactions and applications, particularly those that
require sensitive information.
ORCID
Alex Zarifis
http://orcid.org/0000-0003-3103-4601
Peter Kawalek
http://orcid.org/0000-0002-6248-7745
Aida Azadegan
http://orcid.org/0000-0002-6069-8610
References
Al-Khalaf, E., and P. Choe. 2020. Increasing customer trust towards mobile commerce in a
multicultural society: a case of Qatar in a multicultural society: a case of Qatar. Journal
of Internet Commerce 19 (1):32–61. doi:10.1080/15332861.2019.1695179.
Baloise. 2019. “Friday (Baloise Insurance).” 2019. https://www.friday.de/lp/corporate-en.
Bansal, G., F. M. Zahedi, and D. Gefen. 2010. The impact of personal dispositions on infor-
mation sensitivity, privacy concern and trust in disclosing health information online.
Decision Support Systems 49 (2):138–150. doi:10.1016/j.dss.2010.01.010.
Chen, L., A. Zarifis, and J. Kroenung. 2017. The role of trust in personal information dis-
closure on health-related websites. European Conference on Information Systems
Proceedings 2017, 771–786. Guimaraes.
Chin, W. W. 1998. The partial least squares approach to structural equation modelling. In
In modern methods for business research, ed. G. A. Marcoulides, 295–336. Mahwah, NJ:
Lawrence Erlbaum Associates.
Connolly, R. 2013. Ecommerce trust beliefs: examining the role of national culture. In
Information systems research and exploring social artifacts, eds. P. Isaias and M. B.
Nunes, 20–42. Hershey: IGI Global. doi:10.4018/978-1-4666-2491-7.ch002.
Davis, F. 1989. Perceived usefulness, perceived ease of use, and user acceptance of informa-
tion technology. MIS Quarterly 13 (3):319–340. doi:10.2307/249008.
Dinev, T., H. Xu, J. H. Smith, and P. Hart. 2013. Information privacy and correlates: an
empirical attempt to bridge and distinguish privacy-related concepts. European Journal
of Information Systems 22 (3):295–316. doi:10.1057/ejis.2012.23.
Dinev, T., V. Albano, H. Xu, A. D’Atri, and P. Hart. 2015. Individuals’ attitudes towards
electronic health records: a privacy calculus perspective. In Advances in healthcare
JOURNAL OF INTERNET COMMERCE
81
informatics and analysis, edited by Ashish Gupta, Vimla Patel, and Robert Greenes,
19–50. New York: Springer.
European-Commission. 2019. “Ethics Guidelines for Trustworthy AI.” https://ec.europa.eu/
digital
Gefen, D., E. Karahanna, and W. S. Straub. 2003. Trust and TAM in online shopping: an
integrated model. MIS Quarterly 27 (1):51–90. doi:10.2307/30036519.
Gulati, S., S. Sousa, and D. Lamas. 2019. Design, development and evaluation of a human-
computer trust scale. Behaviour & Information Technology 38 (10):1004–1015. doi:10.
1080/0144929X.2019.1656779.
Hair, J., T. Hult, C. Ringle, and M. Sarstedt. 2014. A Primer on Partial Least Squares
Structural Equation Modeling (PLS-SEM). SAGE Publications. Vol. 46. Thousand Oaks.
10.1016/j.lrp.2013.01.002.
He, J., S. L. Baxter, J. Xu, J. Xu, X. Zhou, and K. Zhang. 2019. The practical implementa-
tion of artificial intelligence technologies in medicine. Nature Medicine 25 (1):30–6. doi:
10.1038/s41591-018-0307-0.
Heijden, H. v d. 2004. User acceptance of hedonic information systems. MIS Quarterly 28
(4):695–704.
Hoque,
R.,
and
G.
Sorwar.
2017.
Understanding
factors
influencing
the
adoption of MHealth by the elderly: An extension of the UTAUT model. International
Journal of Medical Informatics 101 (September 2015):75–84. doi:10.1016/j.ijmedinf.2017.
02.002.
Hui, K. L., H. H. Teo, and T. L. Sang-Yong. 2007. The value of privacy assurance: an
exploratory
field
experiment.
MIS
Quarterly
31
(1):19–33.
10.1177/09697330
07082112.
Kim, K. K., and B. Prabhakar. 2004. Initial trust and the adoption of B2C E-commerce.
ACM SIGMIS Database: The DATABASE for Advances in Information Systems 35 (2):
50–64. doi:10.1145/1007965.1007970.
Lankton, N., H. McKnight, and J. Tripp. 2015. Technology, humanness, and trust: rethink-
ing trust in technology. Journal of the Association for Information Systems 16 (10):
880–918. doi:10.17705/1jais.00411.
Lee, C.-Y., C.-H. Tsao, and W.-C. Chang. 2015. The relationship between attitude toward
using and customer satisfaction with mobile application services: an empirical study
from the life insurance industry. Journal of Enterprise Information Management 44 (3):
347–367. 10.1108/MRR-09-2015-0216.
McKnight, H., and N. L. Chervany. 2001. What trust means in E-commerce customer rela-
tionships: an interdisciplinary conceptual typology. International Journal of Electronic
Commerce 6 (2):35–59. doi:10.1080/10864415.2001.11044235.
McKnight, H., M. Carter, J. B. Thatcher, and P. Clay. 2011. Trust in a specific technology:
an investigation of its components and measures. ACM Transactions on Management
Information Systems 2 (2):1–25. doi:10.1145/1985347.1985353.
McKnight, H., V. Choudhury, and C. Kacmar. 2002. Developing and validating trust meas-
ures for E-commerce: an integrative typology. Information Systems Research 13 (3):
334–359. doi:10.1287/isre.13.3.334.81.
Norberg, P., D. Horne, and D. Horne. 2007. The privacy paradox: personal information
disclosure intentions versus behaviors. Journal of Consumer Affairs 41 (1):100–126. doi:
10.1111/j.1745-6606.2006.00070.x.
Park, Y. J., and D. Shin. 2020. Contextualizing privacy on health-related use of information
technology. Computers in Human Behavior 105:106204–106209. doi:10.1016/j.chb.2019.
106204.
82
A. ZARIFIS ET AL.
Rigdon, E. E., C. M. Ringle, and M. Sarstedt. 2010. Structural modeling of heterogeneous
data with partial least squares. In Review of marketing research, ed. N. K. Malhotra, 7th
ed., 255–296. Armonk: Sharpe.
Riikkinen, M., H. Saarij€arvi, P. Sarlin, and I. L€ahteenm€aki. 2018. Using artificial intelligence
to create value in insurance. International Journal of Bank Marketing 36 (6):1145–1168.
doi:10.1108/IJBM-01-2017-0015.
Sarstedt, M., J. Henseler, and C. M. Ringle. 2011. Multigroup analysis in partial least
squares (PLS) path modeling: alternative methods and empirical results. Advances in
International Marketing 22 (2011):195–218. doi:10.1108/S1474-7979(2011)0000022012.
Sha, W. 2009. Types of structural assurance and their relationships with trusting intentions
in business-to-consumer e-commerce. Electronic Markets 19 (1):43–54. doi:10.1007/
s12525-008-0001-z.
Thatcher, J. B., H. McKnight, E. W. Baker, R. Erg€un Arsal, and N. H. Roberts. 2011. The
role of trust in postadoption IT exploration: an empirical examination of knowledge
management systems. IEEE Transactions on Engineering Management 58 (1):56–70. doi:
10.1109/TEM.2009.2028320.
Torre, I., J. Goslin, and L. White. 2020. If your device could smile: people trust happy-
sounding artificial agents more. Computers in Human Behavior 105:106215. doi:10.1016/
j.chb.2019.106215.
Venkatesh, V., J. Y. L. Thong, and X. Xu. 2016. Unified theory of acceptance and use of
technology: a synthesis and the road ahead. Journal of the Association for Information
Systems 17 (5):328–376. doi:10.17705/1jais.00428.
Wang, Y., and W. Xu. 2018. Leveraging deep learning with LDA-based text analytics to
detect automobile insurance fraud. Decision Support Systems 105:87–95. doi:10.1016/j.dss.
2017.11.001.
Wu, I. L., J. Y. Li, and C. Y. Fu. 2011. The adoption of mobile healthcare by hospital’s pro-
fessionals: an integrative perspective. Decision Support Systems 51 (3):587–596. doi:10.
1016/j.dss.2011.03.003.
Xu, H., T. Dinev, H. J. Smith, and P. Hart. 2008. Examining the formation of individual’s
privacy concerns: toward an integrative view. International conference on information sys-
tems, 1–16.
Zarifis, A., L. Efthymiou, X. Cheng, and S. Demetriou. 2014. Consumer trust in digital cur-
rency enabled transactions. Lecture Notes in Business Information Processing 183:
241–254. 10.1007/978-3-319-11460-6_21.
Zhao, Y., Q. Ni, and R. Zhou. 2018. What factors influence the mobile health service adop-
tion? A meta-analysis and the moderating role of age. International Journal of
Information Management 43: 342–350. doi:10.1016/j.ijinfomgt.2017.08.006.
JOURNAL OF INTERNET COMMERCE
83
","nanPerceived ease of use and usefulness in health insurance with AI:

Health insurance purchasing is typically utilitarian rather than hedonic. Factors influencing adoption and use of technology are similar across different contexts.

Limited AI in the interaction with the consumer can keep a constant state across queries and interpret unstructured data like pictures and emails.

AI can process applications fast and make customized offers, positively influencing perceived usefulness.

Trust in health insurance with AI:

Trust is crucial where there is an exchange of value involving risk.

The increasing role of AI raises new sources of distrust from the lack of human attributes, the unpredictability of AI, and unclear transparency.

Personal information privacy concerns (PIPC) from threats by AI in health insurance:

Sharing personal information during health insurance purchase raises privacy concerns.

AI in healthcare insurance can reduce the perceived information control and increase the perceived risk. These effects may be heightened by an ecosystem of technologies such as big data."
"Many virtual try-on systems aim to fit new in-shop garments into human portraits, but they often fail to generate dynamic features such as shadows and folds that change based on model pose and environmental ambiance. The authors propose PLTON, a Diffusion-based Product-level Virtual Try-on pipeline that preserves fine details of logos and embroideries while producing realistic shadows and wrinkles. Specifically, the main insights are in three folds: 1) Adaptive Dynamic Rendering: A pre-trained diffusion model is used as a generative prior and trained with a dynamic extractor from scratch to generate dynamic tokens that preserve high-fidelity semantic information. 2) Static Characteristics Transformation: High-Frequency Map (HF-Map) is the fundamental insight for static representation. PLTON first deforms the in-shop clothes to the target model pose by a traditional warping network, then a high-pass filter is used to extract an example HF-Map to preserve the static features of the clothes. The HF-Map is then fed into a static extractor to generate modulation maps, which are injected into the fixed U-net structure to synthesize the final result. 3) To further enhance retention, the Two-stage Blended Denoising method is proposed to guide the diffusion process toward the correct spatial layout and color.","Virtual try-on has gained increasing attention, with systems that can generate high-resolution images and preserve clothes characteristics. However, these systems still struggle to replicate dynamic features related to model pose and environment accurately. The authors investigate the limitations of traditional virtual try-on methods and apply large models in image generation. They find that conventional approaches often involve inputting warped clothes into the generative model, making it challenging to disentangle typical clothes static features and dynamic features. They also observe that while diffusion models have stronger generative capabilities, training such models with limited try-on pair data is not straightforward.","The authors propose a product-level try-on (PLTON) method that decouples the traditional one-stage clothes synthesis process into adaptive dynamic rendering and static characteristics transformation. They start by transforming the in-shop clothes using a pose and other conditions. They apply high pass filters to the warped cloth to extract high-frequency features and employ a static extractor to extract modulated prior maps from the HF-Map. A dynamic extractor is utilized to extract dynamic features of the in-shop cloth, generating dynamic tokens. The dynamic tokens and modulated prior maps are then input into a fixed pre-trained diffusion model to guide image generation. To reduce information loss during compression in the dynamic extractor, two-stage blended denoising is proposed, helping to guide the diffusion process toward the correct spatial layout and colors, resulting in more accurate and precise outputs.","PLTON was trained on a small try-on dataset (less than 20k) collected from the Internet and achieved SOTA results on a high-resolution dataset using only one A40 GPU, demonstrating its effectiveness and training efficiency.","The authors propose PLTON, a product-level virtual try-on method that decouples the traditional one-stage clothes synthesis process into adaptive dynamic rendering and static characteristics transformation. By utilizing a pre-trained diffusion model as a generative prior and training a dynamic extractor from scratch, PLTON can preserve fine details of logos and embroideries while producing realistic shadows and wrinkles. The Two-stage Blended Denoising method further enhances retention by guiding the diffusion process toward the correct spatial layout and color. Extensive experiments on 1024 × 768 datasets demonstrate the superiority of PLTON in mimicking real clothes dynamics.",Product-Level Try-on: Characteristics-preserving Try-on with Realistic Clothes Shading and Wrinkles,"Yanlong Zang, Han Yang, Jiaxu Miao, Yi Yang","Product-Level Try-on: Characteristics-preserving Try-on with Realistic Clothes
Shading and Wrinkles
Yanlong Zang1∗ Han Yang2∗ Jiaxu Miao1 Yi Yang1†
1Zhejiang University
2ETH Zurich
yanlongzang@gmail.com
hanyang@ethz.ch
jiaxu.miao@yahoo.com
yangyics@zju.edu.cn
Abstract
Image-based virtual try-on systems for fitting new in-shop
garments into human portraits have attracted increasing re-
search attention. An ideal pipeline should not only preserve
the in-shop clothes static characteristics (e.g. textures, logos,
embroideries) in the generated images but also generate dy-
namic features (e.g. shadow, folds) that change according to
the model pose and the environmental ambiance.
Previous works fail specifically in generating dynamic fea-
tures, as they preserve the warped in-shop clothes trivially
with predicted an alpha mask by composition. To break the
dilemma of over-preserving and textures losses, we propose
a novel diffusion-based Product-level virtual try-on pipeline,
i.e.PLTON, which can preserve the fine details of logos and
embroideries while producing realistic clothes shading and
wrinkles.1 The main insights are in three folds: 1) Adaptive
Dynamic Rendering: We take a pre-trained diffusion model
as a generative prior and tame it with image features, training
a dynamic extractor from scratch to generate dynamic tokens
that preserve high-fidelity semantic information. Due to the
strong generative power of the diffusion prior, we can gen-
erate realistic clothes shadows and wrinkles. 2) Static Char-
acteristics Transformation: High-frequency Map (HF-Map) is
our fundamental insight for static representation. PLTON first
deforms the in-shop clothes to the target model pose by a tra-
ditional warping network, then we use a high-pass filter to
extract an example HF-Map to preserve the static features of
the clothes. The HF-Map is then fed into our static extractor to
generate modulation maps, which are injected into the fixed
U-net structure to synthesize the final result. 3) To further en-
hance retention, the Two-stage Blended Denoising method is
proposed to guide the diffusion process toward the correct
spatial layout and color.
PLTON is finetuned only with our collected small-size try-
on dataset. Extensive quantitative and qualitative experiments
on 1024 × 768 datasets demonstrate the superiority of our
framework in mimicking real clothes dynamics.
Introduction
With the continuous development of generative models,
virtual try-on has become an increasingly popular topic.
While GAN-based methods (Yang, Yu, and Liu 2022; Choi
et al. 2021; Lee et al. 2022) can generate high-resolution
(1024×768) images that preserve nearly all clothes static
1* means equal contribution. † indicates corresponding author.
characteristics (e.g. textures, logos) and dynamic features
(e.g., shadings, folds) of in-shop clothes, questions arise
about whether these results meet our needs. 1) For instance,
in a fashion editorial style, consider the scenario where dif-
ferent models wear the same clothes in various environ-
ments. Should the clothes’ dynamic features always main-
tain the same characteristics as in-shop garments? 2) Can
we take advantage of large models with greater generative
capabilities than GANs to accurately generate natural and
dynamic clothes features related to model pose and environ-
mental atmosphere? Our investigation into previous virtual
try-on methods and the application of large models in image
generation have the following several key findings.
Firstly, we have observed that traditional virtual try-on
pipelines involve inputting warped clothes into the genera-
tive model. However, improving the conventional virtual try-
on pipeline is challenging due to the difficulty in directly dis-
entangling typical clothes static characteristics and dynamic
features. Follow-up methods such as (He, Song, and Xiang
2022; Ge et al. 2021; Yang, Yu, and Liu 2022; Wang et al.
2018; Minar et al. 2020) aim to preserve the static character-
istics of deformed in-shop clothes by generating a compo-
sitional mask. Since most in-shop clothes are stereoscopic,
the unprocessed dynamic features (e.g., shadings and folds)
are mis-preserved in the final synthesis causing incoherent
human-background lighting conditions. Moreover, when we
eliminate the shadow and folds of in-shop clothes (filling
the in-shop clothes with three solid colors: red, green, and
blue), as shown in Figure 1, traditional virtual try-on algo-
rithms (Yang, Yu, and Liu 2022; He, Song, and Xiang 2022;
Lee et al. 2022) can hardly generate natural dynamic shad-
ings and folds.
Secondly, while the diffusion model exhibits stronger
generative capabilities, generating high-resolution images
often requires expensive data and computing resources.
However, high-resolution virtual try-on data is not always
accessible, and the current open-source data set is generally
about 10k, training a photo-realistic try-on pipeline with lim-
ited try-on pair data is a valuable topic.
We propose the product-level try-on (PLTON) to ad-
dress the above challenges. Unlike previous traditional try-
on methods, PLTON is able to preserve static in-shop clothes
details such as textures, logos, and embroideries, while gen-
erating realistic clothes shadows and folds with limited data.
arXiv:2401.11239v1  [cs.CV]  20 Jan 2024
Figure 1: Visual comparison of PLTON and other four tradi-
tional virtual try-on algorithms in generating clothes shad-
ows and folds. To eliminate the influence of the original
clothes’ dynamic features, we fill the clothes with three solid
colors: red, green, and blue (from top to bottom).
Specifically, we decouple the traditional one-stage clothes
synthesis process into Adaptive Dynamic Rendering and
Static Characteristics Transformation. We use a dynamic ex-
tractor to extract dynamic tokens on compressed in-shop
clothes and use a static extractor to extract modulated prior
maps from the high-frequency map (HF-Map) as a supple-
ment. We then inject dynamic tokens and modulated prior
maps into a fixed pre-trained diffusion model to guide image
generation. In order to reduce the information loss caused by
compressing in-shop clothes in the dynamic extractor, we
propose two-stage blended denoising, which can simultane-
ously solve the problem of repeated patterns when gener-
ating high-resolution images, and guide the diffusion pro-
cess toward the correct spatial layout and colors, resulting in
more accurate and precise outputs.
PLTON was trained on a small try-on dataset (less than
20k) collected from the Internet and achieved SOTA results
on a high-resolution dataset using only one A40, illustrating
the effectiveness and training efficiency of our PLTON.
Related Works
Image-based Virtual Try-on.
The goal of image-based
virtual tyr-on is to naturally and realistically transfer in-shop
clothes to a reference person. Image-based virtual try-on can
be divided into two settings: model-to-model try-on such as
(Wu et al. 2019; Dong et al. 2019; Xie et al. 2021; Neu-
berger et al. 2020) and cloth-to-model such as (Han et al.
2018; Wang et al. 2018; Yang et al. 2020; Ge et al. 2021;
He, Song, and Xiang 2022; Bai et al. 2022; Chopra et al.
2021; Han et al. 2019; Matthews et al. 2017). Our primary
focus is on the cloth-to-model setting.
The recent virtual try-on algorithms generally comprise
a warping module and a fusion module. The fusion module
uses warped clothes obtained by the warping module and
other conditions (e.g., after-try-on human parsing) to gener-
ate the try-on results. There are two mainstream methods of
the fusion module: 1) (Wang et al. 2018; Minar et al. 2020;
Ge et al. 2021; Lee et al. 2022) preserve the warped in-shop
clothes trivially with predicting an alpha mask by composi-
tion, but easily results in unrealistic images when the in-shop
garments dynamic features do not match the background and
lighting conditions of the reference person. 2) (Choi et al.
2021; Lee et al. 2022) proposed a GAN-based generator to
generate the clothes dynamic features, but the static charac-
teristics of in-shop garments will be blurred when generat-
ing high-resolution images. In this paper, we target to accu-
rately capture the in-shop clothes’ static characteristics and
naturally generate clothes dynamic features.
Diffusion Probabilistic Model.
The diffusion probabil-
ity model, including forward and inverse processes, was in-
troduced in (Sohl-Dickstein et al. 2015). The model was
used in image generation, with DDPM
(Ho, Jain, and
Abbeel 2020) being the first to synthesize high-quality im-
ages. The inverse process in image generation involves con-
verting raw images into Gaussian distributions, adding ran-
dom Gaussian noise, and then recovering the raw image
through several denoising steps. DDIM (Song, Meng, and
Ermon 2020) improved the reverse process to reduce denois-
ing steps and increased sampling speed. The diffusion model
has shown more excellent generative capabilities than the
long-dominant GAN (Goodfellow et al. 2020) in many chal-
lenging image synthesis tasks (Amit et al. 2021; Baranchuk
et al. 2021; Brempong et al. 2022; Cai et al. 2020).
However, generating high-quality images with diffusion
models requires expensive computing resources and data.
For example, generating images with given prompts gener-
ally requires millions of training data (Ramesh et al. 2022;
Saharia et al. 2022). Furthermore, generating images with
given images is more challenging. Even by fine-tuning a
large diffusion model, millions of data are required. For ex-
ample, (Yang et al. 2022) used 1.9 million data and trained
64 v100s for seven days. Collecting paired image data is dif-
ficult in virtual try-on, and the largest open-source virtual
try-on dataset VITON (Han et al. 2018) has only 14,221
images. To address this challenge, we propose a novel ap-
proach to fine-tune large models by fixing the network and
controlling the bootstrap only with additional conditions.
Clothes Composition.
we reiterate the pros and cons of
the conventional design of composition-based try-on. Tradi-
tional GAN-based pipelines employ a split-transform-merge
pipeline with a final alpha composition to fuse all image
components to generate a synthetic clothed person. As pro-
posed by VITON (Han et al. 2018), alpha masks help com-
posite deformed clothing images with rendered coarse im-
ages. Due to the randomness of logos and embroidery, it
is almost impossible to generate the full features of the
target clothes without a synthetic mask. This acknowledg-
ment seems to dominate the current try-in pipeline design,
severely hindering the development of the field. As shown in
figure 1, it is incredibly challenging to preserve the fine de-
tails of the target clothing while generating coherent clothes
shadows and wrinkles on the reference person. Our pri-
mary motivation is to break this dilemma and design a new
paradigm to replace the traditional design of a product-level
try-on application.
Figure 2: A schematic of PLTON. We utilize the warping module to deform the in-shop clothes using pose (Cao et al. 2019)
and other conditions (e.g. densepose (G¨uler, Neverova, and Kokkinos 2018) segmentation (Gong et al. 2019; Li et al. 2020)).
Firstly, we apply High Pass Filters to the warped cloth to extract high-frequency features of the clothes. Then, we employ a
Static Extractor to extract modulated prior maps from the HF-Map. Subsequently, the Dynamic Extractor is utilized to extract
the dynamic features of the in-shop cloth, generating dynamic tokens. Finally, the dynamic tokens and modulated prior maps are
input into a fixed pre-trained diffusion model, which produces the final output. The terms ”Locked” and ”Lockless” represent
frozen and learnable parameters, respectively.
Methods
Our method aims to transfer the in-shop clothes to the ref-
erence model vividly and naturally. The generated image
showcases the clothes’ static characteristics, such as logos
and embroideries, while incorporating dynamic features that
change with the environment and reference person, such as
shadows and folds. To achieve this goal, we fine-tune a large
diffusion model based on stable diffusion (Rombach et al.
2022) on our collected dataset. Our approach accepts in-
shop and warped clothes signals for retaining static char-
acteristics and rendering dynamic features, resulting in a
product-level try-on.
Framework Overview
Our proposed virtual try-on method involves generating im-
ages of wearing in-shop clothes using a pre-trained large-
scale diffusion model. As shown in Figure 2, PLTON de-
couples the clothing synthesis process into adaptive dynamic
rendering and clothes static and Static Characteristics Trans-
formation. Firstly, we transform the in-shop cloth through
the warping module to obtain the warped cloth, and then per-
form high pass filters on the warped cloth to obtain the high-
frequency map (HF-Map). The method used by the warp-
ing module here is the style-based appearance flow in (He,
Song, and Xiang 2022). Then we use dynamic and static ex-
tractors to extract dynamic tokens and modulated prior maps
from in-shop cloth and HF-Map respectively. Finally, a two-
stage blended diffusion method is used for high-resolution
inference.
Diffusion Prior
In PLTON, we utilize the current open-source and state-of-
the-art stable-diffusion (Rombach et al. 2022) framework as
priors, comprising a variational autoencoder (VAE) (Bow-
man et al. 2015) and denoiser U-Net (Ronneberger, Fischer,
and Brox 2015) ϵ. The denoiser operates in a latent space
more suitable for likelihood-based generative models than a
high-dimensional pixel space. This is because it allows for
focusing on critical semantic bits of the data and training in
a lower dimensionality, which is more computationally effi-
cient. The first step involves training an autoencoder to com-
press and reconstruct the original image x0. Subsequently,
a modified time-conditioned U-net is trained to iteratively
predict the noise corresponding to the latent features at each
time step t ∈ {1, ..., T}. The objective function of U-net is
optimized to achieve the desired results:
LLDM := Eε(x),ϵ∼N (0,1),t[∥ϵ − ϵθ(zt, t, c)∥2
2],
(1)
where c is the embedding of conditional information. In the
previous stable diffusion, the text is passed through the CLIP
text encoder and then added to U-Net in the form of cross-
attention. In the field of virtual try-on, using prompts to de-
scribe the clothes’ static characteristics accurately is chal-
lenging. To overcome this, we use in-shop clothes images
with rich semantics as conditional information embedding.
Dynamic Extractor
To accurately generate the dynamic features of in-shop
clothes (e.g., shading, folds), a simple method is to directly
use the in-shop clothes as the conditional input of U-net.
However, this approach presents some challenges. Firstly,
the process from in-shop clothes to the clothes on models is
complex and cross-domain. Secondly, as shown in figure 1,
if using the warped cloth as input and designing it as a copy-
and-paste process, it is essential to note that this approach
may result in the loss of the network’s ability to generate
dynamic features, such as (Yang, Yu, and Liu 2022; He,
Song, and Xiang 2022).
To address the above issues, we choose a CLIP image en-
coder to extract the features of in-shop clothes images and
decode these features via several additional fully-connected
layers. We then inject these features into U-net in the form
of cross-attention. We denote the down-sample operation
as D. The input in-shop clothes image is represented by
xg ∈ Rh×w×c, a MLP network M(; θ) with a set of pa-
rameters θ transforms the embedding extracted by CLIP into
another feature map F with:
F = M (CLIP (D (xg)) , θ)
(2)
Nevertheless, the issue of lost information during the
compression process has bobbed up while using CLIP. Ad-
ditionally, obtaining accurate clothes features through train-
ing fully connected layers with limited data is challenging.
So, we introduce the static extractor stage to auxiliary train-
ing. Our approach effectively maintains semantic informa-
tion while generating dynamic features, even with a small
amount of data and computing resources.
Static Extractor
In the Static Extractor, we utilize the high-frequency map
(HF-Map) xhf of the warped clothes as additional, condi-
tional information to preserve the clothes’ static characteris-
tics. The HF-Map of the warped clothes is first injected into
zero-convolution Z (Zhang and Agrawala 2023) to convert
it to the same feature size as a fixed diffusion model Gf in-
put. Then, a trainable diffusion model Gt (encoders and mid-
blocks) is cloned from Gf and is used to perform clothes
static characteristics extraction. The modulated prior maps
are extracted by the encoders in Gt with:
y′ = Z (Gt (exT + Z (xhf, θ0) , F, θt) , θz)
(3)
where y′ is the output of the zero-convolution blocks in the
trainable diffusion model Gt. F is the dynamic tokens ex-
tracted by Dynamic Extractor. Then PLTON uses the fixed
diffusion model Gf to fuse modulated prior maps and dy-
namic tokens with:
y = y′ + Gf (xinput, F, θf)
(4)
where y becomes the output of the decoder block in the
fixed diffusion model Gf. Finally, PLTON retains clothes
static characteristics and generates dynamic features of
clothes successfully.
Two-stage Blended Denoising
Pasting warped clothes into the generated image may result
in the unnatural appearance of clothes boundaries on ref-
erence persons. To address this issue, (Yang, Yu, and Liu
2022; Ge et al. 2021; Minar et al. 2020) learns an alpha
mask to paste the static characteristics of the original in-shop
clothes more smoothly. However, as shown in Figure 1, this
approach sacrifices the model’s ability to generate clothes
dynamic features.
The static and dynamic extractors discussed in the previ-
ous two sections provide precise guidance for the diffusion
Algorithm 1: Two-stage Blended Denoising
Input: Input Image: x0, Reference Level of the Input Im-
age: δ, Warped Cloth: w0, Warped Cloth Mask:m, Reference
Level of the Warped Cloth: γ, The Number of Denoising
Steps: Snum, The list of Denoising Steps: Slist, Conditions:
c
Parameter: PLTON Model: ϵθ
Output: Generated image ex0
1: Tnum = Snumδ if δ < 1, else Tnum = Snum
2: Tstart = Snum − Tnum
3: Tlist = Slist [Tstart :]
4: η = 0
5: ϵ ∼ N(0, I)
6: ext = √αtx0 + (1 − αt)ϵ
7: for t = Tlist [Tnum] , ..., Tlist [0] do
8:
ex′
t−1 = √αt−1

xt−√1−αtϵt
θ(ext,c)
√αt

+
9:
p
1 − αt−1 − σ2
t · ϵt
θ(ext, c) + ϵtσt
10:
if η < Tnum ∗ γ then
11:
ϵ ∼ N(0, I), if t > 1, else ϵ = 0
12:
wt = √αtw + (1 − αt)ϵ
13:
ext−1 = ex′
t−1 ⊙ (1 − m) + m ⊙ wt
14:
end if
15:
η = η + 1
16: end for
17: return ex0
model. However, due to the limitation of CLIP input size,
the high-resolution clothes image is compressed to 224 ×
224 resolution, resulting in the information loss of clothes
details.
Secondly, the input image resolution of the diffusion-
based methods training is usually 512 × 512. As shown in
Figure 6, if we want to get an image with 1024 × 1024 res-
olution in one step during inference, there will be a repeated
patterns problem (see ablation research for details). To ad-
dress the above problems, we propose two-stage blended
denoising, which strengthens the model’s retention of static
characteristics by using warped clothes with added noise as
a guide and allows to adjust the degree of dynamic features
generation of clothes through δ and γ. In PLTON, we first
generate a low-resolution image and then use it as guidance
to generate a high-resolution image through image-to-image
generation. Both generation processes use Algorithm 1, with
Snum set to 50. When generating low-resolution images,
the input image x0 is noise, and x0 is not used as guidance
(δ = 1) and the reference degree to warped clothes γ = 0.2.
When generating high-resolution images, the input image x0
is the enlarged result of the generated low-resolution image.
Experiments
Experiments Setup
Datasets.
We collect a high-resolution (1024 × 768) fash-
ion image dataset from the Internet, consisting of 18,327
frontal view pairs of models and top in-shop clothes images.
The dataset is divided into training and test sets, with 15,527
pairs and 2,800 pairs. The test set we have collected is re-
Figure 3: The visual comparison of different models (FS-VTON (He, Song, and Xiang 2022), HR-VTON (Lee et al. 2022),
RT-VTON (Yang, Yu, and Liu 2022) and ours) in the dynamic generation and static characteristics preservation of clothes.
ferred to as ”TEST1”. To further evaluate the generalization
ability of PLTON, we perform direct inference on the test set
in (Lee et al. 2022), which we call ”TEST2”. Due to the low
resolution of the VITON dataset, we were unable to utilize
them in evaluating the generalization ability of our model.
Implementation Details.
Our model is implemented in
PyTorch and utilizes a single Nvidia A40 GPU for train-
ing and high-resolution image inference. The clothes warp-
ing module utilizes a StyleGAN-based architecture (Karras,
Laine, and Aila 2019) in FS-VTON (He, Song, and Xiang
2022) for the appearance flow strategy. The distillation strat-
egy is not used, and the hyperparameters remain consistent
with the FS-VTON open-source code. In order to better ex-
tract and mix clothes dynamic tokens and modulated prior
maps, we adopt stable-diffusion as our baseline model and
utilize the CLIP pre-trained model (ViT-L) as our image en-
coder in dynamic extractor. We extract the in-shop clothes
features from the last hidden state of CLIP as the condition
and decode them through 15 fully connected layers. Then we
inject extracted features into the diffusion process through
cross-attention. Our diffusion priors initialization utilize the
publicly released models of (Yang et al. 2022) and (Zhang
and Agrawala 2023) for the fixed and trainable parts re-
spectively. We train the model using the AdamW optimizer
(Loshchilov and Hutter 2017) with a learning rate of 1e-5,
a batch size of 8, and train for 50 epochs. Throughout the
training process, we did not use any data augmentation strat-
egy.
Qualitative Results
In the field of virtual try-on, we present a comparative anal-
ysis of our method with several current state-of-the-art base-
lines, including flow-based FS-VTON (He, Song, and Xiang
2022), semantic-based methods RT-VTON (Yang, Yu, and
Liu 2022) and HR-VTON (Lee et al. 2022). The distillation
trick is not applied to all methods for fair comparison. We
leverage publicly available open-source code for training or
fine-tuning on our dataset. Our visuals on TEST1 are shown
in Figure 3, where our method produces more realistic im-
ages than baselines. Our model not only well preserves the
static characteristics (e.g. textures, logos, and embroideries)
of the target clothes but also naturally generates the dynamic
features of the clothes (e.g. folds and shadows). Visual com-
parisons on TEST2 are provided in supp.
Table 1: Quantitative results on two different test sets,
TEST1 and TEST2, which are all in 1024 × 768. We show
the FID (Heusel et al. 2017) and LPIPS (Zhang et al. 2018).
”*” indicates methods that are only for reference, not the
main baselines; discussions are provided in supp.
Dataset
Method
FID
LPIPS
TEST1
FS-VTON
9.522
0.109
HR-VTON
11.852
0.146
RT-VTON
9.051
0.116
DAFlow∗
12.110
0.113
PFAFN∗
9.892
0.114
Ours
8.394
0.113
TEST2
FS-VTON
11.803
0.118
HR-VTON
14.684
0.122
RT-VTON
11.471
0.132
DAFlow∗
15.919
0.169
PFAFN∗
12.462
0.125
Ours
11.321
0.129
Effectiveness of Dynamic Extractor.
Dynamic Extrac-
tor is crucial in enhancing the realism of diffusion model-
generated dynamic features. In contrast to the traditional
virtual try-on algorithms FS-VTON (He, Song, and Xiang
2022) and RT-VTON (Yang, Yu, and Liu 2022), which rely
on learning an alpha mask to composite the warped cloth and
generated image, the Dynamic Extractor module guides the
diffusion model to produce more natural-looking images.
The resulting images exhibit more realistic lighting, shad-
ows, and folds, as exemplified by the sleeves and waist of
the clothes (row 1 in Figure 3) and the high collar area (row
1 in Figure 3). As shown in Figure 3, while HR-VTON
leverages GAN to generate clothes dynamic features, the re-
sulting shadows and folds look dirty. By leveraging the guid-
ance provided by the Dynamic Extractor module, PLTON
leverages the strengths of the large model to produce more
reliable, natural, and realistic clothing dynamic features.
Effectiveness of Static Extractor.
The Static Extractor is
designed to enhance the diffusion model’s ability to pre-
serve clothes static characteristics by introducing additional
conditional information (e.g. high-frequency map of warped
clothes). While FS-VTON and RT-VTON rely on learning
the composition mask to paste distorted clothes static fea-
tures back into the generated image. However, as shown in
Figure 3 (row.3, row.4), these methods can only copy and
paste part of the textures when the alpha mask learning is in-
accurate. Similarly, when the warped clothes cannot be well
aligned with the model, only part of the static features of the
garment can be preserved. Additionally, HR-VTON, which
totally uses the GAN-based network to preserve the static
characteristics of warped clothes, struggles to maintain the
static characteristics of clothing well under high-resolution
images.
Quantitative Results
The quantitative evaluation of the try-on task is challeng-
ing due to the absence of a real reference person with tar-
get clothes. In PLTON, we examine the paired and unpaired
settings for image reconstruction and clothing item manip-
ulation. For the unpaired setting, we utilize Fr´echet Incep-
tion Distance (FID (Heusel et al. 2017)) as the evaluation
metric, while for the paired setting, we use Learned Percep-
tual Image Patch Similarity (LPIPS (Zhang et al. 2018)) as
the reconstruction metric. However, it should be noted that
the paired setting may not be suitable for virtual try-on, as
discussed in (Ge et al. 2021; Yang, Yu, and Liu 2022). Be-
sides, the methods of pasting the warped clothes back to the
generated image by learning the alpha mask can effectively
improve the reconstruction metric. Our quantitative results
on two test sets (TEST1 and TEST2) are given in Table 1.
PLTON achieves state-of-the-art results by a large margin on
the unpaired setting.
Figure 4: Visual comparison of traditional virtual try-on
methods and ours. The case when the parsing of the refer-
ence person goes wrong is chosen to demonstrate the ro-
bustness of our method.
Robustness Analysis
In the realm of virtual try-on algorithms, traditional meth-
ods have been categorized into flow-based and seg-based
approaches. However, these methods often fall short when
faced with inaccurate human parsing or complex poses, re-
sulting in subpar outcomes. Our research has shown that
PLTON exhibits greater robustness than baselines. For in-
stance, in Figure 4, when the parsing of reference person
misses the trousers area, traditional methods tend to omit
the trousers altogether, whereas PLTON is capable of com-
plementing the missing piece. Similarly, in Figure 5, when
the model assumes a slightly complicated pose, such as
crossed or raised hands, the warped clothes obtained by the
warping module are often suboptimal, leading to inferior re-
sults. However, PLTON leverages FS-VTON badly warped
clothes as guidance and can tolerate improper distortion er-
rors, resulting in more realistic clothes details.
Figure 5: Visual comparison results between ours and tra-
ditional virtual try-on methods on slightly difficult (raised
hands, crossed hands) model images.
Figure 6: Visual comparison between one-stage and two-
stage inference methods in high-resolution parallax compar-
ison results
Figure 7: Visual ablation study of Static Extractor in
PLTON.
Ablation Study
Our ablation research mainly focuses on three aspects.
Firstly, we investigate the effectiveness of Static Extractor,
as an additional, conditional information control. Secondly,
we explore the necessity of two-stage inference. Lastly, we
analyze the influence of different parameters on clothes’
static feature retention and dynamic feature generation.
Effectiveness of two-stage inference.
Data and comput-
ing resource constraints limit our training process to 512 ×
512 resolution. However, we propose two solutions to ob-
tain high-resolution images of 1024 during inference. The
first is a single-stage inference, where high-resolution im-
ages are directly inferred. The second is a two-stage infer-
ence method, where we first infer a 768 × 576 image and
then use it as guidance to generate high-resolution images.
As illustrated in Figure 6, direct high-resolution reasoning
can lead to the problem of ”repeat pattern”, resulting in is-
sues such as short-sleeved clothes becoming long-sleeved
and sleeve ghosting. In virtual try-on, our two-stage infer-
ence method has proven effective in using the coarse image
as a guide network to generate high-resolution images and
avoid the problem of repeat patterns.
Figure 8: Visual comparsion of difference γ in blended de-
noising.
Ablation
on
Static
Characteristics
Transformation.
PLTON’s Dual Feature Render module is based on stable
diffusion. The module decouples the clothes features into
dynamic and static features to simplify and speed up net-
work training. The dynamic feature uses in-shop cloth with
more information to replace the simple prompt, while the
static feature uses the canny map of the distorted clothes
as an additional condition to guide image generation. Fig-
ure 7 shows the effectiveness of the static feature transfer
module as we compare it with the results obtained by rea-
soning when the static features are set to 0. The comparison
reveals that without the guidance of static features, the net-
work struggles to generate clothes textures and logos details
with a small amount of data.
Effectiveness of Blended Denoising.
In the blended de-
noising process in PLTON, the parameter γ plays a crucial
role in controlling the reference degree of the network to the
warped clothes. It guides the diffusion process toward the
correct spatial layout and colors. However, it is essential to
note that the value of γ should not be too large as it can af-
fect the network’s ability to generate the clothes’ dynamic
features (e.g. shadow and folds) and its robustness. Figure 8
illustrates this point, where a value of 0.75 results in the net-
work referring too much to the distorted clothes, leading to
unnatural dynamic features and retention of defects.
Table 2: Preference comparison. A user study is given by the
preference ratio for our method, which is the higher 705 the
better.
Method
TEST1
TEST2
FS-VTON
74.7%
73.7%
HR-VTON
73.2%
70.2%
RT-VTON
70.2%
75.8%
User Study
Image metrics may have limitations in depicting the try-on
quality. In order to further demonstrate the superiority of our
method, we found 24 volunteers to participate in our user
study. Each volunteer is assigned 30 images, and each im-
age contains a target cloth image, a reference person, a result
from PLTON, and a result randomly selected from baselines.
The user study results, as shown in 2, clearly demonstrate
that PLTON outperforms the existing state-of-the-art meth-
ods.
Conclusion
In this work, we propose a product-level virtual try-on
pipeline based on diffusion priors. Our main motivation is to
split the fitting into two schematics, static feature transfor-
mation, and adaptive dynamic rendering, to replace the tra-
ditional split-transform-merge pipeline. The proposed dual-
feature renderer adaptively blends deformed clothes during
denoising, resulting in coherent clothes wrinkles and shad-
ows with well-preserved details. Extensive experiments on
high-resolution datasets demonstrate the superiority of our
method, especially in qualitative visual results.
References
Amit, T.; Nachmani, E.; Shaharbany, T.; and Wolf, L. 2021.
Segdiff: Image segmentation with diffusion probabilistic
models.
Bai, S.; Zhou, H.; Li, Z.; Zhou, C.; and Yang, H. 2022. Sin-
gle stage virtual try-on via deformable attention flows. In
Computer Vision–ECCV 2022: 17th European Conference,
Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XV,
409–425. Springer.
Baranchuk, D.; Rubachev, I.; Voynov, A.; Khrulkov, V.; and
Babenko, A. 2021. Label-efficient semantic segmentation
with diffusion models.
Bowman, S. R.; Vilnis, L.; Vinyals, O.; Dai, A. M.; Jozefow-
icz, R.; and Bengio, S. 2015. Generating sentences from a
continuous space.
Brempong, E. A.; Kornblith, S.; Chen, T.; Parmar, N.; Min-
derer, M.; and Norouzi, M. 2022. Denoising Pretraining for
Semantic Segmentation. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition,
4175–4186.
Cai, R.; Yang, G.; Averbuch-Elor, H.; Hao, Z.; Belongie,
S.; Snavely, N.; and Hariharan, B. 2020. Learning gradi-
ent fields for shape generation. In Computer Vision–ECCV
2020: 16th European Conference, Glasgow, UK, August 23–
28, 2020, Proceedings, Part III 16, 364–381. Springer.
Cao, Z.; Hidalgo Martinez, G.; Simon, T.; Wei, S.; and
Sheikh, Y. A. 2019. OpenPose: Realtime Multi-Person 2D
Pose Estimation using Part Affinity Fields. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence.
Choi, S.; Park, S.; Lee, M.; and Choo, J. 2021. Viton-hd:
High-resolution virtual try-on via misalignment-aware nor-
malization. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 14131–14140.
Chopra, A.; Jain, R.; Hemani, M.; and Krishnamurthy, B.
2021.
Zflow: Gated appearance flow-based virtual try-on
with 3d priors. In Proceedings of the IEEE/CVF Interna-
tional Conference on Computer Vision, 5433–5442.
Dong, H.; Liang, X.; Shen, X.; Wang, B.; Lai, H.; Zhu, J.;
Hu, Z.; and Yin, J. 2019. Towards multi-pose guided virtual
try-on network. In Proceedings of the IEEE/CVF interna-
tional conference on computer vision, 9026–9035.
Ge, Y.; Song, Y.; Zhang, R.; Ge, C.; Liu, W.; and Luo, P.
2021.
Parser-free virtual try-on via distilling appearance
flows. In Proceedings of the IEEE/CVF conference on com-
puter vision and pattern recognition, 8485–8493.
Gong, K.; Gao, Y.; Liang, X.; Shen, X.; Wang, M.; and Lin,
L. 2019. Graphonomy: Universal human parsing via graph
transfer learning. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition, 7450–
7459.
Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.;
Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y.
2020. Generative adversarial networks. Communications of
the ACM, 63(11): 139–144.
G¨uler, R. A.; Neverova, N.; and Kokkinos, I. 2018. Dense-
pose: Dense human pose estimation in the wild. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, 7297–7306.
Han, X.; Hu, X.; Huang, W.; and Scott, M. R. 2019. Cloth-
flow: A flow-based model for clothed person generation. In
Proceedings of the IEEE/CVF international conference on
computer vision, 10471–10480.
Han, X.; Wu, Z.; Wu, Z.; Yu, R.; and Davis, L. S. 2018.
Viton: An image-based virtual try-on network. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, 7543–7552.
He, S.; Song, Y.-Z.; and Xiang, T. 2022. Style-Based Global
Appearance Flow for Virtual Try-On.
In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 3470–3479.
Heusel, M.; Ramsauer, H.; Unterthiner, T.; Nessler, B.; and
Hochreiter, S. 2017. Gans trained by a two time-scale up-
date rule converge to a local nash equilibrium. Advances in
neural information processing systems, 30.
Ho, J.; Jain, A.; and Abbeel, P. 2020. Denoising diffusion
probabilistic models. Advances in Neural Information Pro-
cessing Systems, 33: 6840–6851.
Karras, T.; Laine, S.; and Aila, T. 2019. A style-based gen-
erator architecture for generative adversarial networks. In
Proceedings of the IEEE/CVF conference on computer vi-
sion and pattern recognition, 4401–4410.
Lee, S.; Gu, G.; Park, S.; Choi, S.; and Choo, J. 2022.
High-Resolution Virtual Try-On with Misalignment and
Occlusion-Handled Conditions. In Proceedings of the Eu-
ropean conference on computer vision (ECCV).
Li, P.; Xu, Y.; Wei, Y.; and Yang, Y. 2020. Self-correction
for human parsing. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 44(6): 3260–3271.
Loshchilov, I.; and Hutter, F. 2017. Decoupled weight decay
regularization.
Matthews, A. G. d. G.; Van Der Wilk, M.; Nickson, T.; Fu-
jii, K.; Boukouvalas, A.; Le´on-Villagr´a, P.; Ghahramani, Z.;
and Hensman, J. 2017. GPflow: A Gaussian Process Library
using TensorFlow. J. Mach. Learn. Res., 18(40): 1–6.
Minar, M. R.; Tuan, T. T.; Ahn, H.; Rosin, P.; and Lai, Y.-
K. 2020. Cp-vton+: Clothing shape and texture preserving
image-based virtual try-on. In CVPR Workshops.
Neuberger, A.; Borenstein, E.; Hilleli, B.; Oks, E.; and
Alpert, S. 2020. Image based virtual try-on network from
unpaired data. In Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition, 5184–5193.
Ramesh, A.; Dhariwal, P.; Nichol, A.; Chu, C.; and Chen, M.
2022. Hierarchical text-conditional image generation with
clip latents.
Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; and Om-
mer, B. 2022. High-Resolution Image Synthesis With Latent
Diffusion Models. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
10684–10695.
Ronneberger, O.; Fischer, P.; and Brox, T. 2015.
U-net:
Convolutional networks for biomedical image segmenta-
tion. In Medical Image Computing and Computer-Assisted
Intervention–MICCAI 2015: 18th International Conference,
Munich, Germany, October 5-9, 2015, Proceedings, Part III
18, 234–241. Springer.
Saharia, C.; Chan, W.; Saxena, S.; Li, L.; Whang, J.; Denton,
E. L.; Ghasemipour, K.; Gontijo Lopes, R.; Karagol Ayan,
B.; Salimans, T.; et al. 2022. Photorealistic text-to-image
diffusion models with deep language understanding.
Ad-
vances in Neural Information Processing Systems, 35:
36479–36494.
Sohl-Dickstein, J.; Weiss, E.; Maheswaranathan, N.; and
Ganguli, S. 2015.
Deep unsupervised learning using
nonequilibrium thermodynamics. In International Confer-
ence on Machine Learning, 2256–2265. PMLR.
Song, J.; Meng, C.; and Ermon, S. 2020. Denoising diffusion
implicit models.
Wang, B.; Zheng, H.; Liang, X.; Chen, Y.; Lin, L.; and Yang,
M. 2018. Toward characteristic-preserving image-based vir-
tual try-on network. In Proceedings of the European confer-
ence on computer vision (ECCV), 589–604.
Wu, Z.; Lin, G.; Tao, Q.; and Cai, J. 2019. M2e-try on net:
Fashion from model to everyone. In Proceedings of the 27th
ACM international conference on multimedia, 293–301.
Xie, Z.; Huang, Z.; Zhao, F.; Dong, H.; Kampffmeyer, M.;
and Liang, X. 2021. Towards scalable unpaired virtual try-
on via patch-routed spatially-adaptive GAN. Advances in
Neural Information Processing Systems, 34: 2598–2610.
Yang, B.; Gu, S.; Zhang, B.; Zhang, T.; Chen, X.; Sun, X.;
Chen, D.; and Wen, F. 2022. Paint by Example: Exemplar-
based Image Editing with Diffusion Models.
Yang, H.; Yu, X.; and Liu, Z. 2022. Full-Range Virtual Try-
On With Recurrent Tri-Level Transform. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 3460–3469.
Yang, H.; Zhang, R.; Guo, X.; Liu, W.; Zuo, W.; and Luo,
P. 2020.
Towards photo-realistic virtual try-on by adap-
tively generating-preserving image content. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition, 7850–7859.
Zhang, L.; and Agrawala, M. 2023. Adding conditional con-
trol to text-to-image diffusion models.
Zhang, R.; Isola, P.; Efros, A. A.; Shechtman, E.; and Wang,
O. 2018. The unreasonable effectiveness of deep features as
a perceptual metric. In Proceedings of the IEEE conference
on computer vision and pattern recognition, 586–595.
","The authors review image-based virtual try-on methods, diffusion probabilistic models, and clothes composition approaches. They discuss the pros and cons of traditional GAN-based pipelines and the challenges associated with relying on prompts to describe clothes' static characteristics. They also highlight the importance of preserving the fine details of the target clothing while generating coherent clothes shadows and wrinkles.nan"
"Ransomware attacks have evolved and increased in frequency, length, and repetition, causing disruption and harm to the way people use technologies and trust in their devices. This study investigates the effect of these attacks on a user's e-commerce status quo and if they are severe enough to change long-standing information system habits.","Ransomware attacks can have far-reaching effects on individuals and organizations, including disrupting core services, reaching a global scale, lasting for extended periods, and repeating, all of which can diminish trust in the attacked organizations and institutions. This research aims to determine whether these repeated, extended, and global ransomware attacks can overcome a user's status quo bias and cause them to switch systems.","The research employed a quantitative approach, specifically Partial Least Squares Structural Equation Modelling (PLS-SEM), to analyze the relationship between ransomware attack variables and e-commerce status quo variables. The measurement model evaluated the relationship between observed and latent variables, and the structural model assessed the strength of the relationship between the latent variables.","The analysis revealed that seven out of sixteen hypotheses were supported. The findings suggest that repeated ransomware attacks negatively impact inertia, trust, and information privacy, which in turn have a positive effect on resistance to switching systems. However, the effect of attack duration and repetition on inertia and trust was found to be insignificant.","The research contributes to the understanding of the impact of ransomware attacks on the user's decision to switch systems. It also provides practical implications for organizations in terms of developing strategies to reduce the effectiveness of attacks, managing disasters during attacks, and building goodwill to buffer the impact on users.","Can global, extended and repeated ransomware attacks overcome the users status quo bias and cause a switch of system","Alex Zarifis, Xusen Cheng, Uchitha Jayawickrama, Simone Corsi","DOI: 10.4018/IJISSS.289219
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1 
This article published as an Open Access article distributed under the terms of the Creative Commons Attribution License
(http://creativecommons.org/licenses/by/4.0/) which permits unrestricted use, distribution, and production in any medium,
provided the author of the original work and original publication source are properly credited.
*Corresponding Author
1
Can Global, Extended, and Repeated 
Ransomware Attacks Overcome 
the User’s Status Quo Bias and 
Cause a Switch of System?
Alex Zarifis, University of Nicosia, Cyprus
 https://orcid.org/0000-0003-3103-4601
Xusen Cheng, Renmin University of China, China
Uchitha Jayawickrama, Loughborough University, UK
 https://orcid.org/0000-0002-7159-6759
Simone Corsi, Loughborough University, UK
ABSTRACT
Ransomware (RW) attack effectiveness has increased causing far-reaching consequences that are not 
fully understood. The ability to disrupt core services, the global reach, extended duration, and the 
repetition has increased their ability to harm organizations. One aspect that needs to be understood 
better is the effect on the user. The user in the current environment is exposed to new technologies 
that might be adopted, but there are also habits of using existing systems. The habits have developed 
over time with trust increasing in the organization in contact directly and the institutions supporting 
it. This research explores whether the global, extended, and repeated RW attacks reduce the trust 
and inertia sufficiently to change long-held habits in using information systems. The model tested 
measures the effect of the RW attack on the e-commerce status quo to evaluate if it is significant 
enough to overcome the user’s resistance to change.
KEywORdS
Cybersecurity, E-Commerce, E-Loyalty, Inertia, Malware, Petya, Ransomware, Sodinokibi, Trust, WannaCry
INTROdUCTION
In the story of David versus Goliath, an underdog manages to beat a much larger and stronger 
opponent. This metaphor can be used to describe the ransomware (RW) attacks. They may have 
limited resources like David while the organizations being targeted and the institutions supporting 
them are often like Goliath with extensive resources. We would like to believe, in this case, that the 
large organizations and institutions will emerge victorious by limiting the harm inflicted on them and 
their users. Is this, however, the case? The user has come to expect a reliable service from the train 
operators, airports and other services and products they use with minimal delay or downtime. Most 
users also experience secure transactions, secure storage and responsible use of personal information. 
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
2
Examples of core service failure such as extended periods without access to services are rare and are 
usually limited to an economic crisis and failing organizations (Mansfield-Devine, 2020). Most users 
have also not experienced breaches of security that would reveal their personal information (Simoiu, 
Symantec, Bonneau, & Goel, 2019). This has built a trust in the institutions, organizations and the 
way personal information is handled. It has also created an e-loyalty (Carter, Wright, Thatcher, & 
Klein, 2014) expressed as an inertia and habit of the user in favour of the current systems used in 
e-commerce (Polites & Karahanna, 2012). The user however, is now facing the new phenomenon of 
global, extended and repeated RW attacks. While many users are directly affected by these attacks 
the reports in the media, social media and word of mouth serve to further magnify the impact. This 
may cause a momentary, or more extended, erosion of trust in the organizations they are directly in 
contact with and the institutions that support them. These attacks may also influence the user to such 
a degree that they overcome the inertia they have in favour of existing systems.
RW attacks use a malware to encrypt files on a computer and request a monetary amount, usually 
in Bitcoin, for the files to be unencrypted and made available for use again (Mercaldo, Nardone, & 
Santone, 2016). Ransomware attacks cost approximately 45 billion dollars in 2018 (Online Trust 
Alliance 2019). While each attack may have some variation in how the computer is infected, what 
files are encrypted and how the encryption is reversed, they are similar in their approach (Kharraz, 
Robertson, Balzarotti, Bilge, & Kirda, 2015). This form of malware is not new but its ability to disrupt 
an organization’s core services repeatedly and for a prolonged period has increased. The effectiveness 
has increased because a combination of technologies and circumstances, are more favourable now than 
ten or fifteen years ago. For example, technologies such as digital currencies and circumstances such as 
outdated, unsupported operating systems have enabled and amplified attacks (Kshetri & Voas, 2017).
Recent RW attacks such as WannaCry, Petya, NotPetya, exPetr, Bad Rabbit, Sodinokibi-REvil 
(Simoiu et al., 2019; Yaqoob et al., 2017) are critical incidents that may have had an impact on the user 
and the willingness to engage in e-commerce as they did before. Since the start of the century business 
to consumer e-commerce has expanded with more people adopting it and existing users utilizing it 
more regularly. These repeated attacks may erode trust and loyalty. The user may stop engaging with 
the online vendor they had a habit of using if that vendor is attacked. A switch might be made to an 
online vendor that has not been attacked or an offline vendor less dependent on information systems. 
The user may switch to a new solution completely or partially. For example, the user may continue 
to use the same vendor but limit the value exchanged or the personal information shared. Lastly, the 
decision may be made to abstain from the exchange of value that was intended to be made. Improving 
the understanding of this phenomenon on the e-commerce user, will enable remedial action to be 
taken before, during and after an attack. Therefore:
The aim of this research is to identify the factors that influence the user’s decision to stop using an 
organization’s system because of a RW attack. 
This research combines studies on inertia and resistance to switching systems (Polites & 
Karahanna, 2012) with a more comprehensive set of variables that cover the current e-commerce status 
quo. Personal information disclosure is included along with inertia and trust as it is now integral to 
e-commerce functioning effectively. The model developed captures the cumulative effect of this form 
of attack and evaluates if it is sufficiently harmful to overcome the e-loyalty and inertia built over time.
The implications of this research are both theoretic and practical. The theoretic contribution is 
highlighting the importance of this issue to IS theory, linking the RW literature to user inertia in IS 
and developing a model. There are three practical implications. Firstly, by better understanding the 
impact on the user it may be possible to have a new strategy to reduce the effectiveness of RW attacks. 
Secondly, processes can be created to manage such disasters as they are happening and maintain a 
positive relationship with the user. Lastly, the organizations can develop a buffer of goodwill and 
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
3
e-loyalty that would absorb the negative impact on the user from an attack and stop them reaching 
the point where they decide to switch system.
BACKGROUNd
Ransomware Attacks
New RW attacks are emerging regularly as the attackers try to overcome the latest software updates 
and security solutions. Google identified 34 variations of RW in 2017 (Ramsey, 2017) and the number 
has since increased with new attacks like STOP(DJVU) in 2019. Despite their large number, they 
share similar characteristics and most new attacks are evolutions of previous ones. RW attacks are a 
combination of malware and extortion. The attack has a number of steps, as illustrated in figure 1: 
Firstly infection, secondly encryption and possibly deletion and thirdly reversal if the ransom is paid.
The infection stage, for the more primitive RW attacks, typical before 2016, usually required an 
action by the victim (Chang & Seow, 2019). This could include an attack known as a ‘web drive-by’ 
where a user downloads and runs a file that appeared to be a software update while visiting a legitimate 
cite (Erridge, 2016). There are also more targeted socially engineered infections that send senior staff 
an email with an attachment that appears to be a compressed document file. More recent attacks such 
as WannaCry and NotPetya, possibly with the exception of Bad Rabbit (Mamedov, Sinitsyn, & Ivanov, 
2017), did not require an action by the victim. For the RW attacks where no action from the victim 
is needed, the malware may be able to move from one computer to another across an organization’s 
network. This is a major factor in RW of this type spreading quickly. In these cases, the vulnerability 
comes primarily from the platform provider, rather than the user. Therefore, these platform providers 
that offer software and hardware, play an important role. It is not just the organization that comes 
into direct contact with the user, that has an influence. While the user may not initially know who 
these institutions are, this information can emerge during the attack.
Once a computer is infected, certain files are encrypted and a ransom request appears on the 
screens of the infected systems. The more sophisticated and extensive the encryption is, the harder 
it is to reverse it without paying the ransom. The malware used can randomly encrypt some files or 
target specific files that are more valuable. Files can also be targeted to make the recovery harder 
such as computer logs of the event. The RW message is designed to cause fear and panic in the 
victim. It usually includes a large countdown, many different fonts and flashing text. The ransom 
is typically requested in Bitcoin, usually half a bitcoin. This payment method is chosen so that it is 
harder to identify the attacker (Zimba, Wang, & Mulenga, 2019). Sometimes, a further threat that 
Figure 1. The steps of a typical ransomware attack
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
4
the ransom will be increased, is included. The ransom request can be forced on to all monitors across 
an organizations network including information screens in public places such as retail stores, train 
stations and hospitals. This puts pressure on the users or consumers which will add additional pressure 
on the organization to pay the ransom.
For the victim to make the ransom payment, a digital currency such as Bitcoin must be acquired 
first. This is a process most victims may not be familiar with. A digital currency is also a technology, 
with certain software and knowledge necessary to use it. Therefore, it can be considered that the 
victim must first adopt a new technology before paying the ransom. In some cases, when the ransom 
is payed the attacker reverses the encryption using a decryption key or ‘kill switch’ and removes the 
malware as the ransom request promised. However, in other cases, the attacker takes no action to 
reverse the harm done. The encryption may not be reversed out of choice or because the attacker does 
not have the ability to reverse it. This highlights that an attack can either be controlled across all the 
stages by the attacker, or it can be caused by self-propagating malware that is no longer controlled 
by anyone (Simoiu et al., 2019).
The number of RW attacks has increased from one in 2012 to 193 in 2016 (Kshetri & Voas, 
2017) and 184 million in 2018 (SonicWall, 2019). The first attack that caused core service failures 
across many countries and could be considered global, was WannaCry in May 2017 affecting over 
200000 systems in over 150 countries (Young & Yung, 2017). This was followed by the NotPetya 
attack in June, 2017. This was a more advanced version of Petya that had started appearing on a 
smaller scale 2016. In October of the same year, the Bad Rabbit attack emerged, initially targeting 
government information systems. In 2019 the new Sodinokibi-REvil attack caused large organizations 
to stop operating (Mansfield-Devine, 2020). In the future, attacks may increase further in their scale 
and ability to disrupt by targeting connected devices. As the Internet of Things (IoT) becomes more 
widespread, our dependence on connected devices will increase and the number of vulnerable targets 
will increase also (Yaqoob et al., 2017).
E-Commerce Status Quo And Inertia
Inertia and E-Loyalty
Many of us have used B2C e-commerce for several years now. In such cases the relationship between 
the user and the organization has gone beyond technology adoption to a habit and e-loyalty (Carter 
et al., 2014; Gefen, 2003; Limayem, Hirt, & Cheung, 2007). Continued behavior that follows the 
status quo instead of a superior alternative, increases inertia (Polites & Karahanna, 2012). The 
information systems and the e-service provided to the user in the current e-commerce environment, 
satisfies many of them and creates this inertia. As the technology and business processes supporting 
e-commerce improve over time, the user is regularly presented with a better service, so the satisfaction 
is maintained or increased. Therefore, there can be an accumulation of goodwill over the years. The 
inertia is compounded by switching costs. Engaging in e-commerce with a specific organization or 
platform requires an investment of time to complete processes such as registering and sharing of 
personal details. In addition to the inevitable cost of changing system, switching barriers are also 
introduced intentionally to make the change harder (Ghazali, Nguyen, Mutum, & Mohd-Any, 2016). 
Consequently, there can be a significant resistance from the user to switching systems. This resistance 
to switching can be overcome by a critical incident that is sufficiently influential.
User and consumer switch resistance has been evaluated in relation to other critical incidents 
apart from RW attacks (Polites & Karahanna, 2012). It has not been sufficiently evaluated for this 
type of incident, particularly when it is repeated. Literature suggests the user’s resistance to changing 
service is different for different types of incidents. It is therefore useful to evaluate the effect of this 
type of incident on the user. For a user to switch system they need an alternative (Ghazali et al., 2016). 
If an incident has made them aware of weaknesses in the current system they use, an alternative may 
be more appealing as long as it does not appear to have the same weaknesses. While the attacks are 
extensive, so far, they have not impacted all the systems and all the organizations in one sector of the 
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
5
economy. Therefore, there are organizations and systems that have not been attacked, that may appear 
to be an appealing alternative for the user to switch to. The switch may not be complete and instant. 
There can be a transitionary period taking some time (Zeithaml, Berry, & Parasuraman, 1996). As 
the goodwill, habit and e-loyalty have built up over time with a series of successful exchanges of 
value, it may take a series of negative events to overcome the inertia.
E-loyalty can be fuelled with the quality of the e-service. One popular method of evaluating 
service quality on the Internet is IS SERVQUAL which includes reliability, responsiveness, assurance 
and empathy (Jiang, Klein, & Carr, 2002). The first three variables reliability, responsiveness and 
assurance measure related concepts to organizational and institutional trust, discussed in the following 
section. All four aspects of the service should be optimized at all times. Maintaining the minimal 
necessary service quality before an attack may build up insufficient e-loyalty to buffer the effect of 
the attack and result in a system switch. A service quality that exceeds user’s expectations, will have 
a higher level of e-loyalty and more possibilities of retaining the user through the challenging period 
of an RW attack. Therefore, given the repeated RW attacks, organizations need to be prepared both 
on a technical level and in their ability to absorb the negative effect on users. A loyal user can use 
the same online service throughout a lifetime showing a degree of tolerance and forgiveness. If an 
incident, or series of incidents, causes the user to switch to an alternative online or offline service, the 
user can show lifelong loyalty to their new choice of system. Inertia can start building in favour of the 
new system, once it is adopted, and it will start to gain the advantages of an incumbent system. The 
previous incumbent system will now be an unappealing alternative, saddled with the dissatisfaction 
that led to the switch. There is, therefore, a lot at stake.
Institutional Trust and Organizational Trust
Trust has been proven to have an effect in human interaction particularly when exchanging value online 
such as when a user purchases a train ticket. Trust has also been found to have a significant influence 
on the consumer’s e-loyalty towards a merchant (Carter et al., 2014). Trust can be distinguished 
between the organization the user is in contact with that provides the product or service and the 
institutions that support this exchange of value (McKnight & Chervany, 2002). These institutions 
include the Internet, the platform such the Google or Microsoft ecosystem, watchdogs and regulators. 
The organizations and institutions support a status quo of trust for many users that encourages them 
to engage in e-commerce. An example of how institutions influence organizations’ behaviour online 
are the investigations into online vendors that have their data compromised. The investigations 
check if the compromised vendor’s information systems and processes were suitable and met legal 
requirements. This is an example of how responsible behavior on the Internet is encouraged and 
enforced. A second example of the role of institutions are the cases when government regulators 
encouraged technology companies to provide updates to vulnerable systems at lower prices, to reduce 
the risk (FRPT Research, 2016).
Information Privacy
For a user to engage in many activities on the Internet, particularly acquiring e-services and products, 
some personal information must be shared. Over time most users have accepted that a level of personal 
information disclosure is necessary with certain vendors, platforms and institutions when exchanging 
value on the Internet (Chen, Zarifis, & Kroenung, 2017). This information can include a name, address 
and banking details. Some record of online activities including browsing and purchase history, may 
also be stored. This can be considered as an informal and formal agreement between the user and 
the Internet based organizations about how personal information is stored, shared, exploited and 
protected from threats (Conger, 2008). The formal part of the agreement can include the corporate 
privacy policies and legal framework. The user calculates the perceived control over the situation, 
the perceived risk and perceived intrusion from sharing this information (Xu, Dinev, Smith, & Hart, 
2008). The user may only have a perception of how the personal information is used and may not be 
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
6
fully aware of the extent of the use. This perception can be informed in several ways such as targeted 
adverts. If the user purchased a ticket to Paris and they start receiving adverts for hotels in Paris, they 
may start to think about which organization shared their personal purchasing information. Given that 
RW attacks compromise the security of the organization targeted and encrypt data, personal information 
may also be accessed. If the user’s personal information was accessed for it to be encrypted, was 
it also stolen? Would the organization know if it was also stolen? Would the organization inform 
them? These questions around privacy increase the perceived information asymmetry (Ba & Pavlou, 
2002) between the user and the organization they are engaging with. Therefore, in the aftermath of 
an attack the user may reconsider the extent to which they are willing to share personal information.
Research Model
The research model is based on the theoretical background covered in the previous section. The model 
presented in figure 2 identifies three variables that encapsulate the total effect of the RW attack and four 
variables that form the e-commerce status quo. The variables of the RW attack negatively influence 
the four variables of the status quo. The four variables of the status quo increase the resistance of 
the user to switching system (Polites & Karahanna, 2012). The proposed model therefore evaluates 
whether the status quo from the user’s perspective is strong enough to absorb the repeated, extended 
RW attacks or if the attacks will cause an intention to switch systems. The RW attacks must be 
evaluated by taking into account the longitudinal and cumulative effect. This effect can be separated 
into three dimensions: Firstly, the specific effect on the user. This refers to the specific inconvenience 
the user endured such as a delay in booking a train ticket. The RW effect is hypothesized to negatively 
influence the four variables that form the e-commerce status quo:
H1: The ransomware attack impact on the user, will have a negative effect on the inertia towards 
switching system.
H2: The ransomware attack impact on the user, will have a negative effect on the trust towards 
institutions that support e-commerce.
H3: The ransomware attack impact on the user, will have a negative effect on trust towards the 
organization engaged with directly for the exchange of value.
H4: The ransomware attack impact on the user, will have a negative effect on the willingness to share 
personal information.
The second constituent part of the attack is the RW duration. It is hypothesized that the longer 
the duration is, the greater the negative impact on the constituent variables of the e-commerce status 
quo. For example, an attack that causes a core service failure for under one hour, over one hour but 
less than 24 hours, and over 24 hours will cause a progressively greater effect on the user’s beliefs.
H5: The ransomware attack duration will have a negative effect on the user’s inertia towards switching 
system.
H6: The ransomware attack duration will have a negative effect on the user’s trust towards institutions 
that support e-commerce.
H7: The ransomware attack duration will have a negative effect on the user’s trust towards the 
organization engaged with directly for the exchange of value.
H8: The ransomware attack duration will have a negative effect on the user’s willingness to share 
personal information on the Internet.
The third and final constituent part of the attack is the RW repetition. It is hypothesized that 
the more times these attacks happen, the greater the cumulative negative impact on the constituent 
variables of the e-commerce status quo.
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
7
H9: The number of ransomware attacks will have a negative effect on the user’s inertia towards 
switching system.
H10: The number of ransomware attacks will have a negative effect on the user’s trust towards 
institutions that support e-commerce.
H11: The number of ransomware attacks will have a negative effect on the user’s trust towards the 
organization they engage with directly for the exchange of value.
H12: The number of ransomware attacks will have a negative effect on the user’s willingness to share 
personal information on the Internet.
The e-commerce status quo is formed by four constituent parts. These are inertia, institutional 
trust, organizational trust and information privacy. Inertia is created by the habit of using an incumbent 
system, the perceived transition costs and a psychological commitment due to perceived sunk costs 
and the appeal of the alternatives (Ghazali et al., 2016; Polites & Karahanna, 2012). The higher the 
level of the inertia, the harder it is for a critical incident to make a user switch system:
H13: The user’s inertia will have a positive effect on the resistance towards switching system.
Institutional trust is shaped by cumulative positive experiences. Positive experiences include 
competent and effective related institutions including the government, regulators, Internet providers 
and software vendors. Additionally, structural assurance is indicated by the Internet environment 
being ordered and normal. Structural assurance is also supported by the availability of regulations and 
legal remedy on the Internet. Furthermore, institutional trust is shaped by the institutions’ response 
to the attack. The initial response may stop short of solving the problem but it can be organized, 
coordinated and reassuring (Aliakbarlou, Wilkinson, Costello, & Jang, 2017). The final response 
must offer an effective and convenient solution. In addition to institutional trust the user must also 
trust the organization that value is exchanged with directly, such as a vendor. The user’s belief in the 
competence, benevolence, integrity of the vendor builds this trust (McKnight & Chervany, 2002).
H14: The user’s trust towards institutions that support e-commerce will have a positive effect on 
resistance towards switching system.
H15: The user’s trust towards the organization engaged with directly for the exchange of value will 
have a positive effect on resistance towards switching system.
The fourth and last constituent part is the explicit and tacit contract between the user and the 
online organization on their personal information privacy. Perceived information privacy is formed 
by the existence of formal policies and procedures such as the perceived effectiveness of privacy 
statement, the perceived reasonableness of the data requested, the perceived reasonableness of the 
use and sharing of the information (Conger, 2008).
H16: The user’s belief that personal information will be kept private, has a positive effect on resistance 
towards switching system.
METHOdOLOGy
The quantitative analysis applied Partial Least Squares Structural Equation Modelling (PLS-SEM) 
using the ADANCO software. As the model is moderately complex the analysis is in two stages. 
The measurement model is evaluated first and then the structural model. The measurement model 
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
8
evaluates the eight latent variables with three measured variables for each one. The structural model 
evaluates the hypothesized relationship between the eight latent variables.
For the operationalization of the research variables a number of validated scales were utilized 
including scales for habit (Polites & Karahanna, 2012), trust (McKnight, Choudhury, & Kacmar, 
2002), technology adoption (Venkatesh, Morris, Davis, & Davis, 2003) and information privacy (Hui, 
Teo, & Sang-Yong, 2007; Liang, Xue, Laosethakul, & Lloyd, 2005). The scales for RW attacks were 
developed by this research.
The sample was collected by the online survey tool SoSci Survey (www.soscisurvey.de) from the 
general population. There was a requirement that participants know what the RW attacks are and that 
they have experienced them either directly or indirectly. The necessary sample size for a significance 
level of 1% and a minimum R2 of 0.10 was calculated to be 191 (Hair, Hult, Ringle, & Sarstedt, 
2014). An alternative method using the G*Power software with an effect size of 0.5, a power of 0.95 
and 8 degrees of freedom suggested a minimum sample size of 91. The survey was completed by 
243 participants from which 204 are considered sufficiently complete and valid.
Figure 2. Research model: The impact of ransomware attacks on the user’s intentions
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
9
ANALySIS ANd RESULTS
The PLS-SEM analysis is presented in two stages starting with the measurement model and then 
the structural model. The measurement model evaluates how strong the relationship is between the 
observed and latent variables. The structural model evaluates how strong the relationship is between 
the latent variables.
Evaluating the Measurement Model
The measurement model is evaluated in a number of ways including the Fornell-Larcker Criterion 
presented in table 2 and the factor loading, Construct Reliability (CR) and Average Variance Extracted 
(AVE) presented in table 3. When the initial research model was tested the Fornell-Lacker criterion 
showed a strong correlation between two sets of variables. The first pair with a high correlation were 
ransomware attack effect and duration. The second pair with a high correlation were institutional 
trust and organizational trust. Therefore, the two pairs were merged leaving the model with six 
variables. Variables with a high correlation can be merged if this is compatible with the logic of the 
model and can also be supported theoretically from the literature (Hair et al., 2014). Merging the two 
dimensions of trust and the two dimensions of RW attacks meets these criteria. The Fornell-Lacker 
criterion measures for the new version of the model presented in table 2 did not have problematic 
correlations. The loadings of the observed variables that were reflective constructs, exceeded the 
required level of 0.70 (Hair et al., 2014). Construct Reliability (CR), calculated by the Cronbach’s 
Alpha is over the necessary 0.70. This is an indication that the items that form the latent variable are 
sufficiently related. Average Variance Extracted (AVE) is above the threshold of 0.50 (Hair et al., 
2014). The AVE indicates that the items explain the latent variable and there is enough convergent 
validity between them.
Table 1. Demographic information of the participants
Frequency
Percentage
Gender
Female
91
42
Male
118
58
Age
Under 18
8
4
18-24
95
47
25-39
64
31
40-59
37
18
60 or older
8
4
Education level
Without educational level
6
3
High school
103
51
Undergraduate university 
degree
56
28
Post-graduate university degree
39
19
Income 
(in British Pounds 
per month)
No regular income
17
8
400-1200
43
21
1201-3000
50
25
3001-5000
86
42
> 5000
8
4
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
10
Evaluating the Structural Model
The structural model is evaluated in several ways that are presented in table 4 and figure 3. The 
coefficient of determination R2 is above 0.1 for Inertia, Trust and Information Privacy (IP) that can 
be considered weak and above 0.8 for User Switching Resistance (USR) which is substantial (Chin, 
Table 2. Fornell-Larcker Criterion
Construct
RAE
RAR
Inertia
Trust
IP
USW
RW attack effect (RAE)
0.7207
RW attack repetit. (RAR)
0.5138
0.8179
Inertia
0.1609
0.0881
0.7558
Trust
0.1060
0.0843
0.7454
0.7305
Information privacy (IP)
0.0519
0.1230
0.6079
0.6341
0.7564
User switch resist. (USW)
0.0729
0.0576
0.7583
0.8054
0.6354
0.8504
Table 3. Results of the measurement model
Scale/Item
Loadings
CR
AVE
Ransomware attack effect
0.8063
0.7207
RAE01
0.7967
RAE02
0.8657
RAE03
0.8820
Ransomware attack repetition
0.8893
0.8179
RAR01
0.9241
RAR02
0.8604
RAR03
0.9270
Inertia
0.8382
0.7558
I01
0.8989
I02
0.8509
I03
0.8574
Trust (Organ. and Instit.)
0.8153
0.7305
T01
0.8518
T02
0.8309
T03
0.8806
Information privacy
0.8388
0.7564
IP01
0.8637
IP02
0.8520
IP03
0.8929
User switching resistance
0.8242
0.8504
USR01
0.9235
USR02
0.9208
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
11
1998). This suggests a weak explanatory power of the exogenous variables. The effect size is large for 
the path from Trust to USR as it is above 0.35 and moderate for Inertia to User Switching Resistance 
(USR) as it is above 0.15. The other paths are below 0.15 and therefore weak (Chin, 1998). Based 
on the final model there is support for seven hypotheses from the initial sixteen. While this could be 
considered low if it was a confirmatory analysis it is acceptable as this is an exploratory analysis. The 
findings validate the use of PLS-SEM in this research over Covariance Based SEM which is better 
for confirmatory analysis of more mature models.
Table 4. Results of the structural model
Path coefficient
Standard 
error
t-value
p-value 
(2-sided)
Cohen’s f2
RAE -> Inertia
0.3875
0.0927
4.1826
0.0000
0.0870
RAE -> Trust
0.2417
0.1072
2.2543
0.0244
0.0320
RAE -> IP
-0.0487
0.1040
-0.4683
0.6397
0.0013
RAR -> Inertia
0.0190
0.0985
0.1926
0.8473
0.0002
RAR -> Trust
0.1171
0.0946
1.2378
0.2161
0.0075
RAR -> IP
0.3856
0.1009
3.8213
0.0001
0.0826
Inertia -> USR
0.3247
0.0550
5.8993
0.0000
0.1608
Trust -> USR
0.5026
0.0643
7.8179
0.0000
0.3596
IP -> USR
0.1437
0.0431
3.3361
0.0009
0.0453
Figure 3. Validated model: The impact of ransomware attacks on the user’s intentions
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
12
dISCUSSION
Theoretical Implications
The results of the analysis improve our understanding of the impact of RW attacks on the user and 
their intention to switch system. Trust in the organization and institutional trust have been evaluated 
separately in some research (McKnight & Chervany, 2002) while other research combines them 
(McKnight, Carter, Thatcher, & Clay, 2011). While this research distinguished between them in the 
initial model, the data showed that they are closely related from the user’s perspective in this context. 
While there is support from the data for both Ransomware Attack Effect (RAE) and duration the 
data also shows that from the user’s perspective, these are very closely related and to some degree 
indistinguishable. Therefore, it is recommended that future research use a variable covering both 
effect and duration together.
User inertia or e-loyalty (Carter et al., 2014; Polites & Karahanna, 2012) and personal information 
privacy concern were supported within the model. The path from trust to user switching resistance 
is stronger than the path from information privacy.
Practical Implications
Based on the findings of this research a new strategy to reduce the effectiveness of an attack can be 
made: As the repetition of a RW attack influences the user, it is important for the organization to 
respond quickly. The response should have two parts: First, the attack should be stopped, and the 
service should be re-established. As the repetition of the attacks influences the user, the organization 
should not pay the ransom because this encourages further attacks. Secondly the three variables that 
support habit should be reinforced. Information privacy concerns should be reduced, trust must be built, 
and inertia should be strengthened. If this is not achieved, then the user may search for alternatives.
The attack should also be seen as part of the relationship with the user. Therefore, there should 
be a plan in place before an attack on how to interact with the user. The user may be required to take 
some steps during the RW attack such as change their password, re-enter data or update their security. 
It has been shown that users can adapt both positively and negatively to such requests (Chenoweth, 
Gattiker, & Corral, 2019) so it is important to have a strong relationship that will encourage a positive 
response from the user.
Lastly, organizations and their executives should show that they followed institutions guidance and 
all legal requirements so that they benefit from institutional trust. As users trust certain institutions, 
by associating with them this trust is transferred. In this way an impression of situational normality 
is also supported. Situational normality is conducive to trust. This research shows that repeated 
attacks can change habits so this provides further encouragement for executives, in addition to their 
legal requirements (Chatterjee, 2019), to take the recommended steps for Cybersecurity preparedness 
before, during and after a security breach.
CONCLUSION
This research developed a model to evaluate whether a user would resist switching systems and stay 
within the e-commerce status quo despite extended and repeated RW attacks. The implications of 
this research are both theoretic and practical. A review of IS literature such as the AIS Electronic 
Library and MIS Quarterly, suggests that RW has received insufficient attention so far. Therefore, the 
first theoretic contribution is highlighting the importance of this issue to IS theory. The second, more 
specific, theoretic contribution is linking the RW literature to existing use of information systems. 
Furthermore, the theoretic understanding of inertia and status quo bias is expanded. The third theoretic 
contribution is exploring and developing a model on the impact of ransomware attacks on the user’s 
witching intentions. After merging two couples of variables because of their strong correlation the 
final model with six latent variables is supported. Ransomware attack effect and repetition influence 
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
13
inertia, trust and information privacy. The last three variables influence user switching resistance. It is 
useful to identify which aspects of the RA attack have the most significant effect on the e-commerce 
status quo bias.
There are three practical implications. Firstly, these RW attacks rely on the disruption and fear they 
cause to achieve their goal of extracting a ransom. By better understanding the impact on the user, it 
may be possible to have a new strategy to reduce the effectiveness of the attack. Secondly, all online 
organizations that are potential victims can develop a number of processes to handle these attacks, 
going beyond the technical dimension. By better understanding the impact on the user, processes can 
be created to manage such disasters. Additionally, organizations such as online vendors can develop 
a buffer of goodwill that can absorb the negative impact on the user from an attack and stop them 
reaching the tipping point where they decide to switch system. Lastly, institutions can understand the 
mechanisms of a RW attack better and improve their approach both in preventing and resolving them.
Future research can evaluate the validity of the model with new RW attacks and explore 
possibilities of extending it to cover other security breaches or other events that have a large impact 
on the user.
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
14
REFERENCES
Aliakbarlou, S., Wilkinson, S., Costello, S. B., & Jang, H. (2017). Client values within post-disaster reconstruction 
contracting services. Disaster Prevention and Management: An International Journal, 26(3), 348–360. 
doi:10.1108/DPM-03-2017-0058
Ba, S., & Pavlou, P. (2002). Evidence of the Effect of Trust Building Technology in Electronic Markets: Price 
Premiums and Buyer Behavior. Management Information Systems Quarterly, 26(3), 243–268. doi:10.2307/4132332
Carter, M., Wright, R., Thatcher, J. B., & Klein, R. (2014). Understanding online customers’ ties to merchants: 
The moderating influence of trust on the relationship between switching costs and e-loyalty. European Journal 
of Information Systems, 23(2), 185–204. doi:10.1057/ejis.2012.55
Chang, K. C., & Seow, Y. M. (2019). Protective measures and security policy non-compliance intention: IT 
vision conflict as a moderator. Journal of Organizational and End User Computing, 31(1), 1–21. doi:10.4018/
JOEUC.2019010101
Chatterjee, D. (2019). Should executives go to jail over cybersecurity breaches? Journal of Organizational 
Computing and Electronic Commerce, 29(1), 1–3. doi:10.1080/10919392.2019.1568713
Chen, L., Zarifis, A., & Kroenung, J. (2017). The role of trust in personal information disclosure on health-related 
websites. European Conference on Information Systems Proceedings, 771–786.
Chenoweth, T., Gattiker, T., & Corral, K. (2019). Adaptive and Maladaptive Coping with an It Threat. Information 
Systems Management, 36(1), 24–39. doi:10.1080/10580530.2018.1553647
Chin, W. W. (1998). The partial least squares approach to structural equation modelling. In G. A. Marcoulides 
(Ed.), In Modern Methods for Business Research (pp. 295–336). Lawrence Erlbaum Associates.
Conger, S. (2008). Personal Information Privacy: A Multi-Party Endeavor. Journal of Electronic Commerce in 
Organizations, 7(1), 71–82. doi:10.4018/jeco.2009010106
Erridge, T. (2016). Ransomware: Threat and response. Network Security, 2016(10), 17–19. doi:10.1016/S1353-
4858(16)30097-6
FRPT Research. (2016). Ransomware Attacks: India Expects Microsoft to Offer Windows 10 Upgrade at Throw-
Away Prices. FRPT Software Industry Snapshot, (August), 51–52. doi:10.1007/1-4020-7985-0_7
Gefen, D. (2003). TAM or Just Plain Habit : A Look at Experienced Online Shoppers. International Journal of 
End User Computing, 15(3), 1–3. doi:10.4018/joeuc.2003070101
Ghazali, E., Nguyen, B., Mutum, D. S., & Mohd-Any, A. A. (2016). Constructing online switching barriers: 
examining the effects of switching costs and alternative attractiveness on e-store loyalty in online pure-play 
retailers. Electronic Markets - The International Journal on Networked Business, 26, 157–171. 10.1007/s12525-
016-0218-1
Hair, J., Hult, T., Ringle, C., & Sarstedt, M. (2014). A Primer on Partial Least Squares Structural Equation 
Modeling (PLS-SEM). SAGE Publications (Vol. 46). 10.1016/j.lrp.2013.01.002
Hui, K. L., Teo, H. H., & Sang-Yong, T. L. (2007). The value of privacy assurance: An exploratory field 
experiment. Management Information Systems Quarterly, 31(1), 19–33. doi:10.2307/25148779
Jiang, J. J., Klein, G., & Carr, C. L. (2002). Measuring Information System Service Quality: SERVQUAL from 
the Other Side. Management Information Systems Quarterly, 26(2), 145. doi:10.2307/4132324
Kharraz, A., Robertson, W., Balzarotti, D., Bilge, L., & Kirda, E. (2015). Cutting the gordian knot: A look 
under the hood of ransomware attacks. Lecture Notes in Computer Science (Including Subseries Lecture Notes 
in Artificial Intelligence and Lecture Notes in Bioinformatics), 9148, 3–24. doi:10.1007/978-3-319-20550-2_1
Kshetri, N., & Voas, J. (2017). Do Crypto-Currencies Fuel Ransomware? IT Professional, 19(5), 11–15. 
doi:10.1109/MITP.2017.3680961
Liang, H., Xue, Y., Laosethakul, K., & Lloyd, S. J. (2005). Information Systems and Healthcare-I: Trust, 
Uncertainty, and Online Prescription Filling. Cais, 15, 41–60. Retrieved from http://ezproxy.net.ucf.edu/
login?url=http://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=17557124&site=ehost-live
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
15
Limayem, M., Hirt, S., & Cheung, C. M. K. (2007). How Habit Limits the Predictive Power of Intention: 
The Case of Information Systems Continuance. Management Information Systems Quarterly, 31(4), 705. 
doi:10.2307/25148817
Mamedov, O., Sinitsyn, F., & Ivanov, A. (2017). Bad Rabbit ransomware. Retrieved from https://securelist.com/
bad-rabbit-ransomware/82851/
Mansfield-Devine, S. (2020). Travelex knocked offline by malware. Computer Fraud & Security, 2020(1), 3. 
doi:10.1016/S1361-3723(20)30003-8
McKnight, H., Carter, M., Thatcher, J. B., & Clay, P. (2011). Trust in a specific technology: An investigation of 
its components and measures. ACM Transactions on Management Information Systems, 2(2), 1–25. Advance 
online publication. doi:10.1145/1985347.1985353
McKnight, H., & Chervany, N. L. (2002). What Trust Means in E-Commerce Customer Relationships: An 
Interdisciplinary Conceptual Typology. International Journal of Electronic Commerce, 6(2), 35–59. doi:10.10
80/10864415.2001.11044235
McKnight, H., Choudhury, V., & Kacmar, C. (2002). Developing and Validating Trust Measures for e-Commerce: 
An Integrative Typology. Information Systems Research, 13(3), 334–359. doi:10.1287/isre.13.3.334.81
Mercaldo, F., Nardone, V., & Santone, A. (2016). Ransomware inside out. In Proceedings - 2016 11th International 
Conference on Availability, Reliability and Security, ARES 2016 (pp. 628–637). doi:10.1109/ARES.2016.35
Online Trust Alliance. (2019). Cyber Incident & Breach Trends report. Author.
Polites, G. L., & Karahanna, E. (2012). Shackled to the Status Quo: The Inhibiting Effects of Incumbent System 
Habit, Switching Costs, and Inertia on New System Acceptance. Management Information Systems Quarterly, 
36(1), 21–42. doi:10.2307/41410404
Ramsey, D. (2017). Google, UC San Diego and NYU Estimate $ 25 Million in Ransomware Payouts. Retrieved 
November 23, 2017, from http://ucsdnews.ucsd.edu/pressrelease/google_uc_san_diego_and_nyu_estimate_25_
million_in_ransomware_payouts
Simoiu, C., Symantec, C. G., Bonneau, J., & Goel, S. (2019). “I was told to buy a software or lose my computer. 
I ignored it”: A study of ransomware. USENIX Symposium on Usable Privacy and Security (SOUPS) 2019. 
Retrieved from https://www.usenix.org/conference/soups2019/presentation/simoiu%0Ahttps://5harad.com/
papers/ransomware.pdf
SonicWall. (2019). Cyber Threat Report. SonicWall. Retrieved from https://www.sonicwall.com/lp/2019-cyber-
threat-report-lp/
Venkatesh, V., Morris, M. G., Davis, G. B., & Davis, F. D. (2003). User Acceptance of Information Technology: 
Toward a unified view. Management Information Systems Quarterly, 27(3), 425–478. doi:10.2307/30036540
Xu, H., Dinev, T., Smith, H. J., & Hart, P. (2008). Examining the Formation of Individual’s Privacy Concerns: 
Toward an Integrative View. In International Conference on Information Systems (pp. 1–16). Academic Press.
Yaqoob, I., Ahmed, E., Rehman, M. H., Ahmed, A. I. A., Al-garadi, M. A., Imran, M., & Guizani, M. (2017). 
The rise of ransomware and emerging security challenges in the Internet of Things. Computer Networks, 0, 
1–15. doi:10.1016/j.comnet.2017.09.003
Young, A. L., & Yung, M. (2017). Cryptovirology: The Birth, Neglect, and Explosion of Ransomware. 
Communications of the ACM, 60(7), 24–26. doi:10.1145/3097347
Zeithaml, V. A., Berry, L. L., & Parasuraman, A. (1996). The Behavioral Consequences of Service Quality. 
Journal of Marketing, 60(2), 31–46. doi:10.1177/002224299606000203
Zimba, A., Wang, Z., & Mulenga, M. (2019). Cryptojacking injection: A paradigm shift to cryptocurrency-based 
web-centric internet attacks. Journal of Organizational Computing and Electronic Commerce, 29(1), 40–59. do
i:10.1080/10919392.2019.1552747
International Journal of Information Systems in the Service Sector
Volume 14 • Issue 1
16
Alex Zarifis is passionate about researching, teaching, and practicing management in its many facets. He has 
taught in higher education for over ten years at universities including the University of Manchester, University of 
Liverpool, and the University of Mannheim. His research is in the areas of information systems and management. 
Dr Alex first degree is a BSc in Management with Information Systems from the University of Leeds. His second 
an MSc in Business Information Technology and a PhD in Business Administration are both from the University 
of Manchester. The University of Manchester PhD in Business Administration is ranked 1st in the world according 
to the Financial Times.
Xusen Cheng is a Full Professor in the School of Information at Renmin University of China in Beijing. He obtained 
his PhD degree from the University of Manchester, UK. His research is in the areas of information systems and 
management particularly focusing on online collaboration, global teams, the sharing economy, e-commerce, and 
e-learning.
Uchitha Jayawickrama is a Lecturer in Information Systems (which is equivalent to Assistant Professor) at the 
Information Management Group, School of Business and Economics, Loughborough University, UK. He has 
research, teaching and industry experience in the field of information systems. He is a Senior Fellow of Higher 
Education Academy (SFHEA), UK. Before joining Loughborough University, he was a Senior Lecturer and a 
Course Leader at Staffordshire University, UK. Dr Jayawickrama has published his research in various renowned 
conferences, books and journals (20+ peer-reviewed outputs) and has won 2 best paper awards in 2 international 
conferences. He is a reviewer for several journals and international conferences. He has editorial experience in 
various journals.
Simone Corsi joined Loughborough University from the University of Manchester, where he managed the Manchester 
China Institute and was Associate Member at the Manchester Institute for Innovation Research. Simone conducts 
research in the field of innovation studies. He has a research background in R&D and Innovation Management and 
has been looking into global innovation and reverse innovation dynamics, with a focus on China. More recently he 
has developed an interest in international R&D alliances and university-industry collaboration. Prior to joining the 
University of Manchester, Simone was Research Fellow at the Lancaster University Management School, where 
he was also Programme Manager for the Lancaster China Catalyst Programme, a Lancaster University project 
which aimed at creating and supporting R&D partnerships between UK and Chinese organisations.
","nanExisting literature has examined ransomware attacks, inertia in information systems, and the concept of e-loyalty. However, the combined effect of repeated, extended ransomware attacks on a user's e-commerce status quo has not been sufficiently studied. This research aims to address this gap by evaluating the impact of these attacks on trust, inertia, and personal information disclosure."
"This paper proposes a hierarchical network architecture for cell-free massive MIMO, integrating co-located and distributed antennas. A central base station (CBS), equipped with an antenna array, positions itself near the coverage area's center, complemented by distributed access points spanning the periphery. The proposed architecture outperforms conventional cell-free networks, demonstrating superior sum throughput while maintaining a comparable worst-case per-user spectral efficiency. Moreover, the implementation cost associated with the fronthaul network is substantially diminished.","Cell-free massive multi-input multi-output (MIMO) has attracted much attention due to its potential in shaping the landscape of sixth-generation (6G) wireless systems. Unlike conventional cellular networks with cells and cell boundaries, CF massive MIMO has no cells or boundaries. Instead, multiple distributed access points (APs) serve relatively fewer users simultaneously over the same time-frequency resource. The CF architecture perfectly matches 6G private or campus networks in isolated coverage areas like stadiums, shopping malls, airports, exhibition halls, islands, or small towns. It ensures uniform quality of service for all users, addressing the issue of under-served areas commonly encountered at the edges of conventional cellular networks. Subsequently, S. Buzzi et al. proposed a user-centric (UC) approach for CF massive MIMO, where each AP serves a subset of users close to it. This UC approach effectively lowers the amount of fronthaul overhead while achieving comparable performance.","To overcome these challenges, this research proposes hierarchical cell-free (HCF) massive MIMO, an architecture that seamlessly integrates co-located and distributed antennas. A central base station (CBS), equipped with an antenna array, is strategically positioned at the coverage area's heart, complemented by distributed APs spanning the periphery. The users are divided into two categories: near users (NUs) and far users (FUs). NUs are connected to the CBS, while each FU is served by a set of neighboring APs. This arrangement offers several advantages:
1. Reduced implementation cost for the fronthaul network
2. Lower signaling overhead in terms of the number of complex-valued symbols exchanged in the fronthaul network
3. Improved spectral efficiency and sum throughput
4. Comparable worst-case per-user rate measured by 5%-likely per-user spectral efficiency (SE)","Numerical evaluations demonstrate the performance of the proposed HCF architecture compared to conventional cell-free (CF) and user-centric (UC) approaches. The simulations consider a representative scenario with 256 antennas serving 16 users within a circular area of 1km radius. The HCF system is configured with 128 antennas allocated to the CBS and 128 single-antenna APs distributed along an annulus between 1km and 100m, 250m, or 500m radii. Performance metrics include per-user SE, sum throughput, and fronthaul overhead.
The results demonstrate that HCF substantially outperforms CF and UC in sum throughput while maintaining comparable worst-case per-user SE. Additionally, HCF reduces the implementation cost associated with the fronthaul network by approximately 50% compared to CF and has lower fronthaul overhead than UC.","The proposed hierarchical cell-free massive MIMO architecture seamlessly integrating co-located and distributed antennas offers several advantages. It remarkably improves sum throughput while maintaining comparable worst-case per-user spectral efficiency, substantially diminishes the implementation cost of the fronthaul network, and reduces signaling overhead in terms of the number of complex-valued symbols exchanged in the fronthaul network. The numerical evaluations justify the superior performance of HCF massive MIMO compared to conventional cell-free and user-centric approaches.",Hierarchical Cell-Free Massive MIMO for High Capacity with Simple Implementation,"Wei Jiang, Hans D. Schotten","Hierarchical Cell-Free Massive MIMO for High
Capacity with Simple Implementation
Wei Jiang∗ and Hans D. Schotten†
∗German Research Center for Artificial Intelligence (DFKI)
Trippstadter Street 122, Kaiserslautern, 67663 Germany
†Rheinland-Pf¨alzische Technische Universit¨at (RPTU) Kaiserslautern-Landau
Building 11, Paul-Ehrlich Street, Kaiserslautern, 67663 Germany
Abstract—Cell-free massive multi-input multi-output (MIMO)
has recently gained much attention for its potential in shaping the
landscape of sixth-generation (6G) wireless systems. This paper
proposes a hierarchical network architecture tailored for cell-free
massive MIMO, seamlessly integrating co-located and distributed
antennas. A central base station (CBS), equipped with an antenna
array, positions itself near the center of the coverage area, com-
plemented by distributed access points spanning the periphery.
The proposed architecture remarkably outperforms conventional
cell-free networks, demonstrating superior sum throughput while
maintaining a comparable worst-case per-user spectral efficiency.
Meanwhile, the implementation cost associated with the fronthaul
network is substantially diminished.
I. INTRODUCTION
Cell-free (CF) massive multi-input multi-output (MIMO) [1]
has recently garnered much attention in both academia and
industry due to its high potential for sixth-generation (6G)
systems [2]. There are no cells or cell boundaries. Instead,
a multitude of distributed access points (APs) simultaneously
serve a relatively smaller user population over the same time-
frequency resource [3]. It perfectly matches 6G private or
campus networks, with relatively isolated coverage areas in
scenarios like factories, stadiums, shopping malls, airports,
railway stations, exhibition halls, islands, or small towns. The
CF architecture ensures uniform quality of service for all
users, effectively addressing the issue of under-served areas
commonly encountered at the edges of conventional cellular
networks [4]. Later, S. Buzzi et al. proposed a user-centric
(UC) approach for CF massive MIMO [5], [6], where each
AP only serves a subset of users that are close to it. UC
can effectively lower the amount of fronthaul overhead while
achieving comparable performance.
Despite its considerable potential, CF still faces a lot of
challenges, including the following two major concerns. Firstly,
connecting a large number of distributed APs and a central
processing unit (CPU) through a fronthaul network is costly
[7]. Deploying a traditional wireless network is already arduous
due to the complexities of acquiring and maintaining sites for
base stations. In the CF architecture, the challenge is intensified
as hundreds of suitable sites must be identified to accommo-
date wireless AP installations. The deployment of a massive-
scale fiber-cable network to interconnect these APs further
exacerbates the difficulty. In addition to the implementation
cost, another concern revolves around uniform service quality,
which is achieved at the price of system capacity degradation.
Essentially, while the worst-case user rate is improved, the
overall performance of other users is compromised through
averaging. Unlike the voice-oriented cellular networks like
GSM in the 1990s, which demand uniform quality, the current
4G/5G networks, as well as the upcoming 6G systems, need
to offer differentiated service quality tailored to the specific
demands of diverse user devices and applications, rather than
settling for averaged service [2].
In this context, this paper proposes hierarchical cell-free
(HCF) massive MIMO, an architecture that seamlessly in-
tegrates co-located and distributed antennas. A central base
station (CBS), equipped with an antenna array, strategically
positions itself at the heart of the coverage area, complemented
by distributed APs spanning the periphery. The users are
divided into two categories: near users (NUs) and far users
(FUs). The NUs are connected to the CBS while each FU is
served by a set of neighboring APs. In this way, the proposed
HCF massive MIMO can offer the following advantages:
• The implementation cost associated with the fronthaul
network is substantially diminished because the service
antennas located at the CBS do not need site acquisition
and fiber connections. The CBS is dual-functional to
replace the CPU in the conventional CF architecture.
• Like the UC approach, the signaling overhead in terms of
the number of complex-valued symbols exchanged in the
fronthaul network is reduced since only a portion of APs
close to each FU participate in communications.
• The proposed architecture demonstrates superior sum
throughput since the CBS offers reinforced service quality
to the NUs. From the perspective of a user, its average data
rate is improved accordingly.
• HCF maintains a comparable worst-case per-user rate
measured by 5%-likely per-user spectral efficiency (SE).
II. SYSTEM MODEL
In conventional cell-free massive MIMO, M distributed APs
serve a few K ≪ M user equipment (UEs) over an intended
coverage area, as shown in the left one of Fig.1. Assume APs
and UEs are equipped with a single antenna for simple analysis.
A CPU coordinates all APs through a fronthaul network. To
avoid the prohibitive overhead of downlink pilots, which scales
arXiv:2401.11236v1  [cs.IT]  20 Jan 2024
Cell-Free massive MIMO
Hierarchical CF massive MIMO
Fig. 1. An illustrative comparison between the proposed hierarchical cell-free massive MIMO (right) and the conventional cell-free architecture (left).
with the number of service antennas, time-division duplexing
(TDD) is employed in massive MIMO to separate the downlink
and uplink transmission. In the downlink, all APs transmit
data symbols over the same time-frequency resource, while all
UEs simultaneously send their signals in the uplink at another
instant.
In this paper, we propose a hierarchical architecture for
CF massive MIMO, as shown in the right side of Fig.1,
where a base station (BS) equipped with an array of Nb
antennas is located near the center of the coverage area.
To differentiate the conventional BS, we name it central BS
(CBS). It also functions as the CPU of the remaining M − Nb
distributed APs that are responsible for covering the edge area
around the center. In this way, the cost of fronthauling is
reduced since only a portion of service antennas is needed
to be connected. The channel coefficient between antenna m,
∀m = 1, . . . , M − Nb and UE k, ∀k = 1, . . . , K is modeled
as a circularly symmetric complex Gaussian random variable,
i.e., gmk ∈ CN(0, βmk), where βmk stands for large-scale
fading including path loss and shadowing. The Nb × 1 channel
signature between the CBS and UE k, ∀k = 1, . . . , K is
denoted by hk = [h1k, . . . , hNbk]T ∈ CN(0, β0
kINb), where
β0
k stands for the large-scale fading between the CBS and
user k. Since large-scale fading is frequency-independent and
varies slowly, the system measures it on a long-term basis and
distributes it periodically. Thus, it is reasonable to assume that
all nodes perfectly know this information.
In our HCF approach, the CBS first labels each user as a
near user or a far user, according to a certain criterion, e.g.,
their distances to the CBS or their receiving signal strengths.
For instance, ordering the indices of the APs in terms of their
large-scale fading in descending order, and then selecting some
’good’ users to form a set of NUs K0 = {k : β0
k ⩾ ¯β0}, where
¯β0 is a pre-defined threshold for the CBS. The data symbols
intended for the NUs are modulated and transmitted by the CBS
in the downlink. In the uplink, all symbols from the NUs are
detected while treating the FUs’ signals simply as interference.
On the other hand, the CBS determines a group of closest APs
Mk = {m : βmk ⩾ ¯βk} to serve an FU k /∈ K0, where ¯βk
denotes the threshold for user k. From the perspective of a
typical AP m, it maintains a list of associated users denoted
by Km = {k : m ∈ Mk}. In the downlink, the CBS only needs
to deliver a portion of data symbols to a certain AP since an
AP serves its closest users. This further lowers the overhead of
fronthauling in comparison with the CF approach where each
AP serves all users. In the uplink, each AP only processes the
signals from the associated FUs k ∈ Km.
III. THE COMMUNICATION PROCESS
Under the assumption of block fading, each coherent interval
is divided into three phases: uplink training, uplink data trans-
mission, and downlink data transmission. We ignore the time
index of signals for simple analysis hereinafter.
A. Uplink Training
During uplink training, UEs transmit orthogonal pilot se-
quences to acquire instantaneous channel state information
(CSI). Unlike multi-cell systems, pilot contamination [8] is
avoidable by increasing the length of pilot sequences. Hence,
we can neglect it for simplicity. A lot of literature like [1],
[3], [6], [9], [10] have already presented uplink training and
therefore this paper does not repeat the details. Conducting
minimum mean-square error (MMSE) estimation, AP m gets
its local estimates ˆgmk ∈ CN(0, αmk), ∀k = 1, . . . , K with
αmk =
puβ2
mk
puβmk+σ2
n , where pu and σ2
n denote the UE power
constraint and the variance of additive noise, which is inter-
changeably denoted by n or w hereinafter. This estimation suf-
fers from an error of ˜gmk = gmk − ˆgmk ∈ CN(0, βmk −αmk).
Likewise, the CBS knows ˆhk ∈ CN(0, α0
kINb), ∀k = 1, . . . , K
with α0
k =
pu(β0
k)2
puβ0
k+σ2n and the estimation error ˜hk = hk − ˆhk ∈
CN(0, (β0
k − α0
k)INb),
B. Uplink Data Transmission
Because the UEs do not conduct channel estimation, data
symbols are transmitted without channel-dependent phase off-
set. All UEs simultaneously send their signals towards the APs
and CBS, where UE k sends xk with a power coefficient
0 ⩽ ηk ⩽ 1. The covariance matrix of the transmit vector
x = [x1, . . . , xK]T satisfies E[xxH] = IK. The CBS observes
yb = √pu
K
X
k=1
√ηkhkxk + nb,
where the receiver noise nb ∈ CN(0, σ2
nINb). Aligning with
[1], we apply matched filtering (MF), a.k.a. maximum-ratio
combining, as the linear detector. It aims to amplify the
desired signal as much as possible while disregarding inter-user
interference (IUI). For each NU k ∈ K0, the CBS multiplies
yb with ˆhH
k to recover the transmitted symbol xk, yielding a
soft estimate of
ˇxk = ˆhH
k
√pu
K
X
k=1
hk
√ηkxk + nb

= √puηk∥ˆhk∥2xk
|
{z
}
S0: desired signal
+
√puηkˆhH
k ˜hkxk
|
{z
}
I1: channel estimation error (CEE)
+ √pu
K
X
j=1,j̸=k
ˆhH
k hj√ηjxj
|
{z
}
I2: IUI
+ ˆhH
k nb
| {z }
I3: noise
,
(1)
applying hk = ˜hk + ˆhk.
Meanwhile, a typical AP m observes
ym = √pu
K
X
k=1
√ηkgmkxk + nm.
(2)
Similar to the UC approach [5], the symbol xk from the FU k /∈
K0 is merely processed on its associated APs m ∈ Mk. That
is to say, the mth AP, thus, form the statistics ¯ymk = ˆg∗
mkym
for each k ∈ Km and sends to the CBS. To detect xk, the CBS
generates a soft estimate ˇxk = PM
m=1 ¯ymk = P
m∈Mk ˆg∗
mkym.
Utilizing (2), we have
ˇxk =
X
m∈Mk
ˆg∗
mk

√pu
K
X
j=1
√ηjgmjxj + nm


= √puηk
X
m∈Mk
∥ˆgmk∥2xk + √puηk
X
m∈Mk
ˆg∗
mk˜gmkxk
+ √pu
X
m∈Mk
ˆg∗
mk
K
X
j=1,j̸=k
√ηjgmjxj +
X
m∈Mk
ˆg∗
mknm, (3)
with gmk = ˆgmk + ˜gmk.
C. Downlink Data Transmission
In the downlink, aligning with [1], conjugate beamforming
(CBF) is applied to spatially multiplex the information-bearing
symbols, i.e., u = [u1, . . . , uK]T , where E[uuH] = IK. The
CBS delivers a subset of symbols {uk : k ∈ Km} to the mth
AP, resulting in lower fronthaul overhead than the CF approach
that broadcasts all symbols {u1, . . . , uK} to every AP. Like the
UC approach, AP m transmits
sm = √pd
X
k∈Km
√ηmkˆg∗
mkuk,
(4)
where ηmk represents the power coefficient for the kth user at
AP m, given per-antenna power constraint pd. Meanwhile, the
CBS spatially multiplexes the information symbols intended for
all NUs {k : k ∈ K0}. The transmitted signal at CBS antenna
nb equals
dnb = √pd
X
k∈K0
√ηnbkˆh∗
nbkuk,
(5)
where ηnbkb represents the power coefficient for the kth user
at CBS antenna nb. As a consequence, a generic user k has the
observation of
yk =
Nb
X
nb=1
hnbkdnb +
M−Nb
X
m=1
gmksm + wk
(6)
= √pd
Nb
X
nb=1
hnbk
X
j∈K0
√ηnbjˆh∗
nbjuj
+ √pd
M−Nb
X
m=1
gmk
X
j∈Km
√ηmjˆg∗
mjuj + wk.
IV. PERFORMANCE ANALYSIS
This section analyzes the performance of the proposed HCF
massive MIMO in terms of spectral efficiency. Per-user and
sum SE in both downlink and uplink are provided.
A. Uplink Spectral Efficiency
Distinct architectures of massive MIMO raise different levels
of CSI availability. To be specific, the CBS has full CSI
knowledge of ˆhk,∀k as it receives the uplink pilots and conducts
channel estimation. We derive the achievable SE for an NU
k ∈ K0 as Rul
nu,k = log(1 + γul
nu,k), where the effective signal-
to-interference-plus-noise ratio (SINR) equals
γul
nu,k =
ηkNbα0
k
PK
j=1 ηjβ0
j − ηkα0
k + σ2
n
pu
.
(7)
Proof: The terms S0, I1, I2, and I3 in (1) are mutually
uncorrelated. According to [11], the worst-case noise for mu-
tual information is Gaussian additive noise with the variance
equalling to the variance of I1 + I2 + I3. Thus, the achievable
rate is lower bounded by R = log(1 + γ), where
γ =
E

|S0|2
E [|I1 + I2 + I3|2] =
E

|S0|2
E [|I1|2] + E [|I2|2] + E [|I3|2]
(8)
with
E

|S0|2
= puηk
yk = √pd
Nb
X
nb=1
√ηnbkE
h
∥ˆhnbk∥2i
uk
|
{z
}
desired signal
+ √pd
Nb
X
nb=1
√ηnbk

∥ˆhnbk∥2 − E
h
∥ˆhnbk∥2i
uk
|
{z
}
channel uncertainty error
+ √pd
Nb
X
nb=1
√ηnbk˜hnbkˆh∗
nbkuk
|
{z
}
channel estimation error
+ √pd
Nb
X
nb=1
hnbk
X
j̸=k,j∈K0
√ηnbjˆh∗
nbjuj
|
{z
}
IUI from other NUs
+ √pd
M−Nb
X
m=1
gmk
X
j∈Km
√ηmjˆg∗
mjuj
|
{z
}
IUI from F Us
+wk
(19)
γdl
nu,k =
PNb
nb=1
√ηnbkα0
k
2
PNb
nb=1 β0
k
P
j∈K0 ηnbjα0
j + PM−Nb
m=1
βmk
P
j∈Km ηmjαmj + σ2n/pd
.
(20)
yk = √pd
M−Nb
X
m=1
√ηmkE

∥gmk∥2
|
{z
}
desired signal
+ √pd
M−Nb
X
m=1
√ηmk
B. Downlink Spectral Efficiency
In the downlink, the kth user knows channel statistics αmk
or α0
k rather than channel estimate ˆgmk or ˆhk since there
are no downlink pilots and channel estimation. As mentioned
above, channel uncertainty error causes a loss since the received
signals can only be detected using channel statistics. For an
NU k ∈ K0, we need to further decompose (6) into (19)
accordingly. Inter-user interference in this case consists of
interference from other NUs and interference from the FUs.
Due to the page limit, the detailed derivations of downlink
SE are skipped. Using similar manipulations as the derivation
of uplink SE, we obtain the effective SINR as (20). On the
other hand, (6) is rewritten to (21) from the FUs’ perspective.
Accordingly, we obtain the effective SINR of an FU k /∈ K0 as
(22). The downlink sum SE of the HCF massive MIMO system
is computed by
Cdl =
X
k∈K0
log(1 + γdl
nu,k) +
X
k/∈K0
log(1 + γdl
fu,k).
(20)
  500
  1000
30
210
60
240
90
270
120
300
150
330
180
0
AP
UE
  500
  1000
30
210
60
240
90
270
120
300
150
330
180
0
Fig. 2. The simulation scenarios of CF in left and HCF in right. It shows the
snapshot for a simulation epoch, where the locations of APs and UEs randomly
vary in different epochs for ergodic evaluation.
V. NUMERICAL RESULTS
The performance of the proposed HCF is numerically com-
pared with that of CF and UC in terms of per-user SE, sum
throughput, and fronthaul overhead. In our simulations, we
establish a representative scenario where a total of M = 256
antennas serve K = 16 users within a circular area. In con-
ventional CF/UC systems, 256 APs and 16 users are randomly
distributed within a 1km radius, as illustrated in the left diagram
of Fig.2. To implement the HCF architecture, we allocate half
of the antennas to the CBS, i.e., Nb = 128, aiming to minimize
the scale of fronthaul networks as much as possible. This means
that the HCF system in our simulations incurs only 50% of
the fronthauling implementation cost. Furthermore, 128 single-
antenna APs are distributed equally along the annulus with radii
between R = 1km and r, which takes three values — 100m,
250m, and 500m. The users falling into the inner circle are
treated as NUs while the others are FUs. Varying r allows
us to observe the behavior of distant users at the cell edge
in a traditional co-located antenna system. At each simulation
epoch, the locations of APs and users randomly change, and a
total of 105 epochs are simulated for the ergodic performance.
Large-scale fading β = 10
L+X
10 , where the shadowing X ∼
N(0, σ2
sd) with standard derivation σsd = 8dB, and the path
loss is calculated by the COST-Hata model [1]:
L =





−L0 − 35 log10(d),
d > d1
−L0 − 10 log10(d1.5
1 d2),
d0 < d ≤ d1
−L0 − 10 log10(d1.5
1 d2
0),
d ≤ d0
,
(21)
where d denotes the distance between a user and the CBS or
an AP, the three-slope breakpoints take values d0 = 10m and
d1 = 50m while L0 = 140.72dB in terms of
L0 = 46.3+33.9 log10 (fc) − 13.82 log10 (hAP )
(22)
− [1.1 log10(fc) − 0.7] hUE + 1.56 log10 (fc) − 0.8
with carrier frequency fc = 1.9GHz, the height of AP antenna
hAP = 15m, and the height of UE hUE = 1.65m. Per-
antenna and UE power constraints are set to pd = 200mW
and pu = 100mW, respectively. The white noise power density
equals −174dBm/Hz with a noise figure of 9dB, and the signal
bandwidth is set to 5MHz. The uplink transmission is carried
out in a distributed manner, it is reasonable that each UE simply
use a full-power strategy ηk = 1, ∀k without global power
control.
Fig.3a and Fig.3b compare the cumulative distribution func-
tions (CDFs) of per-user SE and sum throughput, respectively,
in the uplink data transmission. We implement user selection
in both UC and HCF approaches on a per-user basis. That is,
the threshold of user k is calculated by ¯βk =
1
M
PM
m=1 βmk
and then build a group of closest APs Mk = {m : βmk ⩾ ¯βk}.
During the simulations, our observation is that the system
performance does not affect too much about the exact values of
¯βk. The key point is to exclude the users with the worst channel
conditions, which causes performance degradation. In contrast,
selecting or excluding a user with a moderate channel condition
does not affect the performance. Under this user selection
method, UC achieves identical per-user and sum SE as CF,
and therefore their curves are completely overlapped in both
figures. But UC has the advantage of reducing the fronthaul
overhead, as shown in Fig.3c, resulting in approximately half
of the data amount relative to CF.
When the inner circle is big, namely r = 500m, some
users far away from the CBS suffer from worse SE. To be
specific, the 5%-likely per-user SE for HCF is close to zero,
in comparison with 0.74bps/Hz of CF and UC. However,
HCF outperforms remarkably CF/UC since some users close
to the CBS enjoyed the strengthened services, resulting in
an average sum throughput of 30.6bps/Hz, which is better
than 27.3bps/Hz of CF/UC. If we shrink the inner circle
to r = 250m, as expected, the 5%-likely per-user SE can
be improved to 0.14bps/Hz, while the average sum rate is
increased to 35.1bps/Hz accordingly. Further reducing the
inner circle to r = 100m, it is amazing that the 5%-likely
per-user SE of HCF even surpasses that of CF/UC, reaching
0.84bps/Hz. By far, we can conclude that the HCF architecture
0
1
2
3
4
5
6
7
Per-User SE [bps/Hz]
0
0.2
0.4
0.6
0.8
1
CDF
CF
UC
HCF-500m
HCF-250m
HCF-100m
(a)
20
25
30
35
40
45
50
Sum Rate [bps/Hz]
0
0.2
0.4
0.6
0.8
1
CDF
CF
UC
HCF-500m
HCF-250m
HCF-100m
(b)
CF
UC
HCF
0
500
1000
1500
2000
2500
3000
3500
4000
4500
Number of Symbols
Fronthaul Overhead
(c)
Fig. 3. Performance comparison of CF/UC and HCF massive MIMO systems: (a) the CDF curves in terms of per-user SE; (b) the CDF curves of sum SE; and
(c) the required number of complex-valued symbols delivered over the fronthaul network at each symbol period.
substantially improves the sum rate and per-user average rate,
while it remains a comparable worst-case per-user rate if the
network is properly configured in terms of r. Last but not
least, we should keep in mind that the SE performance gain
of HCF is achieved under a smaller scale fronthaul network,
where only a half number of distributed APs are applied.
Accordingly, approximately 50% fronthaul overhead is further
reduced compared to UC.
VI. CONCLUSION
In this paper, we proposed a hierarchical network architecture
tailored for cell-free massive MIMO, seamlessly integrating
co-located and distributed antennas. A central base station
equipped with an antenna array strategically positions itself at
the heart of the coverage area, complemented by distributed
access points spanning the periphery. Numerical evaluation
justified that the proposed architecture remarkably outperforms
conventional cell-free networks, demonstrating superior sum
rates while maintaining comparable worst-case per-user rates.
Meanwhile, the implementation cost associated with the fron-
thaul network is substantially diminished, adding a layer of
economic viability to its technological advancements.
REFERENCES
[1] H. Q. Ngo et al., “Cell-free massive MIMO versus small cells,” IEEE
Trans. Wireless Commun., vol. 16, no. 3, pp. 1834–1850, Mar. 2017.
[2] W. Jiang et al., “The road towards 6G: A comprehensive survey,” IEEE
Open J. Commun. Society, vol. 2, pp. 334–366, Feb. 2021.
[3] E. Nayebi et al., “Precoding and power optimization in cell-free massive
MIMO systems,” IEEE Trans. Wireless Commun., vol. 16, no. 7, pp.
4445–4459, Jul. 2017.
[4] W. Jiang and H. D. Schotten, “Cell-edge performance booster in 6G:
Cell-free massive MIMO vs. reconfigurable intelligent surface,” in Proc.
IEEE Eur. Conf. on Netw. and Commun. (EUCNC), Gothenburg, Sweden,
Jun. 2023, pp. 1–6.
[5] S. Buzzi and C. D’Andrea, “Cell-free massive MIMO: User-centric
approach,” IEEE Wireless Commun. Lett., vol. 6, no. 6, pp. 706–709,
Dec. 2017.
[6] S. Buzzi et al., “User-centric 5G cellular networks: Resource allocation
and comparison with the cell-free massive MIMO approach,” IEEE Trans.
Wireless Commun., vol. 19, no. 2, pp. 1250–1264, Feb. 2020.
[7] H. Masoumi and M. J. Emadi, “Performance analysis of cell-free massive
MIMO system with limited fronthaul capacity and hardware impair-
ments,” IEEE Trans. Wireless Commun., vol. 19, no. 2, pp. 1038–1052,
Feb. 2020.
[8] W. Zeng et al., “Pilot assignment for cell-free massive MIMO systems
using a weighted graphic framework,” IEEE Trans. Veh. Technol., pp.
6190 – 6194, Jun. 2021.
[9] W. Jiang and H. D. Schotten, “Cell-free massive MIMO-OFDM trans-
mission over frequency-selective fading channels,” IEEE Commun. Lett.,
vol. 25, no. 8, pp. 2718 – 2722, Aug. 2021.
[10] W. Jiang and H. Schotten, “Impact of channel aging on zero-forcing
precoding in cell-free massive MIMO systems,” IEEE Commun. Lett.,
vol. 25, no. 9, pp. 3114 – 3118, Sep. 2021.
[11] B. Hassibi and B. Hochwald, “How much training is needed in multiple-
antenna wireless links?” IEEE Trans. Inf. Theory, vol. 49, no. 4, pp. 951
– 963, Apr. 2003.
","Despite its significant potential, CF still faces considerable challenges, including the high cost of connecting numerous distributed APs and a central processing unit (CPU) through a fronthaul network. Traditional wireless networks are already challenging due to the complexities of acquiring and maintaining sites for base stations, and this challenge intensifies in the CF architecture, requiring hundreds of suitable sites for wireless AP installations. The deployment of a large-scale fiber-cable network to interconnect these APs further exacerbates this difficulty. In addition, uniform service quality, achieved at the expense of system capacity degradation, is another concern. While voice-oriented cellular networks like 1990s GSM demanded uniform quality, current 4G/5G networks and upcoming 6G systems need differentiated service quality tailored to diverse user devices and applications, rather than settling for averaged service.nan"
"Time series anomaly detection (TSAD) plays a crucial role in various domains. Considering that labels are crucial for detection but difficult to obtain, we turn to TSAD with inexact supervision: only series-level labels are provided during the training phase, while point-level anomalies are predicted during the testing phase. Previous works follow a traditional multi-instance learning (MIL) approach, which focuses on encouraging high anomaly scores at individual time steps. However, time series anomalies are not limited to individual point anomalies, they can also be collective anomalies, typically exhibiting abnormal patterns over subsequences. To address the challenge of collective anomalies, in this paper, we propose a tree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to divide the entire series into multiple nodes, where nodes at different levels represent subsequences with different lengths. Then, the subsequences’ features are extracted to determine the presence of collective anomalies. Finally, we calculate point-level anomaly scores by aggregating features from nodes at different levels. Experiments conducted on seven public datasets and eight baselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-score compared to previous state-of-the-art methods.","Time series anomaly detection (TSAD) aims to identify abnormal time points or subsequences within the entire time series signals and has played critical roles in real-world applications like fault diagnosis, network intrusion detection, and health monitoring. Previous studies mainly adopt a kind of unsupervised strategy, i.e., they use normal data exclusively to train generative models and measure abnormality based on the generation error. However, such methodologies could potentially lead to more false alarms due to the limited variation in collected normal samples. On the other hand, some other research, such as [3], suggests incorporating anomaly labels during model training. While it can indeed improve the final results, from a practical perspective, collecting point-level labels is laborious and could be imprecise, which will finally degrade the overall performance. To address this problem, recent research has introduced a new paradigm, i.e., anomaly detection with inexact supervision. They suggest using coarse-grained anomaly labels during the training phase, such as series-level anomaly labels in time series rather than fine-grained point-level labels. This not only enhances detection performance and practicality but also aligns with the principles of Multi-Instance Learning (MIL). In MIL, a collection of data instances constitutes a ‘bag’, where only the bag-level label is available, and the instance-level labels must be predicted. While numerous MIL-based methods have emerged under this paradigm for video data, there is a scarcity of solutions specifically designed for time series data.","Consider a D-dimension time series X = [x1, x2, ..., xL] ℗DxL of length L, where xt ℗ RD denotes the data collected at the t-th time step, we utilize a sliding window of length T to split the entire series into non-overlapping time series segments, resulting in a dataset D = {x1, x2, ..., xM}, where xi ℗ RDxT denotes the i-th segment and L = M ×T. The dataset D is divided into non-overlapping training dataset Dtr and testing dataset Dte. For the training dataset Dtr, we annotate each subsequence with the occurrence of anomalies within it, resulting in {(xi, yi)|xi ℗ Dtr}, where yi ℗ {0, 1} is the series-level label. After training, given a sample xi ℗ Dte, we produce point-level predictions [μ^yi1, μ^yi2, ..., μ^yiT ], where μ^yit ℗ {0, 1} represents whether anomaly exists at the t-th time step in xi.","In this part, we create an N-ary tree using the input time series xi. In this tree, each parent node has N children nodes. Fig. 1 illustrates a special case of a binary tree where N = 2. Specifically, each leaf node represents an individual time point, the root node symbolizes the entire time series, and the internal nodes signify subsequences of varying lengths. Consequently, nodes at higher levels encompass more time points. The tree has a total of S = ⌈logN T⌉ + 1 levels, where ⌈⌉ denotes the ceiling operation. The embedding of the i-th node at the s-th level is denoted as zs
i and calculated as follows. First, we calculate the temporal embedding of each leaf node utilizing the uniform input representation method proposed in [11], which includes a 1-D convolutional filter and a fixed position embedding. This transforms the input into z = [zS
1, zS
2, ..., zS
N], where zS
t represents the embedding of time point t. Then we compute the embeddings for all nodes in a bottom-up, level-by-level fashion, as depicted in Fig. 1. For instance, the embedding of the i-th node at the s-th level zs
i can be calculated by: zs
i = MaxPooling(zs+1
(i⁄1)×N+1, ..., zs+1
i×N).","In this paper, we propose TreeMIL for TSAD with inexact supervision. To address the challenge of collective anomalies, which have been overlooked by previous studies, we represent the entire time series using an N-ary tree structure. This structure is seamlessly integrated into the MIL framework, where we aggregate the feature from multi-scale nodes to produce final point-level predictions. Only series-level labels are provided during the training phases. Experiments conducted on seven public datasets demonstrate that TreeMIL outperforms all unsupervised and weakly supervised methods.",TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision,"Chen Liu, Shibo He, Haoyu Liu, Shizhong Li","TREEMIL: A MULTI-INSTANCE LEARNING FRAMEWORK FOR TIME SERIES
ANOMALY DETECTION WITH INEXACT SUPERVISION
Chen Liu⋆
Shibo He⋆
Haoyu Liu†
Shizhong Li⋆
⋆ Zhejiang University
†NetEase Fuxi AI Lab
ABSTRACT
Time series anomaly detection (TSAD) plays a vital role
in various domains such as healthcare, networks and indus-
try. Considering labels are crucial for detection but difficult
to obtain, we turn to TSAD with inexact supervision: only
series-level labels are provided during the training phase,
while point-level anomalies are predicted during the testing
phase.
Previous works follow a traditional multi-instance
learning (MIL) approach, which focuses on encouraging high
anomaly scores at individual time steps. However, time series
anomalies are not only limited to individual point anomalies,
they can also be collective anomalies, typically exhibiting ab-
normal patterns over subsequences. To address the challenge
of collective anomalies, in this paper, we propose a tree-based
MIL framework (TreeMIL). We first adopt an N-ary tree
structure to divide the entire series into multiple nodes, where
nodes at different levels represent subsequences with differ-
ent lengths. Then, the subsequences’ features are extracted to
determine the presence of collective anomalies. Finally, we
calculate point-level anomaly scores by aggregating features
from nodes at different levels.
Experiments conducted on
seven public datasets and eight baselines demonstrate that
TreeMIL achieves an average 32.3% improvement in F1-
score compared to previous state-of-the-art methods.
The
code is available at https://github.com/fly-orange/TreeMIL.
Index Terms— Time series anomaly detection, weakly
supervised learning, multi-instance learning
1. INTRODUCTION
Time series anomaly detection (TSAD) aims to identify ab-
normal time points or subsequences within the entire time se-
ries signals and has played critical roles in real-world appli-
cations like fault diagnosis, network intrusion detection, and
health monitoring [1]. Previous studies mainly adopt a kind of
unsupervised strategy, i.e., they use normal data exclusively to
train generative models [15, 4, 12, 5, 14] and measure abnor-
mality based on the generation error. However, such method-
ologies could potentially lead to more false alarms due to the
This work was supported by the National Natural Science Foundation
Program of China under Grant No. U23A20326 and No. U21B2029.
limited variation in collected normal samples [17]. On the
other hand, some other research, such as [3], suggests incor-
porating anomaly labels during model training. While it can
indeed improve the final results, from a practical perspective,
collecting point-level labels is laborious and could be impre-
cise [19], which will finally degrade the overall performance.
To address this problem, recent research has introduced a
new paradigm, i.e., anomaly detection with inexact supervi-
sion [2]. They suggest using coarse-grained anomaly labels
during the training phase, such as series-level anomaly la-
bels in time series rather than fine-grained point-level labels.
This not only enhances detection performance and practical-
ity but also aligns with the principles of Multi-Instance Learn-
ing (MIL). In MIL, a collection of data instances constitutes
a ’bag’, where only the bag-level label is available, and the
instance-level labels must be predicted [7]. While numerous
MIL-based methods have emerged under this paradigm for
video data [9, 18, 8], there is a scarcity of solutions specifi-
cally designed for time series data. Janakiraman et al. [10]
and Lee et al. [6] apply conventional MIL to TSAD, which
only encourages high anomaly scores at individual time steps,
overlooking collective anomalies in the time series data. This
flaw leads to high false negatives.
We hereby propose a tree-based MIL framework, TreeMIL.
Our key objective is to enable the MIL structure to recognize
both point and collective anomalies. To achieve this, we begin
by formalizing the entire time series into an N-ary tree struc-
ture, where nodes represent subsequences of varying lengths.
Next, the anomalous feature of each node is generated using
an attention mechanism that incorporates information from
its parent node, children nodes, neighbor nodes, and itself.
Lastly, our anomaly discriminator considers anomaly features
from subsequences at various scales and produces point-level
anomaly scores, where information from multiple levels can
be comprehensively incorporated. Compared to unsupervised
methods, our method is robust to noise because it captures the
shared anomalous patterns. We conduct experiments on seven
public datasets and our method outperforms eight baselines.
The contributions are summarized as follows:
• We propose an MIL framework (TreeMIL) specially
designed for time series data to achieve anomaly de-
arXiv:2401.11235v1  [cs.LG]  20 Jan 2024
MaxPool
Temporal Embedding
…
…
Level 1
Level 𝑆𝑆
Original 
signals
…
…
…
…
𝐾𝐾 ×
…
…
…
…
Add & Norm
Add & Norm
Attention Mechanism
Feed Forward
…
Global Pooling
Linear Layer
Time-wise 
Pooling
Linear Layer
Weak Label
Dense Label 
Training
Testing
Shared 
weight 
𝑥𝑥1
𝑥𝑥2
𝑥𝑥3
𝑥𝑥4
𝑥𝑥𝑇𝑇
𝑥𝑥𝑇𝑇−1
𝑧𝑧1
𝑆𝑆
𝑧𝑧2
𝑆𝑆
𝑧𝑧3
𝑆𝑆
𝑧𝑧4
𝑆𝑆
𝑧𝑧𝑇𝑇−1
𝑆𝑆
𝑧𝑧𝑇𝑇
𝑆𝑆
𝑧𝑧1
3
𝑧𝑧2
3
𝑧𝑧3
3
𝑧𝑧4
3
𝑧𝑧1
2
𝑧𝑧2
2
𝑧𝑧1
1
Level 2
Level 3
𝑧𝑧1
1
𝑧𝑧1
2
𝑧𝑧2
2
𝑧𝑧1
3
𝑧𝑧2
3
𝑧𝑧3
3
𝑧𝑧4
3
𝑧𝑧1
𝑆𝑆
𝑧𝑧2
𝑆𝑆
𝑧𝑧3
𝑆𝑆
𝑧𝑧𝑇𝑇
𝑆𝑆
ℎ1
1
ℎ1
2
ℎ2
2
ℎ1
3
ℎ2
3
ℎ3
3
ℎ4
3
ℎ1
𝑆𝑆
ℎ2
𝑆𝑆
ℎ3
𝑆𝑆
ℎ𝑇𝑇
𝑆𝑆
{𝑧𝑧𝑖𝑖
𝑠𝑠|1 ≤ 𝑖𝑖 ≤ 𝑁𝑁𝑠𝑠−1, 1 ≤ 𝑠𝑠 ≤ 𝑆𝑆}
{ ̂𝑧𝑧𝑖𝑖
𝑠𝑠|1 ≤ 𝑖𝑖 ≤ 𝑁𝑁𝑠𝑠−1, 1 ≤ 𝑠𝑠 ≤ 𝑆𝑆}
ℋ = {ℎ𝑖𝑖
𝑠𝑠|1 ≤ 𝑖𝑖 ≤ 𝑁𝑁𝑠𝑠−1, 1 ≤ 𝑠𝑠 ≤ 𝑆𝑆}
…
Max Pooling
Max Pooling
Max Pooling
Max Pooling
Max Pooling
Max Pooling
Fig. 1. Overall structure of the proposed TreeMIL framework.
tection with inexact supervision.
• To model the collective anomalies that have been ig-
nored by previous studies, we represent multi-scale
subsequences within the entire time series as an N-ary
tree structure, and find that incorporating this structure
into MIL benefits identifying collective anomalies.
• We conduct thorough experiments on seven public
datasets to demonstrate the superiority of TreeMIL.
The effectiveness of TreeMIL in identifying collective
anomalies is experimentally verified through visualiza-
tion results.
2. METHODOLOGY
2.1. Problem Definition
Consider a D-dimension time series X = [x1, x2, ..., xL] ∈
RD×L of length L, where xt ∈ RD denotes the data col-
lected at the t-th time step, we utilize a sliding window of
length T to split the entire series into non-overlapping time
series segments, resulting in a dataset D = {x1, x2, ..., xM},
where xi ∈ RD×T denotes the i-th segment and L = M ×T.
The dataset D is divided into non-overlapping training dataset
Dtr and testing dataset Dte.
For the training dataset Dtr, we annotate each subse-
quence with the occurrence of anomalies within it, resulting
in {(xi, yi)|xi ∈ Dtr}, where yi ∈ {0, 1} is the series-level
label. After training, given a sample xi ∈ Dte, we produce
point-level predictions [ˆyi1, ˆyi2, ..., ˆyiT ], where ˆyit ∈ {0, 1}
represents whether anomaly exists at the t-th time step in xi.
2.2. Multi-resolution Temporal Embedding
In this part, we create an N-ary tree using the input time se-
ries xi. In this tree, each parent node has N children nodes.
Fig. 1 illustrates a special case of a binary tree where N =
2. Specifically, each leaf node represents an individual time
point, the root node symbolizes the entire time series, and the
internal nodes signify subsequences of varying lengths. Con-
sequently, nodes at higher levels encompass more time points.
The tree has a total of S = ⌈logN T⌉ + 1 levels, where ⌈⌉ de-
notes the ceiling operation. The embedding of the i-th node
at the s-th level is denoted as zs
i and calculated as follows.
First, we calculate the temporal embedding of each leaf
node utilizing the uniform input representation method pro-
posed in [11], which includes a 1-D convolutional filter and
a fixed position embedding. This transforms the input into
z = [zS
1 , zS
2 , ..., zS
T ], where zS
t represents the embedding of
time point t. Then we compute the embeddings for all nodes
in a bottom-up, level-by-level fashion, as depicted in Fig. 1.
For instance, the embedding of the i-th node at the s-th level
zs
i can be calculated by:
zs
i = MaxPooling(zs+1
(i−1)×N+1, ..., zs+1
i×N).
(1)
where zs+1
(i−1)×N+1, ..., zs+1
i×N are the embeddings of nodes at
the s + 1-th level. To ensure the construction of a full N-ary
tree, we pad the original time series to a length of N S−1 with
zeros before proceeding with the aforementioned procedures.
2.3. Feature Extraction
Intuitively, a subsequence should be deemed anomalous when
it contains anomalous time points or exhibits distinct patterns
compared to its neighbor subsequences and the entire time
series. Therefore, we calculate the features of each subse-
quence based on information from its children nodes, neigh-
bor nodes, parent node, and itself, as shown in the middle part
of Fig. 1. Specifically, for a node embedding zs
i , we summa-
rize the aforementioned node embeddings as a set:
N s
i =
n
zs
i , zs+1
(i−1)×N+1, ..., zs+1
i×N, zs
(i− l
2 ), ..., zs
i+ l
2 , zs−1
i
N
o
.
(2)
where l is a hyperparameter that controls the number of neigh-
bor nodes. Next, we calculate the features of zs
i using an at-
tention mechanism:
ˆzs
i =
X
ℓ∈N s
i
exp
where qi, ki, vi denote the query, key and value of the i-th
node in the aforementioned set, with dK representing the di-
mension of these vectors. Note that, nodes that solely contain
the padded values are excluded during the feature extraction
process. We also employ a multi-head mechanism, a feed-
forward network and skip connections utilized in Transformer
[16]. The number of attention layers is K. Finally, we obtain
H = {hs
i|1 ≤ i ≤ N s, 1 ≤ s ≤ S}, where hs
i ∈ Rd repre-
sents the anomaly features of the i-th node at the s-th level.
2.4. Anomaly Discriminator
During the training phase, to ensure that the feature of anoma-
lies occurring at different scales can be learned, we place all
node embeddings into a global pooling layer and generate a
series-level label using a subsequent linear layer, as follows:
ˆy = σ(W × Pooling(H) + b).
(4)
where W ∈ Rd×1 and b ∈ R1 are the parameters of the lin-
ear layer, and σ denotes the sigmoid function. We use binary
cross-entropy as the loss function for training the model:
L = −
X
(x,y)∈Dtr
[y · log ˆy + (1 − y) · log (1 − ˆy)].
(5)
where y is the ground truth series-level anomaly label. Dur-
ing the testing phase, to detect both point anomalies and col-
lective anomalies, we propose a time-wise pooling mecha-
nism. Specifically, for the t-th time point, we first aggregate
the features of all nodes that encompass it:
Ht =
n
hS
t , hS−1
⌈ t
N ⌉, hS−2
⌈
t
N2 ⌉..., h1
1
o
.
(6)
then the prediction at the t-th time point is calculated by:
ˆyt = σ(W × Pooling(Ht) + b).
(7)
we finally obtain the predicted point-level anomaly labels
[ˆy1, ˆy2, ..., ˆyT ] for the entire time series.
3. EXPERIMENTS
3.1. Experimental Setup
Datasets.
We evaluate our method on seven public time
series datasets spanning various domains. EMG: It records
myographic signals from the subjects’ forearms. GECCO:
It collects time series data about drinking water composition.
SWAN-SF: It contains space weather data from Harvard
Dataverse. Credit Card: It records transactions of European
cardholders.
SMD and PSM: They contain metrics from
server machines in an internet company. SMAP: It contains
telemetry data and the Incident Surprise Anomaly (ISA) re-
ports. Further details are presented in Table 1. For EMG,
we set T=500, following the approach in [6]. For GECCO,
Table 1. Details of datasets
Dataset
Timestamps
Dimensions
Anomaly Ratio
Length
EMG
423825
8
5.97%
500
GECCO
138520
10
1.246%
120
SWAN-SF
120000
39
23.8%
120
Credit Card
284807
29
0.173%
120
SMD
708420
38
4.16%
720
PSM
87841
25
27.75%
720
SMAP
427617
25
12.79%
1000
SWAN-SF, and Credit Card where anomalies persist for less
than 40 time steps, we set T = 120. For SMD and PSM
with anomalies exceeding 100 time steps, we set T = 720.
For SMAP with anomalies around 700 time steps, we set
T = 1000.
Baselines. We use two kinds of baselines. Unsupervised
methods: DeepSVDD [15], BeatGAN [4], GDN [12], An-
oTrans [5], GANF [14]. Weakly supervised methods: Deep-
MIL [7], DTMIL [10], WETAS [6].
Metrics. We employ three metrics to evaluate the per-
formance of all methods. F1-W: It denotes the F1 score be-
tween series-level labels and predictions. F1-D: It denotes
the F1-score between point-level labels and predictions. IoU:
It represents the intersection over union between point-level
predictions and labels.
Implementation. The baselines are implemented based
on the hyperparameters reported in previous literature. For
our model, we set N = 2, indicating the construction of a
binary tree. As for the attention mechanism, we use l = 3,
K = 2, and dK = d = 128. During the training stage, we
utilize an Adam optimizer with a learning rate of 0.0001 and
a batch size of 32. All our experiments are conducted on a
single RTX 3090.
3.2. Experiment Result and Analysis
Performance comparison. Results are reported in Table 2
Because using the point-adjustment strategy will result in
artificially inflated metrics [13], the results of all meth-
ods are calculated without this strategy. The best and the
second-best results are highlighted in bold and underlined, re-
spectively. Our method achieves an average improvement of
32.3% in F1-D and 51.8% in IoU compared to previous SOTA
methods. WETAS performs slightly better than TreeMIL on
the Credit Card dataset because the dataset contains only
point anomalies.
For other datasets containing both point
and collective anomalies, our method consistently achieves
the best performance. Additionally, three observations can
be made: Firstly, most unsupervised methods exhibit inferior
performance compared to weakly-supervised methods, indi-
cating that coarse-grained labels benefit anomaly detection.
Secondly, the prediction-based method (GDN) outperforms
other unsupervised methods, implying that the prediction
task is more suitable for anomaly detection. Thirdly, among
weakly supervised methods, DTMIL performs the worst be-
cause it tries to maximize the anomaly score of individual
Table 2. Performance comparison with baseline methods (without point-adjustment strategy)
Methods
EMG
GECCO
SWAN-SF
Credit Card
F1-W
F1-D
IoU
F1-W
F1-D
IoU
F1-W
F1-D
IoU
F1-W
F1-D
IoU
DeepSVDD[15]
-
0.104
0.054
-
0.000
0.000
-
0.071
0.037
-
0.003
0.002
BeatGAN[4]
-
0.105
0.056
-
0.000
0.000
-
0.069
0.036
-
0.003
0.002
GDN[12]
-
0.192
0.106
-
0.761
0.610
-
0.635
0.465
-
0.009
0.004
AnoTrans[5]
-
0.106
0.054
-
0.070
0.042
-
0.019
0.010
-
0.007
0.004
GANF[14]
-
0.151
0.082
-
0.024
0.012
-
0.483
0.319
-
0.005
0.003
DeepMIL[7]
0.763
0.558
0.387
0.667
0.477
0.313
0.934
0.555
0.384
0.846
0.220
0.124
DTMIL [10]
0.562
0.016
0.008
0.560
0.142
0.076
0.940
0.504
0.337
0.841
0.290
0.170
WETAS[6]
0.752
0.580
0.412
0.750
0.551
0.310
0.887
0.561
0.390
0.859
0.376
0.231
TreeMIL(ours)
0.818
0.672
0.502
1.000
0.860
0.755
0.948
0.670
0.504
0.867
0.337
0.203
Methods
SMD
PSM
SMAP
Avg
F1-W
F1-D
IoU
F1-W
F1-D
IoU
F1-W
F1-D
IoU
F1-W
F1-D
IoU
DeepSVDD[15]
-
0.014
0.008
-
0.218
0.122
-
0.028
0.015
-
0.063
0.034
BeatGAN[4]
-
0.122
0.066
-
0.253
0.144
-
0.033
0.017
-
0.084
0.046
GDN[12]
-
0.134
0.072
-
0.595
0.423
-
0.302
0.144
-
0.375
0.261
AnoTrans[5]
-
0.037
0.019
-
0.013
0.007
-
0.019
0.010
-
0.039
0.021
GANF[14]
-
0.065
0.033
-
0.561
0.390
-
0.068
0.035
-
0.194
0.125
DeepMIL[7]
0.400
0.163
0.089
0.800
0.414
0.261
0.514
0.361
0.220
0.703
0.393
0.254
DTMIL [10]
0.800
0.156
0.085
0.743
0.163
0.089
0.454
0.022
0.011
0.700
0.185
0.111
WETAS[6]
0.602
0.294
0.207
0.741
0.481
0.317
0.568
0.386
0.239
0.737
0.461
0.301
TreeMIL(ours)
0.769
0.522
0.353
0.764
0.715
0.557
0.675
0.494
0.328
0.834
0.610
0.457
500
value
level
9 8 7 6 5 4 3 2 1
10
0
100
200
300
400
time step (0.01s)
time step (1min)
10
value
layer
8 7 6 5 4 3 2 1
9
0
120
240
360
480
720
11
600
(a) EMG
time step (1min)
value
level
1
5 4 3 2
7 6
8
0
20
40
60
80
120
100
(b) GECCO
Fig. 2. Anomaly score map: The x-axis represents the time
step and the y-axis represents the level of the tree. The red
rectangle denotes the labeled anomaly window.
points.
While DeepMIL and WETAS consider the outly-
ingness of subsequences, they calculate it by summarizing
the anomaly score of time points, which ignores patterns of
subsequences. TreeMIL overcomes this drawback by repre-
senting multi-scale subsequences in an N-ary tree structure.
Anomaly score visualization. To illustrate how subse-
quences at different scales contribute to the final point-level
predictions, we present the anomaly scores of all nodes in
a heat map.
As shown in Fig. 2(a), for a long collective
anomaly, the nodes at lower levels give higher scores, and
those at higher levels could avoid giving high scores.
In
the case of a short collective anomaly (Fig. 2(b)), the high
anomaly scores are assigned by nodes at higher levels. This
demonstrates that collective anomalies of varying lengths can
be effectively captured by multi-scale subsequences.
Sensitivity analysis. We also conduct a sensitivity anal-
ysis of pooling type and ary size N. Fig. 3(a) shows that
the two types have a minimal impact on EMG, whereas max
pooling outperforms average pooling on GECCO, SWAN,
and PSM because these datasets contain more short collec-
F1
dataset
(a) Pooling type
F1
dataset
(b) Ary size
Fig. 3. Sensitivity analysis: a) The violet plot describes the
F1-D distribution of all time series when applying max and
average pooling. b) The bar plot describes the F1-score when
applying different ary size.
tive anomalies. It is easier for max pooling to capture short
anomalous subsequences. Fig. 3(b) shows that setting N = 2
provides the best results since it captures more fine-grained
temporal information.
Different sizes help detect anoma-
lies at different scales, leading to similar results, except for
GECCO, where the anomaly length is relatively fixed.
4. CONCLUSION
In this paper, we propose TreeMIL for TSAD with inexact su-
pervision. To address the challenge of collective anomalies,
which have been overlooked by previous studies, we repre-
sent the entire time series using an N-ary tree structure. This
structure is seamlessly integrated into the MIL framework,
where we aggregate the feature from multi-scale nodes to pro-
duce final point-level predictions. Only series-level labels are
provided during the training phases. Experiments conducted
on seven public datasets demonstrate that TreeMIL outper-
forms all unsupervised and weakly supervised methods.
5. REFERENCES
[1] S. Qin, Y. Luo, and G. Tao, “Memory-augmented u-
transformer for multivariate time series anomaly detec-
tion,” in ICASSP 2023-2023 IEEE International Con-
ference on Acoustics, Speech and Signal Processing
(ICASSP).
IEEE, 2023, pp. 1–5.
[2] M. Jiang, C. Hou, A. Zheng, X. Hu, S. Han, H. Huang,
X. He, P. S. Yu, and Y. Zhao, “Weakly super-
vised anomaly detection:
A survey,” arXiv preprint
arXiv:2302.04549, 2023.
[3] T. Wen and R. Keyes, “Time series anomaly detection
using convolutional neural networks and transfer learn-
ing,” arXiv preprint arXiv:1905.13628, 2019.
[4] B. Zhou, S. Liu, B. Hooi, X. Cheng, and J. Ye, “Beat-
gan: Anomalous rhythm detection using adversarially
generated time series.” in IJCAI, vol. 2019, 2019, pp.
4433–4439.
[5] J. Xu, H. Wu, J. Wang, and M. Long, “Anomaly trans-
former: Time series anomaly detection with association
discrepancy,” arXiv preprint arXiv:2110.02642, 2021.
[6] D. Lee, S. Yu, H. Ju, and H. Yu, “Weakly super-
vised temporal anomaly segmentation with dynamic
time warping,” in Proceedings of the IEEE/CVF In-
ternational Conference on Computer Vision, 2021, pp.
7355–7364.
[7] W. Sultani, C. Chen, and M. Shah, “Real-world anomaly
detection in surveillance videos,” in Proceedings of the
IEEE conference on computer vision and pattern recog-
nition, 2018, pp. 6479–6488.
[8] S. Li, F. Liu, and L. Jiao, “Self-training multi-sequence
learning with transformer for weakly supervised video
anomaly detection,” in Proceedings of the AAAI Confer-
ence on Artificial Intelligence, vol. 36, no. 2, 2022, pp.
1395–1403.
[9] Y. Chen, Z. Liu, B. Zhang, W. Fok, X. Qi, and Y.-
C. Wu, “Mgfn: Magnitude-contrastive glance-and-focus
network for weakly-supervised video anomaly detec-
tion,” in Proceedings of the AAAI Conference on Arti-
ficial Intelligence, vol. 37, no. 1, 2023, pp. 387–395.
[10] V. M. Janakiraman, “Explaining aviation safety inci-
dents using deep temporal multiple instance learning,”
in Proceedings of the 24th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining,
2018, pp. 406–415.
[11] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong,
and W. Zhang, “Informer: Beyond efficient transformer
for long sequence time-series forecasting,” in Proceed-
ings of the AAAI conference on artificial intelligence,
vol. 35, no. 12, 2021, pp. 11 106–11 115.
[12] A. Deng and B. Hooi, “Graph neural network-based
anomaly detection in multivariate time series,” in Pro-
ceedings of the AAAI conference on artificial intelli-
gence, vol. 35, no. 5, 2021, pp. 4027–4035.
[13] K. Doshi, S. Abudalou, and Y. Yilmaz, “Reward once,
penalize once: Rectifying time series anomaly detec-
tion,” in 2022 International Joint Conference on Neural
Networks (IJCNN).
IEEE, 2022, pp. 1–8.
[14] E. Dai and J. Chen, “Graph-augmented normalizing
flows for anomaly detection of multiple time series,”
arXiv preprint arXiv:2202.07857, 2022.
[15] L. Ruff, R. Vandermeulen, N. Goernitz, L. Deecke, S. A.
Siddiqui, A. Binder, E. M¨uller, and M. Kloft, “Deep
one-class classification,” in International conference on
machine learning.
PMLR, 2018, pp. 4393–4402.
[16] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,
L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin,
“Attention is all you need,” Advances in neural informa-
tion processing systems, vol. 30, 2017.
[17] C. Zhang, G. Li, Y. Qi, S. Wang, L. Qing, Q. Huang, and
M.-H. Yang, “Exploiting completeness and uncertainty
of pseudo labels for weakly supervised video anomaly
detection,” in Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, 2023, pp.
16 271–16 280.
[18] H. Lv, Z. Yue, Q. Sun, B. Luo, Z. Cui, and H. Zhang,
“Unbiased multiple instance learning for weakly super-
vised video anomaly detection,” in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2023, pp. 8022–8031.
[19] Z. Zhang, W. Li, W. Ding, L. Zhang, Q. Lu, P. Hu,
T. Gui, and S. Lu, “Stad-gan: unsupervised anomaly
detection on multivariate time series with self-training
generative adversarial networks,” ACM Transactions on
Knowledge Discovery from Data, vol. 17, no. 5, pp. 1–
18, 2023.
","nanWe hereby propose a tree-based MIL framework, TreeMIL. Our key objective is to enable the MIL structure to recognize both point and collective anomalies. To achieve this, we begin by formalizing the entire time series into an N-ary tree structure, where nodes represent subsequences of varying lengths. Next, the anomalous feature of each node is generated using an attention mechanism that incorporates information from its parent node, children nodes, neighbor nodes, and itself. Lastly, our anomaly discriminator considers anomaly features from subsequences at various scales and produces point-level anomaly scores, where information from multiple levels can be comprehensively incorporated. Compared to unsupervised methods, our method is robust to noise because it captures the shared anomalous patterns. We conduct experiments on seven public datasets and our method outperforms eight baselines."
"DNA storage is gaining prominence due to its potential for immense data storage capacity and longevity. For efficient data integrity, powerful codes that can correct insertion, deletion, and substitution errors are crucial. This paper introduces a family of two-insertion/deletion/substitution (2-ins/del/sub) correcting codes with an asymptotic redundancy of 6 log2n+8. This construction outperforms previous works and achieves the goal of correcting two-substitution errors with a redundancy of 6 log2n+8. We present a systematic classification of all possible error patterns via a novel error segmentation technique. This technique enables a unified analysis of the sign-preserving number, facilitating the application of higher-order Varshamov-Tenengolts (VT) syndromes to code construction. Numerical results demonstrate that the proposed codes offer state-of-the-art performance for correcting 2-ins/del/sub errors.","DNA storage has emerged as a promising technology for data storage due to its advantages in data density and longevity. A significant challenge in DNA storage lies in the inherent errors that can occur during the storage and retrieval processes, such as insertions, deletions, and substitutions. To ensure data integrity, the development of efficient codes capable of correcting these errors is essential.

In recent years, various codes for correcting insertion/deletion/substitution (ins/del/sub) errors have been proposed. Levenshtein introduced the Varshamov-Tenengolts (VT) codes, which are capable of correcting single-insertion/deletion errors with asymptotic optimal redundancy. Subsequently, extensions of VT codes were developed for correcting multiple-insertion/deletion errors, single-deletion multiple-substitution errors, and single-deletion single-substitution errors. However, the redundancy of these codes is often far from optimal.

This paper presents a family of two-insertion/deletion/substitution (2-ins/del/sub) correcting codes with an asymptotic redundancy of 6 log2n+8. Specifically, we focus on correcting two-substitution errors, which pose a significant challenge in DNA storage. Our construction achieves a redundancy of 6 log2n+8, outperforming previous works. To achieve this, we introduce a novel error segmentation technique that systematically classifies all possible error patterns. This technique enables a unified analysis of the sign-preserving number, facilitating the application of higher-order VT syndromes to code construction.","The methodology section describes the key techniques and mathematical tools employed in constructing the proposed 2-ins/del/sub correcting codes. It begins by defining the types and type values of all errors, which play a crucial role in error classification and analysis.

The error segmentation technique is then introduced as a pivotal element of the code construction. This technique enables the separation of errors into relatively independent parts, simplifying their analysis and facilitating a unified treatment of different error types. The section proceeds to demonstrate the effectiveness of the error segmentation technique through several illustrative examples.

Furthermore, the section presents a lemma that allows the analysis of a specific type of error pattern in a simplified setting. This lemma is instrumental in extending the proposed code construction to more general cases.","The results section presents the main theorems and corollaries establishing the properties of the proposed 2-ins/del/sub correcting codes. Theorem 3 serves as the cornerstone, stating that under certain conditions, a sequence can be uniquely reconstructed if its VT syndromes satisfy specific criteria. This theorem provides the theoretical foundation for the code construction.

Theorem 4 introduces the family of 2-ins/del/sub correcting codes with an asymptotic redundancy of 6 log2n+8. This family of codes is constructed based on the conditions specified in Theorem 3. Corollary 5 further shows that appropriate parameters can be chosen to achieve this redundancy bound.

In addition, the section presents several subcases where the conditions of Theorem 3 are verified for specific types of errors. These subcases include four substitutions of type value 0, one substitution of type value 2, one substitution of type value -2, and two substitutions of type value 0, among others. The analysis of each subcase demonstrates the code's ability to correct various error combinations.","The conclusion section summarizes the contributions of the paper and highlights the significance of the proposed 2-ins/del/sub correcting codes. It emphasizes the code's ability to achieve state-of-the-art performance for correcting two-substitution errors with a redundancy of 6 log2n+8.

The conclusion also acknowledges the general applicability of the error segmentation technique to the analysis of sign-preserving numbers. This technique provides a novel perspective and valuable tool for future research in code construction and other related areas.",Two-Insertion/Deletion/Substitution Correcting Codes,"Yuhang Pi, Zhifang Zhang","Two-Insertion/Deletion/Substitution Correcting
Codes
Yuhang Pi and Zhifang Zhang
Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China
School of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing 100049, China
Email: piyuhang@amss.ac.cn, zfz@amss.ac.cn
Abstract—In recent years, the emergence of DNA storage
systems has led to a widespread focus on the research of
codes correcting insertions, deletions, and classic substitutions.
During the initial investigation, Levenshtein discovered the
VT codes are precisely capable of correcting single inser-
tion/deletion and then extended the VT construction to single-
insertion/deletion/substitution (1-ins/del/sub) correcting codes.
Inspired by this, we generalize the recent findings of 1-del 1-sub
correcting codes with redundancy 6 log2 n+O(1) to more general
2-ins/del/sub correcting codes without increasing the redundancy.
Our key technique is to apply higher-order VT syndromes to
distinct objects and accomplish a systematic classification of all
error patterns.
I. INTRODUCTION
The research of insertion/deletion/substitution (ins/del/sub)
correcting codes is of significant interest not only in the field of
communication but also in the field of life sciences, exhibiting
a multitude of potential value in applications. Insertions, dele-
tions, and substitutions commonly occur in DNA mutations
[17], as well as in the synthesizing and sequencing processes
of a DNA storage system [6].
Levenshtein
[8]
discovered
the
binary
Varshamov-
Tenengolts (VT) codes [18],
V Ta(n) =
(
x1 · · · xn ∈ {0, 1}n |
n
X
i=1
ixi ≡ a mod n + 1
)
,
are 1-ins/del correcting codes with asymptotic optimal redun-
dancy. If congruence modulo n+1 is replaced by congruence
modulo 2n, the corresponding codes become 1-ins/del/sub
correcting codes [8]. Furthermore, Levenshtein [9] constructed
two-burst-deletion correcting codes which are also 1-ins/del
correcting codes, thereby signifying a complete extension from
VT codes as well. Note that generally a two-burst-deletion
correcting code may not necessarily be a 1-ins/del correcting
code (e.g., C = {101, 010}).
The Helberg codes proposed by Helberg and Ferreira [7]
have been confirmed as multiple-ins/del correcting codes [1]
with redundancy Ω(n) [11]. Based on hash function, Brak-
ensiek et al. [2] presented t-ins/del correcting codes with re-
dundancy O(t2 log2 t log2 n), followed by the work of Gabrys
and Sala [3], Sima and Bruck [13], as well as Song et al.
[16]. However, considering that hash function heavily relies
on exhaustive research, strictly speaking these codes do not
possess explicit forms. In the subsequent discussion we will
primarily concentrate on binary explicit-form codes related to
2-ins/del/sub correcting codes.
Sima et al. [12] constructed 2-ins/del correcting codes
with redundancy 7 log2 n + o(log2 n) from higher-order VT
syndromes. It was improved by Guruswami and Håstad [5]
to 2-ins/del correcting codes with redundancy 4 log2 n +
10 log2(log2 n) + O(1), which is currently the most superior
construction. 2-ins/del correcting codes with list size two and
redundancy 3 log2 n + O(1) are also presented in [5].
Smagloy et al. [14] constructed 1-del 1-sub correcting codes
with redundancy 6 log2 n+O(1). The redundancy was reduced
by a constant in [16]. 1-del 1-sub correcting codes with list
size two were studied by Gabrys et al. [4] and Song et al.
[15].
All of these explicit-form constructions adopted an exten-
sion technique of VT syndrome (i.e., higher-order VT syn-
dromes) either directly or indirectly. Although this technique
has been observed in the study of ins/del correcting codes [10],
its favorable properties were only recently confirmed by Sima
et al. [12], [13], with a particular focus on the sign-preserving
number of a target sequence (referring to Lemma 1). The
1-del 1-sub correcting codes in [14] and the 1-del multiple-
sub correcting codes in [16] serve as the most representative
examples, applying higher-order VT syndromes to each bit (or
equivalently, the number of 1s in an interval).
A. Our Contributions
We construct a family of 2-ins/del/sub correcting codes (i.e.,
Theorem 4), among which at least one has redundancy of at
most 6 log2 n + 8 (i.e., Corollary 5). Compared to previous
work [14], [16], we apply higher-order VT syndromes to the
number of particular adjacent pairs in an interval.
Under the requirement (i.e., Definition 1) that the pairwise
distances between all errors in two sequences are suitably
large, we strictly define the types and type values of all errors
and sequence pair (i.e., Definition 2 and Definition 3). For
the two sequences that may not satisfy the requirement, we
employ a lemma (i.e., Lemma 2) to analyze two other relevant
sequences. In this way, we eliminate the confusion caused by
errors being too close to each other and accomplish a rigorous
classification. Based primarily on the type of sequence pair,
we conduct a unified analysis of sign-preserving number to
complete the proof. This analytical framework provides a
novel perspective for the analysis of sign-preserving number,
arXiv:2401.11231v1  [cs.IT]  20 Jan 2024
thereby facilitating the further applications of higher-order VT
syndromes in code construction.
B. Organization
The rest of this paper is organized as follows. We introduce
notations and known conclusions in Section II and present
main results in Section III, including the construction of 2-
ins/del/sub correcting codes. In Sections IV–VI, we prove
Theorem 3 by examining three cases, essentially verifying the
code Ck1,k2,k3,k4 in Theorem 4 is a 2-sub correcting code,
a 2-del correcting code, and a 1-del 1-sub correcting code,
respectively. Section VII concludes this paper.
II. PRELIMINARIES
Let A2 = {0, 1}, [i] = {1, 2, · · · , i}, [i, j] = {i, i +
1, · · · , j}, and VTn
i = (1i, 2i, · · · , ni). For x ∈ An
2, denoted
by xi the i-th symbol in x, by Bt,s,r(x) the set of sequences
which can be obtained from x by t insertions, s deletions,
and r substitutions. Trivial substitution at xi, i.e., no change
occurring at xi, can also be regarded as one substitution.
Sequence x1 · · · xn and vector (x1, · · · , xn) are commonly
regarded as consistent. If S = {i1, · · · , ij} ⊆ [n] where
i1 < i2 < · · · < ij, xS denotes xi1 · · · xij. Edit distance
L∗(x, y) of x and y is defined as the minimum number of
insertions, deletions, and substitutions needed to transform x
into y. C ⊆ An
2 is called a k-ins/del/sub correcting code if
L∗(c1, c2) ≥ 2k + 1 for all c1, c2 ∈ C, c1 ̸= c2.
Use a to represent any one of 0 and 1, b to represent another
one. For x ∈ An
2, f(x) is defined as the number of adjacent
pair ab in x, i.e., the total number of adjacent pairs 01 and
10 in x. Furthermore, let F(x) = (f(x[1]), · · · , f(x[n])). For
instance, F(000100) = (0, 0, 0, 1, 2, 2).
If a lowercase bold letter represents a sequence, the se-
quence with a 0 added at both the beginning and the end
of it, is denoted by the corresponding uppercase bold letter.
For instance, x = 110 corresponds to X = 01100. Similar
techniques are applied to both [9] and [5]. The advantages of
adding two 0s are twofold. Firstly, it reduces the number of
cases to be discussed later. Secondly, it ensures our capability
to distinguish x and y. Specifically, if x ̸= y, it is possible that
F(x) = F(y) (e.g., x = 10 and y = 01). However, x ̸= y is
equivalent to F(X) ̸= F(Y). This conclusion can be reached
by focusing on the first unequal symbols of X and Y.
If an integer sequence z = z1 · · · zn is non-negative or non-
positive, z is called a 1-sequence. If an integer sequence z
can be divided into k continuous segments such that each
segment is a 1-sequence, z is called a k-sequence. The sign-
preserving number of z, denoted by σ(z), is defined as the
minimum integer k such that z is a k-sequence. For instance,
σ((1, 0, 1, −1, −2, 3)) = 3. Clearly, for 1 ≤ i ≤ n − 1,
σ(z1 · · · zn) ≤ σ(z1 · · · zi) + σ(zi+1 · · · zn). Introducing the
concept of sign-preserving number has the benefit of charac-
terizing the following lemma.
Lemma 1 (c.f., [12], [13]): If z ∈ Zn satisfies z·VTn
i = 0
for 0 ≤ i ≤ σ(z) − 1, then z = 0n.
Definition
1: Let u, v
∈
Am
2 . (U, V) is called a
(s, r)-del/sub good pair if there exist i1, i2, · · · , i2s+2r ∈
[2, m + 1] with pairwise distances at least 2s + 1 such
that the sequence obtained by deleting Ui1, · · · , Uis and
substituting Uis+1, · · · , Uis+2r (allowing trivial substitutions)
from U is equal to the sequence obtained by deleting
Vis+2r+1, · · · , Vi2s+2r from V.
Remark 1: Levenshtein [8] proved the equivalence between
t-ins correcting codes, t-del correcting codes, and t-ins/del
correcting codes. Similarly, the equivalence between t-ins s-
sub correcting codes, t-del s-sub correcting codes, and t-
ins/del s-sub correcting codes still holds. Therefore, we only
need to consider deletions and substitutions in Definition 1.
Moreover, for (X, Y) that may not be a (s, r)-del/sub good
pair, we will later shift our analysis to a relevant (s, r)-del/sub
good pair (U, Y) through Lemma 2.
Assume (U, V) is a (s, r)-del/sub good pair. Consequently,
for any α ∈ [m + 2]\{i1, · · · , is}, there exists a unique
β ∈ [m + 2]\{is+2r+1, · · · , i2s+2r} such that Uα and Vβ are
matched. we express τ(Uα) as Vβ, and conversely, τ(Vβ) as
Uα. For α ∈ {i1, · · · , is} and β ∈ {is+2r+1, · · · , i2s+2r},
τ(Uα) and τ(Vβ) are undefined. This notation is informal, but
highly flexible.
As an example shown in Fig. 1, the deleted symbols are
marked with red dots, while the lines indicate the one-to-
one matching between U[13]\{2} and V[13]\{9}. Particularly,
two dashed lines indicate two substitutions. At this moment,
τ(U3) = V2 = 0 and τ(U6) = V5 = 1. However, τ(U2) and
τ(V9) are undefined. As another example shown in Fig. 2,
τ(Ui) = Vi and τ(Vi) = Ui for i ∈ [8].
Position:
1
2
3
4
5
6
7
8
9
10 11 12 13
U = 0
1
0
0
0
0
0
0
0
0
0
1
0
V = 0
0
0
0
1
0
0
0
1
0
0
0
0
Fig. 1. The matching of U[13]\{2} and V[13]\{9}.
Position:
1
2
3
4
5
6
7
8
U = 0
0
0
0
0
1
1
0
V = 0
1
1
0
0
0
0
0
Fig. 2. The matching of U and V.
For (s, r)-del/sub good pair (U, V), all errors can be
regarded as relatively independent parts, enabling their classifi-
cation into types and type values in Definition 2. Additionally,
there exists an evident sequential order among all errors, which
enables us to define the type and type value of (U, V) in
Definition 3.
Definition 2: Assume (U, V) is a (s, r)-del/sub good pair
introduced in Definition 1. The types and type values of all
errors are defined as follows.
1) The type and type value of substitution occurring at
Ui where i ∈ {is+1, · · · , is+2r} is defined as sub
and e respectively where e = f(τ(Ui−1)UiUi+1) −
f(τ(Ui−1)τ(Ui)Ui+1).
2) The type and type value of deletion occurring at
Ui
where
i
∈
{i1, · · · , is}
is
defined
as
del
and e respectively where e
=
f(Ui−1UiUi+1) −
f(τ(Ui−1)τ(Ui+1)) = f(Ui−1UiUi+1) − f(Ui−1Ui+1).
3) The type and type value of deletion occurring at Vi
where i ∈ {is+2r+1, · · · , i2s+2r} is defined as del
and e respectively where e = f(τ(Vi−1)τ(Vi+1)) −
f(Vi−1ViVi+1) = f(Vi−1Vi+1) − f(Vi−1ViVi+1).
Due to the separation of errors, the definitions and properties
of τ(Ui−1), τ(Ui+1), τ(Vi−1), and τ(Vi+1) in Definition 2 are
valid.
TABLE I
THE TYPES AND TYPE VALUES OF ERRORS. (A) SUBSTITUTIONS IN U.
(B) DELETIONS IN U. (C) DELETIONS IN V.
τ(Ui−1)UiUi+1 → τ(Ui−1)τ(Ui)Ui+1
Types
Type Values
Trivial Substitution
sub
0
abb → aab
sub
0
aab → abb
sub
0
aba → aaa
sub
2
aaa → aba
sub
−2
(a)
Ui−1UiUi+1 → Ui−1Ui+1
Types
Type Values
abb → ab
del
0
aab → ab
del
0
aaa → aa
del
0
aba → aa
del
2
(b)
Vi−1ViVi+1 → Vi−1Vi+1
Types
Type Values
abb → ab
del
0
aab → ab
del
0
aaa → aa
del
0
aba → aa
del
−2
(c)
Table I shows all types and type values of substitutions and
deletions, with the bold symbols indicating the occurrences of
corresponding errors. Although a substitution of type value 0
occurring at Ui does not affect the number of adjacent pair
ab of the entire sequence, it may alter the number of adjacent
pair ab of the first i symbols, with a difference of at most 1.
Definition 3: Assume (U, V) is a (s, r)-del/sub good pair
introduced in Definition 1. The type of (U, V) belongs to
{sub, del, del}2s+2r, determined in sequential order according
to the types of all errors. The type value of (U, V) belongs
to {2, 0, −2, 2, 0, 0, −2}2s+2r, determined in sequential order
according to the type values of all errors.
Fig. 1 corresponds to s = 1, r = 1, i1 = 2, i2 = 6,
i3 = 12, and i4 = 9. Given that the pairwise distances between
i1, · · · , i4 are at least 2s + 1, (U, V) is a (1, 1)-del/sub good
pair. Therefore, the types and type values of errors can be
determined. The deletion occurring at U2 is of type del and
type value 2. The substitution occurring at U6 is of type sub
and type value −2. The deletion occurring at V9 is of type
del and type value −2. The substitution occurring at U12 is of
type sub and type value 2. Based on them, we ascertain that
the type and type value of (U, V) are (del, sub, del, sub) and
(2, −2, −2, 2), respectively.
Fig. 2 corresponds to s = 0, r = 2, i1 = 2, i2 = 3,
i3 = 6, and i4 = 7. Given that the pairwise distances between
i1, · · · , i4 are at least 2s + 1, (U, V) is a (0, 2)-del/sub good
pair. Therefore, the types and type values of errors can be
determined. The substitution occurring at U2 is of type sub
and type value −2. The substitution occurring at U3 is of type
sub and type value 0. The substitution occurring at U6 is of
type sub and type value 0. The substitution occurring at U7
is of type sub and type value 2. Based on them, we ascertain
that the type and type value of (U, V) are (sub, sub, sub, sub)
and (−2, 0, 0, 2), respectively.
Next, we revert to general x, y
∈
An
2, B0,s,r(x) ∩
B0,s,r(y) ̸= ∅, where n ≥ 7 and s + r = 2. In the case of
s = 0, due to the permission of trivial substitutions, (X, Y) is
a (0, 2)-del/sub good pair. In the case of 1 ≤ s ≤ 2, we employ
the following lemma to analyze (U, V) instead of (X, Y),
which satisfies the requirement that all errors are separated
with pairwise distances at least 2s + 1.
Lemma 2: For x, y ∈ An
2, B0,s,r(x) ∩ B0,s,r(y) ̸= ∅,
and any positive integer k, there exist u, v ∈ Am
2 , such that
f(X) − f(Y) = f(U) − f(V) and σ(F(X) − F(Y)) ≤
σ(F(U) − F(V)). Moreover, there exist i1, i2, · · · , i2s+2r ∈
[2, m + 1] with pairwise distances at least k, such that
the sequence obtained by deleting Ui1, · · · , Uis and sub-
stituting Uis+1, · · · , Uis+2r
(allowing trivial substitutions)
from U is equal to the sequence obtained by deleting
Vis+2r+1, · · · , Vi2s+2r from V.
The proof of Lemma 2 is presented in Appendix.
III. MAIN RESULTS
Theorem 3: Let n ≥ 7. If x, y ∈ An
2 satisfy L∗(x, y) ≤ 4
and









(F(X) − F(Y)) · VTn+2
0
= 0
(F(X) − F(Y)) · VTn+2
1
= 0
(F(X) − F(Y)) · VTn+2
2
= 0
f(X) = f(Y)
,
(1)
then x = y.
The proof of Theorem 3 will be systematically developed
in Sections IV–VI. Note that under the conditions in (1),
σ(F(X) − F(Y)) ≤ 3 is a sufficient condition for x = y
by Lemma 1. In the rest of this section, under the premise
of Theorem 3, we present a family of 2-ins/del/sub correcting
codes.
Theorem 4: For n ≥ 7, the binary code Ck1,k2,k3,k4 in
which the codeword x ∈ An
2 satisfies









F(X) · VTn+2
0
≡ k1 mod 4n
F(X) · VTn+2
1
≡ k2 mod 2n2
F(X) · VTn+2
2
≡ k3 mod 2n3
f(X) ≡ k4 mod 9
(2)
is a 2-ins/del/sub correcting code.
Proof: Suppose there exist x ̸= y ∈ Ck1,k2,k3,k4 such that
L∗(x, y) ≤ 4. We only need to derive a contradiction. For the
sake of simplicity, in the rest of this proof, F and fi denote
F(X) − F(Y) and f(X[i]) − f(Y[i]), respectively.
By (2),









F · VTn+2
0
≡ 0 mod 4n
F · VTn+2
1
≡ 0 mod 2n2
F · VTn+2
2
≡ 0 mod 2n3
fn+2 ≡ 0 mod 9
.
(3)
By definition, f1 = f(X[1]) − f(Y[1]) = 0 − 0 = 0.
Moreover, an insertion, deletion, or substitution occurring at
X will change f(X) by at most 2, which implies |fn+2| ≤ 8
and thereby fn+2 = 0. Hence, |f2|, |fn+1| ≤ 1, |f3|, |fn| ≤ 2,
and |f4|, |fn−1| ≤ 3. Due to fn+2 = 0, |fi| ≤ 4 holds for
5 ≤ i ≤ n − 2. Thus,
|F · VTn+2
i
| ≤
n+2
X
j=1
|fj| · ji
≤1 · 2i + 2 · 3i + 3 · 4i + 4 ·
n−2
X
j=5
ji
+ 3 · (n − 1)i + 2 · ni + 1 · (n + 1)i.
(4)
Replacing i with 0, 1, 2 in (4), we obtain





|F · VTn+2
0
| ≤ 4n − 12 < 4n
|F · VTn+2
1
| ≤ 2n2 − 18 < 2n2
|F · VTn+2
2
| ≤ 4n3
3 + 14n
3 − 50 < 2n3
.
(5)
Combining (3), (5), and Theorem 3, x = y holds, a
contradiction.
Corollary 5: For n ≥ 7, there exist appropriate integers
k1, k2, k3, k4 such that the code Ck1,k2,k3,k4 presented in
Theorem 4 is a 2-ins/del/sub correcting code with redundancy
of at most 6 log2 n + 8.
Proof: By Theorem 4 and the pigeonhole principle.
IV. Ck1,k2,k3,k4 IS A 2-SUB CORRECTING CODE
In this section, we assume the conditions in Theorem 3
hold, and proceed to verify x = y in the case of B0,0,2(x) ∩
B0,0,2(y) ̸= ∅. Specifically, Y can be obtained from X by
substituting Xj1, Xj2, Xj3, and Xj4 where 2 ≤ j1 < j2 <
j3 < j4 ≤ n+1 (allowing trivial substitutions). For the sake of
simplicity, in the rest of this section, F and fi denote F(X)−
F(Y) and f(X[i]) − f(Y[i]), respectively.
As a result of fn+2 = 0, the number of substitutions of type
value 2 is equal to the number of substitutions of type value
−2. We divide our discussion into three subcases.
A. Four Substitutions of Type Value 0
In this situation, the conditions specified at the beginning
of this section are transformed into















2 ≤ j1 < j2 < j3 < j4 ≤ n + 1
fj1, fj2, fj3, fj4 ∈ {−1, 0, 1}
fj1 + fj2 + fj3 + fj4 = 0
j1fj1 + j2fj2 + j3fj3 + j4fj4 = 0
j2
1fj1 + j2
2fj2 + j2
3fj3 + j2
4fj4 = 0
.
(6)
Lemma 6: The equation in (6) only has one solution fj1 =
fj2 = fj3 = fj4 = 0.
Proof: Assume at least one of fj1, fj2, fj3, and fj4 is
non-zero. Then the first four conditions in (6) result in





fj1 = fj4 = 1
fj2 = fj3 = −1
j1 + j4 = j2 + j3
,
or





fj1 = fj4 = −1
fj2 = fj3 = 1
j1 + j4 = j2 + j3
.
In all cases, the fifth condition in (6) changes to j2
1 + j2
4 =
j2
2 + j2
3. Additionally,
j1j4 = (j1 + j4)2 − (j2
1 + j2
4)
2
= (j2 + j3)2 − (j2
2 + j2
3)
2
= j2j3.
Therefore, the equation w2 − (j1 + j4)w + j1j4 = 0 has 4
distinct roots j1, j2, j3, and j4, a contradiction.
To sum up, in this subcase, F(X) − F(Y) = F = 0n+2
which implies x = y.
Remark 2: For L∗(x, y) ≤ 4, the advantage of using
Lemma 2 lies in the capability to separate errors into 4
relatively independent parts, thus facilitating clearer discus-
sions. This technique simultaneously entails the drawback
of losing the first three conditions in (1) for U and V,
whereas the first three conditions in (1) are essential to derive
σ(F(X) − F(Y)) ≤ 3 in this subcase. For instance, when
U = 0111001110 and V = 0010000100 fail to meet the first
three conditions in (1), it results in σ(F(U) − F(V)) = 4.
Therefore, in this subcase we directly examine the check
equations without employing Lemma 2 to complete the proof.
B. One Substitution of Type Value 2, One Substitution of Type
Value −2, and Two Substitutions of Type Value 0
Without loss of generality, we may assume the substitution
of type value 2 and the substitution of type value −2 occur
at Xjk and Xjl respectively where 1 ≤ k < l ≤ 4. The
crucial aspect of addressing this subcase lies in observing the
following fact.
Lemma 7: σ(fjk, fjk+1, · · · , fjl) = 1.
Proof: At this moment, fjk = 1, fjl = 1, and fi ≥ 1 for
jk < i < jl, which implies this lemma.
Regarding fi where i /∈ [jk, jl], at most two of them are
non-zero, corresponding to the positions of two substitutions
of type value 0. With the help of Lemma 7, σ(F) ≤ 3, which
implies x = y.
Position:
1
2
j1−2
j1
j1+2
j2−1
j2+1
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
Position:
1
2
j1−1
j1+1
j2−2
j2
j2+2
j3−1
j3+1
j4−1
j4+1
m+2
|
{z
}
{e1, e1 − 1}
|
{z
}
{e1 + e2, e1 + e2 − 1, e1 + e2 − 2}
|
{z
}
{e1 + e2 + e3, e1 + e2 + e3 − 1}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 3. The type of (U, V) is (del, del, del, del).
C. Two Substitutions of Type Value 2 and Two Substitutions
of Type Value −2
Without loss of generality, we may assume the substitution
occurring at Xj1 is of type value 2. Hence, it suffices to verify
all possible type values of (X, Y) below.
• (2, 2, −2, −2). At this moment, given that F is non-
negative, σ(F) = 1 ≤ 3.
• (2, −2, 2, −2). At this moment, given that F is non-
negative, σ(F) = 1 ≤ 3.
• (2, −2, −2, 2). At this moment, fi ≥ 0 for i ∈ [1, j2]
and fi ≤ 0 for i ∈ [j2 + 1, n + 2]. Thus σ(F) ≤
σ((f1, · · · , fj2)) + σ((fj2+1, · · · , fn+2)) = 2 ≤ 3.
To sum up, in this subcase, σ(F) ≤ 3 which implies x = y.
V. Ck1,k2,k3,k4 IS A 2-DEL CORRECTING CODE
In this section, we assume the conditions in Theorem 3
hold, and proceed to verify x = y in the case of B0,2,0(x) ∩
B0,2,0(y) ̸= ∅.
Using Lemma 2, we always assume u, v ∈ Am
2 such that
f(U) = f(V) and σ(F(X) − F(Y)) ≤ σ(F(U) − F(V)).
Moreover, there exist i1, i2, i3, i4 ∈ [2, m + 1] with pairwise
distances at least 5, such that the sequence obtained by deleting
Ui1 and Ui2 from U is equal to the sequence obtained by
deleting Vi3 and Vi4 from V. We arrange i1, i2, i3, i4 in
ascending order as j1 < j2 < j3 < j4. For the sake
of simplicity, in the rest of this section, F and fi denote
F(U) − F(V) and f(U[i]) − f(V[i]), respectively.
We may assume a deletion of type del occurs at Uj1.
Otherwise, given that σ(F(V) − F(U)) = σ(F(U) − F(V)),
it suffices to consider the type of (V, U) rather than (U, V).
According to this assumption, we divide our discussion into
three subcases by the type of (U, V).
A. The Type of (U, V) is (del, del, del, del)
Assume the type value of (U, V) is (e1, e2, e3, e4). That
is to say, deletions of type value e1, e2, e3, and e4 occur
at Uj1, Uj2, Vj3, and Vj4, respectively. Referring to Fig. 3,
e1 = f(U[j1−1,j1+1])−f(V[j1−1,j1]), e2 = f(U[j2−1,j2+1])−
f(V[j2−2,j2−1]), e3 = f(U[j3+1,j3+2]) − f(V[j3−1,j3+1]),
e4 = f(U[j4,j4+1]) − f(V[j4−1,j4+1]). We discuss fi for
i ∈ [m + 2] in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1,
fi =f(U[j1−1,j1]) − f(V[j1−1,j1])
=f(U[j1−1,j1+1]) − f(V[j1−1,j1]) − f(U[j1,j1+1])
=e1 − f(U[j1,j1+1])
∈{e1, e1 − 1}.
• For i ∈ [j1 + 1, j2 − 1],
fi = e1 − f(V[i−1,i]) ∈ {e1, e1 − 1}.
• For i = j2,
fi =e1 + f(U[j2−1,j2]) − f(V[j1−2,j2−1])
− f(V[j2−1,j2])
=e1 + f(U[j2−1,j2+1]) − f(U[j2,j2+1])
− f(V[j2−2,j2−1]) − f(V[j2−1,j2])
=e1 + e2 − f(U[j2,j2+1]) − f(V[j2−1,j2])
∈{e1 + e2, e1 + e2 − 1, e1 + e2 − 2}.
• For i ∈ [j2 + 1, j3 + 1],
fi =e1 + e2 − f(V[i−2,i−1]) − f(V[i−1,i])
∈{e1 + e2, e1 + e2 − 1, e1 + e2 − 2}.
• For i ∈ [j3 + 2, j4],
fi =e1 + e2 + e3 − f(V[i−1,i])
∈{e1 + e2 + e3, e1 + e2 + e3 − 1}.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2−1)) + σ((fj2, · · · , fj3+1))
+ σ((fj3+2, · · · , fm+2))
=3,
which implies x = y.
Position:
1
2
j1−2
j1
j1+2
j2−2
j2
j2+2
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
Position:
1
2
j1−1
j1+1
j2−1
j2+1
j3−1
j3+1
j4−1
j4+1
m+2
|
{z
}
{e1, e1 − 1}
|
{z
}
{e1 + e2}
|
{z
}
{e1 + e2 + e3, e1 + e2 + e3 − 1}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 4. The type of (U, V) is (del, del, del, del).
B. The Type of (U, V) is (del, del, del, del)
Assume the type value of (U, V) is (e1, e2, e3, e4). That
is to say, deletions of type value e1, e2, e3, and e4 occur
at Uj1, Vj2, Uj3, and Vj4, respectively. Referring to Fig. 4,
e1 = f(U[j1−1,j1+1]) − f(V[j1−1,j1]), e2 = f(U[j2,j2+1]) −
f(V[j2−1,j2+1]), e3 = f(U[j3−1,j3+1]) − f(V[j3−1,j3]), e4 =
f(U[j4,j4+1])−f(V[j4−1,j4+1]). We discuss fi for i ∈ [m+2]
in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1,
fi =f(U[j1−1,j1]) − f(V[j1−1,j1])
=f(U[j1−1,j1+1]) − f(V[j1−1,j1]) − f(U[j1,j1+1])
=e1 − f(U[j1,j1+1])
∈{e1, e1 − 1}.
• For i ∈ [j1 + 1, j2],
fi = e1 − f(V[i−1,i]) ∈ {e1, e1 − 1}.
• For i ∈ [j2 + 1, j3 − 1], fi = e1 + e2.
• For i = j3,
fi =e1 + e2 + f(U[j3−1,j3]) − f(V[j3−1,j3])
=e1 + e2 + f(U[j3−1,j3+1]) − f(V[j3−1,j3])
− f(U[j3,j3+1])
=e1 + e2 + e3 − f(U[j3,j3+1])
∈{e1 + e2 + e3, e1 + e2 + e3 − 1}.
• For i ∈ [j3 + 1, j4],
fi =e1 + e2 + e3 − f(V[i−1,i])
∈{e1 + e2 + e3, e1 + e2 + e3 − 1}.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2)) + σ((fj2+1, · · · , fj3−1))
+ σ((fj3, · · · , fm+2))
=3,
which implies x = y.
C. The Type of (U, V) is (del, del, del, del)
Assume the type value of (U, V) is (e1, e2, e3, e4). That
is to say, deletions of type value e1, e2, e3, and e4 occur
at Uj1, Vj2, Vj3, and Uj4, respectively. Referring to Fig. 5,
e1 = f(U[j1−1,j1+1]) − f(V[j1−1,j1]), e2 = f(U[j2,j2+1]) −
f(V[j2−1,j2+1]), e3 = f(U[j3−1,j3]) − f(V[j3−1,j3+1]), e4 =
f(U[j4−1,j4+1])−f(V[j4,j4+1]). We discuss fi for i ∈ [m+2]
in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1,
fi =f(U[j1−1,j1]) − f(V[j1−1,j1])
=f(U[j1−1,j1+1]) − f(V[j1−1,j1]) − f(U[j1,j1+1])
=e1 − f(U[j1,j1+1])
∈{e1, e1 − 1}.
• For i ∈ [j1 + 1, j2],
fi = e1 − f(V[i−1,i]) ∈ {e1, e1 − 1}.
• For i ∈ [j2 + 1, j3 − 1], fi = e1 + e2.
• For i = j3,
fi =e1 + e2 + f(U[j3−1,j3]) − f(V[j3−1,j3])
=e1 + e2 + f(U[j3−1,j3]) − f(V[j3−1,j3+1])
+ f(V[j3,j3+1])
=e1 + e2 + e3 + f(V[j3,j3+1])
∈{e1 + e2 + e3, e1 + e2 + e3 + 1}.
• For i ∈ [j3 + 1, j4],
fi =e1 + e2 + e3 + f(U[i−1,i])
∈{e1 + e2 + e3, e1 + e2 + e3 + 1}.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Position:
1
2
j1−2
j1
j1+2
j2−2
j2
j2+2
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
Position:
1
2
j1−1
j1+1
j2−1
j2+1
j3−1
j3+1
j4−1
j4+1
m+2
|
{z
}
{e1, e1 − 1}
|
{z
}
{e1 + e2}
|
{z
}
{e1 + e2 + e3, e1 + e2 + e3 + 1}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 5. The type of (U, V) is (del, del, del, del).
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2)) + σ((fj2+1, · · · , fj3−1))
+ σ((fj3, · · · , fm+2))
=3,
which implies x = y.
VI. Ck1,k2,k3,k4 IS A 1-DEL 1-SUB CORRECTING CODE
In this section, we assume the conditions in Theorem 3
hold, and proceed to verify x = y in the case of B0,1,1(x) ∩
B0,1,1(y) ̸= ∅.
Using Lemma 2, we always assume u, v ∈ Am
2 such that
f(U) = f(V) and σ(F(X) − F(Y)) ≤ σ(F(U) − F(V)).
Moreover, there exist i1, i2, i3, i4 ∈ [2, m + 1] with pairwise
distances at least 5, such that the sequence obtained by deleting
Ui1 and substituting Ui2 and Ui3 (allowing trivial substitutions)
from U is equal to the sequence obtained by deleting Vi4
from V. We arrange i1, i2, i3, i4 in ascending order as j1 <
j2 < j3 < j4. For the sake of simplicity, in the rest of this
section, F and fi denote F(U)−F(V) and f(U[i])−f(V[i]),
respectively.
There are a total of 12 possible types of (U, V). A concept
is introduced to simplify the discussion.
Definition 4: The inversion of z ∈ Zn is defined as z−1 =
znzn−1 · · · z1.
By
definition,
f(z)
=
f(z−1),
(z−1)[i]
=
znzn−1 · · · zn−i+1, while (z[i])−1 = zizi−1 · · · z1.
Lemma 8: If x, y ∈ An
2, f(x) = f(y), then σ(F(x−1) −
F(y−1)) = σ(F(x) − F(y)).
Proof:
f((x−1)[i]) − f((y−1)[i])
=f(xnxn−1 · · · xn−i+1) − f(ynyn−1 · · · yn−i+1)
=f(x[n−i+1,n]) − f(y[n−i+1,n])
=(f(x) − f(x[n−i+1])) − (f(y) − f(y[n−i+1]))
=f(y[n−i+1]) − f(x[n−i+1])
= − (f(x[n−i+1]) − f(y[n−i+1])).
Therefore, F(x−1) − F(y−1) = −(F(x) − F(y))−1 which
implies
σ(F(x−1) − F(y−1)) =σ(−(F(x) − F(y))−1)
=σ((F(x) − F(y))−1)
=σ(F(x) − F(y)).
(del, del, sub, sub)
(U, V)
(del, del, sub, sub)
(V, U)
(sub, sub, del, del)
(U−1, V−1)
(sub, sub, del, del)
(V−1, U−1)
Fig. 6.
The equivalence between (del, del, sub, sub), (del, del, sub, sub),
(sub, sub, del, del), and (sub, sub, del, del).
As
shown
in
Fig.
6,
by
σ(F(U) − F(V))
=
σ(F(V) − F(U)) and Lemma 8, the four types of (U, V),
(del, del, sub, sub), (del, del, sub, sub), (sub, sub, del, del),
and
(sub, sub, del, del),
are
considered
to
be
equiva-
lent.
Note
that
after
this
transformation,
the
pairwise
distances
of
errors
are
at
least
4,
which
still
satisfy
the requirement of (1, 1)-del/sub good pair. Analogously,
(del, sub, del, sub), (del, sub, del, sub), (sub, del, sub, del),
and (sub, del, sub, del) are equivalent. (del, sub, sub, del)
and (del, sub, sub, del) are equivalent. (sub, del, del, sub) and
(sub, del, del, sub) are equivalent. We divide our discussion
into four non-equivalent subcases by the type of (U, V).
A. The Type of (U, V) is (del, del, sub, sub)
Assume the type value of (U, V) is (e1, e2, e3, e4). That is
to say, deletion of type value e1, deletion of type value e2,
substitution of type value e3, and substitution of type value e4
occur at Uj1, Vj2, Uj3, and Uj4, respectively. Referring to Fig.
7, e1 = f(U[j1−1,j1+1])−f(V[j1−1,j1]), e2 = f(U[j2,j2+1])−
Position:
1
2
j1−2
j1
j1+2
j2−2
j2
j2+2
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
Position:
1
2
j1−1
j1+1
j2−1
j2+1
j3−1
j3+1
j4−1
j4+1
m+2
|
{z
}
{e1, e1 − 1}
|
{z
}
{e1 + e2}
|
{z
}
{e1 + e2 + e3}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 7. The type of (U, V) is (del, del, sub, sub).
f(V[j2−1,j2+1]), e3 = f(U[j3−1,j3+1]) − f(V[j3−1,j3+1]),
e4 = f(U[j4−1,j4+1]) − f(V[j4−1,j4+1]). We discuss fi for
i ∈ [m + 2] in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1,
fi =f(U[j1−1,j1]) − f(V[j1−1,j1])
=f(U[j1−1,j1+1]) − f(V[j1−1,j1]) − f(U[j1,j1+1])
=e1 − f(U[j1,j1+1])
∈{e1, e1 − 1}.
• For i ∈ [j1 + 1, j2],
fi = e1 − f(V[i−1,i]) ∈ {e1, e1 − 1}.
• For i ∈ [j2 + 1, j3 − 1], fi = e1 + e2.
• For i = j3, fi necessitates individual discussion. How-
ever, we only need to use fi ∈ {e1 +e2 +1, e1 +e2, e1 +
e2 − 1} in this subcase.
• For i ∈ [j3 + 1, j4 − 1], fi = e1 + e2 + e3.
• For i = j4, fi necessitates individual discussion. How-
ever, we only need to use fi ∈ {e1 + e2 + e3 + 1, e1 +
e2 + e3, e1 + e2 + e3 − 1} in this subcase.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2)) + σ((fj2+1, · · · , fj3))
+ σ((fj3+1, · · · , fm+2))
=3,
which implies x = y.
B. The Type of (U, V) is (del, sub, del, sub)
Assume the type value of (U, V) is (e1, e2, e3, e4). That
is to say, deletion of type value e1, substitution of type
value e2, deletion of type value e3, and substitution of
type value e4 occur at Uj1, Uj2, Vj3, and Uj4, respectively.
Referring to Fig. 8, e1 = f(U[j1−1,j1+1]) − f(V[j1−1,j1]),
e2 = f(U[j2−1,j2+1]) − f(V[j2−2,j2]), e3 = f(U[j3,j3+1]) −
f(V[j3−1,j3+1]), e4 = f(U[j4−1,j4+1]) − f(V[j4−1,j4+1]). We
discuss fi for i ∈ [m + 2] in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1,
fi =f(U[j1−1,j1]) − f(V[j1−1,j1])
=f(U[j1−1,j1+1]) − f(V[j1−1,j1]) − f(U[j1,j1+1])
=e1 − f(U[j1,j1+1])
∈{e1, e1 − 1}.
• For i ∈ [j1 + 1, j2 − 1],
fi = e1 − f(V[i−1,i]) ∈ {e1, e1 − 1}.
• For i = j2,
fi =e1 + f(U[j2−1,j2]) − f(V[j2−2,j2])
=e1 + f(U[j2−1,j2+1]) − f(V[j2−2,j2])
− f(U[j2,j2+1])
=e1 + e2 − f(U[j2,j2+1])
∈{e1 + e2, e1 + e2 − 1}.
• For i ∈ [j2 + 1, j3],
fi = e1 + e2 − f(V[i−1,i]) ∈ {e1 + e2, e1 + e2 − 1}.
• For i ∈ [j3 + 1, j4 − 1], fi = e1 + e2 + e3.
• For i = j4, fi necessitates individual discussion. How-
ever, we only need to use fi ∈ {e1 + e2 + e3 + 1, e1 +
e2 + e3, e1 + e2 + e3 − 1} in this subcase.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2−1)) + σ((fj2, · · · , fj3))
+ σ((fj3+1, · · · , fm+2))
=3,
which implies x = y.
Position:
1
2
j1−2
j1
j1+2
j2−1
j2+1
j3−1
j3+1
j4−1
j4+1
m+2
Position:
1
2
j1−1
j1+1
j2−2
j2
j2+2
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
|
{z
}
{e1, e1 − 1}
|
{z
}
{e1 + e2, e1 + e2 − 1}
|
{z
}
{e1 + e2 + e3}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 8. The type of (U, V) is (del, sub, del, sub).
Position:
1
2
j1−2
j1
j1+2
j2−1
j2+1
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
Position:
1
2
j1−1
j1+1
j2−2
j2
j2+2
j3−1
j3+1
j4−1
j4+1
m+2
|
{z
}
{e1, e1 − 1}
|
{z
}
{e1 + e2, e1 + e2 − 1}
|
{z
}
{e1 + e2 + e3, e1 + e2 + e3 − 1}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 9. The type of (U, V) is (del, sub, sub, del).
C. The Type of (U, V) is (del, sub, sub, del)
Assume the type value of (U, V) is (e1, e2, e3, e4). That
is to say, deletion of type value e1, substitution of type
value e2, substitution of type value e3, and deletion of
type value e4 occur at Uj1, Uj2, Uj3, and Vj4, respectively.
Referring to Fig. 9, e1 = f(U[j1−1,j1+1]) − f(V[j1−1,j1]),
e2 = f(U[j2−1,j2+1])−f(V[j2−2,j2]), e3 = f(U[j3−1,j3+1])−
f(V[j3−2,j3]), e4
= f(U[j4,j4+1]) − f(V[j4−1,j4+1]). We
discuss fi for i ∈ [m + 2] in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1,
fi =f(U[j1−1,j1]) − f(V[j1−1,j1])
=f(U[j1−1,j1+1]) − f(V[j1−1,j1]) − f(U[j1,j1+1])
=e1 − f(U[j1,j1+1])
∈{e1, e1 − 1}.
• For i ∈ [j1 + 1, j2 − 1],
fi = e1 − f(V[i−1,i]) ∈ {e1, e1 − 1}.
• For i = j2,
fi =e1 + f(U[j2−1,j2]) − f(V[j2−2,j2])
=e1 + f(U[j2−1,j2+1]) − f(V[j2−2,j2])
− f(U[j2,j2+1])
=e1 + e2 − f(U[j2,j2+1])
∈{e1 + e2, e1 + e2 − 1}.
• For i ∈ [j2 + 1, j3 − 1],
fi = e1 + e2 − f(V[i−1,i]) ∈ {e1 + e2, e1 + e2 − 1}.
• For i = j3,
fi =e1 + e2 + f(U[j3−1,j3]) − f(V[j3−2,j3])
=e1 + e2 + f(U[j3−1,j3+1]) − f(V[j3−2,j3])
− f(U[j3,j3+1])
=e1 + e2 + e3 − f(U[j3,j3+1])
∈{e1 + e2 + e3, e1 + e2 + e3 − 1}.
• For i ∈ [j3 + 1, j4],
fi =e1 + e2 + e3 − f(V[i−1,i])
∈{e1 + e2 + e3, e1 + e2 + e3 − 1}.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Position:
1
2
j1−1
j1+1
j2−1
j2+1
j3−1
j3+1
j4−1
j4+1
m+2
Position:
1
2
j1−2
j1
j1+2
j2−2
j2
j2+2
j3−2
j3
j3+2
j4−2
j4
j4+2
m+2
|
{z
}
{e1}
|
{z
}
{e1 + e2, e1 + e2 − 1}
|
{z
}
{e1 + e2 + e3}
U =
· · ·
· · ·
· · ·
· · ·
· · ·
V =
· · ·
· · ·
· · ·
· · ·
· · ·
Fig. 10. The type of (U, V) is (sub, del, del, sub).
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2−1)) + σ((fj2, · · · , fj3−1))
+ σ((fj3, · · · , fm+2))
=3,
which implies x = y.
D. The Type of (U, V) is (sub, del, del, sub)
Assume the type value of (U, V) is (e1, e2, e3, e4). That
is to say, substitution of type value e1, deletion of type
value e2, deletion of type value e3, and substitution of type
value e4 occur at Uj1, Uj2, Vj3, and Uj4, respectively. Re-
ferring to Fig. 10, e1 = f(U[j1−1,j1+1]) − f(V[j1−1,j1+1]),
e2 = f(U[j2−1,j2+1]) − f(V[j2−1,j2]), e3 = f(U[j3,j3+1]) −
f(V[j3−1,j3+1]), e4 = f(U[j4−1,j4+1]) − f(V[j4−1,j4+1]). We
discuss fi for i ∈ [m + 2] in this subcase.
• For i ∈ [1, j1 − 1], fi = 0.
• For i = j1, fi necessitates individual discussion. How-
ever, we only need to use fi ∈ {e1 +1, e1, e1 −1} in this
subcase.
• For i ∈ [j1 + 1, j2 − 1], fi = e1.
• For i = j2,
fi =e1 + f(U[j2−1,j2]) − f(V[j2−1,j2])
=e1 + f(U[j2−1,j2+1]) − f(V[j2−1,j2])
− f(U[j2,j2+1])
=e1 + e2 − f(U[j2,j2+1])
∈{e1 + e2, e1 + e2 − 1}.
• For i ∈ [j2 + 1, j3],
fi = e1 + e2 − f(V[i−1,i]) ∈ {e1 + e2, e1 + e2 − 1}.
• For i ∈ [j3 + 1, j4 − 1], fi = e1 + e2 + e3.
• For i = j4, fi necessitates individual discussion. How-
ever, we only need to use fi ∈ {e1 + e2 + e3 + 1, e1 +
e2 + e3, e1 + e2 + e3 − 1} in this subcase.
• For i ∈ [j4 + 1, m + 2], fi = 0.
Noting that e1, e2, e3 ∈ {2, 0, −2}, we obtain
σ(F(X) − F(Y))
≤σ(F(U) − F(V))
≤σ((f1, · · · , fj2−1)) + σ((fj2, · · · , fj3))
+ σ((fj3+1, · · · , fm+2))
=3,
which implies x = y.
VII. CONCLUSION
The crucial aspects of this paper center around the em-
ployment of error segmentation technique, enabling a rigorous
classification into types and type values for (s, r)-del/sub
good pair (U, V). Furthermore, our discussions are primarily
confined to the type of (U, V). For each type, we proceed to
set its type value to conduct unified analysis, which greatly
reduces the burden of discussions.
APPENDIX
PROOF OF LEMMA 2
The
main
focus
of
our
approach
is
on
segmenta-
tion technique. Assume that the sequence obtained by
deleting Xl1, · · · , Xls
and substituting Xls+1, · · · , Xls+2r
from X is equal to the sequence obtained by deleting
Yls+2r+1, · · · , Yl2s+2r
from Y where l1, l2, · · · , l2s+2r
∈
[2, n + 1]. Therefore, for any α ∈ [n + 2]\{l1, · · · , ls},
there exists a unique β ∈ [n + 2]\{ls+2r+1, · · · , l2s+2r} such
that Xα and Yβ are matched. We claim that, if all matched
Xα and Yβ satisfy
(
α ≤ i
β ≤ j
or
(
α ≥ i + 1
β ≥ j + 1
where 1 ≤
i, j ≤ n + 1, then we can apply segmentation technique to
separate X[i] and X[i+1,n+2], as well as Y[j] and Y[j+1,n+2],
simultaneously. Specifically, we can add an appropriate non-
empty sequence z between Xi and Xi+1 to alter X into
X′, and between Yj and Yj+1 to alter Y into Y′. With this
segmentation in place, f(X) − f(Y) = f(X′) − f(Y′) and
σ(F(X) − F(Y)) ≤ σ(F(X′) − F(Y′)) hold. Noting that all
Position:
i
i+1
j
j+1
j+2
2j−i+1
2j−i+2
Position:
i
i+1
j
j+1
2j−i
2j−i+1
2j−i+2
|
{z
}
The added z in X
|
{z
}
The added z in Y
X′ =
· · ·
Xi
Xi+1
· · ·
Xj
Yj
Xi+1
· · ·
Xj
Xj+1
Y′ =
· · ·
Yi
Yi+1
· · ·
Yj
Xi+1
· · ·
Xj
Yj
Yj+1
Fig. 11. The segmentation technique.
Position:
1
2
3
4
5
X = 0
0
0
1
0
Y = 0
1
1
1
0
Position:
1
2
3
4
5
6
7
8
X′ = 0
0
0
1
1
1
1
0
Y′ = 0
1
1
1
1
1
1
0
Fig. 12. Apply segmentation technique to separate l2 and l3 for X = 00010 and Y = 01110.
matched Xα and Yβ satisfy
(
α ≤ i
β ≤ j
or
(
α ≥ i + 1
β ≥ j + 1
, the
added zs in X and Y can be mutually matched.
Case 1: i = j. We discuss the values of Xi, Xi+1, Yi, and
Yi+1 to determine the added z. If
(
Xi = a
Yi = a
,
(
Xi+1 = a
Yi+1 = a
,
or
(
Xi = Yi+1 = a
Yi = Xi+1 = b
, we select aa as z. Otherwise, for
(
Xi = Xi+1 = a
Yi = Yi+1 = b
, we select ab as z. One can easily verify
f(X′
[k]) − f(Y′
[k]) = f(X[k]) − f(Y[k]) for 1 ≤ k ≤ i and
f(X′
[k]) − f(Y′
[k]) = f(X[k−2]) − f(Y[k−2]) for i + 3 ≤ k ≤
n+4. As a result, F(X)−F(Y) is a subsequence of F(X′)−
F(Y′) which implies σ(F(X)−F(Y)) ≤ σ(F(X′)−F(Y′)).
Case 2: i < j. As shown in Fig. 11, we select X[i+1,j]Yj
as z. Clearly, f(X′
[k]) − f(Y′
[k]) = f(X[k]) − f(Y[k]) for
1 ≤ k ≤ j. For k = 2j − i + 2,
f(X′
[k]) − f(Y′
[k])
=(f(X[j]) + f(XjYj) + f(YjXi+1) + f(X[i+1,j+1]))
− (f(Y[j]) + f(YjXi+1) + f(X[i+1,j]) + f(XjYj)
+ f(Y[j,j+1]))
=f(X[j+1]) − f(Y[j+1]).
Therefore,
f(X′
[k]) − f(Y′
[k])
=
f(X[k−(j−i+1)]) −
f(Y[k−(j−i+1)]) for 2j − i + 2 ≤ k ≤ n + j − i + 3. As
a result, F(X) − F(Y) is a subsequence of F(X′) − F(Y′)
which implies σ(F(X) − F(Y)) ≤ σ(F(X′) − F(Y′)).
Case 3: i > j. Similar to the discussion in Case 2, we select
Y[j+1,i]Xi as z.
Fig. 12 is an extreme example to illustrate its effectiveness.
Let X = 00010 and Y = 01110. Then X[5]\{l1,l2} =
Y[5]\{l3,l4} where l1 = 2, l2 = 3, l3 = 3, and l4 = 4. At
the beginning, l1, l2, l3, and l4 are in very close proximity to
each other. We demonstrate the separation of l2 and l3. For
i = 4 and j = 2, all matched Xα and Yβ (i.e., X1 with Y1, X4
with Y2, and X5 with Y5) satisfy
(
α ≤ i
β ≤ j
or
(
α ≥ i + 1
β ≥ j + 1
.
According to Case 3, we add z = Y[3,4]X4 = 111 between X4
and X5, as well as between Y2 and Y3, with initial separation
of l2 and l3 completed. By implementing additional rounds of
segmentation technique, we can obtain U and V that satisfy
the requirements of Lemma 2.
REFERENCES
[1] K. A. S. Abdel-Ghaffar, F. Palunˇci´c, H. C. Ferreira, and W. A. Clarke,
“On Helberg’s generalization of the Levenshtein code for multiple
deletion/insertion error correction,” IEEE Trans. Inf. Theory, vol. 58,
no. 3, pp. 1804–1808, 2012.
[2] J. Brakensiek, V. Guruswami, and S. Zbarsky, “Efficient low-
redundancy codes for correcting multiple deletions,” IEEE Trans. Inf.
Theory, vol. 64, no. 5, pp. 3403–3410, 2018.
[3] R. Gabrys and F. Sala, “Codes correcting two deletions,” IEEE Trans.
Inf. Theory, vol. 65, no. 2, pp. 965–974, 2019.
[4] R. Gabrys, V. Guruswami, J. Ribeiro, and K. Wu, “Beyond single-
deletion correcting codes: substitutions and transpositions,” IEEE
Trans. Inf. Theory, vol. 69, no. 1, pp. 169–186, 2023.
[5] V. Guruswami and J. Håstad, “Explicit two-deletion codes with redun-
dancy matching the existential bound,” IEEE Trans. Inf. Theory, vol.
67, no. 10, pp. 6384–6394, 2021.
[6] R. Heckel, G. Mikutis, and R. N. Grass, “A characterization of the
DNA data storage channel,” Sci. Rep., vol. 9, no. 1, p. 9663, 2019.
[7] A. S. J. Helberg and H. C. Ferreira, “On multiple insertion/deletion
correcting codes,” IEEE Trans. Inf. Theory, vol. 48, no. 1, pp. 305–
308, 2002.
[8] V. I. Levenshtein, “Binary codes capable of correcting deletions,
insertions, and reversals,” Soviet Phys. Doklady, vol. 10, no. 8, pp.
707–710, 1966.
[9] V. I. Levenshtein, “Asymptotically optimum binary code with correc-
tion for losses of one or two adjacent bits,” Problems of Cybernetics,
vol. 19, pp. 298–304, 1967.
[10] F. Palunˇci´c, T. G. Swart, J. H. Weber, H. C. Ferreira, and W. A. Clarke,
“A note on non-binary multiple insertion/deletion correcting codes,” in
Proc. IEEE Inf. Theory Workshop (ITW), pp. 683–687, 2011.
[11] F. Palunˇci´c, K. A. S. Abdel-Ghaffar, H. C. Ferreira, and W. A. Clarke,
“A multiple insertion/deletion correcting code for run-length limited
sequences,” IEEE Trans. Inf. Theory, vol. 58, no. 3, pp. 1809–1824,
2012.
[12] J. Sima, N. Raviv, and J. Bruck, “Two deletion correcting codes from
indicator vectors,” IEEE Trans. Inf. Theory, vol. 66, no. 4, pp. 2375–
2391, 2020.
[13] J. Sima and J. Bruck, “On optimal k-deletion correcting codes,” IEEE
Trans. Inf. Theory, vol. 67, no. 6, pp. 3360–3375, 2021.
[14] I. Smagloy, L. Welter, A. Wachter-Zeh, and E. Yaakobi, “Single-
deletion single-substitution correcting codes,” IEEE Trans. Inf. Theory,
vol. 69, no. 12, pp. 7659–7671, 2023.
[15] W. Song, K. Cai, and T. T. Nguyen, “List-decodable codes for single-
deletion single-substitution with list-size two,” in Proc. IEEE Int. Symp.
Inf. Theory (ISIT), pp. 1004–1009, 2022.
[16] W. Song, N. Polyanskii, K. Cai, and X. He, “Systematic codes correct-
ing multiple-deletion and multiple-substitution errors,” IEEE Trans. Inf.
Theory, vol. 68, no. 10, pp. 6402–6416, 2022.
[17] W. Suza, D. Lee, P. Becraft, and M. Hanneman, DNA Muta-
tions [Online]. Available: https://iastate.pressbooks.pub/genagbiotech/
chapter/dna-mutations
[18] R. R. Varshamov and G. M. Tenengolts, “Codes which correct single
asymmetric errors,” Avtomatica i Telemekhanika, vol. 26, no. 2, pp.
288–292, 1965.
","The literature review provides an overview of existing coding techniques for correcting insertion, deletion, and substitution errors, highlighting their strengths and limitations. It discusses the significance of Levenshtein's VT codes as the foundation for many subsequent code constructions.

The review then focuses on recent advancements in codes for correcting multiple-insertion/deletion errors, single-deletion multiple-substitution errors, and single-deletion single-substitution errors. It acknowledges the progress made in reducing the redundancy of these codes but emphasizes that there is still room for improvement. This sets the stage for the introduction of our proposed 2-ins/del/sub correcting codes in the subsequent sections.nan"
"Traditional location privacy protection mechanisms often focus solely on protecting individual locations and ignore the temporal correlation between different locations on a trajectory. This paper proposes a personalized trajectory privacy protection mechanism (PTPPM) that considers the temporal correlation between locations on a trajectory. It combines geo-indistinguishability and distortion privacy to improve the privacy protection level. Moreover, PTPPM enables personalized privacy protection by adjusting privacy parameters. It also develops a new location perturbation mechanism, Permute-and-Flip, to achieve a smaller perturbation distance and better balance location privacy and QoS. Simulation results demonstrate that PTPPM outperforms the benchmark mechanism PIVE in terms of privacy protection and QoS.","Location-based services (LBSs) in vehicular ad hoc networks (VANETs) offer convenience, but raise privacy concerns due to the extensive use of location information. Existing research on location privacy protection often focuses on individual locations, overlooking the temporal correlation between locations, which attackers can exploit. Moreover, different users may have varying privacy requirements. This paper aims to address these issues by proposing a personalized trajectory privacy protection mechanism (PTPPM).","The PTPPM framework involves determining the possible location set for each time instant, identifying a protection location set (PLS) for each location using the Hilbert curve-based minimum distance search algorithm, and employing a novel Permute-and-Flip mechanism for location perturbation.",Simulation results show that PTPPM achieves personalized trajectory privacy protection and outperforms the PIVE mechanism in terms of privacy protection while meeting users' QoS requirements.,"The proposed PTPPM effectively protects user trajectory privacy by considering temporal correlation, providing personalized privacy protection, and employing a novel location perturbation mechanism. It offers improved privacy protection compared to PIVE under the same QoS loss.",Protecting Personalized Trajectory with Differential Privacy under Temporal Correlations,"Mingge Cao, Haopeng Zhu, Minghui Min, Yulu Li, Shiyin Li, Hongliang Zhang, Zhu Han","arXiv:2401.11225v1  [cs.CR]  20 Jan 2024
Protecting Personalized Trajectory with Differential
Privacy under Temporal Correlations
Mingge Cao∗, Haopeng Zhu∗, Minghui Min∗†, Yulu Li∗, Shiyin Li∗, Hongliang Zhang‡, and Zhu Han§
∗ School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.
† Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education and School of
CyberScience and Engineering, Wuhan University, Wuhan 430072, China.
‡ School of Electronics, Peking University, Beijing 100871, China.
§ Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77004, USA.
Abstract—Location-based services (LBSs) in vehicular ad hoc
networks (VANETs) offer users numerous conveniences. However,
the extensive use of LBSs raises concerns about the privacy of
users’ trajectories, as adversaries can exploit temporal correla-
tions between different locations to extract personal information.
Additionally, users have varying privacy requirements depending
on the time and location. To address these issues, this paper
proposes a personalized trajectory privacy protection mechanism
(PTPPM). This mechanism ﬁrst uses the temporal correlation
between trajectory locations to determine the possible location
set for each time instant. We identify a protection location
set (PLS) for each location by employing the Hilbert curve-
based minimum distance search algorithm. This approach incor-
porates the complementary features of geo-indistinguishability
and distortion privacy. We put forth a novel Permute-and-Flip
mechanism for location perturbation, which maps its initial
application in data publishing privacy protection to a location
perturbation mechanism. This mechanism generates fake loca-
tions with smaller perturbation distances while improving the
balance between privacy and quality of service (QoS). Simulation
results show that our mechanism outperforms the benchmark by
providing enhanced privacy protection while meeting user’s QoS
requirements.
Index Terms—Location-based service, temporal correlation,
trajectory privacy protection, differential privacy.
I. INTRODUCTION
Location-based services (LBSs) in vehicular ad hoc net-
works (VANETs), such as real-time trafﬁc information reports
and personalized navigation, signiﬁcantly enhance our daily
lives [1], [2]. However, to enjoy these convenient services,
VANET users must provide their real-time location to the
LBS server, raising concerns about privacy breaches [3].
Several location privacy protection mechanisms have been
developed to address this issue. However, focusing solely on
protecting location information is insufﬁcient. Trajectory data,
which consists of interconnected locations, holds valuable
temporal information that potential attackers can exploit to
This research was funded by the National Natural Science Foundation of
China (grant number 62101557 and 62371451), and Xuzhou Basic Research
Plan Project-Young Scientiﬁc and Technological Talent Project (KC23022),
and China Postdoctoral Science Foundation (2022M713378), and the Fun-
damental Research Funds for the Central Universities (2042022kf0021),
and NSF CNS-2107216, CNS-2128368, CMMI-2222810, ECCS-2302469, US
Department of Transportation, Toyota and Amazon. Corresponding author:
Minghui Min (minmh@cumt.edu.cn).
deduce users’ activities and uncover sensitive personal infor-
mation [4]. Besides, different users may have different location
privacy and quality of service (QoS) requirements [5], and
even the same user may have various sensitive information at
different times and locations, and thus have different privacy
protection demands. Therefore, ensuring the privacy of user
trajectories and meeting their personalized demands is of
utmost importance.
Most existing research focuses on privacy protection for
individual locations. For instance, a privacy notion called
geo-indistinguishability, based on differential privacy, is pro-
posed in [6]. This notion aims to protect a user’s location
within a certain radius, guaranteeing “generalized differential
privacy”. However, this approach overlooks arbitrary prior
knowledge that adversaries may possess, leading to potential
privacy leakage [7], and the degree of privacy protection is
not clearly deﬁned. To address these shortcomings, authors
in [8] combine geo-indistinguishability and expected inference
error, leveraging their complementary properties to propose a
personalized location privacy protection mechanism. However,
this approach still fails to consider the temporal correlation
between different locations on a trajectory.
A solution called “δ-location set” based differential privacy
is proposed in [9], which combines the location privacy
protection mechanism in [8] with the temporal correlation
between locations on a trajectory. However, this approach
assigns the same privacy budget to all locations and does not
cater to users’ personalized demands. A few trajectory privacy
protection schemes use k-anonymity [10] to achieve privacy
protection. These methods generalize and aggregate individual
trajectory data, ensuring the trajectory remains protected while
combining it with at least k − 1 other trajectories to form
an anonymous region. However, these approaches rely on a
trusted third party and fail to provide strict privacy guarantees
[11], [12]. In summary, existing trajectory privacy protection
schemes lack consideration of crucial aspects such as the
temporal correlation between locations on a trajectory, meeting
the user’s personalized needs, and ensuring the protection of
the user’s actual location without relying on a trusted third
party. Consequently, a novel trajectory privacy mechanism is
needed to simultaneously satisfy these requirements.
In this paper, we develop a personalized trajectory privacy
protection mechanism (PTPPM) that considers the temporal
correlation between locations on a trajectory. The mechanism
constructs a location transition probability matrix, deriving the
potential location set for the user at each time point along the
trajectory. To improve privacy, we leverage the complementary
features of geo-indistinguishability [6] and distortion privacy
[13] by employing the Hilbert curve-based minimum distance
search algorithm [8] to identify a protection location set (PLS)
encompassing all potential locations along the trajectory. Geo-
indistinguishability can limit the attacker’s posterior knowl-
edge, but cannot quantify the similarity between the attacker’s
inferred location and the actual location. Distortion privacy
can ensure that the attacker’s expected inference error is
greater than a certain threshold. However, it cannot prevent
the leakage of posterior information. The combination of
these two notions can effectively strengthen the resistance
against location inference attacks. The mechanism also enables
personalized user privacy protection by adjusting the privacy
settings through two privacy parameters.
In addition, we introduce an extension of the Permute-
and-Flip mechanism [14], originally designed for data privacy
protection during data publishing, to serve as a location per-
turbation mechanism. This novel approach achieves a smaller
perturbation distance, which has a better balance between
location privacy and QoS. Simulation results demonstrate that
PTPPM provides personalized trajectory privacy protection
and offers superior privacy preservation compared to PIVE [8]
under the same QoS loss. The main contributions of our work
include:
1) We propose a personalized trajectory privacy protec-
tion mechanism called PTPPM, which can defend the
attacker that obtains the temporal correlation between
various locations within a trajectory. This mechanism
combines two privacy notions of geo-indistinguishability
and distortion privacy to enhance the system’s robustness
against location inference attacks.
2) We put forth a novel location perturbation mechanism,
Permute-and-Flip. It has a smaller perturbation distance
to release perturbed locations, thereby achieving a better
balance between location privacy and QoS.
3) We conduct comprehensive simulations to study the im-
pact of different privacy budgets and expected inference
errors on users’ personalized requirements. Additionally,
we demonstrate the performance advantage of PTPPM
over PIVE under the same QoS loss.
The remainder of this paper is organized as follows. Section
II presents the system model. We present the trajectory privacy
protection statement in Section III. A PTPPM framework is
proposed in Section IV. The evaluation results are provided in
Section V. Finally, we conclude this work in Section VI.
II. SYSTEM MODEL
To obtain real-time LBSs, we consider that VANET users
share their location information with a roadside unit (RSU) or
an LBS server at different times and locations [5], [15]. Users

LBS server 
Attacker 
A
B
C
Park
Hotel
Hospital
RSU
RSU
RSU
or
Fig. 1. Illustration of the trajectory privacy protection.
interact with the RSU to access road information, plan their
destinations, and determine driving routes. Fig. 1 illustrates
the user’s driving trajectory, where A, B, and C are the
user’s locations at different times. To protect privacy, the user
releases the perturbed locations. The untrusted LBS server,
which an external attacker might also corrupt, can infer the
user’s sensitive information (e.g., the user’s driving trajectory)
at a particular time by analyzing the received temporally
correlated location information and sending related spam or
scams while providing feedback services.
A. User Model
We consider VANET users driving within a speciﬁc area
of a city, which is divided into multiple grids. Each grid cell
represents a distant location state of the user, and each cell
is associated with a unique 2D coordinate. The state of all
locations of the user in the area is A = {a1, a2, · · ·, an},
where n is the total number of location states. xt represents
the user’s true location at time t, and lt represents the two-
dimensional coordinates of the user’s location state at time t.
For example, a shown in Fig. ??, A = {a1, a2, · · ·, a22},
xt = a6 = [0, 0, 0, 0, 0, 1, 0 · ··, 0], lt = [2, 4].
The user uses the location perturbation mechanism to remap
the actual location xt from the actual location set O1 to the
fake location x
′
t from the perturbed location set O2. The
location perturbation probability distribution f is given by
f

x
′
t|xt

= Pr

O2 = x
′
t|O1 = xt

,
xt, x
′
t ∈ A.
(1)
We use pt to represent the user’s location state at time t, where
pt [i] = Pr (xt = ai) = Pr (lt) represents the probability
that the user’s real location is in ai at time t. Assuming
that users are distributed with the same probability A =
{a2, a3, a5, a7}, then the location probability distribution
of users is pt = [0, 0.25, 0.25, 0, 0.25, 0, 0.25, 0, ·· ·, 0]. We
use p−
t
and p+
t
to represent the prior and posterior proba-
bilities of the user before and after observing the released
perturbed location x
′
t.
B. Attack Model
We consider the attacker to be an untrusted LBS server
or an external attacker who may attack or corrupt the LBS



















 













x
y

Fig. 2. User map coordinates and status coordinates.
server. They can access users’ current location information
for commercial proﬁt or illegal purposes. We assume that the
attacker knows the location perturbation probability distribu-
tion f

x
′
t|xt

, and can obtain the prior distribution p−
t
=
Pr (xt) of the user’s current location through public tracking,
check-in data set, or statistical information [16]. Then, the
attacker can calculate the posterior probability distribution
p+
t = Pr

xt|x
′
t

after observing the user’s reported location
x
′
t, i.e.,
p+
t = Pr

xt|x
′
t

=
Pr (xt) f

x
′
t|xt

P
xt∈A Pr (xt) f
According to the lower bound on expected inference error,
ExpEr

x
′
t

≥ e−ǫE (Φt) ,
(9)
the authors in [8] (Theorem 1) obtain a sufﬁcient condition,
E (Φt) ≥ eǫEm,
(10)
to satisfy the user-deﬁned threshold, ∀x
′
t, ExpEr

x
′
t

≥
Em.
D. Problem Statement
Considering the temporal correlation between locations on
the trajectory, it is insufﬁcient to protect only the user’s current
location, as attackers can still deduce the actual location
by analyzing behavior patterns, geographical constraints, and
other available information. Assuming the attacker possesses
knowledge of the user’s location transition probability matrix
M, they can calculate the prior probability of the user’s current
location based on previously published location information.
To enhance the protection of the user’s current location, we
focus on protecting frequently visited locations with high prior
probabilities [9].
Moreover, different types of LBS and varying contexts
may impose different users’ privacy requirements. Even for
the same LBS, users may have various privacy needs for
the same location at different times or in different locations.
Therefore, we determine the possible location set ∆χt for
each user at any given time based on the prior probability
of locations along the trajectory. By combining the concepts
of geo-indistinguishability and distortion privacy, we use a
Hilbert-based minimum distance search algorithm to identify
the set Φt of possible locations in ∆χt at any location along
the trajectory. We personalize user privacy by adjusting the
privacy budget ǫ and the expected inference error threshold
Em. To enhance performance, we adapt the Permute-and-Flip
mechanism, which was originally designed for data publishing
scenarios, to serve as the location perturbation mechanism.
IV. PRESONALIZED TRAJECTORY PRIVACY PROTECTION
MECHANISM
In this section, we propose a personalized trajectory privacy
protection mechanism PTPPM, as shown in Fig. 3. Here, we
consider the temporal correlation between different locations
on the trajectory and combine geo-indistinguishability and
distortion privacy to protect the user’s personalized trajectory
privacy. Speciﬁcally, we ﬁrst use algorithm F1 to obtain the
set of possible locations for the user at each time, leveraging
the associated prior probability at each moment along the
trajectory. Second, we employ algorithm F2 to dynamically
select PLS for each possible location on the trajectory, incor-
porating both geo-indistinguishability and distortion privacy.
Furthermore, our mechanism enables personalized trajectory
privacy protection by adjusting different privacy settings (min-
imum inference error and privacy budget) for individual users.
Finally, we put forth a novel Permute-and-Flip mechanism K
to generate a perturbed location x
′
t for each location within
į
Actual 
location
Em
K
Perturbed 
location
Minimum 
inference 
error
Privacy 
budget
Prior 
distribution
PLS






















































 














Fig. 3. The framework of PTPPM.
the PLS. These perturbed locations are selected with a smaller
perturbation distance, ensuring a better QoS experience while
providing robust and effective privacy protection.
A. Determine ∆χt at Continuous Times
The transition probability matrix M is constructed accord-
ing to the user’s historical trajectory data and behavior habits
[9]. We eliminate all impossible locations (p−
t is minimal or
p−
t = 0) based on certain criteria to obtain the set of possible
locations at time t, i.e., ∆χt. If the actual location at time t
is removed, we substitute it with ˜xt.
We calculate the posterior probability p+
t according to (2)
and then combine the location transition probability matrix M
according to (4) to obtain the prior probability p−
t+1 at time
t + 1. In terms of p−
t+1, we get ∆χt+1 at time t + 1. We
determine the size of ∆χt+1 by setting the value of δ. Then,
we obtain ∆χt at consecutive times by following the same
process.
B. Determine Protection Location Set
After obtaining ∆χt for each time on the trajectory, we
consider the protection of possible locations within ∆χt at
any given time.
In order to improve the user’s QoS, the smaller the diameter
D (Φt) of the circular area, the better. Since D (Φt) is the
diameter of the Φt, the distance between any two locations
is less than or equal to D (Φt). For ∀xt, ˆxt in Φt, we have
D (Φt) ≥ d (xt, ˆxt). By (10), we have
eǫEm ≤ E (Φt) ≤ min
ˆxt∈Φt
X
xt∈Φt
Pr (xt)
P
yt∈Φt Pr (yt)D (Φt) = D (Φt) .
(11)
To effectively ﬁnd the PLS with the smallest diameter at
time t, the search method based on the Hilbert curve in [8]
is adopted. For each possible location xt in ∆χt on the
trajectory, we search the neighborhood of xt according to the
search direction of the Hilbert curve. We identify the PLS
for xt that satisﬁes (10) and select the one with the smallest
diameter as the PLS Φt.
On this basis, to prevent the single-direction search of
the Hilbert curve might lead to an unreasonable protection
area with a large diameter, we perform spatial rotation of
the Hilbert curve to improve the opportunity of ﬁnding a
PLS for each location xt with a smaller diameter. More
speciﬁcally, similar to [8] we rotate 90, 180, and 270 degrees
clockwise around the center point to generate three more
Hilbert curves. After rotation, search for PLS where the user’s
location is under different Hilbert curves. Then, the group with
the smallest diameter is selected from the four results as the
PLS.
C. Differentially Private Mechanism in Protection Location
Set
We put forth a new perturbation mechanism, Permute-and-
Flip, to release the perturbed location with a smaller pertur-
bation distance, which can better balance location privacy and
QoS. The Permute-and-Flip mechanism was initially devel-
oped to protect privacy in the data publishing process [14]. We
apply this mechanism for the ﬁrst time to protect the location
in the PLS Φt through the mapping relationship between
the utility function and the Euclidean distance. The Permute-
and-Flip mechanism always selects the query option with the
highest score when processing query options. Therefore, we
take the difference between its distance and the maximum
distance as a query function and deﬁne the sensitivity of the
utility function as
∆u =
max max
x′
t∈A,xt,yt∈Φt
d

xt, x
′
t

− d

yt, x
′
t
 ,
(12)
according
to
the
triangle
inequality,
we
have
d

xt, x
′
t

− d

yt, x
′
t
 ≤ d (xt, yt) ≤ D (Φt).
After obtaining ∆χt for each location on the trajectory,
we can ﬁnd the corresponding Φt for each possible location
in ∆χt using (10). Given the current location xt and the
PLS Φt, the probability of the output perturbed location
x
′
t is proportional to exp

−ǫ(u(D,r)−max(u(D,r)))
2∆u

according
to the Permute-and-Flip mechanism. We have the perturbed
locations’ probability distribution
f

x
′
t|xt

= ωx exp


−ǫ

d

xt, x
′
t

− max d

xt, x
′
t

2D (Φt)

 , (13)
where ωx is the probability distribution normalization factor,
i.e.,
ωx =



X
x′
t∈A
exp


−ǫ

d

xt, x
′
t

− max d

xt, x
′
t

2D (Φt)





−1
.
(14)
V. SIMULATION RESULTS
In this section, we evaluate the effectiveness of our proposed
PTPPM. We compare the trajectory privacy performance of
PTPPM with that of PIVE [8] under the same QoS loss.
To facilitate evaluation, we divide the 50 km × 50 km two-
dimensional space evenly into 100 units, and each unit has
the same area. These units serve as areas that VANET users
may access, also known as the attacker’s prior distribution.
Each unit represents the location status of the user and has
corresponding two-dimensional coordinates. We select 5 of
them as the real locations of 5 consecutive moments on the
user’s trajectory, as depicted in Fig. 4.






NP
xkm
ykm
0
5
10
15
20
25
30
35
40
45
50
0
5
10
15
20
25
30
35
40
45
50
Park
Bank
Hotel
Hospital
LBS server
RSU
Fig. 4. Simulation setting of the trajectory of a user.
The location privacy p and QoS loss q are evaluated by the
similar metrics in our previous work [5] which are given by
p =
X
xt,x′
t,ˆxt∈A
Pr (xt)f

x
′
t|xt

h

ˆxt|x
′
t

d (xt, ˆxt) , (15)
q =
X
xt,x′
t∈A
Pr (xt)f

x
′
t|xt

d

xt, x
′
t

.
(16)
First, we set different privacy budgets ǫ and inference error
threshold Em to evaluate their impact on users’ personalized
trajectory privacy protection performance in Figs. 5. We can
see that two privacy parameters (ǫ and Em) have a signiﬁcant
impact on trajectory privacy and QoS loss. More speciﬁcally,
as shown in Figs. 5(a) and ??, when ǫ is small, the trajectory
privacy and QoS loss decrease with increased ǫ under different
Em. Besides, when ǫ is larger than a speciﬁc value, the
trajectory privacy and QoS loss start to increase. That is
because, according to (10), the increase of ǫ will cause D (Φt)
to sharply increase. The turning points under different Em
settings are different. Moreover, because D (Φt) cannot be in-
creased indeﬁnitely in practical scenarios, the location privacy
and QoS loss ﬁnally reach the upper limit value. Figs. 5(b) and
5(d) show that the trajectory privacy, QoS loss, and trajectory
error increase with the increase of Em under different ǫ. Given
a ǫ, when Em increases, the D (Φt) of the protected area
increases, thus increasing the trajectory privacy and QoS loss.
Moreover, the effect of ǫ on D (Φt) is exponential, much
higher than that of Em. Therefore, when ǫ is set to 1.5, with the
increase of Em, D (Φt) changes signiﬁcantly, so the trajectory
privacy and QoS loss increase sharply, resulting in a steep
curve. However, there is a limitation on the D (Φt) of the
protected area, so the trajectory privacy and QoS loss will
converge to a ﬁnite value. We can see that the user’s trajectory
privacy and QoS loss reach the upper limit when ǫ is 0.1,
regardless of the Em setting. By adjusting different privacy
settings, personalized trajectory privacy protection is realized.
Next, we quantitatively compare PF with PIVE in terms of
trajectory privacy and QoS loss to verify its advantages. We set
(16) equal to the set QoS loss value, and the only variable in
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
34
36
38
40
42
44
46
48
50
52
Trajectory privacy
Em=0.7
Em=1.0
Em=1.5
Em=2.5
Em=3.5
(a) Trajectory privacy v.s. ǫ
0.5
1
1.5
2
2.5
3
3.5
4
Em
30
35
40
45
50
Trajectory privacy
=0.1
=0.7
=1.3
=1.5
=1.9
(b) Trajectory privacy v.s. Em
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
35
40
45
50
55
60
65
70
QoS loss
Em = 0.7
Em = 1.0
Em = 1.5
Em = 2.5
Em = 3.5
(c) QoS loss v.s. ǫ
0.5
1
1.5
2
2.5
3
3.5
4
Em
30
35
40
45
50
55
60
65
70
QoS loss
=0.1
=0.7
=1.3
=1.5
=1.9
(d) QoS loss v.s. Em
Fig. 5. Impact of ǫ and Em on personalized trajectory privacy protection.
44
46
48
50
52
54
56
58
60
62
64
QoS loss
32
34
36
38
40
42
44
46
48
50
Trajectory privacy
PTPPM
PIVE[8]
Fig. 6. Performance of different LPPMs under different QoS loss.
this equation is the privacy budget ǫ. By solving this equation,
ǫ corresponding to PF and PIVE can be obtained under the
same QoS loss. By substituting (15), the corresponding privacy
of PF and PIVE under the same QoS loss can be calculated.
As shown in Fig. 6, we can see that PF can better protect
privacy under the same QoS loss. For example, when QoS loss
= 44, the privacy value of PTPPM is 22.4% which is higher
than that of PIVE. That is because the proposed Permute-
and-Flip mechanism provides a smaller perturbation distance
while guaranteeing privacy demands in PLS. In addition, since
D (Φt) cannot be inﬁnitely enlarged in the actual scenario,
privacy eventually reaches the upper limit. We can see that
the proposed mechanism can better protect user privacy while
meeting users’ QoS requirements.
VI. CONCLUSION
In this paper, we have proposed a personalized trajectory
privacy protection mechanism PTPPM. This paper has three
novel contributions: First, we address the issue of attackers
exploiting the temporal correlation between different locations
to compromise user privacy. To mitigate this threat, we design
a robust trajectory privacy protection mechanism. Second, we
combined the privacy notions of geo-indistinguishability and
distortion privacy, enabling personalized privacy protection
by adjusting the privacy budget and the expected inference
error threshold to meet individual user needs. Third, we
proposed a novel perturbation mechanism, Permute-and-Flip,
which releases perturbed locations with smaller perturbation
distances to better balance the trajectory privacy and QoS.
Simulation results show that PTPPM offers improved privacy
protection under the same QoS loss compared to PIVE. For
instance, when QoS loss = 44, the privacy of PTPPM is 22.4%
higher than that of PIVE.
REFERENCES
[1] N. U. Saqib, S. U. R. Malik, A. Anjum, M. H. Syed, S. A. Moqurrab,
G. Srivastava, and J. C.-W. Lin, “Preserving privacy in the internet
of vehicles IoV: A novel group leader-based shadowing scheme using
blockchain,” IEEE Internet Things J., vol. 10, no. 24, pp. 21421–21430,
Jul. 2023.
[2] W. Wang, M. Min, L. Xiao, Y. Chen, and H. Dai, “Protecting semantic
trajectory privacy for vanet with reinforcement learning,” in Proc. IEEE
Int. Conf. Commun. (ICC), Shanghai, China, May 2019.
[3] M. Min, W. Wang, L. Xiao, Y. Xiao, and Z. Han, “Reinforce-
ment learning-based sensitive semantic location privacy protection for
VANETs,” China Commun., vol. 18, no. 6, pp. 244–260, Jun. 2021.
[4] J. Tang, H. Zhu, R. Lu, X. Lin, H. Li, and F. Wang, “DLP: Achieve
customizable location privacy with deceptive dummy techniques in LBS
applications,” IEEE Internet Things J., vol. 9, no. 9, pp. 6969–6984, Sep.
2021.
[5] M. Min, L. Xiao, J. Ding, H. Zhang, S. Li, M. Pan, and Z. Han, “3D
geo-indistinguishability for indoor location-based services,” IEEE Trans.
Wirel. Commun., vol. 21, no. 7, pp. 4682–4694, Dec. 2021.
[6] M. E. Andr´es, N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi,
“Geo-indistinguishability: Differential privacy for location-based sys-
tems,” in Proc. ACM SIGSAC Conf. Comput. & Commun. Secur., Berlin,
Germany, Nov. 2013.
[7] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.-
Y. Le Boudec, “Protecting location privacy: optimal strategy against
localization attacks,” in Proc. ACM Conf. Comput. Commun. Secur.,
Raleigh North, Carolina, Oct. 2012.
[8] L. Yu, L. Liu, and C. Pu, “Dynamic differential location privacy with
personalized error bounds.,” in Proc. 24th Annu. Netw. Distributed Syst.
Secur. Symp. (NDSS), San Diego, CA, Feb. 2017.
[9] Y. Xiao and L. Xiong, “Protecting locations with differential privacy
under temporal correlations,” in Proc. ACM SIGSAC Conf. Comput.
Commun. Secur., Denver, CO, Oct. 2015.
[10] L. Xing, X. Jia, J. Gao, and H. Wu, “A location privacy protection algo-
rithm based on double k-anonymity in the social internet of vehicles,”
IEEE Commun. Lett., vol. 25, no. 10, pp. 3199–3203, Oct. 2021.
[11] F. Jin, W. Hua, M. Francia, P. Chao, M. Orlowska, and X. Zhou, “A
survey and experimental study on privacy-preserving trajectory data
publishing,” IEEE Trans. Knowl. Data Eng., vol. 35, no. 6, pp. 5577–
5596, May 2022.
[12] L. Wu, C. Qin, Z. Xu, Y. Guan, and R. Lu, “TCPP: Achieving privacy-
preserving trajectory correlation with differential privacy,” IEEE Trans.
Inf. Forensics Secur., vol. 18, pp. 4006–4020, Jun. 2023.
[13] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux,
“Quantifying location privacy,” in Proc. IEEE Symp. Secur. Priv., Oak-
land, CA, May 2011.
[14] R. McKenna and D. R. Sheldon, “Permute-and-Flip: A new mechanism
for differentially private selection,” Adv. Neural. Inf. Process. Syst.,
vol. 33, pp. 193–203, Oct. 2020.
[15] S. Zeng, H. Zhang, B. Di, Z. Han, and L. Song, “Reconﬁgurable
intelligent surface (RIS) assisted wireless coverage extension: RIS
orientation and location optimization,” IEEE Commun. Lett., vol. 25,
no. 1, pp. 269–273, Sep. 2021.
[16] K. Chatzikokolakis, C. Palamidessi, and M. Stronati, “Constructing elas-
tic distinguishability metrics for location privacy,” Proc. Priv. Enhanc.
Technol., vol. 2015, no. 2, pp. 156–170, May 2015.
","Previous research on location privacy protection has employed geo-indistinguishability, expected inference error, and k-anonymity. However, these approaches lack consideration of temporal correlation, personalized privacy protection, and protection of the user's actual location. PTPPM aims to fill these gaps by combining geo-indistinguishability and distortion privacy, enabling personalized privacy protection, and utilizing a novel location perturbation mechanism.nan"
"We evaluate the robustness of state-of-the-art medical image segmentation models to adversarial attacks and find that they are indeed vulnerable, highlighting the need for better security in medical imaging settings.","Deep convolutional neural networks (CNNs) are revolutionizing medical imaging, aiding in disease diagnosis and treatment. Image segmentation is a particularly challenging task, as it requires capturing both global and local features. The U-Net family of architectures has shown great promise in this domain. However, recent studies have focused on model performance rather than security. Adversarial attacks can fool models into making incorrect predictions, raising grave consequences in medical contexts. This study analyzes the susceptibility of contemporary MRI image segmentation models to the Fast Gradient Sign Method (FGSM), a common adversarial attack.","Experiments were conducted using U-Net and U-Net++ architectures with various backbones, including VGG16, ResNeXt-101, and EfficientNet-B7. Segmentation masks were obtained from the University of Wisconsin-Madison's gastro-intestinal tract (UW-Madison GI Tract) MRI image dataset, preprocessed, and resized. Models were trained using a hybrid loss function combining Dice and Focal losses, and an AdamW optimizer with cosine annealing learning rate scheduler. Adversarial attacks were performed using FGSM with different loss functions to determine the most effective strategy. Results were evaluated using Dice Similarity Coefficient (DSC) and Attacking Success (AS) metrics.","All four models were significantly impacted by FGSM, with U-Net++ w/ EfficientNet-B7 being the most vulnerable. Contrary to the FGSM paper's suggestion, using binary cross entropy (BCE) loss for attack generation yielded higher success rates compared to the original loss function used for training. Interestingly, the number of model parameters did not correlate with attack success. The models' vulnerability highlights the need for robust security measures in medical imaging applications.","This study emphasizes the importance of addressing security concerns in medical image segmentation models. The findings underscore the effectiveness of FGSM attacks on modern models, especially when BCE loss is used for attack generation. Despite their high performance on clean inputs, the models were susceptible to adversarial attacks, potentially leading to misdiagnosis or inappropriate treatment in medical settings. Future work will explore more U-Net models, different attacks, and defense mechanisms to mitigate these vulnerabilities.",Susceptibility of Adversarial Attack on Medical Image Segmentation Models,"Zhongxuan Wang, Leo Xu","Susceptibility of Adversarial Attack on Medical
Image Segmentation Models
Zhongxuan Wang*
Saint Andrew’s School
Boca Raton, United States of America
cndanielwang@gmail.com
Leo Xu*
Lynbrook High School
San Jose, United States of America
leoxu27@gmail.com
Abstract—The nature of deep neural networks has given rise
to a variety of attacks, but little work has been done to address
the effect of adversarial attacks on segmentation models trained
on MRI datasets. In light of the grave consequences that such
attacks could cause, we explore four models from the U-Net
family and examine their responses to the Fast Gradient Sign
Method (FGSM) [1] attack.
We conduct FGSM attacks on each of them and experiment
with various schemes to conduct the attacks. In this paper,
we find that medical imaging segmentation models are indeed
vulnerable to adversarial attacks and that there is a negligible
correlation between parameter size and adversarial attack suc-
cess. Furthermore, we show that using a different loss function
than the one used for training yields higher adversarial attack
success, contrary to what the FGSM authors suggested. In future
efforts, we will conduct the experiments detailed in this paper
with more segmentation models and different attacks. We will
also attempt to find ways to counteract the attacks by using model
ensembles or special data augmentations. Our code is available
at https://github.com/ZhongxuanWang/adv attk
Index Terms—Adversarial attack, Fast Gradient Sign Method,
image segmentation, medical imaging, U-Net, U-Net++
I. INTRODUCTION
Today, deep convolutional neural networks (CNNs) [2] have
become increasingly popular in medical imaging, playing a
role in the classification brain tumors, detection of organ
boundaries, or segmentation of organ tumors. Since CNNs
can exploit the spatial information present in images [2], they
have been widely used in hospitals to provide doctors with
valuable insights at an increased speed. Among all the medical
imaging tasks, image segmentation is arguably one of the
more challenging ones since it needs to leverage both global
and local features to create masks for objects. While image
classification helps doctors know the class of the image as a
whole, and object detection helps doctors know the general
location of the object, image segmentation allows doctors to
see the boundaries of objects of interest clearly [3]. Their
differences are illustrated in Figure 1.
To leverage CNNs in biomedical image segmentation, Ron-
neberger et al. proposed U-Net, a revolutionary architecture
that consists of a contraction path and a symmetric expansion
path [4]. Recently, many variants of U-Net have been proposed
to achieve state-of-the-art (SOTA) performances in various
* Both authors contributed equally to this paper.
Fig. 1. Difference between image classification, object detection, and image
segmentation methods in the medical imaging field. Predictions are simulated
except for the image segmentation method.
medical imaging tasks. Examples of a few include nested U-
Nets, U-Nets with dense skip connections to learn full-scale
semantic information [5] [6], and U-Net with transformer-
based encoder or decoder to learn long-range semantic infor-
mation [7] [8]. These U-Net variants have all shown superior
performances over the original U-Net.
Although the U-Net family possesses great potential in im-
age segmentation for MRI data, recent studies have prioritized
model performance over security. In fact, a variety of attacks
have recently arisen to intentionally fool models into making
incorrect predictions with high confidence by modifying the
training dataset, testing dataset, model parameters, along oth-
ers [9]. Given the confidentiality of medical imaging datasets,
it is usually impractical to poison the training dataset an
MRI model was trained on or modify its parameters. Thus,
poisoning inference data is a much larger concern for doctors.
One of the methods for attacking inferencing data is known as
a white-box adversarial attack, which assumes that attackers
cannot modify the training data or the model but know about
the model such as its architecture and weights.
In the context of medical image segmentation, successful
adversarial attacks could incur hefty and irreversible conse-
quences. For instance, if poisoned tumor segmentations misled
doctors, doctors may overlook portions of tumor tissues that
could cause death. If doctors relied on compromised tumor
segmentation images to kill diseased tissues, both benign and
arXiv:2401.11224v1  [eess.IV]  20 Jan 2024
Fig. 2.
An example of adversarial attack on the medical MRI image
segmentation model.
vital parts of the organ may be damaged permanently. Unfor-
tunately, most doctors are not trained to discern poisoned data
from those unaffected, nor are they trained to take deterrent
measures. To make the matter worse, Ma et al. pointed out that
medical imaging models are more vulnerable to adversarial
attacks than other types of models [10]. Thus, studying the
effect of adversarial attacks on medical images has overarching
significance.
Most of the current research on adversarial attacks and re-
lated defense techniques only involve image classification [11]
[12], which outputs a confidence score for its classification. In
contrast, little research has been done adversarial attacks on
image segmentation tasks. Further, most papers [13] [14] [15]
exploring adversarial attacks on image segmentation datasets
have been done using the ImageNet [16] dataset. However,
those works haven’t explored medical datasets, which are
proven to be more vulnerable to adversarial attacks [10].
Other works using medical imaging segmentation datasets also
do not account for MRI datasets, which could reveal more
detailed features of soft tissues or nerves [17]. In addition,
most of such works have focused on testing lightweight models
that are no longer widely used in modern applications [18] [19]
[20], even though more recent models have proven to be in-
creasingly supceptible to adversarial attacks [21]. An example
of an adversarial attack on an MRI image segmentation model
is shown in Figure 2.
In light of the grave danger that poisoned MRI data could
pose and evident lack of research in this area, we test the
susceptibility of modern MRI image segmentation models to
a popular white-box adversarial attack method called Fast
Gradient Sign Method (FGSM). The main motivation behind
this research is to raise awareness in the academic community
on the security of the MRI image segmentation models. We
summarize the main contributions below:
1) Through experimenting with different losses to conduct
the FGSM attack, we show that using the BCE loss to
conduct the attack leads to greater success than using the
Fig. 3.
U-Net Architecture by Ronneberger et al. Here the architecture
assumes the input is 572 × 572
default loss as suggested by the FGSM paper’s author.
2) We show that having more parameters does not neces-
sarily make the model more vulnerable to attacks.
3) We show that FGSM can effectively mislead modern
image segmentation models models.
II. APPROACHES
In this section, we will describe the models we selected in
detail, the reasons behind those choices, the dataset we used,
our adversarial attacking strategy, and our training hyperpa-
rameters.
A. Model Architecture
In this section, we will introduce U-Net and U-Net++. We
will also describe why we chose to use VGG16, ResNeXt-101,
and EfficientNet-B7 as our backbones.
1) U-Net: U-Net, introduced by Ronneberger et al., is one
of the most commonly used image segmentation architectures
for biomedical imaging [4]. U-Net is a u-shaped network
containing a down-sampling path, a bottleneck, and an up-
sampling path (Figure 3). During each level of the down-
sampling path, the dimension of the image is contracted by
the max pooling layer, yet the number of feature channels
is expanded by a factor of two, which allows the network
to learn global features better. During each level of the up-
sampling path, the output of the previous layer is concatenated
with the output from the same level’s down-sampling path to
simultaneously fuse the global and local features necessary for
segmentation.
Among four of our models, three of them are U-Net based.
• U-Net: The first model is the basic U-Net with no
modified backbones. We use this model as our baseline.
• U-Net w/ ResNeXt-101: The second model is based
on the U-Net’s architecture, but the down-sampling path
is replaced by layers from a pre-trained ResNeXt101
32x8d model [22]. ResNeXt101 is a 101-layer variant of
Fig. 4. UNet++ Architecture by Zhou et al. UNet++ introduced dense skip
connections as highlighted in blue arrows and green arrows shown in the
graph. The model also introduced deep supervision as indicated by L, but in
our paper, this is excluded during training.
ResNeXt, which achieved second place in the ILSVRC
2016 classification competition [23].
• U-Net w/ EfficientNet-B7: The third model we use
is also based on the U-Net’s architecture, but the en-
coder layers are replaced by layers from a pre-trained
EfficientNet-B7 model [24]. EfficientNet-B7 is a com-
plex variant of the EfficientNet family, which achieves
SOTA efficiency by outperforming most models within
its domain with much higher efficiency [24]. Today,
EfficientNet-B7 is extensively used in industry and in
medical imaging competitions [25] [26] [27] [28].
2) UNet++: UNet++ by Zhou et al. introduces an im-
portant innovation to the U-Net network — dense skip
connections [5]. As shown in Figure 4, instead of naively
concatenating the feature map from each level of the encoder
layer X1,0, X2,0, X3,0 to the feature maps of the correspond-
ing decoder layer X2,2, X1,3, X0,4, intermediate dense skip
connections are introduced, as shown in green colored nodes
in Figure 4. Dense skip connections allow the model to learn
faster because the image representations are richer, and the
semantic gap is smaller.
The last trained model is U-Net++ based.
• UNet++ w/ EfficientNet-B7: The fourth model we used
is based on the U-Net++’s architecture and has an
EfficientNet-B7 backbone [24]. We choose EfficientNet-
B7 because our prior experiments show that a pre-trained
EfficientNet-B7 has a superior performance when used as
an encoder.
B. Datasets
All the models we use in our experiements were trained us-
ing University of Wisconsin-Madison’s gastro-intestinal tract
(UW-Madison GI Tract) MRI image segmentation dataset [29],
which is publicly available on Kaggle. The dataset is made up
of 272 workable 3D scans and 38208 images that are black-
TABLE I
DETAILED DATASET DISTRIBUTION.
Training (Slices)
Testing (Slices)
Total (slices)
Large Bowel Tumor
12,698
1,319
14,017
Small Bowel Tumor
9,955
1,174
11,129
Stomach Tumor
7,611
947
8558
Total
34,432 (90%)
3,776 (10%)
38,208
and-white. Segmentation masks are encoded in the run-length
encoding (RLE) format.
There are three classes in this dataset: large bowel (14,017
images), small bowel (11,129 images), and stomach (8,558 im-
ages). Instances chosen for training and testing datasets were
carefully picked to ensure they all have a similar distribution.
To prevent the data leakage problem, slices from individual
scans were grouped together and together either in the training
set or the testing set. The detailed dataset distribution is shown
in Table I.
1) Pre-processing: During pre-processing, all pixels were
normalized to range from [0, 1], and all images are resized to
224 × 224. (224 = 32 × 7).
C. Model Training
In this section, we will share the training parameters that
we used to conduct our experiments. All of our models were
trained without sufficient fine-tuning because we prioritized
analyzing the impact of adversarial attack over gaining the
best performances on normal input images for all models.
1) Hardware and Software: All four of our models were
trained on one Nvidia A6000 (48GB) instance with 14vCPUs
and 100 GiB RAM.
2) Hyperparameters:
All
models
were
trained
using
AdamW with an initial learning rate of 3e − 4 and a weight
decay of 1e − 3. We also used a cosine annealing learning
rate scheduler with max iterations of 7,081 and a maximum
learning rate of 3e−4. We trained all our models for 15 epochs
with early stopping. We used a batch size of 64 and applied
data augmentation on training images in the form of shifting,
scaling, and deformation.
For our U-Net models, instead of having the number of
kernels starting at 64 and growing by a factor of two until
1024, we modified it to have a kernel number beginning at 16
and ending at 256 because to make the model more efficient
during training.
3) Loss Function: All of the models in this paper were
trained using a hybrid loss that combined the Dice loss and
Focal loss, which helped to deal with class imbalance and
improve the performance of our models [30].
Let’s define y ∈ {0, 1} as the ground truth mask and ˆy ∈
[0, 1] as the predicted mask.
Dice loss (DL) [31] is defined in Formula 1. The Dice loss
is basically 1 − DSC. DSC is expanded in section III-A We
add 10−6 in the numerator and denominator to avoid division
by zero.
DL = 1 − 2 ×
yˆy + 10−6
y + ˆy + 10−6
(1)
Fig. 5. Input images and predictions with various ϵ values for our U-Net++
Model. Diff value is measured by the clean input metric score minus the
poisoned input metric score divided by the clean input metric score again.
Therefore, the more drastic the difference is, the more successful the attack
would be.
Focal loss (FL) [32] is defined in Formula 4. Focal loss
improves binary cross entropy (BCE) loss [33] by dealing
with the imbalanced dataset problem. We derive the focal
loss formula firstly by deriving the binary cross entropy loss
formula, as shown in Formula 3.
We define C, W, and H to indicate the number of channels,
the height, and width of the image. c ∈ [0..C), i ∈ [0..W),
and j ∈ [0..H) are indexes. For example, yc,i,j means the
pixel value of the mask y at channel index c, width index i,
and height index j.
So, we define ˆyt that for each pixel of y,
ˆyt
c,i,j =
(
ˆyc,i,j,
if yc,i,j = 1
1 − ˆyc,i,j,
if yc,i,j = 0
(2)
Therefore, binary cross entropy loss for image segmentation
can be defined in the formula below.
BCE(y, ˆy) = −
C
X
c=0
W
X
i=0
H
X
j=0
log(ˆyt
c,i,j)
(3)
Focal loss adds a modulating factor (1 − ˆyt)γ to BCE. γ
is a tunable hyperparameter. Setting γ > 0 will differentiate
focal loss from binary cross entropy loss. Setting γ > 1 would
make the model less sensitive to class imbalance, and setting
1 > γ > 0 would make the model more sensitive to class
imbalance.
FL(y, ˆy) = −
C
X
c=0
W
X
i=0
H
X
j=0
(1 − ˆyt
c,i,j)γ · log(ˆyt
c,i,j))
(4)
For all our experiments we set γ = 2.
D. Fast Gradient Sign Method
Goodfellow et al. proposed the Fast Gradient Sign Method
(FGSM), which would generate adversarial inputs by nudging
the input in the direction of the gradient with respect to the
input space. [1].
The FGSM attacking formula is provided below, where
advy is the adversarial image, θ is the parameters of the model,
Fig. 6.
Comparison of the predicted masks of four models. Three colors
in the predictions columns indicate three different objective classes. Model
differences to the ground-truth mask are also illustrated. For the differences,
true positive is highlighted in green, false positive is highlighted in blue, and
false negative is highlighted in red.
x is the input to the model, y is the prediction of the model,
J(θ, x, y) is the loss function of the model, sign is the sign
of the gradient with respect to the pixels used in the back-
propagation stage, and ϵ is the multiplier of the noise that
can be tuned to achieve a balance between stealthiness and
effectiveness. Figure 5 shows under different ϵ values, what
do the input image and the predicted mask look like. It shows
that the higher the ϵ value, the more successful the attack will
be, but the input image will loss the stealthiness as the attack
noises would become gradually visible.
Advy = x + ϵ ∗ sign(∇xJ(θ, x, y))
(5)
FGSM is a simple yet robust adversarial attack. The attack is
also illustrated in Figure 2. In this paper, we compared the
performance of all four of our segmentation models before
and after the FGSM attack. In all experiments, we use ϵ =
0.009 because, as shown in Figure 5, ϵ = 0.009 achieves both
stealthiness and effectiveness.
In the original FGSM paper, authors Goodfellow, Shlens,
and Szegedy, suggested that J(θ, x, y) should be the loss
function used to train the network [1]. However, during our
experiments, we found that using the original loss function led
to less effective attacks than using an alternative loss. For our
experiments, we found that using binary cross entropy (BCE)
loss function led to significant improvement in attacking
success.
III. RESULTS
The results are shown in Table II. Since there are some
false negative ground truth masks in this dataset, we only
test our models’ performance using the MRI slices that have
segmentation masks.
For our experiments, U-Net w/ ResNeXt-101 has the most
number of parameters, followed by U-Net++ w/ EfficientNet-
B7 and U-Net w/ EfficientNet-B7 models.
Fig. 7.
Adversarial attacks on four models. The first column contains the
poisoned inputs. The second column contains predictions using the poisoned
inputs. The third column indicates their differences. However, it should be
noted that for the first two models, we used a higher epsilon value, ϵ = 0.015,
for illustration purposes because the first two models are very resilient to the
attack. we also talk it briefly in future work section IV-A. For the differences,
true positive is highlighted in green, false positive is highlighted in blue, and
false negative is highlighted in red.
Fig. 8. Prediction masks showing the differences between the use of binary
cross entropy (BCE) loss, hybrid loss combining dice and focal loss, and focal
loss for an FGSM attack. Attacks were done on the U-Net++ w/ EfficientNet-
B7 model for the same image. Diff value is measured by the clean input metric
score minus the poisoned input metric score divided by the clean input metric
score again.
For normal inputs, U-Net++ with EfficientNet-B7 and U-
Net with EfficientNet-B7 models are the most successful
model among all with U-Net with EfficientNet-B7 model
performing slightly worse. Their predictions based on a normal
image input and their differences to the original mask are
illustrated in Figure 6. All four models predicted the masks
well with few false negatives and false positives.
However, all four models were all significantly impacted
by FGSM, instantly making them unreliable for doctors, as
shown in Figure 7.
Since FGSM attacks require a loss function to derive the
signs of the gradients, we also tested out three different loss
functions to see how the attack success varies. It turned out
that BCE had the highest success rate, despite the fact that our
original model was trained on a hybrid loss of focal and dice
loss. The comparison between three loss functions is shown
in Figure 8 FGSM achieves the highest success in U-Net++
w/ EfficientNet-B7 model in all three loss functions.
Our results also imply a negligible correlation between the
number of parameters and attack success rate. However, it is
worth noting that U-Net w/ EfficientNet-B7 and U-Net++ w/
EfficientNet-B7 models, which had the best performances for
clean inputs, were the most vulnerable to the FGSM attack.
U-Net++ w/ EfficientNet-B7 model has not only the best
performance but also the highest attacking success rate.
In addition, even though the authors of the FGSM paper
suggested to use the cost function used to train the model to
conduct the attack, empirical evidence suggests that it is not
true in this case. The original cost function used to train all
four models is the hybrid loss combing focal loss and dice
loss. As shown in Table II, combining focal loss and dice loss
to conduct the attack received the lowest attack success, yet
using binary cross entropy (BCE) loss to conduct the attack
yielded significantly higher attacking success.
A. Evaluation Metric
Dice Similarity Coefficient (DSC): To evaluate the mod-
els’ performance on testing data before and after applying
adversarial noise, we used DSC that would measure the
effectiveness of the overlap between the ground truth and
predicted mask. DSC is bounded between −1 and +1. [34]. Its
formula is defined below. y and ˆy are the ground-truth mask
and the predicted mask.
DSC = 2 × |y ∩ ˆy|
|y| + |ˆy|
(6)
Attacking Success (AS): To evaluate the effectiveness of the
adversarial attack, we created a metric that would measure
the percentage change in DSC, as shown in Formula 7. The
resulting value is a percentage between 0% and 100%, and
higher the AS the more successful the attack is.
AS = DSC Before Attack − DSC After Attack
DSC Before Attack
(7)
IV. DISCUSSIONS AND CONCLUSIONS
In this paper, we trained four advanced image segmentation
models from the U-Net family and examined the efficacy of
FGSM for poisoning MRI data to understand how vulnerable
they are to adversarial attacks. We observe that all the models
in this paper are heavily impacted by FGSM, stressing an
urgent need to enact serious security measures under profes-
sional environments. In addition, we observe that even though
the FGSM paper suggests using the loss function used to
train the model, using binary entropy loss as an alternative to
generate attacking noises under this context has consistently
demonstrated better attacking success rates. Lastly, we observe
TABLE II
COMPARISON OF THE PERFORMANCE BEFORE AND AFTER A FGSM
ATTACK WAS DONE ON OUR MODELS: U-NET WITH VGG13 (VGG
U-NET), U-NET WITH RESNEXT-101 (RESNEXT U-NET), U-NET WITH
EFFICIENTNET-B7 (EFFB7 U-NET), AND U-NET++ WITH
EFFICIENTNET-B7 (EFFB7 U-NET++) ON THE GI TRACT DATASET. ALL
MEASURED IN DICE SIMILARITY COEFFICIENT (DSC) SCORE.
ATTACKING SUCCESSES OF THREE LOSSES USED FOR FGSM ATTACK
WERE COMPARED. THE MOST SUCCESSFUL ATTACKS ARE HIGHLIGHTED
IN BOLD.
FGSM Using Loss
Model Names
Parameters
Normal
BCE
Focal+Dice
Focal
VGG U-Net
18.44M
0.7509
0.4063
0.5772
0.5105
ResNeXt U-Net
95.76M
0.7841
0.3873
0.6197
0.5560
EffB7 U-Net
67.10M
0.7994
0.4576
0.5348
0.5097
EffB7 U-Net++
68.16M
0.8024
0.3750
0.4705
0.4330
that having more parameters does not necessarily imply the
vulnerability of the model to adversarial attacks.
A. Future Work
In future studies, we will test the adversarial robustness of
more of U-Net models using various attacking methods. Doing
this would give the academic community a more complete
sense of what models are more susceptible to adversarial
attacks, and what types of adversarial attacks are likely be
successful.
During our experiment, we also noted that some models
are resilient to certain types of images, while others are not.
Specifically, we found out image luminosity seems to be an
important factor. We will conduct more experiments to find
out if there is a relationship between image brightness and
attack successes for certain models.
Finally, we will also test out the effectiveness of adversarial
attacks by ensembling all our trained models.
ACKNOWLEDGMENT
We thank our friends, parents, and teachers for constantly
supporting us throughout this process.
REFERENCES
[1] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
adversarial examples,” 2014.
[2] K. O’Shea and R. Nash, “An introduction to convolutional neural
networks,” 2015.
[3] “Image segmentation guide.” https://www.fritz.ai/image-segmentation/.
[4] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” 2015.
[5] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, and J. Liang, “Unet++: A
nested u-net architecture for medical image segmentation,” 2018.
[6] H. Huang, L. Lin, R. Tong, H. Hu, Q. Zhang, Y. Iwamoto, X. Han, Y.-
W. Chen, and J. Wu, “Unet 3+: A full-scale connected unet for medical
image segmentation,” 2020.
[7] J. Chen, Y. Lu, Q. Yu, X. Luo, E. Adeli, Y. Wang, L. Lu, A. L. Yuille, and
Y. Zhou, “Transunet: Transformers make strong encoders for medical
image segmentation,” 2021.
[8] H. Cao, Y. Wang, J. Chen, D. Jiang, X. Zhang, Q. Tian, and M. Wang,
“Swin-unet: Unet-like pure transformer for medical image segmenta-
tion,” 2021.
[9] Y. Li, Y. Jiang, Z. Li, and S.-T. Xia, “Backdoor learning: A survey,”
IEEE Transactions on Neural Networks and Learning Systems, pp. 1–
18, 2022.
[10] X. Ma, Y. Niu, L. Gu, Y. Wang, Y. Zhao, J. Bailey, and F. Lu,
“Understanding adversarial attacks on deep learning based medical
image analysis systems,” Pattern Recognition, vol. 110, p. 107332, feb
2021.
[11] X. Li and D. Zhu, “Robust detection of adversarial attacks on medical
images,” in 2020 IEEE 17th International Symposium on Biomedical
Imaging (ISBI), pp. 1154–1158, 2020.
[12] A. Subramanya, A. Saha, S. A. Koohpayegani, A. Tejankar, and H. Pir-
siavash, “Backdoor attacks on vision transformers,” 2022.
[13] J. H. Metzen, M. C. Kumar, T. Brox, and V. Fischer, “Universal
adversarial perturbations against semantic image segmentation,” in 2017
IEEE International Conference on Computer Vision (ICCV), pp. 2774–
2783, 2017.
[14] C. Xie, J. Wang, Z. Zhang, Y. Zhou, L. Xie, and A. Yuille, “Adversarial
examples for semantic segmentation and object detection,” 2017.
[15] A. Arnab, O. Miksik, and P. H. S. Torr, “On the robustness of semantic
segmentation models to adversarial attacks,” 2017.
[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
A large-scale hierarchical image database,” in 2009 IEEE Conference on
Computer Vision and Pattern Recognition, pp. 248–255, 2009.
[17] L.
M.
Fayad,
“Ct
scan
versus
mri
versus
x-ray:
What
type
of
imaging
do
i
need?.”
https://www.hopkinsmedicine.org/health/
treatment-tests-and-therapies/ct-vs-mri-vs-xray, Oct 2021.
[18] X. Kang, B. Song, X. Du, and M. Guizani, “Adversarial attacks for
image segmentation on multiple lightweight models,” IEEE Access,
vol. 8, pp. 31359–31370, 2020.
[19] S. Li, G. Huang, X. Xu, and H. Lu, “Query-based black-box attack
against medical image segmentation model,” Future Generation Com-
puter Systems, vol. 133, pp. 331–337, 2022.
[20] H. Kwon, “Medicalguard: U-net model robust against adversarially
perturbed images,” Security and Communication Networks, vol. 2021,
p. 1–8, 2021.
[21] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
and R. Fergus, “Intriguing properties of neural networks,” 2013.
[22] S. Xie, R. Girshick, P. Doll´ar, Z. Tu, and K. He, “Aggregated residual
transformations for deep neural networks,” 2016.
[23] S. Xie, R. B. Girshick, P. Doll´ar, Z. Tu, and K. He, “Aggregated residual
transformations for deep neural networks,” CoRR, vol. abs/1611.05431,
2016.
[24] M. Tan and Q. V. Le, “Efficientnet: Rethinking model scaling for
convolutional neural networks,” 2019.
[25] M.
Phan,
“Rsna-miccai
brain
tumor
radiogenomic
classification
2nd
place
solution.”
https://www.kaggle.com/competitions/
rsna-miccai-brain-tumor-radiogenomic-classification/discussion/
280033., July 2021.
[26] C.
Zhao,
“Uw-madison
gi
tract
image
segmentation
1st
place
winning
solution.”
https://www.kaggle.com/code/carnozhao/
1st-place-winning-solution, July 2022.
[27] O.
Takumi,
“Uw-madison
gi
tract
image
segmentation
2nd
place
winning
solution.”
https://www.kaggle.com/code/takuok/
2nd-place-winning-solution, July 2022.
[28] He, “Uw-madison gi tract image segmentation 3rd place winning solu-
tion.” https://www.kaggle.com/code/hesene/3rd-place-winning-solution,
July 2022.
[29] “Uw-madison gi tract image segmentation.” https://www.kaggle.com/
competitions/uw-madison-gi-tract-image-segmentation/data, Apr 2022.
[30] B. Prencipe, N. Altini, G. D. Cascarano, A. Brunetti, A. Guerriero,
and V. Bevilacqua, “Focal dice loss-based v-net for liver segments
classification,” Applied Sciences, vol. 12, no. 7, 2022.
[31] S. Jadon, “A survey of loss functions for semantic segmentation,” in
2020 IEEE Conference on Computational Intelligence in Bioinformatics
and Computational Biology (CIBCB), IEEE, oct 2020.
[32] T. Lin, P. Goyal, R. B. Girshick, K. He, and P. Doll´ar, “Focal loss for
dense object detection,” CoRR, vol. abs/1708.02002, 2017.
[33] T. Gneiting and A. E. Raftery, “Strictly proper scoring rules, predic-
tion, and estimation,” Journal of the American Statistical Association,
vol. 102, no. 477, pp. 359–378, 2007.
[34] K. Zou, S. Warfield, A. Bharatha, C. Tempany, M. Kaus, S. Haker,
W. Wells, F. Jolesz, and R. Kikinis, “Statistical validation of image
segmentation quality based on a spatial overlap index,” Academic
radiology, vol. 11, pp. 178–89, 02 2004.
","nanAdversarial attacks against image classification models are well-studied, but limited research exists for image segmentation tasks. Most prior work has been conducted on non-medical datasets like ImageNet, while medical imaging datasets have been shown to be more vulnerable to attacks. Existing studies on medical image segmentation attacks have focused on lightweight models that are no longer widely used. Furthermore, more recent models have been found to be increasingly susceptible to attack."
"This paper analyzes the performance of secure communication in a wiretap system with finite blocklength (FBL) transmissions over Rayleigh fading channels. An average information leakage (AIL) metric is utilized to quantify secrecy performance. Exact and approximate closed-form expressions for AIL are derived, assuming only statistical channel state information of the eavesdropping link is available. Furthermore, we establish a relationship between the AIL metric in the FBL regime and the commonly used secrecy outage probability in conventional infinite blocklength communications. To enhance the security of the system, a blocklength optimization problem is formulated and solved with low computational complexity. Numerical evaluations validate our findings and provide insights into system parameter impacts on the AIL.","In modern wireless networks, securing communication plays a crucial role in safeguarding sensitive information. Physical-layer security (PLS) has emerged as a promising technique, exploiting the randomness of the transmission medium to protect data confidentiality. Conventional PLS developments have focused on the idea of secrecy capacity in the infinite blocklength (IBL) regime, where coding blocklengths tend to infinity. However, emerging scenarios in beyond-5G (B5G) wireless systems, such as machine-type communication, demand short packets to meet various requirements. This calls for finite blocklength (FBL) analysis, where traditional asymptotic analysis no longer holds. While leveraging FBL communication can minimize end-to-end transmission latency, it often leads to a reduction in channel coding gain, challenging the provision of reliable and secure communication.","The considered system model consists of a typical downlink wiretap communication system, where an access point communicates with an intended receiver via con˝sential FBL transmissions, while an adversary attempts to wiretap the communication. Both legitimate users and the eavesdropper are assumed to have single-antenna nodes. Communication channels are subject to quasi-static Rayleigh block fading, where channel coefficients remain constant for the duration of one FBL packet transmission and their amplitudes follow a Rayleigh distribution. Perfect knowledge of the main channel state information is assumed for both legitimate users, while the eavesdropper has only statistical information about their channel due to passive wiretapping.","The ergodic secrecy performance of FBL transmissions is analyzed, quantifying information leakage to the eavesdropper while assuming desired reliability for the legitimate link. An average information leakage (AIL) metric is defined and approximated in closed form, revealing an inherent relationship between the AIL in the FBL regime and the secrecy outage probability in the IBL regime. This relationship enables the use of the AIL metric to guide secure communication designs in the FBL regime. Furthermore, a blocklength design problem is formulated to optimize the coding block length for improved system secrecy performance. Two approaches are employed: a multi-objective optimization problem and an alternative low-complexity approach that brings the second objective function into the constraint set.","This work presents an analytical framework to analyze the information leakage performance of secure FBL transmissions over fading channels. The study reveals the relationship between the AIL metric and secrecy outage probability, guiding practical designs. Numerical results validate the analytical findings and demonstrate the impact of system parameters on AIL and effective secrecy throughput. Additionally, the proposed blocklength optimization approaches provide insights into the trade-offs between AIL and secrecy performance. The findings emphasize the need for careful resource management and the potential benefits of compromising a small amount of AIL to significantly improve reliability.",On the Information Leakage Performance of Secure Finite Blocklength Transmissions over Rayleigh Fading Channels,"Milad Tatar Mamaghani, Xiangyun Zhou, Nan Yang, A. Lee Swindlehurst, H. Vincent Poor","arXiv:2401.11219v1  [cs.IT]  20 Jan 2024
1
On the Information Leakage Performance of
Secure Finite Blocklength Transmissions over
Rayleigh Fading Channels
Milad Tatar Mamaghani∗, Xiangyun Zhou∗, Nan Yang∗, A. Lee Swindlehurst†, and H. Vincent Poor‡
∗School of Engineering, Australian National University, Canberra, ACT 2601, Australia
†Henry Samueli School of Engineering, University of California, Irvine, CA 92697, USA
‡Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA
Email: {milad.tatarmamaghani, xiangyun.zhou, nan.yang}@anu.edu.au, swindle@uci.edu, poor@princeton.edu
Abstract—This paper presents a secrecy performance study
of a wiretap communication system with ﬁnite blocklength
(FBL) transmissions over Rayleigh fading channels, based on
the deﬁnition of an average information leakage (AIL) metric.
We evaluate the exact and closed-form approximate AIL perfor-
mance, assuming that only statistical channel state information
(CSI) of the eavesdropping link is available. Then, we reveal
an inherent statistical relationship between the AIL metric
in the FBL regime and the commonly-used secrecy outage
probability in conventional inﬁnite blocklength communications.
Aiming to improve the secure communication performance of
the considered system, we formulate a blocklength optimization
problem and solve it via a low-complexity approach. Next, we
present numerical results to verify our analytical ﬁndings and
provide various important insights into the impacts of system
parameters on the AIL. Speciﬁcally, our results indicate that i)
compromising a small amount of AIL can lead to signiﬁcant
reliability improvements, and ii) the AIL experiences a secrecy
ﬂoor in the high signal-to-noise ratio regime.
Index Terms—Beyond-5G communications, physical-layer se-
curity, ﬁnite blocklength, performance analysis, fading channels.
I. INTRODUCTION
In today’s interconnected world, wireless networks have
permeated numerous applications, becoming an indispensable
aspect of our lives. From safeguarding private information
to powering essential services such as credit data, e-health
records, or vital command and control messages, the signif-
icance of beyond-5G (B5G) wireless networks underscores
the paramount need for robust security measures [2]. Thus,
communication security has received considerable attention
from both academia and industry, particularly at the physical
layer. Physical-layer security (PLS) is a promising security
candidate that exploits the distinct features and randomness
of the transmission medium such as channel impairments,
noise, or smart signaling to protect wireless transmissions.
PLS can enhance conﬁdentiality, decrease reliance on upper-
layer cryptography, and ensure security without the need for
sophisticated key-exchange procedures [3].
Conventional PLS developments have been centered around
the idea of secrecy capacity, which refers to the maximum
An extended version of this work has been submitted [1].
achievable secure rate that guarantees both reliability and
conﬁdentiality over a wiretap channel. Wyner in [4] showed
that by employing so-called wiretap coding, it is possible
to concurrently minimize the decoding error probability at a
legitimate receiver and reduce the information leakage to a ma-
licious adversary to an arbitrarily low level with an inﬁnitely
long coding blocklength. Nevertheless, emerging scenarios in
B5G wireless systems such as machine-type communication
(MTC) require data trafﬁc characterized by short packets in
order to satisfy the broader communication requirements [5],
[6]. The use of short packets calls for ﬁnite block-length (FBL)
analysis, as the traditional asymptotic analysis no longer holds
in this regime. While leveraging FBL communication helps
minimize end-to-end transmission latency due to a reduction
in the number of channel uses, it generally comes with
a decrease in channel coding gain, making it challenging
to ensure communication reliability as well as secrecy. In
addition, since wireless FBL communication scenarios cannot
be accommodated by traditional PLS designs, which rely on
the inﬁnite blocklength (IBL) assumption, it is crucial to
meticulously develop PLS schemes tailored to the speciﬁc
requirements of the FBL regime.
Recently, some research has explored the limitations of FBL
transmissions from different perspectives via information-
theoretic approaches. Polyanskiy et al. in [7] addressed the
problem of maximizing the channel coding rate in the FBL
regime with given reliability constraints in general communi-
cation channels. This work urged the research community to
further explore the characterization of non-asymptotic achiev-
able rate regions in different non-security-based schemes [8]
and security-based scenarios [9]–[12], to determine the practi-
cal impacts of FBL on wireless communications. In particular,
the authors in [9] studied secure FBL communication for
mission-critical Internet of Things (IoT) applications with an
external eavesdropper. The work in [10] investigated secrecy
performance in cognitive IoT with low-latency and security
requirements. In [11], the design of a secure aerial commu-
nication system with FBL was considered to improve the
average secrecy rate while meeting security and reliability
requirements. In [12], the authors presented an analytical
© 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any
copyrighted component of this work in other works.
framework to investigate the average secrecy throughput in
the FBL regime.
Despite the aforementioned research efforts, there are still
some fundamental issues that need to be addressed when
designing a secure communication system operating with
FBL transmissions. For instance, the information leakage
performance of such systems with fading channels has been
less reported in the existing literature, e.g., [9]–[14]. Nev-
ertheless, legitimate users do not have direct control over
the amount of information leakage because the instantaneous
channel state information (CSI) for the eavesdropping links
is often unknown in fading channels. Information leakage is
essentially a random quantity that ﬂuctuates depending on
the eavesdropper’s channel quality. Therefore, it is necessary
to conduct further research in order to establish a statistical
measure of information leakage in the FBL regime. This work
presents an analytical framework to address the problem of
information leakage performance through FBL transmissions
over fading channels, which is pivotal for guiding practical
designs. We validate the theoretical ﬁndings via simulations,
and also design the coding blocklength for system secrecy per-
formance improvement via different approaches. In particular,
we obtain a closed-form analytical expression for the optimal
blocklength over Rayleigh fading channels under a constraint
on the maximum allowable AIL.
II. SYSTEM MODEL AND ASSUMPTIONS
Consider a typical downlink wiretap communication sys-
tem, where an access point (Alice) communicates with an
intended receiver (Bob) via conﬁdential FBL transmissions
while an adversary (Eve) attempts to wiretap the ongoing
legitimate communication. We assume that each node in the
network is equipped with a single antenna. We also assume
that communication channels undergo quasi-static Rayleigh
block fading, where the channel coefﬁcients remain unchanged
over the duration of one FBL packet transmission within the
channel coherence time, and their amplitudes are independent
and identically distributed (i.i.d.) according to a Rayleigh
distribution from one packet to another. We denote hb and
he as the reciprocal complex-valued Alice-Bob and Alice-Eve
channels, respectively, considering both large-scale attenuation
and small-scale fading. In this work, we assume that the CSI
for the main link, hb, is perfectly known to both Alice and
Bob via channel reciprocity and training. We also assume that
Eve can obtain the instantaneous CSI for her channel, he.
However, the instantaneous CSI of he is unavailable to Alice
and Bob, and they are only aware of the statistics of he, due
to Eve’s use of passive wiretapping.
Alice generates the transmit signal as a unit-power wave-
form s, i.e., E{∥s∥2} = 1, where E{·} indicates the expectation
operator, and broadcasts it with transmit power P over N
channel uses. Assuming that communication channels are
corrupted with additive white Gaussian noise (AWGN), the
received signal at node i, denoted by yi, can be described as
yi =
√
Phis + ξi,
i ∈ {b, e}
(1)
where hi indicates the i-th channel coefﬁcient such that
E{∥hi∥2} = µi, and ξi ∼ CN(0, σ2) accounts for the AWGN
at the i-th receiver, where CN(µ, σ2) denotes a circularly sym-
metric complex normal distribution with mean µ and variance
σ2. Accordingly, the received signal-to-noise ratio (SNR) at
the intended receiver i can be obtained as γi = ρ∥hi∥2, and
the transmit SNR is deﬁned as ρ =
p
σ2 , which follows an
exponential distribution with mean ¯γi
∆= ρµi, i.e., γi ∼ E (¯γi)
with
fγi(x) = 1
¯γi
e− x
¯γi ,
Fγi(x) = 1 − e− x
¯γi , x > 0
(2)
where fγi(·) and Fγi(·) represent the probability density
function (PDF) and the cumulative distribution function (CDF)
of the random variable (r.v.) γi, respectively.
III. SECRECY PERFORMANCE
In this section, we focus on the ergodic secrecy performance
of FBL transmissions quantiﬁed by the information leakage to
Eve, while assuming the legitimate link can accommodate a
given desired level of reliability. Furthermore, we aim to estab-
lish a simple and intuitive statistical relationship between the
secrecy outage formulation widely used in the IBL regime and
the variational distance-based information leakage formulation
for FBL transmissions. Our objective is to exploit this inherent
relationship to guide secure communication designs in the FBL
regime when dealing with fading channels.
A. Average Information Leakage
Unlike the conventional IBL regime, both decoding errors
at Bob and information leakage to Eve may occur in the
FBL regime, which leads to a further loss of communication
reliability and secrecy. Accordingly, for the considered FBL
communication system, the achievable secrecy rate in bits-
per-channel-use (bpcu), while sustaining a desired decoding
error probability ε at Bob and information leakage δ to Eve,
is approximately given by [15]
R∗
s ≈
h
Cs(γb, γe) −
r
Vb
N Q−1 (ε) −
r
Ve
N Q−1 (δ)
i+
, (3)
where [x]+ = max{x, 0}, and Q−1(x) is the inverse of the
Gaussian Q-function deﬁned as Q(x) =
R∞
x
1
√
2πe− r2
2 dr.
Additionally, Cs is the secrecy capacity in the IBL regime
given by
Cs(γb, γe) = log2(1 + γb) − log2(1 + γe),
(4)
and Vi in (3) represents the stochastic variation of the i-th
channel, which can be expressed as
Vi = log2
2 e γi(γi + 2)
(γi + 1)2 ,
i ∈ {b, e}.
(5)
Since Alice knows the instantaneous CSI of Bob’s but
not Eve’s channel, the legitimate users have the ability to
control the reliability performance (ε) but not the secrecy
performance (δ). Accordingly, we assume that the desired
reliability for the given ε can be achieved, and thus focus our
efforts on determining the best attainable secrecy performance
characterized by δ for the considered scenario. To this end,
we assume that for each FBL transmission, Alice sends m
information bits over N channel uses, such that the secrecy
rate is given by Rs = m
N in the considered wiretap system.
To obtain the best achievable secrecy performance in terms
of information leakage, we set Rs = R∗
s, where R∗
s is the
achievable FBL secrecy rate given by (3), and conduct some
mathematical manipulations leading to
δ = Q
 r
N
Ve
""
Cs(γb, γe) −
r
Vb
N Q−1(ε) − m
N
#!
.
(6)
We note that (6) essentially indicates the amount of informa-
tion leakage that would occur given the best possible coding
strategy for transmitting the conﬁdential information at the rate
of Rs with a decoding error probability of ε at Bob. In addition,
it is evident from (6) that δ is a random quantity determined
by the instantaneous SNR of Eve’s channel γe. Since only sta-
tistical information about Eve’s channel is available, it seems
reasonable to investigate the ergodic secrecy performance by
averaging the information leakage δ over all realizations of γe,
which we refer to as the average information leakage (AIL).
The AIL can be deﬁned as
¯δ = E{δ|hb}
=
Z
R+ Q
 s
N
Ve(x)

log2
1 + γb
1 + x

− R0
!
fγe(x)dx, (7)
where Ve(x) = log2
2 e x(x+2)
(x+1)2 and R0
∆=
q
Vb
N Q−1(ε) + m
N .
Note that obtaining a closed-form expression for (7) is
extremely challenging, due to the complicated integration
over the composite Gaussian Q-function. In Proposition 1,
we derive an approximate expression for (7) by means of
Laplace’s approximation theorem [16].
Proposition 1. The AIL for the considered wiretap system with
Rayleigh fading channels can be approximated as
¯δ ≈ exp

− x0
¯γe

,
(8)
where x0 is deﬁned for x0 ≥ 0 as
x0 = 1 + γb
2R0
− 1.
(9)
Proof. Integrating by parts, we rewrite (7) equivalently as
¯δ =
Z
R+ [1 − Fγe(x)] ×
∂
∂xQ
 s
N
Ve(x)

log2
1 + γb
1 + x

− R0
!
dx,
(10)
where Fγe(·) indicates the CDF of the r.v. γe given by (2).
Because the ﬁrst derivative of the Q-function is
∂Q(x)
∂x
=
−
1
√
2π exp

− x2
2

, applying the chain rule we can express
(10) as
¯δ =
Z
R+ Ψ(x)e−NΞ(x)dx,
(11)
where the functions Ψ(x) and Ξ(x) are given respectively by
Ψ(x)=
s
N
πx(x + 2)

1+
log2

1+γb
1+x

−R0
x(x + 2) log2 e

[1−Fγe(x)] ,
(12)
and
Ξ(x) =

log2

1+γb
1+x

− R0
2
2Ve(x)
.
(13)
Note that Ξ(x) is a twice-differentiable function whose global
minimum occurs at x0, and the function Ψ(x) is smooth. Thus,
with all the required conditions satisﬁed for an application
of the Laplace (a.k.a. saddle-point) approximation, we can
approximate (11) as
¯δ ≈ e−NΞ(x0)Ψ(x0)
s
2π
NΞ′′(x0).
(14)
Finally, computing the values of the corresponding functions in
(14) at x0, i.e., Ξ(x0) = 0, Ψ(x0) =
q
N
πx0(x0+2)[1−Fγe(x0)],
and Ξ′′(x0) =
2
x0(x0+2), as well as considering the CDF of
the r.v. γe given by (2), some algebraic simpliﬁcations lead to
the approximate expression for ¯δ given by (8). This completes
the proof.
■
Remark 1. Based on Proposition 1, we can conclude that
increasing the blocklength N reduces the AIL performance ¯δ,
beneﬁting communication secrecy at the cost of reducing the
secrecy rate Rs. The AIL is always non-zero regardless of how
much communication power is allocated.
B. Secrecy Outage vs. Average Information Leakage
Recall that a secrecy outage event in the conventional IBL
regime, where Eve can observe the inﬁnite blocklength, can
be characterized as an event where the capacity of the wiretap
link Ce = log2(1 + γe) becomes greater than the redundancy
rate Re, as in [17]. Accordingly, the secrecy outage probability
(SOP) is formulated as
Pso = P{Ce > Re} = 1 − Fγe
IV. BLOCKLENGTH DESIGN FOR SECURE TRANSMISSION
In this section, we turn our focus to the transmission design
problem in which we optimize the coding block length N for
the considered secure FBL communication system. Our prob-
lem is formulated as a multi-objective optimization problem
(MOOP), aiming to minimize the AIL ¯δ while maximizing the
effective secrecy throughput (EST) for the considered system,
deﬁned as T = (1−ε)m
N
, given by
(P) : {max
N T ,
min
N
¯δ}
s.t. 1 ≤ N ≤ Nmax, N ∈ Z+
(17)
where Nmax is the maximum blocklength determined by the
maximum allowed delay of the FBL transmission. Problem (P)
leads to an adaptive blocklength design since Alice possesses
knowledge of Bob’s instantaneous CSI and hence γb; thus
it is assumed that she has the ability to adapt the design
parameter N in accordance with this information. Note that we
can convert (P) into a single-objective optimization problem
(SOOP) by introducing a weighting factor λ (0 ≤ λ ≤ 1), as
follows:
(P1) : min
N λ¯δ − (1 − λ)T
m(1 − ε)
s.t. 1 ≤ N ≤ Nmax, N ∈ Z+.
(18)
The parameter λ determines the relative importance of the AIL
and the EST, after proper scaling. Here, we scale the EST by
the factor (1 − ε)m to make its range comparable to that of
the AIL. Note that if we choose λ = 0, then (P1) reduces to
an EST maximization regardless of the amount of information
leakage. On the other hand, the extreme case λ = 1 minimizes
the AIL without regard for the EST. It can be readily seen
that for the former, the optimal blocklength is N∗ = 1, while
for the latter N∗ = Nmax, due to the monotonicity of the
respective objective functions. Nevertheless, for the general
case 0 < λ < 1, the objective function is nonconvex, and
its optimal solution can be determined via a one-dimensional
(1D) search. Note that this scaling approach results in a set
of solutions that form a Pareto-optimal boundary, allowing
system designers to trade-off the AIL and EST depending on
the given circumstances, as shall be shown below.
A. Alternative Low-complexity Approach
From a practical perspective, the AIL should generally not
exceed a certain threshold φ depending on the secrecy level
required for the application of interest. As such, we can
reformulate (P) as a SOOP, by bringing the second objective
function into the constraint set, as
(P2) : max
N T
s.t. 1 ≤ N ≤ Nmax, N ∈ Z+
(19a)
¯δ ≤ φ.
(19b)
Note that the value of the objective function in (P2) increases
as N decreases, while the AIL ¯δ is monotonically non-
decreasing, leading to a tightening of the constraint (19b).
Thus, the optimal solution to (P2) is the minimum value of
N for which the constraint (19b) is satisﬁed. As a result,
assuming the feasibility of (P2) and using (8), we can write
the optimality condition as
log2

1 + γb
1 − ¯γe ln φ

=
√VbQ−1(ε)
√
N
+ m
N ,
(20)
Applying the change of variable N = η2, (20) can be
transformed into the quadratic equation
aη2 − bη − m = 0,
where the coefﬁcients are given respectively by
a = log2

1 + γb
1 − ¯γe ln φ

and b =
p
VbQ−1(ε).
Retaining the positive solution to the quadratic equation leads
to the optimal integer-valued blocklength
N∗ = min



&s
b +
√
b2 + 4am
2a
'
, Nmax


 ,
(21)
where ⌈x⌉ indicates the smallest integer larger than or equal
to x and is used to ensure the constraint (19b) is not violated.
Consequently, the optimal EST is given by T ∗ = (1−ε)m
N∗
.
V. NUMERICAL RESULTS AND DISCUSSION
In this section, we provide simulation results to validate the
accuracy of the approximate expressions obtained above for
the AIL and investigate the impact of key system parameters
such as blocklength, number of conﬁdential bits, transmit
power, and decoding error probability on the AIL and EST
performance. Unless otherwise stated, the simulation param-
eters are set as follows: Number of transmit information bits
m = 200, transmit SNR ρ = 0 dB, decoding error probability
ε = 10−3, maximum tolerable AIL φ = 10−2, coding
blocklength N = 400, maximum blocklength Nmax = 1000,
µb = 1, γb = 1, and µe = 0.1.
Fig. 1 shows the AIL under Rayleigh fading for a ﬁxed
main channel realization and different secrecy coding rates
ranging from Rs = 0.2 bpcu (relatively low) to Rs = 1 bpcu
(relatively high). The markers labeled with Exact represent the
exact AIL evaluated by (7), while the curves labeled as Approx.
indicate the approximate analytical evaluation of the AIL in
the FBL regime according to Proposition 1. We can see that the
theoretical exact and analytical approximate AILs match well
for a wide range of transmit SNRs, validating our analysis.
In addition, we see that for a given transmit SNR, a higher
secrecy rate Rs corresponds to a larger AIL. Furthermore,
the high-SNR performance reveals an AIL ﬂoor regardless
of Rs, where the AIL approaches a nonzero value for large
ρ. This indicates that allocating more resources to increase ρ
has a negligible impact on the AIL, signifying the need for
proper resource management. Overall, this ﬁgure conﬁrms the
accuracy of our derived approximate expressions for the AIL
and once again reveals the inherent close relationship between
the AIL in the FBL regime and the SOP for IBL.
0
2
4
6
8
10
12
14
16
18
20
10-4
10-3
10-2
10-1
100
Rs = 0.2, 0.5, 1 bpcu
Fig. 1. AIL vs. transmit SNR for different Rs.
10-8
10-6
10-4
10-2
100
10-4
10-3
10-2
10-1
100
N = 900, 600, 300
Fig. 2. AIL vs. decoding error probability for different N.
Fig. 2 provides notable insight into the security-reliability
trade-off for the considered secure FBL transmission system.
In particular, we plot the AIL against the decoding error
probability ε for different blocklengths. As can be clearly
seen from the ﬁgure, the exact and approximate AIL are
in good agreement for different values of ε, conﬁrming the
correctness of our analysis. Furthermore, when ε increases, the
AIL becomes smaller, and this decreasing trend becomes more
signiﬁcant as the coding blocklength is reduced. We can also
conclude from the ﬁgure that by compromising a small level
of secrecy in terms of AIL, a large improvement in reliability
is achieved. For example, when N = 900, if the secrecy level
is reduced from ¯δ = 2×10−3 to ¯δ = 10−2, which corresponds
to roughly 7 dB security loss, the communication reliability
is improved from ε = 10−2 to ε = 10−8, i.e., approximately
a 60 dB gain in reliability. This is particularly beneﬁcial for
systems that require ultra-high reliability and can tolerate a
somewhat reduced level of secrecy.
Fig. 3. Pareto boundary for the MOOP given by (P).
0
2
4
6
8
10
12
14
16
18
20
0.4
0.6
0.8
0
2
4
6
8
10
12
14
16
18
20
200
400
600
0
2
4
6
8
10
12
14
16
18
20
9.88
9.9
9.92
9.94
9.96
9.98
10-3
Fig. 4. Designed EST and blocklength vs. transmit SNR using (P1).
Fig. 3 shows the Pareto boundary for the MOOP prob-
lem, illustrating how improvement in one objective results in
degradation for the other. Variations of two algorithms are
employed to solve (P) via the Matlab Optimization Toolbox
[18], namely the genetic algorithm (GA) and the direct/Pareto
search (PS) algorithm. Both algorithms perform well in ﬁnding
the optimal points. PS ﬁnds a more concentrated set of points
on the boundary, while the GA solutions occur more at the
extreme ends of the performance metrics. Overall, this ﬁgure
provides useful insight into the set of optimal AIL and EST
values and their trade-offs.
Fig. 4 depicts the optimal EST and designed blocklength
N∗, as well as the obtained AIL for different transmit SNRs.
It is clear from the ﬁgure that the optimal blocklenth is
monotonically increasing with transmit SNR ρ, yet expe-
riences a ceiling phenomenon at large SNRs due to the
maximum transmission delay requirement corresponding to
Nmax. Furthermore, we observe from Fig. 4 that the larger the
50
100
150
200
250
300
0.2
0.25
0.3
0.35
50
100
150
200
250
300
200
400
600
800
1000
Fig. 5.
Designed EST and blocklength vs. the number of information bits
via (P1).
transmit SNR, the smaller the number of channel uses that is
optimally required for EST improvement while satisfying the
AIL security requirement.
Fig. 5 exhibits the impact of the number of transmit in-
formation bits m on the designed parameter N∗ as well as
the optimal EST ¯T ∗ according to (P1). We observe from the
ﬁgure that as m increases, N∗ grows linearly to improve the
EST for maintaining the demanded secrecy level. Furthermore,
the overall EST performance ¯T ∗ is non-decreasing with m;
however, due to the maximum blocklength threshold Nmax,
a ceiling phenomenon on the optimal EST appears when m
becomes sufﬁciently large.
VI. CONCLUSION
This work has explored the performance analysis and op-
timization of secure FBL transmissions in terms of the AIL
metric for a wiretap communication system without instanta-
neous knowledge of Eve’s CSI. We have obtained expressions
for the exact and approximate AIL of the system assuming
Rayleigh fading channels. We have unveiled the relationship
between the AIL in the FBL regime and the SOP in the IBL
regime and found a simple relationship between these two
statistical metrics. We have further investigated the impact of
key system parameters on the AIL performance. Our ﬁndings
have revealed that increasing blocklength reduces the system’s
AIL, and sacriﬁcing a small level of secrecy could lead
to a substantial improvement in reliability. Finally, we have
formulated and solved a blocklength optimization problem to
improve the secrecy performance of the system using different
optimization approaches, obtaining worthwhile insights into
the practical design of PLS with FBL transmissions.
ACKNOWLEDGMENT
This work was supported by the Australian Research Coun-
cil’s Discovery Projects (project number DP220101318).
REFERENCES
[1] M. Tatar Mamaghani, X. Zhou, N. Yang, A. L. Swindlehurst, and H. V.
Poor, “Performance analysis of ﬁnite blocklength transmissions over
wiretap fading channels: An average information leakage perspective,”
Aug. 2023. [Online]. Available: https://arxiv.org/abs/2308.13184
[2] Y. Wu, A. Khisti, C. Xiao, G. Caire, K.-K. Wong, and X. Gao, “A
survey of physical layer security techniques for 5G wireless networks
and challenges ahead,” IEEE J. Sel. Areas Commun., vol. 36, no. 4, pp.
679–695, Apr. 2018.
[3] H. V. Poor and R. F. Schaefer, “Wireless physical layer security,” Proc.
Natl. Acad. Sci. USA, vol. 114, no. 1, pp. 19–26, 2017.
[4] A. D. Wyner, “The wire-tap channel,” Bell Syst. Tech. J., vol. 54, no. 8,
pp. 1355–1387, Oct. 1975.
[5] I. F. Akyildiz, A. Kak, and S. Nie, “6G and beyond: The future of
wireless communications systems,” IEEE Access, vol. 8, pp. 133 995–
134 030, 2020.
[6] C. Bockelmann et al., “Massive machine-type communications in 5G:
Physical and MAC-layer solutions,” IEEE Commun. Mag., vol. 54, no. 9,
pp. 59–65, Sept. 2016.
[7] Y. Polyanskiy, H. V. Poor, and S. Verd´u, “Channel coding rate in the
ﬁnite blocklength regime,” IEEE Trans. Inf. Theory, vol. 56, no. 5, pp.
2307–2359, May 2010.
[8] P. Mary, J.-M. Gorce, A. Unsal, and H. V. Poor, “Finite blocklength
information theory: What is the practical impact on wireless communi-
cations?” in Proc. IEEE Global Commun. Conf., Washington, DC, USA,
12 2016, pp. 1–6.
[9] H. M. Wang, Q. Yang, Z. Ding, and H. V. Poor, “Secure short-packet
communications for mission-critical IoT applications,” IEEE Trans.
Wirel. Commun., vol. 18, no. 5, pp. 2565–2578, May 2019.
[10] Y. Chen, Z. Xiang, X. Qiao, T. Zhang, and J. Zhang, “Secure short-
packet communications in cognitive Internet of Things,” in Proc. IEEE
3rd Int. Conf. Electron. Commun. Eng., Xi’An, China, 2020, pp. 31–36.
[11] M. Tatar Mamaghani, X. Zhou, N. Yang, and A. L. Swindlehurst,
“Secure short-packet communications via UAV-enabled mobile relaying:
Joint resource optimization and 3D trajectory design,” IEEE Trans.
Wirel. Commun. (early access), Dec. 2023.
[12] C. Feng, H. M. Wang, and H. V. Poor, “Reliable and secure short-
packet communications,” IEEE Trans. Wirel. Commun., vol. 21, no. 3,
pp. 1913–1926, Mar. 2022.
[13] T.-X. Zheng, H.-M. Wang, D. W. K. Ng, and J. Yuan, “Physical-layer
security in the ﬁnite blocklength regime over fading channels,” IEEE
Trans. Wirel. Commun., vol. 19, no. 5, pp. 3405–3420, May 2020.
[14] M. Oh, J. Park, and J. Choi, “Joint optimization for secure and reli-
able communications in ﬁnite blocklength regime,” IEEE Trans. Wirel.
Commun., vol. 22, no. 12, pp. 9457–9472, Dec. 2023.
[15] W. Yang, R. F. Schaefer, and H. V. Poor, “Wiretap channels: Nonasymp-
totic fundamental limits,” IEEE Trans. Inf. Theory, vol. 65, no. 7, pp.
4069–4093, July 2019.
[16] A. Azevedo-Filho and R. D. Shachter, “Laplace’s method approxima-
tions for probabilistic inference in belief networks with continuous
variables,” in Proc. Tenth Conf. Uncertainty Artif. Intell., San Francisco,
CA, USA, 1994, pp. 28–36.
[17] X. Zhou, M. R. McKay, B. Maham, and A. Hjørungnes, “Rethinking the
secrecy outage formulation: A secure transmission design perspective,”
IEEE Commun. Lett., vol. 15, no. 3, pp. 302–304, Mar. 2011.
[18] The MathWorks Inc., “Optimization toolbox version: 9.4 (r2022b),”
Natick, Massachusetts, USA, 2022.
","nanResearch in the FBL regime has been conducted to explore the limitations of such transmissions. Polyanskiy et al. addressed the problem of maximizing channel coding rate in the FBL regime with given reliability constraints. This work inspired further exploration of non-asymptotic achievable rate regions in both security-based and non-security-based scenarios. In particular, studies have investigated secure FBL communication for mission-critical Internet of Things (IoT) applications, secrecy performance in cognitive IoT, secure aerial communication system design, and analytical frameworks for investigating average secrecy throughput in the FBL regime."
"First-principle models construction is a challenging task especially for the wastewater treatment units due to their inherent complex nonlinear behavior. In recent years, data-driven models were widely utilized to overcome the complications related to the first-principle model construction. However, they suffer from issues such as missing, low quality or noisy data. Transfer learning presents a solution to these issues where knowledge from another task is transferred to target one to increase the prediction performance. In this work, the objective is to enhance the prediction accuracy of an industrial wastewater treatment plant by transferring the knowledge (i) of an open-source simulation model, (ii) another industrial plant and (iii) the model in (ii) with making the objective function physics informed. Results indicate that test and validation performance are enhanced up to 27% and 59%, respectively.","Neural networks are mathematical representations of input, output relations. They consist of hidden layers where the information flow is controlled by gates. Recurrent neural network (RNN) is a dynamic structure of ANNs where the past information is considered and suited especially for dynamic process with time-series data. However, they often suffer from the gradient vanishing problem. Long short-term memory (LSTM) blocks are used to handle this issue. Data-driven models are widely used due to their construction simplicity compared to first principle models. However, they are black-box in nature and they often suffer from issues like overfitting/underfitting, lack of data or noisy data. Physics-informed neural networks are suggested in many works to overcome these issues. Transfer learning is transferring the knowledge of a task with abundant data to a target task where the data is scarce to enhance the prediction performance. Similarity between the features of target and related task has importance in transfer learning.","Activated sludge is the biological treatment process in wastewater treatment unit, where the bacteria content breaks down the organic matter in the wastewater. Modeling wastewater treatment systems can be quite challenging due to nonlinearity as a result of parallel reactions. Henze et al. designed a general model for single-sludge wastewater treatment systems named as Activated Sludge Model 1 (ASM1). ASM1 is subject to some limitations, but it is universally accepted. Alex et al. printed Benchmark Simulation Model 1 (BSM1), with biological reactor and secondary clarifier sections of a wastewater treatment unit where the biological reactor section consists of two anaerobic and three aerobic reactors in series form. Controlling dissolved oxygen concentration is important to ensure that the bacteria content has enough oxygen to efficiently treat the wastewater. Lin & Luo adapted a radial basis function neural network controller to control dissolved oxygen concentration at the aerobic section of ASM1. For the same purpose, Tzoneva implemented PID controllers. Holenda et al. designed a model predictive controller (MPC) for ASM1. Qambar & Al Khalidy optimized dissolved oxygen concentration at Madinat Salman wastewater treatment plant by predicting with random forest and gradient boost models resulting in lower energy consumption.","At the initial stage of the research, around 700 data points were available for training and testing. Three different models with varying complexities are trained and evaluated. The first model, termed the standard model, achieves the best test and validation performance among the trials. The second model, more complex than the standard model, is trained with 6 hidden layers and 60 neurons. Finally, a less complex model is trained with 3 hidden layers, each comprising 20 neurons.The standard model is chosen as the benchmark for comparison with the more complex and less complex models.The training performance of the more complex model surpasses that of the standard model, indicating a seemingly better fit to the training data. However, the test and validation MSE and MAE deteriorate as the number of layers and neurons is increased. Conversely, reducing the number of layers and neurons results in an underfit, with worsened training, test, and validation performance.Transfer learning indeed provides a promising avenue to address the limitations of classical machine learning and enhance prediction performance. In this study, the ASM1 model is selected as the first source model to improve the prediction performance of the target model. For the source model, LSTM architecture is employed, featuring 5 hidden layers and 25 neurons at each layer, with the hyperbolic tangent function serving as the activation function. The dataset, comprising 673 data points, is not shuffled, as the sequential nature of the days is preserved.
The resulting figures are presented in Fig. 7.a. and Fig. 7.b., with corresponding performance metrics outlined in the first column of Table 3. While the training performance experiences a slight decline when layers of the open-source model are transferred, the test and validation performances see notable improvements. In terms of MSE, the test and validation performances exhibit enhancements of 15% and 36%, respectively. Correspondingly, MAE is reduced by 4% and 42% compared to the standard model for the test and validation performances.The second case study involves transferring knowledge from another industrial plant within the same city, both equipped with wastewater treatment units. The target wastewater treatment unit is relatively new, having undergone maintenance for only a few years, while the source comprises an older plant with a dataset size of 600, smaller than the target model. Despite the smaller dataset size and potential noise in measurements due to real plant conditions, the advantage lies in the similarity in structure and location between the two plants.The final case study integrates the transfer learning model from the preceding section with an industrial source plant and incorporates physics information derived from the open-source model.","The study reveals the inadequacy of the classical dynamic (recurrent) machine learning approach, illustrating that choosing for either a less or more complex model resulted in underfitting and overfitting, respectively. Transfer learning, however, proves to be a viable solution, leveraging knowledge from related tasks, even in scenarios where the number of features prevents dataset integration. Furthermore, the combination of physics-based information derived from the open-source model and the machine learning model tailored to the target task yields the best model fit.",A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant,"Ece S. Koksal, Erdal Aydin"," 
A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving 
Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant  
Ece Serenat Koksala, Erdal Aydina,b,*
aDepartment of Chemical and Biological Engineering, Koç University, Istanbul 34450, Turkey 
bKoç University TUPRAS Energy Center (KUTEM), Koç University, Istanbul, 34450, Turkey 
 
ABSTRACT 
Constructing first principles models is a challenging task for nonlinear and complex systems such 
as a wastewater treatment unit. In recent years, data-driven models are widely used to overcome 
the complexity. However, they often suffer from issues such as missing, low quality or noisy data. 
Transfer learning is a solution for this issue where knowledge from another task is transferred to 
target one to increase the prediction performance. In this work, the objective is increasing the 
prediction performance of an industrial wastewater treatment plant by transferring the knowledge 
of (i) an open-source simulation model that captures the underlying physics of the process, albeit 
with dissimilarities to the target plant, (ii) another industrial plant characterized by noisy and 
limited data but located in the same refinery, and (iii) the model in (ii) and making the objective 
function of the training problem physics informed where the physics information derived from the 
open-source model in (ii). The results have shown that test and validation performance are 
improved up to 27% and 59%, respectively.  
 
 
Keywords: transfer learning, recurrent neural networks, long short-term memory, wastewater 
treatment unit, physics-informed transfer learning 
 
 
* Corresponding Author.  
E-mail adress: eaydin@ku.edu.tr (E. Aydin). 
 
2 
1. Introduction  
Artificial neural networks (ANN) are unique type of mathematical representations of input and 
output relations. In addition to an input and an output layer, there are hidden layers, user defined 
activation functions representing the neurons with certain amount. The recurrent neural networks 
(RNN) are dynamic structures of ANNs where the past information is also considered. RNNs are 
suited especially for dynamic process with time-series data. However, they often suffer from an 
issue called “vanishing gradient problem” meaning the gradients become smaller as they are 
backpropagated from the output layer to the previous layers. As a respond to this problem, long 
short-term memory (LSTM) blocks are widely used structures where the information flow is 
controlled by gates [1].  
 
Data driven models are widely used since they are easy to construct compared to first-principles 
models. Considering the complexity of the first principles models, data driven models are good 
alternatives to model processes when data is present. However, these models are black box in 
nature often suffer from issues such as overfitting, underfitting, lack of data or noisy data [2]. As 
a solution, physics-informed neural networks are suggested in many works where physics-based 
knowledge is integrated to the data driven models to response to the aforementioned issues [3]–
[11]. 
 
Transfer learning is transferring the knowledge of a related task with abundant data to the target 
task where the data is scarce to increase the prediction performance. Based on the solution 
categorization, transfer learning can be classified into four: instance, feature, parameter, relational 
based approaches. The parameter-based transfer learning focuses on transferring the knowledge at 
the model and the parameter level which is basically transferring the weight and bias information 
at the layers of the machine learning model [12], [13]. Transfer learning is used for many areas 
such as image classification, drug discovery, fault diagnosis, radioactive particle tracking and skin 
 
3 
cancer classification [14]–[18]. Yet, its implementation to regression problems is very limited in 
the literature, especially for chemical and environmental engineering tasks.  
 
The similarity of the features between the related task and the main task can be quite important in 
transfer learning. Li & Rangarajan used interpretable linear models for molecular property and 
demonstrated the requirement of overlapping features with the transferred information and the 
model. While transfer learning can be detrimental when percentage of overlapping features is low, 
the accuracy and generalizability is higher when knowledge is transferred from a task with higher 
percentage of overlapping features [19]. 
 
Transfer learning has been applied to increase prediction capability and overcome the issues of 
lack of useful data in chemical engineering or related applications such as gas adsorption in metal-
organic frameworks and industrial distillation columns in the literature [20], [21]. Chuang et al. 
created a base model which mimics Computational Fluid Dynamics (CFD) simulator to determine 
the feasible operating region. They collected data from the CFD and creates a final model by using 
transfer learning based on Bayesian migration technique. The contribution of transfer learning 
provided constructing a final model with small dataset size [22]. Rogers et al. demonstrated two 
case studies where different transfer learning strategies sustain more accuracy and reliability than 
kinetic and fully data driven models of biochemical processes [23]. Wu & Zhao proposed a fault 
detection and diagnosis method based on transfer learning for multimode chemical processes and 
used Tennessee Eastman process as case study. Information transferred from source mode 
eliminated the issue of lack of data and it is useful even when data is unlabeled [24]. Bi et al. 
integrated transfer learning modeling and intelligent heuristic optimization for a steam cracking 
process to decrease the time consumption and data size requirements [25].  
 
 
4 
Transfer learning is also applied to wastewater treatment plants in which biological treatment is 
achieved with activated sludge. Pisa et al. trained and tested an LSTM based Proportional-Integral 
(PI) controller to capture the quickest dynamics. Then, they transferred the LSTM based 
controller’s knowledge to a different control loop. They obtained a final controller with an 
improved performance and reduced design complexity [26]. Huang et al. considered the 
knowledge of ErWu wastewater treatment plant as source domain and transfer it to increase the 
prediction capacity of TuoDong wastewater treatment plant based on chemical oxygen demand 
(COD) by using two-stage TrAdaBoost.R2 algorithm [27].  
 
Physics informed neural networks and transfer learning approaches are widely used to increase the 
prediction performance and obtain more reliable models. Recently, their combination is also 
applied by some research which enables to improve the data-driven models further by using the 
advantage of both approaches. Lansford et al. integrated transfer learning with physics informed 
directed message passing neural network to predict out-of-sample vapor pressure [28]. Guc & 
Chen utilized physics informed transfer learning through GoogLeNet structure for fault cause 
assignment [29]. Schröder et al. improved wind farm monitoring by transferring simulation data 
and adding a physical constraint to the artificial neural network model [30]. Goswami et al. utilized 
transfer learning enhanced physics informed neural networks to solve brittle fracture problems 
[31]. Xu et al. proposed physics informed transfer learning to solve inverse problems in linear 
elasticity and hyper elasticity. Then, in the online stage, utilized transfer learning for fine-tuning 
to deal with the noisy data [32]. 
 
In the landscape of wastewater treatment modeling, prior studies have predominantly focused on 
classical machine learning or first-principles models. However, classical machine learning 
approaches may encounter limitations in effectively modeling real industrial data, and the 
 
5 
construction of first-principles models proves to be a challenging and time-intensive endeavor. 
What sets our work apart is the integration of transfer learning, a technique not extensively 
explored in the context of industrial wastewater treatment. By addressing this gap, our research 
pioneers a holistic approach that not only increases the prediction performance but also serves as 
a steppingstone for further advancements in the application of transfer learning to complex 
industrial processes. In this work, prediction performance of an industrial wastewater treatment 
unit is increased by transferring the knowledge of (i) an open-source simulation model, (ii) another 
industrial wastewater treatment plant in the same refinery and (iii) combining the physics 
knowledge based on (i) and integrating it to (ii). The key contribution of the proposed work lies 
on (i) combining transfer learning with LSTM models for regression problems related to process 
engineering, (ii)increasing the prediction performance of a real plant by the knowledge of an open-
source model, (iii) increasing the prediction performance of an actual plant by another real plant 
although the source model is trained with noisy data with low set size, (iv) applying physics 
informed transfer learning with recurrent neural network structure and measuring its performance 
on an actual plant.   
 
The paper is organized as follows: A brief introduction for neural networks and transfer learning 
is expressed in Section 1. Section 2 explains the open-source model and the industrial wastewater 
treatment plant in interest. The methodology related to the machine learning methods and transfer 
learning is explained in Section 3. Section 4 presents three case studies illustrating the application 
of transfer learning to increase the prediction performance of the target model. Finally, Section 5 
offers concluding remarks to summarize the key findings and insights presented in this paper. 
 
 
 
 
6 
2. Process Model: Wastewater Treatment Unit  
Wastewater treatment is the process designed to clean the wastewater before it is discharged to the 
environment. Wastewater treatment is crucial for removing contaminants, pollutants and 
impurities since the quality of the treated water affects the environment and public health. In 
wastewater treatment process, the wastewater passes through physical, chemical and biological 
treatment before being discharged to the environment. 
 
Activated sludge is the biological treatment process where the bacteria content breaks down the 
organic matter in the wastewater. Modeling wastewater treatment systems can be quite challenging 
due to nonlinearity as a result of parallel reactions. In 1983, International Association of Water 
Pollution Research and Control (IAWPRC) formed a group to construct a base model for single 
sludge systems to facilitate the design and operation of wastewater treatment units. To respond 
this need, Henze et al. designed a general model for single-sludge wastewater treatment systems 
named as Activated Sludge Model 1 (ASM1) representing the model development for carbon 
oxidation, nitrification, and denitrification [33]. Although ASM1 is subject to some limitations, it 
is universally accepted [34]. Based on ASM1, Alex et al. printed Benchmark Simulation Model 1 
(BSM1), with biological reactor and secondary clarifier sections of a wastewater treatment unit 
where the biological reactor section consists of two anaerobic and three aerobic reactors in series 
form [35].  
 
Besides the difficulties on modelling wastewater treatment systems due to the complex and 
nonlinear behavior, controlling dissolved oxygen concentration is quite important to ensure that 
the bacteria content has enough oxygen to efficiently treat the wastewater. However, feeding the 
unit with excess oxygen gives birth to high energy consumption. The oxygen is fed to the activated 
sludge by aerators and the energy consumption of aerators is between 30-75% of total energy 
consumption in activated sludge system [36]. As a result, predicting the dissolved oxygen 
 
7 
concentration helps to maintain a healthy bacteria content, decrease energy consumption and 
operate with effective minimal cost. Lin & Luo adapted a radial basis function neural network 
controller to control dissolved oxygen concentration at the aerobic section of ASM1 [37]. For the 
same purpose, Tzoneva implemented PID controllers [38]. In addition, Holenda et al. designed a 
model predictive controller (MPC) for ASM1 [39]. Qambar & Al Khalidy optimized dissolved 
oxygen concentration at Madinat Salman wastewater treatment plant by predicting with random 
forest and gradient boost models resulting in lower energy consumption [40]. Asrav et al. 
constructed recurrent neural network models to increase the prediction performance of an 
industrial plant [41].  
 
In ASM1, the change of dissolved oxygen concentration at the aerobic section of the reactors are 
represented as follows [33]:  
 
𝑑𝑆𝑂
𝑑𝑡 = − 1 − 𝑌𝐻
𝑌𝐻
𝜇𝐻 (
𝑆𝑆
𝐾𝑆 + 𝑆𝑆
) (
𝑆𝑂
𝐾𝑂,𝐻 + 𝑆𝑂
) 𝑥𝐵𝐻
− 4.57 − 𝑌𝐴
𝑌𝐴
𝜇𝐴 (
𝑆𝑁𝐻
𝐾𝑁𝐻 + 𝑆𝑁𝐻
) (
𝑆𝑂
𝐾𝑂,𝐴 + 𝑆𝑂
) 𝑥𝐵𝐴 
(1) 
 
where 𝑆𝑂 is the dissolved oxygen concentration at the activated sludge (g/m3), 𝑆𝑆 is the readily 
biodegradable substrate (g COD / m3), 𝑆𝑁𝐻 is the NH4++NH3 nitrogen (g N / m3),  𝑥𝐵𝐻 is the active 
heterotrophic biomass (g COD/m3), 𝑥𝐵𝐴 is the active autotrophic biomass (g COD/m3), 𝑌𝐻 is the 
heterotrophic yield (g 𝑥𝐵𝐻 COD formed-1), 𝑌𝐴 is the autotrophic yield (g 𝑥𝐵𝐴 COD formed-1), 𝜇𝐻 
is the maximum heterotrophic growth rate (day-1), 𝜇𝐴 is the maximum autotrophic growth rate 
(day-1),  𝐾𝑆 is the half saturation of heterotrophic growth (g COD/m3), 𝐾𝑁𝐻 is the half saturation 
of autotrophic growth (g NH3-N / m3),  𝐾𝑂,𝐻 is the half saturation of heterotrophic oxygen (g 
COD/m3), 𝐾𝑂,𝐴 is the half saturation of autotrophic oxygen (g O2 / m3). For the values of 𝑌𝐻, 𝑌𝐴, 
 
8 
𝜇𝐻, 𝜇𝐴, 𝐾𝑆, 𝐾𝑁𝐻, 𝐾𝑂,𝐻 and 𝐾𝑂,𝐴, and for more detailed information on ASM1, readers may refer 
to [33].  
 
In the wastewater treatment plant analyzed in this study, the physical treatment starts at the first 
unit of the process, Oil Water Separator (OWS) which is followed by chemical treatment 
procedure. The next unit is dissolved air floatation (DAF) where the suspended solids are removed 
by attaching bubbles causing them floating to the surface. The outlet stream properties such as pH, 
total suspended solid (TSS), chemical oxygen demand (COD), grease, ammonium nitrogen (NH4-
N), phenol and sulfur are measured regularly since the stream is sent to activated sludge where the 
biological content removes waste from the water by parallel reactions. The outlet stream of the 
activated sludge is separated in a specified ratio. The first separated stream is sent back to the inlet 
of the activated sludge system and the second one is fed to the clarifier which is the last unit in the 
wastewater treatment plant. Compared to ASM1, the wastewater treatment plant in interest has no 
anaerobic section in the activated sludge section. In addition, there are two activated sludges, and 
their inlet stream is separated into two at the outlet of the DAF. The representation of the process 
is shown in Fig. 1. 
 
 
Fig. 1. Representation of the industrial wastewater treatment model. 
 
 
 
 
9 
3. Methodology 
Artificial neural networks are mathematical representation of input and output relations. In an 
artificial neural networks structure inspired by neural connections in the brain, there are user 
defined number of hidden layers and neurons at each layer. A feed-forward and fully connected 
artificial neural network can be represented as:  
 
𝑦̂ = 𝑓1(𝑤1𝑓2(𝑤2𝑥 + 𝑏2) + 𝑏1) 
(2) 
 
where 𝑥  is input, 𝑦̂ is the predicted output, 𝑓1 and 𝑓2 are activation functions, 𝑤1 and 𝑤2 are weight 
terms, 𝑏1 and 𝑏2 are bias terms for output and hidden layers, respectively. For a recurrent neural 
network, the mathematical expression of the predicted output is as follows:   
 
ℎ𝑡 = 𝑓2(𝑤2𝑢𝑡 + 𝑤2ℎ𝑡−1 + 𝑏2) 
(3a) 
𝑦̂𝑡 = 𝑓1(𝑤1𝑓2(𝑤2𝑥𝑡 + 𝑤2ℎ𝑡−1 + 𝑏2) + 𝑏1) 
(3b) 
 
where 𝑡 is the time step and ℎ𝑡 and 𝑦̂𝑡  are hidden state and current state output, respectively. The 
structure of a simple RNN is represented in Fig. 2 [42]. 
 
 
Fig. 2. Simple RNN structure. 
 
 
10 
Recurrent neural networks often suffer from “vanishing gradient problem” in which gradients 
become extremely small as they are backpropagated from output layer to previous layers [43]. As 
a solution to this issue, LSTM blocks are widely used where the flow of information and gradients 
are controlled by three gates of of the each cell, named input, forget and output gates. LSTM 
equations are listed as: [1] 
 
𝑖𝑡 = 𝜎(𝑤𝑖𝑥𝑡 + 𝑢𝑖ℎ𝑡−1 + 𝑏𝑖) 
(4a) 
𝑓𝑡 = 𝜎(𝑤𝑓𝑥𝑡 + 𝑢𝑓ℎ𝑡−1 + 𝑏𝑓) 
(4b) 
𝑜𝑡 = 𝜎(𝑤𝑜𝑥𝑡 + 𝑢𝑜ℎ𝑡−1 + 𝑏𝑜) 
(4c) 
𝑐̃𝑡 = tanh(𝑤𝑐𝑥𝑡 + 𝑢𝑐ℎ𝑡−1 + 𝑏𝑐) 
(4d) 
𝑐𝑡 = 𝑓𝑡 ⊙ 𝑐𝑡−1 + 𝑖𝑡 ⊙ 𝑐̃𝑡 
(4e) 
ℎ𝑡 = 𝑜𝑡 ⊙ 𝑡𝑎𝑛ℎ(𝑐𝑡) 
(4f) 
 
where σ is the sigmoid function, 𝑓𝑡 is the forget gate activation vector, 𝑖𝑡 is the input gate activation 
factor, 𝑜𝑡 is the output gate activation factor, 𝑐𝑡 is the cell state vector, 𝑐̃𝑡is the cell input activation 
vector,  ⊙ is the Hadamart product, 𝑤𝑖, 𝑤𝑓, 𝑤𝑐, 𝑢𝑖, 𝑢𝑓, 𝑢𝑐, 𝑏𝑖, 𝑏𝑓, 𝑏𝑐 are weight and bias terms.  
 
In addition, gated recurrent units (GRU) are another version of RNNs consisting of two gates 
called reset and update without having a cell. The equations for a GRU structure are given below 
[44]: 
 
𝑧𝑡 = 𝜎(𝑤𝑧𝑥𝑡 + 𝑢𝑧ℎ𝑡−1 + 𝑏𝑧) 
(5a) 
𝑟𝑡 = 𝜎(𝑤𝑟𝑥𝑡 + 𝑢𝑟ℎ𝑡−1 + 𝑏𝑟) 
(5b) 
ℎ̃𝑡 = 𝑡𝑎𝑛ℎ(𝑤ℎ𝑥𝑡 + 𝑢ℎ(𝑟𝑡 ⊙ ℎ𝑡−1) + 𝑏ℎ) 
(5c) 
ℎ𝑡 = (1 − 𝑧𝑡) ⊙ ℎ𝑡−1 + 𝑧𝑡 ⊙ ℎ̃𝑡 
(5d) 
 
 
11 
where ℎ𝑡 is the output vector, ℎ̃𝑡 is the candidate activation vector, 𝑧𝑡 is the update gate vector, 
and 𝑟𝑡 is the reset gate vector. GRU has a simpler structure compared to LSTM. As a result, GRU 
has less parameters and computationally more advantageous. However, GRU structure may not be 
as efficient as LSTM to preserve the long-term dependencies. Therefore, it is more suitable for the 
smaller datasets [45]. The structure of the LSTM and GRU are represented in Fig. 3 [42].  
 
 
LSTM 
GRU 
 
 
(a) 
(b) 
Fig. 3. LSTM and GRU structure. 
 
One way to evaluate the training and test performance of the models is mean squared error (MSE) 
which is calculated as follows:  
 
1
𝑁 ∑(𝑦̂𝑖 − 𝑦𝑖)2
𝑁
𝑖=1
 
(6) 
 
Mean absolute error (MAE) is another metric to evaluate the performance of the models. MAE is 
calculated as follows:  
 
 
12 
𝑀𝐴𝐸 = 1
𝑁 ∑|𝑦̂𝑖 − 𝑦𝑖|
𝑁
𝑖=1
 
(7) 
 
Training is an optimization problem in which MSE is minimized. During training an LSTM 
network, the objective function of the training problem becomes: 
 
𝑚𝑖𝑛𝑤𝑖,𝑤𝑓,𝑤𝑐,𝑢𝑖,𝑢𝑓,𝑢𝑐,𝑏𝑖,𝑏𝑓,𝑏𝑐
1
𝑁 ∑(𝑦̂𝑖 − 𝑦𝑖)2
𝑁
𝑖=1
 
(8) 
 
Physics informed neural networks are widely used to increase the prediction performance and to 
handle the issues related to the black-box nature of neural network training. One way to make a 
neural network is embedding a physics term to the objective function so that the neural network 
minimizes the error and obeys the physics rule simultaneously. In case of static neural networks, 
the change in the objective function is straightforward:  
 
𝑚𝑖𝑛𝑤1,𝑤2,𝑏1,𝑏1
1
𝑁 ∑(𝑦̂𝑖 − 𝑦𝑖)2
𝑁
𝑖=1
+ (𝛼𝒑) 
(9) 
 
where 𝒑 is the physics term and 𝛼 is the weight for the physics term.  
 
Recurrent neural networks are dynamic structures governed by differential equations. In order to 
embed a physics term to the objective function, firstly the discretized form of the differential 
equation according to the Euler backward method is used:  
 
𝑦𝑛 = 𝑦𝑛−1 + (𝑡𝑛 − 𝑡𝑛−1)𝑓(𝑥𝑛,𝑦𝑛,𝑡𝑛) 
(10) 
 
 
13 
where t is the time and n is the time step. Rewriting the expression so that the left and the right- 
hand sides represent the actual and the predicted values, respectively:  
 
𝑦𝑛 − 𝑦𝑛−1 = (𝑡𝑛 − 𝑡𝑛−1)𝑓(𝑥𝑛,𝑦𝑛,𝑡𝑛) 
(11) 
 
As a result, the physics term can be written regarding that the square of the difference between the 
left and the right hand-sides of the Eq.11 should be minimized. Then, physics term for the recurrent 
neural network structures, represented as 𝒑𝒓becomes:  
 
𝒑𝒓 = 1
𝑁 ∑(𝑦𝑖 − 𝑦𝑖−1 − (𝑡𝑖 − 𝑡𝑖−1)𝑓(𝑥𝑖,𝑦̂𝑖, 𝑡𝑖))2
𝑁
𝑖=1
 
(12) 
 
Embedding the physics term to the objective function and rewriting Eq. 8:  
 
𝑚𝑖𝑛𝑤𝑖,𝑤𝑓,𝑤𝑐,𝑢𝑖,𝑢𝑓,𝑢𝑐,𝑏𝑖,𝑏𝑓,𝑏𝑐
1
𝑁 ∑(𝑦̂𝑖 − 𝑦𝑖)2
𝑁
𝑖=1
+ 𝛼𝒑𝒓 
(13) 
 
Transfer learning is transferring the knowledge from a related task to the target one where data is 
scarce, aiming to increase the prediction performance. Based on ANN or RNN structures, transfer 
learning scheme can be constructed as a combination of a source model and a target model. The 
schematic representation of the steps of the transfer learning is given in Fig. 4.  
 
14 
 
Fig. 4. Steps of the transfer learning. 
 
The explanation of the steps are as follows:  
Step 1: Creating the source model  
The source model is trained aiming to achieve lowest MSE. The resulting model is called the 
“pretrained model”.  
Step 2. Freezing the transferred layers and constructing the custom model   
The layers of the pretrained model with their weight and bias information are transferred to the 
target model. Additional layers are added to this model. However, the layers transferred from the 
pretrained model are frozen which keeps the weight and bias terms in these layers fixed. The 
resulting model with transferred and additional layers are called “custom model”. Mathematically, 
this means that 𝑤𝑖, 𝑤𝑓, 𝑤𝑐, 𝑢𝑖, 𝑢𝑓, 𝑢𝑐, 𝑏𝑖, 𝑏𝑓, 𝑏𝑐 corresponding to the layers of the source model 
are fixed. However, these terms corresponding to the new custom model are still decision variables 
to be determined during the training step.  
Step 3. Training the custom model 
The custom model is trained based on the predefined hyperparameters.  
 
15 
Step 4. Fine tuning  
In the last step, all layers are unfrozen. The obtained model in Step 3 is retrained with a low 
learning rate such as 10-5. Mathematically, this means that all 𝑤𝑖, 𝑤𝑓, 𝑤𝑐, 𝑢𝑖, 𝑢𝑓, 𝑢𝑐, 𝑏𝑖, 𝑏𝑓, 𝑏𝑐 
corresponding to the source and the custom model are again decision variables but they are subject 
to the specified learning rate. This step enables to decreasing errors as a result of the dissimilarity 
between the source and the target model and adjust the weight and bias terms to obtain the final 
model.  
 
The transfer learning structure is represented in Fig. 5.  
 
 
Fig. 5. Transfer learning structure. 
 
Similarly, to construct a physics informed transfer learning model, only the objective function can 
be changed regarding the neural network structure. If static neural networks are used and the 
physics of the process are in algebraic relations, the physics term can be directly embedded to the 
objective function of the custom model. Otherwise, if recurrent neural networks are used and the 
 
16 
physics of the process are governed by differential equations, Euler backward method provides 
discretized form of these relations which enables embedding the physics term to the objective 
function.  
 
4. Results & Discussion  
4.1.Problem Statement  
Activated sludge plays a pivotal role in wastewater treatment, serving as the core of the system 
where biological treatment occurs, separating a significant portion of waste from water. 
Maintaining an optimal dissolved oxygen concentration is crucial for sustaining the aerobic 
bacteria responsible for biological treatment. Regular measurement of dissolved oxygen 
concentration is performed, and oxygen is supplied to the activated sludge system through aerators, 
which consume energy. 
 
The objective of this study is to predict the dissolved oxygen concentration at activated sludge A 
in the target plant, as depicted in Figure 1. The features considered for prediction include DAF 
outlet properties (pH, TSS, COD, grease, NH4-N, phenol, sulfur), TSS at return activated sludge, 
and TSS at activated sludge A and B. The measurements are averaged over a 1-day interval. The 
training procedure is executed using the TensorFlow and Keras frameworks [46], [47], with 
hyperbolic tangent is chosen as the activation function for the hidden layers. The Adam optimizer 
algorithm is selected for training [48]. The time-step is set to 5 days in accordance with process 
requirements determined by the operation group. Among neural network architectures, including 
ANN, simple RNN, LSTM, and GRU, LSTM is chosen as the machine learning model, having 
demonstrated convergence to the lowest Mean Squared Error (MSE). Hyperparameters are fine-
tuned through a trial-and-error process. 
 
 
17 
At the initial stage of the research, around 700 data points were available for training and testing. 
Data normalization is performed between -1 and +1, and the training ratio is set at 90%. The data 
is sequential and not shuffled due to the dynamic nature of the process. After model construction, 
an offline validation procedure is executed, incorporating 200 sequential days from the end of the 
test dataset. Three different models with varying complexities are trained and evaluated. 
 
The first model, termed the standard model, achieves the best test and validation performance 
among the trials. It is trained with 5 hidden layers, each comprising 30 neurons. The second model, 
more complex than the standard model, is trained with 6 hidden layers and 60 neurons. Finally, a 
less complex model is trained with 3 hidden layers, each comprising 20 neurons. 
 
The training, test, and validation performance results for each model are presented in the first three 
rows of Tables 1 and 2. Additionally, the trends are visualized in Fig. 6. The standard model, 
exhibiting superior test and validation performance, serves as a benchmark for comparison with 
the more complex and less complex models. 
 
Table 1 
MSE of different models. 
MSE 
Train 
Test 
Validation 
Standard 
0.020 
0.044 
0.098 
More complex 
0.015 
0.045 
0.133 
Less complex 
0.026 
0.048 
0.110 
Open-Source TL 
0.030 
0.037 
0.042 
Industrial TL 
0.030 
0.035 
0.052 
Physics Informed TL 
0.028 
0.032 
0.040 
 
 
18 
 
Table 2 
MAE of different models. 
MAE 
Train 
Test 
Validation 
Standard 
0.113 
0.155 
0.246 
More complex 
0.098 
0.166 
0.255 
Less complex 
0.122 
0.179 
0.261 
Open-Source TL 
0.121 
0.149 
0.142 
Industrial TL 
0.120 
0.141 
0.159 
Physics Informed TL 
0.113 
0.135 
0.132 
 
 
 
Standard and More Complex 
Standard and Less Complex 
Training 
 
(a) 
 
(d) 
Test 
 
(b) 
 
(e) 
 
19 
Validation 
 
(c) 
 
(f) 
Fig. 6. Trends for standard, more complex and less complex models. 
 
The training performance of the more complex model surpasses that of the standard model, 
indicating a seemingly better fit to the training data. However, the test and validation MSE and 
MAE deteriorate as the number of layers and neurons is increased. The deviation becomes notably 
pronounced in the right-hand side of the validation trend, especially after the 850th day, where the 
more complex model diverges significantly from the actual trend. This divergence is accompanied 
by a considerable gap between the predicted and actual values, marking an overfitting of the 
process under consideration. The increased complexity of the model, while capturing intricacies 
in the training data, fails to generalize well to unseen data. 
 
Conversely, reducing the number of layers and neurons results in an underfit, with worsened 
training, test, and validation performance. The deviation from actual values is once again more 
pronounced in the validation trend, particularly during the days 720-800 and 850-875. These 
outcomes underscore the delicate balance required in model complexity for accurate prediction of 
dissolved oxygen concentration at the activated sludge. A more nuanced approach, integrating 
classical machine learning with complementary methods, is necessary to achieve a more precise 
and robust prediction. This can involve leveraging techniques such as transfer learning or physics-
informed models, as discussed in previous sections, to enhance the performance and generalization 
capabilities of the model. 
 
20 
 
4.2.Transfer Learning with an Open-Source Plant 
Transfer learning indeed provides a promising avenue to address the limitations of classical 
machine learning and enhance prediction performance. In this study, the ASM1 model [33] is 
selected as the first source model to improve the prediction performance of the target model. The 
source model is constructed using features such as readily and slowly biodegradable substrates, 
particulate inert organic matter, feed flow rate, soluble and particulate biodegradable organic 
nitrogen, active heterotrophic biomass, and ammonium nitrogen. 
 
 For the source model, LSTM architecture is employed, featuring 5 hidden layers and 25 neurons 
at each layer, with the hyperbolic tangent function serving as the activation function. The dataset, 
comprising 673 data points, is not shuffled, as the sequential nature of the days is preserved. The 
resulting figures are presented in Fig. 7.a. and Fig. 7.b., with corresponding performance metrics 
outlined in the first column of Table 3. 
 
 
Training 
Test 
Open-Source 
Model 
(ASM1) 
 
(a) 
 
(b) 
 
21 
Industrial 
Model 
 
 
(c) 
 
(d)  
Fig. 7. Trends for open-source and industrial transfer learning models. 
 
Table 3 
Metrics for open-source and industrial source models. 
Metric 
Open-Source Model 
Industrial Source Model 
Training MSE 
0.0019 
0.0262 
Test MSE 
0.0017 
0.0485 
Training MAE 
0.0336 
0.1167 
Test MAE 
0.0318 
0.1550 
 
In the pursuit of enhancing prediction performance, three layers of the open-source model are 
transferred to the target task. The custom model is designed with careful consideration to combine 
the source and target models, accounting for their differing numbers of features. The first layer, 
utilizing the identity function, includes 9 neurons, matching the number of features plus the output 
of the open-source model. This layer facilitates the integration of the source and target models, 
having potentially different type and number of features and targets. 
 
Subsequently, the first 3 layers of the open-source model are transferred, and their weights are 
frozen. These frozen layers are followed by 6 additional layers, each comprising 30 neurons, where 
training is allowed. The output layer employs the identity function with a single output. The custom 
 
22 
model is trained, and in the final step, fine-tuning is performed with all layers set as trainable, 
employing a learning rate of 10-5. The resulting model is named ""Open-Source TL,"" with 
performance metrics provided in the fourth row of Tables 1 and 2. The trends for training, test, 
and validation are illustrated in the first column of Fig. 8. 
 
While the training performance experiences a slight decline when layers of the open-source model 
are transferred, the test and validation performances see notable improvements. In terms of MSE, 
the test and validation performances exhibit enhancements of 15% and 36%, respectively. 
Correspondingly, MAE is reduced by 4% and 42% compared to the standard model for the test 
and validation performances. Particularly noteworthy is the strength of the usage of the open-
Source TL model, which becomes more apparent in the validation set. The trends also demonstrate 
a reduction in the gap between actual values and the standard model prediction during the 725-800 
days interval when knowledge from the open-source model is transferred. Consequently, the 
deviation around the 850th day is much smaller compared to the standard model prediction. 
 
These results might be considered as promising, since they highlight the potential of transfer 
learning to improve prediction performance, even when the source model has dissimilarities with 
the target model. Despite the challenges of industrial processes, such as intermittent inputs, noise, 
and data scarcity, the open-source model's knowledge, based on equation-based simulations, 
significantly enhances the prediction performance of the machine learning model through transfer 
learning. The transferred layers enable the industrial data to align with the general physics of the 
process, contributing to the overall improvement in prediction accuracy. 
 
4.3.Transfer Learning with an Industrial Source Plant  
The second case study involves transferring knowledge from another industrial plant within the 
same city, both equipped with wastewater treatment units. The target wastewater treatment unit is 
 
23 
relatively new, having undergone maintenance for only a few years, while the source comprises 
an older plant with a dataset size of 600, smaller than the target model. Despite the smaller dataset 
and potential noise in measurements due to real plant conditions, the advantage lies in the 
similarity in structure and location between the two plants. The overarching question of this case 
study is whether the prediction performance of the target plant can be improved by employing a 
source model trained on noisy data with a smaller set size, leveraging the advantage of structural 
and locational similarities. 
 
In the initial step, the source plant is trained using LSTM with an 80% training ratio, employing 6 
hidden layers with 120 neurons each. The available features for the source model include OWS 
feed flow rate and three DAF outlet properties (pH, COD, NH4-N). The activation function 
employed is hyperbolic tangent. The trends are visualized in the second row of Fig. 7, and the 
corresponding metrics are provided in the second column of Table 3. The test results, as shown in 
Fig. 7.d, indicate that they are not as satisfactory as those observed in the open-source model. 
 
In the subsequent step, the first layer is constructed with the identity function and 5 neurons (total 
number of features and the output). The transferred layers are frozen, followed by an additional 3 
layers with 30 neurons each. After completing the training procedure, fine-tuning is initiated with 
a learning rate of 10-5. The resulting model is termed ""Industrial TL,"" and its trends are displayed 
in the second column of Fig. 8. Metrics for this model are provided in the last row of Table 1 and 
2. 
 
While the training performance is inferior to the standard model, both test and validation 
performances are enhanced. The Industrial TL model improves MSE by 20% for the test set and 
47% for the validation set. Similarly, for MAE, the model enhances test and validation 
performance by 9% and 35%, respectively. The trends indicate notable improvements, particularly 
 
24 
in the validation segment. The gap between the standard and actual values for the 725-800th days 
is closed when knowledge from the industrial source model is transferred to the target model. 
Consequently, the disparity between actual values and the standard model prediction diminishes 
around the 850th and 900th days. These results illustrate that despite the source model's smaller 
dataset size and potential noise in measurements, transfer learning effectively exploits the 
structural and locational similarities between the source and target models to enhance prediction 
performance. In many standard ANN or RNN studies, the validation step mismatches can be easily 
classified as measurement issues or unpredictable and unmeasured disturbances, but this study 
shows that many uncaught operation swings and trends changes can be captured well using transfer 
learning. 
 
 
Open-Source TL 
Industrial TL 
Training 
 
(a) 
 
(d) 
Test 
 
(b) 
 
(e) 
 
25 
Validation 
 
(c) 
 
(f) 
Fig. 8. Trends for open-source TL and industrial TL models. 
 
 
4.4.Physics-Informed Transfer Learning with an Industrial Source Plant 
The concluding case study integrates the transfer learning model from the preceding section with 
an industrial source plant and incorporates physics information derived from the open-source 
model. This enhanced model represents an upgraded version of the previous industrial transfer 
learning model, featuring a distinct objective function. Specifically, the physics loss associated 
with dissolved oxygen concentration in ASM1 [33] is integrated into the objective function, 
compelling the training process to adhere to the underlying physics principles. For detailed physics 
information, readers are referred to Eq. 1 and ASM1 [33].  
 
In the physics-informed transfer learning model (PITL), the initial layer once again employs the 
identity activation function. Three layers are transferred from the industrial source model and held 
constant (frozen). Subsequently, three additional layers are appended to the model, resulting in a 
custom architecture that incorporates a physics-informed loss function. In contrast to previous 
transfer learning models, where custom layers were implemented as LSTM units due to their 
convergence to lower MSE, the PITL model yielded suboptimal results when LSTM layers were 
employed in this context. This outcome was anticipated, as the combination of transfer learning 
and a physics-informed loss function can increase model complexity. To address this, and to 
 
26 
leverage the advantages of both transfer learning and physics-informed neural networks, the 
custom layers are structured as simple RNNs, which converge to lower MSE compared to LSTM 
and GRU structures. 
 
The final PITL model exhibits lower test and validation MSE not only compared to the standard 
model but also in comparison to the industrial transfer learning model. The results presented in 
Table 1 indicate a 27% reduction in test MSE and a 59% reduction in validation MSE compared 
to the standard model. Similarly, MAE improvements for test and validation are 13% and 46%, 
respectively. Furthermore, in comparison to the industrial transfer learning model, the PITL model 
demonstrates improvements of 9% in test MSE, 23% in validation MSE, 4% in test MAE, and 
17% in validation MAE. 
 
The left column of Fig. 9 illustrates the trend comparison with the standard model, while the right 
column displays the comparison between the PITL and the industrial transfer learning model. Over 
the validation period, the PITL predictions closely align with actual values, particularly after the 
800th day, showcasing the model's superior performance compared to both the standard model and 
the industrial transfer learning model. 
 
These results highlight that the combination of a physics-informed objective function and transfer 
learning allows for a simplified model structure, utilizing simple RNN layers instead of more 
complex structures like LSTM. Consequently, this approach enhances the sequential prediction 
performance compared to classical machine learning and standard transfer learning. Importantly, 
despite the physics information and transferred model not being specific to the target model, the 
final model effectively leverages related information from both first principles and machine 
learning models. This promising outcome suggests that the integration of physics-informed neural 
 
27 
networks and transfer learning, when applied to industrial data, presents a novel and effective 
solution to real-world challenges. 
 
 
PITL and the standard model 
PITL and the industrial TL model 
Training 
 
(a) 
 
(d) 
Test 
 
(b) 
 
(e) 
Validation 
 
(c) 
 
(f) 
Fig. 9. Trends for PITL model. 
 
 
 
28 
5. Conclusion  
In this work, utilization of transfer learning to regression problems related to complex and actual 
plants is discussed. The prediction performance of dissolved oxygen concentration at the activated 
sludge of an industrial refinery’s wastewater treatment plant is increased by three transfer learning 
cases. The initial source model, ASM1, is an open-source simulation model, but its structure differs 
significantly from that of the target plant. The second source model represents another wastewater 
treatment plant within the same refinery. Despite having fewer available features and a smaller 
dataset, the model is compromised by noisy measurements due to real-life conditions. Despite 
these drawbacks in the two source models, the implementation of transfer learning has effectively 
boosted the prediction performance of the target plant. 
 
Notably, a physics-informed transfer learning (PITL) model is devised, incorporating the layers of 
the industrial source model while introducing a customized objective function during the training 
process. This objective function integrates physics information derived from the open-source 
model. The resulting PITL model converges to the lowest MSE and MAE for both test and 
validation sets. Consequently, the validation MSE for the PITL model is approximately 60% lower 
than that of the classical machine learning model. 
 
The study reveals the inadequacy of the classical dynamic (recurrent) machine learning approach, 
illustrating that choosing for either a less or more complex model resulted in underfitting and 
overfitting, respectively. Transfer learning, however, proves to be a viable solution, leveraging 
knowledge from related tasks, even in scenarios where the number of features prevents dataset 
integration. Furthermore, the combination of physics-based information derived from the open-
source model and the machine learning model tailored to the target task yields the best model fit.  
 
 
 
29 
Acknowledgements 
We gratefully acknowledge TÜPRAS¸ refinery and TÜPRAS¸ R&D department for their 
contributions and support. 
 
 
References  
[1] 
S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural Comput, vol. 9, 
no. 8, pp. 1735–1780, 1997, doi: https://doi.org/10.1162/neco.1997.9.8.1735. 
[2] 
A. Thebelt, J. Wiebe, J. Kronqvist, C. Tsay, and R. Misener, “Maximizing information 
from chemical engineering data sets: Applications to machine learning,” Chem Eng Sci, 
vol. 252, Apr. 2022, doi: 10.1016/j.ces.2022.117469. 
[3] 
M. Raissi, P. Perdikaris, and G. E. Karniadakis, “Physics Informed Deep Learning (Part 
I): Data-driven Solutions of Nonlinear Partial Differential Equations,” Nov. 2017, 
[Online]. Available: http://arxiv.org/abs/1711.10561 
[4] 
M. Raissi, P. Perdikaris, and G. E. Karniadakis, “Physics-informed neural networks: A 
deep learning framework for solving forward and inverse problems involving nonlinear 
partial differential equations,” J Comput Phys, vol. 378, pp. 686–707, Feb. 2019, doi: 
10.1016/j.jcp.2018.10.045. 
[5] 
J. Stiasny, S. Chevalier, and S. Chatzivasileiadis, “Learning without Data: Physics-
Informed Neural Networks for Fast Time-Domain Simulation,” 2021 IEEE International 
Conference on Communications, Control, and Computing Technologies for Smart Grids 
(SmartGridComm), 2021, doi: 10.1109/SMARTGRIDCOMM51999.2021.963. 
[6] 
R. Nellikkath and S. Chatzivasileiadis, “Physics-Informed Neural Networks for AC 
Optimal Power Flow,” Oct. 2021, [Online]. Available: http://arxiv.org/abs/2110.02672 
[7] 
R. Nellikkath and S. Chatzivasileiadis, “Physics-Informed Neural Networks for 
Minimising Worst-Case Violations in DC Optimal Power Flow,” in 2021 IEEE 
 
30 
International Conference on Communications, Control, and Computing Technologies for 
Smart Grids, SmartGridComm 2021, Institute of Electrical and Electronics Engineers Inc., 
2021, pp. 419–424. doi: 10.1109/SmartGridComm51999.2021.9632308. 
[8] 
F. Masi, I. Stefanou, P. Vannucci, and V. Maffi-Berthier, “Thermodynamics-based 
Artificial Neural Networks for constitutive modeling,” J Mech Phys Solids, vol. 147, Feb. 
2021, doi: 10.1016/j.jmps.2020.104277. 
[9] 
G. P. P. Pun, R. Batra, R. Ramprasad, and Y. Mishin, “Physically informed artificial 
neural networks for atomistic modeling of materials,” Nat Commun, vol. 10, no. 1, Dec. 
2019, doi: 10.1038/s41467-019-10343-5. 
[10] E. S. Koksal and E. Aydin, “Physics Informed Piecewise Linear Neural Networks for 
Process Optimization,” Comput Chem Eng, vol. 174, Jun. 2023, doi: 
10.1016/j.compchemeng.2023.108244. 
[11] T. Asrav and E. Aydin, “Physics-informed recurrent neural networks and hyper-parameter 
optimization for dynamic process systems,” Comput Chem Eng, vol. 173, May 2023, doi: 
10.1016/j.compchemeng.2023.108195. 
[12] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Transactions on Knowledge 
and Data Engineering, vol. 22, no. 10. pp. 1345–1359, 2010. doi: 
10.1109/TKDE.2009.191. 
[13] F. Zhuang et al., “A Comprehensive Survey on Transfer Learning,” Proceedings of the 
IEEE, vol. 109, no. 1. Institute of Electrical and Electronics Engineers Inc., pp. 43–76, 
Jan. 01, 2021. doi: 10.1109/JPROC.2020.3004555. 
[14] M. Shaha and M. Pawar, “Transfer Learning for Image Classification,” in Proceedings of 
the 2nd International Conference on Electronics, Communication and Aerospace 
Technology, ICECA 2018, Institute of Electrical and Electronics Engineers Inc., Sep. 
2018, pp. 656–660. doi: 10.1109/ICECA.2018.8474802. 
 
31 
[15] C. Cai et al., “Transfer Learning for Drug Discovery,” J Med Chem, vol. 63, no. 16, pp. 
8683–8694, Aug. 2020, doi: 10.1021/acs.jmedchem.9b02147. 
[16] W. Li, S. Gu, X. Zhang, and T. Chen, “Transfer learning for process fault diagnosis: 
Knowledge transfer from simulation to physical processes,” Comput Chem Eng, vol. 139, 
Aug. 2020, doi: 10.1016/j.compchemeng.2020.106904. 
[17] G. Lindner, S. Shi, S. Vučetić, and S. Mišković, “Transfer learning for radioactive particle 
tracking,” Chem Eng Sci, vol. 248, Feb. 2022, doi: 10.1016/j.ces.2021.117190. 
[18] A. Eldeib, T. Basha, Inas. Yassine, IEEE Engineering in Medicine and Biology Society, 
and Institute of Electrical and Electronics Engineers, “Skin Cancer Classification using 
Deep Learning and Transfer Learning,” in 9th Cairo International Biomedical 
Engineering Conference (CIBEC) : conference proceedings : 20-22 December, 2018, 
Hilton Pyramids, Egypt, 2018. 
[19] B. Li and S. Rangarajan, “A conceptual study of transfer learning with linear models for 
data-driven property prediction,” Comput Chem Eng, vol. 157, Jan. 2022, doi: 
10.1016/j.compchemeng.2021.107599. 
[20] Y. Da Hsiao, J. L. Kang, and D. S. H. Wong, “Development of robust and physically 
interpretable soft sensor for industrial distillation column using transfer learning with 
small datasets,” Processes, vol. 9, no. 4, Apr. 2021, doi: 10.3390/pr9040667. 
[21] R. Ma, Y. J. Colón, and T. Luo, “Transfer Learning Study of Gas Adsorption in Metal-
Organic Frameworks,” ACS Appl Mater Interfaces, vol. 12, no. 30, pp. 34041–34048, Jul. 
2020, doi: 10.1021/acsami.0c06858. 
[22] Y. C. Chuang, T. Chen, Y. Yao, and D. S. H. Wong, “Transfer learning for efficient meta-
modeling of process simulations,” Chemical Engineering Research and Design, vol. 138, 
pp. 546–553, Oct. 2018, doi: 10.1016/j.cherd.2018.07.008. 
 
32 
[23] A. W. Rogers, F. Vega-Ramon, J. Yan, E. A. del Río-Chanona, K. Jing, and D. Zhang, “A 
transfer learning approach for predictive modeling of bioprocesses using small data,” 
Biotechnol Bioeng, vol. 119, no. 2, pp. 411–422, Feb. 2022, doi: 10.1002/bit.27980. 
[24] H. Wu and J. Zhao, “Fault detection and diagnosis based on transfer learning for 
multimode chemical processes,” Comput Chem Eng, vol. 135, Apr. 2020, doi: 
10.1016/j.compchemeng.2020.106731. 
[25] K. Bi, B. Beykal, S. Avraamidou, I. Pappas, E. N. Pistikopoulos, and T. Qiu, “Integrated 
Modeling of Transfer Learning and Intelligent Heuristic Optimization for a Steam 
Cracking Process,” Ind Eng Chem Res, vol. 59, no. 37, pp. 16357–16367, Sep. 2020, doi: 
10.1021/acs.iecr.0c02657. 
[26] I. Pisa, A. Morell, J. L. Vicario, and R. Vilanova, “Transfer Learning Approach for the 
Design of Basic Control Loops in Wastewater Treatment Plants,” in IEEE International 
Conference on Emerging Technologies and Factory Automation, ETFA, Institute of 
Electrical and Electronics Engineers Inc., 2021. doi: 10.1109/ETFA45728.2021.9613360. 
[27] S. Huang et al., “Construction and application of effluent quality prediction model with 
insufficient data based on transfer learning algorithm in wastewater treatment plants,” 
Biochem Eng J, vol. 191, Feb. 2023, doi: 10.1016/j.bej.2023.108807. 
[28] J. L. Lansford, K. F. Jensen, and B. C. Barnes, “Physics-informed Transfer Learning for 
Out-of-sample Vapor Pressure Predictions,” Propellants, Explosives, Pyrotechnics, Mar. 
2023, doi: 10.1002/prep.202200265. 
[29] F. Guc and Y. Q. Chen, “Fault Cause Assignment with Physics Informed Transfer 
Learning,” in IFAC-PapersOnLine, Elsevier B.V., Nov. 2021, pp. 53–58. doi: 
10.1016/j.ifacol.2021.11.152. 
[30] L. Schröder, N. K. Dimitrov, D. R. Verelst, and J. A. Sørensen, “Using Transfer Learning 
to Build Physics-Informed Machine Learning Models for Improved Wind Farm 
Monitoring,” Energies (Basel), vol. 15, no. 2, Jan. 2022, doi: 10.3390/en15020558. 
 
33 
[31] S. Goswami, C. Anitescu, S. Chakraborty, and T. Rabczuk, “Transfer learning enhanced 
physics informed neural network for phase-field modeling of fracture,” Theoretical and 
Applied Fracture Mechanics, vol. 106, Apr. 2020, doi: 10.1016/j.tafmec.2019.102447. 
[32] C. Xu, B. T. Cao, Y. Yuan, and G. Meschke, “Transfer learning based physics-informed 
neural networks for solving inverse problems in engineering structures under different 
loading scenarios,” May 2022, doi: 10.1016/j.cma.2022.115852. 
[33] M. Henze, C. P. Leslie Grady Jr, W. Gujer Eawag, G. V R Marais, and T. Matsuo, “A 
General Model for Single-Sludge Wastewater Treatment Systems,” 1987. 
[34] J. Alex et al., “The COST simulation benchmark,” European Commission Directorate-
General for Research, 2002. 
[35] J. Alex et al., “Benchmark Simulation Model no. 1 (BSM1),” 2018. 
[36] E. Pittoors, Y. Guo, and S. W. H. Van Hulle, “Modeling Dissolved Oxygen Concentration 
for Optimizing Aeration Systems and Reducing Oxygen Consumption in Activated 
Sludge Processes: A Review,” Chemical Engineering Communications, vol. 201, no. 8. 
Taylor and Francis Ltd., pp. 983–1002, 2014. doi: 10.1080/00986445.2014.883974. 
[37] M. J. Lin and F. Luo, “An adaptive control method for the dissolved oxygen concentration 
in wastewater treatment plants,” Neural Comput Appl, vol. 26, no. 8, pp. 2027–2037, Nov. 
2015, doi: 10.1007/s00521-015-1858-3. 
[38] R. Tzoneva, “Optimal PID Control of the Dissolved Oxygen Concentration in the 
Wastewater Treatment Plant,” AFRICON 2007, Windhoek, South Africa, pp. 1–7, 2007, 
doi: 10.1109/AFRCON.2007.4401608. 
[39] B. Holenda, E. Domokos, Á. Rédey, and J. Fazakas, “Dissolved oxygen control of the 
activated sludge wastewater treatment process using model predictive control,” Comput 
Chem Eng, vol. 32, no. 6, pp. 1270–1278, 2008, doi: 
10.1016/j.compchemeng.2007.06.008. 
 
34 
[40] A. S. Qambar and M. M. Al Khalidy, “Optimizing dissolved oxygen requirement and 
energy consumption in wastewater treatment plant aeration tanks using machine learning,” 
Journal of Water Process Engineering, vol. 50, Dec. 2022, doi: 
10.1016/j.jwpe.2022.103237. 
[41] T. Asrav et al., “Physics-informed Neural Network based Modeling of an Industrial 
Wastewater Treatment Unit,” in 33rd European Symposium on Computer Aided Process 
Engineering, vol. 52, A. C. Kokossis, M. C. Georgiadis, and E. Pistikopoulos, Eds., in 
Computer Aided Chemical Engineering, vol. 52. , Elsevier, 2023, pp. 227–234. doi: 
https://doi.org/10.1016/B978-0-443-15274-0.50037-8. 
[42] M. Sit, B. Z. Demiray, Z. Xiang, G. J. Ewing, Y. Sermet, and I. Demir, “A comprehensive 
review of deep learning applications in hydrology and water resources,” Water Science 
and Technology, vol. 82, no. 12, pp. 2635–2670, Dec. 2020, doi: 10.2166/wst.2020.369. 
[43] S. Hochreiter, “The Vanishing Gradient Problem During Learning Recurrent Neural Nets 
and Problem Solutions,” International Journal of Uncertainty, Fuziness and Knowledge-
Based Systems, vol. 6, no. 2, pp. 107–116, 1998, doi: 
https://doi.org/10.1142/S0218488598000094. 
[44] K. Cho et al., “Learning Phrase Representations using RNN Encoder-Decoder for 
Statistical Machine Translation,” 2014. 
[45] J. Zhou, J. Ye, Y. Ouyang, M. Tong, X. Pan, and J. Gao, “On Building Real Time 
Intelligent Agricultural,” in Proceedings - IEEE 8th International Conference on Big Data 
Computing Service and Applications, BigDataService 2022, Institute of Electrical and 
Electronics Engineers Inc., 2022, pp. 89–95. doi: 
10.1109/BigDataService55688.2022.00021. 
[46] M. Abadi et al., TensorFlow: A System for Large-Scale Machine Learning. OSDI, 2016. 
[47] F. Chollet and et al, “Keras.” [Online]. Available: https://keras.io 
 
35 
[48] D. P. Kingma and J. Ba, “Adam: A Method for Stochastic Optimization,” Dec. 2014, 
[Online]. Available: http://arxiv.org/abs/1412.6980 
  
 
 
",Several studies in the literature employed transfer learning to increase the prediction capability and to overcome the issues of lack of useful data. Transfer learning has been applied to wastewater treatment plants in which biological treatment is achieved with activated sludge.nan
"Machinery for data analysis often requires a numeric representation
of the input. Towards that, a common practice is to embed compo-
nents of structured data into a high-dimensional vector space. We
study the embedding of the tuples of a relational database, where
existing techniques are often based on optimization tasks over a
collection of random walks from the database. The focus of this
paper is on the recent FoRWaRD algorithm that is designed for
dynamic databases, where walks are sampled by following foreign
keys between tuples. Importantly, different walks have different
schemas, or “walk schemes,” that are derived by listing the rela-
tions and attributes along the walk. Also importantly, different walk
schemes describe relationships of different natures in the database.
We show that by focusing on a few informative walk schemes,
we can obtain tuple embedding significantly faster, while retaining
the quality. We define the problem of scheme selection for tuple
embedding, devise several approaches and strategies for scheme
selection, and conduct a thorough empirical study of the perfor-
mance over a collection of downstream tasks. Our results confirm
that with effective strategies for scheme selection, we can obtain
high-quality embeddings considerably (e.g., three times) faster, pre-
serve the extensibility to newly inserted tuples, and even achieve
an increase in the precision of some tasks.","Machine-learning algorithms are conventionally designed to gener-
alize observations about numerical vectors, and hence, their appli-
cation to non-numeric data requires embeddings of these data into a
numerical vector space. The embedding should faithfully reflect the
semantics of data in the sense that similar entities are to be mapped
to vectors that are close geometrically and vice versa. Instantiations
of this practice include models like Word2Vec [17] and BERT (Bidi-
rectional Encoder Representations from Transformers) [9] that map
words (or tokens of words) in natural language [15], Node2Vec
that maps nodes of a graph [11], TransE [5] that map entities of
a knowledge graph, Mol2Vec [14] that maps molecule structures,
and EmbDI [6] and FoRWaRD [22] that map database tuples. Data-
base embeddings have enabled the deployment of machine-learning
architectures to traditional database tasks such as record similar-
ity [2–4, 12, 13], record linking [10, 19] integration tasks such as
schema, token and record matching (entity resolution) [6], and
column prediction [22]. The embedded entities are typically either
tuples or attribute values. Here we focus on tuple embeddings.
Embedding techniques are often based on the analysis of se-
quences obtained from the data. In word embedding, the data is
naturally organized in sequences (e.g., sentences or sliding win-
dows in the text) [9, 17]; in node embedding, the sequences are
paths obtained from random walks in the graph [11]; and in tuple
embedding, the sequences consist of database components (cells
and tuples) that one can reach through natural joins [6] or foreign-
key references [22]. The analysis is typically done by learning to
predict masked parts of the sequence from other parts of the se-
quence [6, 9, 11, 17]. We focus on FoRWaRD that is designed for
producing stable embeddings in dynamic databases, as we explain
next. FoRWaRD analyzes walks, which are sequences of tuples con-
nected via foreign-key references, and it does so differently from
masking. Roughly speaking, training aims for the distance between
two (vector representations of) tuples to capture the distance be-
tween the distributions of values reachable from the tuples through
foreign-key references, starting from the corresponding tuples. (We
recall the exact definition of FoRWaRD in Section 2.)
The FoRWaRD algorithm has been designed to solve the stable
embedding problem, where the goal is to infer the embedding of
the new tuples without recomputing the embedding over the entire
database and without changing the embeddings of existing tuples","In each approach, several different strategies can be proposed. In
the FoRWaRD-less approach, we look at measures that inspect the
probability distribution that one establishes by following random
walks guided by the walk scheme (in addition to simple baselines
such as eliminating the longest schemes and random schemes). The
strategy that stands out is what we call kernel variance: what is the
variance among the differences that one observes by selecting two
random starting points for the walks? In the light-training approach, we
look at two types of training restrictions: a single epoch (out of
all epochs) and a full training on a sample of the database. In the
online elimination approach, we apply the single-epoch selection
(of light training) after every epoch.","In the experiments, we follow the convention of evaluating the
embedding quality on downstream tasks and use column-prediction
tasks in the bio-medical and geography domains. Our study (Sec-
tion 5) has three parts. First, we test the performance of each se-
lection strategy as a function of the time and number of selected
schemes. Second, we conduct a comparison among the strategies in
a technique that we devise. Third, we study the performance with
the selected walk schemes in a dynamic setting. Our conclusion is
that kernel-variance performs best.","Walking through connected data items is the basis of sequence-
based embeddings like Word2Vec and Node2Vec. Database se-
quences are also associated with meta-data, namely the walk scheme.
The premise of this work was the conjecture that the walk schemes
have significant semantic value, as they can guide the embedding
algorithm to a small subset of informative sequences, thus dramati-
cally improving efficiency for a mild sacrifice of quality. We studied
the problem of selecting walk schemes in the context of FoRWaRD.
We considered different strategies of three types: FoRWaRD-less,
light training, and online scheme elimination. We conducted an
experimental study that measured the benefit of each strategy, com-
pared between them and tested how well they preserved the main
strength of FoRWaRD—extensibility to newly inserted tuples in dy-
namic settings. Our study has confirmed our conjecture and showed
that we can considerably accelerate FoRWaRD with negligent loss
of quality. Moreover, restricting the embedding phase to the right
walk schemes can even improve the quality on downstream classifi-
cation tasks. The kernel-variance strategy typically outperforms the
rest, and we recommend this one to be used alongside FoRWaRD.",Selecting Walk Schemes for Database Embedding,"Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, Benny Kimelfeld","Selecting Walk Schemes for Database Embedding
Yuval Lev Lubarsky
Technion
Haifa, Israel
lubarsky@cs.technion.ac.il
Jan Tönshoff
RWTH Aachen University
Aachen, Germany
toenshoff@informatik.rwth-aachen.de
Martin Grohe
RWTH Aachen University
Aachen, Germany
grohe@informatik.rwth-aachen.de
Benny Kimelfeld
Technion
Haifa, Israel
bennyk@cs.technion.ac.il
ABSTRACT
Machinery for data analysis often requires a numeric representation
of the input. Towards that, a common practice is to embed compo-
nents of structured data into a high-dimensional vector space. We
study the embedding of the tuples of a relational database, where
existing techniques are often based on optimization tasks over a
collection of random walks from the database. The focus of this
paper is on the recent FoRWaRD algorithm that is designed for
dynamic databases, where walks are sampled by following foreign
keys between tuples. Importantly, different walks have different
schemas, or “walk schemes,” that are derived by listing the rela-
tions and attributes along the walk. Also importantly, different walk
schemes describe relationships of different natures in the database.
We show that by focusing on a few informative walk schemes,
we can obtain tuple embedding significantly faster, while retaining
the quality. We define the problem of scheme selection for tuple
embedding, devise several approaches and strategies for scheme
selection, and conduct a thorough empirical study of the perfor-
mance over a collection of downstream tasks. Our results confirm
that with effective strategies for scheme selection, we can obtain
high-quality embeddings considerably (e.g., three times) faster, pre-
serve the extensibility to newly inserted tuples, and even achieve
an increase in the precision of some tasks.
CCS CONCEPTS
• Information systems → Relational database model; • Com-
puting methodologies → Machine learning.
KEYWORDS
Database embedding, random walks, walk schemes
ACM Reference Format:
Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, and Benny Kimelfeld. 2023.
Selecting Walk Schemes for Database Embedding. In Proceedings of the 32nd
ACM International Conference on Information and Knowledge Management
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0124-5/23/10...$15.00
https://doi.org/10.1145/3583780.3615052
(CIKM ’23), October 21–25, 2023, Birmingham, United Kingdom. ACM, New
York, NY, USA, 10 pages. https://doi.org/10.1145/3583780.3615052
1
INTRODUCTION
Machine-learning algorithms are conventionally designed to gener-
alize observations about numerical vectors, and hence, their appli-
cation to non-numeric data requires embeddings of these data into a
numerical vector space. The embedding should faithfully reflect the
semantics of data in the sense that similar entities are to be mapped
to vectors that are close geometrically and vice versa. Instantiations
of this practice include models like Word2Vec [17] and BERT (Bidi-
rectional Encoder Representations from Transformers) [9] that map
words (or tokens of words) in natural language [15], Node2Vec
that maps nodes of a graph [11], TransE [5] that map entities of
a knowledge graph, Mol2Vec [14] that maps molecule structures,
and EmbDI [6] and FoRWaRD [22] that map database tuples. Data-
base embeddings have enabled the deployment of machine-learning
architectures to traditional database tasks such as record similar-
ity [2–4, 12, 13], record linking [10, 19] integration tasks such as
schema, token and record matching (entity resolution) [6], and
column prediction [22]. The embedded entities are typically either
tuples or attribute values. Here we focus on tuple embeddings.
Embedding techniques are often based on the analysis of se-
quences obtained from the data. In word embedding, the data is
naturally organized in sequences (e.g., sentences or sliding win-
dows in the text) [9, 17]; in node embedding, the sequences are
paths obtained from random walks in the graph [11]; and in tuple
embedding, the sequences consist of database components (cells
and tuples) that one can reach through natural joins [6] or foreign-
key references [22]. The analysis is typically done by learning to
predict masked parts of the sequence from other parts of the se-
quence [6, 9, 11, 17]. We focus on FoRWaRD that is designed for
producing stable embeddings in dynamic databases, as we explain
next. FoRWaRD analyzes walks, which are sequences of tuples con-
nected via foreign-key references, and it does so differently from
masking. Roughly speaking, training aims for the distance between
two (vector representations of) tuples to capture the distance be-
tween the distributions of values reachable from the tuples through
foreign-key references, starting from the corresponding tuples. (We
recall the exact definition of FoRWaRD in Section 2.)
The FoRWaRD algorithm has been designed to solve the stable
embedding problem, where the goal is to infer the embedding of
the new tuples without recomputing the embedding over the entire
database and without changing the embeddings of existing tuples
arXiv:2401.11215v1  [cs.LG]  20 Jan 2024
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, and Benny Kimelfeld
Schema
Walk
schemes
Database
Walks
Embedding
Database
Walks
Embedding
Walk
schemes
Selected
schemes
Schema
Figure 1: FoRWaRD vs. FoRWaRD with scheme selection
(that downstream tasks might already be using and rely on past
decisions thereupon) [22]. A technique for performing this task has
been proposed along with the FoRWaRD framework [22].
A walk in a database is naturally associated with a meta-data
pattern, which is formed by taking the names of the relations of the
tuples along the sequence, as well as the names of the attributes that
are used for the (outgoing and incoming) references. This pattern
is called a walk scheme [22], and examples of these are depicted in
Figure 4 in the context of a geographical database. Sequence-based
embedding algorithms for other modalities do not encounter (and
do not account for) such meta-information in the training phase.
Our premise is that the walk scheme determines, to a large extent,
the contribution of a walk to the quality of the learned embedding.
Hence, unlike word and node embedding, in tuple embedding, we
can introduce important a-priori bias over the training sequences.
We claim and prove empirically that one can considerably reduce
the number of training walks by restricting the learning phase to
the walks of the most effective walk schemes, with a mild (or no) re-
duction in quality. Moreover, the embedding quality might improve
by filtering out walk schemes that contribute more noise than ben-
eficial information. We devise techniques for the selection of walk
schemes within FoRWaRD, as illustrated in Figure 1. To illustrate
the importance of scheme selection, a sample of our experiments is
shown in Figure 2. Here, we are using the learned embedding in the
Mondial database [21] to predict the religion of a country based on
the database’s information. Each curve corresponds to a selected
percentage of the walk schemes and shows the quality of the pre-
diction as a function of the embedding time (where each epoch
contributes a point). The actual way of selecting the walk schemes
is discussed in the next paragraphs. As the chart showed, selecting
a fifth of the walk schemes fully preserves the quality in about
one-third of the embedding time and eventually even outperforms
the embedding with the entire set of walk schemes.
The main question then is how to select the best walk schemes for
learning an embedding? This is the challenge that we focus on in
this paper. The goodness of a selection method is reflected in two
measures: (1) Efficiency—the choice should be considerably faster
than the embedding itself, and (2) Quality—the choice should be
such that we can select just a small number of walk schemes and
retain the quality of the embedding (e.g., on downstream tasks).
Regarding the efficiency measure, we already said that an important
(but not the only) use case for walk-scheme selection is that the
combined time it takes to select the walk schemes and then learn
the embedding is considerably faster than learning the embedding
on the initial full collection of walk schemes. As for the quality
0
50
100
150
200
250
60
65
70
75
80
85
Time (sec)
Accuracy (%)
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
Figure 2: Religion prediction over the Mondial dataset with
FoRWaRD and scheme selection via kernel variance. With a
fifth of the walk schemes, we get to full equality in about one-
third of the embedding time and eventually even outperform
the embedding with the entire set of walk schemes.
measure, if we are to select 𝛼% of the walk schemes and have
downstream success of 𝛽% compared to 100% of the walk schemes,
then we would like 𝛼 to be as small as possible (e.g., 10) and 𝛽 as
large as possible (e.g., 95). Actually, our experiments show cases
where 𝛽 exceeds 100 for the reason discussed above. Importantly,
the quality of the selection strategy should also apply to the stable
embedding problem in the dynamic setting. In particular, we would
like the performance of the learned embedding to reach (or even
exceed) that of the full set of walk schemes when the embedding is
extended to newly arriving tuples.
The choice can be made by ranking the walk schemes by some
scoring function and selecting the top candidates. This scoring
function can reflect properties that are hypothetically important
to the embedding but do not require seeing in action the embed-
ding algorithm, namely FoRWaRD; we refer to this approach as
FoRWaRD-less. Alternatively, one can execute the embedding al-
gorithm in some limited (light) manner and infer the walks from
that execution (or, more precisely, from the internal state of the
model); we refer to this approach as light training. Finally, one can
also eliminate walk schemes gradually during the embedding pro-
cess, where in each epoch, we estimate the importance of a walk
scheme (similarly to the way it is done in light training) and leave
a strict subset for the next epochs, until we decide that none can be
further eliminated; we refer to this approach as online scheme elim-
ination. In summary, we devise and study strategies for selecting
walk-schemes in three different approaches: (1) FoRWaRD-less, (2
light training, and (3) online scheme elimination.
In each approach, several different strategies can be proposed. In
the FoRWaRD-less approach, we look at measures that inspect the
probability distribution that one establishes by following random
walks guided by the walk scheme (in addition to simple baselines
such as eliminating the longest schemes and random schemes). The
strategy that stands out is what we call kernel variance: what is the
variance among the differences that one observes by selecting two
random starting points for the walks? In the light-training approach,
we look at two types of training restrictions: a single epoch (out of
all epochs) and a full training on a sample of the database. In the
online elimination approach, we apply the single-epoch selection
(of light training) after every epoch.
Selecting Walk Schemes for Database Embedding
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
In the experiments, we follow the convention of evaluating the
embedding quality on downstream tasks and use column-prediction
tasks in the bio-medical and geography domains. Our study (Sec-
tion 5) has three parts. First, we test the performance of each se-
lection strategy as a function of the time and number of selected
schemes. Second, we conduct a comparison among the strategies in
a technique that we devise. Third, we study the performance with
the selected walk schemes in a dynamic setting. Our conclusion is
that kernel-variance performs best.
In summary, our contributions are as follows. First, we intro-
duce the problem of scheme selection for tuple embedding. We do
so in the context of FoRWaRD, yet the problem applies to every
sequence-based database embedding. Second, we propose three ap-
proaches to scheme selection and devise several specific strategies
within each approach. Third, we conduct a thorough experimen-
tal evaluation that investigates the empirical effectiveness of the
strategies, compares them, and studies their performance in the
dynamic setting.
2
PRELIMINARIES
Relational Model. A database schema 𝜎 consists of a finite col-
lection of relation schemas 𝑅(𝐴1, . . . ,𝐴𝑘) where 𝑅 is a distinct rela-
tion name and each 𝐴𝑖 is a distinct attribute name. Each attribute
𝐴 is associated with a domain, denoted dom(𝐴). Each relation
schema 𝑅(𝐴1, . . . ,𝐴𝑘) has a unique key, denoted key(𝑅), such that
key(𝑅) ⊆ {𝐴1, . . . ,𝐴𝑘}. A fact over a relation schema 𝑅(𝐴1, . . . ,𝐴𝑘)
has the form 𝑅(𝑎1, . . . ,𝑎𝑘) where 𝑎𝑖 ∈ dom(𝐴𝑖) for all 𝑖 = 1, . . . ,𝑘.
A database 𝐷 over the schema 𝜎 is a finite set of facts over the
relation schemas of 𝜎. In addition, such an 𝑎𝑖 can be missing and
given as a distinguished null value. The fact 𝑅(𝑎1, . . . ,𝑎𝑘) is also
called an 𝑅-fact and a 𝜎-fact. We denote by 𝑅(𝐷) the restriction
of 𝐷 to its 𝑅-facts. For a fact 𝑓 = 𝑅(𝑎1, . . . ,𝑎𝑘) over 𝑅(𝐴1, . . . ,𝐴𝑘),
we denote by 𝑓 [𝐴𝑖] the value 𝑎𝑖, and by 𝑓 [𝐵1, . . . , 𝐵ℓ] the tuple
(𝑓 [𝐵1], . . . , 𝑓 [𝐵ℓ]). The active domain of an attribute 𝐴 (w.r.t. to the
database 𝐷), denoted adom𝐷 (𝐴), is the set {𝑓 [𝐴] | 𝑓 ∈ 𝑅(𝐷)}.
A foreign-key constraint (FK) is an inclusion dependency of the
form 𝑅[𝑩] ⊆ 𝑆[𝑪] where 𝑅 and𝑆 are relation names, 𝑩 = 𝐵1, . . . , 𝐵ℓ
and 𝑪 = 𝐶1, . . . ,𝐶ℓ are sequences of distinct attributes of 𝑅 and 𝑆,
respectively, and key(𝑆) = {𝐶1, . . . ,𝐶ℓ}. For every FK 𝑅[𝑩] ⊆ 𝑆[𝑪]
and 𝑅-fact 𝑓 ∈ 𝐷 there exists an 𝑆-fact𝑔 ∈ 𝐷 such that 𝑓 [𝑩] = 𝑔[𝑪].
We then say that 𝑓 references 𝑔.
FoRWaRD. The goal of FoRWaRD is to derive an embedding
function 𝛾 : 𝐷 → R𝑘 for the tuples in a database. Here, the dimen-
sion 𝑘 > 0 is a hyperparameter. The general objective is to compute
an embedding 𝛾 that represents the data in a way that makes it
accessible for data analysis and machine learning algorithms. To
this end, FoRWaRD learns embeddings that encode the distribution
of values seen along random walks through the database. Next, we
introduce FoRWaRD’s notion of random walks through databases
formally and recap how these walks are used to produce an embed-
ding. A walk scheme 𝑠 has the form
𝑅0[𝑨0]—[𝑩1]𝑅1[𝑨1]—[𝑩2]𝑅2[𝑨2]— · · · —[𝑩ℓ]𝑅ℓ
(1)
such that for all 𝑘 = 1, . . . , ℓ, either 𝑅𝑘−1[𝑨𝑘−1] ⊆ 𝑅𝑘 [𝑩𝑘] is an FK
or 𝑅𝑘 [𝑩𝑘] ⊆ 𝑅𝑘−1[𝑨𝑘−1] is an FK. We say that 𝑠 has length ℓ, that
it starts from 𝑅0, and that it ends with 𝑅ℓ.
A walk with the scheme 𝑠 is a sequence (𝑓0, . . . , 𝑓ℓ) of facts such
that 𝑓𝑘 is an 𝑅𝑘-fact and 𝑓𝑘−1[𝑨𝑘−1] = 𝑓𝑘 [𝑩𝑘] for all 𝑘 = 1, . . . , ℓ.
We say that (𝑓0, . . . , 𝑓ℓ) starts from, or has the source, 𝑓0, and that it
ends with, or has the destination, 𝑓ℓ. FoRWaRD allows walk schemes
and walks of length zero; the walks of this scheme have the form
(𝑓0) and consist of the fact 𝑓0. A random walk with 𝑠 defines a
distribution over the destinations. Formally, let 𝑓0 = 𝑓 be an 𝑅0-fact.
We denote by W(𝑓 ,𝑠) the distribution over the walks with the walk
scheme 𝑠 where each walk is sampled by starting from 𝑓0 and then
iteratively selecting 𝑓𝑘, for 𝑘 = 1, . . . , ℓ, randomly and uniformly
from the set {𝑓 ∈ 𝑅𝑘 | 𝑓 [𝑩𝑘] = 𝑓𝑘−1[𝑨𝑘−1]}]. We denote by
𝑑𝑓 ,𝑠 the random element that maps each walk in W(𝑓 ,𝑠) to its
destination—the last fact in the walk. For 𝑔 ∈ 𝑅𝑘 (𝐷), the probability
that a walk sampled from W(𝑓 ,𝑠) ends with 𝑔 is Pr(𝑑𝑓 ,𝑠 = 𝑔).
Targeted Walk Schemes. A targeted walk scheme is a pair (𝑠,𝐴)
such that 𝑠 is a walk scheme from a relation 𝑅 to a relation 𝑅′, and 𝐴
is an attribute of 𝑅′. Given a start fact 𝑓 in the start relation 𝑅 of the
walk scheme 𝑠, a targeted walk scheme (𝑠,𝐴) defines the random
variable 𝑑𝑓 ,𝑠 [𝐴] that forms the value of the random walk’s destina-
tion in the attribute 𝐴. We denote by TWS(𝑅, ℓmax) is the set of all
targeted walk schemes (𝑠,𝐴) such that 𝑠 is a walk scheme of length
at most ℓmax starting from the relation 𝑅 (and ending in any relation
that includes 𝐴). For example, Figure 4 shows several targeted walk
schemes over the schema of the database 𝐷 of Figure 3. To illustrate,
(𝑠7,𝐴7) is the targeted walk scheme with 𝐴7 := name and 𝑠7 :=
Country[code]—[country]Member[org]—[abbrev]Org. Walks of
𝑠7 include the sequences (𝑐1,𝑚1,𝑜1) and (𝑐2,𝑚3,𝑜2). The distribu-
tion 𝑑𝑐2,𝑠7 [𝐴7] is uniform between European Union and Nordic
Council. The walk schemes (𝑠1,𝐴1), ..., (𝑠7,𝐴7) are in the set
TWS(Country, 3) since they all start with Country and have
length at most three, yet (𝑠8,𝐴8) is not in TWS(Country, 3) but
rather in TWS(Country, 4).
Recall that databases may have nulls. A random walk starting
at 𝑓 might end at an 𝑅ℓ-fact 𝑔 with null on 𝐴. As a convention, we
define the probability distribution of 𝑑𝑓 ,𝑠 [𝐴] by ignoring the nulls
(and normalizing). With this modification, we enforce 𝑑𝑓 ,𝑠 [𝐴] ∈
dom(𝐴). This will be crucial in Section 2, where we define similarity
measures for 𝑑𝑓 ,𝑠 [𝐴] based on dom(𝐴).
Kernelized Domains. FoRWaRD assumes that every attribute 𝐴
is associated with a kernel function 𝜅𝐴 that maps all pairs of ele-
ments from dom(𝐴) to the nonnegative reals. Intuitively, 𝜅𝐴(𝑎,𝑏)
measures the similarity between elements 𝑎,𝑏 ∈ dom(𝐴). Kernel
functions offer a straightforward way of encoding domain knowl-
edge by modeling the similarity of the domain values. Kernels are
also helpful when dealing with noisy data. For example, kernels
based on the edit distance can be used to smooth out random typos
in text. FoRWaRD uses these kernel functions to define similarity
measures for the random variables 𝑑𝑓 ,𝑠 [𝐴].
Let 𝑠 be a walk scheme of length ℓ from 𝑅 to 𝑅′. Let 𝐴 be an
attribute of 𝑅′ and let 𝑓 and 𝑓 ′ be two distinct 𝑅-facts. Then 𝑑𝑓 ,𝑠 [𝐴]
and 𝑑𝑓 ,𝑠′ [𝐴] are random variables over a shared kernelized domain
dom(𝐴). The Expected Kernel Distance KD is the expected distance
between two random values selected independently at random:
KD(𝑑𝑠,𝑓 [𝐴],𝑑𝑠,𝑓 ′ [𝐴]) =
E
W(𝑓 ,𝑠)×W(𝑓 ′,𝑠)
[𝜅𝐴(𝑑𝑠,𝑓 [𝐴],𝑑𝑠,𝑓 ′ [𝐴])]
(2)
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, and Benny Kimelfeld
Country
code
name
capital
𝑐1
A
Austria
Vienna
𝑐2
SF
Finland
Helsinki
𝑐3
PR
P. Rico
San Juan
Member
country
org
type
𝑚1
A
EU
member
𝑚2
SF
EU
member
𝑚3
SF
NC
member
Member[country] ⊆
Country[code]
Member[org] ⊆ Org[abbrev]
Politics
country
independence
depend
gov
𝑝1
A
12/11/1918
-
fed. republic
𝑝2
SF
06/12/1917
-
republic
𝑝3
PR
-
USA
assoc. with US
Politics[country] ⊆ Country[code]
Politics[dependent] ⊆ Country[code]
Org
abbrev
name
city
country
𝑜1
EU
European Union
Brussels
B
𝑜2
NC
Nordic Council
Stockholm
S
Org[country] ⊆ Country[code]
Figure 3: Example of a database, with foreign-key constraints,
taken from the Mondial dataset.
FoRWaRD uses the Expected Kernel Distance to quantify the simi-
larity between 𝑑𝑓 ,𝑠 [𝐴] and 𝑑𝑓 ′,𝑠 [𝐴] with respect to the kernel 𝜅𝐴.
Embedding . Intuitively, FoRWaRD aims to encode the kernel
KD(𝑑𝑠,𝑓 [𝐴],𝑑𝑠,𝑓 ′ [𝐴]). The primary output is the embedding 𝜑 :
𝐷 → R𝑘. Additionally, the FoRWaRD algorithm learns an aux-
iliary embedding 𝜓 : TWS(𝑅, ℓmax) → R𝑑×𝑑 that maps each tar-
geted walk scheme (𝑠,𝐴) to a symmetric matrix𝜓 (𝑠,𝐴). (Recall that
TWS(𝑅, ℓmax) is the set of targeted walk schemes of length at most
𝑘.) The objective is to find 𝜑 and 𝜓 satisfying 𝜑(𝑓 )⊤𝜓 (𝑠,𝐴)𝜑(𝑓 ′) =
KD(𝑑𝑠,𝑓 [𝐴],𝑑𝑠,𝑓 ′ [𝐴]) for all 𝑓 , 𝑓 ′ ∈ 𝑅(𝐷) and (𝑠,𝐴) ∈ TWS(𝑅, ℓmax).
Effectively, FoRWaRD minimizes
𝜑(𝑓 )⊤𝜓 (𝑠,𝐴)𝜑(𝑓 ′) − KD(𝑑𝑠,𝑓 [𝐴],𝑑𝑠,𝑓 ′ [𝐴])

(3)
for all 𝑓 , 𝑓 ′, 𝑠 and 𝐴, via Stochastic Gradient Descent (SGD).
Intuitively, the algorithm learns an inner product ⟨·, ·⟩𝑆,𝐴 on the
latent space of the embedding 𝜑 defined by ⟨𝑥,𝑦⟩𝑆,𝐴 = 𝑥⊤𝜓 (𝑠,𝐴)𝑦
for all 𝑠 and 𝐴 such that the similarity of facts 𝑓 and 𝑓 ′ with respect
to this inner product matches the similarity between the random
variables 𝑑𝑓 ,𝑠 [𝐴] and 𝑑𝑓 ′,𝑠 [𝐴] with respect to the kernel 𝜅𝑅ℓ .𝐴.
FoRWaRD uses gradient descent to learn 𝜑 and 𝜓. During train-
ing, tuples of the form (𝑓 , 𝑓 ′,𝑠,𝐴,𝑔,𝑔′) are sampled, where 𝑓 and
𝑓 ′ are 𝑅 facts from the database and (𝑠,𝐴) ∈ TWS(𝑅, ℓmax). The 𝑅ℓ
facts 𝑔 and 𝑔′ are the destinations of random walks with scheme
𝑠 sampled for 𝑓 and 𝑓 ′, respectively. We use a hyperparameter
𝑛samples ∈ N. For each 𝑅-fact 𝑓 and scheme (𝑠,𝐴) ∈ TWS(𝑅, ℓmax),
we sample 𝑛samples tuples (𝑓 , 𝑓 ′,𝑠,𝐴,𝑔,𝑔′) with 𝑓 ′ ≠ 𝑓 . The follow-
ing loss is then minimized for each sample using SGD:
L = 1
2 |𝜑(𝑓 )⊤𝜓 (𝑠,𝐴)𝜑(𝑓 ′) − 𝜅𝑅ℓ .𝐴(𝑔[𝐴],𝑔′[𝐴])|2.
(4)
This objective uses 𝜅𝑅ℓ .𝐴(𝑔[𝐴],𝑔′[𝐴]) as a (stochastic) estimate of
KD(𝑑𝑠,𝑓 [𝐴],𝑑𝑠,𝑓 ′ [𝐴]).
1/3
15.5
1/2
12.9
Country
Member
code
country
type
0.9
1/3
Country
Member
code
country org
Org
abbrev
name
Org
country
abbrev
Country
name
code
6.5
1/4
Country
Member
code
country org
1
Country
code
gov
Politics
country
1/2
name
Country
(𝑠1,𝐴1)
0.0
(𝑠2,𝐴2)
12.3
(𝑠3,𝐴3)
Country
code
country
Politics
depend
Country
code
(𝑠4,𝐴4)
Country
code
country depend
Country
name
code
Politics
(𝑠5,𝐴5)
(𝑠6,𝐴6)
(𝑠7,𝐴7)
(𝑠8,𝐴8)
capital
Country
code
indep
Politics
country
1/2
5.0
15.5
1/3
Figure 4: Examples of targeted walk schemes of length one to
four, for the database schema of Figure 3. All walk schemes
start at the Country relation. The figure of the walk scheme
for (𝑠,𝐴) shows 𝑠 as a path of rectangles and 𝐴 (e.g. name) as
an attribute under the rightmost (last) rectangle.
3
PROBLEM DEFINITION
Recall that FoRWaRD uses all targeted walk schemes of length at
most ℓmax for training its embedding. That is, all of TWS(𝑅, ℓmax).
Our conjecture in this work is that some targeted walk schemes are
considerably more useful than others for the task of embedding,
and furthermore, that a small subset of TWS(𝑅, ℓmax) suffices for
achieving the quality of the full set. If so, then we can considerably
reduce the training time by focusing on just a few walk schemes.
It is also perceivable that, with a small yet valuable collection of
targeted walk schemes, we can surpass the quality of the original
set for the same training time.
Consequently, our goal in this work is to find a subset T ′ of
TWS(𝑅, ℓmax) such that the training of FoRWaRD on T ′ rather
than TWS(𝑅, ℓmax) is more effective. In particular, we would like to
find a T ′ such that: (1) T ′ is small compared to TWS(𝑅, ℓmax), and
importantly an epoch of training with T ′ is considerably faster than
training with TWS(𝑅, ℓmax); and (2) the quality (on downstream
tasks) of the embedding resulting from T ′ is high compared to
TWS(𝑅, ℓmax). Hence, we would like to find a T ′ that would enable
us to train considerably faster without a penalty of loss in quality.
Example 3.1. One way of selecting a subset of TWS(𝑅, ℓmax) is to
score each and take the top-𝑘 for a desired number𝑘 of schemes. For
Selecting Walk Schemes for Database Embedding
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
illustration, Figure 4 depicts two scores (written in filled ellipses)
beside each targeted walk scheme. The first (blue) score is what
we later define as the kernel variance score. The second (green) is a
simplistic score that we use as a baseline; this is the reciprocal of the
scheme’s length (e.g., it is 1/3 for (𝑠7,𝐴7) since 𝑠7 is of length three).
If we use the second scoring function, then we take the shortest of
the targeted walk schemes (and apply tie-breaking if needed).
_
4
STRATEGIES FOR SCHEME SELECTION
Recall that our goal is to study how walk schemes should be se-
lected in order to establish a proper balance between the execution
cost and the quality of the embedding. Our general approach is to
start with a large collection of walk schemes (i.e., the initial one of
FoRWaRD) and eliminate walk schemes one by one. In this section,
we propose several strategies for such elimination.
Technically, a strategy 𝑇 assigns to every (𝑠,𝐴) ∈ TWS(𝑅, ℓmax)
a number score𝑇 (𝑠,𝐴, 𝐷) for the database 𝐷, where a higher score
means that the targeted walk scheme is considered more valuable.
When we select 𝑘 schemes to eliminate, we select the bottom 𝑘
according to the score. We propose strategies that fall into three cat-
egories: (1) The FoRWaRD-less strategies determine score𝑇 (𝑠,𝐴, 𝐷)
based on an evaluation that does not require the actual execu-
tion of FoRWaRD. (2) In the light training strategies, we run FoR-
WaRD in some limited and light fashion in order to determine
score𝑇 (𝑠,𝐴, 𝐷). (3) The strategy of online scheme elimination incor-
porates the scheme selection in the actual embedding phase (using
FoRWaRD) while targeted walk schemes are eliminated during
the epochs of the training; hence, the values score𝑇 (𝑠,𝐴, 𝐷) are
computed multiple times during the embedding phase.
4.1
FoRWaRD-Less Strategies
This category includes simplistic baseline strategies such as the
length of the scheme, which is illustrated in Figure 4 in the green
ellipses. Next, we describe two more involved strategies: mutual
information and kernel variance.
Mutual Information. A walk scheme 𝑠, as defined in (1), induces a
probability distribution over random walks, which are sequences
(𝑓1, . . . , 𝑓ℓ) of facts in 𝑅1, . . . , 𝑅ℓ, respectively. For 𝑖 = 1, . . . , ℓ, let 𝑋𝑖
be the random variable that takes the random fact 𝑓𝑖. Let𝑝(𝑓𝑖, 𝑓𝑖+1) ∈
[0, 1] denote the marginal joint distribution of the variables 𝑋𝑖 and
𝑋𝑖+1. Recall that the mutual information of 𝑋𝑖 and 𝑋𝑖+1 is given by:
𝐼 (𝑋𝑖;𝑋𝑖+1) :=
∑︁
𝑓𝑖 ∈𝑋𝑖 , 𝑓𝑖+1∈𝑋𝑖+1
𝑝(𝑓𝑖, 𝑓𝑖+1) log 𝑝(𝑓𝑖, 𝑓𝑖+1)
𝑝(𝑓𝑖)𝑝(𝑓𝑖+1)
(5)
We estimate the probabilities 𝑝(𝑓𝑖, 𝑓𝑖+1) as the empirical probabili-
ties, that is, their probability in our samples.
We score a targeted walk scheme by the minimal mutual infor-
mation along the walk. Formally, we have the following score:
scoremi(𝑠,𝐴, 𝐷) := −
min
0≤𝑖<ℓ+1 𝐼 (𝑋𝑖 |𝑋𝑖+1)
(6)
Note that the minus sign means that we favor schemes with small
mutual information. The rationale is that small mutual information
encourages the embedding to capture less predicted distributions.
As we show later, this rationale is consistent with our experiments.
Kernel Variance. The measure kernel variance is, intuitively, one
that favours targeted walk schemes where different start tuples
are associated with varied distributions, and so, the embedding
of FoRWaRD is encouraged to distinguish between these starting
tuples. Formally, for a targeted walk scheme (𝑠,𝐴) we define the
kernel variance score, denoted scorekvar(𝑠,𝐴, 𝐷), as the variance of
the expected kernel distance between the distributions induced by
𝑠 and 𝐴 when starting with random 𝑓 and 𝑓 ′ in the source of 𝑠.
scorekvar(𝑠,𝐴, 𝐷) := Var
𝑓 ,𝑓 ′
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, and Benny Kimelfeld
Table 1: Datasets used in the experiments. “#TWS” is the
cardinality of TWS(𝑅, ℓmax), that is, the number of targeted
walk schemes of length up to ℓmax. “Avglen” is the average
length of a walk scheme in TWS(𝑅, ℓmax).
Dataset
#Rel.
#Tuples
#Attr.
#TWS
ℓmax
Avglen
Mondial
40
21497
167
63
3
2.44
World
3
5411
24
60
3
1.68
Hepatitis
7
12927
26
21
3
1.73
Genes
3
6063
15
32
3
2.25
Mutagen.
3
10324
14
58
4
3.10
4.3
Online Scheme Elimination
This strategy is similar to the single-epoch training, except that
we apply it iteratively during training, where in each epoch we
remove the bottom-𝑘 schemes according to the score computed for
that epoch according to Equation (8). This way, we are potentially
allowing to account for schemes that become more important once
other schemes are removed (in earlier epochs). Note that online
scheme elimination is different from the light-training approach in
the sense that the latter is performed as a pre-processing step that
takes place before the embedding computation, while the former is
performed as part of the embedding computation.
5
EXPERIMENTAL EVALUATION
The goal of our experimental study is threefold. First, we evaluate
the effectiveness of the scheme-selection strategies in terms of the
quality of the embedding and the execution cost of its computation.
Second, we compare the strategies. Third, we study the impact of
the strategy on the performance in a dynamic setting where new
tuples are repeatedly inserted, and their embedding is computed
without changing the embedding of existing tuples.
To evaluate an embedding, we adopt the common approach of
measuring the accuracy on downstream predictions. Hence, we
measure the running time of the embedding algorithm, namely
FoRWaRD, and the quality of a learned model for the downstream
task. We focus on multi-relational data and use the same databases
and tasks that were used for the evaluation of FoRWaRD [22].
5.1
Experimental Setup
5.1.1
Datasets and Tasks. Information about the datasets and down-
stream tasks of our experiments is given in Tables 1 and 2, respec-
tively. Each dataset is a database of multiple relations (with the
number of relations given in the “#Rel.” column of Table 1), and
the task is to predict the content of an attribute of one of the rela-
tions. Hereafter, we refer to this relation as the prediction relation.
In different downstream tasks on the same dataset, the prediction
attribute is changed in the prediction relation to the one we aim to
predict. Importantly, the predicted attribute is excluded from the
database throughout the entire embedding phase, and it is seen by
neither FoRWaRD nor the walk-scheme selector.
Mondial contains information from multiple geographical re-
sources [16]. We used multiple attributes for prediction tasks on
this dataset: religion (Christian or not), continent, infant mortality
g40 (whether the rate is lower than forty per thousand), gdp g8e3
Table 2: Downstream tasks. “CC” (Common Class) is the fre-
quency of the common value of the predicted bit.
Downstream task
Pred. Rel.
Pred. Attr.
#Samples
CC
M.-Religion
Target
religion
206
54.8%
M.-Continent
continent
242
22.7%
M.-Infant Mort.
infant g40
238
60.5%
M.-GDP
gdp g8e3
238
50.0%
M.-Inflation
inflation g6
238
50.8%
World
Country
continent
239
24.2%
Hepatitis
Dispat
type
500
58.8%
Genes
Classific.
localization
862
42.5%
Mutagenesis
Molecule
mutagenic
188
66.4%
(whether GDP is lower than $8000M), and inflation g6(whether the
inflation rate is lower than 6%).
World has geographical data on states and their cities [18]. The
task is to predict the continent of a country. The dataset contains
40 different relations with a total of 167 attributes and 21,497 tuples.
We use the whole database and use the Target relation as the
prediction relation as previously done by Bina et al. [1].
Hepatitis is from the 2002 ECML/PKDD Discovery Challenge.1
The task is to predict the type column, which is either Hepatitis B or
Hepatitis C based on medical examinations. There are in total 206
instances of the former and 484 cases of the latter. The relation with
the predicted column contains, in addition to the type classification,
the age, gender and identifier of the patient. The other relations
contain the rest of the medical data. The dataset contains 7 relations
with a total of 26 attributes and 12,927 tuples.
Genes [7] contains genomic and drug-design data. The task is to
predict the localization of the gene, based on biological data, with
15 different labels. The prediction relation contains only the class
and an identifier for the gene, while the rest contain biological data
such as the function, gene type, cellular location, and the expression
correlation between genes. The dataset contains 3 relations with a
total of 15 attributes and 6,063 tuples. (We deleted two tuples with
a unique class to prevent split in-balances during cross-validation.)
Mutagenesis contains data on the mutagenicity of molecules on
Salmonella Typhimurium [8]. The task is to predict the mutagenic-
ity of molecules, based on chemical properties of the molecule, with
122 positive samples and 63 negative ones. The prediction relation
contains the binary class, molecule ID, and some of the chemical
data, while the other relations contain more chemical data and
information about the relations between the molecules. The dataset
contains 3 relations with a total of 14 attributes and 10,324 tuples.
5.1.2
Compared Strategies. We compare the following strategies.
Random eliminates random schemes. Length eliminates the schemes
with the longest length. KVar eliminates the schemes with the least
scorekvar (kernel variance), as defined in Equation (7). MI elimi-
nates the schemes with the least scoremi (mutual information) as
defined in Equation (5). 1epoch eliminate the schemes with the least
score1ep (one epoch), as defined in Equation (8). Sampling elimi-
nate the schemes with the least scoresmpl (sampling), as defined in
1https://sorry.vse.cz/~berka/challenge/PAST/. We use the modified version of [20].
Selecting Walk Schemes for Database Embedding
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
KVar Genes
0
100
200
300
40
60
80
100
Time (sec)
1epoch Genes
100
200
300
40
60
80
100
Time (sec)
Random Genes
0
100
200
300
40
50
60
70
80
90
Time (sec)
KVar MR
0
50
100
150
200
250
60
65
70
75
80
85
Time (sec)
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
1epoch MR
50
100
150
200
250
60
65
70
75
80
85
Time (sec)
Random MR
0
50
100
150
200
250
65
70
75
80
85
Time (sec)
Figure 5: Performance on the downstream task as a function of time for different ratios of schemes used for training. At the
end of each training epoch of FoRWaRD we record the time (x-axis) and accuracy of the downstream task (y-axis).
Equation (9). Recall that in this strategy, we run the algorithm for
ten epochs on the sample 𝐷′ of the database 𝐷; afterward, we run
FoRWaRD from scratch on the remaining schemes. Online is the
online scheme-elimination approach is described in Section 4.3.
We have a full separation between the embedding process and
the downstream task: we generate the embedding independently
from the task (as opposed to training for the task) and then use
these embeddings as the input to a downstream classifier (that sees
only the embeddings and none of the other database information).
5.1.3
Programming. For a tuple embedding𝜑, we denote by 𝛼(𝜑) ∈
[0, 1] the mean accuracy achieved by an SVM (Scikit-learn’s SVC im-
plementation) trained as a classifier that takes the tuple embeddings
in 𝜑 as input, and learns to predict the target of the downstream
task. The results are given for a ten-fold cross validation. We fix
one split for each dataset and task where this cross validation is
performed, and we do so for every evaluated embedding.
The value of 𝛼(𝜑) is our primary metric for the quality of an
embedding 𝜑. We usually train five embeddings Φ = {𝜑1, . . . ,𝜑5}
for each configuration, each with a different seed. We use the mean
cross-validated accuracy across the five as a measure of the expected
embedding quality: 𝛼(Φ) = mean1≤𝑖≤5 𝑎(𝜑𝑖). We study how this
expectation develops over time for different strategies and selection
ratios. More formally, let T be a scheme selection strategy and let
𝑟 ∈ [0, 1] be the ratio of schemes used for training. By Φ(T,𝑟,𝑡) we
denote the set of embeddings obtained after training five FoRWaRD
embeddings for 𝑡 seconds on the targeted walk schemes reduced
using T by ratio 1 − 𝑟. We evaluate the expected accuracy after
each epoch, thus the set of times 𝑡 where we record 𝛼(Φ(T,𝑟,𝑡))
is determined by the time it takes to complete an epoch.
We run all the experiments a server with two Intel Xeon Gold
6130 processors, 512 MB RAM, and an NVIDIA QUADRO RTX 6000
GPU with 24 GB memory.
5.2
Performance of Individual Strategies
We first study how the embedding quality develops throughout the
training of the embedding. We record the training time and the
quality on the downstream task at the end of each epoch. We study
the progress when training on different subsets of the targeted walk
schemes selected by the different strategies. In Figure 5, we provide
results for the Mondial-Religion (MR) and Genes downstream tasks
using the strategies KVar (kernel variance), 1epoch (one epoch),
and Random.
In each sub-figure of Figure 5, there are nine colored curves
and one gray curve. Each colored curve represents one ratio of
removed schemes from 10% to 90%. The gray curve shows the
original FoRWaRD run when training on all targeted walk schemes.
The x-axis provides the training time 𝑡 in seconds and we plot the
value of 𝛼(Φ(T,𝑟,𝑡)) (i.e. the evaluation of the expected accuracy
𝑡 seconds) on the y-axis. Intuitively, this shows how the embedding
quality develops throughout the training of the embedding.
Across the experiments, we observe a range of behaviors. First,
the selection strategy has a significant influence on the result. For ex-
ample, the Random elimination strategy yields significantly worse
performance when a large percentage of schemes is removed. This
justifies the design of more sophisticated strategies that are able
to yield embeddings of high quality even when a larger ratio of
TWS(𝑅, ℓmax) is removed. One example of this is the Mondial-
Religion downstream task. Vanilla FoRWaRD with all schemes
reaches 83% accuracy on the downstream task. When using Ran-
dom to train on only 50% of the walk schemes, accuracy drops to
74% while taking longer to converge. Furthermore, when using the
Random strategy to train on 20% of the targeted walk schemes, we
observe a more dramatic decrease in accuracy to 71%. In contrast,
when training with the KVar strategy on 50% or 20% of the targeted
walk schemes, the accuracy over the downstream task does not
differ much from the original 83%.
For most of the combinations of tasks and strategies, a signifi-
cant portion of the targeted walk schemes can be removed with
a negligible decrease in quality. The speed of convergence natu-
rally increases with the ratio of removed schemes. An example of
this behavior is the Mondial-Religion task. Here, when we train on
fewer schemes (using the KVar and 1epoch strategies), we reach
the same 0.83 accuracy with less training time. For instance, by
selecting a fifth of the walk schemes using KVar, we get to the full
quality in about a third of the embedding time. Another example
is the Genes downstream task. Here, the original FoRWaRD with
all walk schemes takes 300 seconds to reach 92.9% accuracy over
the downstream task. This time improves to 124.5 and 148 seconds
when training on just 30% of the targeted walk schemes selected
by the KVar and 1epoch strategies, respectively.
There are several instances where the removal of schemes not
only accelerates training but actually increases the downstream
performance. An example of this is the Genes dataset. Here, the ac-
curacy achieved with all scheme selection strategies increases with
the percentage of removed schemes until about 70% of all schemes
are discarded. More specifically, the accuracy on the downstream
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, and Benny Kimelfeld
Table 3: The best training time for each scheme selection strategy and task. The table contains the shortest time it takes to
reach the threshold quality 𝛼∗ over all tested removal ratios 𝑟 (i.e. 𝑡∗(T)). The last row (ALL) refers to the embedding time of
the original FoRWaRD run, with all schemes, as a baseline. The best (lowest) train time for each task is printed in bold.
Mutagenesis
World
Hepatitis
Genes
M.-Religion
M.-Infant
M.-Continent
M.-GDP
M.-Inflation
KVar
20.59
154.32
29.31
107.18
42.75
42.17
54.39
56.84
49.46
(+-2.67)
(+-18.71)
(+-6.52)
(+-5.73)
(+-2.63)
(+-4.61)
(+-1.58)
(+-8.20)
(+-6.47)
Online
41.89
150.38
60.88
115.91
61.76
61.96
69.44
56.55
65.31
(+-2.68)
(+-11.09)
(+-33.53)
(+-4.15)
(+-2.31)
(+-2.48)
(+-2.88)
(+-9.86)
(+-4.80)
Random
39.09
268.97
69.98
115.39
88.22
76.16
113.15
71.02
82.5
(+-7.29)
(+-81.67)
(+-16.33)
(+-5.83)
(+-14.12)
(+-0.71)
(+-7.07)
(+-6.00)
(+-35.24)
1epoch
41.57
191.2
58.68
126.46
55.06
56.03
67.16
65.63
65.08
(+-1.21)
(+-31.45)
(+-15.50)
(+-7.12)
(+-1.20)
(+-3.36)
(+-1.37)
(+-4.88)
(+-6.58)
All
55.89
550.65
58.36
161.9
101.32
76.16
113.14
69.03
95.37
(+-8.67)
(+-22.92)
(+-9.3)
(+-6.74)
(+-8.53)
(+-0.71)
(+-7.06)
(+-8.77)
(+-8.61)
task is 93.8% for the original FoRWaRD run with the full set of walk
schemes; it goes up to 98% when 70% of the schemes are discarded
using the KVar and 1epoch strategies. Similar results are obtained
on the Mondial-Inflation and World tasks, although the margin of
improvement is different on these tasks.
5.3
Comparison between Strategies
We aim to better quantify the difference between strategies. We
first introduce additional metrics. We establish a high-performance
threshold by training five standard FoRWaRD embeddings ΦFWD
with all targeted walk schemes. We set 95% of the expected cross-
validated accuracy as the performance target on each downstream
task: 𝛼∗ = 0.95 ·𝛼(ΦFWD). In Figure 5 described next, the threshold
is shown as a dashed red line. We wish to study how each considered
strategy for scheme selection affects the compute time needed to
obtain an embedding of high quality. To this end, we will measure
how much training time is needed to reach the threshold 𝛼∗ with
each strategy. We will use the following definitions.
For a strategy T and a ratio 𝑟, we denote by 𝑡∗(T,𝑟) the earliest
time it takes to reach the performance threshold: 𝑡∗(T,𝑟) = min{𝑡 |
𝛼(Φ(T,𝑟,𝑡)) ≥ 𝛼∗}. For the strategy T, we can further define a
metric that is the shortest time it takes to reach the target quality
over all tested ratios 𝑟: 𝑡∗(T) = min𝑟 𝑡∗(T,𝑟). This is the primary
metric that we use for measuring the effectiveness of a strategy.
Table 3 provides the value of 𝑡∗(T) for each strategy T and
task. Overall, KVar yields the fastest training times on most tasks.
However, the exact performance of each strategy depends on the
data. The Length strategy yields the best overall results on the
Genes dataset, but KVar performs substantially better than Length
on all other tasks. The Online strategy also yields the fastest training
times on the World and Modial-GDP tasks.
To further study training different selection strategies, in Figure 6
we provide the “best” learning curve of each strategy on each task.
More specifically, we plot the value of 𝛼(Φ(T,𝑟∗(T),𝑡)), where
the ratio 𝑟∗(T) ∈ [0, 1] is 𝑟∗(T) = arg min𝑟 𝑡∗(T,𝑟). Note that
we also provide the training curve of FoRWaRD when using all
targeted walk schemes (gray). When training with reduced scheme
sets the training converges consistently speeds up. As observed
previously, the margin of the speedup depends on the scheme se-
lection strategy. The KVar (kernel Variance) strategy (red) yields
the fastest convergence on most downstream tasks.
The strong overall performance of the KVar (kernel Variance)
method suggests that it strikes the best balance between running
efficiently and determining a good subset of schemes to remove.
Thus, it enables us to train on less targeted walk schemes and reach
the same accuracy faster than simpler selection strategies.
5.4
Embedding for Dynamic Databases
Finally, we investigate how the reduction in the set of schemes af-
fects the dynamic-database setting, where new tuples arrive and we
need to compute an embedding of the new tuples without changing
the embedding of existing tuples. (Note that tuple deletion is not an
issue in this setting since we simply leave intact the embedding of
the remaining tuples; see Tönshoff et al. [22] for a discussion on
tuple insertion and its possible subtleties.) For this experiment, we
will use the dynamic extension of FoRWaRD [22]. This extension
is one of the key motivations for the design of FoRWaRD as it is
able to compute embeddings of new tuples unseen during training
by solving a single linear system of equations.
Naturally, a useful scheme-selection strategy should not impair
the quality of the new tuple embeddings. Here, we will conduct a
brief experiment to verify that this is indeed the case. More specifi-
cally, we adopt the exact experimental setup of the dynamic experi-
ments conducted by Tönshoff et al. [22]. This setup first deletes a
part of the database and trains an embedding on the remaining data.
This embedding is then used to train a classifier for the downstream
task. Only after this, the removed tuples are inserted back into the
database and the embedding is inductively extended to the new
data. These new embeddings can then be evaluated by measuring
the accuracy of the downstream classifier on the inserted data. By
varying the ratio of data that is initially removed we can test the
robustness of this dynamic embedding extension.
We train and then extend FoRWaRD where 60% of all targeted
walk schemes have been removed according to the KVar strategy.
As baselines, we include the results of FoRWaRD with no schemes
removed as well as the dynamic extension of node2vec, which was
Selecting Walk Schemes for Database Embedding
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
Genes
0
50
100
150
200
40
60
80
100
World
0
200
400
600
20
40
60
80
M-Religion
0
20 40 60 80 100 120 140
60
65
70
75
80
85
M-Continent
0
20 40 60 80 100 120 140
20
40
60
80
100
M-GDP
20
40
60
80
100
50
60
70
80
Legend
1ep
MI
O.S. Elimination
k_var
len
random
sampling
all schemes
𝑎∗
M-Infant Mort.
0
20 40 60 80 100 120 140
60
65
70
75
80
M-Inflation
0
20 40 60 80 100 120 140
50
60
70
Mutagenesis
0
20 40 60 80 100 120 140
70
75
80
85
90
Hepatitis
0
20
40
60
80
100
60
65
70
75
80
Figure 6: Comparison between different strategies. For each downstream task, we provide the best learning curve of each
strategy, that is, the first curve that reaches an accuracy of 𝛼∗. Note that the color now denotes the selection strategy.
also proposed by Tönshoff et al. [22]. Figure 7 provides the results
on four tasks: Genes, World, Mondial Religion and Mutagenesis. We
observe that the FoRWaRD version with the reduced set of schemes
performs as well as the original FoRWaRD with all schemes. On
the Genes and World tasks the results actually improve slightly
when only the selected 40% of targeted walk schemes are used.
There is, though, a slight decrease in the accuracy in the case of
the Mutagenesis dataset.
Overall, we conclude that reduced scheme sets with a strong
performance on a static database are also well-suited for a dynamic
setting where new tuples are inserted over time.
6
CONCLUDING REMARKS
Walking through connected data items is the basis of sequence-
based embeddings like Word2Vec and Node2Vec. Database se-
quences are also associated with meta-data, namely the walk scheme.
The premise of this work was the conjecture that the walk schemes
have significant semantic value, as they can guide the embedding
algorithm to a small subset of informative sequences, thus dramati-
cally improving efficiency for a mild sacrifice of quality. We studied
the problem of selecting walk schemes in the context of FoRWaRD.
We considered different strategies of three types: FoRWaRD-less,
light training, and online scheme elimination. We conducted an
experimental study that measured the benefit of each strategy, com-
pared between them and tested how well they preserved the main
strength of FoRWaRD—extensibility to newly inserted tuples in dy-
namic settings. Our study has confirmed our conjecture and showed
that we can considerably accelerate FoRWaRD with negligent loss
of quality. Moreover, restricting the embedding phase to the right
walk schemes can even improve the quality on downstream classifi-
cation tasks. The kernel-variance strategy typically outperforms the
rest, and we recommend this one to be used alongside FoRWaRD.
The idea of directing the embedding algorithm to beneficial walk
schemes goes beyond FoRWaRD and is applicable to every database
embedding we are aware of. Our experience with EmbDI [6] has
indicated that EmbDI uses a large number of walk schemes with tiny
pairwise differences and a heavy-tailed distribution of a number
of instances. Thus we need to use ways of abstracting (clustering)
walk schemes. We also plan to expand the scope of our work to
data integration tasks (e.g., entity and schema matching) as done
with other database embedding algorithms [6, 19]. In the case of
FoRWaRD, there is a need to devise alignment between embeddings
of different databases, since FoRWaRD makes no attempt to produce
similar embeddings to matching entities of different databases.
20
40
60
80
0
20
40
60
80
100
Ratio of new data (%)
Accuracy (%)
Genes
N2V
FW
FW-KV
20
40
60
80
0
20
40
60
80
100
Ratio of new data (%)
World
20
40
60
80
0
20
40
60
80
100
Ratio of new data (%)
Mondial-Religion
20
40
60
80
0
20
40
60
80
100
Ratio of new data (%)
Mutagenesis
Figure 7: Experiments on the dynamic setting: accuracy as a
function of the percentage of inserted tuples for Node2Vec,
FoRWaRD, and FoRWaRD with 60% of the schemes selected
by KVar. The black line is the accuracy of the common class.
CIKM ’23, October 21–25, 2023, Birmingham, United Kingdom
Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, and Benny Kimelfeld
REFERENCES
[1] Bahareh Bina, Oliver Schulte, Branden Crawford, Zhensong Qian, and Yi Xiong.
2013. Simple decision forests for multi-relational classification. Decis. Support
Syst. 54, 3 (2013), 1269–1279. https://doi.org/10.1016/j.dss.2012.11.017
[2] Rajesh Bordawekar, Bortik Bandyopadhyay, and Oded Shmueli. 2017. Cog-
nitive Database: A Step towards Endowing Relational Databases with Artifi-
cial Intelligence Capabilities. CoRR abs/1712.07199 (2017). arXiv:1712.07199
http://arxiv.org/abs/1712.07199
[3] Rajesh Bordawekar and Oded Shmueli. 2017. Using Word Embedding to Enable
Semantic Queries in Relational Databases. In Proceedings of the 1st Workshop on
Data Management for End-to-End Machine Learning (Chicago, IL, USA) (DEEM’17).
ACM, New York, NY, USA, Article 5, 4 pages. https://doi.org/10.1145/3076246.
3076251
[4] Rajesh Bordawekar and Oded Shmueli. 2019. Exploiting Latent Information
in Relational Databases via Word Embedding and Application to Degrees of
Disclosure. In CIDR. www.cidrdb.org. http://cidrdb.org/cidr2019/papers/p27-
bordawekar-cidr19.pdf
[5] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. 2013.
Translating embeddings for modeling multi-relational data. In Advances in neural
information processing systems. 2787–2795.
[6] Riccardo Cappuzzo, Paolo Papotti, and Saravanan Thirumuruganathan. 2020.
Creating Embeddings of Heterogeneous Relational Datasets for Data Integration
Tasks. In SIGMOD, David Maier, Rachel Pottinger, AnHai Doan, Wang-Chiew
Tan, Abdussalam Alawini, and Hung Q. Ngo (Eds.). ACM, 1335–1349.
https:
//doi.org/10.1145/3318464.3389742
[7] Jie Cheng, Christos Hatzis, Hisashi Hayashi, Mark-A. Krogel, Shinichi Morishita,
David Page, and Jun Sese. 2002. KDD Cup 2001 Report. SIGKDD Explor. Newsl. 3,
2 (Jan. 2002), 47–64. https://doi.org/10.1145/507515.507523
[8] Asim Kumar Debnath, Rosa L. Lopez de Compadre, Gargi Debnath, Alan J. Shus-
terman, and Corwin Hansch. 1991. Structure-activity relationship of mutagenic
aromatic and heteroaromatic nitro compounds. Correlation with molecular orbital
energies and hydrophobicity. Journal of Medicinal Chemistry 34, 2 (1991), 786–797.
https://doi.org/10.1021/jm00106a046 arXiv:https://doi.org/10.1021/jm00106a046
[9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding. In
NAACL-HLT (1). Association for Computational Linguistics, 4171–4186.
[10] Muhammad Ebraheem, Saravanan Thirumuruganathan, Shafiq R. Joty, Mourad
Ouzzani, and Nan Tang. 2018. Distributed Representations of Tuples for Entity
Resolution. Proc. VLDB Endow. 11, 11 (2018), 1454–1467.
[11] Aditya Grover and Jure Leskovec. 2016. Node2vec: Scalable Feature Learning for
Networks. In Proceedings of the 22nd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (San Francisco, California, USA) (KDD ’16).
ACM, New York, NY, USA, 855–864. https://doi.org/10.1145/2939672.2939754
[12] Michael Günther. 2018. FREDDY: Fast Word Embeddings in Database Systems.
In SIGMOD Conference. ACM, 1817–1819.
[13] Michael Günther, Maik Thiele, Erik Nikulski, and Wolfgang Lehner. 2020. Retro-
Live: Analysis of Relational Retrofitted Word Embeddings. In EDBT. OpenPro-
ceedings.org, 607–610.
[14] Sabrina Jaeger, Simone Fulle, and Samo Turk. 2018. Mol2vec: Unsupervised
Machine Learning Approach with Chemical Intuition. J. Chem. Inf. Model. 58, 1
(2018), 27–35.
[15] Quoc V. Le and Tomás Mikolov. 2014. Distributed Representations of Sentences
and Documents. In ICML (JMLR Workshop and Conference Proceedings), Vol. 32.
JMLR.org, 1188–1196.
[16] Wolfgang May. 1999. Information extraction and integration: The Mondial case
study. Technical Report. Universität Freiburg, Institut für Informatik.
[17] T. Mikolov, I. Sutskever, K. Chen, G.S. Corrado, and J. Dean. 2013. Distributed
representations of words and phrases and their compositionality. In Proceedings of
the 27th Annual Conference on Neural Information Processing Systems. 3111–3119.
[18] Jan Motl. 2020. The World Dataset. https://relational.fit.cvut.cz/dataset/World
[19] Sidharth Mudgal, Han Li, Theodoros Rekatsinas, AnHai Doan, Youngchoon Park,
Ganesh Krishnan, Rohit Deep, Esteban Arcaute, and Vijay Raghavendra. 2018.
Deep Learning for Entity Matching: A Design Space Exploration. In SIGMOD
Conference. ACM, 19–34.
[20] Jennifer Neville, David D. Jensen, Lisa Friedland, and Michael Hay. 2003. Learning
relational probability trees. In KDD. ACM, 625–630.
[21] Ben Taskar, Pieter Abbeel, and Daphne Koller. 2002. Discriminative Probabilistic
Models for Relational Data. In Proceedings of the Eighteenth Conference on Un-
certainty in Artificial Intelligence (Alberta, Canada) (UAI’02). Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA, 485–492.
[22] Jan Tönshoff, Neta Friedman, Martin Grohe, and Benny Kimelfeld. 2023. Stable
Tuple Embeddings for Dynamic Databases. In ICDE. IEEE.
","A walk in a database is naturally associated with a meta-data
pattern, which is formed by taking the names of the relations of the
tuples along the sequence, as well as the names of the attributes that
are used for the (outgoing and incoming) references. This pattern
is called a walk scheme [22], and examples of these are depicted in
Figure 4 in the context of a geographical database. Sequence-based
embedding algorithms for other modalities do not encounter (and
do not account for) such meta-information in the training phase.
Our premise is that the walk scheme determines, to a large extent,
the contribution of a walk to the quality of the learned embedding.
Hence, unlike word and node embedding, in tuple embedding, we
can introduce important a-priori bias over the training sequences.
We claim and prove empirically that one can considerably reduce
the number of training walks by restricting the learning phase to
the walks of the most effective walk schemes, with a mild (or no) re-
duction in quality. Moreover, the embedding quality might improve
by filtering out walk schemes that contribute more noise than ben-
eficial information. We devise techniques for the selection of walk
schemes within FoRWaRD, as illustrated in Figure 1. To illustrate
the importance of scheme selection, a sample of our experiments is
shown in Figure 2. Here, we are using the learned embedding in the
Mondial database [21] to predict the religion of a country based on
the database’s information. Each curve corresponds to a selected
percentage of the walk schemes and shows the quality of the pre-
diction as a function of the embedding time (where each epoch
contributes a point). The actual way of selecting the walk schemes
is discussed in the next paragraphs. As the chart showed, selecting
a fifth of the walk schemes fully preserves the quality in about
one-third of the embedding time and eventually even outperforms
the embedding with the entire set of walk schemes.nan"
"Organoid communication is a promising area in biomedical research, and molecular communication (MC) is a viable method for achieving it—it uses molecules as information carriers and is considered one of the most promising methods for enabling the Internet of Nano-Things (IoNT) and nanonetworks. This paper introduces the first FinFET-based MC receiver that covers both the top and side gates with receptors, and analyzes its performance in terms of signal-to-noise ratio (SNR) and symbol error probability (SEP). The proposed receiver demonstrates better noise performance and good SEP under physiological conditions compared to its 2D counterpart.","Organoids have attracted attention due to their effectiveness in modeling 3D structures and interactions of organs. However, the communication engineering perspective has received less attention. One approach to achieving organoid communication is through molecular communication (MC), a  bio-inspired communication paradigm that utilizes molecules as information carriers. This paper presents the first FinFET-based MC receiver model that incorporates both top and side gate coverage with receptors. We consider both binding noise and flicker noise in the analysis, and compare the SNR and SEP performance with that of a 2D receiver.","The proposed receiver consists of a recognition unit, a transducer, and a processing unit. The FinFET structure offers improved control over the channel, leading to higher transconductance and better noise performance. We formulate a model that considers the unique 3D structure of FinFET, including the threshold voltage, surface area of functionalized gate, and oxide thickness. Binding noise due to ligand-receptor interactions and flicker noise are analyzed, and the overall noise power spectral density is derived.","The expected current response and noise power of the receiver are investigated under various system parameters. Results show that the proposed 3D receiver outperforms the 2D receiver in terms of SNR and SEP. The effects of diffusion coefficient, intrinsic binding rate, receptor length, and number of free charges per ligand are also analyzed. Furthermore, SEP analysis demonstrates the feasibility of the proposed design in physiological solutions, where it exhibits good performance despite the challenging conditions.","This paper presented the first investigation of a 3D FinFET-based MC receiver for organoid communication, taking into account the crucial threshold voltage and 3D structure. The analysis demonstrates better noise performance and good SEP under physiological conditions compared to the 2D receiver. This work provides insights into the design of 3D MC receivers and their potential applications in organoid communication and the Internet of Organoids.",3D Receiver for Molecular Communications in Internet of Organoids,"Shaojie Zhang, Ozgur B. Akan","1
3D Receiver for Molecular Communications in
Internet of Organoids
Shaojie Zhang, Student Member, IEEE and Ozgur B. Akan, Fellow, IEEE
Abstract—Organoids have garnered attention due to their
effectiveness in modeling the 3D structure of organ interac-
tions. However, the communication engineering perspective has
received relatively little attention. One way to achieve organoids
communication is molecular communication (MC). Molecular
communication is a bio-inspired communication paradigm that
uses molecules as information carriers. It is considered one of the
most promising methods for enabling the Internet of Nano-Things
(IoNT) and nanonetworks. BioFETs are commonly used to im-
plement practical MC receivers. However, most previous analyses
have focused on a planar device, neglecting considerations like
the threshold voltage and its potential 3D structure. This paper
introduces the first FinFET-based MC receiver that covers both
the top and side gates with receptors. Both binding noise and
flicker noise are considered in the analysis. The performance, in
terms of signal-to-noise ratio (SNR) and symbol error probability
(SEP), is compared with that of the 2D receiver.
Index Terms—Molecular communications, receiver, Internet of
Organoids, biosensor, ligand-receptor interactions.
I. INTRODUCTION
O
RGANOIDS are fundamental in vitro, tissue-engineered
cell models derived from self-organizing human stem
cells. They mimic many intricate details of the structure and
function of corresponding in vivo tissues [1]. Due to their
advantages over the more expensive and less reliable tradi-
tional animal models, organoids are increasingly utilized in
biomedical research. Unlike 2D tissue cultures, which cannot
accurately model drug diffusion kinetics and dosage effective-
ness, organoids successfully simulate three-dimensional tissue
architectures and the physiological fluid flow conditions essen-
tial for maintaining normal tissue environments. This makes
them a more effective tool for studying drug interactions and
effectiveness [2], [3].
A significant barrier to advancing biological complexity
and in vivo-like functionality in the early stages of organoids
cultivation is the absence of a perfusable vasculature [4].
Microfluidic devices replace the vasculature and enable con-
trolled perfusion of oxygen, nutrients, and growth stimulants
as well as the removal of waste products, permitting a more
Shaojie Zhang is with the Internet of Everything Group, Electrical Engi-
neering Division, Department of Engineering, University of Cambridge, CB3
0FA Cambridge, U.K. (e-mail: sz466@cam.ac.uk).
Ozgur B. Akan is with the Internet of Everything Group, Electrical
Engineering Division, Department of Engineering, University of Cambridge,
CB3 0FA Cambridge, U.K., and also with the Center for neXt-Generation
Communications (CXC), Department of Electrical and Electronics Engineer-
ing, Koc¸ University, 34450 Istanbul, Turkey (e-mail: oba21@cam.ac.uk;
akan@ku.edu.tr)
This work was supported in part by the AXA Research Fund (AXA Chair
for Internet of Everything at Koc¸ University).
physiologic-like differentiation in the direction of a more
intricate, advanced, and ’in vivo-like’ model [5].
In most cases, a single organoid cannot fully replicate the
drug effectiveness in human body since it does not take into
account the interaction between multiple tissues. For example,
in cancer metastasis, multiple tissue sites and circulatory sys-
tems are involved, which underscore the significance of multi-
organoids system [2]. Multi-organoid systems have already
been implemented in the past, for instance, in [6], authors
proposed a microfluidic cell culture device representing 13
organs to model the inter-organ crosstalk and to assess the
relationship between organ volume and blood residence time.
The whole cascade of cancer metastasis, including the extrava-
sation of cancer cells from the tumor, their movement through
the bloodstream, and their penetration of an external organ are
modelled in [7]. Comparatively, little attention has been given
to the communication engineering perspective of organoid
interactions. Therefore, the Internet of Organoids aims to
provide seamless communication for organoids to organoids,
organoids to electronic entities, and organoids to organs. More
specifically, the Internet of Organoids involves viewing this
biological system through the lens of communication system
design, data transmission, and signal processing.
One common way that human tissues interact with each
other is molecular communication (MC). MC is a biologically
inspired technology that encodes, transmits, and receives in-
formation through the use of messages conveyed in patterns of
molecules [8], [9]. Over billions of years, living things have
already chosen and utilized fully functional molecular commu-
nication (MC) networks through evolutionary processes. This
method is proven to be bio-compatible, and require very little
energy to generate and propagate. As a result, it is regarded
as one of the most promising methods for enabling Internet
of Nano-Things (IoNT) and nanonetworks [10], [11].
MC has been investigated from various perspectives. Many
studies focus on the modulation scheme, detection methods,
and information-theoretical models of MC channels. However,
most of these studies ignore the physical properties of re-
ceiver signals within the communication channel [12]. In the
Internet of Nano-Things, nanomachines are considered as po-
tential receivers. Bio-transceiver and bio-nanomachines have
been proposed in [13] and [14], respectively. While creating
nanomachines only from biocomponents has the benefit of
biocompatibility, there are some drawbacks that limit the range
of applications that nanonetworks can be used for. The low
computational capabilities of biocomponents significantly con-
fine the implementation of complex communication protocols
and algorithms [14]. At same time, they can only operate in
arXiv:2401.11214v1  [cs.ET]  20 Jan 2024
2
vivo application. Moreover, biocomponents create difficulties
in seamlessly connecting organoids to electronic entities such
as computers, thus challenging to integrate organoids to the
Internet of Nano-Things (IoNT) [8]. Contrarily, artificial MC
receiver can conduct in situ, continuous, label-free operation
for both in vivo and in vitro applications [15], [16]. An artifical
MC reciver will selectively detect the targetted information
ligands concentration and transfer to a more understandable
signal.
Thanks to new nanomaterials such as nanowires, carbon
nanotubes (CNTs), and graphene, FET-based biosensors, or
bioFETs, meet the primary requirements of an MC receiver
with enhanced performance. For example, a silicon nanowire
(SiNW) bioFET-based MC receiver is modeled in [17] and
[16], which discuss the structures of bioFET-based MC re-
ceivers. These investigations were expanded in [18], which
includes a thorough noise analysis based on the equilibrium
assumption for the receptor-ligand response at the receiver
surface. However, there are still some unresolved questions
in the modeling. In [18], the authors suggest an ideal BioFET
with a 0V threshold voltage so that the device operates in
the triode region during detection. However, achieving a 0V
threshold voltage is challenging in real life. High gate voltage
could potentially cause difficulty in power supply.
In system modeling, the MC receiver is usually considered
as a spherical entity [19]. However, in previous work [18],
[12], although a gate-all-around structure has already been
proposed, the full analysis is based on 2D MOSFETs, and
therefore, cannot demonstrate its 3D properties. FinFET, due
to its improved subthreshold slope (SS), better stability, higher
(ION/IOFF) ratio, enhanced short channel performance, and
smaller intrinsic gate capacitance [20], [21], has become the
ideal candidate for a 3D MC receiver. Up until now, many
papers have explored new FET-based structures. For example,
nanowire FET-based biosensors are proposed in [22], and junc-
tionless gate-all-around nanowire field-effect transistors with
an extended gate for biomolecule detection are presented in
[23]. However, none of these have performed the analysis from
a communication engineering perspective. For the first time,
the signal-to-noise ratio (SNR), and symbol error probability
(SEP) of a 3D MC receiver are carried out in the work, taking
into account the significance of signaling particles in MC
transceiver design.
The rest of the paper is organised as follows. In Section
II, we describe our proposed 3D BioFETs and explain its
operation principle. We develop the model of SiNW FET-
based MC receivers in Section III. Section IV includes an
evaluation of noise, signal-to-noise ratio (SNR), and symbol
error probability (SEP). These aspects will be presented and
contrasted with those of the planar design. Finally, our key
findings are concluded in Section V.
II. 3D BIOFET WORKING PRINCIPLE AND MODELING
A BioFET consists of a recognition unit, a transducer, and
a processing unit, as illustrated in Figure 1(a). Information
molecules propagate in the MC channel and approach the
recognition unit. When ligands reach the gate area, receptors
(a)
(b)
Fig. 1: (a) Functional units of an MC receiver [17], and (b) 3D
SiNW FET-based MC receiver antenna where receptors cover
all the gate area. Insulating SiO2 layer entirely covering the
SiNW, source and drain is not shown for better visualization
of the transducer
identify and bind with the appropriate ligands. The transducer
then converts this signal, originally encoded in the concen-
tration of information molecules, into an electrical potential
[17]. The potential generated at the gate is proportional to
the accumulated ligands. Upon applying a potential difference
to the drain and source, a current flows through them. This
gate potential modulates the channel’s conductance, resulting
in varying current levels. Figure 1(b) depicts the conceptual
3D FinFET MC receiver we propose, where all three sides of
the SiNW channel are covered with receptors.
For the FinFET-based receiver, due to its unique 3D struc-
ture, using the original MOSFET (2D) based current equation
and transconductance equation will no longer be an accurate
estimation. FinFET improves the control of the gates over
the MOSFET channel as the gate voltage is applied from the
top and sides. To better understand the structure, Figure 2(a)
shows a cross-sectional view of the proposed device along
the channel length. To more accurately quantify the location
within the channel, we define the source and the drain that
are at y = 0 and y = yeff, respectively, where yeff is the
effective channel length. The front and back interfaces between
SiNW − SiO2 are defined as x = 0 and x = ts where ts
represents the thickness of SiNW. The front and back oxide
3
thicknesses are toxf and toxb. The cross-sectional view along
the channel width is shown in Figure 2(b). Two Si − SiO2
interfaces are located in z = 0 and z = W. toxw is the side
wall oxide thickness. In our model, we assume the source and
the body are perfectly grounded. For simplicity, we assume
toxf = toxw = tox. Therefore, the area of functionalized
surface, i.e., Ar can be approximated as
Ar = (W + ts × 2) × Leff
(1)
where Leff is the effective length of the channel in y direction.
Assume the width of oxide layer is negligible compared to the
height of the channel.
The threshold voltage, Vt, is a key parameter for FET-based
transistors. In many previous works on modeling FET-based
receivers, the threshold voltage has not been taken into account
[17], [24]. The threshold voltage of a long-channel n-type
FinFET is expressed as
Vt = Vfb − 2kT
q
ln

qtox
εox
s
n2
i εSiNW
2kTNA

 ,
(2)
where Vfb is the flat-band voltage, k is the Boltzmann con-
stant, T is the temperature in Kelvin. ni is the intrinsic carrier
concentration and NA is the doping concentration. q is the
charge of an electron, εSiNW and εox are the permittivity of
SiNW and oxide, respectively [25].
For most tri-gate FinFET (similar structure as in Figure
1(b)), ts > W. With this simplification, most of the current
flows along the side gates. Therefore, the effective width of
the device becomes Weff = W +ts ×2, and hence, the drain
current Id, in FinFET can be found by
Id = µ2Weff
Leff
εox
toxf
2kT
q
2 
(qis − qid) + 1
2
4
(a)
(b)
Fig. 3: (a) 3D and (b) 2D views of a microfluidic channel and the locations of transmitter and receiver [18]
Fig. 4: Block diagram of microfluidic MC system with SiNW FET-based MC receiver [18].
distributed over the channel’s cross-section at the release time,
the ligand concentration, e.g., ρm(x, t = 0) can be expressed
as
ρm(x, t = 0) = Nm
Ach
δ(x),
(7)
where δ(x) is the Dirac delta function and Ach = hc × lch
is the cross-sectional area of the channel. By solving the
one-dimensional advection-diffusion equation and consider
solution for t > 0, the ligand concentration profile is given
by [27]
ρm(x, t) = Nm/Ach
√
4πDt
exp

−(x − ut)2
4Dt

.
(8)
B. Received Signal
The peak ligand concentration is attenuated when the lig-
ands diffuse and transported along the channel by the fluid
flow. The expected time it takes for the peak concentration to
reach the receiver’s center position, x = xR, is how we define
the propagation delay, i.e.,
tD = xR
u ,
(9)
where u is the average flow velocity [18]. Assuming that the
transmitter and receiver are perfectly synchronized in time
[18], that is the received signal can be detected in the peak
value of ρm(x, t) at tD. Therefore, the input signal at the
receiver will be
ρm (xR, t) ≈ρm (xR, tD) =
Nm
Ach
√4πDtD
for t ∈ [tD − τp/2, tD + τp/2] ,
(10)
where τp is the approximate passage duration of a portion of
ligand concentration to be sampled over the receiver surface
[18].
5
C. Biorecognition Block and Binding Noise
The transport rate, also known as ligand flux to the receiver
surface, determines the biorecognition process. For a rectan-
gular cross-section microfluidic channel, transport rate can be
approximated as
kT = Dlr×








0.8075P 1/3
s
+ 0.7058P −1/6
s
− 0.1984P −1/3
s

,
if Ps > 1
2π
4.885−ln(Ps)

1 −
0.09266Ps
4.885−ln(Ps)

, if Ps < 1
(11)
where Ps =
6
The bioFET-based MC receiver suffers from flicker noise
during low-frequency operation, similar to other transistor
devices. The flicker noise for FET type devices is accurately
described by the correlated carrier number and mobility fluc-
tuation model, which we use in this paper. We attribute the
source of the flicker noise to the random generation and
recombination of charge carriers as a result of defects and traps
in the SiNW channel brought about by imperfect fabrication
[36]. The resulting output current-referred noise PSD at triode
region is [37]
SIF
m(f) = SV,F B(f)g2
F ET [1 + αsµnCOX (VSG − |Vt|)]2 ,
(22)
where the PSD of the flatband-voltage noise SV,F B(f) is given
as
SV,F B(f) = λkBTq2Not
wRlRC2
OX|f|,
(23)
where λ is the characteristic tunneling distance, Not is the
oxide trap density, i.e., impurity concentration, of the SiNW
channel [37].
F. Overall Noise PSD
The overall PSD of the output current referred noise can be
given as
SIm(f) = SIB
m(f) + SIF
m(f),
(24)
Where additive binding noise SIB
m = SNB,m(f)×Ψ2
L ×g2
F ET .
Therefore, the SNR at the output will be
SNRout ,m = µ2
Im
σ2
Im
,
(25)
where σ2
Im is the output current variance which can be
computed as follows
σ2
Im =
Z ∞
−∞
SIm(f)df.
(26)
IV. PERFORMANCE ANALYSIS
In this section, we present numerical results derived from
our model, using various settings to demonstrate the efficacy
of concentration shift keying (CSK) with a 3D MC receiver.
Table I outlines the default settings for configurable parameters
used in our studies. These settings are based on those used in
a planar MC receiver, as referenced in [18]. The original work
did not include the threshold voltage in its analysis; therefore,
we use the same overhead voltage (VSG − Vt) to ensure a
fair comparison. We have chosen a Fin height of 5 × 10−8m,
assuming it is significantly smaller than the channel height and
thus does not affect the fluid flow.
A. Receiver Response and Noise Power
1) Receiver Response: In Figure 5, the expected current
response at the receiver due to the variation in the number
of ligands released by the transmitter, denoted as Nm, is
shown. We also investigate the impact of different transmission
distances on this response.
TABLE I: Default Values of Simulation Parameters
Parameter
Value
Flatband voltage(Vfb))
−0.4762 V
SiNW height(ts))
5 × 10−8 m
Microfluidic channel height (hch)
3 µm
Microfluidic channel width (lch)
15 µm
Number of transmitted ligands for symbol m(Nm)
5 × 105
Max number of ligands transmitter can release (K)
4 × 106
Transmitter-receiver distance (d)
1 mm
Average flow velocity (u)
10 µm/s
Diffusion coefficient of ligands (D0)
2 × 10−10 m2/s
Binding rate (k1)
2 × 10−19 m3/s
Unbinding rate (k−1)
20 s−1
Average number of electrons in a ligand (N−
e )
3
Width of the SiNW (W)
10π nm
Concentration of receptors on the surface (ρSR)
4 × 1016 m−2
Length of a surface receptor (lSR)
2 nm
Temperature (T)
300K
Relative permittivity of oxide layer (εox/ε0)
3.9
Relative permittivity of SiNW (εNW /ε0)
11.68
Relative permittivity of medium (εr/ε0)
78
Ionic strength of electrolyte medium (cion)
30 mol/m3
Source-drain voltage (VSD)
0.1 V
Overhead voltage (VSD − Vt)
0.4 V
Hole density in SiNW (p)
1018 cm−3
Tunneling distance (λ)
0.05 nm
Thickness of oxide layer (tox)
2 nm
Oxide trap density (Not)
1016 eV −1cm−3
Effective mobility of hole carriers (µp)
500 cm2/V s
Coulomb scattering coefficient (αs)
1.9 × 10−4 V s/C
Fig. 5: Expected output current µIm as a function of number
of ligands Nm released by transmitter in 3D receiver
The performance observed is similar to the 2D cases
referred to in [18]. As the number of transmitted ligands
increases, a higher output current is generated. However,
beyond a certain threshold, owing to the saturation of surface
receptors, the device begins to lose its sensitivity to variations
in ligand concentration.
Transmission distance is another crucial factor affecting
the performance of the output current. The concentration
attenuates by a factor of
√
d with an increase in transmission
distance, as shown in (10). The shorter the transmission length,
the more sensitive the output current is to the number of
transmitted information molecules. However, this also leads
to quicker saturation. For instance, in the 10mm transmission
distance case, the expected output current does not saturate
even at Nm = 107, but the sensitivity is reduced, potentially
leading to detection issues.
7
Fig. 6: PSD of noise on SiNW based receiver in 2D and 3D
cases
The results obtained, when compared to 2D cases, show a
significantly higher expected output level. This is attributed
to the new proposed device having a much larger area of
receptors, allowing for more charges to accumulate on its
surface. Additionally, the FinFET structure, with its better-
controlled channel, results in a higher transconductance, fur-
ther improving the expected output current, as seen in (21)).
2) Noise Power: The PSD of noise on SiNW based receiver
in 2D and 3D cases are plotted in Figure (6). The individual
PSDs of binding and flicker noises are plotted as well, respec-
tively. At low frequencies, 1/f noise dominates for both cases
since binding noise has a flat power density at frequencies
below
1
τB [18]. At high frequencies (f > 10Hz), the binding
noise attenuates more than flicker noise, hence, both 2D and
3D models are dominated by flicker noise. Around its cut-
off frequency, binding noise starts to dominate in the 2D
case, whereas in the 3D case, both binding noise and flicker
noise contribute to the total noise almost equally. The cut-
off frequency is reduced due to the 3D structure since it has
a higher number of surface receptors (see (14)). The flicker
noise is higher in 3D cases. Since the flicker noise PSD is
proportional to g2
F ET (see (22)), and due to its larger effective
width, the 3D structure has a higher transconductance.
B. SNR analysis
In this section, the SNR at the output of our proposed
FinFET-based receiver is investigated under varying system
parameters. These parameters are further divided into three
groups: (i) communication system related parameters, (ii)
information molecules and receptors related parameters, and
(iii) receiver related parameters. rR is defined as the SiNW
radius, which can be approximated as Wfin
π
.
1) Effect of Communication System-related Parameters:
SNR is first investigated against various numbers of ligands
released at the transmitter in Figure 7(a). From the graph
plotted, it is observed that the more ligands transmitted, the
higher the SNR that can be achieved. The SNR starts to
saturate at 45dB when the surface receptors are exposed to
a high concentration of ligands. Compared to the 2D receiver,
the saturation SNR is 5dB higher because of a larger surface
area to accommodate receptors, which can produce a higher
expected current. This outweighs the effect of an increase in
noise. In Figure 7(b), for a fixed number of transmitted ligands,
the output SNR decreases with an increase in transmission
distance. This is because the concentration of information
molecules is attenuated by
√
d as the distance increases.
Figure 7(c) shows how the ionic strength of the fluid affects
the output SNR. The larger the ionic strength of the fluid, the
lower the Debye length. As a result, the effective charge will
be smaller, leading to a reduced potential generated at the gate.
This results in a smaller output current and, consequently, a
lower SNR.
The effect of fluid flow u on the receiver SNR is shown
in Figure 7(d). An increase in u means that the information
molecules move faster towards the receiver, resulting in less
attenuation. Therefore, the SNR improves before reaching
saturation.
For the FinFET-based receiver, the SNR exhibits a similar
trend compared to the 2D receiver, with overall noise perfor-
mance improved against communication parameters.
2) Effect of Information Molecules and Receptors-related
Parameters: The diffusion coefficient D0 has a significant
effect on the output SNR, as shown in Figure 8(a). A higher
D0 leads to a higher effective diffusion coefficient D. Since
an increase in D attenuates the concentration of molecules at
the receiver by
√
D, a higher D0 results in a lower SNR at
the output.
The intrinsic binding rate k1 measures the rate at which
ligands can combine with the receptors as they flow over the
receiver. A higher k1 leads to a lower dissociation constant
K, which increases the mean number of bound receptors, thus
increasing the expected output current and SNR, as shown in
Figure 8(b).
The receptor length is an important receiver characteristic.
A higher receptor length reduces the effective charge, hence
reducing the output level. An almost linear reduction of SNR
in dB can be observed from Figure 8(c).
Finally, the effect of the number of free charges per ligand is
investigated and shown in Figure 8(d). Highly charged ligands
generate more potential at the gate, leading to a higher output
current, which results in a better SNR.
3) Effect of Receiver-related Parameter: The size of SiNW
also affects the performance of the receiver, as shown in Figure
9(a). rR is directly related to the width of the FET-based
receiver. A larger width implies a larger area of receptors,
hence more ligands can be accommodated. Moreover, the
capacitance of the oxide layer and diffusion layer are all
related to this parameter. The increased SNR shows the same
trend compared to 2D cases, whereas the increase in SNR
performance due to the increase in rR is less pronounced
compared to the 2D receiver. This is because the 3D structure
has a larger effective width compared to the 2D one, making
the percentage increase in W smaller. Figure 9(b) shows how
the density of the receptor affects the performance of the
output SNR. A higher number of receptors will potentially
produce a higher fluctuation in gate voltage, hence, producing
a better SNR. At a high level of surface receptor, the SNR
begins to saturate because the transmitted signal is less than
8
(a)
(b)
(c)
(d)
Fig. 7: Effect of the communication system parameters on the SNR at the electrical output of the FinFET-based receiver. SNR
as a function of (a) number of transmitted ligands Nm, (b) transmitter-receiver distance d, (c) ion concentration cion of the
electrolyte medium, (d) average flow velocity u inside the microfluidic channel.
(a)
(b)
(c)
(d)
Fig. 8: Effect of the molecular parameters on the SNR at the electrical output of the FinFET-based receiver. SNR as a function
of (a) intrinsic diffusion coefficient of ligands D0, (b) intrinsic binding rate of ligands k1, (c) surface receptor length lSR, (d)
number of free electrons per ligand molecule N −
e
(a)
(b)
(c)
(d)
Fig. 9: Effect of the receiver design parameters on the SNR at the electrical output of the FinFET-based receiver. SNR as
a function of (a) SiNW radius rR, (b) surface receptor concentration ρSR, (c) SiO2 layer thickness rox, and (d) oxide trap
density Not in SiNW.
the number of surface receptors, indicating that an increase in
surface receptors may not necessarily lead to a higher number
of bindings.
The effect of the thickness of the oxide layer tox is shown
in Figure 9(c). A thicker tox leads to a decrease in COX,
which reduces the transconductance of the FET-based receiver.
Therefore, less gate voltage fluctuation can be transduced to
the current signal, leading to a lower SNR. In the FinFET-
based receiver, the trap density has a negative impact on the
output SNR, as shown in Figure 9(d). This is because a larger
Not leads to a higher flatband-voltage noise. A higher flatband-
voltage noise causes a higher flicker noise PSD, which reduces
the SNR.
C. SEP Analysis in physiological solutions
SNR analysis shows superior performance for the proposed
3D FinFET-based receiver, which utilizes vertical space. How-
ever, there are still some design parameters that need to be
considered. The gate voltage applied, after considering the
threshold voltage, is around -0.9V, which seems to be too large
for a device ultimately aimed at harvesting energy from the
surroundings. Moreover, the ionic strength used in previous
analysis is too small if we aim at organoid communication.
For example, Bovine serum and saline, often used as dialysate,
have an ionic strength around 150 mol/m3 [38]. A higher fin
is used in the following analysis with ts = 5 × 10−7 m.
SEP based on maximum likelihood (ML) detection is given
9
(a)
(b)
(c)
Fig. 10: Symbol error probability (SEP) for 1-bit and 2-bit modulation. SEP as a function of (a) transmission distance d, (b)
height of the SiNW ts, (c) source-drain voltage VSD
(a)
(b)
(c)
Fig. 11: Symbol error probability (SEP) for 1-bit and 2-bit modulation. SEP as a function of (a) intrinsic diffusion coefficient
D0, (b) ion concentration of the electrolyte cion, (c) oxide trap density Not
as
Pe =
1
2M
""
erfc
λ1 − µI0
σI0
√
2

+ erfc
 
µIM−1 − λM−1
σIM−1
√
2
!#
+
M−2
X
m=1

erfc
µIm − λm
σIm
√
2

+ erfc
λm+1 − µIm
σIm
√
2

,
(27)
where µIm is the mean output current and σIm is the output
current variance for symbol m, i.e., m = 0, . . . , M −1, erfc(x)
is the complementary error function, and λm is the decision
threshold based on ML [18].
In the following analysis, 1-bit and 2-bit Concentration
Shift Keying (CSK) will be taken into account. Figure 10(a)
shows how the SEP changes as a function of transmission
distance. It is evident that at short transmission distances, the
receiver tends to saturate, and at longer transmission distances,
the concentration of information molecules attenuates, hence
resulting in a high SEP. Therefore, it is clear that certain
optimizations can be performed on the transmission distance
to achieve the optimal transmission distance. Compared to 1-
bit CSK, 2-bit CSK exhibits a higher SEP but is less sensitive
to changes in transmission distance.
One of the key parameters in our proposed 3D model is
the height of the fin, which is almost the same magnitude as
the height of SiNW ts, as shown in Figure 10(b). Devices
with a thicker ts tend to have a higher number of surface
receptors, hence creating a higher expected output, with each
symbol then being further apart. Therefore, as ts increases,
SEP decreases. Note that as ts increases, it will eventually
affect the fluid flow and ligand propagation. Hence, a higher
channel height should be used in the analysis, or a new
received signal equation should be derived.
VSD is an important parameter if we consider the power
consumption of the device. The relationship between VSD and
SEP is shown in Figure 10(c). A larger magnitude of VSD
causes a higher level of flicker noise, which reduces the SEP
level. Therefore, as long as the device is operating in the linear
region, the lower the VSD, the better the SEP performance.
The intrinsic diffusion coefficient D0 is a crucial parameter
in physiological solutions. As shown in Figure 11(a), a higher
D0 leads to a higher SEP. This is due to the fact that a
higher diffusion coefficient will attenuate the signal received.
To cope with different ionic strengths in different physiological
solutions, SEP is found against different cion. A higher ionic
strength leads to a low Debye length, hence a lower effective
charge. This makes it difficult for the system to distinguish
different output levels, leading to a high SEP. The oxide
trap density Not indicates the impurity within the channel.
A lower Not means a clearer channel and a lower flicker
noise. Hence, as Not increases, a higher SEP is observed, as
shown in Figure 11(c). In general, the proposed 3D receiver
demonstrates the capability to operate effectively in more
challenging environments compared to 2D counterparts, while
10
still maintaining an acceptable SEP.
V. CONCLUSIONS
The implementation of a 3D FinFET-based molecular com-
munication receiver for organoid communication was investi-
gated for the first time in the literature, where both the top
and side gates are covered by receptors. The model takes
into account the height of the fin and the threshold voltage.
A rectangular microfluidic channel is considered, and both
biological binding noise as well as flicker noise are included
in the analysis. The results based on Signal-to-Noise Ratio
(SNR) and Symbol Error Probability (SEP) for the proposed
3D receiver have been compared to those of the 2D receiver,
demonstrating better noise performance and good SEP under
physiological conditions.
REFERENCES
[1] Z. Zhao et al., “Organoids,” Nat Rev Methods Primers, vol. 2, no. 1,
p. 94, Dec 2022.
[2] A. Skardal, T. Shupe, and A. Atala, “Organoid-on-a-chip and body-on-a-
chip systems for drug screening and disease modeling,” Drug Discovery
Today, vol. 21, no. 9, pp. 1399–1411, Sep 2016.
[3] U. Marx et al., “”human-on-a-chip” developments: A translational
cutting-edge alternative to systemic safety assessment and efficiency
evaluation of substances in laboratory animals and man?” Altern Lab
Anim, vol. 40, no. 5, pp. 235–257, Oct 2012.
[4] S. Zhang, Z. Wan, and R. D. Kamm, “Vascularized organoids on a chip:
strategies for engineering organoids with functional vasculature,” Lab on
a Chip, vol. 21, no. 3, pp. 473–488, 2021.
[5] L. Smirnova et al., “Organoid intelligence (oi): the new frontier in
biocomputing and intelligence-in-a-dish,” Front. Sci., vol. 1, p. 1017235,
Feb 2023.
[6] P. G. Miller and M. L. Shuler, “Design and demonstration of a
pumpless 14 compartment microphysiological system,” Biotechnology
and Bioengineering, vol. 113, no. 10, pp. 2213–2227, 2016.
[7] B. F. L. Lai et al., “Invade: Integrated vasculature for assessing dynamic
events,” Adv Funct Materials, vol. 27, no. 46, p. 1703524, Dec 2017.
[8] I. F. Akyildiz et al., “The internet of bio-nano things,” IEEE Communi-
cations Magazine, vol. 53, no. 3, pp. 32–40, Mar 2015.
[9] T. Nakano, A. W. Eckford, and T. Haraguchi, Molecular Communica-
tion.
Cambridge, U.K.: Cambridge Univ. Press, 2013.
[10] O. B. Akan et al., “Fundamentals of molecular information and com-
munication science,” Proceedings of IEEE, 2016.
[11] T. Nakano et al., “Molecular communication and networking: Oppor-
tunities and challenges,” IEEE Trans. Nanobiosci., vol. 11, no. 2, pp.
135–148, Jun 2012.
[12] M. Kuscu and O. B. Akan, “On the physical design of molecular
communication receiver based on nanoscale biosensors,” IEEE Sensors
J., vol. 16, no. 8, pp. 2228–2243, Sep 2016.
[13] T. Nakano et al., “Molecular communication among biological nanoma-
chines: A layered architecture and research issues,” IEEE Trans.
Nanobiosci., vol. 13, no. 3, pp. 169–197, Sep 2014.
[14] B. D. Unluturk, A. O. Bicen, and I. F. Akyildiz, “Genetically engi-
neered bacteria-based biotransceivers for molecular communication,”
IEEE Trans. Commun., vol. 63, no. 4, pp. 1271–1281, Apr 2015.
[15] M. Kuscu et al., “Transmitter and receiver architectures for molecular
communications: A survey on physical design with modulation, coding,
and detection techniques,” Proc. IEEE, vol. 107, no. 7, pp. 1302–1341,
Jul 2019.
[16] M. Kuscu and O. B. Akan, “On the physical design of molecular
communication receiver based on nanoscale biosensors,” IEEE Sensors
J., vol. 16, no. 8, pp. 2228–2243, Sep 2016.
[17] Kuscu, M. and Akan, O. B., “Modeling and analysis of sinw biofet
as molecular antenna for bio-cyber interfaces towards the internet of
bio-nanothings,” in 2015 IEEE 2nd World Forum on Internet of Things
(WF-IoT).
IEEE, 2015, pp. 669–674.
[18] Kuscu, M. and Akan, O. B., “Modeling and analysis of sinw fet-based
molecular communication receiver,” IEEE Transactions on Communica-
tions, vol. 64, no. 9, pp. 3708–3721, 2016.
[19] M. Pierobon and I. F. Akyildiz, “Diffusion-based noise analysis for
molecular communication in nanonetworks,” IEEE Trans. Signal Pro-
cess., vol. 59, no. 6, pp. 2532–2547, Jun 2011.
[20] Y. Taur and T. H. Ning, Fundamentals of Modern VLSI Devices, 2nd ed.
New York: Cambridge Univ. Press, 1998.
[21] J. Chen, T. Y. Chan, I. C. Chen, P. K. Ko, and C. Hu, “Subbreakdown
drain leakage current in mosfet,” IEEE Electron Device Letters, vol. 8,
no. 11, pp. 515–517, Nov 1987.
[22] J.-H. e. a. Ahn, “Nanowire fet biosensors on a bulk silicon substrate,”
IEEE Trans. Electron Devices, vol. 59, no. 8, pp. 2243–2249, Aug 2012.
[23] C.-W. Chen, R.-Z. Lin, L.-C. Chiang, F.-M. Pan, and J.-T. Sheu,
“Junctionless gate-all-around nanowire field-effect transistors with an
extended gate in biomolecule detection,” Jpn. J. Appl. Phys., vol. 58,
no. 2, p. 027001, Feb 2019.
[24] D. Aktas and O. B. Akan, “Weight shift keying (wsk) with practical
mechanical receivers for molecular communications in internet of every-
thing,” IEEE J. Select. Areas Commun., vol. 40, no. 11, pp. 3285–3294,
Nov. 2022.
[25] A. Tsormpatzoglou, N. Fasarakis, D. H. Tassis, I. Pappas, K. Papathana-
siou, and C. A. Dimitriadis, “Analytical unified drain current model of
long-channel tri-gate finfets,” in 2012 28th International Conference on
Microelectronics Proceedings.
Nis, Serbia: IEEE, May 2012, pp. 115–
118.
[26] K. Papathanasiou, C. Theodorou, A. Tsormpatzoglou, D. Tassis, C. Dim-
itriadis, M. Bucher, and G. Ghibaudo, “Symmetrical unified compact
model of short-channel double-gate mosfets,” Solid-State Electronics,
vol. 69, pp. 55–61, 2012.
[27] A. O. Bicen and I. F. Akyildiz, “System-theoretic analysis and least-
squares design of microfluidic channels for flow-induced molecular
communication,” IEEE Transactions on Signal Processing, vol. 61,
no. 20, pp. 5000–5013, Oct. 2013.
[28] D. Dutta, A. Ramachandran, and D. T. Leighton, “Effect of channel
geometry on solute dispersion in pressure-driven microfluidic systems,”
Microfluidics and Nanofluidics, vol. 2, no. 4, pp. 275–290, July 2006.
[29] P. E. Sheehan and L. J. Whitman, “Detection limits for nanoscale
biosensors,” Nano Lett., vol. 5, no. 4, pp. 803–807, 2005.
[30] A. M. Berezhkovskii and A. Szabo, “Effect of ligand diffusion on
occupancy fluctuations of cell-surface receptors,” Journal of Chemical
Physics, vol. 139, no. 12, p. 121910, 2013.
[31] M. Curreli et al., “Real-time, label-free detection of biological entities
using nanowire-based fets,” IEEE Transactions on Nanotechnology,
vol. 7, no. 6, pp. 651–667, Nov. 2008.
[32] E. Stern, R. Wagner, F. J. Sigworth, R. Breaker, T. M. Fahmy, and M. A.
Reed, “Importance of the debye screening length on nanowire field effect
transistor sensors,” Nano Letters, vol. 7, no. 11, pp. 3405–3409, Nov.
2007.
[33] N. K. Rajan, X. Duan, and M. A. Reed, “Performance limitations
for nanowire/nanoribbon biosensors,” Wiley Interdisciplinary Reviews:
Nanomedicine and Nanobiotechnology, vol. 5, no. 6, pp. 629–645, 2013.
[34] K. Shoorideh and C. O. Chui, “On the origin of enhanced sensitivity in
nanoscale fet-based biosensors,” Proceedings of the National Academy
of Sciences of the USA, vol. 111, no. 14, pp. 5111–5116, Mar. 2014.
[35] X. P. A. Gao, G. Zheng, and C. M. Lieber, “Subthreshold regime has the
optimal sensitivity for nanowire fet biosensors,” Nano Letters, vol. 10,
no. 2, pp. 547–552, 2010.
[36] S. M. Sze and K. K. Ng, Physics of Semiconductor Devices.
Hoboken,
NJ, USA: Wiley, 2007.
[37] N. K. Rajan, D. A. Routenberg, J. Chen, and M. A. Reed, “Temperature
dependence of 1/f noise mechanisms in silicon nanowire biochemical
field effect transistors,” Appl. Phys. Lett., vol. 97, no. 24, p. 243501,
2010.
[38] M. Okada, T. Watanabe, K. Imamura, T. Tsurumi, Y. Suma, and
K. Sakai, “Ionic strength affects diffusive permeability to an inorganic
phosphate ion of negatively charged dialysis membranes,” ASAIO Trans-
actions, vol. 36, no. 3, pp. M324–M326, 1990.
","nanMC has been extensively studied, with focus on modulation schemes, detection methods, and channel models, but few investigations consider the physical properties of receiver signals. Studies have proposed bio-transceivers and bio-nanomachines for artificial MC receivers, but these suffer from limitations in biocompatibility, computational capabilities, and seamless integration with electronic entities. On the other hand, artificial MC receivers can conduct continuous, label-free operation in both in vivo and in vitro applications."
"This research presents a Legal-BERT and SVC-based method for identifying unfair clauses in Terms of Service (ToS) documents. The methodology, which incorporates custom fine-tuning of transformer language models (TLMs), delivers superior unfair clause detection performance compared to existing approaches. Empirical analysis and comparative studies highlight the effectiveness of various transformer models and embedding modes in this task.","Companies often use complex and ambiguous clauses in their ToS agreements, which can lead to unfair outcomes for consumers. Traditional methodologies for detecting unfair clauses have shown limited efficacy. This research aims to address this issue by presenting a novel approach based on customized fine-tuning of transformer language models (TLMs) in conjunction with Support Vector Classifiers (SVC). The study leverages Legal-BERT, a pre-trained TLM for legal documents, and explores multiple transformer architectures to ascertain the best model for the task.","This research utilizes a dataset of ToS documents annotated with eight categories of unfair clauses. The study explores various transformer architectures, including Legal-BERT, ELECTRA, DeBERTa, DistilBERT, and DistilRoBERTa. Custom architectures are designed and fine-tuned for the task. Additionally, the research investigates the impact of different embedding generation modes to derive sentence embeddings from the TLMs.","The proposed Legal-BERT-based approach in conjunction with SVC outperforms existing state-of-the-art methods, achieving a macro F1-score of 0.922 at unfair clause detection. Comparative analyses reveal the varying performances of transformer models and embedding modes. Furthermore, the study demonstrates the proposed approach's effectiveness in classifying unfair clauses into specific categories.","The study showcases the ability of customized fine-tuning of TLMs to achieve superior results in unfair clause detection from ToS documents. By leveraging Legal-BERT and SVC, the proposed method provides a more accurate and efficient approach to identifying unfair terms. The study's findings contribute to automated unfair clause detection, saving valuable time and resources in the legal and business domains.",Unfair TOS: An Automated Approach using Customized BERT,"Bathini Sai Akash, Akshara Kupireddy, Lalita Bhanu Murthy","arXiv:2401.11207v1  [cs.CL]  20 Jan 2024
Highlights
Unfair TOS: An Automated Approach using Customized BERT
Bathini Sai Akash, Akshara Kupireddy, Lalita Bhanu Murthy
• ToS deﬁnes legal relationships between Service Providers and End-users
in digital services.
• Users often accept ToS without complete comprehension, risking legal
implications.
• Traditional methodologies for ToS unfair clause detection show limited
eﬃcacy. Additionally, existing ML methodologies applied to the task
are obsolete, failing to perform adequately.
• Research presents SOTA results in unfair clause detection from ToS
documents via integration of custom Fine-tuning BERT with SVC.
• Comparative analysis conducted, focusing on Transformer models used,
to answer pertinent research questions.
Unfair TOS: An Automated Approach using
Customized BERT
Bathini Sai Akash, Akshara Kupireddy, Lalita Bhanu Murthy
aBITS Pilani Hyderabad Campus, Secunderabad, Hyderabad, 500084, Telangana, India
bSymbiosis Law School, Hyderabad, Mamidipalle,
Nandigaon, Hyderabad, 509217, Telangana, India
cBITS Pilani Hyderabad Campus, Secunderabad, Hyderabad, 500084, Telangana, India
Abstract
Terms of Service (ToS) form an integral part of any agreement as it deﬁnes
the legal relationship between a service provider and an end-user. Not only
do they establish and delineate reciprocal rights and responsibilities, but they
also provide users with information on essential aspects of contracts that per-
tain to the use of digital spaces. These aspects include a wide range of topics,
including limitation of liability, data protection, etc. Users tend to accept
the ToS without going through it before using any application or service.
Such ignorance puts them in a potentially weaker situation in case any ac-
tion is required. Existing methodologies for the detection or classiﬁcation of
unfair clauses are however obsolete and show modest performance. In this
research paper, we present SOTA(State of The Art) results on unfair clause
detection from ToS documents based on unprecedented Fine-tuning BERT in
integration with SVC(Support Vector Classiﬁer). The study shows proﬁcient
performance with a macro F1-score of 0.922 at unfair clause detection, and
superior performance is also shown in the classiﬁcation of unfair clauses by
each tag. Further, a comparative analysis is performed by answering research
questions on the Transformer models utilized. In order to further research
and experimentation the code and results are made available on GitHub.
Keywords:
Unfair Clause Detection, BERT Fine-tuning, Terms of service,
Data protection, Consumer rights
1. INTRODUCTION
As consumers, we know that though we are notiﬁed on perusing the Terms
of Service (hereinafter ToS) before the use of any application or service online,
Preprint submitted to Information Systems
January 23, 2024
we often accept the conditions without reviewing them thoroughly. Each
smartphone typically contains a minimum of 10 to 15 applications, each
governed by its respective set of ToS. It is the responsibility of the user
to go through the TOS and understand how their personal and sensitive
information is dealt with. In simple words, accepting ToS means that we have
entered into an agreement with the provider and now we will be governed
by these terms. Various modalities of acceptance are observed in relation
to diﬀerent software and applications: (i) Upon downloading an application
onto our devices, we are prompted to consent to the provider’s ToS; (ii) While
browsing online, upon accessing a web page, a notiﬁcation appears requesting
acceptance of cookies, privacy policy, or ToS; (iii) Some websites implement
implicit acceptance, assuming consent is granted through the act of browsing
the content of the site, among other approaches. Consumers or end-users do
not think twice before accepting these terms because usage of the application
at the moment is perceived much more necessary than going through legal
implications later. For example, a consumer that has accepted the terms
where the company has limited its liability is a complex situation because if
the consumer is dissatisﬁed with the services provided, he can only claim to
the extent limited though the damages are much higher. It is also observed
that the clauses are quite overwhelming to even erudite users to read and
understand as shown in the case of Commerce (2010). Estimates suggest
that merely dedicating time to read ToS or privacy policies could amount to
an annual time investment of more than 200 hours per individual as shown
in McDonald A (2008). Considering this, it can be interpreted that a lack of
awareness among consumers on their rights and limitations has led to the very
concept and core conundrum of this research, “acceptance of unfair terms and
conditions”. Further, startups in general don’t have a dedicated Legal team
for recognition of unfair clauses in the Business-to-Business(B2B) services
that are being used. This could lead to detrimental eﬀects in the long run.
Automation of such unfair clause detection without any interference from
legal experts could have numerous lucrative beneﬁts.
Though countries have adopted laws to prevent unfair trade practices,
many companies obligate consumers into accepting their terms which are
highly dominant and there is a signiﬁcant imbalance in the rights and obliga-
tions of the parties to the contract. It can also be observed that some jurisdic-
tions do not bar companies from practicing these imbalanced rights over con-
sumers. Our work, hence, deals with identifying unfair terms in ToS contracts
consecutively helping end-users and businesses. We present a Legal-BERT
2
and SVC-based model that identiﬁes clauses based on 8 categories(tags):
Limitation of liability, Unilateral termination, Unilateral change, Content re-
moval, Contract by choice/use, Choice of Law, Jurisdiction, and Arbitration.
The study works on two tasks. The ﬁrst task is a classiﬁcation of each state-
ment into unfair or not based on Unfair Binary as shown in Section(). This
task aims to check for the existence of any clause in a statement but not for a
speciﬁc unfair tag. The second task aims at the categorization of statements
into a speciﬁc unfair tag. The work has the potential for complete automation
with notable superior performance, saving crucial time that can be invested
elsewhere for users. Its lucrative impact also reduces the ﬁnancial burden on
companies that employ services to go through these contracts. Most impor-
tantly, its high impact would be in the B2C market directly providing keen
information and rightly deserved decision-making to fellow customers.
2. RELATED WORK
Several ideas in the literature have sought to evaluate online legal docu-
ments, such as privacy policies and terms of service, to provide protection
for the rights of citizens. Without the inclusion of studies with regard to
Privacy Policies such as [Bannihatti Kumar et al. (2020), Fukushima et al.
(2018), Harkous et al. (2018)], little eﬀort has been presented in terms of the
TOS. In the following section, we show the literature that aimed at unfair
clause detection from TOS documents.
Lippi et al. (2019) revolutionized TOS tagging with unfair clauses with
the creation of a dataset with TOS documents of 50 companies all annotated
with 8 unfair clause categories. The study also uses ensemble classiﬁcation
methods for the prediction of these classes. Next, the following studies made
use of the same dataset for TOS unfair clause detection. A notable study by
Guarino et al. (2021) utilized sentence embeddings from mUSE(Yang et al.
(2019)) and further ML classiﬁers for predictions. The results surpassed the
results presented in CLAUDETTE(Lippi et al. (2019)).
Lucia et al.
pro-
posed Legal-BERT in the study Zheng et al. (2021).
Legal-BERT stems
from pre-training vanilla BERT further on 12 GB(53000 data entries) of var-
ied English legal material from many disciplines (such as legislation, court
cases, and contracts).
Next, Mamakas et al. (2022) proposed adapting a
LegalBERT-warm-started Longformer for processing larger texts. This was
referred to as LegalLongformer, however, it underperformed as compared to
LegalBERT in the case of TOS unfair clause classiﬁcation.
3
Furthermore, the study by Ruggeri et al. (2022) investigates conﬁgura-
tions for memory-augmented neural networks with a focus on the signiﬁ-
cance of rationales in context modeling. According to the results, rationales
improve classiﬁcation precision and provide concise, understandable justiﬁca-
tions for classiﬁer output that might otherwise be ambiguous. The study fur-
ther added 50 TOS documents to the dataset annotated by Lippi et al. (2019)
leading to a total of 100 TOS documents and focused on only 5 categories
of unfair clauses. As an extension to this, a recent study by Ruggeri et al.
(2022) suggests an addition to transformer models, using external memory to
store and then apply natural language interpretations to explain classiﬁcation
outcomes.
Finally, Xu et al. (2022) worked on analysis using all-encompassing ad-
versarial triggers to attack an unfair-clause detector. Studies reveal that any
minor modiﬁcation to the text can signiﬁcantly lower the detection perfor-
mance. Our study works on achieving SOTA(State Of The Art) performance
at TOS classiﬁcation of unfair clauses on the dataset presented by Lippi et al.
(2019).
3. BACKGROUND AND DATASET
AI and technology have recently shaped the legal ﬁeld by making it easier
to understand clauses, rules, and the law itself. This is also evident in the
recent hike in the employment of lawyers with tech backgrounds who are
well-versed in tech law. These lawyers increase the eﬃciency of working of
law because, through the perspective of science, interpretation, comprehen-
sion, and explanation are the three most crucial structures for the proper
functioning of a model(Loos and Luzak (2016)). Our work deals with these
three components by comprehending the law in simple terms and then inter-
preting and giving accurate outcomes with explanations. Companies exploit
their customers by causing substantial injury, by not giving the option to
negotiate ToS, and by countervailing the unfair clauses with beneﬁts or ad-
ditional services provided to the customers. The legal system also cannot
provide complete assistance with these issues as it is limited to the view
that both the parties, the companies, and the end users, should be dealt
with in fairness adhering to audi alteram partem. This standpoint can also
be observed in the case of Securicor (1980), the Upper House of the Indian
Parliament was of the opinion that “the principles against the exclusion of
liability clauses are not applicable in their full vigor when considering the
4
facet of mere limitation of liability clauses.” A similar judgment was held
in Mitchell (1983). Further, in Pittalis (1986) the courts held that though
there is a dominant arbitration clause in favor of one of the parties, it can-
not be rendered invalid. But in September 2019, one of the giants- Amazon,
was ﬁned 4 million Euros for including unfair clauses such as unilateral ter-
mination, unilateral change, limitation of liability, etc. It was also ordered
that its “standard terms of service” be amended within 180 days. Now that
we observe, these clauses are determined as fair and unfair case by case on
approaching the courts, and there is no standard law that protects the con-
sumers. In order to increase consumers’ awareness and maintain contractual
security, our research suggests establishing a precise description of unfairness
in the Terms of Service. This description will be determined by a comprehen-
sive measure of unfairness, which includes eight diﬀerent categories, which
later evaluates the number of unfair provisions incorporated in a company’s
ToS. Additionally, the measure will underscore these terms depending on the
brunt of the actual concerns of consumers.
3.1. Dataset
Our work makes use of the dataset from Lippi et al. (2019). It consists
of 8+1 classes. Eight classes are unfair clause classes of each category, and
the last class is annotated positive if one or more clauses of any category
are present in the statement. This class is referred to as Unfair Binary. An
explanation of each unfair category is given below:
(1) Limitation of Liability[ltd]: This category in ToS is where companies
either completely exclude liability or cap the amount/loss which they
are actually liable for. Any clause that explicitly mentioned that the
company was liable for certain acts was identiﬁed as fair (0). Instances
where the companies capped or excluded their liability were marked as
unfair (1). Example clause: “7(c)neither we nor any of our aﬃliates
or licensors will be liable for any indirect, incidental, special, conse-
quential or exemplary damages, including damages for loss of proﬁts,
goodwill, use, or data or other losses, even if we have been advised of
the possibility of such damages.” OpenAi.
(2) Unilateral termination[ter]: This category in ToS is when the ser-
vice provider retains the right to terminate/suspend a part/clause of
ToS or the contract as a whole, temporarily or permanently. Such a
termination/suspension could be for any/no reason whatsoever.
All
5
the clauses that gave service providers the right were marked as unfair
(1). Example clause: “Any breach of the following restrictions consti-
tutes a breach of the Terms of Use and entitles Ferrari to unilateral
termination of the Agreement.” Ferrari.
(3) Unilateral change[ch]: This category in ToS gives the service provider
the right to amend or change the terms of the contract or the contract
as a whole. Such a change could be for any/no reason whatsoever. All
the clauses that gave service provider such right were marked as unfair
(1). Example clause: “You should look at these Terms regularly, which
are posted on the Hulu Site at hulu.com/terms. If we make a material
change to these Terms, we will notify you by posting a notice on the
Hulu Site.” Hulu.
(4) Content removal[cr]: This category in ToS gives the service provider
the right to alter/remove any content provided at a point of time with
or without any notice.
Such a removal could be for any/no reason
whatsoever.
All the clauses that gave service providers such rights
were marked as unfair (1). Example clause: “You agree that from time
to time we may remove the service for indeﬁnite periods of time or
cancel the service at any time, without notice to you.” TLC.
(5) Contract by using[use]: This category of ToS stipulates how the
customer is legally obligated to adhere to the terms and conditions
of utilizing a certain service that is provided by the service provider,
regardless of necessitating explicit acknowledgment or acceptance to
the conditions of use. All the clauses that gave service providers such
rights were marked as unfair (1). Example clause: “The Terms include
our Service Terms, Sharing & Publication Policy, Usage Policies, and
other documentation, guidelines, or policies we may provide in writing.
By using our Services, you agree to these Terms.” OpenAi.
(6) Choice of law[law]: This category of ToS lets the service provider
specify which state’s law shall govern the contract and which shall
prevail if there is any dispute arising out of the contract. All the clauses
mentioning the choice of law is that of the consumer’s country was
marked as fair (0). All the clauses that prefer or specify otherwise
were marked as unfair (1). Example clause: “These Terms of Service
and any separate agreements whereby we provide you Services shall
be governed by and construed in accordance with the laws of South
Africa.” TLC.
(7) Jurisdiction[j]: This category of ToS speciﬁes under which jurisdic-
6
tion the disputes shall be addressed regardless of where the cause of
action arose. All the clauses mentioning the jurisdiction as that of the
consumer’s residence/country were marked as fair (0). All the clauses
that specify otherwise were marked as unfair (1). Example clause: “To
the extent that the arbitration provision outlined in Section 13 is not
applicable, you and Hulu agree to submit to the exclusive jurisdiction of
the courts located in the Los Angeles County of the State of California.”
Hulu.
(8) Arbitration[a]: This category of ToS mentions arbitration as the ﬁrst
step before approaching the courts or makes arbitration the sole re-
lief. All the clauses mentioning the arbitration as a mere choice were
marked as fair (0). All the clauses that specify otherwise in terms of
place of residence or service provider discretion were marked as unfair
(1). Example clause: “In the unlikely event that an issue between us
remains unresolved, please note that THESE TERMS REQUIRE AR-
BITRATION ON AN INDIVIDUAL BASIS, RATHER THAN JURY
TRIALS OR CLASS ACTIONS.” Hulu.
(9) Unfair binary[ub]: This category of ToS marks sentences with at least
one above unfair clauses as 1 and all fair/neutral sentences as 0.
Example clauses for each category and statistics of the dataset are pre-
sented in Table(1). In total, there were 9414 statements each annotated into
eight categories.
Table 1: Examples for each unfair category
Unfair Tag
Clause/Category
Spread
ltd
Limitation of Liability
296
ter
Unilateral termination
236
ch
Unilateral change
188
cr
Content removal
118
use
Contract by using
117
law
Choice of law
70
j
Jurisdiction
68
a
Arbitration
44
ub
Unfair binary
1137
7
4. FINE TUNING PRE-TRAINED LANGUAGE MODELS
The development of ""pretrained"" (or self-supervised) language models,
beginning with Google’s BERT model, is considered one of the most impor-
tant developments in natural language processing (NLP). The incorporation
of these exceptional models in the ﬁeld of law has however been belated. In
this study, we ﬁrst explore multiple transformer architectures in the ﬁeld of
Law for unfair clause detection.
Legal-BERT. The Bidirectional Encoder Representations from Trans-
formers (BERT, for short) is a comprehensive deep learning-based language
model.
A transformer model with 12 stacked encoders is at the founda-
tion of the BERT architectural framework. As used in previous studies, un-
like context-independent methods like words2vec, Tf-Idf, GloVe, and Elmo,
which create single-word embeddings without taking into account global con-
text, BERT employs embeddings that dynamically adjust depending on the
contextual use of a particular word across distinct phrases.
The research made use of a further pre-trained BERT base model called
Legal Bert. Legal-BERT is a set of BERT models for the legal domain that is
meant to support applications in computational law, legal technology, and le-
gal NLP research(Zheng et al. (2021)) Pre-trained on gathered 12 GB(53000
data entries) of varied English legal material(such as legislation, court cases,
and contracts), it shows more proﬁcient results in the legal ﬁelds as compared
to vanilla bert.
ELECTRA After BERT, a revolutionary pretraining method ELEC-
TRA trains the generator and discriminator transformer models. The gener-
ator is trained as a masked language model since its function is to substitute
tokens in a sequence. The discriminator attempts to determine which to-
kens in the chain were substituted by the generator. ELECTRA generically
outperforms BERT requiring lesser training data(Clark et al. (2020)). The
study made use of google/electra-base-discriminator.
DeBERTa DeBERTa is a brand-new model that improves RoBERT and
BERT by adding disentangled attention and a better mask decoder for pre-
training. Disentangled attention, which represents each word’s content and
location using two vectors, and an improved mask decoder, which takes the
place of the softmax layer and predicts masked tokens, are the two main
strategies used(He et al. (2020)). The study made use of microsoft/deberta-
base. DeBERTa being a lesser-known model, its performance in the ﬁeld of
Law is yet to be tested and analyzed.
8
DistilBERT DistilBERT is a faster and more compact version of the
transformers model proposed by Sanh et al. (2019). It was pre-trained using
the same corpus while being guided by the BERT basic model, which served
as a teacher. BERT’s performance was not intended to be maximized via
DistilBERT. Instead, it seeks to maximize training optimization while mini-
mizing the enormous size of BERT (and having 110M and 340M parameters,
respectively).
DistilRoBERTa
The reﬁned version of the RoBERTa base is called
DistilRoBERTa. DistilBERT and DistilRoBERTa have similar training. Since
RoBERTa used alternative hyperparameters during training, it performs no-
tably better than BERT. The model has six layers, seven hundred sixty-eight
dimensions, twelve heads, and 82 million parameters (compared to 125M pa-
rameters for RoBERTa-base).
4.1. Custom Fine tune
The study ﬁrst aims to understand the raw performance of pre-trined
language models. To do this, we create custom architectures that incorporate
Dense Perceptron layers over the transformer stack to get binary output
of unfair clause classiﬁcation.
After the architecture is built, ﬁne-tuning
is performed for each model, respectively, and weights are tuned for the
task. The performance and architectures are shown in table2. We test with
ﬁve epochs, batch size in [8,16,32], and learning rate [1e-5,2e-5,4e-5].
In
the custom architecture shown, Dense(x) is a perceptron layer where x is
the input neuron size.
If it is the last Dense layer then output neurons
would be 2(Binary Classiﬁcation). Next, dr(x) is a dropout layer with p=x.
When employing pre-trained language representation models like BERT, the
text does not need dedicated preprocessing, and the removal of tokens shows
detrimental eﬀects elucidated by Zhong et al. (2023). In speciﬁc, it employs a
multi-head self-attention system to utilize all of the information in a phrase,
including punctuation and stop words, from a variety of angles.
Further,
the dataset under consideration is already pre-processed with the removal of
unnecessary characters.
On inspection of table2, there’s a notable diﬀerence in the performance of
Distil models over traditional transformer models. Further, the performance
of ELECTRA slightly improves over Legal-BERT although Legal-BERT was
pre-trained(NSP) in the Legal domain. The reason for this could be because
of the low domain speciﬁcity of TOS in legal documents trained on BERT as
9
Table 2: Performance of Custom Transformer Architectures
Model
Hyper-parameters
Custom Arch
P
R
F1
Legal-BERT
bs=8,lr=1e-5
dr(0.1)+Dense(768)
0.835
0.88
0.858
Electra
bs=8,lr=2e-5
Dense(768)+dr(0.1)+Dense(768)
0.879
0.848
0.863
DeBERTa
bs=16,lr=1e-5
dr(0.1)+Dense(768)
0.867
0.840
0.857
DistilBERT
bs=16,lr=4e-5
Dense(768)+Dense(768)+dr(0.2)
0.838
0.816
0.826
DistilRoBERT
bs=16,lr=2e-5
Dense(768)+dr(0.1)+Dense(768)
0.842
0.825
0.833
mentioned in Zheng et al. (2021). Hence, we consider Legal-BERT, Electra,
and DeBERTa for further testing.
5.
RESEARCH FRAMEWORK
The following section shows the proposed design and techniques used for
Unfair Binary prediction(Task-1).
5.1. Research Methodology
While working with transformer models the following prospective method-
ologies were used in the research are as follows:
1. Generation of Vannila LM embeddings(Baseline)
2. Further pre-training of LM on Target Corpus(Pretarined): The trans-
former models are pre-trained on TOS dataset. Even though the dataset
is considerably smaller compared to the extensive pre-training that was
already performed, studies show that marginal performance gains could
be achievedAraci (2019). For transformer models, two forms of pre-
training exist, Masked Language Modeling (MLM) pre-training and
Next Sentence Prediction(NSP). The pre-training performed for Legal-
BERT and DeBERTa was MLM pre-training without NSP pre-training.
For Electra, (MLM+NSP) pre-training over electra-base-discriminator
and MLM per-training over electra-base-generator were performed sepa-
rately. But the latter performed better so we utilized it for the research.
3. Fine-tuning Custom models and saving base model(Fine-tune-base):
The approach makes use of custom models shown in Section(4.1) to
ﬁne-tune LM’s on train data set(0.15 split) and save only ﬁne-tuned
base model without perceptron layers(Figure(2). This unprecedented
approach could show prospective results considering the weight opti-
mization due to the ﬁne-tuning of LMs to the task.
4. Pre-training LM’s as in approach 2 and then ﬁne-tuning as in approach
3(Pretrained-ﬁnetuned)
10
5.2. Embedding Generation
While sentence embeddings are generated from word embeddings the
study inspects 8 diﬀerent embedding generation modes and the best-performing
mode is later comprehended. Electra, Legal-BERT, and DeBERTa have 12
transformer layers and each word embedding is a 768-valued vector. The
ﬁrst value in the word vector set for any sentence is the ’cls’ token. The
8 embedding modes are shown in Table(3). The original authors of BERT,
Devlin et al. (2018) perform ablation studies on combinations of word em-
beddings which instigated our research. Further, To account for the diﬀerent
modes and variability, probing tests have been conducted to analyse BERT
layer semantic similarity, NER, etc(Wallat et al. (2023)).
Table 3: Diﬀerent modes for sentence embedding calculation
Mode Number
Explanation
Mode-1
Mean only 12th layer
Mode-2
Mean all 13 layers(12+embed)
Mode-3
Mean 9 to 12 layers
Mode-4
Mean 7 to 12 layers
Mode-5
Cls only 12th layer
Mode-6
Cls all 13 layers(12+embed)
Mode-7
Cls 9 to 12 layers
Mode-8
Cls 7 to 12 layers
5.3. Research Pipeline
The research pipeline is shown in Figure(2) The steps followed in the
pipeline are as follows:
• Step-1(Implementation of Methodology): First, the dataset was split
into testing and training with 0.15 split for testing.
The test and
train sets remain separated henceforth.
This is because Fine-tune-
base approach utilizes only a training set. Any dilution of data could
lead to inﬂation in results.
The ﬁrst three aforementioned method-
ologies(Baseline, Pretrained, Fine-tune-base) were formulated for each
transformer model, leading to nine combinations of output models
(Legal-BERT*3 methodologies, Electra*3 methodologies, and DeBERTa*3
methodologies). Added to this, Only Legal-BERT was processed with
Pretrained_ﬁnetuned owing to the reasoning presented in Section(7.2).
This led to the generation of 10 custom transformer models in total.
11
Figure 1: Step by step Research Framework
Figure 2: Fine-tune-base Methodology
• Step-2(Embedding generation): Next, sentence embeddings were cal-
culated for each TOS dataset entry. While sentence embeddings are
calculated from word embeddings, all eight modes were utilized. Hence,
12
each transformer approach variant resulted in 8 diﬀerent outputs. In
total, 80 embedding sets were generated(10 Transformer models times
eight embedding modes).
• Step-3(Grid search+SMOTE): There is a severe class imbalance in
the TOS dataset in all categories, as illustrated in Table(??). In order
to compensate, we utilize vanilla SMOTE (Synthetic Minority Over-
sampling Technique)Chawla et al. (2002) only on the training set. Grid
Search was performed for hyper-parameter tuning of ML classiﬁers over
all embedding sets generated in a 5-fold cross-validation fashion respec-
tively. SMOTE was applied in the grid search pipeline for the training
set alone. Finally, during testing the best ﬁt hyperparameters were
trained on training data after the application of SMOTE and tested on
a pristine test dataset.
6. EXPERIMENTS AND RESULTS
The study works on two tasks. The ﬁrst task is a classiﬁcation of each
statement into unfair or not based on Unfair Binary as shown in Table(??).
This problem checks for the existence of any clause in a statement but not
for a speciﬁc unfair tag.
The second task aims to categorize statements
into a speciﬁc unfair tag. Each statement could have multiple unfair tags
in diﬀerent categories.
Following the pipeline shown in Figure(2) steps 1
through 4 were followed. On initial testing with diﬀerent ML classiﬁers on
embeddings with baseline Legal-BERT embeddings using grid search, it was
found that SVC clearly performed signiﬁcantly better by a notable margin
as compared to the other models. Hence, for all analysis and testing, only
SVM(SVC) was used. Added to this, the performance of MLP was already
tested in Section(4.1).
SOTA results for unfair clause classiﬁcation(Binary) are shown in Ta-
ble(4). The metrics shown are macro testing averages for precision, recall,
and F-score. Further, we also show other notable results from the pipeline for
holistic discussion and comparison. A grid search was performed with 5-fold
cross-validation in all cases, and SMOTE was applied only to the training
data.
For best ﬁt, the kernel remained Radial Basis Function(rbf).
The
other hyperparameters are shown in Table(4). Further, the best-ﬁt Mode
for embedding is mentioned in ’[]’ where ’SS’ refers to the use of SVC after
Standard Scaler and ’S’ refers to Vanilla SVC in the Grid Search pipeline
respectively. The corresponding number is the Embedding Mode number.
13
Table 4: Macro testing metrics on Unfair Binary
Transformer model
Methodology
(c,gamma)[model]
P
R
F1
Legal-BERT
Baseline
(10,0.001) [SS-2]
0.891
0.836
0.86
ELECTRA
Baseline
(1,auto) [SS-7]
0.853
0.837
0.845
Legal-BERT
Pretrained
(10,0.1) [S-1]
0.872
0.875
0.874
Legal-BERT
Pretrained-Fine-tuned
(10,0.001) [S-4]
0.923
0.921
0.922
ELECTRA
Fine-tune-base
(1,0.001) [SS-8]
0.935
0.897
0.915
DeBERTa
Fine-tune-base
(100,0.01) [S-2]
0.923
0.908
0.915
Legal-BERT
Fine-tune-base
(1,0.001) [SS-4]
0.937
0.907
0.921
Lippi et al. (2019)
Ensemble
0.828
0.798
0.806
Guarino et al. (2021)
SVM+mUSE
0.86
0.86
0.87
Zheng et al. (2021)
Legal-BERT+Dense(softmax)
-
-
0.787
Mamakas et al. (2022)
LegalLongformer
-
-
0.806
6.0.1. Analysis and Discussion
The results surpass the current SOTA(State Of The Art), Guarino et al.
(2021) achieving macro F-1 at the binary unfair classiﬁcation of 0.92. Even
though Legal-BERT Pretrained-Fine-tuned and Fine-tune-base have compa-
rable results, we propose Legal-BERT-Fine-tune-base with SVC for the prob-
lem(shown in bold above).
The procedure is less elaborate and could be
implemented with lesser computational capabilities. Pre-training consumes
high GPU resources and has and performs worse asymptotically during the
training phase. The ﬁnal proposed design is illustrated in Figure(2).
6.1. Experiments on each Unfair Category
The following section shows the results for the second task mentioned.
However, in this case, we only consider the statements with at least one
unfair clause (essentially unfair Binary annotated 1 in Table(??)). Further,
each statement can have multiple unfair tags from diﬀerent categories. This
gives 1137 statements. On application of the design proposed above with
Legal-BERT-Fine-tune-base in conjunction with SVC standard scaler and
shown in 2, the results obtained are shown below.
All eight embedding
modes are tested with Legal-BERT-Fine-tune-base, and the best results are
shown. The study achieves SOTA results in all ﬁelds by a notable margin as
compared to Lippi et al. and Guarino et al. Micro(µ) and macro(m) averages
for F1-score are shown for comparison.
14
Table 5: Testing metrics based on each Unfair Clause/Category
Category
(c,gamma)
P
R
F1(m,µ)
Lippi(µF1)
Guarino(µF1)
Arbitration
(1,0.01)
1.0
1.0
1.0,1.0
0.823
0.89
Choice of law
(0.1,0.01)
1.0
1.0
1.0,1.0
0.93
0.97
Contract by using
(0.1,0.01)
0.989
0.929
0.956.0.98
0.953
0.86
Content removal
(0.1,0.001)
0.955
0.955
0.955,0.98
0.745
0.64
Jurisdiction
(0.1,0.01)
1.0
1.0
1.0,0.99
0.970
0.97
Limitation of liability
(0.1,0.01)
0.988
0.958
0.972,0.98
0.932
0.93
Unilateral change
(0.1,0.01)
0.94
0.894
0.914,0.94
0.823
0.86
Unilateral termination
(0.1,0.001)
0.938
0.938
0.938,0.96
0.853
0.86
7. COMPARITIVE ANALYSIS
As shown in the Research Framework5, numerous models and method-
ologies were utilized.
In this Section we perform comparative analysis to
answer two research questions. Although the results pertain to TOS data,
they could be generically applied to Binary text classiﬁcation problems and
further help the research community in perspective and design. Based on
the results generated at Unfair Binary Classiﬁcation, the following research
questions are answered:
RQ1: How does the performance of Transformer models ﬂuctuate based on
the methodology utilized?
RQ2: What is the extent of performance deviation among distinct
embedding modes concerning Transformer models? How does the same vary
depending on the methodology employed?
The Research questions are answered in the sections below with empirical
evidence based on the study.
7.1. RQ1
In order to reach a conclusion, the inﬂuence of each research methodology
is analyzed in relation to each respective transformer model.
Analysis based on Descriptive Statistics: After the pipeline resulted
in outputs for every combination, we ﬁrst cluster the results based on each
respective transformer model. Next, we provide the mean and max macro
F-1 score as shown in table6. In the case of each of these, the inﬂuence of
embedding mode was deliberately omitted for a more focused understanding
of the ablation regarding RQ1. Its to be noted that, Pretrained-Finetuned
15
methodology was only calculated for Legal-BERT, this was due to the poor
performance of other pre-trained transformer models as shown. The Descrip-
tive Statistics lead to the following observations:
1. Baseline Legal-BERT appears to be the most versatile baseline model
in light of its performance in varying conditions.
2. The performance of all models undergoing Fine-tune-base is very simi-
lar. Further, Legal-BERT performs slightly better at max statistics.
3. In the case of pretraining, Legal-BERT clearly outperforms other mod-
els with Electra showing deteriorated results in mean and max statis-
tics. DeBERTa and ELECTRA perform similarly at pretraining in Max
statistics. Nevertheless, the mean performance of Electra, attributed
to variations in embedding modes, shows a lower value compared to
DeBERTa.
Table 6: Mean and max macro F1 at Unfair Binary Classiﬁcation(model w.r.t methodol-
ogy)
Transformer
Baseline
Fin-tune-bse
Pre-tran
Pre-ﬁn-tune
Av.
Stat.
Legal-BERT
0.847
0.92
0.863
0.917
0.887
mean
Electra
0.827
0.912
0.777
-
0.839
mean
deBERTa
0.82
0.912
0.812
-
0.848
mean
Legal-BERT
0.86
0.921
0.874
0.922
0.894
max
Electra
0.845
0.915
0.817
-
0.859
max
deBERTa
0.825
0.915
0.818
-
0.853
max
Through this, we infer that although the performance of the transformer
models in the case of Fine-tune-base is comparable, the study suggests that
there is a notable diﬀerence in Pretraining and vanilla baseline performances.
The best performance is shown in Fine-tune-base.
7.2. RQ2
The impact of each embedding method in relation to each individual
transformer model and research methodlogy is examined independently in
this section.
Analysis based on Descriptive Statistics: To answer this research
question we ﬁrst cluster the results based on each respective Embedding
mode. We further show two variants in taking mean statistics, one takes mean
w.r.t transformer models and the latter takes mean w.r.t research methodol-
ogy. The descriptive statistics over mean macro F1-score are shown in table6
leading to the following observations:
16
Table 7: Mean macro F1 at Unfair Binary Classiﬁcation(Embedding Modes)
Mode
Legal-BERT
Electra
DeBERTa
Baseline
Fin-tune-bse
Pre-tran
1
0.889
0.822
0.844
0.832
0.914
0.8
2
0.888
0.85
0.846
0.83
0.913
0.832
3
0.884
0.844
0.852
0.832
0.915
0.821
4
0.885
0.838
0.85
0.831
0.915
0.816
5
0.889
0.82
0.844
0.829
0.914
0.8
6
0.888
0.85
0.845
0.83
0.912
0.832
7
0.884
0.845
0.852
0.834
0.915
0.821
8
0.887
0.84
0.85
0.832
0.916
0.818
1. There is little deviation in Legal-BERT performance in relation to em-
bedding modes. Similarly, comparable deviation is shown in DeBERTa
performance.
2. ELECTRA shows maximum ﬂuctuation with the best performance
shown in embed modes 2 and 6 respectively. Embedding modes 1 and
5 perform notably lower at 0.82 macro F1.
3. For the results combining all Baseline Models and Fine-tune-base mod-
els, there is minimal variation.
4. Finally, the mean Pretrained Model performance diﬀers notably with
Modes 2 and 6 performing the best. Modes 1,4 and 5 underperform
relatively.
Both modes 2 and 6 utilize mean embeddings of all layers and show better
performance in the case of pre-training. The reason for this could be that
holistic semantic information from all layers could be essential for text classi-
ﬁcation. The research by Jawahar et al. (2019) demonstrates that a complex
hierarchy of linguistic information is encoded in BERT’s intermediate layers,
with semantic attributes at the top, surface characteristics at the bottom,
and syntactic features in the middle layers.Kovaleva et al. (2019) validated a
similar view, proving that the intermediary layers of BERT capture meaning-
ful linguistic information. Zhong et al. (2023), expounds on Semantic drift
and Semantic loss that appears with BERT pre-training. Through this, we
deduce that in the case of pretraining transformer-based models, embedding
modes 2 and 6 perform relatively better. Both modes utilize a mean of all
layers. In the case of Fine-tune-base and Baseline models, the performance
seems to be similar.
17
8. CONCLUSION
End-users predominantly fail to comprehend the complete consequences
of terms they are consenting to owing to complexities in the language and
a paucity of legal expertise.
As a result, they frequently forgo reviewing
these components. This enables ﬁrms to use ambiguous, complex, and un-
just contractual provisions that restrict their own obligations or grant them
the ability to capriciously terminate services they provide at an instance.
Considering these complexities, we propose a Legal-BERT plus SVC-based
approach to achieving proﬁcient results at automated unfair clause detection.
Comparative analysis is also performed on the various transformer architec-
tures used. As future work to the study, we would aim to utilize other LLM
approaches and prompt engineering to analyze contractual terms in the B2B
market. These transactions between businesses and their contractual rela-
tions have been under light but with no signiﬁcant results.
9. APPENDIX
Descriptions of the Dataset utilized are shown below.
9.1. Availability of Code
The code and output performance metrics utilized in the study are avail-
able at Github on request.
References
Dogu Araci. 2019. Finbert: Financial sentiment analysis with pre-trained
language models. arXiv preprint arXiv:1908.10063 (2019).
Vinayshekhar Bannihatti Kumar, Roger Iyengar, Namita Nisal, Yuanyuan
Feng, Hana Habib, Peter Story, Sushain Cherivirala, Margaret Hagan, Lor-
rie Cranor, Shomir Wilson, et al. 2020. Finding a choice in a haystack:
Automatic extraction of opt-out statements from privacy policy text. In
Proceedings of The Web Conference 2020. 1943–1954.
Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip
Kegelmeyer. 2002. SMOTE: synthetic minority over-sampling technique.
Journal of artiﬁcial intelligence research 16 (2002), 321–357.
Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D Manning.
2020. Electra: Pre-training text encoders as discriminators rather than
generators. arXiv preprint arXiv:2003.10555 (2020).
18
Commerce. 2010. Commercial data privacy and innovation in the Internet
economy: A dynamic policy framework. Department of Commerce (2010).
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.
Bert: Pre-training of deep bidirectional transformers for language under-
standing. arXiv preprint arXiv:1810.04805 (2018).
Keishiro Fukushima, Toru Nakamura, Daisuke Ikeda, and Shinsaku Kiy-
omoto. 2018. Challenges in classifying privacy policies by machine learning
with word-based features. In proceedings of the 2nd international confer-
ence on cryptography, security and privacy. 62–66.
Alfonso Guarino, Nicola Lettieri, Delﬁna Malandrino, and Rocco Zaccagnino.
2021. A machine learning-based approach to identify unlawful practices in
online terms of service: analysis, implementation and evaluation. Neural
Computing and Applications 33 (2021), 17569–17587.
Hamza Harkous, Kassem Fawaz, Rémi Lebret, Florian Schaub, Kang G Shin,
and Karl Aberer. 2018. Polisis: Automated analysis and presentation of
privacy policies using deep learning. In 27th USENIX Security Symposium
(USENIX Security 18). 531–548.
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020. De-
berta: Decoding-enhanced bert with disentangled attention. arXiv preprint
arXiv:2006.03654 (2020).
Ganesh Jawahar, Benoît Sagot, and Djamé Seddah. 2019. What does BERT
learn about the structure of language?. In ACL 2019-57th Annual Meeting
of the Association for Computational Linguistics.
Olga Kovaleva, Alexey Romanov, Anna Rogers, and Anna Rumshisky. 2019.
Revealing the dark secrets of BERT.
arXiv preprint arXiv:1908.08593
(2019).
Marco Lippi, Przemysław Pałka, Giuseppe Contissa, Francesca Lagioia,
Hans-Wolfgang Micklitz,
Giovanni Sartor, and Paolo Torroni. 2019.
CLAUDETTE: an automated detector of potentially unfair clauses in on-
line terms of service. Artiﬁcial Intelligence and Law 27 (2019), 117–139.
19
Marco Loos and Joasia Luzak. 2016. Wanted: a bigger stick. On unfair terms
in consumer contracts with online service providers. Journal of consumer
policy 39 (2016), 63–90.
Dimitris Mamakas, Petros Tsotsi, Ion Androutsopoulos, and Ilias Chalkidis.
2022. Processing long legal documents with pre-trained transformers: Mod-
ding legalbert and longformer. arXiv preprint arXiv:2211.00974 (2022).
Cranor L McDonald A. 2008. The cost of reading privacy policies. A Journal
of Law and Policy for the Information Society (2008).
Mitchell. 1983. George Mitchell (Chesterhall) Ltd. v. Finney Lock Seeds Ltd.
3 WLR 163 (1983).
Pittalis. 1986. Pittalis v. Sherefettin. 1 QB 868 (1986).
Federico Ruggeri, Francesca Lagioia, Marco Lippi, and Paolo Torroni. 2022.
Detecting and explaining unfairness in consumer contracts through mem-
ory networks. Artiﬁcial Intelligence and Law 30, 1 (2022), 59–92.
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.
DistilBERT, a distilled version of BERT: smaller, faster, cheaper and
lighter. arXiv preprint arXiv:1910.01108 (2019).
Securicor. 1980. Photo Production Ltd. v. Securicor Transport Ltd. 2 WLR
283, pp. 288, 289 (1980).
Jonas Wallat, Fabian Beringer, Abhijit Anand, and Avishek Anand. 2023.
Probing BERT for ranking abilities. In European Conference on Informa-
tion Retrieval. Springer, 255–273.
Shanshan Xu, Irina Broda, Rashid Haddad, Marco Negrini, and Matthias
Grabmair. 2022. Attack on Unfair ToS Clause Detection: A Case Study
using Universal Adversarial Triggers.
arXiv preprint arXiv:2211.15556
(2022).
Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Con-
stant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan
Sung, et al. 2019. Multilingual universal sentence encoder for semantic
retrieval. arXiv preprint arXiv:1907.04307 (2019).
20
Lucia Zheng, Neel Guha, Brandon R Anderson, Peter Henderson, and
Daniel E Ho. 2021. When does pretraining help? assessing self-supervised
learning for law and the casehold dataset of 53,000+ legal holdings. In Pro-
ceedings of the eighteenth international conference on artiﬁcial intelligence
and law. 159–168.
Qihuang Zhong, Liang Ding, Juhua Liu, Xuebo Liu, Min Zhang, Bo Du, and
Dacheng Tao. 2023. Revisiting Token Dropping Strategy in Eﬃcient BERT
Pretraining. arXiv preprint arXiv:2305.15273 (2023).
21
","nanPrior studies in the literature have focused on evaluating online legal documents, such as privacy policies and terms of service, to protect citizens' rights. Efforts to detect unfair clauses in ToS documents have been limited. Notable works include the creation of a dataset with annotated unfair clauses, the use of ensemble classification methods for predictions, and the adaptation of a LegalBERT-warm-started Longformer for processing larger texts. Additionally, research has investigated configurations for memory-augmented neural networks and employed all-encompassing adversarial triggers to analyze unfair clause detection."
"A novel architecture called reconfigurable distributed antennas and reflecting surfaces (RDARS) is proposed to maintain the benefits of distributed antennas while reducing the hardware cost by replacing some active antennas with low-cost passive reflecting surfaces. The RDARS structure offers the potential to achieve selection gains by leveraging the additional degree of freedom (DoF) provided by the dynamically programmed modes for all elements. To improve the system transmission reliability, the total mean-square-error (MSE) of all data streams is minimized by jointly optimizing the receive beamforming matrix, the reflection phase shifts, and the channel-aware placement of elements in the connection mode.","As a revolutionary technology aimed at realizing green communication, reconfigurable intelligent surface (RIS) plays a pivotal role in the development of 6G. Unlike conventional technologies designed to enhance wireless communication, RIS exhibits remarkable capability to dynamically reshape the wireless propagation environment and explore new physical dimensions of transmission. By deploying a massive number of low-cost passive elements, RIS can adjust the phase of the incident signal to create favorable wireless channels, thereby improving communication performance.","To tackle the intractable binary and cardinality constraints, we first propose an inexact block coordinate descent (BCD)-based penalty dual decomposition (PDD) algorithm to alternatively optimize the beamforming vector and the mode selection matrix. Furthermore, in order to reduce the computational complexity, we approximate the original objective function and propose a low-complexity greedy-search-based alternating optimization (AO) algorithm, which yields a semi-closed-form solution with acceptable performance. Moreover, we present some insightful results in the special cases of the RDARS-aided single-user scenario.",The performance comparison between the RDARS and the conventional fully passive RIS or DAS systems is conducted through simulations. The results demonstrate the superiority of the proposed architecture.,"To our best knowledge, this paper presents the first investigation of a novel RDARS-aided system that incorporates distribution gains, reflection gains, and selection gains. We propose a RDARS-aided uplink multi-user communication system and explore the performance improvement in transmission reliability brought by the newly proposed architecture. In this paper, we aim to minimize the total mean-square-error (MSE) of all data streams by joint beamforming design and channel-aware placement of elements in the connection mode characterized by a binary selection matrix. Since the channel-aware placement involves binary variables and unit-modulus constraints, the MSE minimization becomes the mixed-integer program-ming problem, which is non-deterministic polynomial-time (NP)-hard and lacks efficient solutions.",Joint Beamforming Optimization and Mode Selection for RDARS-aided MIMO Systems,"Jintao Wang, Chengzhi Ma, Shiqi Gong, Xi Yang, Shaodan Ma","JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
1
Joint Beamforming Optimization and Mode
Selection for RDARS-aided MIMO Systems
Jintao Wang, Chengzhi Ma, Shiqi Gong, Xi Yang, Shaodan Ma, Senior Member, IEEE
Abstract—Reconfigurable
intelligent
surface
(RIS)
has
emerged as a cost-effective solution for green communications in
6G. However, its further extensive use has been greatly limited
due to its fully passive characteristics. Considering the appealing
distribution
gains
of
distributed
antenna
systems
(DAS),
a
flexible
reconfigurable
architecture
called
reconfigurable
distributed antenna and reflecting surface (RDARS) is proposed.
RDARS encompasses DAS and RIS as two special cases and
maintains the advantages of distributed antennas while reducing
the hardware cost by replacing some active antennas with
low-cost passive reflecting surfaces. In this paper, we present
a RDARS-aided uplink multi-user communication system and
investigate the system transmission reliability with the newly
proposed architecture. Specifically, in addition to the distribution
gain and the reflection gain provided by the connection and
reflection modes, respectively, we also consider the dynamic
mode switching of each element which introduces an additional
degree of freedom (DoF) and thus results in a selection gain.
As such, we aim to minimize the total sum mean-square-error
(MSE) of all data streams by jointly optimizing the receive
beamforming matrix, the reflection phase shifts and the channel-
aware placement of elements in the connection mode. To tackle
this nonconvex problem with intractable binary and cardinality
constraints, we propose an inexact block coordinate descent
(BCD) based penalty dual decomposition (PDD) algorithm with
the guaranteed convergence. Since the PDD algorithm usually
suffers from high computational complexity, a low-complexity
greedy-search-based alternating optimization (AO) algorithm is
developed to yield a semi-closed-form solution with acceptable
performance. Numerical results demonstrate the superiority of
the proposed architecture compared to the conventional fully
passive RIS or DAS. Furthermore, some insights about the
practical implementation of RDARS are provided.
Index Terms—RIS, HR-RIS, MSE Minimization, Mode Selec-
tion, RDARS, Greedy Search, PDD
I. INTRODUCTION
As a revolutionary technology aimed at realizing green
communication, reconfigurable intelligent surface (RIS) plays
a pivotal role in the development of 6G. Unlike conventional
technologies designed to enhance wireless communication,
RIS exhibits remarkable capability to dynamically reshape the
wireless propagation environment and explore new physical
J. Wang, C. Ma, and S. Ma are with the State Key Laboratory
of Internet of Things for Smart City and the Department of Electri-
cal and Computer Engineering, University of Macau, Macao SAR, China
(e-mails: wang.jintao@connect.um.edu.mo; yc074993@um.edu.mo; shao-
danma@um.edu.mo).
S. Gong is with the School of Cyberspace Science and Technology, Beijing
Institute of Technology, Beijing 100081, China (e-mail: gsqyx@163.com).
X. Yang is with the Shanghai Key Laboratory of Multidimensional
Information Processing, School of Communication and Electronic Engi-
neering, East China Normal University, Shanghai 200241, China (email:
xyang@cee.ecnu.edu.cn).
dimensions of transmission. By deploying a massive number
of low-cost passive elements, RIS can adjust the phase of the
incident signal to create favorable wireless channels, thereby
improving communication performance.
Due to its high potential for energy and spectrum efficiency,
numerous research works have been conducted to explore the
benefits of RIS-aided communication systems. These studies
have shown RIS has the ability to address a wide range of
challenges, such as improving coverage area, overcoming local
dead zones, enhancing edge user rates, eliminating co-channel
interference, and enabling high-precision positioning [1], [2].
For instance, the authors in [3] optimized RIS to enrich the
propagation environment by adding multi-paths and increasing
the rank of the channel matrix to support spatial multiplexing,
thus leading to substantial capacity gains. The authors in [4]
conducted a performance analysis of the coverage enhance-
ment for RIS under current commercial mobile networks in
various urban scenarios. The field trial results showed a signif-
icant improvement in the user experience, including extending
the coverage and improving the throughput. However, due to
the fully passive nature of RIS’s elements, its further extensive
use has been greatly limited. For example, unless a large
number of elements are deployed, the performance improve-
ment brought by RIS is limited due to the “multiplicative
fading” effect, particularly in the presence of a direct link.
Moreover, the signaling overhead for channel estimation and
the configuration overhead for passive beamforming increase
with the number of reflecting elements, thereby restricting its
implementation to some extent. Although some RIS variants,
e.g., active RIS [5], [6], semi-passive RIS [7]–[9] or hybrid
relay-reflecting intelligent surface (HR-RIS) [10], [11] have
been proposed to address some of the challenges above. The
incorporation of extra reflection-type power amplifiers (PAs)
or radio-frequency (RF) chains may fail to meet the ultra-low-
power requirements in 6G.
Another promising technology aimed at improving spectral
efficiency in 6G networks is distributed antenna system (DAS)
[12], [13]. DAS involves the deployment of a large number of
spatially distributed antennas or radio access points (RAPs) to
provide uniform services to users. Various DAS architectures
have been proposed, including cloud radio access network
(C-RAN), ultra-dense network (UDN), and cell-free massive
multiple-input multiple-output (CF-mMIMO) systems. For ex-
ample, CF-mMIMO, where a large number of distributed
access points are connected to a central processing unit and
serve all users within a network, has a high potential in im-
proving the network performance from different perspectives
by integrating emerging technologies such as non-orthogonal
arXiv:2401.11205v1  [cs.IT]  20 Jan 2024
2
JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
multiple access (NOMA) and unmanned aerial vehicle (UAV)
[14]. However, such dense deployment of a large number
of antennas or RAPs leads to significant hardware costs and
increased energy consumption.
Recently, a novel architecture called reconfigurable dis-
tributed antennas and reflecting surfaces (RDARS) has been
proposed to maintain the benefits of distributed antennas while
reducing the hardware cost by replacing some active antennas
with low-cost passive reflecting surfaces [15]. Specifically,
RDARS combines the flexibility of distributed antennas and
reconfigurability of passive reflecting surfaces, where each
element can be dynamically programmed to two modes: the
reflection mode and the connection mode. Elements in the
reflection mode function similarly to the conventional passive
RIS, while elements in the connection mode act as distributed
antennas to directly transmit/receive signals. The proposed
RDARS architecture inherits the low-cost advantage of the
conventional RIS while overcoming the multiplicative fading
effect. By utilizing the connection mode, RDARS achieves
additional distribution gains. Furthermore, elements in the
connection mode also facilitate channel estimation of the
RDARS-related channels and ease the RDARS configuration
with reduced overhead. The RDARS architecture demon-
strates significant superiority over conventional RIS and DAS,
as highlighted by the theoretical performance analysis and
experimental demonstrations [15]. Additionally, a RDARS-
aided integrated sensing and communication system (ISAC)
prototype was implemented in [16], showcasing the potential
of RDARS in future wireless systems.
There are several advantages when implementing RDARS.
Firstly, RDARS can be deployed by building upon existing
distributed antenna systems, such as C-RAN, UDN, and CF-
mMIMO systems. Such integration and reuse of the infrastruc-
ture significantly reduce the deployment costs and complex-
ities. From the perspective of RISs, they are interfaced with
the base station (BS) through a smart controller. The controller
intelligently adjusts the phase shifters of the RIS to optimize
wireless channels. Due to the fully passive characteristics, the
optimization process must be performed at the BS. Various
methods can be used for controlling RIS, including wired
connections, IP routing, wireless connections, or autonomous
sensing [17]. While wireless controls offer flexibility in the
deployment and power consumption, achieving high-accuracy
beamforming through wireless controls is still challenging.
Additionally, wireless controls require precise time synchro-
nization between the BS and RIS, which is difficult to im-
plement in practice. Moreover, mutual interference between
wireless access links and wireless controls can impact the over-
all network performance. On the other hand, the distributed
antennas are connected to a central unit through optical front-
hauls, including baseband-over-fiber (BBoF), intermediate-
frequency-over-fiber (IFoF), and analog radio-frequency-over-
fiber (RFoF) links [13]. The implementation and configuration
of RDARS can leverage the existing optical infrastructure,
thus enhancing the practicality of RDARS-aided systems. By
considering these practical aspects, the implementation of
RDARS becomes feasible and can be aligned with current
technological capabilities.
To the best of our knowledge, the potential of such appeal-
ing architecture has not been fully investigated. Due to the
channel randomness, the location of elements in the connection
mode also influences the system performance. The RDARS
structure offers the potential to achieve selection gains by
leveraging the additional degree of freedom (DoF) provided
by the dynamically programmed modes for all elements.
Therefore, considering the appealing structure of RDARS
with distribution, reflection and selection gains, we study the
RDARS-aided multi-user uplink system and investigate the
potential of RDARS on transmission reliability. In this paper,
we aim to minimize the total mean-square-error (MSE) of all
data streams by joint beamforming design and channel-aware
placement of elements in the connection mode characterized
by a binary selection matrix. Since the channel-aware place-
ment involves binary variables and unit-modulus constraints,
the MSE minimization becomes the mixed-integer program-
ming problem, which is non-deterministic polynomial-time
(NP)-hard and lacks efficient solutions. To tackle such a non-
convex combinatorial optimization problem, we propose an
inexact block coordinate descent (BCD)-based penalty dual
decomposition (PDD) algorithm to alternatively optimize the
beamforming and selection variables. Furthermore, a greedy-
search-based alternating optimization (AO) algorithm is pro-
posed to reduce the computational complexity with semi-
closed-form solutions. Moreover, we discover some insightful
results under special channel conditions. Simulation results
demonstrate the superiority of the proposed RDARS-aided
system compared to the conventional fully passive RIS-aided
and DAS systems.
The main contributions are summarized as follows:
• To our best knowledge, this paper presents the first inves-
tigation of a novel RDARS-aided system that incorporates
distribution gains, reflection gains, and selection gains.
We propose a RDARS-aided uplink multi-user communi-
cation system and explore the performance improvement
in transmission reliability brought by the newly proposed
architecture.
• We consider the flexible and programmable configu-
ration of the RDARS’s elements, where each element
can be dynamically switched between the connection
and reflection modes as needed. The additional DoF for
dynamic mode switching is investigated to enhance the
system performance. To improve the system transmission
reliability, the total MSE of all data streams is minimized
by jointly optimizing the receive beamforming matrix, the
reflection phase shifts, and the channel-aware placement
of elements in the connection mode.
• To tackle the intractable binary and cardinality con-
straints, we first propose an inexact BCD-based PDD al-
gorithm to alternatively optimize the beamforming vector
and the mode selection matrix. Furthermore, in order to
reduce the computational complexity, we approximate the
original objective function and propose a low-complexity
greedy-search-based AO algorithm, which yields a semi-
closed-form solution with acceptable performance. More-
over, we present some insightful results in the special
WANG et al.: JOINT BEAMFORMING OPTIMIZATION AND MODE SELECTION FOR RDARS-AIDED MIMO SYSTEMS
3
Fiber
Phase 
Shifter
BS 
RF Port
SW Network
Connection Mode
Reflection Mode
Connection Mode
Reflection Mode
...
...
...
N
a
N-a
Fiber
Phase 
Shifter
BS 
RF Port
SW Network
Connection Mode
Reflection Mode
...
...
...
N
a
N-a
Fig. 1. Illustration of the dynamic mode switching of RDARS.
cases of the RDARS-aided single-user scenario.
• The performance comparison between the RDARS and
the conventional fully passive RIS or DAS systems is
conducted through simulations. The results demonstrate
the superiority of the proposed architecture. It also shows
the necessity of optimizing the location of elements in the
connection mode according to the channel conditions. We
further analyze the impact of the number of elements in
the connection mode, thereby offering valuable insights
for the practical implementation of RDARS.
The remainder of this paper is organized as follows. Section
II introduces the RDARS’s architecture, system model, and
problem formulation. The proposed inexact BCD-based PDD
algorithm is presented in Section III. Section IV provides a
low-complexity AO algorithm. Numerical results are shown
in Section V. Finally, Section VI concludes this paper.
Notation: Through this paper, scalars, vectors, and matrices
are denoted by lowercase, bold-face lowercase, and bold-
face uppercase letters, respectively. The notation Cn denotes
the n-dimensional space of the complex number. (·)T and
(·)H represent the transpose and conjugate transpose of a
complex-valued vector or matrix, respectively. IN denotes
the identity matrix of size N × N. The expectation opera-
tor is denoted by E[·]. diag(a) indicates a square diagonal
matrix whose diagonal elements consist of a vector a, and
diag(A) returns a vector consisting of the diagonal elements
of matrix A. g
diag(A) represents a square diagonal matrix
whose diagonal elements are the same as those of matrix A.
B = blkdiag(A1, ..., AN) returns the block diagonal matrix
created by aligning the input matrices A1,...,AN along the
diagonal of B. |a| and ∠a refer to the modulus and phase of
a complex input a, respectively. ||a||0 denotes the zero norm
of vector a. CN(0, A) means the distribution of a circularly
symmetric complex Gaussian (CSCG) random vector with
zero mean vector and covariance matrix A and ∼ denotes
“distributed as”. ℜ{·} returns the real part of the complex
input.
II. SYSTEM MODEL AND PROBLEM FORMULATION
A. RDARS Architecture
A RDARS composed of N elements is employed, with a
elements connected to the BS and operating in the “connection
mode”, while the remaining N−a passive elements operate in
the “reflection mode” to reflect the incident signal to favorable
Base Station
User 1
RDARS
Reflection Mode
Connection Mode
User m
User M
Fiber
rh ,1
,r m
h
,r M
h
,
d M
h
,
d m
h
,1
dh
SW Network
SW Network
···
···
H
G
Fig. 2. A RDARS-aided uplink MIMO communication system.
directions. Since each element can be dynamically switched
between the connection and reflection modes, it offers an
extra DoF to achieve selection gains. Such transformation can
be realized via a switching network (SW) as illustrated in
Fig. 1. Flexible configurations are available for the number
and locations of elements in the connection mode. In this
paper, we assume the number of connected elements, i.e., a,
is predefined.
In comparison to the traditional fully passive RIS, the
RDARS architecture inherits low-cost advantages from ele-
ments in the reflection mode. On the other hand, it overcomes
the multiplicative fading effect from those in the connection
mode. Since a small number of elements in the connection
mode can lead to a substantial performance improvement, we
assume the number of connected elements is much smaller
than the total number of elements on RDARS, i.e., a << N.
Denoted by A the index set of the connected components,
the mode selection matrix can be represented by the diagonal
matrix A ∈ CN×N, whose diagonal value equal to 1 for the
connection mode and 0 for the reflection mode. The reflection
coefficients of all elements operating in the reflection mode
can be denoted as θ ∈ CN×1 with Φ ≜ diag(θ), while (I−
A)θ stands for the realistic phase shifts of elements in the
reflection mode.
B. System Model
As shown in Fig. 2, a RDARS-aided uplink multi-user
communication system with M single-antenna users and a
BS equipped with Nr antennas is considered. Considering
the quasi-static far-field channel environment, the channel
from M users to the BS and RDARS can be denoted as
Hd ∈ CNr×M and Hr ∈CN×M, respectively, where Hd =

hd,1 hd,2 . . . hd,M

and Hr
=

hr,1 hr,2 . . . hr,M

. In
addition, the channel between the BS and the RDARS is rep-
resented as G ∈ CN×Nr. All channel state information (CSI)
is assumed to be known perfectly to explore the performance
limit1. Denoted by s the transmitted symbols from M users
1Since the elements on RDARS can be dynamically programmed to the
connection mode, the channel related to the connected elements can be easily
estimated via the pilot training. Recalling the channel estimation methods
in asymmetrical uplink and downlink massive MIMO systems [18], the full-
dimensional CSI related to the RDARS can be efficiently recovered.
4
JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
MSE =E[(ˆs − s)(ˆs − s)H] = Wb(HbPPHHH
b +σ2
bINr)WH
b −WbHbP−PHHH
b WH
b +IM
|
{z
}
ERIS
(2)
+ Wc(HcPPHHH
c +σ2
cIa)WH
c −WcHcP − PHHH
c WH
c +IM
|
{z
}
EDAS
+ WbHbPPHHH
c WH
c + WcHcPPHHH
b WH
b −IM
|
{z
}
Ecross
,
with E[ssH] = I, the uplink received signal y ∈ C(Nr+a)×1
at the BS can be divided into two parts, i.e., yb ∈ CNr×1 and
yc ∈ Ca×1, defined as follows2

yb
yc

|{z}
y
=

Hd+GH(I−A)ΦHr
AaHr

|
{z
}
H
Ps +

nb
nc

| {z }
n
,
(1)
where yb and yc represent the signals received by the
BS’s antennas and the RDARS’s elements operating in the
connection mode, respectively. The effective channel H is
composed of two parts, i.e., Hb and Hc. First, Hb represents
the effective channel between users and the BS assisted with
the RDARS’s elements in the reflection mode, similar to
that of the conventional RIS-aided system, defined as Hb =
Hd + GH(I−A)ΦHr. On the other hand, Hc denotes the
effective channel between the users and the elements working
in the connection mode, i.e., Hc = AaHr, where Aa ∈ Ca×N
stands for the channel index matrix of those components
connected to the BS. Specifically, Aa is a submatrix of A
consisting of non-zero rows of the mode selection matrix
A. Here, P denotes the transmit power matrix for M users,
i.e., P = diag([√p1, √p2, . . . , √pM]), with pm representing
the transmit power for the m-th user. nb and nc repre-
sent the additive white Gaussian noise (AWGN) obeying the
CSCG distributions with zero mean and covariance matrices
Λb = σ2
bINr and Λc = σ2
cIa, i.e., nb ∼ CN(0, σ2
bINr) and
nc ∼ CN(0, σ2
cIa), respectively. Λ = blkdiag(Λb, Λc) is the
covariance matrix of the effective noise vector n.
At the BS side, the receive beamforming matrix W ∈
CM×(Nr+a) is applied to estimate the data symbol vector
ˆs = Wy. The resultant MSE of individual data streams of
all users can be denoted as diagonal elements of the average
MSE matrix derived in (2) at the top of this page, where
Wb ∈ CM×Nr and Wc ∈ CM×a denote the linear equalizers
related to the received signals yb and yc, respectively.
As seen from the MSE expression, the average MSE is
divided into three sections, i.e., ERIS, EDAS and Ecross. Obvi-
ously, ERIS represents the MSE of all data streams induced by
N−a passive elements in the reflection mode. EDAS stands for
the MSE generated by an a-element distributed antenna array.
As for the last term Ecross, it can be regarded as the mutual
impact brought by the combination of RIS and distributed
antennas at the RDARS-aided system. In particular, the system
reduces to the conventional fully passive RIS-aided system
with N reflecting elements when a equals zero, or A = 0.
On the other hand, it becomes identical to the DAS system
with N + Nr distributed antennas when all of the RDARS
elements are connected to the BS.
2We assume the ideal inter-element isolation of the practical arrays on
RDARS, where the received signal originating from the remaining elements
in the reflection and connection modes can be ignored [5], [19].
C. Problem Formulation
The average sum MSE minimization problem for the
RDARS-aided MIMO system can be formulated as
(P1) :
min
A,W,Φ f A,W,Φ
MSE
= Tr(MSE)
(3a)
s.t.
|Φ|n,n = 1, ∀n ∈ N,
(3b)
[A]n,n ∈ {0, 1}, ∀n ∈ N,
(3c)
[A]i,j = 0, ∀i, j ∈ N, i ̸= j,
(3d)
||diag(A)||0 = a.
(3e)
where (3b) denotes the unit-modulus constraints for the passive
reflection coefficients at the RADAS, and (3c)(3d) imply the
mode selection matrix A is diagonal and has diagonal value
of 0 or 1, indicating whether the RDARS element is connected
to the BS. The cardinality constraint (3e) limits the number
of elements in the connection mode to a. Unfortunately, prob-
lem (P1) is essentially a mixed-integer optimization problem,
which is intractable and NP-hard. Due to the cardinality
and binary constraints, problem (P1) is more challenging
than the conventional fully passive RIS-aided system design.
To the best of our knowledge, there have been very few
studies considering dynamically configuring the RIS elements
to be active or not. Additionally, existing algorithms are also
inapplicable to our works. In the following section, we propose
two different algorithms to overcome the challenges arising
from unit-modulus, binary, and cardinality constraints.
III. PROPOSED INEXACT BCD-PDD ALGORITHM
In this section, we propose an efficient inexact BCD-based
PDD algorithm to solve the non-convex optimization problem
(P1) with the guaranteed convergence.
By taking the first derivative w.r.t W to 0, the optimal
receive beamforming matrix W⋆ can be obtained as
W⋆ = PHHH WANG et al.: JOINT BEAMFORMING OPTIMIZATION AND MODE SELECTION FOR RDARS-AIDED MIMO SYSTEMS
5
The constraints are generally intractable. Moreover, the ob-
jective function in problem (P2) encompasses the matrix
inversion of a matrix-valued quadratic function, which renders
the problem intractable and NP-hard with regard to the binary
matrix variable A. Even when the RDARS’s phase shifts
are fixed, the subproblem of the mode selection remains a
challenging combinatorial optimization problem. While the
exhaustive search method can provide the globally optimal
solution, its computational complexity grows exponentially
with the number of RDRAS elements. Consequently, the
exhaustive search method becomes infeasible for the large-
scale RDARS-aided systems.
In the sequel, we begin by providing an equivalent trans-
formation and introducing an auxiliary variable ¯A to enhance
the tractability of the problem. Then, a PDD-based iterative
algorithm is proposed to address such issues, where the inner
iteration updates the primal variables by inexactly solving
its corresponding augmented Lagrangian (AL) problem via
the BCD method, while the outer iteration updates the dual
variables and the penalty parameter.
A.
Equivalent Transformation
Binary optimization problems are known to be generally
NP-hard, posing significant challenges in finding optimal
solutions. One common approach to tackle the binary opti-
mization problem is to relax the binary constraints and treat the
problem as a continuous optimization one, and then project the
continuous solution onto the nearest integer values. However,
such relaxation technique often results in a notable loss of
performance. Another type of binary optimization method that
yields optimal solutions is the branch-and-bound (BB) method.
However, the worst-case computational complexity of the
BB method increases exponentially, similar to the exhaustive
search method. As the number of RDARS’s elements grows,
the computational time required to find the optimal solution
may become prohibitively high.
To balance the complexity and optimality, we propose a
variational reformulation of the binary constraints. The con-
straints can be equivalently transformed into the l2 box non-
separable constraints based on the following lemma.
Lemma 1. Assume x ∈ RN, v ∈ RN and define χ ≜
{(x, v)|0 ≤ x ≤ 1, ||2v − 1||2
2 ≤ N, ⟨2x−1, 2v−1⟩ =
N, ∀v}. Assume that x, v ∈ χ, then we have x ∈ {0, 1}N,
and x = v.
Proof. See [20] for detailed proof.
Based on Lemma 1, we have the following proposition with
regard to problem (P2).
Proposition 1. Define x = diag(A), v = diag(¯A) and
θ = diag(Φ), problem (P2) is then equivalent to the following
problem: (P3) :
min
0≤x≤1,v,θ f x,v,θ
MSE
(9a)
s.t.
||2v − 1||2
2 ≤ N,
(9b)
(2x−1)T (2v−1) = N,
(9c)
xT 1 = a
(9d)
|θ|n = 1, ∀n.
(9e)
where f x,v,θ
MSE
= Tr

(IM +σ−2
b Rb(A, Φ)+σ−2
c
¯Rc(¯A))−1	
and ¯Rc(¯A) is obtained by replacing ¯A with A in (7).
Proof. By virtue of Lemma 1, we can establish the equivalence
between problem (P2) and problem (P3).
From Proposition 1, the intractable binary constraints have
been rewritten in a tractable form by introducing an extra
variable. Unfortunately, problem (P3) is still difficult to solve
due to the non-separable objective function and the equality
constraints. In the following, we propose an efficient PDD
method to address the aforementioned challenges.
We first convert problem (P3) into its AL form by adding the
equality constraints as a penalty term to the objective function,
given by
(P4) :
min
0≤x≤1,||2v−1||2
2≤N,|θ|n=1,∀n L(θ, x, v, λ, ν),
(10)
where the augmented Lagrange function L(θ, x, v, λ, ν) are
defined as
L(θ, x, v, λ, ν) = f x,v,θ
MSE +ν
6
JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
D = HrP
WANG et al.: JOINT BEAMFORMING OPTIMIZATION AND MODE SELECTION FOR RDARS-AIDED MIMO SYSTEMS
7
Ξ =
8
JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
h2
r,c1 ≥ . . . ≥ h2
r,cN . The reflection coefficients are optimally
solved by θ⋆ = ej(∠hd−∠hr+∠g), where g denotes the reduced
channel G in the SISO case.
Proof. See Appendix A for the detailed proof.
2) LoS case: Assuming the BS and the RDARS are prop-
erly deployed, the deterministic LoS links exist in the RDARS-
related channels. Then, we conclude the following proposition.
Proposition 3. Assume the LoS BS-RDARS channel G =
κgagraH
gt and the LoS RDARS-user channel hr = κrar,
then the selection matrix A can be chosen arbitrarily. The
reflection coefficients can be optimally solved with θ⋆ =
ej(∠˜ar−∠hH
d at)., where ˜ar = κgaH
gr(I−A)diag(hr).
Proof. See Appendix B for the detailed proof.
Proposition 3 indicates the optimal mode selection is sig-
nificant to fully unleash the potential of the RDARS unless
both BS-RADRS and RDARS-user channels are LoS channels.
In other words, an optimized selection strategy is necessary
to enhance the performance of the RDARS-aided system in
fading channels. A similar conclusion can be derived for
the multi-user case under LoS channels, though the proof is
omitted here for simplicity.
Algorithm 1: Inexact BCD-based PDD Algorithm
Input : System parameters M, Nr, N, a, the threshold
ϵ, etc.
Output: A⋆, W⋆ and RIS phase shifts Φ⋆.
1 Initialize (θ0, x0, v0), and set the initial λ, ν, ρ.
2 repeat
3
update θ via (21),
4
update x by solving (24) via CVX solver,
5
update v by solving (30) via CVX solver,
6
if h < ϵ
7
update λ via (33) and ν via (34)
8
else
9
update ρ via (35)
10
end
11
k = k + 1
12 until RBP termination criterion is met;
13 Return W⋆ in (4), Φ⋆ = diag(θ), A⋆ = diag(x).
IV. LOW-COMPLEXITY AO ALGORITHM
Since the BCD iterations in the PDD algorithm involve the
numerical calculation of the CVX solver, the computational
complexity is unaffordable as the number of RDARS’s ele-
ments increases. In the following, we first approximate the
objective function and subsequently present a greedy-search-
based AO algorithm, significantly reducing the computational
complexity while yielding a near-optimal solution.
A. Mode Selection Optimization
Referring to (5), the mode selection matrix A has a crucial
impact on the effective channel related to the elements in the
reflection mode between the BS and users, i.e., Hb, as well
as the effective channel related to the elements in the connec-
tion mode, Hc. Rewriting Hb as Hb = H′
b − GHAΦHr,
where H′
b = Hd + GHΦHr, it is reasonable to ignore
the term GHAΦHr and approximate Hb as H′
b due to the
multiplicative fading effect and the small number of elements
in the connection mode. Here, H′
b represents the effective
channel of the RDARS where whole elements work in the
reflection mode. Based on the aforementioned approximation,
the objective function f A,Φ
MSE can be approximated as f app
MSE,
given by:
f app
MSE = Tr

(IM + ¯Rb(Φ)+σ−2
c Rc(A))−1	
,
(37)
where ¯Rb(Φ) = PHH
′H
b Λ−1
B H
′
Due to Rc(A) = PHHH bP.
r AHrP, the mode selection
optimization problem turns into selecting a sub-channel matrix
of size a × M leading to the lowest value of f app
MSE from
the entire channel between users and the RDARS, i.e., Hr.
Let Hr,x represent the submatrix of x rows chosen from
Hr after x selections and f app
MSE,x denotes the approximated
MSE value at x-th selection, x
=
1, 2, ..., a. We have
f app
MSE,x = Tr

(IM + ¯Rb(Φ)+σ−2
c PHHH
r,xHr,xP)−1	
. Spe-
cially, f app
MSE,0 = Tr
nWANG et al.: JOINT BEAMFORMING OPTIMIZATION AND MODE SELECTION FOR RDARS-AIDED MIMO SYSTEMS
9
B. Beamforming Design
With the fixed mode selection matrix A, the phase coeffi-
cients optimization problem becomes
(P9) : min
Φ
f app
MSE
s.t.(3b).
(41)
Noting the problem (P9) has the same structure as the θ-
subproblem in Section III.B, the proposed MM technique for
solving θ-subproblem can be applied to address the problem
(P9) with semi-closed-form solutions. Due to length limita-
tions, we omit this procedure for simplicity.
The procedure for the proposed low-complexity AO algo-
rithm is meticulously outlined in Algorithm 2. The computa-
tional complexity of the greedy-search-based mode selection
is estimated to be O(aNM 3) [28]. On the other hand, the
MM-based beamforming optimization incurs a complexity
of O(N 2M + N 3
r ). Consequently, the aggregate complexity
of Algorithm 2 can be approximated as O(IAO(aNM 3 +
N 2M + N 3
r )), with IAO denoting the number of itera-
tions. The complexity of the greedy search-based AO al-
gorithm is substantially lower than the inexact BCD-based
PDD algorithm, as observed from the complexity analysis.
In conclusion, Algorithm 2 offers a computationally efficient
solution to tackle the intractable optimization problem. Such
integration of the greedy-search-based mode selection and the
MM-based beamforming optimization achieves an acceptable
performance while upholding a manageable computational
complexity.
Algorithm 2: Low-Complexity AO Algorithm
Input : System parameters M, Nr, N, a, the threshold
ϵ, etc.
Output: A⋆, W⋆ and RIS phase shifts Φ⋆.
1 Set the initial point (A0, W0, Φ0).
2 repeat
3
update M−1
0 , N = {1, 2, ..., N},
4
repeat
5
update Jx in (39),
6
update N = N − {Jx},
7
for j ∈ N
8
update ∆j,x+1 via (40),
9
end
10
until x = 1 : a;
11
update Ak = {1, 2, ..., N} − N,
12
update θk by solving problem (P9),
13 until |f app
MSE(Ak, θk) − f app
MSE(Ak−1, θk−1)| ≤ ϵ;
14 Return W⋆ in (4), Φ⋆ = diag(θk), A⋆ = Ak.
V. SIMULATIONS
In this section, we provide numerical simulations to evaluate
the performance of all proposed algorithms for the RDARS-
aided communication system. Unless otherwise stated, we set
the basic system parameters as follows: Nr = 4, M = 4,
N = 256. Under a three-dimensional deployment setup as
shown in Fig. 3, the coordinate of the BS is set as (0, 100, 5)m
and the users are randomly distributed in a circle with a radius
of 10m and a center of (0, 0, 1.5)m. The location of RDARS
are (0, 50, 15)m and (0, 100, 15)m, respectively. The path loss
model at 3GPP [29] is considered, i.e., PL(d)=β0Ψa(d)−αp,
where d and αp respectively denote the propagation distance
and the path loss exponent. β0 stands for the path loss at the
reference distance 1m and Ψa denotes the random shadowing
impact subject to the Gaussian distribution with zero mean and
a standard derivation of σ. We assume β0 =−30dB and Ψa ∼
N(0, σ2) with σ = 5.8dB in this simulation. In particular,
we set αRB
p
= 2.2, αUR
p
= 2.2 and αUB
p
= 3.5 for the BS-
RDRAS channel HRB, the RDRAS-user channels HUR and
BS-user channels HUB, respectively.
As for the small-scale fading, we assume the Rician fading
channels, modeled as
H = √κtHLoS +
√
1 − κtHNLoS,
(42)
where HLoS and HNLoS represent the deterministic LoS
and non-LoS (NLoS) components, respectively. The NLoS
component HNLoS is assumed to be Rayleigh fading, where
each entry of HNLoS subjects to the CSCG distribution
with CN(0, 1). The deterministic LoS component is deter-
mined by the antenna array response vectors, i.e., hLoS
UB,m =
aB(ψUB,m), GLoS = aR(ψA, ϑA)aB(ψRB)H and hLoS
UR,m =
aR(ψD,m, ϑD,m), where aB and aR denote the array response
vectors at the BS and the RDARS, respectively. ψUB,m and
ψRB are the angles of departure (AoDs) at the BS towards
the m-th user and the RDARS, respectively. Furthermore, ψA
and ϑA denote the azimuth and elevation angles of arrival
(AoAs) at the RDARS, respectively, whereas ψD and ϑD
stand for the AoDs. κt in (42) represents the normalized
Rician factor belonging to [0, 1]. With κt increasing from 0
to 1, the channel H at Rayleigh fading becomes the LoS
channel. Specifically, we assume the channel between users
and the BS Hd is assumed to be Rayleigh fading, while
the RDARS-related channels Hr and G obey Rician fading
with Rician factor κt being 0.75 in this simulation unless
otherwise stated. The noise powers σ2
b and σ2
c are given by
σ2
b = σ2
c = σ2 = −90dBm. The average normalized MSE
(ANMSE) denoted by ANMSE ≜ Tr(MSE)/M is adopted
as the performance metric. All simulation results are obtained
by averaging over 300 channel realizations.
For the purpose of comparison, the following schemes
are utilized in the simulation: 1) Passive RIS: This scheme
represents the conventional fully passive RIS, serving as the
benchmark. The number of passive elements in the RIS is the
same as that in the RDARS system. 2) DAS: Similar to the
passive RIS, the DAS system is employed as a comparative
scheme, where the number of distributed antennas matches
the number of connected elements in the RDARS system. 3)
Random Index: In this scheme, the indices of elements in
the connection mode on RDARS are randomly selected, with
optimized phase coefficients assigned to the passive elements.
4) Fixed Index: Similarly, in the “Fixed Index” scheme, the
first a elements are designated in the connection mode. 5) GS-
AO: The “GS-AO” method refers to the proposed algorithm
outlined in Section IV, which alternately optimizes the mode
selection matrix using the greedy search approach and the
phase coefficients using the MM technique. 6) IBCD-PDD:
10
JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
10m
x
y
z
Users
(0m,0m,1.5m)
(0m,100m,5m)
BS
(0m,100m,15m)
RDARS
(b) Topology 2
10m
x
y
z
Users
(0m,0m,1.5m)
(0m,100m,5m)
BS
(0m,50m,15m)
RDARS
10m
x
y
z
Users
(0m,0m,1.5m)
(0m,100m,5m)
BS
(0m,50m,15m)
RDARS
(a) Topology 1
Fig. 3. Three-dimensional coordinates of the system deployment for simula-
tions.
The proposed inexact BCD-based PDD algorithm is referred
to as “IBCD-PDD”.
A. Convergence.
The convergence behaviors of the proposed PDD algorithm
under various initialization schemes are depicted in Fig. 4. The
initial mode selection index is chosen as the “Random Index”
in initialization 1 and the “Fixed Index” in initialization 2.
Both initialization schemes adopt random phase coefficients.
Fig. 4 (a) illustrates the constraints violation during the PDD
iteration. As the number of iterations increases, the penalty
is adaptively adjusted to gradually force the constraint viola-
tion to approach the predefined accuracy. Regardless of the
initial conditions or parameter settings, the PDD algorithm
consistently guarantees feasibility. From Fig. 4 (b), the PDD
algorithm exhibits monotonically convergent behavior, with
the ANMSE value converging towards a maximum value. This
can be attributed to the relatively small initial penalty. Thus,
the solution obtained in the first few iterations fails to satisfy
the equality constraints, ultimately leading to the incremental
behavior. Different initialization schemes can significantly
influence the effectiveness of convergence, as an appropriate
initial point plays a pivotal role in achieving optimal outcomes.
B. ANMSE vs P.
Fig. 5 shows the ANMSE performance of all considered
schemes as a function of the transmit power. The RDARS-
aided MIMO system is equipped with a total of 256 elements
on RDARS, and either 2 or 4 elements operating in the connec-
tion mode. Firstly, it is evident that both the “Random Index”
and “Fixed Index” schemes outperform the DAS or the passive
RIS-aided systems. This observation underscores the inherent
advantages of the RDARS’s structure, even without the mode
selection optimization. Interestingly, the “Random Index” and
0
10
20
30
40
50
Number of iterations
10-10
10-8
10-6
10-4
10-2
100
102
Constraint Vialation
a=2,  Initialization 1
a=2,  Initialization 2
a=4,  Initialization 2
a=4,  Initialization 1
(a) a
0
10
20
30
40
50
Number of iterations
10-4
10-3
10-2
10-1
ANMSE
a=2,  Initialization 1
a=2,  Initialization 2
a=4,  Initialization 1
a=4,  Initialization 2
(b) b
Fig. 4. Convergence behaviors of the PDD algorithm under different initial-
ization schemes.
-5
0
5
10
15
20
25
Transmit power (dBm)
10-5
10-4
10-3
10-2
10-1
100
ANMSE
Passive RIS
Random Index
Fixed Index
DAS
GS-AO
IBCD-PDD
a=2
a=4
Fig. 5. ANMSE vs the transmit power for different algorithm comparisons
with a = 2 or a = 4 when N = 256.
“Fixed Index” schemes exhibit similar performance, which
aligns with previous findings in RIS-aided systems employing
random and identity phase coefficients [30]. Although individ-
ual channel realizations may yield varying performance for the
random index scheme as compared to the fixed index scheme,
such performance fluctuations tend to cancel out in Monte
Carlo simulations, resulting in similar overall performance.
These performance improvements can be attributed to the
additional but non-optimized connected links on RDARS. Fur-
thermore, the proposed “IBCD-PDD” algorithm is observed to
have the best ANMSE performance, demonstrating its effec-
tiveness. Notably, the performance gain of the “IBCD-PDD”
scheme exhibits substantial growth when the number of con-
nected elements increases from 2 to 4. Additionally, the “GS-
AO” algorithm shows promise in approaching a high-quality
sub-optimal solution with low complexity. The performance
gap between the proposed “IBCD-PDD” algorithm and the
“Random Index/Fixed Index” scheme highlights the selection
gain originating from the mode selection optimization. This
gap becomes more significant as the number of connected
elements increases, emphasizing the importance of leveraging
the additional DoF offered by the channel-aware placement of
elements in the connection mode.
WANG et al.: JOINT BEAMFORMING OPTIMIZATION AND MODE SELECTION FOR RDARS-AIDED MIMO SYSTEMS
11
32
64
96
128
160
192
224
256
The number of RDARS‘s elements
10-2
10-1
100
ANMSE
Passive RIS
Random Index
GS-Rand
GS-AO
Fixed Index
a=4
a=2
Fig. 6. ANMSE vs the number of RDARS’s elements for different algorithm
comparisons when a = 2 and a = 4.
C. ANMSE vs N.
The relationship between the ANMSE performance and
the number of RDARS elements for a = 2/4 under dif-
ferent algorithm setups is illustrated in Fig. 6. The “GS-
Rand” scheme represents a greedy search-based mode selec-
tion scheme without phase optimization. Firstly, it is worth
noting that all RDARS schemes outperform the conventional
RIS-aided systems, even with a small number of elements
in the connection mode. This superiority is further enhanced
as the value of a increases from 2 to 4. Furthermore, the
performance gap between the “GS-AO” and the “GS-Rand”
schemes represents the reflection gain achieved through phase
optimization of the passive elements on RDARS. This gap
becomes more prominent as the number of RDARS elements
increases when a = 2. However, when a = 4, this gap
remains relatively stable due to the gradual dominance of
the distribution gain over the reflection gain. In addition,
both the “Random Index” and the “Fixed Index” schemes
outperform the “GS-Rand” scheme when a = 2, since the
reflection gain takes precedence over the distribution gain
and selection gain. However, as the value of a increases to
4, the distribution gain and selection gain start to outweigh
the reflection gain. Finally, the proposed “GS-AO” algorithm
achieves the best performance by effectively integrating the
distribution gain, reflection gain and selection gain in both
cases. In summary, these findings underscore the advantages
of RDARS systems and emphasize the significance of striking
a balance between the distribution gain and reflection gain for
optimal performance.
D. ANMSE vs a.
To further harness the distribution gain in the RDARS, we
investigate the ANMSE performance versus the number of
elements in the connection mode for different algorithms with
N = 256, as depicted in Fig. 7. When a is set as 0, the
RDARS-aided systems reduce to the conventional RIS-aided
systems, with “DAS” being equivalent to the traditional MIMO
system. In this scenario, all schemes, including “Passive
RIS/GS-AO/Fixed Index/Random Index/IBCD-PDD”, outper-
form the “GS-Rand” scheme due to the optimization of
phase coefficients. “GS-Rand” performs better than “DAS”
because of the reflection elements. As a increases, the “Passive
0
1
2
3
4
5
6
The number of connected elements
10-3
10-2
10-1
100
ANMSE
Passive RIS
Random Index
Fixed Index
DAS
GS-Rand
GS-AO
IBCD-PDD
Fig. 7. ANMSE vs the number of connected elements for different algorithm
comparisons when N = 256.
0
2
4
6
8
The number of connected elements
10-3
10-2
10-1
100
ANMSE
BS-UE: Rayleigh;  RDARS-UE: Rician
BS-UE: Rayleigh;  RDARS-UE: Rayleigh
BS-UE: Rician;      RDARS-UE: Rician
BS-UE: Rician;      RDARS-UE: Rayleigh
(a) Topology 1
0
2
4
6
8
The number of connected elements
10-3
10-2
10-1
100
ANMSE
BS-UE: Rayleigh;  RDARS-UE: Rician
BS-UE: Rayleigh;  RDARS-UE: Rayleigh
BS-UE: Rician;      RDARS-UE: Rician
BS-UE: Rician;      RDARS-UE: Rayleigh
(b) Topology 2
Fig. 8. ANMSE vs the number of connected elements under various channel
conditions when Nr = 4, M = 6 in (a) Topology 1 (b) Topology 2.
RIS” scheme remains unchanged, while the other schemes
exhibit improving performance due to the distribution gain.
Furthermore, as a increases, the mode selection becomes more
significant, resulting in a larger performance gap between
the “IBCD-PDD” and “Fixed Index/Random Index” schemes.
Additionally, the performance improvement for the “IBCD-
PDD” algorithm becomes less significant when a exceeds a
certain threshold. While it still contributes to the enhancement
of ANMSE performance, the gains gradually saturate.
To determine the suitable value for the number of elements
in the connection mode in terms of the hardware complexity
and performance gain, we analyze the ANMSE performance
versus the number of elements in the connection mode under
various system typologies and channel conditions, as shown
in Fig. 8. We consider four channel conditions based on
the presence or absence of LoS components in the BS-
UE and RDARS-UE channels. In topology 1, the RDARS
is located in the middle of the BS and users, while in
topology 2, it is closer to the BS. We clearly find that the
performance gain of the proposed scheme is not significant as
a increases in both topologies when the RDARS-UE channel
12
JOURNAL OF LATEX CLASS FILES, SEPTEMBER 2023
0
0.2
0.4
0.6
0.8
1
Rician factor
10-3
10-2
10-1
100
ANMSE
Random Mode Selection
Greedy-Search
Fixed Mode Selection
Multiple Users
Single User
Fig. 9.
ANMSE vs the Rician factor under the case of a single user and
multiple users for different index selection schemes.
lacks LoS components. However, when the LoS paths exist
between the RDARS and users, the RDARS architecture
exhibits substantial performance improvement as a increases.
Furthermore, the slope of MSE performance initially increases
and then decreases as the number of elements in the connection
mode increases when the deterministic LoS paths exist in
the RDARS-UE channel. This suggests an optimal number of
connected elements for maximizing the slope of performance
improvement exists. Specifically, when the BS-UE channel
follows Rayleigh fading, the slope becomes larger when a ≤ 6
and then decreases when a > 6, where the transformation
threshold is equal to the number of users. However, under the
condition of the BS-UE channel subject to Rician fading, this
slope changes at a = 2, which equals the difference between
the number of receive antennas at the BS and the number
of users. In conclusion, the optimal number of elements in
the connection mode on RDARS depends on the channel
conditions, the number of users, and the number of receive
antennas at the BS. These findings provide crucial insights
when selecting the appropriate value of connected elements in
the practical implementation of RDARS-aided systems.
E. ANMSE vs κt.
In Fig. 9, we explored the ANMSE performance versus
the Rician factor κt under different mode selection schemes
with the same phase coefficients, considering both single-user
and multiple-user scenarios. In the single-user case, as the
Rician factor κt increases from 0 to 1, the channel transitions
from Rayleigh fading to a LoS channel. Consequently, the
ANMSE performance is gradually improved. Additionally,
as the Rician factor grows, the performance gap between
the optimized mode selection scheme and the random/fixed
mode selection schemes diminishes. This implies that the
optimization of the mode selection becomes less critical as the
strength of the LoS component increases. On the other hand,
the ANMSE performance in the case of multiple users does
not exhibit a monotonic relationship with the Rician factor due
to the increased interference among multiple users as the LoS
components become more dominant. The presence of stronger
LoS components will lead to more significant interference,
impacting the overall performance. Lastly, when considering
only LoS components (κT = 1), both the optimized mode
selection scheme and the random/fixed mode selection scheme
achieve the same ANMSE performance. This finding aligns
with Proposition 3, as stated in Section III, suggesting the
mode selection matrix A can be arbitrarily chosen when
only LoS channels are present. In conclusion, the ANMSE
performance in the RDARS is influenced by the Rician factor,
with different trends observed in single-user and multiple-
user scenarios. The necessity for mode selection optimization
diminishes when only LoS components are present. These
insights are valuable for guiding the practical implementation
of RDARS systems.
VI. CONCLUSION
In this paper, we investigated a novel RDARS-aided uplink
MIMO communication system and explored the performance
limits of this innovative structure. To improve the system
transmission reliability, the sum MSE minimization problem
of all data streams was formulated. The flexible and pro-
grammable configuration of RDARS’s elements, where each
element can be dynamically switched between the connection
mode and the reflection mode, was also exploited to enhance
the system performance. To address the intractable binary,
unit-modulus, and cardinality constraints in the optimization
problem, we proposed an inexact BCD-based PDD algorithm.
Additionally, we presented a low-complexity greedy-search-
based AO algorithm, which provides a near-optimal solution
with low computational complexity. Numerical results demon-
strated the proposed architecture showed great superiority in
comparison with the conventional RIS and DAS systems.
We also concluded that the optimal number of elements in
the connection mode on RDARS is closely related to the
channel conditions, the number of users, and the number of BS
antennas. Moreover, some insightful results about the practical
implementation of RDARS were investigated.
APPENDIX
A. Proof of Proposition 2
Proof. In the single-user SISO case, the MSE minimization
problem is equivalently transformed to
max
θ
||hd+gH(I−A)diag(θ)hr||2 + hH
r Ahr
(43)
The optimal θ⋆ in the SISO case is derived as:
θ⋆
n =
(
ej(∠hd−∠hr,n+∠gn),
n ∈ ˜
N,
any θn with |θn| = 1,
otherwise,
(44)
where ˜
N ≜ {n|An,n = 0}. For simplicity, the optimal θ⋆ can
be selected as θ⋆ = ej(∠hd−∠hr+∠g). With the optimal θ⋆,
the mode selection optimization turns into
max
xn,∀n
 
|hd|+
N
X
n
|gn||hr,n|−
N
X
n
xn|gn||hr,n|
!2
+
N
X
n
xn|hr,n|2
(45)
Since |gn| is much smaller than 1, xn|gn||hr,n| can be ignored.
The maximization problem turns into selecting the a largest
|hr,n|. Thus, we complete the proof.
WANG et al.: JOINT BEAMFORMING OPTIMIZATION AND MODE SELECTION FOR RDARS-AIDED MIMO SYSTEMS
13
B. Proof of Proposition 3
Proof. Assume the LoS channels G = κgagraH
gt, then the
problem turns into
max
θ,A
||hd+κgagtaH
gr(I−A)diag(θ)hr||2 + hH
r Ahr (46)
Denoting ˜ar = κgaH
gr(I−A)diag(hr), the problem can be
equivalently turned into
max
θ
||hd+agt˜aH
r θ||2
(47)
With some mathematical transformation, it can be rewritten
as
max
θ
θH˜ar˜aH
r θaH
gtagt + 2ℜ

hH
d ˜at˜aH
r θ
	
(48)
The optimal θ⋆ should satisfy θ⋆ = ej(∠˜ar+α) to maximize
θH˜ar˜aH
r θ with unit-modulus constraints, where α can be
arbitrarily chosen. On the other hand, to maximize the second
term ℜ

hH
d at˜aH
r θ
	
, it can be transformed to
max
θ
ℜ
(
|hH
d at|
N
X
n
|˜ar,n|ej(∠θn−∠˜ar,n+∠hH
d at)
)
(49)
the optimal θ⋆ can be derived as θ⋆ = ej(∠˜ar−∠hH
d at).
Combining these two optimal conditions, the optimal θ⋆ for
problem (46) can be determined as θ⋆ = ej(∠˜ar−∠hH
d at)..
Based on the derived optimal θ⋆, the mode selection opti-
mization problem under the LoS case is expressed as
max
xn,∀n
aH
t at|˜ar|2+2|hH
d at|
N
X
n
|˜ar,n| +
N
X
n
xn|hr,n|2 (50)
where
|˜ar|2 = κ2
g
N
X
n
|ar,n|2|hr,n|2(1−xn)2,
|˜ar,n| = κg|ar,n||hr,n|(1−xn),
(51)
Under the LoS channel hr, we have |hr,1| = |hr,n| = · · · =
|hr,N|. Thus, it can be readily referred that the mode selection
matrix A can be arbitrarily chosen. Then, we complete the
proof.
REFERENCES
[1] R. Chen, M. Liu, Y. Hui, N. Cheng, and J. Li, “Reconfigurable intelligent
surfaces for 6G IoT wireless positioning: A contemporary survey,” IEEE
Internet of Things Journal, vol. 9, no. 23, pp. 23 570–23 582, 2022.
[2] S. Basharat, S. A. Hassan, H. Pervaiz, A. Mahmood, Z. Ding, and
M. Gidlund, “Reconfigurable intelligent surfaces: Potentials, applica-
tions, and challenges for 6G wireless networks,” IEEE Wireless Com-
munications, vol. 28, no. 6, pp. 184–191, 2021.
[3]
¨O. ¨Ozdogan, E. Bj¨ornson, and E. G. Larsson, “Using intelligent re-
flecting surfaces for rank improvement in MIMO communications,” in
ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP).
IEEE, 2020, pp. 9160–9164.
[4] J. Sang, Y. Yuan, W. Tang, Y. Li, X. Li, S. Jin, Q. Cheng, and T. J. Cui,
“Coverage enhancement by deploying RIS in 5G commercial mobile
networks: Field trials,” IEEE Wireless Communications, pp. 1–21, 2022.
[5] Z. Zhang, L. Dai, X. Chen, C. Liu, F. Yang, R. Schober, and H. V.
Poor, “Active RIS vs. passive RIS: Which will prevail in 6G?” IEEE
Transactions on Communications, vol. 71, no. 3, pp. 1707–1725, 2023.
[6] L. Dong, H.-M. Wang, and J. Bai, “Active reconfigurable intelligent
surface aided secure transmission,” IEEE Transactions on Vehicular
Technology, vol. 71, no. 2, pp. 2181–2186, 2022.
[7] Z. Kang, C. You, and R. Zhang, “Active-passive IRS aided wireless
communication: New hybrid architecture and elements allocation opti-
mization,” IEEE Transactions on Wireless Communications, 2023.
[8] Q. Peng, Q. Wu, G. Chen, R. Liu, S. Ma, and W. Chen, “Hybrid active-
passive IRS assisted energy-efficient wireless communication,” IEEE
Communications Letters, vol. 27, no. 8, pp. 2202–2206, 2023.
[9] R. S. P. Sankar and S. P. Chepuri, “Channel-aware placement of active
and passive elements in hybrid RIS-assisted MISO systems,” IEEE
Wireless Communications Letters, vol. 12, no. 7, pp. 1229–1233, 2023.
[10] N. T. Nguyen, Q.-D. Vu, K. Lee, and M. Juntti, “Hybrid relay-
reflecting intelligent surface-assisted wireless communications,” IEEE
Transactions on Vehicular Technology, vol. 71, no. 6, pp. 6228–6244,
2022.
[11] N. T. Nguyen, V.-D. Nguyen, H. V. Nguyen, H. Q. Ngo, S. Chatzinotas,
and M. Juntti, “Spectral efficiency analysis of hybrid relay-reflecting
intelligent surface-assisted cell-free massive MIMO systems,” IEEE
Transactions on Wireless Communications, vol. 22, no. 5, pp. 3397–
3416, 2023.
[12] A. Moerman, J. Van Kerrebrouck, O. Caytan, I. L. de Paula, L. Bogaert,
G. Torfs, P. Demeester, H. Rogier, and S. Lemey, “Beyond 5G without
obstacles: mmWave-over-fiber distributed antenna systems,” IEEE Com-
munications Magazine, vol. 60, no. 1, pp. 27–33, 2022.
[13] L. Yu, J. Wu, A. Zhou, E. G. Larsson, and P. Fan, “Massively distributed
antenna systems with nonideal optical fiber fronthauls: A promising
technology for 6G wireless communication systems,” IEEE Vehicular
Technology Magazine, vol. 15, no. 4, pp. 43–51, 2020.
[14] S. Elhoushy, M. Ibrahim, and W. Hamouda, “Cell-free massive MIMO:
A survey,” IEEE Communications Surveys & Tutorials, vol. 24, no. 1,
pp. 492–523, 2022.
[15] C. Ma, X. Yang, J. Wang, G. Yang, W. Zhang, and S. Ma, “Reconfig-
urable distributed antennas and reflecting surface: A new architecture
for wireless communications,” arXiv preprint arXiv:2303.06950, 2023.
[16] J. Wang, C. Ji, J. Guo, and S. Ma, “Reconfigurable distributed an-
tennas and reflecting surface (RDARS)-aided integrated sensing and
communication system,” in 2023 IEEE/CIC International Conference
on Communications in China (ICCC).
IEEE, 2023, pp. 1–2.
[17] 6G White Paper on Metamaterials for Information Technology.
China
Mobile Research Institute, Southeast University, 2022.
[18] X. Yang, S. Ma, and S. Jin, “Antenna selection for asymmetrical
uplink and downlink transceivers in massive MIMO systems,” IEEE
Transactions on Wireless Communications, pp. 1–1, 2023.
[19] J. Hu, H. Yin, and E. Bj¨ornson, “Mmwave MIMO communication with
semi-passive RIS: A low-complexity channel estimation scheme,” in
2021 IEEE Global Communications Conference (GLOBECOM), 2021,
pp. 01–06.
[20] G. Yuan and B. Ghanem, “An exact penalty method for binary optimiza-
tion based on mpec formulation,” in Proceedings of the AAAI Conference
on Artificial Intelligence, vol. 31, no. 1, 2017.
[21] Q. Shi and M. Hong, “Penalty dual decomposition method with appli-
cation in signal processing,” in 2017 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), 2017, pp. 4059–
4063.
[22] X. Zhang, Matrix analysis and applications.
Cambridge University
Press, 2017.
[23] J. Wang, S. Gong, Q. Wu, and S. Ma, “RIS-aided MIMO systems with
hardware impairments: Robust beamforming design and analysis,” IEEE
Transactions on Wireless Communications, vol. 22, no. 10, pp. 6914–
6929, 2023.
[24] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex
programming, version 2.1,” http://cvxr.com/cvx, Mar. 2014.
[25] A. Tenenbaum, “MSE-based linear transceiver designs for multiuser
MIMO wireless communications,” Ph.D. dissertation, 2011.
[26] Q. Shi and M. Hong, “Penalty dual decomposition method for non-
smooth nonconvex optimization—part I: Algorithms and convergence
analysis,” IEEE Transactions on Signal Processing, vol. 68, pp. 4108–
4122, 2020.
[27] M. Gharavi-Alkhansari and A. Gershman, “Fast antenna subset selection
in MIMO systems,” IEEE Transactions on Signal Processing, vol. 52,
no. 2, pp. 339–347, 2004.
[28] Y. Gao, H. Vinck, and T. Kaiser, “Massive MIMO antenna selection:
Switching architectures, capacity bounds, and optimal antenna selection
algorithms,” IEEE Transactions on Signal Processing, vol. 66, no. 5, pp.
1346–1360, 2018.
[29] Y. S. Cho, J. Kim, W. Y. Yang, and C. G. Kang, MIMO-OFDM wireless
communications with MATLAB.
John Wiley & Sons, 2010.
[30] X. Zhao, K. Xu, S. Ma, S. Gong, G. Yang, and C. Xing, “Joint
transceiver optimization for IRS-aided MIMO communications,” IEEE
Transactions on Communications, vol. 70, no. 5, pp. 3467–3482, 2022.
","Due to its high potential for energy and spectrum efficiency, numerous research works have been conducted to explore the benefits of RIS-aided communication systems. These studies have shown RIS has the ability to address a wide range of challenges, such as improving coverage area, overcoming local dead zones, enhancing edge user rates, eliminating co-channel interference, and enabling high-precision positioning. For instance, the authors in [3] optimized RIS to enrich the propagation environment by adding multi-paths and increasing the rank of the channel matrix to support spatial multiplexing, thus leading to substantial capacity gains. The authors in [4] conducted a performance analysis of the coverage enhance-ment for RIS under current commercial mobile networks in various urban scenarios. The field trial results showed a significant improvement in the user experience, including extending the coverage and improving the throughput.nan"
"This research aims to utilize deep reinforcement learning, specifically Deep Q Networks (DQN), to enhance the navigational capabilities of soft growing robots. The proposed algorithm takes advantage of the inherent flexibility of soft robots, seamlessly integrating environmental interactions into the decision-making process. This approach is particularly geared towards enabling navigation through densely cluttered spaces, a task that presents significant challenges for conventional robotic systems.","Exploration of confined spaces, such as those encountered in Minimally Invasive Surgeries (MIS) or the inspection of archaeological sites, poses significant challenges for traditional rigid robot designs. Consequently, there is a critical need for innovative materials and locomotion systems in robotics to navigate these challenging environments effectively. Inspired by biological systems like elephant trunks, octopus tentacles, and snakes, the development of soft continuum robots featuring continuous bending backbones has facilitated non-destructive navigation in congested spaces.","The proposed DQN reinforcement learning algorithm observes the current state of the growing robot, which includes its length, curvature, and tip position, as well as the goal and obstacle locations. The action space consists of actuation length and curvature rate. A deep neural network is used to approximate the Q-values for each state-action pair. The network is trained using experience replay and a sliding window approach to maintain a balance between exploration and exploitation.","Numerical experiments evaluate the effectiveness of the proposed DQN-based method for obstacle-aware navigation in growing robots. The robot demonstrates a significant improvement in its ability to reach goals in obstacle-free environments, even with varying goal locations. In obstacle-aware scenarios, the robot successfully navigates around obstacles and reaches goals with high efficiency. The proposed approach exhibits adaptability, enabling the robot to exploit the presence of obstacles to reach challenging goals.","The study presents a promising approach to addressing the challenges faced by growing robots in particular and soft robots general in planning obstacle-aware paths in real-world scenarios. The proposed algorithm, DQN, enhances the navigational capabilities of soft growing robots by exploiting obstacles as part of their pathfinding strategy. As a future direction, continuous action space learning techniques can be explored to provide more fine-grained control and potentially enhance the robot’s performance in complex tasks.",Obstacle-Aware Navigation of Soft Growing Robots via Deep Reinforcement Learning,Haitham El-Hussieny,"Obstacle-Aware Navigation of Soft Growing Robots via Deep
Reinforcement Learning
Haitham El-Hussieny
Department of Mechatronics and Robotics Engineering,
Egypt-Japan University of Science and Technology, Alexandria, Egypt
(E-mail: haitham.elhussieny@ejust.edu.eg)
January 23, 2024
Abstract
Soft growing robots, are a type of robots that are
designed to move and adapt to their environment in a
similar way to how plants grow and move with poten-
tial applications where they could be used to navigate
through tight spaces, dangerous terrain, and hard-to-
reach areas. This research explores the application of
deep reinforcement Q-learning algorithm for facilitat-
ing the navigation of the soft growing robots in clut-
tered environments. The proposed algorithm utilizes
the flexibility of the soft robot to adapt and incor-
porate the interaction between the robot and the en-
vironment into the decision-making process. Results
from simulations show that the proposed algorithm
improves the soft robot’s ability to navigate effec-
tively and efficiently in confined spaces. This study
presents a promising approach to addressing the chal-
lenges faced by growing robots in particular and soft
robots general in planning obstacle-aware paths in
real-world scenarios.
1
Introduction
The exploration of confined spaces, such as those
encountered in Minimally Invasive Surgeries (MIS)
or the inspection of archaeological sites, presents
significant challenges for traditional rigid robot de-
signs [1, 2].
Consequently, there is a critical need
for innovative materials and locomotion systems in
robotics to navigate these challenging environments
effectively. Drawing inspiration from biological sys-
tems like elephant trunks, octopus tentacles, and
snakes, the development of soft continuum robots fea-
turing continuous bending backbones has facilitated
non-destructive navigation in congested spaces [3–5].
However, the limited lengths of traditional continuum
robots restrict their capacity to explore more distant
spaces [6].
Addressing this limitation, the concept of growth
mobility, inspired by the way plants grow, has
emerged as a groundbreaking approach in robotics.
Growing robots, emulating the biological growth of
plants, can extend their lengths, volumes, or knowl-
edge, gradually adapting to their environment [7].
These robots, made of soft materials or equipped with
flexible joints, can extend to reach faraway spaces
while maintaining compliance in confined settings.
Prior efforts in designing long, flexible robots suit-
able for tight spaces include the “Active Hose” by
Tsukagoshi et al., a multi-degree-of-freedom robot
designed for search and rescue applications [8]. Isaki
et al.
developed a flexible, extended cable with a
camera for exploration in narrow areas [9], and the
“Slime Scope,” a pneumatically driven soft arm, was
created for use in rubble environments [10].
How-
ever, these designs often require moving the entire
robot body, leading to significant friction with the
environment.
Recent advancements in plant-inspired robotics
1
arXiv:2401.11203v1  [cs.RO]  20 Jan 2024
have led to the development of two novel types
of growing robots capable of extending their body
lengths by adding materials at their tips.
Sadeghi
et al.
proposed a plant root-like robot with a 3D
printer-like head at its tip, enabling efficient steering
by varying material deposition speeds [11,12]. How-
ever, the growth speed is environment-dependent. In
contrast, Hawkes et al. developed a vine-like growing
robot using a ”tip-eversion” mechanism [13,14]. This
pneumatically-driven robot, made from thin-walled
polyethylene tubing, can extend for tens of meters
and navigate slippery or sticky environments. Steer-
ing is achieved through environmental interaction or
by using Series Pneumatic Artificial Muscles (SPAM)
for controlled movements [4, 15]. The unique com-
bination of lengthening capacity, length-to-diameter
ratio, and a compliant body allows vine-like robots
to effectively navigate through distant, cluttered en-
vironments, as demonstrated in [16,17].
The very features that make vine-like robots so
versatile also introduce complex challenges in motion
planning. One of the critical aspects of vine robots is
their irreversible growth process. Once a segment of
the robot has extended or turned in a particular di-
rection, retracting or reversing this action is not fea-
sible. This irreversible nature of growth necessitates
highly accurate and forward-thinking motion plan-
ning. In their recent work, [18] have pioneered the
use of a Model Predictive Control (MPC) approach
in the context of vine robot navigation, incorporat-
ing the kinematics of a vine robot as the predictive
model, enabling advanced motion planning and ob-
stacle avoidance. However, the development of an ac-
curate kinematic model for vine-growing robots poses
significant challenges.
This research introduces a new application of deep
reinforcement learning, specifically Deep Q Networks
(DQN), to enhance the navigational capabilities of
soft growing robots, as depicted in Figure 1.
Our
algorithm capitalizes on the inherent flexibility of
soft robots, seamlessly integrating environmental in-
teractions into the decision-making process.
This
approach is particularly geared towards enabling
navigation through densely cluttered spaces, a task
that presents significant challenges for conventional
robotic systems.
Reinforcement Learning
Deep
Neural
Network
Sense
Act
Controller
Experience Replay 
Growing Robot 
Figure 1: Enhancement of Movement Skills in the
Vine-Growing Robot Through Deep Reinforcement
Learning: This process involves the robot’s adaptive
learning from its interactions with the environment.
The findings from our simulations indicate a
marked improvement in the ability of soft robots
to exploit obstacles effectively to reach challenging
goals, leveraging the DQN framework. This advance-
ment addresses a critical obstacle in soft robotics, sig-
nificantly enhancing the operational performance of
soft growing robots in real-life scenarios, especially
those characterized by complex, obstacle-rich envi-
ronments. By equipping these robots with the capa-
bility to plan and execute obstacle-aware paths more
effectively, this research lays the groundwork for their
enhanced utilization in diverse, real-world applica-
tions.
The paper is organized as follows: Section 2 intro-
duces the kinematic model of the vine growing robot,
including the interaction model with obstacles.
In
Section 3 details the proposed DQN reinforcement
learning algorithm, including the observation, action
and reward definitions. In Section 4, we present the
simulation results to asses the performance of our
DQN approach for planning safe paths for growing
robots. Finally, Section 5 concludes the paper, sum-
marizes our main contributions, and outlines poten-
tial directions for future work.
2
2
Modeling of Vine Robots
In this research, we focus on the vine-growing robot
recently developed by [16]. Using an eversion mech-
anism [19], the robot can elongate its tip up to tens
of meters. The robot’s body is made of a thin-walled
polyethylene tube, initially inverted, as depicted in
Figure 2.
The robot’s length can be increased by
applying air pressure to its chamber, which permits
the tip to move away from its base.
The eversion
mechanism allows the vine robot to navigate eas-
ily through adhesive environments without getting
stuck. To control the robot’s bending, three serial
Pneumatic Actuator Muscles (sPAM) are installed
around its circumference, and air pressure is applied
to these actuators. The arrangement of these sPAM
actuators enables 360◦ steering, achieved by manip-
ulating the input pressure for each actuator, as de-
scribed in [16].
This section is dedicated to exploring the connec-
tion between actuation parameters and the position
of the robot’s tip, as delineated by the kinematic
model.
Additionally, it will illustrate the method
of integrating the robot body’s interaction with ob-
stacles into the kinematics. This integration will be
achieved by resolving a nonlinear constrained opti-
mization problem that symbolizes this interaction.
2.1
Kinematics of Vine Robots
Given the inherent characteristics of soft grow-
ing robots, particularly their lightweight construction
and the typically slow-paced nature of their opera-
tional movements, the primary focus in research and
application tends to be on statics and kinematics,
rather than dynamics. The forward kinematics of the
vine robot are formulated predominantly under the
guiding principle of the constant-curvature assump-
tion, as detailed in the seminal work of Jones et al.
(2006) [20]. This robot is conceptualized as a single-
section, extensible entity exhibiting continuum-like
characteristics, endowed with dual degrees of freedom
for curvature and bending, along with an additional
degree for axial extension.
The spatial orientation and positioning of the
robot, denoted as Tb
r, are intrinsically linked to
P
P
P1
IMU
P
P
sPAMs
pump
eversion
encoder
steering
extension
(a)
(b)
(c)
Figure 2:
Operational Mechanics of the Growing
Vine Robot. (a) The application of air pressure to
the robot’s central tube aids in extending the tip, as
shown in (b). The steering mechanism, depicted in
(c), is achieved by altering the air pressure in one or
more of the soft pneumatic artificial muscles (sPAMs)
surrounding the vine robot.
its configurational state, represented by q ∈ R3.
This state vector q encompasses the pivotal elements
defining the robot’s structure: the length of the robot
(s), the curvature (κ), and the angle of the curvature
plane (ϕ), all of which are comprehensively illustrated
in Figure 3. The pose Tb
r is derived from these param-
eters, offering a precise mathematical representation
of the robot’s positioning and orientation in space.
A =


cos2 ϕ(cos κs − 1) + 1
sin ϕ cos ϕ(cos κs − 1)
sin ϕ cos ϕ(cos κs − 1)
cos2 ϕ(1 − cos κs) + cos κs
cos ϕ sin κs
sin ϕ sin κs
0
0
− cos ϕ sin κs
cos ϕ(cos κs−1)
κ
− sin ϕ sin κs
sin ϕ(cos κs−1)
κ
cos κs
sin κs
κ
0
1

 .
(1)
The robot’s tip position p = [x, y, z]T ∈ R3 in Carte-
sian space can be stated from Eq. (1) as,
3
θ 
s
φ 
β 
d
p
li
x
y
z
Figure 3: Schematic of vine-like growing robot and its
configuration parameters. The robot is characterized
by its length s, curvature κ = θ
s, and angle of robot
plane ϕ.
x = cos ϕ(cos κs − 1)
κ
,
y = sin ϕ(cos κs − 1)
κ
,
z = sin κs
κ
(2)
In the context of this research, we have adopted
the simplifying assumption of a planar environment,
denoted mathematically as ϕ = 0. This assumption
is primarily for the sake of analytical and compu-
tational simplicity, allowing us to focus on the core
aspects of the algorithm and control strategy with-
out the additional complexity introduced by a three-
dimensional environment. However, it is important
to note that the extension of our model and method-
ologies to a spatial, three-dimensional environment is
straightforward.
The kinematic formulation encapsulated in Eq. (2)
is key for understanding the vine robot’s intrinsic be-
havior and practical application in autonomous navi-
gation. This model is integral to the training regimen
of the Deep Q-Network (DQN) agent, a critical com-
ponent in enabling the vine robot to accurately navi-
gate towards designated target positions, particularly
in scenarios involving interaction with its surround-
ing environment.
Central to the operational mechanics of the vine
robot is the actuation lengths, denoted by l
=
[s, l1, l2, l3].
These lengths represent the tangible
actuation space, encompassing both the core robot
length and the lengths of the soft Pneumatic Artificial
Muscles (sPAMs). Notably, utilizing shape parame-
ters within this framework does more than merely
dictate the robot’s movements; it effectively general-
izes the control problem. This generalization ensures
that the control strategies developed are not limited
to this specific vine robot but apply to a broader
spectrum of continuum-like robots adhering to the
constant-curvature model previously discussed.
2.2
Interaction Modeling
When a vine robot makes contact with an obstacle,
it adapts its form to accommodate this interaction.
Predicting and understanding this shape adaptation
is essential for refining control algorithms and ensur-
ing smooth, efficient navigation.
In order to integrate the influence of obstacles into
the change of the robot’s shape, we implemented the
strain energy minimization principle as emphasized
in [21]. In general, the approach involves treating a
single-section continuum robot of length s as a flex-
ible beam formed of N sub-segments. Each segment
 
Figure 4: Effect of a point obstacle on the continuum
robot shape. On the left the robot has no interaction
with the obstacle and the robot curvature is the same
to all segments. On the right, the robot has collided
with a point obstacle making the robot curvature not
consistent along it’s backbone.
4
is subjected independently to bending deformation
caused by the external torque resulting the actuation
and the interaction with the environment as depicted
in Figure 4. Consequently, the robot assumes a con-
figuration that optimizes its strain energy at a state
of static equilibrium. This optimization leads to a
curvature alignment denoted as κ ∈ RN across the
segmented length of the vine robot’s body, divided
into N sections. This alignment serves as the central
objective, encapsulated by the following key objective
function with the aim of finding the set of curvatures
κ ∈ RN for the sub-segments.
arg min
κ
 
γ1
N−1
X
i=0
(κi − κt)2 + γ2
N−2
X
i=0
(κi+1 − κi)2
!
(3)
trim=5cm 4cm 9cm 1cm,clip In the specified equa-
tion, the formulation is strategically divided into two
principal terms, each addressing a distinct aspect of
the vine robot’s curvature control. The first term is
designed to minimize the deviation between the cur-
vature of each sub-segment of the robot and a pre-
defined target curvature, κ.
This target curvature
is established under the assumption of obstacle-free
conditions, serving as a benchmark for the desired
trajectory of the robot in an unobstructed environ-
ment.
Simultaneously, the second term in the equation is
tasked with a different objective: it aims to reduce
the disparity in curvature between adjacent segments
of the robot. This is a critical consideration, as it
adheres to the principle of minimizing strain energy,
thereby preserving the integrity of the robot’s contin-
uous backbone structure. The necessity to maintain a
smooth transition between segments is paramount in
ensuring the robot’s efficient and effective movement,
particularly in scenarios involving complex naviga-
tion paths.
The incorporation of the factors γ1 and γ2 in this
equation plays a vital role. These weighting factors
are employed to establish a balance between the dual
objectives of the equation.
To avoid the growing robot from colliding with the
obstacle, the optimization problem in Eq. (3) is sub-
jected to the constraint that the Cartesian coordi-
nates (xi, yi) of the tip of each sub segment i is within
a safe distance rr from the center of the obstacle at
the location (xo, yo) with radius ro as follow, assum-
ing the obstacle location is known
dio ≥ ro + rr,
∀i = 0, 1, . . . , N − 1
(4)
where dio =
p
(xi − xo)2 + (yi − yo)2 is the Eu-
clidean distance from the segment i of the robot and
the obstacle location.
While the constant curvature model serves as the
foundational assumption in our kinematic modeling
of the vine robot, it’s important to recognize that
interactions with environmental obstacles can signif-
icantly alter the robot’s shape, thereby challenging
this assumption. In scenarios where the robot comes
into contact with an obstacle, its behavior diverges
from that of a single-segment, constant curvature en-
tity. Instead, the robot begins to exhibit characteris-
tics akin to a multi-segmented structure, displaying
varying curvatures along its length.
3
DQN Reinforcement Learn-
ing Algorithm
This section elaborates on the Reinforcement
Learning (RL) algorithm employed to train the grow-
ing robot.
The primary objective is to enable the
robot to efficiently navigate towards a specified goal
within its environment, while skillfully navigating
around and interacting with obstacles. The RL agent
operates by observing the current state x ∈ R9 of the
growing robot, which is defined within the observa-
tion space as:
x = [s κ ˙s ˙κ xg yg xo yo d]T
(5)
In this state vector x, s and κ represent the robot’s
length and curvature, respectively, and ˙s and ˙κ are
the corresponding time derivatives of these quanti-
ties. These variables are crucial for the RL agent to
5
understand and predict the robot’s physical configu-
ration and movement dynamics. To maintain aware-
ness of the goal and obstacle locations within the en-
vironment, the coordinates (xg, yg) for the goal and
(xo, yo) for the obstacle are included in the observa-
tion space.
Additionally, the Euclidean distance d
is calculated and tracked. This distance, defined be-
tween the robot’s tip (x, y) as derived in Eq. (2) and
the goal position, is given by:
d =
q
(x − xg)2 + (y − yg)2
(6)
In order to ensure the generalizability of the RL
model to different goal locations, the position of the
goal is varied randomly during the training process,
with a probability of 0.2 for changing in each training
iteration. This randomization strategy is designed to
expose the growing robot to a diverse set of scenarios,
thereby enhancing its ability to adapt and perform ef-
fectively in a wide range of environmental conditions
and goal configurations.
The reinforcement learning agent in this study is
designed to manage the movement of a growing robot
by sampling an action vector a, defined as follows:
a = [ ˙s ˙κ]
(7)
Here, ˙s represents the robot’s growth speed, and ˙κ
indicates the rate of change in the robot’s curvature.
By incorporating these specific actuation variables,
the proposed algorithm demonstrates versatility and
adaptability across a broad range of continuum-like
robotic systems. This flexibility is crucial as it en-
sures the applicability of the goal-reaching algorithms
irrespective of the underlying actuation mechanism,
whether it be cable-driven or pneumatically driven
systems.
In the domain of Q-learning, a crucial aspect is
the representation of actuation in discrete values.
This discretization ensures that each actuation com-
ponent of the robot operates within a predefined set
of actions, effectively covering the entire operational
range. Specifically, in our model:
1. The rate of change of curvature, ˙κ, is restricted
to three discrete values, [κl 0 κr] rad/s. These
values correspond to the robot bending to the
left, remaining stationary (no bending), and
bending to the right, respectively.
2. The growth speed, ˙s, is either set to elongate the
robot at a constant rate of sm m/s or to halt its
elongation, denoted as ˙s = 0.
Consequently, the action space for the robot is de-
fined as a set of all possible combinations of these
discrete values:
a =
κl
0

,
 κl
sm

,
0
0

,
 0
sm

,
κr
0

,
κr
sm

This discrete action space encapsulates all the pos-
sible movements of the robot within its operational
constraints, allowing for a structured approach in the
Q-learning algorithm to optimize the robot’s behav-
ior for achieving specific goals. At the onset of each
training episode, the RL algorithm initializes with
predetermined parameters κ0 and s0. The algorithm
initially adopts a strategy of exploration, where ac-
tions a are chosen randomly based on an exploration
probability ϵ, as delineated in Algorithm 1. This ex-
ploratory phase is crucial for the agent to acquire di-
verse experiences and insights into the environment’s
dynamics.
As training progresses, the algorithm gradually
shifts its focus towards exploitation, increasingly se-
lecting actions that are anticipated to yield the high-
est cumulative reward.
The formulation for calcu-
lating the cumulative reward Rk at each step k is
expressed as:
Rk = rk+γrk+1+γ2rk+2+. . .+γn−krn = rk+Rk+1
(8)
In this equation, rk represents the immediate re-
ward assigned at each step k, and γ is the discount
factor, which balances the importance of immediate
and future rewards.
The computation of the immediate reward rk in
our proposed method is designed to incentivize goal-
oriented behavior.
Specifically, a high reward of
6
+1000 is assigned if the robot’s tip is within a maxi-
mum distance of dmax = 0.1 from the goal, leading to
the termination of the training episode. Conversely,
if the robot’s tip is farther from the goal, the reward
is inversely proportional to this distance d, as defined
in Eq. (6). The reward function is thus formulated
as:
rk = 1 −
 ln(1 + dk)
ln(1 + dmax)

(9)
This reward structure ensures that the agent is mo-
tivated to minimize the distance to the goal, effec-
tively guiding its learning process towards efficient
and goal-directed actions.
During both the training and testing phases of our
approach, the position of the obstacle is assumed to
be fixed. This static positioning of the obstacle sim-
plifies the learning and evaluation process, allowing
the reinforcement learning agent to focus on under-
standing and adapting to a consistent environmental
factor. However, it’s noteworthy that our approach
possesses the inherent capability to handle dynamic
obstacles as well. This adaptability stems from the
inclusion of the goal position in the agent’s obser-
vation space. Since the agent is already equipped to
process and respond to changes in the goal’s location,
extending this adaptability to accommodate moving
obstacles is a feasible and logical progression.
The deep Q-learning algorithm [22] is utilized in
this research to train the agent to reach the desired
goal while maximizing the accumulative reward of
Eq. (8). The RL agent learns to select the best pos-
sible action a at every state s as described in Algo-
rithm 2 and Figure 5. This is represented by a policy
π(s)
π(s) = max
a
Q(s, a)
(10)
where Q(s, a) is approximated in Q-learning algo-
rithm as
Q(s, a) ← Q(s, a)+α

r + γ max
a′ Q(s′, a′) − Q(s, a)

(11)
State
Action
input
FC1 (64)
FC3 (64)
output
Dropout(0.2)
FC2 (128)
Figure 5: Illustration of the DQN Agent Architec-
ture: This diagram depicts the agent as it observes
state s and executes action a. The process of trans-
forming the observed state into an actionable decision
is facilitated through a feed-forward neural network,
which serves as the core mechanism for mapping ob-
servations to corresponding actions.
Algorithm 1 Action sampling
P ← P 0
for episode = 1 to N do
for k = 1 to M do
with probability ϵ select random action ak,
otherwise ak = maxa Q(s, a)
(sk+1, rk) = step(sk, ak)
▷ Simulate the
system
P k = (sk, ak, sk+1, rk)
Algorithm 2 Learning Q-value
θ ← θ0
▷ Initialize network weights
while No termination signal recieved do
Sample random minibatch of (s, a, r, s′) from
P .
Set target = r + γ maxa′ Qθ(s′, a′)
Set prediction = Qθ(s′, a′)
L = 1
2 [target − prediction]2
θ ← θ − α∂L
∂θ
▷ Update network weights
where s′ is the next state while a′ is the next action.
Meanwhile, α is the learning rate.
In conventional Q-learning [23], where the state
space is small, the Q value is represented as a ta-
ble of state and the corresponding Q of each action
in that state. However, in this navigation problem,
7
Figure 6: The vine growing robot interacting with an
obstacle after applying constant actuation of ˙κ.
the state space is enormous.
Thus, a deep neural
network is used to approximate the the Q-table as
Qθ(s, a), where θ is the deep neural network that is
trained as follows:
θ ← θ − α∂L
∂θ
(12)
where L is the loss:
L = 1
2 [target − prediction]2
= 1
2
h
r + γ max
a′ Q(s′, a′) − Q(s, a)
i2
(13)
4
Results and Discussion
A comprehensive series of numerical experiments
designed to evaluate the effectiveness of the DQN-
based method for obstacle-aware navigation in grow-
ing robots. Initially, the focus was on analyzing the
interaction model. This model crucially predicts how
the morphology of the vine robot alters in response to
encounters with obstacles. In Figure 6, we illustrate
the initial phase of the robot’s navigation sequence,
wherein it begins in a configuration that is free from
any collision with the obstacle, depicted in transpar-
ent red. Subsequently, as the robot navigates through
its environment, there is an incremental increase in
its bending motion, applying constant ˙κ. This pro-
gression continues until the point of collision with the
obstacle.
Upon this interaction, the robot’s shape
undergoes a transformation, conforming to the pa-
rameters set out by the interaction model discussed
in Section 2. Such an analysis is vital for understand-
ing the adaptive behavior of the robot under varying
environmental constraints.
In this study, we configured the replay memory to
accommodate a maximum of 20,000 steps, as delin-
eated in Algorithm 1. This memory utilizes a First-
In-First-Out (FIFO) strategy for data replacement,
ensuring a continual update of experiences for the
learning agent. The training protocol, detailed in Al-
gorithm 2, comprised an extensive series of 200,000
episodes (N), with each episode constrained to a
maximum of 100 steps (kmax). This comprehensive
approach is designed to provide the agent with a wide
array of scenarios for robust training.
The learning thread, initiating after a prelude of
20 episodes, facilitates the accumulation of initial
experiences in the replay memory, essential for ef-
fective learning. A batch size of 64 was chosen for
the random selection of experiences from the mem-
ory pool (denoted as P), balancing the computational
efficiency and diversity in experience sampling.
The exploration rate of the network was initially
set to 1.0, promoting a purely exploratory approach
at the onset of the learning phase.
Subsequently,
this rate was decremented by 0.05 following each
episode, culminating at zero. Such a gradual decre-
ment facilitates a strategic shift from exploration to
exploitation, enabling the agent to progressively rely
on learned behaviors over random actions.
For optimization, the ADAMS optimizer [24] was
employed, renowned for its efficacy in handling large
datasets and complex variable interactions. Finally,
the discount factor and learning rate were set at 0.5
and 0.1, respectively.
4.1
Fixed goal, obstacle-free
In the initial phase, the training process of the pro-
posed DQN-based navigation system was evaluated
in a goal-reaching scenario. This scenario was char-
acterized by a fixed goal position set in an environ-
ment free of obstacles. Figure 7 presents the learning
progression when the goal is set at coordinates (1, 3),
with the vine robot starting from initial parameters
8
Figure 7: Evaluation of the Proposed DQN Goal-
Seeking Algorithm: This figure illustrates the learn-
ing performance of the algorithm, showcasing two key
metrics. On the left, the graph displays the number
of steps required by the agent to reach the goal. On
the right, the graph depicts the accumulated reward
achieved by the agent.
s0 = 1 meter and κ0 = 0.01 m−1.
The left side of Figure 7 illustrates a notable de-
crease in the number of steps required for the robot
to successfully complete the reaching phase. This re-
duction indicates an improvement in the efficiency of
the robot’s path-finding as the training progresses.
On the right side, the figure depicts an increase in
the average accumulated reward over the course of
the training steps.
It is important to note the observable fluctuations
in both the number of steps and the average reward,
particularly in the early stages of training.
These
fluctuations can be attributed to the high exploration
rate ϵ initially set in the training process. At this
stage, the robot is more inclined to make random de-
cisions, exploring a broader range of policies. This
exploratory approach is crucial for the robot to dis-
cover and learn from diverse situations, even though
it may temporarily deviate from the policy that max-
imizes expected rewards. As training progresses and
the exploration rate decreases, the robot increasingly
adopts strategies that focus on reward maximization,
leading to more consistent and goal-oriented behav-
ior.
Figure 8 evaluates the DQN algorithm post-
training, focusing on its ability to direct the robot to-
wards a specified goal using the learned DQN model.
The upper section of the figure graphically represents
0
10
20
30
40
50
steps
0
1
2
3
4
error
0
10
20
30
40
50
steps
-2
-1
0
1
2
action [
 s,   x 10]
 s
 
Figure 8: (Top) The decay of the error between the
robot’s tip and the target location of the trained
DQN. (Bottom) The set of discrete action commands
executed by the vine robot to reach the goal.
Figure 9: The learning performance of the DQN algo-
rithm in an obstacle-free goal changing environment.
the decrease in error distance, which is the spatial dis-
crepancy between the robot’s tip and the designated
goal. The lower section of the figure depicts the dis-
crete control actions executed by the robot during its
journey to the goal. These actions are a direct re-
sult of the decisions made by the DQN agent based
on the trained model. A key observation from the
results is that after 38 steps, equivalent to 3.8 sec-
onds, the robot successfully reaches the goal, where
the DQN agent applying zero control actions.
4.2
Varying goal, obstacle-free
To assess the generalization capabilities of the pro-
posed DQN model, particularly in navigating towards
a goal with varying location within the environment,
we incorporated a goal-changing strategy during the
9
training phase. This strategy involved altering the
goal’s location with a predefined probability of 10%,
thus presenting the agent with diverse navigation
challenges. The environment was kept free of obsta-
cles for this phase of training to simplify the evalua-
tion process and focus on the agent’s ability to adapt
to changing goals.
Figure 9 illustrates the training progress of the
DQN agent under this variable goal location condi-
tion. Notably, the figure demonstrates a decreasing
trend in the number of steps required for the agent
to reach the goals as the episodes progress. Concur-
rently, there is an observable increase in the accu-
mulated rewards over the episodes, indicating an im-
provement in the agent’s efficiency and goal-reaching
capability.
The observed fluctuations in both the number of
steps and the accumulated rewards can be attributed
to the dynamic nature of the goal locations. Despite
these variations in goal locations, the DQN model
exhibits a notable robustness over the episodes. Dur-
ing the testing phase, the DQN agent was tasked with
directing the vine robot to reach various goals, with
the goal locations (xo, yo) sequentially altered within
the environment, adhering to the ranges xo ∈ [0, 4]
and yo ∈ [−4, 4].
Figure 10 presents a heat map
illustrating the normalized error distribution across
the working environment. The visualization indicates
minimal errors in goal-reaching accuracy across di-
verse goal locations, with the exception of areas near
Figure 10: Normalized error distribution among the
working environment of the growing robot.
the edges. This observation of increased error at the
periphery could potentially be attributed to the con-
strained size of the simulated vine robot, which was
limited to five meters.
4.3
Varying goal, obstacle-aware
In the final series of experiments, the DQN agent
underwent extensive training, consisting of 2 million
steps, within an environment that included a fixed
obstacle with a radius of ro = 0.5 meters, located
at coordinates (1, 2). Concurrently, the goal’s posi-
tion was dynamically altered throughout the train-
ing, with a 10% probability of being randomly relo-
cated within the environmental boundaries. Figure
11 illustrates the agent’s progressive learning curve,
showcasing an efficient reduction in the number of
steps required to reach the goal while simultaneously
maximizing the accumulated rewards.
This training efficacy was further analyzed under
two distinct learning rate scenarios, α1 = 0.01 and
α2 = 0.001, as demonstrated in Figure 11. The com-
parative analysis suggests that a lower learning rate
tends to enhance the training performance, poten-
tially leading to a more precise and refined learn-
ing outcome. However, it’s important to note that
this improved performance might come at the cost
of increased computational resources.
This trade-
off between learning rate and computational demand
is a crucial consideration in the optimization of the
DQN training process, particularly in complex en-
vironments where obstacle navigation and dynamic
goal-seeking are key factors.
During the testing phase, the proficiency of the
DQN agent was rigorously evaluated through a se-
ries of 100 trials, wherein it was tasked to navigate
to randomly set goals within a maximum limit of 200
time steps. The performance outcomes of these trials
are comprehensively visualized in the histograms pre-
sented in Figure 12, focusing on two key metrics: the
number of steps taken and the accumulated rewards.
The data illustrates that in approximately 75% of
the trials, the robot successfully accrued positive re-
wards ranging between 500 and 1000. This result in-
dicates a high level of efficiency in reaching the goals.
Additionally, it was observed that the majority of
10
these successful trials were completed within 50 steps,
further underscoring the agent’s effectiveness.
However, it is noteworthy that in about 25% of the
trials, the robot failed to reach the goal within the
stipulated 200 steps. This failure could be attributed
to a couple of factors: Firstly, the random goal lo-
cations might occasionally be generated within the
obstacle’s space, rendering them physically inaccessi-
ble. Secondly, the goals may be positioned at distant
locations in the environment, posing a challenge for
the robot to reach them within the 200-step limit.
To mitigate this issue and decrease the failure rate,
a couple of strategies could be implemented: One ap-
proach would be to modify the goal generation algo-
rithm to ensure that goals are not placed within or
too close to the obstacle’s location.
Alternatively,
extending the time limit beyond 200 steps could pro-
vide the robot with additional leeway to reach more
distantly placed goals. Either of these adjustments
could enhance the overall success rate of the DQN
agent in effectively reaching the goals across a vari-
ety of environmental conditions.
Figure 13 depicts a specific testing scenario for the
DQN agent, illustrating a strategic navigation task
involving the vine robot, marked with red indicators,
and an obstacle, represented by a blue circle. This
scenario demonstrates the robot’s ability to exploit
the presence of the obstacle in order to reach a goal
that is otherwise challenging to access. The figure se-
quentially portrays the robot’s movement across dif-
ferent time steps, highlighting its adaptive navigation
strategy.
A key observation from this scenario is the alter-
ation in the robot’s shape upon encountering the ob-
stacle, deviating from the constant curvature model
initially assumed. This deviation is not just a con-
sequence of the robot’s interaction with the obsta-
cle but is also strategically advantageous. The vine
robot’s inherent compliance, a fundamental charac-
teristic of soft robotics, is effectively utilized here to
navigate around the obstacle. This flexibility allows
the robot to mold its path and shape in response to
environmental constraints, showcasing an advanced
level of adaptability.
The scenario illustrated in Figure 13 exemplifies
the practical benefits of the robot’s compliance in
Figure 11: The training progress in terms of the num-
ber of steps and the accumulated rewards of the DQN
agent for commanding the vine robot to reach a vary-
ing goal while considering the interaction with obsta-
cles.
Figure 12: The histogram of the DQN agent perfor-
mance in terms of the number of steps and the accu-
mulated rewards in the varying goal obstacle-aware
scenario.
real-world applications. It demonstrates the robot’s
capacity to dynamically adjust its form and tra-
jectory in complex environments, leveraging obsta-
cles not as hindrances, but as aids in navigating to-
wards difficult-to-reach goals. This ability to intel-
ligently interact with and utilize environmental fea-
tures underscores the sophistication and potential of
the DQN-guided navigation strategy in soft robotics.
5
Conclusion
In this research a Deep Q Network (DQN)-based
navigation approach is implemented for a soft vine-
growing robot resulting in significant insights into
the capabilities and adaptability of this technique
11
-1
-0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
x
0
0.5
1
1.5
2
2.5
3
3.5
4
y
(a) t = 0s
-1
-0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
x
0
0.5
1
1.5
2
2.5
3
3.5
4
y
(b) t = 1.6s
-1
-0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
x
0
0.5
1
1.5
2
2.5
3
3.5
4
y
(c) t = 3.2s
Figure 13: The trained DQN agent successfully commands the vine growing robot to reach the goal (repre-
sented in a black cross) while considering the interaction with the obstacle located at (1, 2).
in environments with obstacles.
Through a series
of meticulously designed experiments, the study has
demonstrated the proficiency of the trained DQN
agent in guiding the robot to effectively reach des-
ignated goals, even in scenarios with challenging ob-
stacle placements.
Particularly notable is the robot’s ability to nav-
igate around and utilize obstacles as part of its
pathfinding strategy.
This scenario illustrated the
robot’s sophisticated interaction with the environ-
ment, where it skillfully adapted its shape in response
to obstacles, deviating from the constant curvature
model. This adaptability, facilitated by the robot’s
inherent compliance, proved to be advantageous in
navigating through and leveraging the environment
to reach difficult goals.
The
methodology
implemented
in
this
study
adopts a discrete set of actions to accomplish the nav-
igation task of the vine growing robot. This approach
is characterized by its simplicity and ease of imple-
mentation, as it allows the robot to choose from a
predefined set of actions at each step. However, this
discrete action space may limit the robot’s ability to
perform fine-grained movements, which can be cru-
cial in tasks requiring high precision.
As a natural progression of this research, it is es-
sential to explore and analyze how this discrete ac-
tion space approach compares with continuous space
learning techniques.
Continuous action spaces, as
employed in algorithms like Asynchronous Advan-
tage Actor-Critic (A3C) [25] and Deep Deterministic
Policy Gradient (DDPG) [26], offer a broader range
of potential actions at each step. This can lead to
more nuanced and precise control strategies, poten-
tially enhancing the robot’s performance in complex
tasks.
References
[1] K. Leibrandt, C. Bergeles, and G.-Z. Yang,
“Concentric tube robots:
Rapid, stable path-
planning and guidance for surgical use,” IEEE
Robotics & Automation Magazine, vol. 24, no. 2,
pp. 42–53, 2017.
[2] G. Brantner and O. Khatib, “Controlling ocean
one:
Human–robot collaboration for deep-sea
manipulation,” Journal of Field Robotics.
[3] R. J. Webster III and B. A. Jones, “Design and
kinematic modeling of constant curvature con-
tinuum robots:
A review,” The International
Journal of Robotics Research, vol. 29, no. 13, pp.
1661–1683, 2010.
[4] J. D. Greer, L. H. Blumenschein, A. M. Oka-
mura, and E. W. Hawkes, “Obstacle-aided nav-
igation of a soft growing robot,” in 2018 IEEE
12
International Conference on Robotics and Au-
tomation (ICRA).
IEEE, 2018, pp. 1–8.
[5] I. A. Seleem, S. F. Assal, H. Ishii, and H. El-
Hussieny, “Guided pose planning and track-
ing for multi-section continuum robots consid-
ering robot dynamics,” IEEE Access, vol. 7, pp.
166 690–166 703, 2019.
[6] P. Liljeb¨ack, K. Y. Pettersen, Ø. Stavdahl,
and J. T. Gravdahl, “A review on modeling,
implementation, and control of snake robots,”
Robotics and Autonomous Systems,
vol. 60,
no. 1, pp. 29–40, 2012.
[7] E. Del Dottore, A. Sadeghi, A. Mondini, V. Mat-
toli, and B. Mazzolai, “Toward growing robots:
A historical evolution from cellular to plant-
inspired robotics,” Frontiers in Robotics and AI,
vol. 5, p. 16, 2018.
[8] H. Tsukagoshi, A. Kitagawa, and M. Segawa,
“Active hose:
An artificial elephant’s nose
with maneuverability for rescue operation,” in
Robotics and Automation, 2001. Proceedings
2001 ICRA. IEEE International Conference on,
vol. 3.
IEEE, 2001, pp. 2454–2459.
[9] K. Isaki, A. Niitsuma, M. Konyo, F. Take-
mura, and S. Tadokoro, “Development of an ac-
tive flexible cable by ciliary vibration drive for
scope camera,” in Intelligent Robots and Sys-
tems, 2006 IEEE/RSJ International Conference
on.
IEEE, 2006, pp. 3946–3951.
[10] D. Mishima, T. Aoki, and S. Hirose, “Devel-
opment of pneumatically controlled expandable
arm for search in the environment with tight ac-
cess,” in Field and Service Robotics.
Springer,
2003, pp. 509–518.
[11] A.
Sadeghi,
A.
Mondini,
E.
Del
Dottore,
V. Mattoli, L. Beccai, S. Taccola, C. Lucarotti,
M. Totaro, and B. Mazzolai, “A plant-inspired
robot with soft differential bending capabilities,”
Bioinspiration and Biomimetics, vol. 12, no. 1,
p. 015001, 2017.
[12] A. Sadeghi, E. Del Dottore, A. Mondini, and
B. Mazzolai, “Passive morphological adapta-
tion for obstacle avoidance in a self-growing
robot produced by additive manufacturing,”
Soft Robotics, vol. 7, no. 1, pp. 85–94, 2020.
[13] E. W. Hawkes, L. H. Blumenschein, J. D. Greer,
and A. M. Okamura, “A soft robot that navi-
gates its environment through growth,” Science
Robotics, vol. 2, no. 8, p. eaan3028, jul 2017.
[14] L. H. Blumenschein, A. M. Okamura, and E. W.
Hawkes, “Modeling of bioinspired apical ex-
tension in a soft robot,” in Conference on
Biomimetic and Biohybrid Systems.
Springer,
2017, pp. 522–531.
[15] H. El-Hussieny, U. Mehmood, Z. Mehdi, S.-G.
Jeong, M. Usman, E. W. Hawkes, A. M. Okar-
nura, and J.-H. Ryu, “Development and evalua-
tion of an intuitive flexible interface for teleoper-
ating soft growing robots,” in 2018 IEEE/RSJ
International Conference on Intelligent Robots
and Systems (IROS).
IEEE, 2018, pp. 4995–
5002.
[16] M. M. Coad, L. H. Blumenschein, S. Cutler,
J. A. R. Zepeda, N. D. Naclerio, H. El-Hussieny,
U. Mehmood, J.-H. Ryu, E. W. Hawkes, and
A. M. Okamura, “Vine robots: Design, teleoper-
ation, and deployment for navigation and explo-
ration,” arXiv preprint arXiv:1903.00069, 2019.
[17] E.-H. Haitham, S.-G. Jeong, and J.-H. Ryu,
“Dynamic modeling of a class of soft growing
robots using euler-lagrange formalism,” in Soci-
ety of Instrument and Control Engineers (SICE)
2019. IEEE, Society of Instrument and Control
Engineers (SICE), 2019.
[18] H. El-Hussieny, I. A. Hameed, and A. B. Zaky,
“Plant-inspired soft growing robots: A control
approach using nonlinear model predictive tech-
niques,” Applied Sciences, vol. 13, no. 4, p. 2601,
2023.
[19] J. D. Greer, T. K. Morimoto, A. M. Okamura,
and E. W. Hawkes, “A soft, steerable contin-
13
uum robot that grows via tip extension,” Soft
robotics, 2018.
[20] B. A. Jones and I. D. Walker, “Kinematics for
multisection continuum robots,” IEEE Transac-
tions on Robotics, vol. 22, no. 1, pp. 43–55, 2006.
[21] K. Ashwin, S. K. Mahapatra, and A. Ghosal,
“Profile and contact force estimation of cable-
driven continuum robots in presence of obsta-
cles,” Mechanism and Machine Theory, vol. 164,
p. 104404, 2021.
[22] V. Mnih, K. Kavukcuoglu, D. Silver, A. A.
Rusu, J. Veness, M. G. Bellemare, A. Graves,
M. Riedmiller, A. K. Fidjeland, G. Ostrovski
et al., “Human-level control through deep rein-
forcement learning,” nature, vol. 518, no. 7540,
pp. 529–533, 2015.
[23] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves,
I. Antonoglou, D. Wierstra, and M. Riedmiller,
“Playing atari with deep reinforcement learn-
ing,” arXiv preprint arXiv:1312.5602, 2013.
[24] M. D. Zeiler, “Adadelta: an adaptive learning
rate method,” arXiv preprint arXiv:1212.5701,
2012.
[25] T. Moore and D. Stouch, “A generalized ex-
tended kalman filter implementation for the
robot operating system,”
in Intelligent au-
tonomous systems 13.
Springer, 2016, pp. 335–
348.
[26] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess,
T. Erez, Y. Tassa, D. Silver, and D. Wierstra,
“Continuous control with deep reinforcement
learning,”
arXiv
preprint
arXiv:1509.02971,
2015.
14
","nanPrior efforts in designing long, flexible robots suitable for tight spaces include the “Active Hose” by Tsukagoshi et al., a multi-degree-of-freedom robot designed for search and rescue applications. Isaki et al. developed a flexible, extended cable with a camera for exploration in narrow areas, and the “Slime Scope,” a pneumatically driven soft arm, was created for use in rubble environments. However, these designs often require moving the entire robot body, leading to significant friction with the environment."
"Pseudo-relevance feedback (PRF) can enhance average re-trieval effectiveness over a sufficiently large number of queries. However, PRF often introduces a drift into the original information need, thus hurting the retrieval effectiveness of several queries. While a selective ap-plication of PRF can potentially alleviate this issue, previous approaches have largely relied on unsupervised or feature-based learning to deter-mine whether a query should be expanded. In contrast, we revisit the problem of selective PRF from a deep learning perspective, presenting a model that is entirely data-driven and trained in an end-to-end manner.","The keywords that a user enters as query to a search engine are often insufficient to express the user’s information need, resulting in a lexical gap between the text in the query and the relevant documents [2]. Standard pseudo-relevance feedback (PRF) methods, such as the relevance model [19] and its variants [14,36,35,26], can overcome this problem and ultimately yield improvements in retrieval effec-tiveness. Generally speaking, PRF methods are designed to enrich a user’s initial query with distinctive terms from the top-ranked documents [34,27,43]. Despite the demonstrated success of PRF in improving retrieval effectiveness, a number of studies have identified certain limitations of this strategy [3,25,9,13]. For the most part, these limitations share a common theme: there is no consistent PRF setting that works well across a wide range of queries; to put in simple words, one size does not fit all. Figure 1 illustrates such a situation, where nearly 38.9% of queries from TREC DL’20 topic set are penalized as a result of PRF.","Given a set of queries Q = {Q1, . . . , Qn}, a standard relevance feedback model M uses the information from the top-retrieved documents of each query to enrich its representation, i.e., M : Q 7→ ∆M(Q). Consequently, each query Q ∈ Q is transformed to an enriched representation ∆M(Q), which is then used either for re-ranking the initial list, or to execute a second-step retrieval.
Unlike the standard PRF setting, a decision-based selective PRF framework first applies a decision function, θ : Q 7→ {0, 1}, which outputs a Boolean to indicate if the retrieval results for Q is likely to be improved after application of PRF. As per our proposal, the overall PRF process on the set of queries Q does not simply replace each query Q with its enriched form ∆M(Q). Rather, it makes use of the function θ(Q) for each query Q to decide whether to output the initial ranked list or to make use of the enriched query representation ∆M(Q), as obtained by a PRF model M (leading to either re-ranking the initial list or re-retrieving a new list via a second stage retrieval). The top-k ranked list of documents, Lk(Q) = {DQ1, . . . , DQk }, retrieved for a query Q, in addition to being a function of the query Q itself, is thus also a function of i) the feedback model M, ii) the enriched query representation ∆M(Q), and iii) the decision function θ, i.e.,
Lk(Q) = (
•	σ(Q),	if θ(Q) = 0
•	σ(∆M(Q)),	if θ(Q) = 1,
)","Main observations. The key findings of our experiments are reported in Table 2. We observe that the accuracy of the decisions is quite satisfactory, even for the unsupervised threshold-based approaches. The results also indicate that more accurate PRF decisions usually lead to an increase in retrieval effectiveness.
For RQ1, we find that supervised selective PRF approaches yield improved results over their unsupervised counterparts. Of particular interest is the fact that a data-driven approach (as per our proposal in this paper) outperforms the feature-based approach LR-SRF [25], which answers RQ1 in the affirmative.
In relation to RQ2, we see that a soft combination of the initial and the feed-back lists via a confidence-based calibration (Deep-SRF-BERT-R2F2) improves results further.
An interesting finding is that the SRF decision function trained on RLM on a set of queries generalises well not only for a different set of queries (the test set), but also across different feedback models. This suggests that the queries which improve with RLM also improve with other feedback models, such as GRF or ColBERT-PRF. This can be seen from the GRF and the ColBERT-PRF group of results for both BM25 and MonoT5. This entails that the SRF based decision function does not need to be trained for specific PRF approaches, which makes it more suitable to use in a practical setup, affirming RQ3.","In this paper, we proposed a selective relevance feedback framework that includes a data-driven supervised neural approach to optimize retrieval effectiveness by applying feedback on queries in a selective fashion. By testing this approach using multiple PRF models over sparse and dense architectures, we observed that it performs favorably compared to alternative strategies, approaching the performance of an oracle system.
This work opens the door for interesting future studies. Although our method is effective, it requires executing PRF to gauge result quality. Exploring tech-niques to determine the necessity of the PRF step could reduce computational costs for queries where PRF is ultimately ignored. Further work could also ex-amine strategies for predicting the parameters of PRF itself, such as the number of relevant documents.",A Deep Learning Approach for Selective Relevance Feedback,"Suchana Datta, Debasis Ganguly, Sean MacAvaney, Derek Greene","A Deep Learning Approach for Selective
Relevance Feedback
Suchana Datta1[0000−0001−9220−6652], Debasis Ganguly2[0000−0003−0050−7138],
Sean MacAvaney2[0000−0002−8914−2659], and Derek Greene1[0000−0001−8065−5418]
1 University College Dublin, Ireland
2 University of Glasgow, United Kingdom
suchana.datta@ucdconnect.ie, debasis.ganguly@glasgow.ac.uk,
sean.macavaney@glasgow.ac.uk, derek.greene@ucd.ie
Abstract. Pseudo-relevance feedback (PRF) can enhance average re-
trieval effectiveness over a sufficiently large number of queries. However,
PRF often introduces a drift into the original information need, thus
hurting the retrieval effectiveness of several queries. While a selective ap-
plication of PRF can potentially alleviate this issue, previous approaches
have largely relied on unsupervised or feature-based learning to deter-
mine whether a query should be expanded. In contrast, we revisit the
problem of selective PRF from a deep learning perspective, presenting a
model that is entirely data-driven and trained in an end-to-end manner.
The proposed model leverages a transformer-based bi-encoder architec-
ture. Additionally, to further improve retrieval effectiveness with this se-
lective PRF approach, we make use of the model’s confidence estimates
to combine the information from the original and expanded queries. In
our experiments, we apply this selective feedback on a number of dif-
ferent combinations of ranking and feedback models, and show that our
proposed approach consistently improves retrieval effectiveness for both
sparse and dense ranking models, with the feedback models being either
sparse, dense or generative.
1
Introduction
The keywords that a user enters as query to a search engine are often insufficient
to express the user’s information need, resulting in a lexical gap between the text
in the query and the relevant documents [2]. Standard pseudo-relevance feedback
(PRF) methods, such as the relevance model [19] and its variants [14,36,35,26],
can overcome this problem and ultimately yield improvements in retrieval effec-
tiveness. Generally speaking, PRF methods are designed to enrich a user’s initial
query with distinctive terms from the top-ranked documents [34,27,43]. Despite
the demonstrated success of PRF in improving retrieval effectiveness, a number
of studies have identified certain limitations of this strategy [3,25,9,13]. For the
most part, these limitations share a common theme: there is no consistent PRF
setting that works well across a wide range of queries; to put in simple words, one
size does not fit all. Figure 1 illustrates such a situation, where nearly 38.9% of
arXiv:2401.11198v1  [cs.IR]  20 Jan 2024
QID
Relative changes in AP 
-1
0
1
2
3
4
67316
258062
1131069
555530
1121353
156498
940547
673670
1136047
336901
583468
141630
332593
1127540
1071750
330975
174463
1106979
1113256
390360
169208
1064670
23849
135802
1030303
1043135
121171
1136043
701453
1122767
324585
1105792
1109707
1136962
730539
47210
911232
997622
42255
1133579
914916
1132532
768208
1110678
877809
640502
938400
1037496
118440
405163
1051399
1108651
1115210
1116380
Fig. 1: Relative changes in AP, i.e., (AP(post-fdbk) - AP(pre-fdbk))/AP(pre-fdbk), for
TREC DL’20 queries. We observe that many queries are negatively impacted by PRF
(bars below the x-axis).
queries from TREC DL’20 topic set are penalized as a result of PRF. It has been
shown that not all documents contribute equally well to PRF, as certain doc-
uments may impair retrieval effectiveness when used to expand a query [20,1].
This can even be true when relevant documents are used to enrich a query’s
representation [39]. It has also been observed that some queries are amenable to
more aggressive query expansion, while others work better with more conserva-
tive settings [32]. Moreover, not all terms might contribute equally well in terms
of enriching the representation of a query [4,16], which suggests that a selective
approach to PRF can potentially improve the overall IR effectiveness.
Rather than following the previous approaches on adapting the number of
feedback terms [32] or attempting to choose a robust subset of documents for
PRF [20,1], we rather focus on solving the more fundamental decision question
of “whether or not to apply PRF for a given query” [9,25] with the help of
a supervised data-driven approach. We hypothesise that selectively applying
feedback to only those queries that are amenable to PRF can improve the overall
retrieval effectiveness by avoiding query drift in cases where feedback would not
be beneficial. Our idea is depicted in Figure 2.
The main novelty of our proposed selective pseudo relevance feedback (SRF)
approach is that in contrast to existing work on selective PRF, we propose a
data-driven supervised neural model for predicting which queries are conducive
to PRF. More specifically, during the training phase we make use of the rel-
evance assessments to learn a decision function that, given the query and the
top-retrieved set of documents both with and without feedback, predicts whether
it is useful to apply PRF. During the inference phase, we make use of only a
part of the shared parameter network which, given a query and its top-retrieved
document set, predicts whether PRF is to be applied (schematically illustrated
in Figure 2). This way of inference reduces computational costs for queries where
PRF should eventually be ignored.
A key advantage of our SRF approach is that it can be applied to the output
ranked list obtained by any retrieval model, ranging from sparse models (e.g.,
BM25, LM-Dir etc.) to dense ones (e.g., MonoBERT [31]). Moreover, in the
SRF workflow it also is possible to use any PRF model to enrich a query’s
Fig. 2: A schematic diagram of selective feedback. The main contribution of this paper
is a supervised data-driven approach towards realising the decision function.
representation, ranging from sparse models (e.g., RLM [19]) to dense ones (e.g.,
ColBERT-PRF [41]) to even generative ones (e.g., GRF [26]).
2
Related Work
The evolution of relevance feedback in IR spans from traditional query expansion
models [32,4] to cluster-based feedback document selection [20,16]. While prior
research has considered both unsupervised selective feedback [9] and feature-
driven methods [25], we introduce a data-driven neural strategy for selective
relevance feedback. Several existing methods, both supervised and unsuper-
vised, hinge on decision-based relevance feedback. One unsupervised approach
uses Query Performance Prediction (QPP) scores [38,47,10,37,15], which we in-
clude as a baseline. The higher the QPP score, the greater the chance of identi-
fying relevant documents at the top rank positions with the initial query. How-
ever, high variances in retrieval status values, as seen in neural re-rankers like
MonoBERT [31], can make QPP scores deceptive. To avoid such heuristics, our
method focuses solely on query terms and the documents retrieved by that query
in order to learn the selection function.
PRF on and for Dense Retrieval. Recently, the community has seen a sig-
nificant interest in feedback for dense retrieval to boost performance. Precursors
to dense feedback models made use of word embeddings for PRF, e.g., KDERLM
[35] which proposed a generalised RLM with word embeddings, and PRF-NMF
[45], which leveraged matrix factorisation to bridge the semantic gap between
terms from a query and its top-retrieved documents.
The study by [44] explored relevance feedback principles within dense re-
trieval models. Li et al. [22] analyzed feedback signal quality, comparing tradi-
tional models like Rocchio [34] with dense retrievers like ANCE-based retrievers
[42], finding the latter more resilient. Representation models, such as ColBERT
[18], can allow us to append additional embedding layers to the query repre-
sentation, as demonstrated by [40]. This method employed contextualized PRF
to cluster and rank feedback document embeddings in order to select suitable
expansion embeddings, thus improving document ranking. In other work, [48]
leveraged implicit feedback from historical clicks for relevance feedback in dense
retrieval. The authors introduced counterfactual-based learning-to-rank, show-
ing that historic clicks can be highly informative in terms of relevance feedback.
Lastly, [23] proposed the idea of fusing feedback signals from both sparse and
dense retrievers in the context of PRF.
More recently, PRF on dense IR models has garnered significant interest
[21,29,46,41]. The concept of ‘dense for PRF’ was first emphasized in [28], which
proposed a reinforcement-based learning algorithm designed to explore and ex-
ploit various retrieval metrics, aiming to learn an optimized PRF function. With
the recent success of LLMs, [26] proposed a generative feedback method (GRF)
that makes use of LLM generated long-form texts instead of first pass retrieved
results to build a probabilistic feedback model. In contrast, our work aims to
develop a generic PRF strategy that does not apply feedback blindly, but rather
learns a selection function in a supervised manner to analyze the suitability of
relevance feedback for each query irrespective of sparse or generative PRF.
Selective PRF. Prior work on selective PRF has considered either fully unsu-
pervised approaches [9] or feature-based supervised approaches [25] for selective
relevance feedback (SRF). The former makes use of query performance predic-
tion (QPP) based measures to predict if a query should be expanded, where
the decision depends on whether the QPP score exceeds a given threshold. On
the other hand, existing supervised approaches first represent each query as a
bag of characteristic features derived from its top-retrieved set of documents.
A classifier is then trained on these features to predict whether or not a query
should be expanded [25].
3
Model Description
3.1
A Generic Decision Framework for PRF
Given a set of queries Q = {Q1, . . . , Qn}, a standard relevance feedback model
M uses the information from the top-retrieved documents of each query to enrich
its representation, i.e., M : Q 7→ ϕM(Q). Consequently, each query Q ∈ Q is
transformed to an enriched representation ϕM(Q), which is then used either for
re-ranking the initial list, or to execute a second-step retrieval.
Unlike the standard PRF setting, a decision-based selective PRF framework
first applies a decision function, θ : Q 7→ {0, 1}, which outputs a Boolean to
indicate if the retrieval results for Q is likely to be improved after application
of PRF. As per our proposal, the overall PRF process on the set of queries Q
does not simply replace each query Q with its enriched form ϕM(Q). Rather, it
makes use of the function θ(Q) for each query Q to decide whether to output the
initial ranked list or to make use of the enriched query representation ϕM(Q),
as obtained by a PRF model M (leading to either re-ranking the initial list
or re-retrieving a new list via a second stage retrieval). The top-k ranked list
of documents, Lk(Q) = {DQ
1 , . . . , DQ
k }, retrieved for a query Q, in addition to
being a function of the query Q itself, is thus also a function of i) the feedback
model M, ii) the enriched query representation ϕM(Q), and iii) the decision
function θ, i.e.,
Lk(Q) =
(
σ(Q),
if θ(Q) = 0
σ(ϕM(Q)),
if θ(Q) = 1,
(1)
where σ(Q) denotes a retrieval model, e.g., BM25, that outputs an ordered set
of k documents sorted by the similarity scores.
Previous approaches have explored the use of both unsupervised and super-
vised approaches for addressing this decision problem. We now briefly explain
both strategies in our own context.
Unsupervised decision function. An unsupervised approach, such as [9],
applies a threshold parameter on a QPP estimator function, θQPP : Q 7→ [0, 1].
More concretely, if the predicted QPP score is lower than the threshold param-
eter, it is likely to indicate that the retrieval performance for the query has
scopes for further improvement and subsequently PRF is applied for this query.
Formally speaking, the decision function of an unsupervised approach takes the
form
θ(Q)
def
== I(θQPP < τ),
(2)
where τ ∈ [0, 1] is the threshold parameter.
Supervised decision function. In the supervised approach, the decision func-
tion also depends on the enriched query representation and its top-retrieved doc-
uments. More precisely, a supervised PRF decision is a parameterized function of
features of i) the query Q, ii) its top-retrieved documents Lk(Q), iii) the enriched
query ϕM(Q), and iv) its top-retrieved set Lk(ϕM(Q)) [25]. The training process
itself makes use of a set of queries Qtrain for which ground-truth indicator labels
are computed by evaluating the relative effectiveness obtained with the original
query vs. the enriched query with the help of available relevance assessments.
Formally,
y(Q) = I(AP(ϕM(Q)) > AP(Q)),
(3)
where AP(Q) denotes the average precision of a query Q ∈ Qtrain. The indicator
values of y(Q) are used to learn the parameters of a classifier function to yield
a supervised version of the decision function θ:
θ(Q)
def
== ζ · zQ,ϕM(Q), where θ(Q) ≈ argmin
ζ
X
Q′∈Q′train
(y(Q′) − ζ · zQ′,ϕM(Q′))2. (4)
In Equation 4, ζ represents a set of learnable parameters, with zQ′,ϕM(Q′) denot-
ing a set of features extracted from both the original query Q′ and the enriched
query ϕM(Q′) along with the features from their top-retrieved set of documents
Lk(Q′) and Lk(ϕM(Q′)). The variable y(Q′), as per the definition of y(Q), de-
notes the ground-truth indicating if PRF should be applied for Q′. The optimal
parameter vector ζ, as learned from a training set of queries Qtrain (Equation 4)
is then used to predict the decision for any new query Q. The features we use
are described later in the paper in Section 4.2.
3.2
Transformer-based Encoding for PRF Decision
We now describe a data-driven approach for learning the decision function with
deep neural networks. Instead of making use of a specific set of extracted features
as used in the QPP model in [11], the learning objective of a transformer-based
PRF model makes use of the terms present in the documents and the queries.
As with Equation 4, we make use of both the content of the original query Q
and its enriched form ϕM(Q), along with their top-retrieved sets. More formally,
θ(Q)
def
== ζ · (E(Q, DQ
1 , . . . , DQ
k ) ⊕ E(ϕM(Q), DϕM(Q)
1
, . . . , DϕM(Q)
k
)),
(5)
where θ(Q) is learned by computing
argmin
ζ
X
Q′∈Q′train
(y(Q′) − ζ · (E(Q′, Lk(Q′)) ⊕ E(ϕM(Q′), Lk(ϕM(Q′))))2.
(6)
In Equation 6, E is a parameterized function for encoding the interaction between
a query Q and its top-retrieved documents, Lk(Q). This encoding function, gen-
erally speaking, maps a query (a sequence of query terms) and a sequence of
documents (which are themselves sequences of their constituent terms) into a
fixed length vector, i.e., E : Q, Lk 7→ Rp (p an integer, e.g., for BERT embed-
dings p = 768). Here ⊕ indicates an interaction operation (e.g., a merge layer in
a neural network) between the query-document encodings corresponding to the
original query and the enriched one.
The transformer-based encoding uses the BERT architecture which takes as
input the contextual embeddings of the terms for each pair comprising a query
Q and its top-retrieved document DQ
i
∈ Lk(Q). The 768 dimensional ‘[CLS]’
representations of each query-document pair is then encoded with LSTMs as a
realisation of the encoded representation of a query and its top-retrieved set,
i.e., to define E(Q, Lk(Q)) as per the notation of Equation 6. We further obtain
a BERT-based encoding of the expanded query ϕM(Q) and its top-retrieved set
and then merge the two representations before passing them through a feed-
forward network. More formally,
E( ¯Q, Lk( ¯Q)) = LSTM(BERT( ¯Q, D
¯
Q
1 )[CLS], . . . , BERT( ¯Q, D
¯
Q
k )[CLS]).
(7)
The variable ¯Q ∈ {Q, ϕM(Q)}, i.e., in one branch of the network it corresponds
to the original query, whereas in the other it corresponds to the expanded one.
Figure 3 shows the transformer-specific implementation of the encoding function.
The set of learnable parameters ζ in this case comprises of the LSTM and the
Fig. 3: Training of a transformer based query-document architecture with shared pa-
rameters for selective PRF. During inference, only the left part of the network is used
to output whether to apply PRF or not for a given query.
fully connected (dense) layer parameters, as shown in Figure 3. We name this
particular model Deep-SRF-BERT (Deep Selective Relevance Feedback with
the use of BERT transformers).
Model Inference. During inference, only the part corresponding to the original
query and its top-retrieved set of documents is used to predict the output variable
(a sigmoid) which if higher than 0.5 indicates that PRF should be applied.
3.3
Model Confidence-based PRF Calibration
Prior work has applied confidences of prediction models to improve retrieval
effectiveness [5]. In our work, we use the uncertainties in the prediction of the
decision function to further improve search results. Rather than only reporting
either results with or without relevance feedback, we make use of the confidence
of the decision function θ(Q) to combine the results from the two lists – one
without feedback and the other with feedback. Specifically, if the supervised
model outlined in Section 3.1 is decisive in its choice between Lk(Q) (original
query retrieved list) and Lk(ϕM(Q)) (the list retrieved with the expanded query),
then one of the rankings is expected to dominate over the other. However, when
the model θ(Q) itself is not confident about the prediction, we can potentially
achieve better results if we ‘meet somewhere in the middle’.
Formally, we propose a rank-fusion based method, where the fusion weights
are obtained from the predictions of the PRF decision model θ(Q). The predicted
value θ(Q) being a sigmoid represents the probability of classifying the decision
into one of the two outcomes - the closer θ(Q) is to 0, the higher is the model’s
confidence in not applying feedback, and similarly the closer θ(Q) is to 1, the
higher is the model’s confidence in applying PRF. The predicted value of θ(Q) ∈
[0, 1] can thus be used as weights to fuse the two different ranked lists, i.e., the
fusion score σF (Q, D) of a document D for a query Q is given by
σF (Q, D) =
1 − θ(Q)
Rank(D, Lk(Q)) +
θ(Q)
Rank(D, Lk(ϕM(Q))),
(8)
where the notation Rank(D, L) denotes the rank of a document D in a list L.
If D /∈ L, then the rank is set to a large value ℵ(> k), which in our exper-
iments was set to 1000 (higher than all possible values of k we experimented
with). For values of θ(Q) close to 0.5 (the most uncertainty in prediction), the
fusion-based approach leads to a more uniform contribution from both the lists.
In contrast, a value of θ(Q) close to 0 ensures that the majority of the score
contribution comes from the original query (because 1 − θ(Q) >> θ(Q)), and
a similar argument applies for θ(Q) → 1, in which case the major contribution
comes from the second term in the right-hand side of Equation 8.
4
Evaluation
4.1
Research Questions
Since a primary contribution of this paper is the idea of applying a fully data-
driven approach, the first research question that we investigate is whether a shift
from the existing feature-based approach for selective PRF to a data-driven one
does indeed result in improved retrieval effectiveness. Therefore, we formulate
our first research question as follows.
- RQ1: Does SRF lead to overall improvements in IR effectiveness over non-
selective and other baseline approaches?
Our second research question aims to investigate whether the model predic-
tion uncertainty-based fusion of the two ranked lists – one retrieved with the
original query and the other with the expanded one, can potentially improve the
retrieval effectiveness further.
- RQ2: Can we use the confidence estimates from our selective PRF model for a
soft selection of information from both pre-feedback and post-feedback sources
to further improve IR effectiveness?
In our third research question, the aim is to investigate how effectively the
selection strategy in PRF transfers across different feedback approaches, i.e.,
training the SRF approach only once on a PRF model (e.g., RLM), and then
apply the decision model on other PRF models (e.g., ColBERT-PRF).
- RQ3: Does selection effectively transfers the learning across different PRF
approaches?
4.2
Methods Investigated
We consider a range of unsupervised and supervised methods, described below.
Some baselines refer to existing methods, while others are extensions of alter-
native approaches to allow us to provide a fair comparison, such as by using a
more recent QPP method instead of the originally-proposed clarity score [9].
PRF is a standard non-selective relevance feedback model, namely the relevance
model (RLM) [19]. We use the RM3 version of the relevance model as reported
in [17], which is a linear combination of the weights of the original query model
and new expansion terms. In fact, we use RLM as one of the base PRF model M
which means that the standard RLM degenerates to a specific case of the generic
selective PRF framework of Equation 1 with θ(Q) = 1 ∀Q ∈ Q, i.e., when for
each query we use its enriched form ϕM(Q).
R2F2 refers to an adaptation of the Reciprocal Rank-based Fusion (RRF) [6], a
simple yet effective approach for combining the document rankings from multiple
IR systems. For our task, instead of combining ranked lists from two different
retrieval models, we merge the ranked lists of the original and the expanded
queries, i.e., Lk(Q) and Lk(ϕM(Q)) as per our notations. We name the adapted
method Reciprocal Rank Fusion-based Feedback (R2F2). Formally, the score for
document D after fusion is given by
σF (Q, D) =
1 − α
Rank(D, Lk(Q)) +
α
Rank(D, Lk(ϕM(Q))),
(9)
where, similar to Equation 8 Rank(D, L) denotes the rank of a document in a list
L (this being a large number ℵ if D /∈ L), and α ∈ [0, 1] is a linear combination
hyper-parameter that we adjust with grid search on each training fold. A lower
value of α puts more emphasis on the initial retrieval list, whereas a higher value
ensures that the feedback rank of a document contributes more. Equation 9 is a
special case of Equation 8 with a constant value of θ(Q) = α for each query Q.
QPP-SRF is an adaptation of the method proposed in [9], where the QPP
score of a query is used as estimate to decide if PRF should be applied for
that query (see θ(Q) in Section 3.1). The idea here is that a high QPP score is
already indicative of an effective retrieval performance, in which case, the method
avoids any further risk of potentially degrading the retrieval quality with query
expansion. We refer to this method as QPP-based selective relevance feedback
(QPP-SRF). The method requires a base QPP estimator to provide θQPP scores.
To choose the QPP estimator, we conducted a set of initial experiments
using several standard unsupervised QPP approaches. The recently introduced
supervised QPP method qppBERT-PL [12] demonstrated the best downstream
retrieval effectiveness. Therefore, we report results of QPP-SRF combined with
qppBERT-PL, where training is conducted using the settings as reported in [12].
A key parameter for QPP-SRF is the threshold value τ (τ ∈ [0, 1]) which controls
the decision around whether PRF is applied or not. In our experiments we tune
Table 1: Summary of the data used in our experiments. The columns ‘ ¯
|Q|’ and ‘
¯
#Rel’
denote average number of query terms and average number of relevant documents.
Collection
#Docs
Topic Set
#Topics
¯
|Q|
¯
#Rel
MS MARCO Passage
8,841,823
MS MARCO Train
502,939
5.97
1.06
TREC DL’19
43
5.40
58.16
TREC DL’20
54
6.04
30.85
τ on the train folds. To ensure that the threshold can be applied for any QPP
estimate, we normalize the QPP estimates in the range [0, 1].
TD2F is an unsupervised selective feedback approach that is conceptually simi-
lar to QPP-SRF [9]. Rather than using a QPP method, it computes the difference
of the term weight distributions across the sets of documents retrieved with the
original and the expanded queries, i.e., the sets Lk(Q) and Lk(ϕM(Q)) as per
our notations introduced in Section 3.1. Formally,
θ(Q) =
1
|V |
X
t∈V
log P(t|Lk(Q)) − log P(t|Lk(ϕM(Q))),
(10)
where the set V denotes the vocabulary of the two lists, i.e., V
= VLk ∪
VLk(ϕM(Q)). As per [9], we set the feedback decision threshold τ to a value such
that over 95% of the queries satisfy the criterion that θ(Q) ≤ τ. We name this
method as Term Distribution Divergence based Feedback, or TD2F for short.
LR-SRF is the only existing supervised method that uses the query features,
along with their top-retrieved documents, to predict the PRF decision [25]. The
ground-truth labels for learning the decision function is obtained for a training
set of queries with existing relevance assessments, i.e. y(Q) = I(AP(ϕM(Q)) >
AP(Q)). The method then uses Equation 4 to train a feature-based logistic
regression classifier. In particular, the experiments reported in [25] used the
following features for training the logistic regression model: i) the clarity [10] of
top-retrieved documents, ii) the absolute divergence between the query model
Q and the relevance model [19], iii) the Jensen-Shannon divergence [24] between
the language model of the feedback documents, and iv) the clarity of the query
language model. We name this method as Regression-based Selective relevance
Feedback (LR-SRF).
Proposed methods In addition to conducting experiments with our proposed
model Deep-SRF-BERT (Figure 3), we also incorporate confidence-based cali-
bration (as per objective RQ2) with rank fusion (Equation 8 and 9), which we
denote by adding the suffix R2F23.
3 Implementation available at: https://github.com/suchanadatta/AdaptiveRLM.
git
4.3
Experimental Setup
Dataset and train-test splits. Our retrieval experiments are conducted on a
standard ad-hoc IR dataset, the MS MARCO passage collection [30]. The rele-
vance of the passages in the MS MARCO collection are more of personalized in
nature. A common practice is to use the TREC DL topic sets, which contains
depth-pooled relevance assessments on the passages of the MS MARCO collec-
tion. For TREC DL, we conduct experiments on a total of 97 queries from the
years 2019 and 2020 [7,8]. Table 1 provides an overview of the dataset.
We use a random sample of 5% of queries (constituting a total of about 40K
queries) to train the supervised models in our experiments, whereas evaluation
is conducted on the TREC DL (both ’19 and ’20) query sets. We use a small
sample from the training set since the training process requires executing a
feedback model (e.g., RLM) for all queries. Therefore, the model needs to learn
a task-specific encoding for each query-document pair, both for the original and
the expanded queries.
To investigate the generalisation of our selective feedback model, we employ
RLM as the feedback approach to train the decision function (Figure 3). During
inference, we employ three different PRF approaches, namely RLM, ColBERT-
PRF [41] and GRF [26] to test the effectiveness of selective feedback.
Parameter settings. A common parameter for all the methods is the number
of top-retrieved documents k used for the feedback process and also for training
the supervised PRF decision models. For each method we tune the k ∈ [5, 40] via
grid search on the training folds, and use the optimal value on the test fold. We
use the same approach to tune the parameter α in Equation 8, which controls the
importance of the feedback process for the rank-based fusion methods. For the
R2F2-based methods, we conduct a grid search for α in the set {0, 0.1, . . . , 1}.
The number of terms used for relevance feedback was tuned for the collection
and we use the optimal value across all the methods considered.
To obtain the initial retrieval list, we use both sparse and dense models. As
a sparse model, we employ BM25 [33] to retrieve the top-1000 results from MS
MARCO collection and a supervised neural model, namely, MonoT5 [31] which
operates by reranking the top-1000 of BM25. MonoT5 model was trained on the
MS MARCO training queries.
4.4
Results and Discussion
Main observations. The key findings of our experiments are reported in Table
2. We observe that the accuracy of the decisions is quite satisfactory, even for
the unsupervised threshold-based approaches. The results also indicate that more
accurate PRF decisions usually lead to an increase in retrieval effectiveness.
For RQ1, we find that supervised selective PRF approaches yield improved
results over their unsupervised counterparts. Of particular interest is the fact
that a data-driven approach (as per our proposal in this paper) outperforms the
feature-based approach LR-SRF [25], which answers RQ1 in the affirmative.
Table 2: Comparison of different SRF approaches on the TREC DL (2019 and 2020)
topic sets with BM25 and MonoT5 set as the initial retrieval models. MAP values
are computed for top-1000 documents. Paired t-test (p < 0.05) shows a significant
improvement of Deep-SRF over the best performing baselines (comparing bold-faced
results with the underlined ones).
BM25 (ϕ: RLM)
BM25 (ϕ: GRF)
BM25 (ϕ: ColBERT-PRF)
Methods
Accuracy MAP nDCG@10 Accuracy MAP nDCG@10 Accuracy MAP
nDCG@10
Baselines
No PRF
N/A
0.3766
0.5022
N/A
0.3766
0.5022
N/A
0.3766
0.5022
PRF
N/A
0.4321
0.5134
N/A
0.4883
0.6226
N/A
0.4514
0.6067
R2F2
N/A
0.4381
0.5140
N/A
0.5094
0.6332
N/A
0.4968
0.6184
QPP-SRF
0.7835
0.4400
0.5152
0.7844
0.5321
0.6667
0.7742
0.5238
0.6400
TD2F
0.7611
0.4392
0.5135
0.7580
0.4579
0.5900
0.7642
0.4910
0.6038
LR-SRF
0.7842
0.4411
0.5154
0.7784
0.5107
0.6512
0.7854
0.5254
0.6414
Ours
Deep-SRF-BERT
0.8081∗ 0.4705
0.5374
0.8093∗ 0.5654
0.6821
0.8165∗ 0.5631
0.6765
Deep-SRF-BERT-R2F2
0.4961
0.5486
0.5730
0.6839
0.5785
0.6873
Oracle
1.0000
0.5038
0.5528
1.0000
0.5876
0.6941
1.0000
0.5820
0.6936
MonoT5 (ϕ: RLM)
MonoT5 (ϕ: GRF)
MonoT5 (ϕ: ColBERT-PRF)
Methods
Accuracy MAP nDCG@10 Accuracy MAP nDCG@10 Accuracy MAP
nDCG@10
Baselines
No PRF
N/A
0.5062
0.6451
N/A
0.5062
0.6451
N/A
0.5062
0.6451
PRF
N/A
0.5081
0.6463
N/A
0.5200
0.6487
N/A
0.5297
0.6491
R2F2
N/A
0.5112
0.6484
N/A
0.5241
0.6494
N/A
0.5324
0.6502
QPP-SRF
0.7963
0.5189
0.6559
0.7871
0.5313
0.6604
0.7900
0.5419
0.6673
TD2F
0.7789
0.5071
0.6453
0.7670
0.4991
0.6403
0.7612
0.5179
0.5986
LR-SRF
0.7958
0.5180
0.6543
0.7980
0.5422
0.6628
0.7928
0.5500
0.6654
Ours
Deep-SRF-BERT
0.8152∗ 0.5306
0.6640
0.8160∗ 0.5529
0.6694
0.8067∗ 0.5624
0.6733
Deep-SRF-BERT-R2F2
0.5317
0.6659
0.5607
0.6719
0.5711
0.6746
Oracle
1.0000
0.5416
0.6786
1.0000
0.5722
0.6803
1.0000
0.5801
0.6821
In relation to RQ2, we see that a soft combination of the initial and the feed-
back lists via a confidence-based calibration (Deep-SRF-BERT-R2F2) improves
results further.
An interesting finding is that the SRF decision function trained on RLM on a
set of queries generalises well not only for a different set of queries (the test set),
but also across different feedback models. This suggests that the queries which
improve with RLM also improve with other feedback models, such as GRF or
ColBERT-PRF. This can be seen from the GRF and the ColBERT-PRF group
of results for both BM25 and MonoT5. This entails that the SRF based decision
function does not need to be trained for specific PRF approaches, which makes
it more suitable to use in a practical setup, affirming RQ3.
We observe that the best results obtained by our method are close to those
achieved by an ‘oracle’. In the ideal oracle scenario, PRF is applied only if the AP
of a query is actually improved (i.e., the oracle uses the relevance assessments for
the test queries). The fact that the results from Deep-SRF-BERT are close to the
oracle suggests that further attempts to increase the accuracy of PRF decisions
may have little impact on retrieval effectiveness, likely due to saturation effects.
Per-query analysis. Table 3 shows examples of queries from the TREC DL
dataset. Firstly, we see that the average differences in the AP values before
and after feedback are mostly higher for the green cells, which indicates that
Table 3: Contingency tables of the Deep-SRF-BERT model with sample queries from
TREC DL. Here, |Q| is the count of queries for each of the 4 possible cases of prediction
(true/false positives and true/false negatives), and ∆AP denotes the average ∆AP
values of each cell, where ∆AP(Q) = AP(ϕM (Q))−AP(Q)
AP(Q)
.
Actual
∆AP > 0
∆AP ≤ 0
Predicted
∆AP > 0 What is active margin?
Why is Pete Rose banned
|Q| = 59
from hall of fame?
|Q| = 8
Exon definition Biology ∆AP = 0.1302 What are best foods to
∆AP = 0.0525
lower cholesterol?
∆AP ≤ 0 Define BMT medical
|Q| = 11
Do Google docs auto save? |Q| = 19
Who is Robert Gray?
∆AP = 0.0246 How many sons Robert
∆AP = 0.0737
Kraft has?
the penalty incurred due to queries for which the model (Deep-SRF-BERT)
predicts incorrectly is not too high. This also conforms to the fact that at close
to 80% accuracy, Deep-SRF-BERT achieves results close to the oracle. Secondly,
a manual inspection of the examples reveals that the queries for which the Deep-
SRF-BERT model correctly decides to apply PRF appear to be those with under-
specified information needs, i.e., those queries which are likely to be benefited
from enrichment, e.g., the query ‘what is active margin’ as seen from Table 3.
5
Conclusions and Future Work
In this paper, we proposed a selective relevance feedback framework that includes
a data-driven supervised neural approach to optimize retrieval effectiveness by
applying feedback on queries in a selective fashion. By testing this approach
using multiple PRF models over sparse and dense architectures, we observed
that it performs favorably compared to alternative strategies, approaching the
performance of an oracle system.
This work opens the door for interesting future studies. Although our method
is effective, it requires executing PRF to gauge result quality. Exploring tech-
niques to determine the necessity of the PRF step could reduce computational
costs for queries where PRF is ultimately ignored. Further work could also ex-
amine strategies for predicting the parameters of PRF itself, such as the number
of relevant documents.
Acknowledgement The first and the fourth authors were partially supported by
Science Foundation Ireland (SFI) grant number SFI/12/RC/2289 P2.
References
1. Bashir, S., Rauber, A.: Improving retrievability of patents with cluster-based
pseudo-relevance feedback documents selection. In: Proc. CIKM ’09. p. 1863–1866.
ACM, New York, NY, USA (2009)
2. Belkin, N.J., Oddy, R.N., Brooks, H.M.: Ask for information retrieval: Part i.
background and theory. Journal of documentation (1982)
3. Billerbeck, B., Zobel, J.: Questioning query expansion: An examination of be-
haviour and parameters. In: Proc. 15th Australasian Database Conference - Vol-
ume 27. p. 69–76. ADC ’04, Australian Computer Society, Inc., AUS (2004)
4. Cao, G., Nie, J.Y., Gao, J., Robertson, S.: Selecting good expansion terms for
pseudo-relevance feedback. In: Proc. SIGIR ’08. p. 243–250. ACM, New York, NY,
USA (2008)
5. Cohen, D., Mitra, B., Lesota, O., Rekabsaz, N., Eickhoff, C.: Not all relevance
scores are equal: Efficient uncertainty and calibration modeling for deep retrieval
models. In: Proc. SIGIR’21. pp. 654–664. ACM, New York, NY, USA (2021)
6. Cormack, G.V., Clarke, C.L.A., Buettcher, S.: Reciprocal rank fusion outperforms
condorcet and individual rank learning methods. In: Proc. SIGIR ’09. p. 758–759.
ACM, New York, NY, USA (2009)
7. Craswell, N., Mitra, B., Yilmaz, E., Campos, D.: Overview of the TREC 2020 deep
learning track. In: Proc. TREC 2020. NIST Special Publication, vol. 1266 (2020)
8. Craswell, N., Mitra, B., Yilmaz, E., Campos, D., Voorhees, E.M.: Overview of the
trec 2019 deep learning track (2019)
9. Cronen-Townsend, S., Zhou, Y., Croft, W.B.: A framework for selective query
expansion. In: Proc. CIKM ’04. pp. 236–237. ACM, New York, NY, USA (2004)
10. Cronen-Townsend, S., Zhou, Y., Croft, W.B.: Predicting query performance. In:
Proc. SIGIR ’02. p. 299–306. ACM, New York, NY, USA (2002)
11. Datta, S., Ganguly, D., Greene, D., Mitra, M.: Deep-qpp: A pairwise interaction-
based deep learning model for supervised query performance prediction. In: Proc.
WSDM ’22. pp. 201–209. ACM, New York, NY, USA (2022)
12. Datta, S., MacAvaney, S., Ganguly, D., Greene, D.: A ’pointwise-query, listwise-
document’ based query performance prediction approach. In: Proc. SIGIR ’22. pp.
2148–2153. ACM, New York, NY, USA (2022)
13. Deveaud, R., Mothe, J., Ullah, M.Z., Nie, J.Y.: Learning to adaptively rank doc-
ument retrieval system configurations. ACM Trans. Inf. Syst. 37(1) (2018)
14. Ganguly, D., Leveling, J., Jones, G.J.F.: Cross-lingual topical relevance models.
In: COLING. pp. 927–942. Indian Institute of Technology Bombay, India (2012)
15. He, B., Ounis, I.: Combining fields for query expansion and adaptive query expan-
sion. Inf. Process. Manage. 43(5), 1294–1307 (sep 2007)
16. He, B., Ounis, I.: Finding good feedback documents. In: Proc. CIKM ’09. p.
2011–2014. ACM, New York, NY, USA (2009)
17. Jaleel, N.A., Allan, J., Croft, W.B., Diaz, F., Larkey, L.S., Li, X., Smucker, M.D.,
Wade, C.: Umass at TREC 2004: Novelty and HARD. In: TREC 2004 (2004)
18. Khattab, O., Zaharia, M.: ColBERT: Efficient and Effective Passage Search via
Contextualized Late Interaction over BERT, p. 39–48. ACM, New York, NY, USA
(2020)
19. Lavrenko, V., Croft, W.B.: Relevance based language models. In: Proc. SIGIR ’01.
pp. 120–127. ACM, New York, NY, USA (2001)
20. Lee, K.S., Croft, W.B., Allan, J.: A cluster-based resampling method for pseudo-
relevance feedback. In: Proc. SIGIR ’08. p. 235–242. ACM, New York, NY, USA
(2008)
21. Li, C., Sun, Y., He, B., Wang, L., Hui, K., Yates, A., Sun, L., Xu, J.: NPRF: A
neural pseudo relevance feedback framework for ad-hoc information retrieval. In:
Proc. EMNLP ’18. pp. 4482–4491. ACL, Brussels, Belgium (2018)
22. Li, H., Mourad, A., Koopman, B., Zuccon, G.: How does feedback signal quality
impact effectiveness of pseudo relevance feedback for passage retrieval. In: Proc.
SIGIR ’22. p. 2154–2158. ACM, New York, NY, USA (2022)
23. Li, H., Wang, S., Zhuang, S., Mourad, A., Ma, X., Lin, J., Zuccon, G.: To interpo-
late or not to interpolate: Prf, dense and sparse retrievers. In: Proc. SIGIR ’22. p.
2495–2500. ACM, New York, NY, USA (2022)
24. Lin, J.: Divergence measures based on the shannon entropy. IEEE Trans. Inf.
Theor. 37(1), 145–151 (sep 2006)
25. Lv, Y., Zhai, C.: Adaptive relevance feedback in information retrieval. In: Proc.
CIKM ’09. p. 255–264. ACM, New York, NY, USA (2009)
26. Mackie, I., Chatterjee, S., Dalton, J.: Generative relevance feedback with large
language models. In: Proc. SIGIR ’23. pp. 2026–2031. ACM, New York, NY, USA
(2023)
27. Mitra, M., Singhal, A., Buckley, C.: Improving automatic query expansion. In:
Proc. SIGIR ’98. p. 206–214. ACM, New York, NY, USA (1998)
28. Montazeralghaem, A., Zamani, H., Allan, J.: A reinforcement learning framework
for relevance feedback. In: Proc. SIGIR’20. pp. 59–68. ACM, New York, NY, USA
(2020)
29. Naseri, S., Dalton, J., Yates, A., Allan, J.: Ceqe: Contextualized embeddings for
query expansion. In: Advances in Information Retrieval. pp. 467–482. Springer
International Publishing, Cham (2021)
30. Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R., Deng,
L.: MS MARCO: A human generated machine reading comprehension dataset. In:
CoCo@NIPS. CEUR Workshop Proceedings, vol. 1773 (2016)
31. Nogueira, R.F., Yang, W., Cho, K., Lin, J.: Multi-stage document ranking with
BERT. CoRR abs/1910.14424 (2019)
32. Ogilvie, P., Voorhees, E., Callan, J.: On the number of terms used in automatic
query expansion. Information Retrieval 12(6), 666–679 (2009)
33. Robertson, S., Walker, S., Beaulieu, M., Gatford, M., Payne, A.: Okapi at TREC-4
(1996)
34. Rocchio, J.J.: Relevance Feedback in Information Retrieval. Prentice Hall, Engle-
wood, Cliffs, New Jersey (1971)
35. Roy, D., Ganguly, D., Mitra, M., Jones, G.J.: Word vector compositionality based
relevance feedback using kernel density estimation. In: Proc. CIKM ’16. pp. 1281–
1290. ACM, New York, NY, USA (2016)
36. Salakhutdinov, R., Mnih, A.: Bayesian probabilistic matrix factorization using
markov chain monte carlo. In: Proc. ICML ’08. pp. 880–887. ACM, New York,
NY, USA (2008)
37. Shtok, A., Kurland, O., Carmel, D.: Using statistical decision theory and relevance
models for query-performance prediction. In: In Proc. SIGIR’10. p. 259–266. ACM,
New York, NY, USA (2010)
38. Shtok, A., Kurland, O., Carmel, D., Raiber, F., Markovits, G.: Predicting query
performance by query-drift estimation. ACM Trans. Inf. Syst. 30(2) (2012)
39. Terra, E., Warren, R.: Poison pills: Harmful relevant documents in feedback. In:
Proc. CIKM ’05. p. 319–320. ACM, New York, NY, USA (2005)
40. Wang, X., Macdonald, C., Tonellotto, N., Ounis, I.: Pseudo-relevance feedback for
multiple representation dense retrieval. In: ICTIR. pp. 297–306. ACM, New York,
NY, USA (2021)
41. Wang, X., MacDonald, C., Tonellotto, N., Ounis, I.: ColBERT-PRF: Semantic
pseudo-relevance feedback for dense passage and document retrieval. ACM Trans-
actions on the Web 17(1), 1–39 (2023)
42. Xiong, L., Xiong, C., Li, Y., Tang, K., Liu, J., Bennett, P.N., Ahmed, J., Over-
wijk, A.: Approximate nearest neighbor negative contrastive learning for dense text
retrieval. In: ICLR (2021)
43. Xu, J., Croft, W.B.: Improving the effectiveness of information retrieval with local
context analysis. ACM Transactions on Information Systems 18(1), 79–112 (2000)
44. Yu, H., Xiong, C., Callan, J.: Improving Query Representations for Dense Retrieval
with Pseudo Relevance Feedback, p. 3592–3596. ACM, New York, NY, USA (2021)
45. Zamani, H., Dadashkarimi, J., Shakery, A., Croft, W.B.: Pseudo-relevance feedback
based on matrix factorization. In: Proc. CIKM ’16. pp. 1483–1492. ACM, New
York, NY, USA (2016)
46. Zheng, Z., Hui, K., He, B., Han, X., Sun, L., Yates, A.: BERT-QE: Contextualized
Query Expansion for Document Re-ranking. In: Findings of the ACL: EMNLP
2020. pp. 4718–4728. ACL (2020)
47. Zhou, Y., Croft, W.B.: Query performance prediction in web search environments.
In: Proc. SIGIR ’07. p. 543–550. SIGIR ’07, ACM, New York, NY, USA (2007)
48. Zhuang, S., Li, H., Zuccon, G.: Implicit feedback for dense passage retrieval: A
counterfactual approach. In: Proc. SIGIR ’22. p. 18–28. ACM, New York, NY,
USA (2022)
","nanRather than following the previous approaches on adapting the number of feedback terms [32] or attempting to choose a robust subset of documents for PRF [20,1], we rather focus on solving the more fundamental decision question of “whether or not to apply PRF for a given query” [9,25] with the help of a supervised data-driven approach. We hypothesise that selectively applying feedback to only those queries that are amenable to PRF can improve the overall retrieval effectiveness by avoiding query drift in cases where feedback would not be beneficial. Our idea is depicted in Figure 2.
The main novelty of our proposed selective pseudo relevance feedback (SRF) approach is that in contrast to existing work on selective PRF, we propose a data-driven supervised neural model for predicting which queries are conducive to PRF. More specifically, during the training phase we make use of the relevance assessments to learn a decision function that, given the query and the top-retrieved set of documents both with and without feedback, predicts whether it is useful to apply PRF. During the inference phase, we make use of only a part of the shared parameter network which, given a query and its top-retrieved document set, predicts whether PRF is to be applied (schematically illustrated in Figure 2). This way of inference reduces computational costs for queries where PRF should eventually be ignored."
"This research paper presents a machine learning based observer for systems evolving on Lie groups that keeps the state of the observer on the Lie group. Conventional techniques involve designing charts for the Lie group, training multiple machine learning based observers for each chart, and switching between the trained models based on the state of the system. The proposed deep learning based technique makes predictions on a measure 0 subset of Euclidean space without charts. This network predicts an “errror term” on the Lie algebra of the Lie group. It uses the map from the Lie algebra to the group, and the group action and the present state to estimate the state at the next epoch. The deep learning network does not require a system model since it is data-driven. This work provides a novel framework for constraining the output of machine learning networks to a measure 0 subset of a Euclidean space without chart specific training or switching. Validation of this method is done using Monte Carlo simulations on the rigid body rotation and translation system.","State estimation is an active area of research due to its importance in feedback based control. Many important systems evolve on Lie groups. A common example of this is the state of a quadcopter, which lies on the special Euclidean group. Estimation algorithms for systems evolving on Lie groups have to be designed such that the estimate of the state also evolves on the Lie group. Classical state estimation techniques usually design a deterministic observer for the state of the system under consideration based on the system dynamics. The design of such observers is based on some notion of error defined on the Lie group converging to 0. Due to the deterministic nature of these observers, they do not consider noise in the system and measurements. Moreover, considering noise in the observer for systems evolving on Lie groups requires noise models on the group, which are more complicated than their Euclidean counterparts. Alternatively, observers can also be designed such that the observer state does not lie on the Lie group, but converges asymptotically to it. Due to the advances in computing technologies, machine learning is a viable technique for tackling such problems. Since models are not required for machine leraning based methods, they can design effective estimators for complex systems. Moreover, since deep learning methods are regression based methods designed not to overfit on the data used for training, they inherently reject noise in the measurements.","The authors propose a machine learning based method for state estimation which respects the Lie group. They note that machine learning based methods are not able to predict state on measure 0 subsets of Euclidean spaces. To handle such constrained sets, machine learning algorithms predict state in a lower dimensional set, and these estimates are mapped to the measure 0 sets in the higher dimensional Euclidean space. However, for many subsets of Euclidean spaces, this technique may require the use of multiple maps to cover the subset, and an algorithm trained for each map, along with a switching rule between the maps. To remedy the problem of the estimates of the machine learning based method not restricted to the Lie group, they propose a network whose estimate lies on the Lie algebra of the Lie group on which the system evolves. They use the previous estimate of the state, the exponential map from the Lie algebra to the Lie group and the group action of the Lie group to arrive at the next estimate of the state.","A benefit of this approach is that the estimator network has a ResNet like structure, which has shown to improve neural networks by allowing them to be trained easily and achieve higher accuracy [5]. The results here, using Monte Carlo simulations of a rigid body system, validate the technique. An example of an observer for the rigid body rotation and translation system dynamics, which evolves on the special Euclidean group, is also presented. They also present simulations with a measurement scheme. The effect of noise on the estimates is also shown.","The authors summarize the results here, list the benefits and drawbacks of the proposed observer, comment of the benefits afforded due to the exponential map, and present possible future topics of research related to this topic.",Machine learning based state observer for discrete time systems evolving on Lie groups,"Soham Shanbhag, Dong Eui Chang","arXiv:2401.11196v1  [eess.SY]  20 Jan 2024
Machine learning based state observer for discrete time systems
evolving on Lie groups
Soham Shanbhag∗ and Dong Eui Chang†
School of Electrical Engineering, Korea Advanced Institute of Science and Technology,
Daejeon, Republic of Korea
Abstract
In this paper, a machine learning based observer for systems evolving on manifolds is designed such
that the state of the observer is restricted to the Lie group on which the system evolves. Conventional
techniques involving machine learning based observers on systems evolving on Lie groups involve designing
charts for the Lie group, training a machine learning based observer for each chart, and switching between
the trained models based on the state of the system. We propose a novel deep learning based technique
whose predictions are restricted to a measure 0 subset of Euclidean space without using charts. Using
this network, we design an observer ensuring that the state of the observer is restricted to the Lie group,
and predicting the state using only one trained algorithm. The deep learning network predicts an “error
term” on the Lie algebra of the Lie group, uses the map from the Lie algebra to the group, and uses the
group action and the present state to estimate the state at the next epoch. This model being purely data
driven does not require the model of the system. The proposed algorithm provides a novel framework
for constraining the output of machine learning networks to a measure 0 subset of a Euclidean space
without chart speciﬁc training and without requiring switching. We show the validity of this method
using Monte Carlo simulations performed of the rigid body rotation and translation system.
Keywords: Observer design, Machine learning, Lie groups
1
Introduction
State estimation is an active area of research due to its importance in feedback based control. Many important
systems evolve on Lie groups. A common example of this is the state of a quadcopter, which lies on the
special Euclidean group. Estimation algorithms for systems evolving on Lie groups have to be designed such
that the estimate of the state also evolves on the Lie group.
Classical state estimation techniques usually design a deterministic observer for the state of the system
under consideration based on the system dynamics [9, 7, 6, 14, 15, 1]. The design of such observers is based
on some notion of error deﬁned on the Lie group converging to 0. Due to the deterministic nature of these
observers, they do not consider noise in the system and measurements. Moreover, considering noise in the
observer for systems evolving on Lie groups requires noise models on the group, which are more complicated
than their Euclidean counterparts. Alternatively, observers can also be designed such that the observer state
does not lie on the Lie group, but converges asymptotically to it [2, 10, 13]. Such observers are designed
based on the Kalman Filter and other noise rejecting ﬁlters for good performance in the presence of noise.
These estimators also allow a global region of convergence.
Another disadvantage of classical observer design techniques is that they require an accurate model for
the system.
Modelling of such a system for discrete time systems involves ﬁrst modelling a continuous
time system using the Newton’s laws of motion or Lagrangian mechanics. The discrete time model is then
generated by discretizing the continuous time system using a discretization scheme which respects the Lie
group on which the system evolves.
Clearly, constructing the dynamical models for systems which are
∗sshanbhag@kaist.ac.kr
†Corresponding author, dechang@kaist.ac.kr
1
complex using classical techniques faces signiﬁcant diﬃculty due to the complexity of the system. Moreover,
the discretization process also introduces errors in the modelling of the system.
Due to the advances in computing technologies, machine learning is a viable technique for tackling such
problems. Since models are not required for machine leraning based methods, they can design eﬀective esti-
mators for complex systems. Moreover, since deep learning methods are regression based methods designed
to not overﬁt on the data used for training, they inherently reject noise in the measurements. However, the
literature concerning use of machine learning based algorithms for state estimation is sparse. The authors
in [4] assume linear system dynamics and design a data driven observer for this system. The authors in
[12] use a deep learning based auto-encoder model for state observer, where the encoder generates a linear
system which is a latent space representation of the system, and the decoder generates the estimates using
the latent space representation of the estimator of the linear system. Similarly, the authors in [11] extend
this using unsupervised learning based mapping to address the shortcomings of [12]. However, the estimates
by the observers proposed in the literature are not restricted to the Lie groups on which the systems evolve.
In this paper, we propose a machine learning based method for state estimation which respects the Lie
group. We note that machine learning based methods are not able to predict state on measure 0 subsets
of Euclidean spaces. To handle such constrained sets, machine learning algorithms predict state in a lower
dimensional set, and these estimates are mapped to the measure 0 sets in the higher dimensional Euclidean
space. However, for many subsets of Euclidean spaces, this technique may require the use of multiple maps
to cover the subset, and an algorithm trained for each map, along with a switching rule between the maps.
To remedy the problem of the estimates of the machine learning based method not restricted to the Lie
group, we propose a network whose estimate lies on the Lie algebra of the Lie group on which the system
evolves. We use the previous estimate of the state, the exponential map from the Lie algebra to the Lie
group and the group action of the Lie group to arrive at the next estimate of the state. This technique is a
novel technique which allows us to design observers without the use of multiple maps and multiple trained
networks. We validate the technique using Monte Carlo simulations of a rigid body system. A beneﬁt of
this approach is that the estimator network has a ResNet like structure, which has shown to improve neural
networks by allowing them to be trained easily and achieve higher accuracy [5].
The structure of the paper is as follows. Section 2 introduces the system considered for state estimation.
The system considered in Section 2 is a general system evolving on a Lie group. This section also presents
the observer network for state estimation and loss function used for training the same. Section 3 shows
an example of the proposed observer for the rigid body system dynamics evolving on the special Euclidean
group. We present our network and various maps required for designing the network in this section for the
special Euclidean group. We also present simulations with a measurement scheme. The eﬀect of noise on
the estimates is also shown. Finally, Section 4 concludes the paper. We summarise the results here, list the
beneﬁts and drawbacks of the proposed observer, comment of the beneﬁts aﬀorded due to the exponential
map, and present possible future topics of research related to this topic.
2
Proposed machine learning based observer
2.1
Preliminaries
Consider the dynamical system evolving on a Lie group G given by the diﬀerence equation
xk+1 = f(xk, uk, µ),
yk = h(xk, ν),
(1)
where xk ∈ G is the state of the system at epoch k, uk ∈ Rm is the control input to the system at epoch k,
yk ∈ Rl is a measurement of the state of the system at epoch k, and µ and ν are noise representing process
and measurement noise in the system. A discrete time observer for this system is of the form
¯xk+1 = ¯f(¯xk, yk+1, uk),
where ¯xk ∈ G is the estimate of the state xk on G. For an ideal estimator, limk→∞ E(¯xk, xk) = 0, where
E : G × G → R is the error between two elements of G deﬁned on G.
A machine learning based approach for state estimation is beneﬁcial if we do not have information
regarding the state update equation (1). To design an observer for system (1) using machine learning, we
2
Neural Network
exp¯xk
¯xk
yk+1
uk
vk
¯xk+1
T : G × Rl × Rm → TeG
Figure 1: Proposed observer model for state estimation.
design a deep learning based network T : G × Rl × Rm → TeG, which is used to estimate the function ¯f
using properties of the Lie group, such that the estimated state is restricted to G.
2.2
Observer design
From the strong Whitney embedding theorem [16], the Lie group G can be smoothly embedded into a
higher dimensional Euclidean space. Denote the dimension of this ambient Euclidean space by n, and the
embedding from G to Rn by π : G ֒→ Rn. Fig. 1 shows the observer structure used for state estimation. To
estimate the state of the system at epoch k + 1, the input to the model is the state estimate π(¯xk) ∈ Rn at
epoch k, the measurement yk+1 ∈ Rl at epoch k + 1, and the input to the system uk ∈ Rm at epoch k. The
model is trained to output vk ∈ TeG, a “residual error”, such that the estimate of the state at epoch k + 1
is arrived at by the equation
¯xk+1 = exp¯xk(vk) = ¯xk · exp(vk),
(2)
where · is the group action on G, and exp : TeG → G is the exponential map.
Deﬁning π(¯xk) also allows the addition and subtraction operators to be deﬁned, which may not be deﬁned
on the Lie group. Using the embedding map, the loss between two elements of G is deﬁned as
l(gk, g′
k) = ∥π(gk) − π(g′
k)∥,
gk, g′
k ∈ G,
Algorithm 1: Learning T from data.
Data: N sequences: {{uk−1, yk}, k = 1, . . . , M} and their corresponding ground truth states
1 Initialize parameters Θ of T randomly
2 for iter ← 1 to itermax do
3
foreach Sequence do
4
Set ¯x0 = e ∈ G
5
for k ← 0 to M do
6
Compute vk = T (¯xk, yk+1, uk)
7
Compute ¯xk+1 = exp¯xk(vk)
8
Calculate L using (3)
9
Update Θ using gradient descent to minimize L
3
This loss function can be used for training of the function approximator. Using this loss function, assuming
N sequences each of length M available for training, the loss used for training is
L =
1
MN
N
X
i=1
M
X
k=1
l(¯xi
k, xi
k)2,
(3)
where the superscript denotes the sequence.
This loss is the mean squared error loss deﬁned using the
embedding map on G.
The procedure for designing a state observer using the proposed method is shown in Algorithm 1. We
denote the identity element of the group by e.
3
Example: Rigid body system
To show the estimation capability of the proposed observer, we show an example of an observer for the rigid
body rotation and translation system. Denote by SO(3) the set of orthogonal matrices of dimension 3 with
determinant 1, and by so(3) its corresponding Lie algebra. The elements of so(3) are skew-symmetric matrices
in R3×3. The matrix representation of the cross product with a vector v is denoted by v× : R3 → so(3)
such that for all w ∈ R3, v × w = v×w.
The Euclidean norm of a matrix A ∈ Rm×n is denoted by
∥A∥ =
p
trace(AT A). The vectorization of a matrix A ∈ Rm×n is denoted by vec(A) ∈ Rmn.
3.1
Preliminaries
The state of a rigid body can be expressed using a rotational pose R ∈ SO(3) ⊂ R3×3 and a translational
pose p ∈ R3. We assume that the measurements of R and p are available as
Rm = R exp(ω1×), and pm = p + ω2,
where ω1 and ω2 are Gaussian noise with mean 0 and standard deviation 0.1. While we here assume the
availability of R and p directly, the measurements in application depend on the measurement scheme, a
commonly used example being the body frame measurement of at least three non-collinear markers whose
inertial frame positions are known a priori in the case of camera or LiDAR sensors. Since this would only
aﬀect the dimension of the input space to the model, we assume a more general measurement scheme to
show applicability of the proposed observer. We also assume availability of measurements of the angular
velocity (Ω) and the linear velocity (v) available as
Ωm = Ω + bΩ + ω3 and vm = v + bv + ω4,
where ω3 and ω4 are Gaussian noise with mean 0 and standard deviation 0.1, and bΩ and bv are measurement
biases. The biases bΩ and bv are constant turn-on biases, and are a property of the operating conditions at
the time of starting the sensors. These measurement models are common measurement models of sensors
like IMUs, velocity sensors, and accelerometers.
While the strong Whitney embedding theorem suggests that SO(3) can be embedded in a 6 dimensional
Euclidean space, we here consider R9 as the ambient Euclidean space. This allows us to deﬁne π : SO(3) → R9
trivially using the vectorization map on R3×3, i.e. π(R) = vec(R), where R is expressed as a matrix in R3×3.
The state of the system is then x = (vec(R), p, bΩ, bv) ∈ R18. Similarly, the measurements available for this
system are y = (vec(Rm), pm, Ωm, vm) ∈ R18. Since Ω and v are included in the measurements for this
system, we consider no control input for the purpose of observer design.
In the chosen system, the state evolves on SO(3) × R3 × R3 × R3. Since only the rotational state evolves
on a manifold, we here only consider the exponential map for the rotational state. The exponential map
exp : so(3) → SO(3) is deﬁned as the matrix exponential. The group action on SO(3) is deﬁned as the
matrix product. Then, equation (2) can be written as
¯Rk+1 = ¯Rk exp(α×), ¯pk+1 = ¯p + β, ¯bΩ = γ, ¯bv = δ,
4
Layer
Input size
Output size
GRU
36
512
GRU
512
512
FC
512
12
Table 1: Network structure for observer for rigid body system. FC: Fully connected, GRU: Gated Recurrent
Unit.
where the output of T is (α, β, γ, δ) ∈ R12. Assuming a sequence of length M used for training, the loss
function used for training is deﬁned as
L =
1
18M
M
X
k=0
∥¯xk − xk∥2 =
1
18M
M
X
k=0
0
200
400
600
800
1000
0.1
0.15
0.2
0.25
0.3
Epochs
∥R − ¯R∥
Estimation Error
Measurement Error
(a) Error in rotational state.
0
200
400
600
800
1000
0.12
0.13
0.14
0.15
0.16
0.17
0.18
0.19
Epochs
∥p − ¯p∥
Estimation Error
Measurement Error
(b) Error in position.
0
200
400
600
800
1000
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Epochs
∥bΩ − ¯bΩ∥
(c) Error in the estimate of bias in angular velocity.
0
200
400
600
800
1000
0.15
0.2
0.25
0.3
0.35
0.4
Epochs
∥bv − ¯bv∥
(d) Error in the estimate of bias in linear velocity.
0
200
400
600
800
1000
0
1e-06
2e-06
3e-06
4e-06
Epochs
∥RRT − I∥
(e) Distance of the rotational state estimate from SO(3).
Figure 2: State estimation results for the machine learning based observer for the rigid body system.
able to estimate the state correctly in the presence of noisy measurements of the state. We also note that the
observer improves the estimate of the state as compared to the measurements by a signiﬁcant amount. The
estimates show a 47.83% reduction in mean error as compared to the measurements in case of the rotational
pose and a 6.25% reduction in mean error in case of position.
We also show that the proposed observer respects the manifold on which the system evolves. The system
here evolves on SO(3) × R3 × R3 × R3, hence showing that the rotational state is restricted to SO(3) suﬃces.
6
σ
Error: ∥x − xtrue∥
% error reduction
∥RRT − I∥
Rm
¯R
pm
¯p
¯bΩ
¯bv
Rm vs ¯R
pm vs ¯p
0.1
0.23
0.12
0.16
0.15
0.22
0.23
47.83
6.25
4 × 10−6
0.2
0.45
0.18
0.32
0.18
0.37
0.33
60.00
43.75
4 × 10−6
0.3
0.66
0.22
0.48
0.20
0.51
0.46
66.67
58.33
4 × 10−6
0.4
0.88
0.36
0.64
0.26
0.63
0.59
59.09
59.38
4 × 10−6
0.5
1.08
0.54
0.80
0.34
0.74
0.74
50.00
57.50
3 × 10−6
Table 2: Mean error in simulations with varying noise.
We plot the distance of the observer from the set SO(3) in Fig. 2e. This error is deﬁned as ∥RRT −I∥, which
is 0 for elements of SO(3). It can be seen that the distance of the estimate of the rotational state from the
manifold is of the order of 10−6, which is due to the precision of the programming language used. An error
of 10−6 is negligible for application purposes.
To show the eﬀect of noise on the observer, we also perform simulations varying the noise added to the
measurements. This noise is modelled as a Gaussian noise with mean 0 and standard deviation σ. The mean
error in the measurements and the estimates from the true value is shown in Table 2. We see that the state
estimates reduce the noise in the measurement by 50% – 60% even in presence of high amount of noise.
However, the presence of noise does aﬀect the estimates of the states, which is expected. Moreover, from
Table 2, it can be seen that the distance between the state and the manifold is of the order 10−6 irrespective
of the noise. This is a signiﬁcant improvement over existing machine learning based algorithms, which are
unable to restrict the estimated state to a Lie group, or require multiple charts and switching logic.
4
Discussions and Conclusion
Due to the exp map, the state of our observer is restricted to the manifold. The exp map also performs
similar to skip connections used in ResNets, which have shown to improve neural networks by allowing them
to be trained easily and achieve higher accuracy. Due to the network being trained using deep learning,
the network allows the design of an observer without knowledge of the system equations. The design of the
network only requires knowledge of the Lie group to design the exp map. We also note that due to the
inherent ability of neural networks to reject noise, the network does not require information of the noise
in the system and the measurements during training. It can estimate the state of the system even in the
presence of noise in the measurements.
Another similar approach to observer design on Lie groups involves using local charts of the group. The
estimate of the state can be estimated in the local charts, and then the corresponding state on the group
can be arrived at using the chart map. However, this method requires a diﬀerent network to be trained for
each chart, which is cumbersome. The proposed exp map based observer allows us to mitigate this problem
of multiple charts due to embedding the manifold in the Euclidean space, while respecting the manifold.
However, due to being a deep learning based method, the training of this algorithm requires a large
amount of data. This data can be collected through experiments or simulations. Also, while the estimation
algorithm using a well-trained network is globally convergent, no guarantees can be provided about the rate
of convergence of the network.
We have shown the estimation properties of the network with an example, where the network is correctly
able to estimate the state and biases in the system. While we have assumed the measurements of the states
(R, p) directly available here, the network can be easily modiﬁed for a diﬀerent measurement scheme using
transfer learning, using a preprocessing step if the measurement equations are known, or a trained network
to generate R and p from measurements used as a preprocessing step.
Possible future work in this problem may include reducing the amount of data needed. Also, the properties
of convergence of the network should be studied. Another possible extension of the above result is to design
constrained deep learning networks. Since manifolds are level sets of continuous diﬀerentiable functions, the
above result can be extended to constrained subsets of the Euclidean space in a straightforward manner.
7
References
[1] S´ergio Br´as, Maziar Izadi, Carlos Silvestre, Amit Sanyal, and Paulo Oliveira. Nonlinear observer for
3D rigid body motion. In 52nd IEEE Conference on Decision and Control (CDC), pages 2588–2593,
December 2013.
[2] Dong Eui Chang. Globally exponentially convergent continuous observers for velocity bias and state
for invariant kinematic systems on matrix Lie groups.
IEEE Transactions on Automatic Control,
66(7):3363–3369, July 2021.
[3] Kyunghyun Cho, Bart van Merri¨enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using RNN Encoder–Decoder for sta-
tistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1724–1734, October 2014.
[4] S. X. Ding, S. Yin, Y. Wang, Y. Wang, Y. Yang, and B. Ni. Data-driven design of observers and its
applications. IFAC Proceedings Volumes, 44(1):11441–11446, January 2011.
[5] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recogni-
tion. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778,
June 2016.
[6] Alireza Khosravian, Jochen Trumpf, Robert Mahony, and Christian Lageman. Observers for invariant
systems on Lie groups with biased input measurements and homogeneous outputs. Automatica, 55:19–
26, May 2015.
[7] Christian Lageman, Jochen Trumpf, and Robert Mahony. Gradient-like observers for invariant dynamics
on a Lie group. IEEE Transactions on Automatic Control, 55(2):367–377, February 2010.
[8] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Conference
on Learning Representations (ICLR), September 2018.
[9] Robert Mahony, Tarek Hamel, and Jean-Michel Pﬂimlin.
Nonlinear Complementary Filters on the
Special Orthogonal Group. IEEE Transactions on Automatic Control, 53(5):1203–1218, June 2008.
[10] Jae Hyeon Park, Karmvir Singh Phogat, Whimin Kim, and Dong Eui Chang.
Transversely stable
extended Kalman ﬁlters for systems on manifolds in Euclidean spaces. Journal of Dynamic Systems,
Measurement, and Control, 143(6), February 2021.
[11] Johan Peralez and Madiha Nadri. Deep learning-based Luenberger observer design for discrete-time
nonlinear systems. In 2021 60th IEEE Conference on Decision and Control (CDC), pages 4370–4375,
December 2021.
[12] Louise da C. Ramos, Florent Di Meglio, Val´ery Morgenthaler, Lu´ıs F. Figueira da Silva, and Pauline
Bernard. Numerical design of Luenberger observers for nonlinear systems. In 2020 59th IEEE Conference
on Decision and Control (CDC), pages 5435–5442, December 2020.
[13] Soham Shanbhag and Dong Eui Chang. Globally exponentially convergent observer for the rigid body
system on SE(3). In 2022 IEEE 61st Conference on Decision and Control (CDC), pages 1257–1262,
December 2022.
[14] Jos´e Fernandes Vasconcelos, Rita Cunha, Carlos Silvestre, and Paulo Oliveira. A nonlinear position and
attitude observer on SE(3) using landmark measurements. Systems & Control Letters, 59(3):155–166,
March 2010.
[15] Miaomiao Wang and Abdelhamid Tayebi.
Hybrid nonlinear observers for inertial navigation using
landmark measurements. IEEE Transactions on Automatic Control, 65(12):5173–5188, December 2020.
[16] Hassler Whitney. The Self-Intersections of a Smooth n-Manifold in 2n-Space. The Annals of Mathe-
matics, 45(2):220, April 1944.
8
","The authors in [4] assume linear system dynamics and design a data driven observer for this system. The authors in [12] use a deep learning based auto-encoder model for state observer, where the encoder generates a linear system which is a latent space representation of the system, and the decoder generates the estimates using the latent space representation of the estimator of the linear system. Similarly, the authors in [11] extend this using unsupervised learning based mapping to address the shortcomings of [12]. However, the estimates by the observers proposed in the literature are not restricted to the Lie groups on which the systems evolve.nan"
"This paper studies beam training for extremely large-scale multiple-input multiple-output systems. By considering both the near field and far field, a triple-refined hybrid-field beam training scheme is proposed, where high-accuracy estimates of channel parameters are obtained through three steps of progressive refinement. First, the hybrid-field beam gain (HFBG)-based first refinement method is developed. Based on the analysis of the HFBG, the first-refinement codebook is designed and the beam training is performed accordingly to narrow down the potential region of the channel path. Then, the maximum likelihood (ML)-based and principle of stationary phase (PSP)-based second refinement methods are developed. By exploiting the measurements of the beam training, the ML is used to estimate the channel parameters. To avoid the high computational complexity of ML, closed-form estimates of the channel parameters are derived according to the PSP. Moreover, the Gaussian approximation (GA)-based third refinement method is developed. The hybrid-field neighboring search is first performed to identify the potential region of the main lobe of the channel steering vector. Afterwards, by applying the GA, a least-squares estimator is developed to obtain the high-accuracy channel parameter estimation. Simulation results verify the effectiveness of the proposed scheme.","Millimeter wave (mmWave) that reserves wide spectrum resources is a promising technology for achieving high data rates. Thanks to its small wavelength, the space-limited base station (BS) can accommodate a large number of antennas to enhance the spectral efficiency by implementing the massive multiple-input multiple-output (MIMO). The perfect match between the abundant spectrum resources provided by mmWave and the high spectral efficiency enabled by massive MIMO has led to the boom of mmWave massive MIMO. Recently, extremely large-scale MIMO (XL-MIMO) with far more antennas than existing massive MIMO has been developed to further improve the spectral efficiency via ultrahigh-gain beamforming. Attracted by the tremendous potentials, researchers move on to develop XL-MIMO based on the well-explored massive MIMO. However, extending the works in massive MIMO to XL-MIMO is not straightforward.","In this paper, we investigate hybrid-field beam training for XL-MIMO systems. We aim to achieve high-accuracy beam alignment for XL-MIMO systems with low overhead and low computational complexity, which is beyond the scopes of the existing works in [25] -– [31]. Inspired by the idea of the multi-stage beam training, we propose to acquire the CSI of XL-MIMO systems in a progressive refinement way. To obtain the high-accuracy CSI with low overhead, efficient refinement methods and effective progressive strategies are devised. The main contributions of this paper are summarized as follows.",Simulation results have shown that the proposed scheme outperforms the existing methods.,"In this paper, beam training for XL-MIMO systems has been investigated. By considering both the near field and far field, a triple-refined hybrid-field beam training scheme has been proposed, where the HFBG-based first refinement method, the ML-based and PSP-based second refinement methods, and the GA-based third refinement method have been developed. Simulation results have shown that the proposed scheme outperforms the existing methods. In our future work, we will try to extend this work to the THz band by considering the molecular absorption loss, THz spectrum windows, and beam split effects, following the works in [50] -– [52]. In addition, we will also focus on reducing the attainable latency for beam alignment by jointly considering the training overhead and feedback.",Triple-Refined Hybrid-Field Beam Training for mmWave Extremely Large-Scale MIMO,"Kangjian Chen, Chenhao Qi, Octavia A. Dobre, Geoffrey Ye Li","ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
1
Triple-Refined Hybrid-Field Beam Training for
mmWave Extremely Large-Scale MIMO
Kangjian Chen, Student Member, IEEE, Chenhao Qi, Senior Member, IEEE,
Octavia A. Dobre, Fellow, IEEE and Geoffrey Ye Li, Fellow, IEEE
Abstract—This paper investigates beam training for extremely
large-scale multiple-input multiple-output systems. By consider-
ing both the near field and far field, a triple-refined hybrid-
field beam training scheme is proposed, where high-accuracy
estimates of channel parameters are obtained through three
steps of progressive beam refinement. First, the hybrid-field
beam gain (HFBG)-based first refinement method is devel-
oped. Based on the analysis of the HFBG, the first-refinement
codebook is designed and the beam training is performed
accordingly to narrow down the potential region of the channel
path. Then, the maximum likelihood (ML)-based and principle
of stationary phase (PSP)-based second refinement methods
are developed. By exploiting the measurements of the beam
training, the ML is used to estimate the channel parameters.
To avoid the high computational complexity of ML, closed-form
estimates of the channel parameters are derived according to the
PSP. Moreover, the Gaussian approximation (GA)-based third
refinement method is developed. The hybrid-field neighboring
search is first performed to identify the potential region of the
main lobe of the channel steering vector. Afterwards, by applying
the GA, a least-squares estimator is developed to obtain the
high-accuracy channel parameter estimation. Simulation results
verify the effectiveness of the proposed scheme.
Index Terms—Beam training, extremely large-scale multiple-
input multiple-output (XL-MIMO), Gaussian approximation,
near field, principle of stationary phase.
I. INTRODUCTION
Millimeter wave (mmWave) that reserves wide spectrum
resources is a promising technology for achieving high data
rates. Thanks to its small wavelength, the space-limited base
station (BS) can accommodate a large number of antennas to
enhance the spectral efficiency by implementing the massive
multiple-input multiple-output (MIMO) [2]–[4]. The perfect
match between the abundant spectrum resources provided by
This work was supported in part by the National Natural Science Foun-
dation of China under Grants 62071116 and U22B2007, in part by the
National Key Research and Development Program of China under Grant
2021YFB2900404, in part by the Natural Sciences and Engineering Research
Council of Canada (NSERC) through its Discovery program, and in part
by the Postgraduate Research & Practice Innovation Program of Jiangsu
Province under Grant KYCX23 0262. Part of this work has been accepted
by IEEE Global Communications Conference, Kuala Lumpur, Malaysia, Dec.
2023 [1]. (Corresponding author: Chenhao Qi)
Kangjian Chen and Chenhao Qi are with the School of Information
Science and Engineering, Southeast University, Nanjing 210096, China (e-
mail: qch@seu.edu.cn).
Octavia A. Dobre is with the Faculty of Engineering and Applied
Science, Memorial University, St. John’s, NL A1C 5S7, Canada (e-mail:
odobre@mun.ca).
Geoffrey Ye Li is with the Department of Electrical and Electronic
Engineering, Imperial College London, SW7 2AZ London, U.K. (e-mail:
geoffrey.li@imperial.ac.uk).
mmWave and the high spectral efficiency enabled by massive
MIMO has led to the boom of mmWave massive MIMO [5].
Recently, extremely large-scale MIMO (XL-MIMO) with
far more antennas than existing massive MIMO has been
developed to further improve the spectral efficiency via
ultrahigh-gain beamforming [6]–[8]. Attracted by the tremen-
dous potentials, researchers move on to develop XL-MIMO
based on the well-explored massive MIMO. However, ex-
tending the works in massive MIMO to XL-MIMO is not
straightforward. Due to the much larger array aperture, the
channel model of the latter differs greatly from that of the
former. Generally, the radiation fields of the electromagnetic
waves can be divided into the near field and the far field
according to the distance between the BS and the radiation
source [9], [10]. In the far field, the channel characteristics
conform to the planar-wave model, and the phase differences
among antennas can be reasonably approximated as a linear
function of the antenna indices [7]. In the near field, the
channel characteristics cannot be accurately modeled using
the planar-wave model. Instead, they must be characterized by
the spherical-wave model, where the phase differences among
antennas are expressed as a nonlinear function of the antenna
indices [7]. For conventional massive MIMO, where the array
aperture is relatively small, the BS coverage predominantly
falls within the far field. However, in the emerging XL-
MIMO, the substantial expansion of the array aperture results
in a significant portion of the BS coverage lying within
the near field. In this context, XL-MIMO communications
will operate within the coexistence of the far and near
fields. In addition, the difference in channel models renders
conventional far-field techniques unsuitable for the near field.
Therefore, in the realm of XL-MIMO communications, the
focus should be shifted towards techniques that can effectively
adapt to the hybrid field, including the near and far fields.
One pivotal issue in wireless communications is the chan-
nel state information (CSI) acquisition [11]–[13]. Due to the
large propagation attenuation of mmWave, beam training that
can achieve high beamforming gain is preferred [14]. Gen-
erally, beam training can be categorized into beam sweeping
and multi-stage beam training. Although beam sweeping can
effectively combat noise by using narrow beams, its success
is founded on the intensive beam training. In contrast, multi-
stage beam training that explores and refines the CSI stage
by stage can compare favorably with the beam sweeping
while requiring much lower training overhead [15]. A special
case of the multi-stage beam training is the hierarchical beam
training (HBT) [16]–[20]. By comparing the received powers
arXiv:2401.11195v1  [cs.IT]  20 Jan 2024
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
2
of the codewords in the predefined hierarchical codebook
layer by layer, the HBT can gradually narrow down the
candidate sets of channel paths, leading to the increasing
beamforming gain. Different from the HBT that depends
on the hierarchical codebook and mainly exploits the power
information of the received signals, the general multi-stage
beam training flexibly divides the whole training process into
several stages and extracts CSI from the former stage via
signal processing techniques to assist the beam training of the
latter stage [21]–[24]. In [21], an optimized two-stage search
algorithm is developed, where the second stage only trains the
beam candidates derived from the first stage to accomplish
beam alignment. In [22], an adaptive and sequential beam
alignment algorithm is proposed, where the codeword for the
beam training in the lower layer is determined by the posterior
of the channel angle derived in the upper layer. In [23],
based on the beam sweeping results, an auxiliary beam pair
method is proposed to obtain the high-accuracy estimates of
channel angles by comparing the powers of received signals.
In [24], to further refine the result of beam sweeping, the
far-field array gain is approximated as a Gaussian function
and the channel angles are estimated based on additional
channel tests.
The fundamental changes in the radiation fields for XL-
MIMO communication invalidate the conventional far-field
beam training methods in [13]–[24]. In addition, the coex-
istence of the near and far fields appeals for novel hybrid-
field beam training methods for XL-MIMO communications.
One straightforward method for hybrid field beam training is
the hybrid-field beam sweeping (HFBS) [25], which explores
the far field via beam scanning and the near field via beam
focusing. Nevertheless, the HFBS exhaustively tests every
codeword in the predefined hybrid-field codebook and needs
an extensive amount of beam training. To reduce the overhead
of HFBS, a two-phase beam training (TPBT) method is
proposed in [26], where the first phase determines the can-
didate channel angles via far-field beam sweeping while the
second phase finds the channel distance based on shortlisted
candidate angles in the first phase. However, the overhead
of the TPBT is still high due to the employment of the far-
field beam sweeping in the first phase. To further reduce the
overhead of TPBT, a hierarchical codebook is designed and
a chirp-based HBT (CHBT) method is proposed for the XL-
MIMO in [27]. It is worth noting that the imperfection in
the beam patterns of codewords in the hierarchical codebook
could lead to degradation in beam training performance. For
the distance-based HBT (DHBT) method in [28], the code-
book is designed by equally sampling the space in distance.
However, the neglect of the polar-domain sparsity leads to a
deterioration in the training performance of DHBT. For the
two-stage HBT (TSHBT) in [29], the training procedure is
divided into two stages, where the first stage only refines
the channel angle with wide beams while the second stage
simultaneously refines the channel angle and distance with
beam focusing. However, a large number of antennas need
to be deactivated to form wide beams in the first stage.
Owing to the powerful feature extraction ability of neural
networks, deep learning has also been exploited for hybrid-
field beam training [30]–[32]. However, the substantial com-
putational overhead and resource-intensive characteristics of
deep learning present significant barriers to its widespread im-
plementation in XL-MIMO systems. Furthermore, the beam
training methods in [25]–[31] construct codebooks based
on the quantized samples, which not only deteriorates the
beamforming gain but also increases errors in near-field local-
ization. While numerous studies have explored high-accuracy
near-field sensing and localization [33]–[35], they often rely
on complicated hardware configurations or necessitate ex-
tensive computational resources, which is incompatible with
the concise beam training framework. One simple method
to improve the accuracy of hybrid-field beam training is the
beam refinement [36]. However, the beam refinement method
in [36] is specially tailored for the partially-connected hybrid
beamforming structure. In the context of XL-MIMO, beam
refinement methods for the fully-connected hybrid beamform-
ing structure are missing in the existing works.
In this paper, we investigate hybrid-field beam training for
XL-MIMO systems. We aim to achieve high-accuracy beam
alignment for XL-MIMO systems with low overhead and low
computational complexity, which is beyond the scopes of the
existing works in [25]–[36]. Inspired by the idea of the multi-
stage beam training, we propose to acquire the CSI of XL-
MIMO systems in a progressive refinement way. To obtain
the high-accuracy CSI with low overhead, efficient refinement
methods and effective progressive strategies are devised. The
main contributions of this paper are summarized as follows.
• By considering both the near field and far field, we de-
velop a triple-refined hybrid-field beam training (THBT)
scheme, where high-accuracy estimates of channel pa-
rameters are obtained through three steps of progressive
refinement. Benefiting from the devised refinement meth-
ods and progressive strategies, the proposed THBT can
accomplish the beam alignment for XL-MIMO systems
with substantially reduced training overhead.
• We develop the hybrid-field beam gain (HFBG)-based
first refinement method. By analyzing the HFBG of
the channel steering vector for the XL-MIMO systems,
we design the first-refinement codebook that satisfies
the presented two design criteria and perform the beam
training accordingly to determine the potential region of
the channel path.
• We then exploit the maximum likelihood (ML) and
principle of stationary phase (PSP) to develop the sec-
ond refinement methods. Based on the property of the
HFBG, we first design the second-refinement codebook,
where the beam coverage of each codeword contains
the potential region from the first refinement. Then, by
exploiting the measurements of the beam training, the
ML is used to estimate the channel parameters. To avoid
the high computational complexity of ML, the phase
of the hybrid-field beam gain is analytically expressed
according to the PSP, and closed-form estimates of the
channel parameters are derived.
• We develop the Gaussian approximation (GA)-based
third refinement method. First, we perform the hybrid-
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
3
field neighboring search to identify the potential re-
gion of the main lobe of the channel steering vector.
Inspired by the similarities between the Taylor series
of the Gaussian function and that of the HFBG, we
approximate the main lobe of the HFBG as a two-
dimensional Gaussian function. Then, by sampling the
surrogate distance and angle uniformly within the po-
tential region, we design the third-refinement codebook
and perform the beam training accordingly. Based on
the measurements of the beam training, a least-squares
(LS) estimator is developed to obtain the high-accuracy
channel parameter estimation.
The rest of this paper is organized as follows. The model
of the XL-MIMO system is introduced in Section II. The
codebook design and beam training for the first, second, and
third refinement are presented in Sections III, IV, and V, re-
spectively. The proposed methods are evaluated in Section VI,
and the paper is concluded in Section VII.
The notations are defined as follows. Symbols for matrices
(upper case) and vectors (lower case) are in boldface. (·)∗,
(·)T, and (·)H denote the conjugate, transpose, and conjugate
transpose (Hermitian), respectively. [a]n, [A]m,:, [A]:,n, and
[A]m,n denote the nth entry of vector a, the mth row of
matrix A, the nth column of matrix A, and the entry on the
mth row and the nth column of matrix A, respectively. {C}n
is the nth element of the set C. In addition, j, |·|, C, and CN
denote the square root of −1, the absolute value of a scalar,
the set of the complex number and the complex Gaussian
distribution. Moreover, f ′(·) and f ′′(·) represent the first-
order and the second-order derivative of f(·), respectively.
ln(·) denotes the natural logarithm of a number.
II. SYSTEM MODEL
As shown in Fig. 1, we consider the downlink beam train-
ing between the BS and the user, where a half-wavelength-
interval array with Nt antennas is equipped at the BS while
a single-antenna transceiver is adopted at the user. To ease
the notation, we assume that Nt is an odd number, and
Nt = 2N + 1. With the hybrid beamforming structure, the
Nt antennas are connected to NRF radio frequency (RF)
chains through a phase shifter network. In this work, the beam
training is performed based on the analog beamforming, and
hence, we only focus on one of the multiple RF chains for
simplicity. Then the sth received signal, for s = 1, 2, . . . , S,
can be expressed as
ys = hHfsxs + η
(1)
where h ∈ CNt, fs ∈ CNt, and xs denote the channel
between the BS and the user, the analog beamformer at
the BS, and the transmit signal, respectively. In addition,
η ∼ CN(0, ϱ2) denotes the additive white Gaussian noise.
To depict the channel, we first establish a Cartesian coor-
dinate, which sets the center, the normal direction, and the
tangent direction of the antenna array as the origin, the x-
axis, and the y-axis, respectively. Then the coordinate of the
nth antenna can be expressed as (0, nλ/2) for n ∈ I, where
I ≜ {−N, · · · , 0, · · · , N} and λ denotes the wavelength.
0
...
...
1
-1
2
N
-2
-N 
x-axis
Scatterer
User
y-axis
BS 
Antenna 
Array
Fig. 1.
Illustration of the system model.
From Fig. 1, the coordinate of the radiation source at the
lth path is (rl cos ωl, rl sin ωl), for l = 1, 2, · · · , L, where L
denotes the number of paths, rl is the distance between the
origin and the lth radiation source, and ωl ∈ [−π/2, π/2]
represents the angle of the lth radiation source relative to the
x-axis. The distance between the lth radiation source and the
nth antenna is calculated as
r(n)
l
=
q
r2
l + n2λ2/4 − nrlΩlλ
(2)
where Ωl ≜ sin ωl ∈ [−1, 1]. Then, the channel steering
vector between the BS and the user can be expressed as
h =
L
X
l=1
glα(Ωl, rl)
(3)
where gl denotes the channel gain of the lth path and the
channel steering vector α(·) is defined as
α(Ωl, rl)=
1
√Nt
h
e−j 2π
λ (r(−N)
l
−rl),. . ., e−j 2π
λ (r(N)
l
−rl)iT
.
(4)
Note that the channel steering vector in (4) adapts to both the
near and far fields. To ease the notation, we omit the subscript
“l” and focus on processing the path of interest. Then, r(n)
can be simplified as
r(n) ≈ r − nΩλ/2 + n2λ2(1 − Ω2)
8r
(5)
according to √1 + ϵ ≈ 1 + 1
2ϵ − 1
8ϵ2, which is verified to be
accurate if r(n) ≥ 0.5
√
N 3λ2 [7], [9]. In fact, 0.5
√
N 3λ2 is
quite small compared to the coverage of the BS. For example,
if N = 128 and λ = 0.005 m, we have 0.5
√
N 3λ2 ≈ 3.6 m,
which is much smaller than the typical coverage of the BS.
Therefore, in this work, we focus on the radiation field with
r(n) ≥ 0.5
√
N 3λ2. Substituting (5) into (4), we have
[α(Ω, r)]n ≈
1
√Nt
e
jπ

Ωn− λ(1−Ω2)
4r
n2

(6)
for n ∈ I. We define
b ≜ λ(1 − Ω2)
4r
(7)
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
4
which is referred to as the “surrogate distance” in this paper.
Then (4) can be approximated as
α(Ω, r)≈
1
√Nt
h
ejπ(−ΩN−bN 2), . . . , ejπ(ΩN−bN 2)iT
≜ γ(Ω, b).
(8)
We then propose the THBT scheme to obtain high-accuracy
channel parameter estimation through three steps of progres-
sive refinement.
III. HFBG-BASED FIRST REFINEMENT METHOD
In this section, we first analyze the HFBG of the channel
steering vector for XL-MIMO systems. Based on the analysis,
we develop the HFBG-based first refinement method, where
the first-refinement codebook is designed and the beam train-
ing is performed accordingly to determine the potential region
of the channel path.
A. Hybrid-Field Beam Gain
For an arbitrary steering vector, u ≜ γ(Θ, k), we define
its HFBG as
G(u, Ω, b) ≜ Ntγ(Ω, b)Hu
=
N
X
n=−N
ejπ((Θ−Ω)n+(b−k)n2)
(a)
≈
Z N+1/2
−N−1/2
ejπ((Θ−Ω)z+(b−k)z2)dz
=
Z ∞
−∞
U(z)ejπ((Θ−Ω)z+(b−k)z2)dz
(9)
where
U(z) =
 1,
−N − 1/2 ≤ z ≤ N + 1/2
0,
others.
(10)
In (9), we approximate the summation as the integral in (a).
Due to the quadratic phase structure of the integrand, it is
hard to obtain the closed-form solution of (9). Alternatively,
a simple but effective approximation based on the PSP is
widely adopted [37]–[39]. We define
J(z, Ω, b) ≜ π((Θ − Ω)z + (b − k)z2)
(11)
and denote z0 as the stationary phase. According to the PSP,
the differential of J(z, Ω, b) at the stationary phase satisfies
the condition that J′(z0, Ω, b) = 0. Therefore, we can obtain
z0 = Ω − Θ
2(b − k).
(12)
Then, based on the PSP, (9) can be approximated as
G(u, Ω, b) ≈
s
−2π
J′′(z0, Ω, b)e−jπ/4U(z0)ejJ(z0,Ω,b)
= e−jπ/4
√
k − bU(z0)ejπ (Ω−Θ)2
4(k−b)
=
(
e−jπ/4
√k−bejπ (Ω−Θ)2
4(k−b) ,
−Nt
2 ≤z0 ≤ Nt
2
0,
others.
(13)
Fig. 2.
Comparison of the calculated and the approximated HFBGs.
By taking the absolute value of G(u, Ω, b), we have
|G(u, Ω, b)| ≈
(
1
√
|b−k|,
− Nt
2 ≤ z0 ≤ Nt
2
0,
others.
(14)
Combining (12) and (14), we can express the beam coverage
of u as
B(u) =

(Ω, b)

|Ω − Θ|
|b − k| ≤ Nt

.
(15)
From (15), the angle coverage of u for a fixed b is
Θ − Nt|b − k| ≤ Ω ≤ Θ + Nt|b − k|
(16)
which indicates that the beam coverage is symmetric about
angle Θ and the angle coverage width (ACW) for a fixed b
is 2Nt|k − b|.
In Fig. 2, we illustrate the calculated and the approximated
HFBGs of u, where we set Nt = 513, N = 256, Θ = 0 and
k = −6.09 × 10−5. From the figure, the calculated HFBG
and the approximated HFBG share similarities in several
aspects, including the boundary, the ACW and the axis of
the symmetry, which indicates that the PSP can provide a
good approximation for the HFBG.
B. First-Refinement Codebook Design and Beam Training
Suppose the initial potential region of the interested channel
path is
Φ1 =

(Ω, b)
 − Ω ≤ Ω ≤ Ω, 0 ≤ b ≤ b
	
(17)
where Ω and b denote boundaries of Ω and b, respectively.
Note that in (17) we assume the angle of the potential region
is symmetric about zero for simplicity. However, more com-
plicated cases can also be developed by exploiting the phase-
shift invariance property of the channel steering vector [27].
In addition, b is lower bounded by zero due to its definition
in (7).
Generally, the beam training focuses on narrowing down
the potential region by testing the codewords in the predefined
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
5
Fig. 3.
Illustration of the beam gain of vm for m = −M1, · · · , 0, · · · M1.
codebook. Then, directional beams with high beamforming
gains can be formed to combat the noise. To narrow down
the potential region effectively and efficiently, the codeword
design commonly considers the following two criteria [40]:
1) The beam coverages of the codewords do not overlap with
each other. 2) The potential region should be fully covered
by the union of the beam coverage of the codewords. In the
following, by considering the aforementioned two criteria, the
first-refinement codebook is designed accordingly.
Denote the first-refinement codebook as
C1 = {v−M1, · · · , v0, · · · , vM1}
(18)
where 2M1 + 1 is the number of codewords. We design the
mth codeword in C1 as
vm = γ
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
6
due to the similar beam gains of adjacent codewords [41].
Therefore, we extend the potential region in (25) as
Φ2 =

(Ω, b)
0 ≤ b ≤ b,
|Ω − mΘ1|
|b − k1| + 1/N 2
t
≤ Nt

(26)
to include the transition zone, where the width of the transi-
tion zone is typically set as 1/Nt [42]. Then we perform the
beam training within Φ2.
We denote the second-refinement codebook as
C2 = {w−M2, · · · , w0, · · · , wM2}
(27)
where 2M2 + 1 is the number of codewords. We design the
mth codeword in (27) as
wm = γ(eΘm, k2), eΘm = mΘ1 + mΘ2
(28)
for m = −M2, · · · , 0, · · · , M2, where k2 and Θ2 > 0 are
introduced parameters to control the beam coverage and the
angle deviation of the codewords, respectively. According
to (15), the beam coverage of the mth codeword can be
expressed as
Ψm =
(
(Ω, b)
0 ≤ b ≤ b, |Ω − eΘm|
|b − k2|
≤ Nt
)
.
(29)
To provide high beam gain during beam training, the beam
coverage of each codeword in C2 should contain Φ2. Based
on (26) and (29), k2 should satisfy
1
Nt
+ Nt|b − k1| ≤ Nt|b − k2| + mΘ2.
(30)
From (30), we have
 k2 ≤ k1 − M2Θ2/Nt − 1/N 2
t ,
m is even
k2 ≥ k1 + M2Θ2/Nt + 1/N 2
t ,
m is odd.
(31)
Then, we perform the beam training based on C2. When
testing the mth codeword in C2, the signal received by the
user can be expressed as
ym = hHwm + η
(a)
≈ hHγ(eΘm, k2)
(b)
≈ g∗γ(Ω, b)Hγ(eΘm, k2)
(32)
where we omit the noise term in (a) and the effects of the
non-line-of-sight (NLoS) paths in (b).
1) ML-based Second Refinement Method: Based on the
measurements in (32), the ML estimation of channel param-
eters can be expressed as
(bΩ2,bb2, bg)=arg min
Ω,b,g
M2
X
m=−M2
y∗
m−gγ(eΘm,k2)Hγ(Ω,b)
2
(33)
We express (33) in a vector form as
(bΩ2,bb2, bg)=arg min
Ω,b,g ∥y − gΓHγ(Ω,b)∥2
2
(34)
where y and Γ are the stack of y∗
m and γ(eΘm,k2), re-
spectively. Given γ(Ω,b), the optimal solution of g is bg =
γ(Ω,b)HΓy/∥ΓHγ(Ω,b)∥2
2. Then, (34) is converted to
(bΩ2,bb2)=arg max
Ω,b
yHΓHγ(Ω,b)

2
ΓHγ(Ω,b)

2
(35)
which can be solved by the two-dimensional search. We term
the THBT with this method as the THBT-ML.
2) PSP-based Second Refinement Method: From (31), the
channel path locates in the beam coverage of γ(eΘm,k2),
which indicates that |γ(Ω,b)Hγ(eΘm,k2)| has similar values
for m = −M2, · · · , 0, · · · , M2. Therefore, we may normalize
amplitudes of the measurements to simplify the analysis. Then
we convert (33) to
(bΩ2,bb2, bg) = arg min
Ω,b,g
M2
X
m=−M2
(P(y∗
m) − ψm)2
(36)
where ψm ≜ P(gγ(eΘm,k2)Hγ(Ω,b)) and P(·) denotes the
phase of a complex number. One method to solve (36)
is performing the multi-dimensional search similar to (35).
However, a vast number of calculations are needed especially
for intensive samples of Ω and b. To avoid the high compu-
tational complexity, we revisit the PSP in (13). By extracting
the phase of G(u, Ω, b), we have
U(G(u, Ω, b))≈
(
(Ω−Θ)2
4(k−b) π− π
4 ,
− Nt
2 ≤ z0 ≤ Nt
2
0,
others
(37)
where U(·) denotes the unwrapped phase of a complex
number. By applying the PSP approximation, we can convert
(36) to
(bΩ2,bb2,bϕ2)=arg min
Ω,b,ϕ
M2
X
m=−M2

U(y∗
m)−π (Ω− eΘm)2
4(b−k2) −ϕ
2
(38)
where ϕ is a parameter introduced to eliminate the constant
phases. We define
L(α, β, γ) ≜
M2
X
m=−M2
(U(y∗
m) + αeΘ2
m + β eΘm + γ)2
(39)
where α ≜ −
π
4(b−k2), β ≜
πΩ
2(b−k2) and γ ≜ −
πΩ2
4(b−k2) − ϕ.
The optimal solution of (38) is achieved when
∂L(α, β, γ)
∂(2α)
=
M2
X
m=−M2
(U(y∗
m)+αeΘ2
m+β eΘm+γ)eΘ2
m =0
∂L(α, β, γ)
∂(2β)
=
M2
X
m=−M2
(U(y∗
m)+αeΘ2
m+β eΘm+γ)eΘm =0
∂L(α, β, γ)
∂(2γ)
=
M2
X
m=−M2
(U(y∗
m)+αeΘ2
m+β eΘm+γ)=0. (40)
Note that (40) is a system of linear equations and the closed-
form solutions can be obtained via the Gaussian elimination.
We omit the details and denote its solutions as bα, bβ and bγ.
Then we can express the results of the second refinement as
bb2 = − π
4bα + k2, and bΩ2 = −
bβ
2bα.
(41)
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
7
(a) The coverage of eΦ1, Φ2 and wm.
-8
-6
-4
-2
0
2
4
6
8
-2
0
2
4
6
8
10
12
14
16
Phase (rad)
(b) The phase unwrapping and the PSP approximation.
(c) Parameters Estimation.
Fig. 4.
Illustration of the second-refinement codebook and beam training.
We term the THBT with this method as the THBT-PSP.
Remark 1: One remaining problem is how to obtain the
unwrapped phase of y∗
m in (38). The classic method unwraps
the phase by comparing the phase difference between the
adjacent sample points with the threshold π [43]. To guarantee
the successful phase unwrap, we have
1
π |U(y∗
m+1) − U(y∗
m)| ≤ 1.
(42)
Note that
1
π |U(y∗
m+1) − U(y∗
m)|
(a)
≈

(Ω− eΘm+1)2
4(b−k2)
− (Ω− eΘm)2
4(b−k2)

= Θ2|2Ω − eΘm+1 − eΘm|
4|b−k2|
(b)
≤ Θ2(1/Nt + |b − k1|Nt + M2Θ2)
2|b−k2|
(c)
≤ Θ2(1/Nt+(b − ek1)Nt+M2Θ2)
2|b−k2|
(43)
where we obtain (a) by applying the PSP approximation in
(37), obtain (b) by considering the range of Ω in (26) and the
expression of eΘm in (28), and obtain (c) by considering the
range of b in (26) and the expression of k1 in (20). Combining
(42) and (43), we have
 k2 ≤ −B,
m is even
k2 ≥ b + B,
m is odd
(44)
where
B ≜ Θ2(1/Nt+(b − ek1)Nt+M2Θ2)
2
.
(45)
With the setting of k2 in (44), the constraints in (42) are
satisfied. Then, based on P(y∗
m), the unwrapped phase of y∗
m
can be expressed as
U(y∗
m+1) = U(y∗
m)+mod(P(y∗
m+1)−P(y∗
m)+π, 2π)−π
(46)
for m = −M2, · · · , 0, · · · , M2 − 1, where U(y∗
−M2) is
initialized to be zero.
Remark 2: Note that two constraints on k2 are derived
in (31) and (44), respectively. To ensure the successful per-
forming of the beam training, both (31) and (44) should be
satisfied. In addition, according to (14), a larger deviation
between the surrogate distance of the channel and that of the
codeword will result in a smaller beam gain. Therefore, we
need to satisfy both (31) and (44) while reducing the deviation
between the surrogate distance of the channel and that of the
codeword. Based on the above discussions, we set k2 as
k2 =
 min{−B, k1 − M2Θ2/Nt − 1/N 2
t },
m is even
max{b + B, k1 + M2Θ2/Nt + 1/N 2
t },
m is odd.
(47)
Now, we provide an example for the second-refinement
codebook design and the beam training based on the PSP in
Design Example 2.
Design Example 2: Consider an XL-MIMO system with
N = 256, Nt = 513, λ = 0.005 m, k1 = −6.09 × 10−5,
b = 1.22 × 10−4, Θ2 = 2/Nt, and M2 = 8. The number
of channel paths are set to L = 1 and the corresponding
channel steering vector is γ(Ω, b), where b = 4.9782 × 10−5
and Ω = 0.05. Suppose the beam training result of the
first refinement is m = 0. According to (25) and (26), we
can obtain potential region eΦ1 and extended potential region
Φ2, which are illustrated as the red and the blue trapezoidal
regions in Fig. 4(a), respectively. According to (47), we can
obtain k2. Then, we can design wm based on (28). As shown
in Fig. 4(a), the beam coverage of wm+1 can be obtained
through translating the beam coverage of wm by Θ2. In
Fig. 4(b), we illustrate the wrapped phase, the unwrapped
phase, and the approximated phase of y∗
m via the PSP. It is
shown that the phase of y∗
m is well unwrapped via (46) and
the unwrapped phase can be well approximated by the PSP. In
Fig. 4(c), we illustrate the beam gain of γ(Ω, b) and the values
of the real parameters as well as the estimated parameters in
(41). It is shown that the estimated parameters are close to
the real parameters, which verifies the effectiveness of the
second refinement.
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
8
Algorithm 2 ML-based and PSP-based Second Refinement
Method
1: Input: N, Nt, λ, h, m, b, k1, ek1, M2, Θ2.
2: Obtain k2 via (47).
3: Obtain C2 via (27).
4: Obtain ym for m = −M2, · · · , 0, · · · , M2 via (32).
5: if ML is adopted then
6:
Obtain bΩ2 and bb2 via (35).
7: else if PSP is adopted then
8:
Obtain U(y∗
m) via (46).
9:
Obtain bΩ2 and bb2 via (41).
10: end if
11: Output: bΩ2 and bb2.
Finally, we summarize the ML-based and PSP-based sec-
ond refinement methods in Algorithm 2.
V. GA-BASED THIRD REFINEMENT METHOD
In this section, we develop the GA-based third refinement
method to further improve the beam training accuracy. First,
we perform the hybrid-field neighboring search to identify the
potential region of the main lobe of the channel steering vec-
tor. Then, by applying the GA, an LS estimator is developed
to obtain the high-accuracy channel parameter estimation.
A. Hybrid-Field Neighboring Search
In this part, we present the details of the hybrid-field neigh-
boring search, which includes initialization, beam training,
and stop conditions.
1) Initialization: We divide the hybrid-field neighboring
search into Mn groups, each consisting of five times of
beam training. The parameters of the central codeword in
the neighboring search are initialized to be eΘ(1)
n
= bΩ2 and
ek(1)
n
= bb2. The surrogate distance deviation and the angle
deviation between adjacent codewords are set to kn and Θn,
respectively. The index of the current group is initialized to
be m = 0.
2) Beam Training: We update m ← m + 1 and design the
codebook for the beam training of the mth group as
C(m)
n
=

γ
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
9
Fig. 6.
Illustration of the Gaussian approximation.
fails. Then the THBT stops at this step and its results are
expressed as
bbf = bbn, and bΩf = bΩn.
(54)
Now, we provide an example for the hybrid-field neighbor-
ing search in Design Example 3.
Design Example 3: In Fig. 5, we consider the neighboring
search consisting of Mn = 3 groups, where each group tests
the adjacent four codewords of the central codeword. If the
best codeword in the third group is the one with pink borders,
the neighboring search is successful. Otherwise, it fails. In
addition, it is noteworthy that there are two overlapping
codewords between the adjacent groups. Therefore, each
group only needs to test three additional codewords except
the first one. In total, the maximum training overhead of the
hybrid-field neighboring search is 3Mn + 2.
B. Gaussian Approximation
From (9), we have
|G(u, Ω, b)|2 =
 
N
X
n=−N
ej(ebn2−eΩn)
! 
N
X
n=−N
ej(ebn2−eΩn)
!∗
=
N
X
n=−N
N
X
i=−N
ej
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
10
|G(u, Ω, b)|2 =
N
X
n=−N
N
X
i=−N
∞
X
p=0
2p−1
X
q=1
(−1)p(i−n)2peΩ2p
(2p)!
+ (−1)p(n2−i2)2peb2q
(2p)!
+2(−1)p(i − n)q(n2−i2)2p−q eΩqeb2p−q
(q)!(2p − q)!
(a)
≈
∞
X
p=0
2p−1
X
q=1
(−1)pCpN 2peΩ2p
(2p)!
+ (−1)p eCp(N 2)2peb2q
(2p)!
+2(−1)pCp,qN 4p−q+2eΩqeb2p−q
(q)!(2p − q)!
(56)
e−
eΩ2
σ2
1 −
eb2
σ2
2 =
∞
X
p=0
p−1
X
q=1
(−1)pACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
11
峰值点
功率较小
辅助点
(m,n-1) (m,n)
(m,n+1)
(m-1,n)
(m+1,n)
功率较大
辅助点
Angle
 Surrogate Distance
Quantized Samples
Angle
 Surrogate Distance
Quantized Samples
Fig. 7.
Illustration of the GA-based channel parameter estimation.
which is a quadratic function about the channel parameters
Ω and b. Note that
ln |bym,t| ≈ ln(|eg| bf(eΘ(m)
3
, ek(t)
3 )) + ln

1 +
eη
|eg| bf(eΘ(m)
3
, ek(t)
3 )

(a)
≈ ln(|eg| bf(eΘ(m)
3
, ek(t)
3 )) +
eη
|eg| bf(eΘ(m)
3
, ek(t)
3 )
(71)
where (a) holds because ln(1 + ϵ) ≈ ϵ. The relations
in (71) indicate that the noise term will be magnified by
1
|eg| b
f(eΘ(m)
3
,ek(t)
3 ) times in the process of taking the logarithm.
Therefore, large errors will be introduced for small values of
bf(eΘ(m)
3
, ek(t)
3 ). To avoid the noise amplification effects, we
multiply (70) by |bym,t| [47], [48], and obtain
Υm,t = |bym,t|eΘ(m)
3
bσ2
1
Ω + |bym,t|ek(t)
3
bσ2
2
b + |bym,t|χ + bη
(72)
where
Υm,t = |bym,t| ln |bym,t| + |bym,t|(eΘ(m)
3
)2
2bσ2
1
+ |bym,t|(ek(t)
3 )2
2bσ2
2
χ = ln(|eg|ba) − Ω2
2bσ2
1
− b2
2bσ2
2
.
(73)
We rewrite (72) in the vector form as
Az + bη = y,
(74)
where z ≜ [Ω, b, χ]T and bη is the stack of noise terms. The
uth row of A and the uth entry of y are expressed as
[A]u,: =
|bym,t|eΘ(m)
3
bσ2
1
, |bym,t|ek(t)
3
bσ2
2
, |bym,t|

, [y]u =Υm,t, (75)
respectively, for u = (m − 1)M3 + t, m = 1, 2, · · · , M3,
and t = 1, 2, · · · , M3. The LS solution of (74) is bz =
(ATA)−1ATy. Then the estimates of Ω and b can be
expressed as
bΩ3 = [bz]1, and bb3 = [bz]2.
(76)
Now we provide an example for the GA-based channel
parameter estimation in Design Example 4.
Design Example 4: In Fig. 7, we illustrate the process of
the GA-based channel parameter estimation, where M3 = 3,
ey( e
2m)
| > |ey( e
1m)
, and
ey( e
3m)
| > |ey( e
4m)
. From (64) and (65),
ΨL = bΩn, ΨR = bΩn +Θ3, dL = bbn −k3, and dR = bbn. Then
the quantized samples can be obtained via (66). Note that
one of the quantized samples is exactly the central codeword
in the hybrid-field neighboring search, whose received signal
can be reused for the GA. Therefore, the training overhead
of the GA-based channel parameter estimation is M 2
3 − 1.
The final results of the THBT are expressed as
bbf = bb3, and bΩf = bΩ3.
(77)
According to (7), the estimation of the distance can be
expressed as
brf = λ(1 − bΩ2
f )
4bbf
.
(78)
Finally, we summarize the details of the GA-based third
refinement method in Algorithm 3.
Now we evaluate the computational complexity of the
proposed THBT-ML and THBT-PSP. For the THBT-PSP,
the first refinement method only involves a straightforward
comparison of the received signal power, resulting in a com-
putational complexity of O(M1). The second and third refine-
ment methods provide closed-form expressions for channel
parameter estimation, as shown in (41) and (76), respectively.
Their computational complexities are O(M2) and O(M 2
3 ),
respectively. Therefore, the computational complexity of the
THBT-PSP is O(max{M1, M2, M 2
3 }). On the other hand, the
THBT-ML shares the same first and third refinement methods
as the THBT-PSP. However, during the second refinement
step, it employs a two-dimensional search to solve (35). De-
note the number of the searches as V . Then, the computational
complexity of the THBT-ML is O(V (2M2 + 1)).
Remark 5: The proposed scheme is also adaptable to
the uniform planar array (UPA) configuration. According to
Lemma 3 of [49], the hybrid-field steering vector of a UPA
can be approximated as the Kronecker product of channel
steering vectors for the horizontal uniform linear array (ULA)
and the vertical ULA, which indicates that beam training
of a UPA can be decoupled into the beam training of two
ULAs. By performing the beam training for the horizontal
ULA and the vertical ULA separately, the proposed scheme
can be extended to the UPA configuration.
VI. SIMULATION RESULTS
Now we evaluate the performance of the proposed THBT
scheme. We consider an XL-MIMO system including a BS
equipped with Nt = 513 antennas and a single-antenna user.
We set the wavelength as λ = 0.005 m corresponding to
the carrier frequency of 60 GHz. The channel between the
BS and the user is composed of one line-of-sight (LoS) path
and two NLoS paths, where the channel gain of the LoS
path obeys g1 ∼ CN(0, δ2
1) and that of the NLoS paths
obeys gl ∼ CN(0, δ2
l ) for l ∈ {2, 3}. The channel angles
distribute uniformly within [−
√
3/2,
√
3/2]. The HFBS [25],
TPBT [26], CHBT [27], DHBT [28], and TSHBT [29] are
adopted as benchmarks. The parameters of different methods
are set in the Parameter Settings of Table I, where P, Q,
K, O, T, R, W1, and W2 denote the angle samples, the
distance samples, the number of candidate angles, the number
of codewords in the first layer, the number of layers in the
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
12
TABLE I
COMPARISON OF TRAINING OVERHEAD FOR DIFFERENT METHODS.
Methods
Training Overhead
Parameter Settings
Calculated Training Overhead
HFBS [25]
PQ
P = 513, Q = 9
4617
TPBT [26]
Nt + KQ
Nt = 513, K = 3, Q = 9
540
CHBT [27]
O + 4(T − 1)
O = 33, T = 5
49
DHBT [28]
TR
R = 100, T = 2
200
TSHBT [29]
2W1 + 4W2
W1 = 7, W2 = 3
26
Proposed THBT
2(M1 + M2) + 3Mn + M2
3 + 3
M1 = 7, M2 = 8, Mn = 3, M3 = 2
46
-5
0
5
10
15
20
SNR (dB)
4
6
8
10
12
14
16
18
20
22
24
Beamforming Gain
HFBS [25]
TPBT [26]
CHBT [27]
DHBT [28]
TSHBT [29]
Upper Bound
Proposed THBT-ML
Proposed THBT-PSP
Fig. 8.
Comparisons of the beamforming gains for different methods.
hierarchical codebook, and the number of space samples in
each layer, the number of layers in the first stage of TSHBT,
and the number of layers in the second stage of TSHBT,
respectively. In addition, for the introduced parameters in the
THBT, we set ek1 = −6.09 × 10−5, Θ2 = 2/Nt, kn = 6/N 2
t
and Θn = 2/Nt.
In Fig. 8, we compare the beamforming gains of different
methods. The beamforming gain after beam alignment is
defined as
ξ = max
l
|gl|
gm
|α(Ωl, rl)Hα(Ωf, rf)|,
(79)
where gm = maxl |gl|. The distances between the BS and
the user or scatterers obey the uniform distribution within
[10, 200] m. We set δ1 = 1 and δl = 0.1 for l ∈ {2, 3}.
From Fig. 8, at low signal-to-noise-ratios (SNRs), the HFBS
achieves the best performance among all the methods; the
justification is that the HFBS exhaustively tests the codewords
in the hybrid-field codebook [25] and needs far more times of
beam training than other methods. Then the TPBT achieves
the second-best performance due to the accurate identification
of candidate angles by far-field beam sweeping. With the
increase of the SNR, the performance of the proposed THBT-
ML and THBT-PSP improves significantly and exceeds that
of other methods when the SNR is larger than 5 dB. The
advantage of the proposed methods mainly comes from the
three steps of progressive refinement. In addition, the CHBT
performs worse than other methods because of the imperfect
hierarchical codebook [27] while the poor performance of
-5
0
5
10
15
20
SNR (dB)
2
4
6
8
10
12
14
16
Spectral Efficiency (bps/Hz)
HFBS [25]
TPBT [26]
CHBT [27]
DHBT [28]
TSHBT [29]
Upper Bound
Proposed THBT-ML
Proposed THBT-PSP
Fig. 9.
Comparisons of the spectral efficiency for different methods.
the DHBT is attributed to the neglect of the polar-domain
sparsity [7]. The TSHBT performs worse than other methods
at low SNRs due to low beamforming gains of the upper-
layer codewords. Furthermore, at high SNRs, the proposed
THBT-ML and THBT-PSP outperform other methods and can
approach the upper bound.
In Fig. 9, we evaluate the spectral efficiency performance
of different methods, where the simulation settings are the
same as those in Fig. 8. From the figure, we can notice
that the spectral efficiency performance is consistent with
the beamforming gain performance in Fig. 8. In addition, the
proposed THBT-ML and THBT-PSP can approach the upper
bound with a negligible gap, e.g., 0.2 bps/Hz at 15 dB.
In Fig. 10, we compare the beamforming gains of different
methods with varying distances. The SNR is set to 10 dB and
the distances between the BS and the user or scatterers obey
the uniform distribution between [10, r] m, where r ranges
from 50 m to 600 m. From the figure, the THBT-ML achieves
the best performance among all the methods, followed by
the THBT-PSP, and then the HFBS, TPBT, TSHBT, CHBT
and DHBT in descending order. In addition, the THBT-ML,
THBT-PSP, HFBS, and CHBT are robust to distance changes
due to the consideration of both the near-field and far-field
effects. The performance of the TSHBT deteriorates at short
distances because approximating the near-field channels with
far-field ones by deactivating part of antennas may be not
accurate enough for short distances. The performance of the
DHBT deteriorates for short distances due to the neglect of
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
13
50
100
150
200
250
300
350
400
450
500
550
600
Distance (m)
12
14
16
18
20
22
Beamforming Gain
HFBS [25]
TPBT [26]
CHBT [27]
DHBT [28]
TSHBT [29]
Upper Bound
Proposed THBT-ML
Proposed THBT-PSP
Fig. 10.
Comparisons of the beamforming gains for different methods with
varying distances.
10-1
100
101
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CDF
HFBS [25]
TPBT [26]
CHBT [27]
DHBT [28]
TSHBT [29]
Proposed THBT-ML
Proposed THBT-PSP
Fig. 11.
Comparisons of the positioning performance for different methods.
the polar-domain sparsity.
In Fig. 11, we compare the positioning performance of
different methods, where the SNR is set to 20 dB and the
distances between the BS and the user or scatterers obey the
uniform distribution between [10, 30] m. The deviation be-
tween the true position and the estimated position is denoted
as E and 105 times of Monte Carlo simulation are used to
calculate the cumulative distribution function (CDF). From
the figure, the THBT-ML and THBT-PSP achieve much better
performance than the other five methods. For example, when
E = 1 m, the values of CDF for the THBT-ML, THBT-
PSP, HFBS, TPBT, TSHBT, CHBT, and DHBT are 98.7%,
97.6%, 37.4%, 36.3%, 34.3%, 20.1%, and 0.13%, respec-
tively, which indicates that the proposed schemes outperform
existing ones and can attain high-accuracy positioning in most
cases.
In Fig. 12, we compare the beamforming gains of the
THBT-ML and THBT-PSP for different stages of refinement.
From the figure, the THBT-ML and THBT-PSP have similar
performance for the first refinement, which is due to the
fact that the THBT-ML and THBT-PSP share the same first-
-5
0
5
10
15
20
SNR (dB)
0
5
10
15
20
25
Beamforming Gain
1st Refinement (THBT-ML)
2nd Refinement (THBT-ML)
3rd Refinement (THBT-ML)
1st Refinement (THBT-PSP)
2nd Refinement (THBT-PSP)
3rd Refinement (THBT-PSP)
Fig. 12.
Comparisons of the beamforming gains for different stages of
refinement.
-5
0
5
10
15
20
SNR (dB)
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
Success Rate
-30
-25
-20
-15
-10
-5
0.97
0.975
0.98
0.985
0.99
0.995
Success Rate
THBT-ML (  = -20dB)
THBT-PSP (  = -20dB)
THBT-ML (SNR = 20dB)
THBT-PSP (SNR = 20dB)
Fig. 13.
Illustration of the success rate of the neighboring search.
refinement beam training. In addition, the beamforming gains
of both the THBT-ML and the THBT-PSP improve with the
progress of the THBT. Moreover, the THBT-ML outperforms
the THBT-PSP at low SNRs due to the robustness of ML to
noise while the performance of the THBT-PSP can approach
that of the THBT-ML at high SNRs thanks to the exploitation
of the phase property of the hybrid-field beam gain.
In Fig. 13, we evaluate the performance of the neighbor-
ing search in terms of success rate, where Γ denotes the
ratio of the LoS path power to the NLoS path power, i.e.,
Γ ≜ 20 log10(δ1/δl) for l ∈ {2, 3}. From the figure, the
success rate of the neighboring search increases with SNR and
Γ, which indicates that the performance of the neighboring
search is affected by the effects of noise and NLoS paths.
In addition, when Γ = −20 dB and the SNR is larger
than 5 dB, the success rate of the neighboring search is
considerably high, e.g. 98.8% for the THBT-ML. Therefore,
the neighboring search can successfully find the mainlobe of
the channel path in most cases.
In Table I, we compare the training overheads of different
methods. The training overheads of the HFBS, TPBT, CHBT,
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
14
DHBT, TSHBT, and the proposed THBT are PQ, Nt +KQ,
O + 4(T − 1), TR, 2W1 + 4W2, and 2(M1 + M2) + 3Mn +
M 3
3 + 3, respectively. Under the simulation settings, these
six methods require 4617, 540, 49, 200, 26, and 46 times
of beam training, respectively. Specifically, when the SNR is
larger than 5 dB, the proposed THBT outperforms the HFBS
with a 99% reduction in training overhead.
VII. CONCLUSION
In this paper, beam training for XL-MIMO systems has
been investigated. By considering both the near field and
far field, a triple-refined hybrid-field beam training scheme
has been proposed, where the HFBG-based first refinement
method, the ML-based and PSP-based second refinement
methods, and the GA-based third refinement method have
been developed. Simulation results have shown that the
proposed scheme outperforms the existing methods. In our
future work, we will try to extend this work to the THz band
by considering the molecular absorption loss, THz spectrum
windows, and beam split effects, following the works in [50]–
[52]. In addition, we will also focus on reducing the attainable
latency for beam alignment by jointly considering the training
overhead and feedback.
REFERENCES
[1] K. Chen, C. Qi, and O. A. Dobre, “Beam refinement for THz extremely
large-scale MIMO systems based on Gaussian approximation,” in Proc.
IEEE Global Commun. Conf. (GLOBECOM), accepted, Kuala Lumpur,
Malaysia, Dec. 2023, pp. 1–6.
[2] E. Bjornson, L. Van der Perre, S. Buzzi, and E. G. Larsson, “Massive
MIMO in sub-6 GHz and mmWave: Physical, practical, and use-case
differences,” IEEE Wireless Commun., vol. 26, no. 2, pp. 100–108, Apr.
2019.
[3] M. Chen, J. Guo, C.-K. Wen, S. Jin, G. Y. Li, and A. Yang, “Deep
learning-based implicit CSI feedback in massive MIMO,” IEEE Trans.
Commun., vol. 70, no. 2, pp. 935–950, Feb. 2022.
[4] Z. Qiu, S. Zhou, M. Zhao, and W. Zhou, “Low-complexity precoding
by exploiting spatial sparsity in massive MIMO systems,” IEEE Trans.
Wireless Commun., vol. 21, no. 7, pp. 4740–4753, Dec. 2022.
[5] C. Qi, P. Dong, W. Ma, H. Zhang, Z. Zhang, and G. Y. Li, “Acquisition
of channel state information for mmWave massive MIMO: Traditional
and machine learning-based approaches,” Sci. China Inf. Sci., vol. 64,
no. 8, p. 181301, Aug. 2021.
[6] M. Cui, Z. Wu, Y. Lu, X. Wei, and L. Dai, “Near-field MIMO
communications for 6G: Fundamentals, challenges, potentials, and
future directions,” IEEE Commun. Mag., vol. 61, no. 1, pp. 40–46,
Feb. 2023.
[7] M. Cui and L. Dai, “Channel estimation for extremely large-scale
MIMO: Far-field or near-field?” IEEE Trans. Commun., vol. 70, no. 4,
pp. 2663–2677, Jan. 2022.
[8] Y. Lu and L. Dai, “Near-field channel estimation in mixed LoS/NLoS
environments for extremely large-scale MIMO systems,” IEEE Trans.
Commun., vol. 71, no. 6, pp. 3694–3707, June 2023.
[9] K. T. Selvan and R. Janaswamy, “Fraunhofer and Fresnel distances:
Unified derivation for aperture antennas.” IEEE Antennas Propag. Mag.,
vol. 59, no. 4, pp. 12–15, Aug. 2017.
[10] H. Lu and Y. Zeng, “Communicating with extremely large-scale ar-
ray/surface: Unified modeling and performance analysis,” IEEE Trans.
Wireless Commun., vol. 21, no. 6, pp. 4039–4053, June 2022.
[11] Z. Chen, B. Ning, C. Han, Z. Tian, and S. Li, “Intelligent reflecting
surface assisted Terahertz communications toward 6G,” IEEE Wireless
Commun., vol. 28, no. 6, pp. 110–117, Dec. 2021.
[12] B. Ning et al., “Beamforming technologies for ultra-massive MIMO in
terahertz communications,” IEEE Open J. Commun. Society, vol. 4, pp.
614–658, Feb. 2023.
[13] B. Ning, Z. Chen, Z. Tian, C. Han, and S. Li, “A unified 3D beam
training and tracking procedure for terahertz communication,” IEEE
Trans. Wireless Commun., vol. 21, no. 4, pp. 2445–2461, Apr. 2022.
[14] X. Sun, C. Qi, and G. Y. Li, “Beam training and allocation for
multiuser millimeter wave massive MIMO systems,” IEEE Trans.
Wireless Commun., vol. 18, no. 2, pp. 1041–1053, Feb. 2019.
[15] C. Liu, M. Li, S. V. Hanly, I. B. Collings, and P. Whiting, “Millimeter
wave beam alignment: Large deviations analysis and design insights,”
IEEE J. Sel. Areas Commun., vol. 35, no. 7, pp. 1619–1631, July 2017.
[16] J. Wang et al., “Beam codebook based beamforming protocol for multi-
Gbps millimeter-wave WPAN systems,” IEEE J. Sel. Areas Commun.,
vol. 27, no. 8, pp. 1390–1399, Oct. 2009.
[17] Z. Xiao, H. Dong, L. Bai, P. Xia, and X. Xia, “Enhanced channel
estimation and codebook design for millimeter-wave communication,”
IEEE Trans. Veh. Technol., vol. 67, no. 10, pp. 9393–9405, Oct. 2018.
[18] C. Qi, K. Chen, O. A. Dobre, and G. Y. Li, “Hierarchical codebook-
based multiuser beam training for millimeter wave massive MIMO,”
IEEE Trans. Wireless Commun., vol. 19, no. 12, pp. 8142–8152, Sep.
2020.
[19] B. Ning, Z. Chen, W. Chen, Y. Du, and J. Fang, “Terahertz multi-user
massive MIMO with intelligent reflecting surface: Beam training and
hybrid beamforming,” IEEE Trans. Veh. Technol., vol. 70, no. 2, pp.
1376–1393, Feb. 2021.
[20] B. Ning, T. Wang, C. Huang, Y. Zhang, and Z. Chen, “Wide-beam
designs for Terahertz massive MIMO: SCA-ATP and S-SARV,” IEEE
Internet Things J., no. 12, pp. 10 857–10 869, June 2023.
[21] M. Li, C. Liu, S. V. Hanly, I. B. Collings, and P. Whiting, “Explore
and eliminate: Optimized two-stage search for millimeter-wave beam
alignment,” IEEE Trans. Wireless Commun., vol. 18, no. 9, pp. 4379–
4393, Sep. 2019.
[22] S.-E. Chiu, N. Ronquillo, and T. Javidi, “Active learning and CSI ac-
quisition for mmWave initial alignment,” IEEE J. Sel. Areas Commun.,
vol. 37, no. 11, pp. 2474–2489, Nov. 2019.
[23] D. Zhu, J. Choi, and R. W. Heath, “Auxiliary beam pair enabled AoD
and AoA estimation in closed-loop large-scale millimeter-wave MIMO
systems,” IEEE Trans. Wireless Commun., vol. 16, no. 7, pp. 4770–
4785, July 2017.
[24] J. A. Zhang, K. Wu, X. Huang, and Y. J. Guo, “Beam alignment for
analog arrays based on Gaussian approximation,” IEEE Trans. Veh.
Technol., vol. 72, no. 6, pp. 8152–8157, June 2023.
[25] K. Chen, C. Qi, and C.-X. Wang, “Two-stage hybrid-field beam
training for ultra-massive MIMO systems,” in Proc. IEEE/CIC Int.
Conf. Commun. China (ICCC), Foshan, China, Aug. 2022, pp. 1074–
1079.
[26] Y. Zhang, X. Wu, and C. You, “Fast near-field beam training for
extremely large-scale array,” IEEE Wireless Commun. Lett., vol. 11,
no. 12, pp. 2625–2629, Dec. 2022.
[27] X. Shi, J. Wang, Z. Sun, and J. Song, “Spatial-chirp codebook-based
hierarchical beam training for extremely large-scale massive MIMO,”
IEEE Trans. Wireless Commun., early access, pp. 1–15, 2023.
[28] X. Wei, L. Dai, Y. Zhao, G. Yu, and X. Duan, “Codebook design and
beam training for extremely large-scale RIS: Far-field or near-field?”
China Commun, vol. 19, no. 6, pp. 193–204, June 2022.
[29] C. Wu, C. You, Y. Liu, L. Chen, and S. Shi, “Two-stage hierarchical
beam training for near-field communications,” IEEE Trans. Veh. Tech-
nol., early access, pp. 1–13, 2023.
[30] G. Jiang and C. Qi, “Near-field beam training based on deep learning
for extremely large-scale MIMO,” IEEE Commun. Lett., vol. 27, no. 8,
pp. 2063–2067, Aug. 2023.
[31] W. Liu, H. Ren, C. Pan, and J. Wang, “Deep learning based beam
training for extremely large-scale massive MIMO in near-field domain,”
IEEE Commun. Lett., vol. 27, no. 1, pp. 170–174, Jan. 2023.
[32] W. Liu, C. Pan, H. Ren, F. Shu, S. Jin, and J. Wang, “Low-overhead
beam training scheme for extremely large-scale RIS in near field,” IEEE
Trans. Commun., vol. 71, no. 8, pp. 4924–4940, Aug. 2023.
[33] J. Liang and D. Liu, “Passive localization of mixed near-field and far-
field sources using two-stage MUSIC algorithm,” IEEE Trans. Signal
Process., vol. 58, no. 1, pp. 108–120, Jan. 2010.
[34] Z. Wang, X. Mu, and Y. Liu, “Near-field integrated sensing and
communications,” IEEE Commun. Lett., vol. 27, no. 8, pp. 2048–2052,
Aug. 2023.
[35] B. Friedlander, “Localization of signals in the near-field of an antenna
array,” IEEE Trans. Signal Process., vol. 67, no. 15, pp. 3885–3893,
Aug. 2019.
[36] K. Chen, C. Qi, C.-X. Wang, and G. Y. Li, “Beam training and track-
ing for extremely large-scale MIMO communications,” IEEE Trans.
Wireless Commun., early access, pp. 1–15, 2023.
[37] N. M. Temme, Asymptotic Methods for Integrals.
Singapore: World
Scientific, vol. 11, 2014.
ACCEPTED BY IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
15
[38] C. M. Bender and S. A. Orszag, Advanced Mathematical Methods for
Scientists and Engineers.
New York, NY, USA: McGraw-Hill, 1978.
[39] F. W. J. Olver, Asymptotics and Special Functions.
Boca Raton, FL,
USA: CRC Press, 1997.
[40] K. Chen, C. Qi, and G. Y. Li, “Two-step codeword design for millimeter
wave massive MIMO systems with quantized phase shifters,” IEEE
Trans. Signal Process., vol. 68, pp. 170–180, Dec. 2019.
[41] J. Zhang, Y. Huang, Q. Shi, J. Wang, and L. Yang, “Codebook design
for beam alignment in millimeter wave communication systems,” IEEE
Trans. Commun., vol. 65, no. 11, pp. 4980–4995, Nov. 2017.
[42] K. Chen and C. Qi, “Beam training based on dynamic hierarchical
codebook for millimeter wave massive MIMO,” IEEE Commun. Lett.,
vol. 23, no. 1, pp. 132–135, Jan. 2019.
[43] K. Itoh, “Analysis of the phase unwrapping algorithm,” Appl. Opt.,
vol. 21, no. 14, p. 2470, July 1982.
[44] G. Buttazzoni and R. Vescovo, “Density tapering of linear arrays
radiating pencil beams: A new extremely fast Gaussian approach,” IEEE
Trans. Antennas Propag., vol. 65, no. 12, pp. 7372–7377, Dec. 2017.
[45] K. Lo, “Theoretical analysis of the sequential lobing technique,” IEEE
Trans. Aerosp. Electron. Syst., vol. 35, no. 1, pp. 282–293, Jan. 1999.
[46] T. F. Coleman and Y. Li, “An interior trust region approach for nonlinear
minimization subject to bounds,” SIAM J. Optim., vol. 6, no. 2, pp.
418–445, 1996.
[47] H. Guo, “A simple algorithm for fitting a Gaussian function [DSP Tips
and Tricks],” IEEE Signal Process. Mag., vol. 28, no. 5, pp. 134–137,
Sep. 2011.
[48] K. Wu, J. A. Zhang, and Y. J. Guo, “Fast and accurate linear fitting for
an incompletely sampled Gaussian function with a long tail [DSP Tips
and Tricks],” IEEE Signal Process. Mag., vol. 39, no. 6, pp. 76–84,
Nov. 2022.
[49] Z. Wu and L. Dai, “Multiple access for near-field communications:
SDMA or LDMA?” IEEE J. Sel. Areas Commun., vol. 41, no. 6, pp.
1918–1935, June 2023.
[50] I. F. Akyildiz, C. Han, Z. Hu, S. Nie, and J. M. Jornet, “Terahertz band
communication: An old problem revisited and research directions for
the next decade,” IEEE Trans. Commun., vol. 70, no. 6, pp. 4250–4285,
June 2022.
[51] A. Shafie, N. Yang, C. Han, J. M. Jornet, M. Juntti, and T. K¨urner,
“Terahertz communications for 6G and beyond wireless networks:
Challenges, key advancements, and opportunities,” IEEE Netw., vol. 37,
no. 3, pp. 162–169, May 2023.
[52] J. Tan and L. Dai, “THz precoding for 6G: Challenges, solutions, and
opportunities,” IEEE Wireless Commun., vol. 30, no. 4, pp. 132–138,
Aug. 2023.
","One pivotal issue in wireless communications is the channel state information (CSI) acquisition. Due to the large propagation attenuation of mmWave, beam training that can achieve high beamforming gain is preferred. Generally, beam training can be categorized into beam sweeping and multi-stage beam training. Although beam sweeping can effectively combat noise by using narrow beams, its success is founded on the intensive beam training. In contrast, multi-stage beam training that explores and refines the CSI stage by stage can compare favorably with the beam sweeping while requiring much lower training overhead. A special case of the multi-stage beam training is the hierarchical beam training (HBT). By comparing the received powers of the codewords in the predefined hierarchical codebook layer by layer, the HBT can gradually narrow down the candidate sets of channel paths, leading to the increasing beamforming gain. Different from the HBT that depends on the hierarchical codebook and mainly exploits the power information of the received signals, the general multi-stage beam training flexibly divides the whole training process into several stages and extracts CSI from the former stage via signal processing techniques to assist the beam training of the latter stage.nan"
"This research paper presents the first parallel algorithm capable of exact enumeration of deep networks (DNs) partitions regions. The proposed algorithm addresses the challenge of computing the partition of the DN's input space, which is crucial for theoretical studies and practical guidelines for DN practitioners. The study reveals that uniform sampling of the input space is efficient for regions with large volume, but exponentially costly for discovering small regions as the input space dimension increases. On the other hand, the proposed method scales linearly with the input dimension and the number of regions.","Deep networks (DNs) are compositions of linear and nonlinear operators forming a differentiable functional governed by trainable parameters. Research efforts to understand the properties of DNs have employed different mathematical formulations. One formulation, based on piecewise affine (CPA) mapping, provides an exact description of the DN's input-output mapping. Despite recent progress, a key challenge remains in computing the partition of the DN's input space, which is crucial for various theoretical results and practical applications. Current approaches rely on approximation strategies or estimates, leading to inaccuracies in conveying the underlying properties of the partition. This paper aims to address this challenge by proposing a principled and provable enumeration method for DNs partitions.","The paper presents an efficient layer-wise analysis to enumerate the regions of a single DN layer. The layer's partition arises from an arrangement of hyperplanes, allowing the adaptation of existing reverse search algorithms for efficient enumeration. For the multilayer case, the subdivision process is utilized to recursively build the partition of the DN's input space. The proposed method combines these steps to provide an exact enumeration of the multilayer DN's partition.","The results demonstrate the effectiveness of the proposed enumeration method compared to sampling-based region discovery. The method outperforms sampling in terms of computational efficiency, particularly for high-dimensional input spaces and regions with small volume. The study reveals that uniform sampling is suitable for discovering regions with large volume, but its performance degrades exponentially as the input dimension increases for regions with small volume. In contrast, the proposed method scales linearly with the input dimension and the number of regions.",The paper introduces the first exact enumeration method for DNs partitions. The method addresses the limitations of existing approximation strategies and provides provable enumeration of all the regions of the DN's partition. The findings highlight the importance of exact enumeration in accurately assessing the properties of DNs and the limitations of sampling-based methods. The proposed method serves as a baseline algorithm for applications requiring provable partition region enumeration or evaluation of theoretical findings obtained from the CPA formulation of DNs.,Fast and Exact Enumeration of Deep Networks Partitions Regions,"Randall Balestriero, Yann LeCun","FAST AND EXACT ENUMERATION OF DEEP NETWORKS PARTITIONS REGIONS
Randall Balestriero
Meta AI, FAIR
rbalestriero@meta.com
NYC, USA
Yann LeCun
Meta AI, FAIR, NYU
yann@meta.com
NYC, USA
ABSTRACT
One fruitful formulation of Deep Networks (DNs) enabling
their theoretical study and providing practical guidelines to
practitioners relies on Piecewise Affine Splines. In that realm,
a DN’s input-mapping is expressed as per-region affine map-
ping where those regions are implicitly determined by the
model’s architecture and form a partition of their input space.
That partition –which is involved in all the results spanned
from this line of research– has so far only been computed on
2/3-dimensional slices of the DN’s input space or estimated
by random sampling. In this paper, we provide the first parallel
algorithm that does exact enumeration of the DN’s partition
regions. The proposed algorithm enables one to finally as-
sess the closeness of the commonly employed approximations
methods, e.g. based on random sampling of the DN input
space. One of our key finding is that if one is only interested
in regions with “large” volume, then uniform sampling of the
space is highly efficient, but that if one is also interested in
discovering the “small” regions of the partition, then uniform
sampling is exponentially costly with the DN’s input space
dimension. On the other hand, our proposed method has com-
plexity scaling linearly with input dimension and the number
of regions.
1. INTRODUCTION
Deep Networks (DNs) are compositions of linear and nonlin-
ear operators altogether forming a differentiable functional fθ
governed by some trainable parameters θ [1]. Understanding
the underlying properties that make DNs the great function
approximators that they are involve many different research
directions e.g. the underlying implicit regularization of archi-
tectures [2], or the impact of input and feature normalization
into the optimization landscape [3]. Most existing results
emerge from a few different mathematical formulations. One
eponymous example relies on kernels and emerges from push-
ing the DN’s layers width to infinity. In this case, and under
some additional assumptions, a closed-form expression for
the DN’s underlying embedding space metric is obtained [4].
With that form, training dynamics and generalization bounds
are amenable to theoretical analysis [5]. Another line of re-
search considers the case of deep linear networks i.e. a DN
Fig. 1. Proposed exact region enumeration depicted as an orange
star against sampling-based region discovery of the partition Ω de-
picted as blue dots for a single hidden layer DN with leaky-ReLU,
random parameters and width 64 as a function of computation time
(x-axis) and number of partition regions found (y-axis); for a 4-
dimensional input space at the top and 8-dimensional input space
at the bottom. The proposed Algorithm 1 is able to dramatically
outperform the sampling-based search that has been used throughout
recent studies on CPA DNs.
without nonlinearities. In this setting, it is possible to obtain
the explicit regularizer that acts upon the DN’s functional and
that depends on the specifics of the architecture e.g. depth
and with [6]. Another direction, most relevant to our study,
arXiv:2401.11188v1  [cs.LG]  20 Jan 2024
proposes to unravel the Continuous Piecewise Affine (CPA)
mapping of standard DNs [7]. In short, one can combine the
fact that (i) the nonlinearities present in most current DNs
are themselves CPA e.g. (leaky-)ReLU, absolute value, max-
pooling, (ii) the interleaved affine mappings preserve the CPA
property, and (iii) composition of CPA mappings remain CPA.
Thus, the entire input-output DN is itself a CPA. From that
observation, it is possible to study the DN’s loss landscape
[8], the implicit regularizer of different architectures [9], the
explicit probabilistic distributions of CPA Deep Generative
Networks [10, 11], the approximation rates [12, 13], or even
the conditions for adversarial robustness guarantees [14, 15].
A striking benefit of the CPA viewpoint lies in the fact that it
is an exact mathematical description of the DN’s input-output
mapping without any approximation nor simplification. This
makes the obtained insights and guidelines highly relevant to
improve currently deployed state-of-the-art architectures.
Despite this active recent development of CPA-based re-
sults around DNs, one key challenge remains open. In fact,
because under this view one expresses the DN mapping as a
collection of affine mappings –one for each region ω of some
partition Ω of their input space– it becomes crucial to compute
that partition Ω or at least infer some statistics from it. Current
analytical characterizations of Ω are in fact insufficient e.g.
existing bounds characterizing the number of regions in Ω are
known to be loose and uninformative [16]. As such, practition-
ers resort to simple approximation strategies, e.g. sampling,
to estimate such properties of Ω. Another approach is to only
consider 2/3-dimensional slices of the DN’s input space and
estimate Ω restricted on that subspace. All in all, nothing is
known yet about how accurate are those approximations at
conveying the underlying properties of the entire partition Ω
that current theoretical results heavily rely on. In particular,
[17] uses estimates of the partition’s number of region to per-
form Neural Architecture Search (NAS), and for which exact
computation of the DNN’s partition regions will further im-
prove the NAS; [11] uses estimates of the partition to adapt
the distribution of deep generative networks (e.g. variational
autoencoders) and for which exact computation of the partition
would make their method exact, and not an approximation
In this paper, we propose a principled and provable enu-
meration method for DNs partitions (Algorithm 1) that we first
develop for a layer-wise analysis in Section 2 and then extend
to the multilayer case in Section 3. As depicted in Fig. 1,
the proposed method becomes exponentially faster than the
sampling-based strategy to discover the regions ω ∈ Ω as the
input dimensionality increases. Practically, the proposed enu-
meration method enables for the first time to measure the accu-
racy of the currently employed approximations. Our method
is efficiently implemented with a few lines of codes, lever-
ages parallel computations, and provably enumerates all the
regions of the DN’s partition. Lastly, our method has linear
asymptotic complexity with respect to the number of regions
and with respect to the DN’s input space dimension. This
property is crucial as we will demonstrate that sampling-based
enumeration method has complexity growing exponentially
with respect to the DN’s input space dimension as a direct
consequence of the curse of dimensionality [18, 19]. We hope
that our method will serve as the baseline algorithm for any
application requiring provable partition region enumeration,
or to assess the theoretical findings obtain from the CPA for-
mulation of DNs.
2. ENUMERATION OF SINGLE-LAYER PARTITIONS
We now develop the enumeration algorithm for a single DN
layer. Because a DN recursively subdivides the per-layer parti-
tion, the single layer case will be enough to iteratively compute
the partition of a multilayer DN as shown in the next Section 3.
2.1. Layer Partitions and Hyperplane Arrangements
We denote the single layer of a DN1 input-output mapping
as fθ : RD 7→ RK, with θ the parameters of the mapping.
Without loss of generality, we consider vectors as inputs since
when dealing with images, one can always flatten them into
vectors and reparametrize the layer accordingly. The layer
mapping takes the form
fθ(x) = σ(h(x)) with h(x) = W x + b
(1)
where σ is a pointwise activation function, W is a weight
matrix of dimensions K × D, b is a bias vector of length
K, h(x) denotes the pre-activation map and lastly x is some
input from RD. The layer parameters are thus θ ≜ {W , b.
Although simple, Eq. (1) encompasses most current DNs layers
by specifying the correct structural constraints on the matrix
W , e.g. to be circulant for a convolutional layer. The details
on the layer mapping will not impact our results. The CPA
view of DNs [20, 7] consists in expressing Eq. (1) as
fθ(x) =
X
ω∈Ω
(Aωx + bω)1{z∈ω},
(2)
where Ω is the layer input space partition [21]. Understanding
the form of Ω will greatly help the development of the enumer-
ation algorithm in Section 2.2. Given nonlinearities σ such as
(leaky-)ReLU or absolute value, it is direct to see that the layer
stays linear for a region ω so that all the inputs within it have
the same pre-activation signs. That is, a region is entirely and
uniquely determined by those sign patterns
fθ affine on ω ⇐⇒ sign(h(x))=sign(h(x′)),∀(x, x′) ∈ ω2,
where the equality is to be understood elementwise on all of
the K entries of the sign vectors. The only exception arises for
degenerate weights W which we do not consider since any ar-
bitrarily small perturbation of such degeneracies remove those
1without loss of generality we consider the first layer, although the exact
same analysis applies to any layer in the DN when looking at the partition of
its own input space
edge cases. From the above observation along, it becomes
clear that the transition between different regions of Ω must
occur when a pre-activation sign for some unit k ∈ {1, . . . , K}
changes, and because h is nothing more but an affine mapping,
this sign change for some unit k can only occur when crossing
the hyperplane
Hk ≜ {x ∈ RD : ⟨Wk,., x⟩ + bk = 0}.
(3)
Leveraging Eq. (3) we obtain that ∂Ω, the boundaries of the
layer’s partition, is an hyperplane arrangement as in ∂Ω =
SK
k=1 Hk.
We are now able to leverage this particular structure of the
layer’s partition to present an enumeration algorithm that will
recursively search for all the regions ω ∈ Ω.
2.2. Region Enumeration Algorithm
From the previous understanding that the layer’s partition
arises from an hyperplane arrangements involving Eq. (3),
we are now able to leverage and adapt existing enumeration
methods for such partitions to obtain all the regions ω ∈ Ω,
form which it will become trivial to consider the multilayer
case that we leave for the following Section 3.
Enumerating the regions of the layer fθ’s partition can be
done efficiently by adapting existing reverse search algorithms
[22] optimized for hyperplane arrangements. In fact, a naive
approach of enumerating all of the 2K possible sign patterns
q ∈ {−1, 1}K and checking if each defines a non-empty
region
K
\
k=1

x ∈ RD : (⟨Wk,., x⟩ + bk) qk ≥ 0
	 ?= ∅,
would be largely wasteful. In fact, most of such sign combina-
tions do produce empty regions e.g. if the partition is central
i.e. the intersection of all the hyperplane is not empty then the
total number of regions grows linearly with K [23] and is thus
much smaller than 2K. Instead, a much more efficient strategy
is to only explore feasible sign patterns in a recursive tree-like
structure. To do so, the algorithm recursively sub-divides a
parent region by the hyperplane of unit k. If that hyperplane
does not intersect the current region then we can skip unit k
and recurse the sub-division of that same region by unit k + 1.
On the other hand, if hyperplane k divides the current region,
we consider both sides of it and keep the recursion going on
both sides. We formally summarize the method in Algorithm 1
and present one illustrative example and comparison against
sampling-based region enumeration in Fig. 1. In particular,
we provide the efficiency of the sampling solution for various
configurations in Table 1.
3. ENUMERATION OF MULTI-LAYERS PARTITIONS
This section demonstrates how the derivation carried out in
Section 2 for the single layer setting is sufficient to enumerate
the partition of a multilayer DN, thanks to the subdivision
Algorithm 1 Proposed region enumeration method for the single
hidden layer case that recursively searches over the feasible sign
patterns q one unit at a time, and only explores the branches that
coincide with non-empty region i.e. avoiding the 2K total number
of possible of combinations. The step checking for intersection
between an hyperplane and a given polytopal region can be done
easily by setting up a linear program with dummy constant objective,
the hyperplane as a linear constraint, and the polytopal region as
inequality constraint; during the feasibility check the test will fail if
the intersection is empty. This algorithm is obtained to provide the
results from Fig. 1 and Table 1. The algorithm terminates once all the
regions of the partition Ω have been visited.
Require: W ∈ RK×D, b ∈ RK, k ∈ {1, . . . , K}, q ∈
{−1, 0, 1}k
1: if k
?= K + 1 then this branch has reached a leaf, the
sign pattern q is feasible and can be accumulated into Ω’s
current estimate
2: Check if the hyperplane defined by (wk, bk) intersects the
polytopal region defined by Tk−1
j=1{x ∈ RD : (⟨wj, x⟩ +
bj)qj ≥ 0}
3: if NO then unit j is redundant, call the routine again with
[qj, 0] as q and k + 1 as k
4: if YES then unit j splits the region into two, call the
routine again with [qj, 1] and k +1 and [qj, −1] and k +1
Ensure: X(L)
▷ Evaluate loss and back-propagate as usual
Table 1.
Comparison of our exact enumeration method versus
sampling-based partition discovery for various single layer configura-
tions with random weights and biases. The sampling-based discovery
is run 5 times and we report the average and standard deviation of
the number of regions found after sampling. The number of input
space sample is obtain so that the computation time of the proposed
method is the same as the computation time of the sampling method
i.e. for each configuration, both methods have run the exact same
amount of time. We observe that for low-dimensional input space,
and with the same fixed time-budget, both methods perform simi-
larly and sampling is sufficient to quickly discover all of the layer’s
partition.
input dim \width K=16 K=32 K=64
K=128
K=256
D=2
enumeration 16
13
71
127
631
sampling
16 ±0 13 ±0 67±0
127±0
611 ±2
samp. found 100% 100 % 94 %
100 %
96 %
D=4
enumeration 54
80
1107
4271
95954
sampling
51 ±0 69 ± 1 866±3 3288±18
70635 ±55
samp. found 94 % 86 %
78 %
77%
73%
D=8
enumeration 24
1242
8396
386566
-
sampling
18 ±0 543±2 2875±5 136748±251 -
samp. found 75 % 44 %
34 %
35 %
-
process under which the composition of many layers ultimately
form the global DN’s input space partition. We first recall this
subdivision step in Section 3.1 and summarize the enumeration
algorithm in Section 3.2.
Fig. 2. Depiction of the multilayer case which corresponds to a union of region-constrained hyperplane arrangements and thus which can be
studied directly form the proposed hyperplane arrangement region enumeration. The only additional step is to first enforce that the search takes
place on the restricted region of interest from the up-to-layer-ℓ input space partition. For example on the left column one first obtains the first
layer partition depicted in black. On each of the enumerated region, a subdivision will be performed by the next layer; pick any region of
interest, compose the per-region affine mapping (fixed on that region) with the second layer affine mappings, and repeat the region enumeration
algorithm. This discovers the second subdivision done by the second layer, highlighted in blue in the middle column. This can be repeated to
obtain the subdivision of the third layer, here highlighted in red in the right column.
3.1. Deep Networks are Continuous Piecewise Affine
We specialize the per-layer notations from Section 2 by explic-
iting the layer index ℓ as f (ℓ) for the layer mapping, as θ(ℓ)
for its parameters, and the entire DN’s input-output mapping
is now referred to as fθ : RD 7→ RK with K the output space
dimension. The composition of layers take the form
fθ =

f (L)
θ(L) ◦ · · · ◦ f (1)
θ(1)

,
(4)
where each layer mapping f (ℓ) : RD(ℓ) 7→ RD(ℓ+1) produces
a feature map; with D(1) ≜ D and D(L) ≜ K; with mapping
given by Eq. (1), and h(ℓ) denoting the pre-activation map of
layer ℓ. A key result from [20, 7] is the DN mapping is itself
defined on a partition as in
fθ(x) =
X
ω∈Ω
(Aωx + bω)1{z∈ω},
which is known to be recursively built by each layer subdivid-
ing the previously built partition of the space [21].
3.2. Enumerating Union of Hyperplane Arrangements
Considering an arbitrarily deep model can be tackled by un-
derstanding the recurrent subdivision process of a two hidden
layer DN and applying the same principle successively. In
this setting, notice that for the (two-layer) DN to be affine
within some region ω of the DN’s input space, each layer
must stay affine as well. By composition the first layer stay-
ing linear does not ensure that the DN stays linear, but the
first layer being nonlinear does imply that the entire DN is
nonlinear. From that, we see that the first layer’s partition
are “coarser” the the entire DN’s partition regions. More pre-
cisely, and following the derivation of [21], we obtain that
each layer is a recursive subdivision of the previously build
partition when in our case we need to search for each region
ω of the first layer’s partition the regions within it where the
second layer stays linear. As a result, the proposed single hid-
den layer enumeration method from Section 2 can be applied
recursively as follows. First, compute the first layer partition
enumeration. Then, for each enumerated region with corre-
sponding sign pattern q, define a new single layer model with
h(x) ≜ σ(W (2) diag(q)W (1)x + W (2)(q ⊙ b(1)) + b(2)
and within ω apply the single layer enumeration; repeating the
process for all regions –and corresponding sign patterns q of
the previously found first layer partition. This enumerates the
partition of (f (2) ◦f (1)), and the same process can be repeated
as many times as there are layers in the DN; as illustrated in
Fig. 2.
4. CONCLUSION AND FUTURE WORK
In this paper, we provided the first exact enumeration method
for Deep Networks partitions that relies on the existing highly
efficient enumeration method of hyperplane arrangements. In
fact, both the hallow and deep architectures produce partitions
that correspond to hyperplane arrangements or union of re-
stricted hyperplane arrangements. A crucial finding that was
enabled by the proposed method is that sampling-based re-
gion enumeration, which is the only strategy used in current
research studies dealing with DNs and affine splines, is in fact
relatively poor at finding the regions of the DN’s partition. In
particular, when using such sampling to estimating some sensi-
tive statistics e.g. the volume of the smallest region, sampling
is biased and should be avoid in favor of an exact enumeration
method.
5. REFERENCES
[1] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton,
“Deep learning,” nature, vol. 521, no. 7553, pp. 436–
444, 2015.
[2] Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro,
“In search of the real inductive bias: On the role of im-
plicit regularization in deep learning,” arXiv preprint
arXiv:1412.6614, 2014.
[3] Yann Le Cun, Ido Kanter, and Sara A Solla, “Eigenvalues
of covariance matrices: Application to neural-network
learning,” Physical Review Letters, vol. 66, no. 18, pp.
2396, 1991.
[4] Arthur Jacot, Franck Gabriel, and Clément Hongler,
“Neural tangent kernel: Convergence and generalization
in neural networks,” arXiv preprint arXiv:1806.07572,
2018.
[5] Kaixuan Huang, Yuqing Wang, Molei Tao, and Tuo Zhao,
“Why do deep residual networks generalize better than
deep feedforward networks?—a neural tangent kernel
perspective,” Advances in neural information processing
systems, vol. 33, pp. 2698–2709, 2020.
[6] Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya
Gunasekar, and Nathan Srebro, “The implicit bias of
gradient descent on separable data,”
The Journal of
Machine Learning Research, vol. 19, no. 1, pp. 2822–
2878, 2018.
[7] Randall Balestriero and Richard Baraniuk, “A spline
theory of deep learning,” in International Conference on
Machine Learning. PMLR, 2018, pp. 374–383.
[8] Rudolf H Riedi, Randall Balestriero, and Richard G Bara-
niuk, “Singular value perturbation and deep network
optimization,” arXiv preprint arXiv:2203.03099, 2022.
[9] Randall Balestriero and Richard G Baraniuk, “From
hard to soft: Understanding deep network nonlinearities
via vector quantization and statistical inference,” arXiv
preprint arXiv:1810.09274, 2018.
[10] Randall Balestriero, Sébastien Paris, and Richard Bara-
niuk,
“Analytical probability distributions and exact
expectation-maximization for deep generative networks,”
Advances in neural information processing systems, vol.
33, pp. 14938–14949, 2020.
[11] Ahmed Imtiaz Humayun, Randall Balestriero, and
Richard Baraniuk, “Polarity sampling: Quality and di-
versity control of pre-trained generative networks via
singular values,” in Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition,
2022, pp. 10641–10650.
[12] Ingrid Daubechies, Ronald DeVore, Simon Foucart,
Boris Hanin, and Guergana Petrova,
“Nonlinear ap-
proximation and (deep) relu networks,” Constructive
Approximation, vol. 55, no. 1, pp. 127–172, 2022.
[13] Randall Balestriero and Richard G Baraniuk, “Batch nor-
malization explained,” arXiv preprint arXiv:2209.14778,
2022.
[14] Lily Weng, Huan Zhang, Hongge Chen, Zhao Song,
Cho-Jui Hsieh, Luca Daniel, Duane Boning, and Inderjit
Dhillon, “Towards fast computation of certified robust-
ness for relu networks,” in International Conference on
Machine Learning. PMLR, 2018, pp. 5276–5285.
[15] Aditi Raghunathan, Jacob Steinhardt, and Percy S Liang,
“Semidefinite relaxations for certifying robustness to ad-
versarial examples,” Advances in Neural Information
Processing Systems, vol. 31, 2018.
[16] Herbert Edelsbrunner, Algorithms in combinatorial ge-
ometry, vol. 10, Springer Science & Business Media,
1987.
[17] Wuyang Chen, Xinyu Gong, and Zhangyang Wang,
“Neural architecture search on imagenet in four gpu hours:
A theoretically inspired perspective,”
arXiv preprint
arXiv:2102.11535, 2021.
[18] Richard E Bellman and Stuart E Dreyfus, Applied dy-
namic programming, vol. 2050, Princeton university
press, 2015.
[19] Mario Köppen, “The curse of dimensionality,” in 5th
online world conference on soft computing in industrial
applications (WSC5), 2000, vol. 1, pp. 4–8.
[20] Guido F Montufar, Razvan Pascanu, Kyunghyun Cho,
and Yoshua Bengio, “On the number of linear regions of
deep neural networks,” Advances in neural information
processing systems, vol. 27, 2014.
[21] Randall Balestriero, Romain Cosentino, Behnaam
Aazhang, and Richard Baraniuk, “The geometry of deep
networks: Power diagram subdivision,” Advances in
Neural Information Processing Systems, vol. 32, 2019.
[22] David Avis and Komei Fukuda, “Reverse search for
enumeration,” Discrete applied mathematics, vol. 65, no.
1-3, pp. 21–46, 1996.
[23] Richard P Stanley et al., “An introduction to hyperplane
arrangements,” Geometric combinatorics, vol. 13, no.
389-496, pp. 24, 2004.
","Existing research on DNs has explored different mathematical formulations to understand their properties. One prominent approach relies on kernels, leading to closed-form expressions for certain architectures. Another formulation considers deep linear networks, providing explicit regularizers. The CPA viewpoint, which expresses DNs as a collection of affine mappings, has enabled studies on loss landscapes, implicit regularizers, probabilistic distributions of deep generative networks, and approximation rates. However, despite these advancements, the computation of the DN's partition remains a challenge, leading to the use of approximation strategies or estimates that may not accurately represent the underlying properties of the partition.nan"
"Target localization is essential in radar systems, particularly for azimuth and velocity estimation. Earlier studies have employed gradient descent algorithms to reach the theoretical limits of the Cramér Rao Bound (CRB) for parameter estimation errors. This research presents a neural network approach that outperforms these techniques, demonstrating improved accuracy in target azimuth and velocity estimation. Using a representative simulated scenario, our proposed neural network model consistently achieves improved parameter estimates due to its inherent bias, yielding a diminished mean squared error (MSE). Our findings emphasize the potential of deep learning methods in radar systems, paving the way for more accurate localization in cluttered and dynamic environments.","Accurate target localization is crucial in modern radar systems, with applications spanning defense, surveillance, automotive navigation, and weather prediction. Estimating target parameters such as azimuth and velocity with high precision is of paramount importance, necessitating sophisticated signal processing methodologies. Gradient descent algorithms have been extensively utilized in this realm, comprising iterative methods to approach the theoretical performance limits defined by the Cramér Rao Bound (CRB). This study delves deeper into the paradigm of biased optimization approaches that yield improved target parameter estimation accuracies, thereby reducing the mean squared error (MSE); this is not to be construed as outperforming the CRB.","The representative scenario considered in this analysis is developed using RFView®, a knowledge-aided, high-fidelity, site-specific, and physics-based RF modeling and simulation environment. This scenario consists of a stationary airborne radar platform above coastal Southern California. We randomly place a moving point target in a radar processing region that contains κ range bins and varies in range, r, azimuth angle, θ, and velocity, v. The signal model considers a radar with an L-element receiver array and Λ transmitted pulses. We define the NAMF test statistic for coordinates (θ, ϕ, v) in range bin ρ and sweep it over θ, v at azimuth and velocity step size, (Δθ, Δv), with ϕ = 0. Stacking these heatmap matrices over the κ range bins yields a 3-dimensional heatmap tensor. For parameter estimation, we utilize the gradient descent algorithm, which iteratively minimizes the mean squared error loss function to obtain optimal azimuth and velocity estimates.","The empirical results demonstrate the superiority of the proposed regression CNN approach over the peak cell midpoint and gradient descent methods. Across two evaluations, one over the range of mean output SCNR and the other over the number of radar returns, the regression CNN consistently achieves a reduced MSE in predicting target azimuth and velocity. This improvement is attributed to the inherent bias of the regression CNN, which allows it to surpass the theoretical limits imposed by the Cramér Rao Bound (CRB). The results underscore the potential of data-driven models in enhancing radar target localization accuracy, particularly in cluttered and dynamic environments.","In conclusion, this research highlights the effectiveness of a data-driven neural network approach in radar target localization. The proposed regression CNN outperforms traditional gradient descent algorithms, demonstrating improved azimuth and velocity estimation accuracies due to its inherent bias. This finding challenges the notion that unbiased estimation methods are always optimal and opens up new avenues for exploration in the field of radar target localization. Future research will focus on uncovering the underlying mechanisms of this improvement and optimizing neural network architectures for enhanced parameter estimation.",Data-Driven Target Localization: Benchmarking Gradient Descent Using the Cramér-Rao Bound,"Shyam Venkatasubramanian, Sandeep Gogineni, Bosung Kang, Ali Pezeshki, Muralidhar Rangaswamy, Vahid Tarokh","1
Data-Driven Target Localization: Benchmarking
Gradient Descent Using the Cram´er-Rao Bound
Shyam Venkatasubramanian, Student Member, IEEE, Sandeep Gogineni, Senior Member, IEEE, Bosung Kang,
Member, IEEE, Ali Pezeshki Member, IEEE, Muralidhar Rangaswamy Fellow, IEEE, Vahid Tarokh Fellow, IEEE
Abstract—In modern radar systems, precise target localization
using azimuth and velocity estimation is paramount. Traditional
unbiased estimation methods have leveraged gradient descent al-
gorithms to reach the theoretical limits of the Cram´er Rao Bound
(CRB) for the error of the parameter estimates. In this study, we
present a data-driven neural network approach that outperforms
these traditional techniques, demonstrating improved accuracies
in target azimuth and velocity estimation. Using a representative
simulated scenario, we show that our proposed neural network
model consistently achieves improved parameter estimates due to
its inherently biased nature, yielding a diminished mean squared
error (MSE). Our findings underscore the potential of employing
deep learning methods in radar systems, paving the way for more
accurate localization in cluttered and dynamic environments.
Index Terms—adaptive radar processing, convolutional neu-
ral networks, Cram´er Rao Bound, data-driven radar, gradient
descent, RFView, target localization
I. INTRODUCTION
A
CCURATE target localization is a critical component in
contemporary radar systems, with applications that range
from defense and surveillance to automotive navigation and
weather prediction [1], [2]. Estimating target parameters such
as azimuth and velocity with high precision is of considerable
importance, necessitating the development of sophisticated sig-
nal processing methodologies. In this realm, gradient descent
algorithms have been extensively utilized, comprising iterative
methods to approach the theoretical performance limits defined
by the Cram´er Rao Bound (CRB) [3], [4], [5], [6].
In this study, we delve deeper into the paradigm of biased
optimization approaches that yield improved target parameter
estimation accuracies, thereby reducing the mean squared error
(MSE); this is not to be construed as outperforming the CRB.
Building upon this notion, our previous research unveiled the
potential of regression convolutional neural networks (CNN)
in radar target localization [7]. We contrasted the performance
This research is supported in part by the Air Force Office of Scientific
Research (AFOSR) under award FA9550-21-1-0235. Dr. Muralidhar Ran-
gaswamy and Dr. Bosung Kang are supported by the AFOSR under project
20RYCORO51. Dr. Sandeep Gogineni is supported by the AFOSR under
project 20RYCOR052.
Shyam Venkatasubramanian and Vahid Tarokh are with the Department
of Electrical and Computer Engineering, Duke University, Durham, NC
27705, USA, E-mail: (sv222@duke.edu; vahid.tarokh@duke.edu); Sandeep
Gogineni is with Information Systems Laboratories Inc., Dayton, OH 45431;
Bosung Kang is with University of Dayton, Dayton, OH 45469, USA (bo-
sung.kang@udri.udayton.edu); Ali Pezeshki is with the Department of Elec-
trical and Computer Engineering, Colorado State University, Fort Collins, CO
80523, USA, E-mail: (ali.pezeshki@colostate.edu); Muralidhar Rangaswamy
is with the US Air Force Research Laboratory, Wright-Patterson Air Force
Base, OH 45433, USA, E-mail: (muralidhar.rangaswamy@us.af.mil).
of these networks with a classical ‘peak cell midpoint’ method,
which relied on aggregating test statistics [8], [9], [10] into a
multidimensional tensor to determine the target location using
the center of the dominant cell. By extracting and synthesizing
complex patterns inherent within these tensors, our proposed
CNN achieved substantial gains in localization accuracy over
the aforementioned more classical approach [11].
Expanding upon these initial findings, we juxtapose gradient
descent algorithms for target azimuth and velocity estimation
with our proposed regression CNN architecture in a realistic
simulated example scenario. Our analysis assesses the parame-
ter estimation accuracies of both methodologies, underscoring
the nuanced capability of the CNN model to deliver parameter
estimates with a reduced MSE, attributed to its inherent bias.
Through this exploration, we aim to illuminate the impact and
performance superiority that data-driven models impart on the
domain of radar target localization.
The structure of the paper is as follows. Section II details the
representative scenario considered in this analysis. Section III
provides a detailed exposition of the signal model. Section IV
outlines the error metric and empirical evaluations. Section V
details the gradient descent algorithms utilized for parameter
estimation. Section VI outlines the CRB calculation. Section
VII presents the empirical results, and we conclude the paper
in Section VIII, summarizing the key insights gained from our
analysis and outlining potential avenues for future research.
II. RFVIEW® EXAMPLE SCENARIO
Developed by ISL Inc, RFView® [12] is a knowledge-aided,
high-fidelity, site-specific and physics-based RF modeling and
simulation environment that operates on a world-wide database
of terrain and land cover data. Using RFView®, we can define
synthetic example scenarios that accurately model real-world
environments — our considered example scenario consists of
a stationary airborne radar platform above coastal Southern
California. RFView® aggregates the information on land types,
the geographical characteristics across the simulation region,
and the radar parameters when simulating the radar return. The
site and radar parameters of our RFView® example scenario is
given in Table I, where we utilize a single-channel transmitter
and an L-channel receiver. The radar return is beamformed for
each size (48/L × 5) receiver sub-array, which condenses the
receiver array to size (L×1). The radar operates in ‘spotlight’
mode and points toward the center of the simulation region.
Each radar return data matrix comprises Λ transmitted pulses.
We set the elevation angle to ϕ = 0, because in our scenario,
the radar platform is far from the ground scene.
arXiv:2401.11176v1  [eess.SP]  20 Jan 2024
2
TABLE I: Site and Radar Parameters
Parameters
Values
Carrier frequency (fc)
10, 000 MHz
Bandwidth (B) & PRF (fP R)
5 MHz & 1100 Hz
Receiving antenna
48 × 5 (horizontal × vertical)
Transmitting antenna
48 × 5 (horizontal × vertical)
Antenna element spacing
0.015 m
Platform height
1000 m
Platform latitude, longitude
32.4275◦, −117.1993◦
Area range (rlower, rupper)
(14538 m, 14688 m)
Area azimuth (θmin, θmax)
(20◦, 30◦)
Area velocity (vmin, vmax)
(175 m/s, 190 m/s)
For our RFView® example scenario, we consider a stationary
airborne radar platform within the scene described by Figure 1.
We randomly place a moving point target in a radar processing
region that contains κ range bins and varies in range, r, where
r ∈ [rlower, rupper], azimuth angle, θ, where θ ∈ [θmin, θmax], and
velocity, v, where v ∈ [vmin, vmax]. The size of each range bin
is ∆r =
c
2B = 30 [m], where c is the speed of light and B is
the radar waveform bandwidth. The target RCS, σ, is randomly
sampled from a uniform distribution, σ ∼ U[µ−l/2, µ+l/2].
We conduct a series of N independent experiments, wherein
each experiment involves positioning a point target uniformly
at random by following the above procedure. For every target
placement, we generate K independent random realizations of
the radar return using RFView®. The parameters pertaining to
the radar processing region are listed in Table I.
Fig. 1: The RFView® example scenario map. The blue triangle is the platform
location and the red region is the radar processing area for tatget placement.
III. SIGNAL MODEL
We now consider a radar with an L-element receiver array,
and Λ transmitted pulses. Let Yρ ∈ C(ΛL)×K denote a matrix
comprising K independent realizations of the radar return and
let Zρ ∈ C(ΛL)×K be a matrix consisting of K independently
generated clutter-plus-noise returns, both of which have been
matched filtered to range bin ρ ∈ {P, P + 1, ..., P + κ − 1}.
Subsequently, we consider a deterministic signal, SH
ρ ∈ CK,
in the presence of clutter, cρ ∈ CΛL, and noise, nρ ∈ CΛL. We
let Cρ, ¯Cρ ∈ C(Λ·L)×K denote two unique matrices consisting
of K independent realizations of the clutter return, where each
return is randomly sampled from cρ ∼ CN(0, Σc). We also
let Nρ, ¯Nρ ∈ C(Λ·L)×K denote two unique matrices consisting
of K independent realizations of the noise, where each noise
matrix is randomly sampled from nρ ∼ CN(0, Σn). Finally,
we let aρ(θ, ϕ, v) ∈ C(ΛL) be the space-time steering vector
obtained for coordinates (θ, ϕ, v) in azimuth, elevation, and ve-
locity, with array steering vector, ξρ(θ, ϕ) ∈ CL, and Doppler
steering vector, ψρ(v) ∈ CΛ, where fdop = (2 · v · fc)/c and
k = (2π · fc)/c. The sub-array phase centers are: z ∈ RL×3.
aρ(θ, ϕ, v) = ψρ(v) ⊗ ξρ(θ, ϕ)
(1)
ξρ(θ, ϕ) = e(i)(k)(z [ cos(ϕ)cos(θ), cos(ϕ)sin(θ), sin(ϕ) ]H)
(2)
ψρ(v) =

e−(i)(2π)(
fdop
fPR )(0), . . . , e−(i)(2π)(
fdop
fPR )(Λ−1)
H
(3)
More formally, we have that1:
Zρ = ¯Cρ + ¯Nρ
(4)
Yρ = aρ(θ, ϕ, v)Sρ + Cρ + Nρ
(5)
Accordingly, the sample clutter-plus-noise covariance matrix,
ˆΣρ, is calculable via Eq. (8) — this matrix is used to whiten
both aρ(θ, ϕ, v), and the clutter-plus-noise component of Yρ.
˜Yρ = ˆΣρ
−1/2Yρ
(6)
˜aρ(θ, ϕ, v) = ˆΣρ
−1/2aρ(θ, ϕ, v)
(7)
where:
ˆΣρ = (ZρZρ
H)/K
(8)
Subsequently, the NAMF test statistic [8], Γρ(θ, ϕ, v) ∈ R+,
for coordinates (θ, ϕ, v) in range bin ρ is given by:
Γρ(θ, ϕ, v) =
∥˜aρ(θ, ϕ, v)H ˜Yρ∥2
2
[˜aρ(θ, ϕ, v)H˜aρ(θ, ϕ, v)]∥diag(˜YH
ρ ˜Yρ)∥2
(9)
By sweeping aρ(θ, ϕ, v) over θ, v at azimuth and velocity step
size, (∆θ, ∆v), with ϕ = 0, and then recording Γρ(θ, ϕ, v) at
each attribute step, we generate an azimuth-Doppler heatmap
matrix. Stacking these heatmap matrices over the κ range bins
comprising the radar processing area (indexed by ρ) yields a 3-
dimensional heatmap tensor. Per Section II, the N independent
experiments yield N heatmap tensors in total.
IV. EVALUATIONS AND ERROR METRIC
In this analysis, we consider the scenario outlined in Section
II across two evaluations: [1] over the range of mean output
SCNR, where (SCNROutput)ρ ∈ {−20 dB, −15 dB, ..., 20 dB}
(see [13] for SCNR calculation), and [2] over the number of
radar returns, where K ∈ {75, 100, ..., 300}. We fix the clutter-
to-noise ratio (CNR) to 20 dB (l = 10, σ chosen accordingly),
and we let Λ = 4, L = 16. In [1], we let K = 300, and in [2],
we let (SCNROutput)ρ = 20 dB. Subsequently, we consider the
site and radar parameters provided in Table I, with range bins
of size ∆r = 30 m, with azimuth and velocity step sizes of
(∆θ, ∆v) = (0.4◦, 0.5 m/s), where κ = 5 and each heatmap
tensor is of size 5 × 26 × 21. Finally, for each value of [1]
(SCNROutput)ρ and [2] K, we produce N = 1 × 104 heatmap
tensors, which we partition into training (Ntrain = 0.9N) and
test (Ntest = 0.1N) datasets. We train our regression CNN on
each training dataset, and evaluate the efficacy of our peak cell
midpoint, gradient descent, and regression CNN methods on
each test dataset. These results are provided in Section VII.
1We note that all relevant data matrices (e.g., Zρ, Yρ) are preliminarily
mean centered (E[Zρ] = ⃗0 and E[Yρ] = ⃗0).
3
Per the signal model outlined in Section III, we now define
the mean squared error (MSE) metric to interpret the parameter
estimation errors of our peak cell midpoint (ErrMP), gradient
descent (ErrGD), and regression CNN (ErrCNN) methods. Let
(θ∗
i , v∗
i ) denote the ground truth target azimuth and velocity
for example i from our test dataset. Furthermore, let (˘θi,˘vi)
denote the azimuth and velocity values from the midpoint of
the peak tensor cell, let (˙θi, ˙vi) denote the optimal azimuth and
velocity values yielded by the gradient descent algorithm, and
let (˜θi,˜vi) denote the azimuth and velocity values predicted
by the regression CNN, for example i from our test dataset.
The empirical MSE of the parameter estimates are defined as:
(Err)θ =
Ntest
P
i=1
(θ∗
i − ˆθi)2
Ntest
(Err)v =
Ntest
P
i=1
(v∗
i − ˆvi)2
Ntest
(10)
where (ˆθi,ˆvi) = (˘θi,˘vi) for (ErrMP), (ˆθi,ˆvi) = (˙θi, ˙vi) for
(ErrGD), and (ˆθi,ˆvi) = (˜θi,˜vi) for (ErrCNN). We compare
these MSE estimates with the theoretical MSE yielded by the
Cram´er Rao Bound calculation in Section VI.
V. GRADIENT DESCENT PARAMETER ESTIMATION
We now outline the gradient descent algorithm that has been
used to obtain the azimuth and velocity parameter estimates.
For the azimuth case, we note that the ground truth range bin,
ρ∗, and velocity, v∗, of each target are known beforehand. For
the velocity case, we note that the ground truth range bin, ρ∗,
and azimuth, θ∗, of each target are known beforehand.
A. Azimuth Estimation
The motivation behind the Gradient Descent Azimuth Esti-
mator algorithm is to determine the optimal azimuth estimate,
˙θ, of a given target using gradient descent. Using the matched
filtered radar array data matrix, ˜Yρ∗, and an initial estimate ˆθ,
corresponding to the azimuth of the peak cell midpoint from
the provided heatmap tensor, the algorithm operates iteratively
for a total of T iterations. At each step, we obtain an estimate
for the amplitude and phase of Sρ via least squares. The least
squares solution seeks to minimize the MSE between ˜Yρ∗ and
the estimated model, aρ(θ, ϕ, v∗)ˆc, from which the optimal
array of coefficients, ˆcH ∈ CK, is defined as [14]:
ˆc =
˜aρ∗(θ, ϕ, v∗)H ˜Yρ∗
˜aρ∗(θ, ϕ, v∗)H˜aρ∗(θ, ϕ, v∗)
(11)
Subsequently, this least squares solution is used to compute
the mean squared error loss, L(θ), which is defined as:
L(θ) =
1
L K
L
X
i=1
K
X
j=1
[(˜Yρ∗)ij − (ˆc ⊗ ˜aρ∗(θ, ϕ, v∗))ij]2 (12)
Using the gradient, ∇θL(θ) and a preset learning rate, α, we
adjust the azimuth estimate to obtain an updated estimate of
θ. This procedure is summarized in Algorithm 1.
B. Velocity Estimation
As in Section V-A, the Gradient Descent Velocity Estimator
algorithm is used to determine the optimal velocity estimate,
Algorithm 1 Gradient Descent Azimuth Estimator (GDˆθ)
1: procedure GDˆθ(˜Yρ∗,ˆθ, ϕ, v∗, α, T)
2:
θ ← ˆθ, θmin ← 20, θmax ← 30
3:
for t = 1 : T do
4:
ˆc ←
˜aρ∗(θ,ϕ,v∗)H ˜Yρ∗
˜aρ∗(θ,ϕ,v∗)H˜aρ∗(θ,ϕ,v∗)
5:
L(θ) ←
1
L K
L
P
i=1
K
P
j=1
[(˜Yρ∗)ij − (ˆc ⊗ ˜aρ∗(θ, ϕ, v∗))ij]2
6:
θ ← θ − α · ∇θL(θ)
7:
θ ← max(min(θ, θmax), θmin)
8:
end for
9:
return ˙θ ← θ
10: end procedure
˙v, of a given target via gradient descent. Using the matched
filtered radar array data matrix, ˜Yρ∗, and an initial estimate ˆv,
corresponding to the velocity of the peak cell midpoint from
the provided heatmap tensor, the algorithm operates iteratively
for a total of T iterations. At each step, we obtain an estimate
for the amplitude and phase of Sρ via least squares. The least
squares solution seeks to minimize the MSE between ˜Yρ∗ and
the estimated model, aρ(θ∗, ϕ, v)ˆd, from which the optimal
array of coefficients, ˆdH ∈ CK, is defined as [14]:
ˆd =
˜aρ∗(θ∗, ϕ, v)H ˜Yρ∗
˜aρ∗(θ∗, ϕ, v)H˜aρ∗(θ∗, ϕ, v)
(13)
Subsequently, this least squares solution is used to compute
the mean squared error loss, L(v), which is defined as:
L(v) =
1
L K
L
X
i=1
K
X
j=1
[(˜Yρ∗)ij − (ˆd ⊗ ˜aρ∗(θ∗, ϕ, v))ij]2 (14)
Using the gradient, ∇vL(v) and a preset learning rate, α, we
adjust the azimuth estimate to obtain an updated estimate of
v. This procedure is summarized in Algorithm 2.
Algorithm 2 Gradient Descent Velocity Estimator (GDˆv)
1: procedure GDˆv(˜Yρ∗, θ∗, ϕ,ˆv, α, T)
2:
v ← ˆv, vmin ← 175, vmax ← 190
3:
for t = 1 : T do
4:
ˆd ←
˜aρ∗(θ∗,ϕ,v)H ˜Yρ∗
˜aρ∗(θ∗,ϕ,v)H˜aρ∗(θ∗,ϕ,v)
5:
L(v) ←
1
L K
L
P
i=1
K
P
j=1
[(˜Yρ∗)ij − (ˆd ⊗ ˜aρ∗(θ∗, ϕ, v))ij]2
6:
v ← v − α · ∇vL(v)
7:
v ← max(min(v, vmax), vmin)
8:
end for
9:
return ˙v ← v
10: end procedure
VI. CRAM´ER-RAO BOUND
In this section, we derive the Cram´er-Rao Bound (CRB) for
the aforementioned azimuth and velocity parameter estimation
errors. We compare each derived CRB with the MSE yielded
by each of the approaches outlined in Section IV.
4
(a) Azimuth Estimation Error vs. CRB — (Err)θ vs. CRB(θ)
(b) Velocity Estimation Error vs. CRB — (Err)v vs. CRB(v)
Fig. 2: Comparing azimuth and velocity estimation errors of the peak cell midpoint, gradient descent, and regression CNN methods with the CRB.
A. Azimuth Estimation
Deriving from the signal model in Section III, we note that
Yρ consists of K independent radar returns randomly sampled
from yρ ∼ CN(bρ(θ)¯Sρ, R), wherein bρ(θ) = aρ(θ, ϕ, v∗),
¯Sρ = (PK
j=1[Sρ]j)/K, and R = Σc +Σn. Using the Slepian
formula [15], the Fisher Information for θ is defined as:
I(θ) = E
"" ∂
∂θ ln p(yρ|θ)
2#
(15)
= (¯Sρ)2
∂bρ(θ)
∂θ
H
R−1
∂bρ(θ)
∂θ

(16)
Wherein ( ∂bρ(θ)
∂θ
) = (aρ(v∗) ⊗ [(i)(k)aρ(θ, ϕ) ⊙ [zg]]), with
g = [ −cos(ϕ)sin(θ), cos(ϕ)cos(θ∗), 0 ]H ∈ R3. Therefore,
the Cram´er Rao Bound, which provides a lower bound on the
MSE of any unbiased estimator of θ, is defined as:
E[(ˆθ − θ)2] ≥ I(θ)−1 = CRB(θ)
(17)
For both of the evaluations outlined in Section IV, we average
CRB(θ) over the N different point target locations for θ = θ∗.
We compare (ErrMP)θ, (ErrGD)θ, (ErrCNN)θ with CRB(θ).
B. Velocity Estimation
Paralleling the derivation in Section VI-A, we first note that
Yρ consists of K independent radar returns randomly sampled
from yρ ∼ CN(bρ(v)¯Sρ, R), wherein bρ(v) = aρ(θ∗, ϕ, v),
¯Sρ = (PK
j=1[Sρ]j)/K, and R = Σc +Σn. Using the Slepian
formula [15], the Fisher Information for v is defined as:
I(v) = E
"" ∂
∂v ln p(yρ|v)
2#
(18)
= (¯Sρ)2
∂bρ(v)
∂v
H
R−1
∂bρ(v)
∂v

(19)
Wherein ∂bρ(v)
∂v
= [aρ(v) ⊙ ([2 · fc]/c) h)] ⊗ aρ(θ∗, ϕ), with
h = [(2π)(0)/fPR, · · · , (2π)(Λ−1)/fPR]H. Consequently, the
Cram´er Rao Bound, which provides a lower bound on the MSE
of any unbiased estimator of v, is defined as:
E[(ˆv − v)2] ≥ I(v)−1 = CRB(v)
(20)
For both of the evaluations outlined in Section IV, we average
CRB(v) over the N different point target locations for v = v∗.
We compare (ErrMP)v, (ErrGD)v, (ErrCNN)v with CRB(v).
VII. EMPIRICAL RESULTS
As detailed in Section IV, we compare our peak cell mid-
point, gradient descent, and regression CNN methods versus
the CRB across two evaluations: [1] over the range of mean
output SCNR, and [2], over the number of radar returns, K.
For the gradient descent approach, the azimuth estimates were
compiled using α = 1 × 10−5 and T = 100, and the velocity
estimates were compiled using α = 1×10−2 and T = 150. For
the regression CNN case, the azimuth and velocity estimates
were compiled using our Doppler CNN introduced in [7]. The
results of this empirical study are provided in Figure 2.
Per Figure 2, we observe that our regression CNN provides
improved azimuth and velocity parameter estimates, yielding a
test MSE that is below the CRB — this is due to the inherently
biased nature of the regression CNN. More concretely, in each
of our empirical evaluations (for the regression CNN case), we
observe that the bias term of the MSE dominates the variance
term, supporting the notion that the regression CNN is a biased
estimator. This evaluation underscores that the enhancements
achieved with the regression CNN are not attainable utilizing
conventional unbiased estimation methods.
VIII. CONCLUSION
In this paper, we first reviewed the performance of gradient
descent algorithms for estimating azimuth and velocity in radar
systems, confirming their efficiency in approaching the Cram´er
Rao Bound (CRB). Despite their effectiveness, we highlighted
that our proposed regression CNN architecture can outperform
these classical methods. In particular, our comparative analysis
demonstrated that this regression CNN consistently achieves a
reduced MSE when predicting target azimuth and velocity due
to its biased nature; the CNN is not to be interpreted as outper-
forming the CRB. These findings, validated through RFView®
simulations, demonstrated the feasibility of our neural network
approach in complex radar environments. Future research will
be directed toward uncovering the underlying mechanisms of
this improvement and optimizing neural network architectures
for enhanced radar target parameter estimation.
5
REFERENCES
[1] S. Blackman, “Multiple hypothesis tracking for multiple target tracking,”
IEEE Aerospace and Electronic Systems Magazine, vol. 19, no. 1, pp.
5–18, 2004.
[2] T. Ort, I. Gilitschenski, and D. Rus, “Autonomous navigation in in-
clement weather based on a localizing ground penetrating radar,” IEEE
Robotics and Automation Letters, vol. 5, no. 2, pp. 3267–3274, 2020.
[3] Z. Cheng, B. Liao, S. Shi, Z. He, and J. Li, “Co-design for overlaid
mimo radar and downlink miso communication systems via cram´er–rao
bound minimization,” IEEE Transactions on Signal Processing, vol. 67,
no. 24, pp. 6227–6240, 2019.
[4] P. Stoica and A. Nehorai, “Music, maximum likelihood, and cramer-rao
bound,” IEEE Transactions on Acoustics, Speech, and Signal Processing,
vol. 37, no. 5, pp. 720–741, 1989.
[5] F. Xi, Y. Xiang, Z. Zhang, S. Chen, and A. Nehorai, “Joint angle and
doppler frequency estimation for mimo radar with one-bit sampling: A
maximum likelihood-based method,” IEEE Transactions on Aerospace
and Electronic Systems, vol. 56, no. 6, pp. 4734–4748, 2020.
[6] S. M. Kay, Fundamentals of Statistical Signal Processing: Estimation
Theory.
Prentice Hall, 1993.
[7] S. Venkatasubramanian, S. Gogineni, B. Kang, A. Pezeshki, M. Ran-
gaswamy, and V. Tarokh, “Data-driven target localization using adaptive
radar processing and convolutional neural networks,” 2023.
[8] L. Scharf and L. McWhorter, “Adaptive matched subspace detectors and
adaptive coherence estimators,” in Conference Record of The Thirtieth
Asilomar Conference on Signals, Systems and Computers, 1996, pp.
1114–1117 vol.2.
[9] S. Kraut, L. Scharf, and L. McWhorter, “Adaptive subspace detectors,”
IEEE Transactions on Signal Processing, vol. 49, no. 1, pp. 1–16, 2001.
[10] B. Van Veen and K. Buckley, “Beamforming: a versatile approach to
spatial filtering,” IEEE ASSP magazine, vol. 5, no. 2, pp. 4–24, 1988.
[11] S. Venkatasubramanian, C. Wongkamthong, M. Soltani, B. Kang,
S. Gogineni, A. Pezeshki, M. Rangaswamy, and V. Tarokh, “Toward
data-driven stap radar,” in 2022 IEEE Radar Conference (RadarConf22),
2022, pp. 1–5.
[12] S. Gogineni, J. R. Guerci, H. K. Nguyen, J. S. Bergin, D. R. Kirk, B. C.
Watson, and M. Rangaswamy, “High fidelity rf clutter modeling and
simulation,” IEEE Aerospace and Electronic Systems Magazine, vol. 37,
no. 11, pp. 24–43, 2022.
[13] S. Venkatasubramanian, S. Gogineni, B. Kang, A. Pezeshki, M. Ran-
gaswamy, and V. Tarokh, “Subspace perturbation analysis for data-
driven radar target localization,” in 2023 IEEE Radar Conference
(RadarConf23), 2023, pp. 1–6.
[14] H. L. Van Trees, Optimum Array Processing: Part IV of Detection,
Estimation, and Modulation Theory.
John Wiley & Sons, 2002.
[15] D. Slepian, “Estimation of signal parameters in the presence of noise,”
Transactions of the IRE Professional Group on Information Theory,
vol. 3, no. 3, pp. 68–89, 1954.
","nanBuilding upon prior research, this study investigates the potential of regression convolutional neural networks (CNN) in radar target localization. We contrast the performance of these networks with a classical ‘peak cell midpoint’ method, which relies on aggregating test statistics into a multidimensional tensor to determine the target location using the center of the dominant cell. By extracting and synthesizing complex patterns inherent within these tensors, our proposed CNN achieved substantial gains in localization accuracy over the aforementioned more classical approach. Expanding upon these initial findings, we juxtapose gradient descent algorithms for target azimuth and velocity estimation with our proposed regression CNN architecture in a realistic simulated example scenario. Our analysis assesses the parameter estimation accuracies of both methodologies, underscoring the nuanced capability of the CNN model to deliver parameter estimates with a reduced MSE, attributed to its inherent bias."
"By combining machine learning with evolutionary theory, OMNIREP has been used to discover representations and interpreters that succeed on a given problem. The article demonstrates how OMNIREP can be successfully applied within the field of evolutionary art. It also showcases the evolution of artistic images, wherein representations that encode image position coevolve alongside interpreters that transform these positions into one of three pre-defined shapes (chunks, polygons, or circles).","Evolutionary art is a growing domain. The emergence of conferences and impressive results has shown its popularity. The article focuses on the evolution of artistic images through three primary branches of artistic image evolution, differentiated by the standard of ‘beauty’ applied to drive the fitness of evolving images.","The research proposed OMNIREP, a coevolutionary algorithm framework, to discover both a representation and an interpreter that solves a particular problem of interest. An interpreter-representation distinction is put to good use in computer science. The algorithm's basic idea is to not specify a specific representation or interpreter in advance, but rather set up a cooperative coevolutionary algorithm to coevolve the two. The OMNIREP methodology can aid researchers in solving specific problems and as an exploratory tool when searching for a good representation.","The researchers evolved images using OMNIREP with three variations, referred to as chunks, polygons, and circles. A population of representations coevolved alongside a population of interpreters, both of which used a single-population evolutionary algorithm. The images evolved from a state of abstraction to one closer to the inspirational piece.",The article demonstrates the potential of a mutualistic coevolutionary system towards the task of evolved artistic images. The proposed framework can be expanded in the future to generate a greater variety of novel and intriguing imagery.,Coevolving Artistic Images Using OMNIREP,"Moshe Sipper, Jason H. Moore, Ryan J. Urbanowicz","Coevolving Artistic Images Using OMNIREP⋆
Moshe Sipper1,2, Jason H. Moore1, and Ryan J. Urbanowicz1
1 Institute for Biomedical Informatics, University of Pennsylvania, Philadelphia, PA 19104, USA
2 Department of Computer Science, Ben-Gurion University, Beer Sheva 84105, Israel
sipper@gmail.com, https://epistasis.org/
Abstract. We have recently developed OMNIREP, a coevolutionary al-
gorithm to discover both a representation and an interpreter that solve
a particular problem of interest. Herein, we demonstrate that the OM-
NIREP framework can be successfully applied within the field of evolu-
tionary art. Specifically, we coevolve representations that encode image
position, alongside interpreters that transform these positions into one
of three pre-defined shapes (chunks, polygons, or circles) of varying size,
shape, and color. We showcase a sampling of the unique image variations
produced by this approach.
Keywords: Evolutionary algorithms · Evolutionary art · Cooperative
coevolution · Interpretation.
1
Introduction
Evolutionary art is a branch of evolutionary computation (EC) wherein art-
work is generated through an evolutionary algorithm. It is a growing domain,
which has boasted a specialized conference over the past few years [4] and many
impressive results [8,26,27,36].
In the present study we focus on the evolution of artistic images. To this end,
there are generally three major branches of artistic image evolution, differenti-
ated by the standard of ‘beauty’ applied to drive the fitness of evolving images.
The first relies on subjective, interactive feedback from a user [6,29,30].
The second approach relies on a target ‘inspiration’ image to drive fitness. For
example, work by [18] used what is essentially a 1 + 1 evolution strategy—single
parent, single child, both competing against each other—to evolve a replica of
the Mona Lisa using semi-transparent polygons. This type of evolved art can
produce beautiful abstractions of existing pieces of art, or potentially hybrids
of existing images. A series of images sampled during the evolutionary process
targeting an inspiration image can also offer an artistically appealing output.
The third approach to artistic image evolution incorporates aesthetic mea-
sures in the fitness function (light, saturation, hue, symmetry, complexity, en-
tropy, and more) [5,11,14,23].
⋆ This work was supported by National Institutes of Health (USA) grants LM010098,
LM012601, AI116794. ©Springer Nature Switzerland AG 2020 J. Romero et al.
(Eds.): EvoMUSART 2020, LNCS 12103, pp. 165–178, 2020. https://doi.org/10.
1007/978-3-030-43859-3_12
arXiv:2401.11167v1  [cs.NE]  20 Jan 2024
2
M. Sipper et al.
Returning to the evolutionary methodology, one of the EC practitioner’s
foremost tasks is to identify a representation—a data structure—and its inter-
pretation, or encoding. These can be viewed, in fact, as two distinct tasks, though
they are usually dealt with simultaneously. To wit, one might define the repre-
sentation as a bitstring and in the same breath go on to state the encoding or
interpretation, e.g., “the 120-bit bitstring represents 6 numerical values, each
encoded by 20 bits, which are treated as signed floating-point values”.
We have recently developed OMNIREP, a coevolutionary algorithm frame-
work to discover both a representation and an interpreter that solve a partic-
ular problem of interest [32]. We applied OMNIREP successfully to regression
and program-evolution tasks. Herein, we demonstrate that OMNIREP can be
fruitfully applied within the field of evolutionary art. While the interpreter-
representation distinction is perhaps less striking here than with other problems
studied by us, we believe both the results and the future possibilities are worthy
of presentation, as they demonstrate the efficacy of an alternative and flexi-
ble framework for generating evolved art. To the best of our knowledge, this is
the first evolutionary art strategy adopting a cooperative (mutualistic) coevolu-
tionary approach, however, some previous work has explored the application of
competitive (host-parasite) coevolution to evolving images [11].
In the next section we discuss coevolution and its use as a basis for OM-
NIREP. Section 3 briefly discusses some previous work. Section 4 presents the
OMNIREP algorithm and its application to evolving artful pictures. Results are
shown in Section 5, followed by concluding remarks in Section 6.
2
Coevolution and OMNIREP
In this paper we consider two tasks—discovering a representation and discovering
an interpreter—as distinct yet tightly coupled: A representation is meaningless
without an interpretation; an interpretation is useless without a representation.
Our basic idea herein is to employ coevolution to evolve the two simultaneously.
Coevolution refers to the simultaneous evolution of two or more species
with coupled fitness [24]. Coevolving species usually compete or cooperate, with
a third form of coevolution being commensalistism, wherein members of one
species gain benefits while those of the other species neither benefit nor are
harmed [33] (Figure 1).
In a competitive coevolutionary algorithm the fitness of an individual is based
on direct competition with individuals of other species, which in turn evolve
separately in their own populations. Increased fitness of one of the species implies
a reduction in the fitness of the other species [15].
A cooperative coevolutionary algorithm involves a number of independently
evolving species, which come together to obtain problem solutions. The fitness
of an individual depends on its ability to collaborate with individuals from other
species [7,24,25].
The basic idea of OMNIREP can be stated simply: Rather than specify a
specific representation along with a specific interpreter in advance, we shall set
Coevolving Artistic Images Using OMNIREP
3
(a)
(b)
(c)
Fig. 1. Coevolution: (a) cooperative: Purple-throated carib feeding from and pollinat-
ing a flower (credit: Charles J Sharp, https://commons.wikimedia.org/wiki/File:
Purple-throated_carib_hummingbird_feeding.jpg); (b) competitive: predator and
prey—a leopard killing a bushbuck (credit: NJR ZA, https://commons.wikimedia.
org/wiki/File:Leopard_kill_-_KNP_-_001.jpg); (c) commensalistic: Phoretic mites
attach themselves to a fly for transport (credit: Alvesgaspar, https://en.wikipedia.
org/wiki/File:Fly_June_2008-2.jpg).
up a cooperative coevolutionary algorithm to coevolve the two, with a population
of representations coevolving alongside a population of interpreters.3
Of importance to note is OMNIREP’s not being a specific algorithm but
rather an algorithmic framework, which can hopefully be of use in various set-
tings. We believe that the OMNIREP methodology can aid researchers not only
in solving specific problems but also as an exploratory tool when one is seeking
out a good representation [32].
3
Previous Work
Generative and Developmental Encoding is a branch of EC concerned with ge-
netic encodings motivated by biology. A structure that repeats multiple times can
be represented by a single set of genes that is reused in a genotype-to-phenotype
mapping [2,12,13,16,19,20,34,35].
In Gene Expression Programming the individuals in the population are en-
coded as linear strings of fixed length, which are afterwards expressed as non-
linear entities of different sizes and shapes (i.e., simple diagram representations
or expression trees) [9].
Though not used extensively, variable-length genomes have been around for
quite some time (of course, some representations, such as trees in genetic pro-
gramming, are inherently variable-length; herein, we simply refer to the literature
on “variable-length genomes”) [10,21].
Grammatical Evolution (GE) was introduced by [28] as a variation on ge-
netic programming. Here, a Backus-Naur Form (BNF) grammar is specified that
allows a computer program or model to be constructed by a simple genetic al-
gorithm operating on an array of bits. The GE approach is appealing because
3 OMNIREP derives from ‘OMNI’—universal, and ‘REP’—representation; it also de-
notes an acronym: Originating MeaNing by coevolving Interpreters and REPresen-
tations.
4
M. Sipper et al.
only the specification of the grammar needs to be altered for different applica-
tions. One might consider subjecting the grammar encoding to evolution in an
OMNIREP manner (as done, e.g., by [1]).
Within a memetic computing framework, Iacca et al. [17] proposed, “a bottom-
up approach which starts constructing the algorithm from scratch and, most im-
portantly, allows an understanding of functioning and potentials of each search
operator composing the algorithm.” Caraffini et al. [3] proposed a computational
prototype for the automatic design of optimization algorithms, consisting of two
phases: a problem analyzer first detects the features of the problem, which are
then used to select the operators and their links, thus performing the algorithmic
design automatically. Both these works share the desire to tackle basic algorith-
mic design issues in a (more) automatic manner.
Tangentially related to our work herein is the extensive research on param-
eters and hyper-parameters in EC, some of which has focused on self-adaptive
algorithms, wherein the parameters to be adapted are encoded into the chro-
mosomes and undergo crossover and mutation. The reader is referred to [31]
for a comprehensive discussion of this area. Another tangential connection is to
“smart” crossover and mutation operators, wherein, interestingly, coevolution
has also been applied [37].
4
Evolving Art using OMNIREP
OMNIREP uses cooperative coevolution with two coevolving populations, one
of representations, the other of interpreters. The evolution of each population is
identical to a single-population evolutionary algorithm—except where fitness is
concerned (Figure 2). One might argue that the distinction between “represen-
tation” and “interpretation” is a malleable one, but this distinction is often put
to good use in computer science [32].
We describe below in detail the components and parameters of the OM-
NIREP system, including: population composition, initialization, selection, crossover,
mutation, fitness, elitism, evolutionary rates, and parameters.
Populations. To showcase the application of OMNIREP to evolutionary
art, we designed three relatively simple interpreter-representation setups, which
produced quite striking results; we refer to them as: chunks, polygons, and circles
(Figure 3). These setups evidence the ease with which OMNIREP can be applied
beneficially.
Chunks. An evolving image is composed of linear chunks. A two-dimensional
image of dimensions {width, height} is treated as a one-dimensional list of pixels
of size width × height (ranging from 10848 pixels to 68816, depending on the
particular inspiration image selected for fitness). The representation individual’s
genome is a list of pixel indexes, pi ∈ {0, . . . , width∗height−1}, i = 1, . . . , 5000,
where pi is the start of a same-color chunk of pixels. The interpreter individual is
a list equal in length to the representation individual, consisting of tuples (bi, ci),
where bi is chunk i’s length, and ci is chunk i’s color. The image-producing
process moves sequentially through the list of chunks, coloring pixels i through
Coevolving Artistic Images Using OMNIREP
5
Fig. 2. OMNIREP algorithm adapted to the task of evolutionary art. (A). OMNIREP
includes two coevolving populations, one with candidate representations, and the other
with candidate interpreters. Each population is evolved using the same fundamental
evolutionary algorithm mechanisms (as summarized in the purple boxes). (B) The
fitness of a given representation depends on representative interpreters (i.e., the 4
interpreters with the best fitness from the previous generation). In this example R3’s
fitness is the average fitness of the four representation-interpreter pairings. The fitness
of a given interpreter (e.g., I3) similarly depends on representative representations (not
shown). The fitness of a representation-interpreter pair is computed by combining a
representation individual (R) with an interpreter individual (I) to produce the pixel
values of an image. Pair fitness is the mean absolute error between the pixels of the
new image vs. the inspiration image.
6
M. Sipper et al.
Fig. 3. Overview and examples of the three image-mapping strategies employed by
OMNIREP in experimental evolutionary runs.
Coevolving Artistic Images Using OMNIREP
7
i + bi − 1 with color ci. If a pixel is uncolored by any chunk it is assigned a
default base color.
Thus an interpreter individual combines with a representation individual to
paint a picture, made up of same-color chunks of length and color indicated by
the former and start positions indicated by the latter.
Polygons. An evolving image is composed of polygons. The representation
individual’s genome is a list of 600 polygon coordinates, [xi, yi], i ∈ {1, . . . , 600}.
The number of polygons was set to 50 and the maximum number of sides to
12, hence 600. The interpreter individual is a list of length 50, representing 50
polygons, consisting of tuples (si, ci), where si is polygon i’s shape, i.e., number
of sides, and ci is polygon i’s color.
An interpreter individual combines with a representation individual to paint
a picture, made up of 50 polygons whose shape and color are indicated by the
former and coordinates by the latter. The image-producing process moves se-
quentially through the interpreter and representation genomes, picking the ap-
propriate number of coordinates determined by si, and coloring the resultant
shape with color ci. Coordinates “left over” in the representation genome in the
end are unused.
Circles. An evolving image is composed of circles. The representation individ-
ual’s genome is a list of 50 circle centers, [xi, yi], i ∈ {1, . . . , 50}. The interpreter
individual is a list equal in length to the representation individual, consisting of
tuples (ci, ri), where ci is circle i’s color and ri is its radius.
An interpreter individual combines with a representation individual to paint
a picture, made up of 50 circles whose colors and radii are indicated by the
former and centers by the latter.
For chunks, polygons, and circles, if there is any overlap in these shapes form-
ing the image, the most recently placed shape opaquely covers the overlapped
shape.
Initialization. For every coevolutionary run: both populations are initialized
to random values in the appropriate range, depending on the particulars of the
interpreter-representation setup delineated above (chunks, polygons, or circles).
An inspiration image is chosen per evolutionary run as one of the 8 shown in
Figure 4. The inspiration images were converted to 4 colors from their originals
using Python’s Image.ADAPTIVE palette (in the PIL package). Note that the 4
colors differ between images.
Selection. Tournament selection with tournament size 4, i.e., choose 4 indi-
viduals at random from the population and return the individual with the best
fitness as the selected one.
Crossover. Single-point crossover — select a random crossover point and
swap two parent genomes beyond this point to create two offspring — is employed
every generation.
Mutation. Mutation is done with probability 0.3 (per individual) by select-
ing a random gene and replacing it with a new random value in the appropriate
range.
8
M. Sipper et al.
Fig. 4. Inspirational images.
Fitness. To compute fitness the two coevolving populations cooperate. Specif-
ically, to compute the fitness of a single individual in one population, we use
representatives from the other population [24]. The representatives (also called
cooperators) are selected via a greedy strategy as the 4 fittest individuals from
the previous generation. When evaluating the fitness of a particular represen-
tation individual, we combine it 4 times with the top 4 interpreter individuals,
compute 4 fitness values, and use the average fitness over these 4 evaluations as
the final fitness value of the representation individual. In a similar manner we
use the average of 4 representatives from the representations population when
computing the fitness of an interpreter individual. (Other possibilities include
using the best fitness of the 4, the worst fitness, and selecting a different mix of
representatives, e.g., best, median, and worst.)
A representation individual and an interpreter individual are combined as
described above per interpreter-representation setup (chunks, polygons, or cir-
cles). A single fitness value then equals the mean absolute error with respect to
the known inspirational pixels (Figure 2).
Note that our objective was not to reproduce the original image precisely—
which would be uninteresting. Rather, the selected image serves as inspiration,
setting an evolutionary direction.
Elitism. The 2 individuals with the highest fitness in a generation are copied
(“cloned”) into the next generation unchanged.
Evolutionary rates differ between the two populations, with the inter-
preters population evolving more slowly, specifically, every 3 generations.
Parameters. Table 1 provides a summary of parameters discussed through-
out the paper.4
4 Some parameters may seem arbitrary but our recent findings provide some justifi-
cation for this [31].
Coevolving Artistic Images Using OMNIREP
9
Table 1. Evolutionary parameters. Shown first are common parameters, followed by
experiment-specific ones.
Description
Value
Common
Number of images
8
Size of representations population
20
Size of interpreters population
10
Type of selection
Tournament
Tournament size
4
Type of crossover
single-point
Probability of mutation (representations)
0.3
Probability of mutation (interpreters)
0.3
Evolve interpreters population every
3 generations
Number of representatives used for fitness
4
Number of top individuals copied (elitism)
2
Number of colors
4
Chunks
Number of generations
20000
Size of representation individual
5000
Size of interpreter individual
5000 (chunks)
Minimum chunk size
1 pixel
Maximum chunk size
10 pixels
Polygons
Number of generations
50000
Size of representation individual
600
Size of interpreter individual
50 (polygons)
Minimum polygon sides
3
Maximum polygon sides
12
Circles
Number of generations
50000
Size of representation individual
50
Size of interpreter individual
50 (circles)
Minimum radius
3
Maximum radius
50
10
M. Sipper et al.
5
Results
We performed multiple evolutionary runs for each of the 8 target images. Fig-
ures 5 through 7 present select examples of the images evolved with OMNIREP.
Each figure gives sample outputs from each of the three underlying setups uti-
lized (i.e., chunks, circles, or polygons). Each set of 4 images (derived from a
specific inspiration image) serves two purposes: (1) demonstrating the evolu-
tionary trajectories of evolving art, namely, images in intermediate generations
of an evolutionary run, and (2) presenting the images as part of a ‘panel’, i.e.,
a collection of images in series, meant to be viewed as a single artistic piece.
Indeed, subjectively, we feel that part of the appeal of the images evolved by
OMNIREP is the progression of an image from a state of abstraction to one
closer to the inspirational piece. Of course, individual images generated with
OMNIREP can also be selected as the output artistic piece.
Beyond generating static images, we have also explored converting the set of
evolving images into appealing animated GIFs (see samples at https://github.
com/EpistasisLab/OMNIREP).
Fig. 5. Evolutionary trajectories of evolving images (chunks). Each row represents a
single run.
Coevolving Artistic Images Using OMNIREP
11
Fig. 6. Evolutionary trajectories of evolving images (circles). Each row represents a
single run.
6
Concluding Remarks
We adapted and applied OMNIREP, which coevolves representations and inter-
preters simultaneously, to evolutionary art. This work demonstrates the potential
of a mutualistic coevolutionary system, as well as a strategy that separates rep-
resentations from interpreters, towards the task of evolved artistic images. This
framework can be flexibly extended in the future to generate an even greater
diversity of novel and intriguing imagery.
Some of the immediate future directions we expect would be valuable to
explore include:
1. Expansion of the color palette beyond 4 colors per image.
2. Giving interpreters the option to choose one or more shapes (i.e., chunks,
polygons, or circles) to incorporate into a given evolved image.
3. Expand the shape options to include other forms or orientations (e.g., ellip-
soids, squares, rectangles, etc.).
4. Promote overlapping shapes in the image and assign color mixes to the image
in these overlapping regions.
5. More complex interpreters, e.g., an interpreter genetic programming tree
that interprets a representation of pixels.
6. Evolving a hybrid of multiple inspiration images through integration of mul-
tiobjective optimization.
7. Incorporate novelty [22] into the coevolutionary algorithm (as proposed in
[33]) to promote a greater variety of novel images that create interesting
departures from the inspiration image.
We perceive OMNIREP not as a particular algorithm but rather as a meta-
algorithm, which might hopefully be suitable for other settings, beyond the artful
one described herein. Essentially, any scenario where some form of representation
12
M. Sipper et al.
Fig. 7. Evolutionary trajectories of evolving images (polygons). Each row represents a
single run.
Coevolving Artistic Images Using OMNIREP
13
may be interpreted in several ways, or where the representation and interpreter
can be rendered “fluid” rather than fixed, might be a candidate for an OMNIREP
approach.
References
1. Azad, R.M.A., Ryan, C.: An examination of simultaneous evolution of grammars
and solutions. In: Yu, T., Riolo, R., Worzel, B. (eds.) Genetic Programming Theory
and Practice III. pp. 141–158. Springer US, Boston, MA (2006)
2. Bentley, P., Kumar, S.: Three ways to grow designs: A comparison of embryogenies
for an evolutionary design problem. In: Proceedings of the 1st Annual Conference
on Genetic and Evolutionary Computation - Volume 1. pp. 35–43. GECCO’99,
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA (1999), http://dl.
acm.org/citation.cfm?id=2933923.2933928
3. Caraffini, F., Neri, F., Picinali, L.: An analysis on separability for memetic com-
puting automatic design. Information Sciences 265, 1–22 (2014)
4. Correia, J., Ciesielski, V., Liapis, A.: Proceedings of Computational Intelligence
in Music, Sound, Art and Design: 6th International Conference. Springer, Berlin
(2017)
5. Datta, R., Joshi, D., Li, J., Wang, J.Z.: Studying aesthetics in photographic images
using a computational approach. In: European conference on computer vision. pp.
288–301. Springer (2006)
6. Dawkins, R.: The Blind Watchmaker: Why the Evidence of Evolution Reveals a
Universe Without Design. WW Norton & Company (1996)
7. Dick, G., Yao, X.: Model representation and cooperative coevolution for finite-state
machine evolution. In: 2014 IEEE Congress on Evolutionary Computation (CEC).
pp. 2700–2707. IEEE, Piscataway, NJ (2014)
8. DiPaola, S., Gabora, L.: Incorporating characteristics of human creativity into an
evolutionary art algorithm. Genetic Programming and Evolvable Machines 10(2),
97–110 (2009)
9. Ferreira, C.: Gene expression programming: A new adaptive algorithm for solving
problems. Complex Systems 13(2), 87–129 (2001)
10. Goldberg, D.E., Korb, B., Deb, K.: Messy genetic algorithms: Motivation, analysis,
and first results. Complex Systems 3, 493–530 (1989)
11. Greenfield, G.R.: Simulated aesthetics and evolving artworks: A coevolutionary
approach. Leonardo 35(3), 283–289 (2002)
12. Gruau, F., Whitley, D., Pyeatt, L.: A comparison between cellular encoding and
direct encoding for genetic neural networks. In: Proceedings of the 1st Annual
Conference on Genetic Programming. pp. 81–89. MIT Press, Cambridge, MA, USA
(1996), http://dl.acm.org/citation.cfm?id=1595536.1595547
13. Hart,
W.E.,
Kammeyer,
T.E.,
Belew,
R.K.:
The
role
of
development
in
genetic
algorithms.
In:
Whitley,
L.D.,
Vose,
M.D.
(eds.)
Founda-
tions
of
Genetic
Algorithms.
vol.
3,
pp.
315
–
332.
Elsevier
(1995).
https://doi.org/https://doi.org/10.1016/B978-1-55860-356-1.50019-4,
http:
//www.sciencedirect.com/science/article/pii/B9781558603561500194
14. den Heijer, E., Eiben, A.E.: Comparing aesthetic measures for evolutionary art.
In: European Conference on the Applications of Evolutionary Computation. pp.
311–320. Springer (2010)
14
M. Sipper et al.
15. Hillis, W.: Co-evolving parasites improve simulated evolution as an optimization
procedure. Physica D: Nonlinear Phenomena 42(1), 228 – 234 (1990)
16. Hornby, G.S., Pollack, J.B.: Creating high-level components with a generative rep-
resentation for body-brain evolution. Artificial Life 8(3), 223–246 (2002)
17. Iacca, G., Neri, F., Mininno, E., Ong, Y.S., Lim, M.H.: Ockham’s razor in memetic
computing: three stage optimal memetic exploration. Information Sciences 188,
17–43 (2012)
18. Johansson,
R.:
Genetic
programming:
Evolution
of
Mona
Lisa.
www.rogerjohansson.blog/2008/12/07/
genetic-programming-evolution-of-mona-lisa/
(2008),
[Online;
accessed
23-April-2018]
19. Koza, J.R.: Genetic Programming IV: Routine Human-Competitive Machine In-
telligence. Kluwer Academic Publishers, Norwell, MA, USA (2003)
20. Koza, J.R., Andre, D., Bennett, F.H., Keane, M.A.: Genetic Programming III:
Darwinian Invention & Problem Solving. Morgan Kaufmann Publishers Inc., San
Francisco, CA, USA, 1st edn. (1999)
21. Lee, C.Y., Antonsson, E.K.: Variable length genomes for evolutionary algorithms.
In: Proceedings of the Genetic and Evolutionary Computation Conference. Morgan
Kaufmann (2000)
22. Lehman, J., Stanley, K.O.: Exploiting open-endedness to solve problems through
the search for novelty. In: In Proceedings of the Eleventh International Conference
on Artificial Life (ALIFE). MIT Press (2008)
23. Machado, P., Romero, J., Manaris, B.: Experiments in computational aesthetics.
In: The art of artificial evolution, pp. 381–415. Springer (2008)
24. Pena-Reyes, C.A., Sipper, M.: Fuzzy CoCo: A cooperative-coevolutionary approach
to fuzzy modeling. IEEE Transactions on Fuzzy Systems 9(5), 727–737 (2001)
25. Potter, M.A., De Jong, K.A.: Cooperative coevolution: An architecture for evolving
coadapted subcomponents. Evolutionary Computation 8(1), 1–29 (2000)
26. Romero, J., Machado, P. (eds.): The Art of Artificial Evolution: A Handbook on
Evolutionary Art and Music. Natural Computing Series, Springer (2008)
27. Romero, J., McDermott, J.: Evomusart 2014: Third international conference on
evolutionary and biologically inspired music, sound, art and design. Leonardo
49(3), 245–245 (2016)
28. Ryan, C., Collins, J.J., O’Neill, M.: Grammatical evolution: Evolving programs
for an arbitrary language. In: Genetic Programming, First European Workshop,
EuroGP’98, Paris, France, April 14-15, 1998, Proceedings. pp. 83–96 (1998).
https://doi.org/10.1007/BFb0055930, https://doi.org/10.1007/BFb0055930
29. Secretan, J., Beato, N., D Ambrosio, D.B., Rodriguez, A., Campbell, A., Stanley,
K.O.: Picbreeder: evolving pictures collaboratively online. In: Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems. pp. 1759–1768.
ACM (2008)
30. Sims, K.: Artificial evolution for computer graphics, vol. 25. ACM (1991)
31. Sipper, M., Fu, W., Ahuja, K., Moore, J.H.: Investigating the parameter space of
evolutionary algorithms. BioData Mining 11(2), 1–14 (2018)
32. Sipper, M., Moore, J.H.: OMNIREP: originating meaning by coevolving encodings
and representations. Memetic Computing pp. 1–11 (2019)
33. Sipper, M., Moore, J.H., Urbanowicz, R.J.: Solution and fitness evolution (SAFE):
Coevolving solutions and their objective functions. In: European Conference on
Genetic Programming (EuroGP 2019). Springer International Publishing, Cham
(2019), (to appear)
Coevolving Artistic Images Using OMNIREP
15
34. Stanley, K.O., D’Ambrosio, D.B., Gauci, J.: A hypercube-based encoding for evolv-
ing large-scale neural networks. Artificial life 15(2), 185–212 (2009)
35. Stanley, K.O., Miikkulainen, R.: A taxonomy for artificial embryogeny. Artificial
Life 9(2), 93–130 (2003)
36. Wikipedia:
Evolutionary
art
(2018),
https://en.wikipedia.org/wiki/
Evolutionary_art
37. Zaritsky, A., Sipper, M.: The preservation of favored building blocks in the struggle
for fitness: The puzzle algorithm. IEEE Transactions on Evolutionary Computation
8(5), 443–455 (2004)
","The first relies on subjective, interactive feedback from a user; the second approach relies on a target ‘inspiration’ image to drive fitness; the third approach to artistic image evolution incorporates aesthetic measures in the fitness function (light, saturation, hue, symmetry, complexity, entropy, and more).nan"
"This study explores the potential and the limitations of ChatGPT in a Functional Programming course. Experiments were conducted on a corpus of 72 coding assignments, showing that ChatGPT provides correct answers in 68% of cases, but only half of those are legible solutions beneficial to students. However, ChatGPT excels at code review, providing 77% accurate responses to generated feedback questions.","ChatGPT is a chatbot based on supervised and reinforcement learning capable of answering questions, generating text, and writing code. Its release has sparked discussions about its usage in academia, particularly by students for completing homework assignments. This research investigates ChatGPT's accuracy and usefulness in educational settings by solving a semester's worth of coding assignments and evaluating its performance.","This study utilizes a dataset consisting of 72 coding assignments from a Functional Programming course, categorized based on difficulty, statement complexity, and solution size. Each exercise was evaluated using ChatGPT, assessing the correctness, legibility, and efficiency of the generated solutions. ChatGPT's ability to improve its responses to feedback and to generate accurate tests for the solutions was also examined. Furthermore, a code-reviewing tool was developed to automate the code-review process using ChatGPT.","ChatGPT achieved an overall accuracy of 68% in generating correct solutions, with a 57% rate of legibility among the correct answers. Follow-up questions improved ChatGPT's performance to 86% accuracy, but legibility remained a challenge. ChatGPT could generate correct tests for 70% of the assignments, although its ability to improve incorrect tests was limited. The tool developed for code review produced a 77% accuracy rate in identifying issues and suggesting improvements in the submitted homework.","Although ChatGPT exhibits strong performance in coding assignments, its solutions are not always legible or efficient, hindering their usefulness for student learning. However, ChatGPT demonstrates exceptional ability in code review, providing valuable insights and feedback. This study emphasizes the need for further exploration into ChatGPT and similar tools in education. It is crucial to understand the benefits and drawbacks of these tools, particularly in the context of programming courses, and to develop strategies for using them effectively in teaching and learning.",ChatGPT in the classroom. Exploring its potential and limitations in a Functional Programming course,Dan-Matei Popovici,"ChatGPT in the classroom. 
Exploring its potential and limitations in a Functional 
Programming course.
Matei Dan Popovici 
POLITEHNICA University of Bucharest 
Splaiul Independentei 313. 
Bucharest, Romania 
matei.popovici@upb.ro 
 
ABSTRACT 
In November 2022, OpenAI has introduced ChatGPT – a chatbot based on supervised and reinforcement learning. Not only can it answer 
questions emulating human-like responses, but it can also generate code from scratch or complete coding templates provided by the user. 
ChatGPT can generate unique responses which render any traditional anti-plagiarism tool useless. Its release has ignited a heated debate 
about its usage in academia, especially by students. We have found, to our surprise, that our students at POLITEHNICA University of 
Bucharest (UPB) have been using generative AI tools (ChatGPT and its predecessors) for solving homework, for at least 6 months. We 
therefore set out to explore the capabilities of ChatGPT and assess its value for educational purposes. We solved all our coding asignments 
for the semester from our UPB Functional Programming course. We discovered that, although ChatGPT provides correct answers in 68% of 
the cases, only around half of those are legible solutions which can benefit students in some form. On the other hand, ChatGPT has a very 
good ability to perform code review on student programming homework. Based on these findings, we discuss the pros and cons of ChatGPT 
in education. 
1. INTRODUCTION 
ChatGPT [7] has experienced a surge in popularity in recent times. There is a great deal of lively debate 
surrounding its potential uses, impact on research [4], science [5], and education [1,3,6]. Since its increase 
in popularity in November 2022, academia has been testing its limits with surprising results in its apparent 
proficiency to address a wide range of questions. ChatGPT is the most recent addition to a series of 
generative pre-trained transformers (GPTs) that utilize language AI models trained on vast amounts of 
human text. Its purpose is to generate discourses that closely resemble those produced by humans. In brief, 
ChatGPT relies on word probabilities to predict the most meaningful continuation of a current sentence. 
In addition, ChatGPT incorporates a degree of randomness, resulting in text that appears more natural and 
human-like. Due to its ability to generate coherent discourse, ChatGPT is an attractive option for students 
who wish to utilize it for various homework assignments: written essays, argumentation, coding. 
Additionally, its ability to generate unique text renders all traditional plagiarism tools ineffective, adding 
to its appeal as a valuable resource for students.  
While the debate about ethics and long-term implications of ChatGPT carries on, there is also a separate 
debate, among students, about the role of ChatGPT in learning and access to correct information. We have 
conducted a survey among more than 180 students which shows that at least 40% of respondents have 
used generative AI tools for solving homework on at least one occasion. At the same time, only 28% of 
students believe that this has benefited them in actual learning or in a better understanding of the 
assignment. It is well-known that ChatGPT is not designed to provide references for the text it generates, 
thus making it hard, if not impossible to trace every statement to assess its validity. Despite that, at our 
University reports have surfaced anecdotally of students favoring ChatGPT answers as a study resource 
over lecture notes to prepare for exams. While ChatGPT eliminates the need for reformulation and 
narrative discourse development, it also underscores the importance of the verification and validity of 
information sources. 
Our work is an attempt to explore this problem, in the limited setting of an undergraduate programming 
course taught at POLITEHNICA University of Bucharest (UPB) to undergraduate second-year students. 
We are interested in exploring how and to what extent ChatGPT can benefit both students and tutors in 
supporting the educational process in a positive and constructive manner. We firmly believe that ChatGPT 
is a valuable tool and that forbidding it, by ignorance or by rules, as was the case in New York City where 
ChatGPT was blocked [3], is both impractical and lacking in innovation.  
Our goal is to gain a deeper understanding of the tool and its limitations, while also exploring healthy 
ways for its application in a programming-focused lecture. We have initiated an extensive survey to gain 
insights into our students' relationship with ChatGPT. We have found that: (i) over 40% of the respondents 
have been using ChatGPT or similar tools for at least 6 months for coding assignments, and (ii) over 38% 
of the respondents are confident with the answers provided by ChatGPT. The complete details of the 
survey are discussed in Section 2. 
Subsequently, we studied the actual precision of ChatGPT in solving programming assignments. We 
subjected our complete corpus of 72 programming tasks, which covers the entire laboratory of our 
Functional Programming lecture [17] to ChatGPT to evaluate its performance. Laboratories include 
mostly medium to short programming assignments which students usually solve in class with the help of 
a Teaching Assistant. In our study, a solution generated by ChatGPT must: (i) compile as well as (ii) pass 
a series of tests to be deemed correct. In addition to these two distinct criteria, we include two more: (iii) 
a solution must be educational in some sense - students should have the opportunity to learn from reading 
it, and (iv) efficient - it must use sound coding practices which ensure code legibility as well as efficiency. 
The latter is our primary teaching goal in our course. We were surprised to see that ChatGPT did very 
well on our tasks. ChatGPT as a student would receive an approximate score of 7 out of a maximum of 
10. Nonetheless, 43% of the accurate solutions provided by ChatGPT are either inefficient or comprise of 
code that is incomprehensible for the average student. We were also interested to see to what extent 
ChatGPT is able to correct itself when errors within its answers are highlighted. We discovered that 
ChatGPT could enhance its score from 7 to 8.6, once a follow-up question or issue was highlighted. 
However, prompting such issues requires a certain level of expertise from the average student. To this 
end, we also used ChatGPT to generate tests for each of its solutions. We have found that only 70% of 
generated tests are correct, and not even follow-up questions can improve this result. Our labs do not 
provide tests for students in our assignments. Thus, when a test fails, students may find it difficult to 
determine whether the issue lies with the solution or in the test supplied by ChatGPT. The entire setup, as 
well as results for our evaluation study are detailed in Section 3.  
Lastly, during our assessment, we noticed that ChatGPT can accurately respond to qualitative questions 
concerning the code we submitted. Examples of such questions are: “is the code functional?”, “does the 
code use side-effects?”, “is the given function tail-recursive?”. This observation prompted us to develop 
a tool which relies on ChatGPT for code-reviewing submitted homework. Unlike testing, which ensures 
the correctness of a submitted solution, the objective of code review is to assess and possibly improve the 
legibility and structure of the code. In our lecture, it is particularly important to review if the code was 
written in the functional style. Our team usually goes over more that 60 submissions, for each of the 4 
homework that we give in the Functional Programming lecture. Although code-review is highly beneficial 
for students, conducting it comprehensively can be extremely time-consuming and resource-intensive for 
our team. Our tool relying on ChatGPT can automate most of this process, with high accuracy. Code 
reviewers can select dedicated parts of the homework under review (e.g. functions with specific names), 
then formulate questions such as the ones previously illustrated. Our tool will parse the desired code 
fragment from each submitted homework and combine it with the question we are targeting. Next, it will 
perform a sequence of ChatGPT queries, one for each homework, and retrieve each answer. These can 
subsequently be subject to human review before being submitted as feedback to students. We supply more 
details on this in Section 4. 
We draw conclusions and discuss the implications of our observations in Section 5 and in Section 6 we 
review related work. 
2. CHATGPT AND THE STUDENT BODY  
At the beginning of January 2023 we have performed a survey at POLITEHNICA University of Bucharest 
and received 181 responses from students mostly ranging in the second and third years. We have found 
that, within the last year, 31% of students became aware of code generation tools, while over 55% became 
aware of them within the last 6 months of the survey time. Over 40% of responding students have reported 
using generative AI for homework and lab assignment. Roughly a third of responding students believe 
generative AI has good or perfect accuracy, meaning that it generates code which is correct and compiles. 
At the same time, a third of responders believe such tools to have low accuracy and 13% believe they are 
not accurate at all. Finally, when asked whether generative AI has been helpful in solving programming 
assignments, 42% of respondents believe it has been helpful, while 40% believe it has provided little to 
no assistance.  
 
 
 
 
 
 
The survey clearly indicates that tools such as ChatGPT are utilized by students in writing homework and 
pursuing exams. For this reason, we would like to gain a better understanding into the accuracy and 
practicality of generative AI tools, in particular ChatGPT, in providing correct but also useful results for 
students. 
 
 
 
 
Figure 1. Survey results: Answers to: (left) “When did you hear about generative AI?” (right) “How many times have you used generative 
AI for homework or other school activities?” 
. 
 
 
Figure 2. Survey results: Answers to: (left) “Has generative AI helped you gain a better understanding of curricula?” (right) “Do you believe 
generative AI has good accuracy?” 
 
 
3. CHATGPT EVALUATION 
3.1 Dataset description and methodology 
Our dataset consists of the entire corpus of exercises spanning 7 labs from the lecture “Functional 
Programming” (FP) taught in the Scala programming language [15] during the second year of a Computer 
Science engineering degree program at UPB. It contains 72 coding exercises, which we grouped into three 
categories: easy (23 exercises), medium (35 exercises), hard (14 exercises), based on our teaching 
experience from previous years.  
 
We tagged each exercise as having a simple (49 exercises) or complex statement (23 exercises). Simple 
statements are single-phrased and may be followed by a simple function signature. Complex statements 
are multi-paragraph, may contain several code snippets which are relevant for the solution or alternatively 
may contain mathematical equations described using ASCII symbols (e.g. x_1^2 + 1 = x_2). Many of our 
exercises rely on templates, wherein the students are required to fill-out a function signature or a code 
structure provided to them. An example of such a template is the following: 
 
def factorial (n: Int): Int = ??? 
A small number of exercises (9 in number) are not template-based. Their statement is defined solely in 
natural language.  Finally, we have also classified each 
exercise according to the size of the solution, more precisely 
its number of lines of code (loc), into: small (1 to 6 loc) - 49 
exercises, medium (6-12 loc) - 18 exercises and large (over 12 
loc) - 5 exercises.  
The version of ChatGPT utilized in our experiments was the 
one released on January 30th. To maintain context, each 
interaction with ChatGPT was conducted seamlessly in a 
single chat session, to allow ChatGPT to learn from previous 
answers and to preserve context. Some sets of exercises may 
require individual solutions which, used in combination, can 
be utilized to solve a more intricate problem. For instance, 
computing the square root of a natural number using Newton’s 
Approximation Method requires a function which: (i) improves by one iteration one estimation of the 
square root and another which (ii) checks if an estimation is accurate enough (by a given threshold). These 
are split along several exercises. 
Figure 3. Breakdown of our dataset into: (left) hard, medium and easy exercises. (right) exercises with simple/complex statements. 
 
 
Figure 4. Breakdown of our dataset into exercises with 
small, medium or large-sized solutions. 
 
 
We ran each solution generated by ChatGPT using the Scala compiler. We have found that most solutions 
compile, hence we focused on their correctness which we evaluated using our own tests. We have recorded 
all valid solutions from the initial ChatGPT response. If a solution was incorrect (with some tests failing 
or, less frequently, being unable to compile) we replied to ChatGPT that there was an issue, without any 
indication of the specific problem. If the second follow-up answer did not produce a correct solution, we 
tried to steer ChatGPT towards the root-cause of the problem. We wanted to see if ChatGPT can improve, 
however this usage scenario is less likely from a student’s viewpoint, since we do not provide tests for 
students in our lab. We find it less likely that students which rely on ChatGPT will able to write good test-
suites for their solutions. 
We have found that, in many instances, if ChatGPT’s second solution was incorrect, our recommendations 
were not useful in enhancing its response. If the answer remained incorrect, we stopped after the second 
suggestion and recorded whether the answer was improved. We used ChatGPT to generate tests for each 
solution and followed the same procedure as previously described (a maximum of two follow-up questions 
if the test was incorrect). Lastly, we documented whether the final solution was legible or not. An illegible 
solution contains code or code-structure which is not necessarily incorrect, but it is either unnatural or 
difficult to understand from a learning perspective. We provide two examples (generated by ChatGPT): 
def take(n: Int, l: List[Int]): List[Int] = { 
def go(n: Int, result: List[Int], l: List[Int]): List[Int] = 
(n, l) match { 
case (0, _) => result.reverse 
case (_, Nil) => result.reverse 
case (n, h :: tail) => go(n - 1, h :: result, tail) 
} 
go(n, Nil, l) 
} 
The function take creates a new list containing only the first n elements of list l. The natural solution to 
implement take is using simple recursion. The solution given by ChatGPT relies on a helper function go, 
which is tail-recursive and has the property of extracting elements in reverse order. For this reason, before 
returning the result, the list must be reversed. This behavior is not yet understood at this stage of our 
lecture, and students not familiar with tail-recursion may have a hard time understanding why reversal is 
necessary. This type of an illegible solution (although correct and effective) will not help students in 
comprehending the task and may result in them incorrectly assuming that reversal is a necessary 
component of the take implementation. 
The second example is a solution for a task related to the main diagonal of a matrix. The two nested for’s 
(over i and j) are not necessary and are inefficient. They should be replaced by a single for loop ranging 
over the line/column of the matrix. 
for (i <- 0 until n) { 
 for (j <- 0 until m) { 
   diagImg(i)(j) = img(i)(j) 
   if (i == j || i + j == n - 1) diagImg(i)(j) = 1 
 } 
} 
3.2 Evaluation results 
We have found that ChatGPT performs surprisingly well and for two exercises it actually produced better 
code than our official solutions. However, the “first response” solution is correct only in 68% of the cases, 
which is roughly two-thirds. Thus, ChatGPT’s performance is comparable to that of an average student. 
Once one or more follow-up questions are given, ChatGPTs improvement is substantial: 86% of the 
generated solutions are correct.  
However, the percentage of legible solutions out of all correct ones is 57%, which means that almost one 
in two correct answers may not actually be insightful for 
the student, either because the code is hard to understand, 
or because it is not efficient or properly written. In 60% of 
the cases when a follow-up question was asked, the answer 
was helpful in the sense that ChatGPT improved on the 
previous solution, either by giving a better code structure which is still incorrect or by immediately 
identifying the correct solution. 
The percentage of correct tests that was generated from the first response is comparable to that of the 
solutions: 70%. Unfortunately, ChatGPT is unable to improve on most of its incorrect tests. After follow-
up questions the percentage of correct generated tests increases only to 72%. ChatGPT is unable to infer 
basic mathematical facts. One such example is finding the divisors of 7 out of a range of integers. When 
asked if 7 is a divisor of 21 (7 was generating an incorrect test in one exercise), ChatGPT was unable to 
reply correctly. The answers to follow-up questions did not help in improving the answer. 
We were interested to see whether ChatGPT’s correct answers correlate with features of our exercises. 
We discovered that, for exercises involving complex 
statements, the initial correct answer rate was 52%, which 
increased to 78% after follow-up questions. On the other hand, 
 
Simple 
statements 
Complex statements 
Correct in the first reply 
75% 
52% 
Correct after follow-up 
questions 
89% 
78% 
 
Easy 
exercises 
Medium exercises 
Hard exercises 
Correct in the first reply 
69% 
71% 
57% 
Correct after follow-up questions 
91% 
88% 
71% 
Figure 5. ChatGPT exercise correctness results 
 
Figure 7. Correctness of ChatGPT solution per statement 
size. 
 
 
Figure 6. ChatGPT exercise correctness results 
 
Figure 8. Correctness of ChatGPT solutions per 
exercise difficulty 
 
 
for exercises with basic statements, the correct answer rate was 75%, improving to 89% after follow-up 
questions. Another interesting correlation to explore is that with student difficulty. ChatGPTs performance 
is almost indistinguishable at the easy and medium levels, however ChatGPT is sensibly less able to 
answer hard questions correctly. These questions contain subtleties in code which ChatGPT is unable to 
capture. One such example is related to an overflow/underflow during division in the following program 
statement: 
abs(a - x*x) < threshold 
 
For very small values of a and x, the value of the left-hand-side of the expression may become very large, 
thus incorrectly validating the condition and triggering a loop. ChatGPT is unable to identify the problem 
with this code even when it is explicitly prompted in a reply. Finally, we looked at the correlation of 
correctness with the solution size. 
As before, we observe that there is no sensible correlation 
here. ChatGPT is equally capable in generating small and 
medium code solutions. Out of 5 exercises with an expected 
large solution, 2 received a first-answer solution and after 
follow-up questions one more correct solution was given. Due to the small number of such exercises, it is 
hard to draw any conclusions regarding ChatGPT’s ability to generate larger code. 
While performing this study we also asked ChatGPT a lot of questions about the code it generated. We 
noticed that it can correctly establish if a given piece of code is written in functional style, if a given 
function is recursive/tail-recursive or not. This motivated us to experiment with writing a tool which our 
teaching team could use to semi-automatically generate code reviews over student homework. 
4. CHATGPT AS CODE REVIEWER 
Our tool is written in Scala. It uses the Scalameta [11] parser to isolate particular pieces of code (e.g. 
function implementations) from each homework submissions. It then assembles the code as well as the 
question under scrutiny into a ChatGPT query. Finally, it uses the OpenAI Scala Client [10] which 
interacts with the OpenAI API using HTTP requests, to submit the query to ChatGPT and retrieve the 
answer. 
Using our tool, we have queried select pieces of code from 67 homework assignments and asked whether 
they have been written in functional style. The code pieces ranged in size from 1-2 to a record of 55 lines 
of code, for the same implementation task. Approx. 77% of the queries received complete and correct 
answers, containing valid argumentation. Around 7% of the answers where overall correct but contained 
some parts of argumentation that had flaws. For instance, the claim generated by ChatGPT “the use of 
return statements to exit early from the function is not idiomatic of functional programming” is correct in 
principle but did not apply to the code piece under scrutiny. Finally, around 15% of the answers were 
incorrect. 
5. DISCUSSION 
Our experiments suggest that ChatGPT is very good at coding in our lab. Although it might seem ideal as 
a tool for scoring points, ChatGPT is not that good at providing textbook solutions: around half of the 
correct solutions contain awkward or inefficient pieces of code. While ChatGPTs accuracy is robust 
against the statement or the solution size, we can see it strongly decreases to around 50% (a coin toss) for 
 
Small-size 
solutions 
Medium-size solutions 
Correct in the first reply 
71% 
60% 
Correct after follow-up questions 
85% 
94% 
Figure 9. Correctness of ChatGPT solutions per 
solution size 
 
 
difficult lab assignments, as previously shown. We should be careful about generalizing these results to 
other courses or learning subjects. FP is a basic programming course, which combines learning topics 
which are widespread on the Internet. For instance, Newton’s Approximation Method is often used as a 
basic programming exercise. Also, Scala code syntax examples are pervasive online. These would 
certainly be part of the training corpus for ChatGPTs model. It is unclear how good will ChatGPT do in 
other scenarios and with other programming languages. We believe that ChatGPT does not currently scale 
as a learning tool, under no setting, and may do more harm than good if its answers are taken for good in 
the general case. ChatGPT works best when there is a possibility to validate its results e.g. with a credible 
test suite. Using ChatGPT to create tests may add to the level of uncertainty regarding its answers. 
Finally, we do believe ChatGPT is a valuable resource to generate code reviews for students as long as it 
is subject to review itself from human experts. As previously shown, ChatGPT provides ample feedback 
to our questions, and correctness rates of 77% mean that human intervention in writing reviews can be 
minimized.  Our datasets for ChatGPT evaluation are publicly available here [16]. 
6. RELATED WORK 
To our knowledge, the is little body of work covering ChatGPTs performance in generating code, 
especially for the purposes of teaching. The work of [6] explores both coding questions as well as 
questions in natural language in the setting of a software testing course, but it not directly focused on the 
code-generation capabilities of ChatGPT. [9] evaluates Codex, a specific language model that inherits 
GPT3, for the purposes of python code generation from documentation. [12] studies ChatGPTs bug-fixing 
capabilities with promising results. Both [9] and [12] target more complex code generation tasks and yield 
smaller correctness scores than our observations. There are also a lot of public debate covering the future 
of programming after ChatGPT, such as [13].  
Also, as far as we are aware, there is no tool which attempts to assess if a piece of code has been AI-
generated. So far, AI text generation detection is limited to natural language: [2,8]. Work covering the 
impact of ChatGPT in education is less sparse. We recall only a few [1,2,4,8]. 
7. REFERENCES 
[1] Ken Lambeets. How should Radboud University handle ChatGPT? Retrieved ian. 2023, 
https://www.voxweb.nl/english/how-should-radboud-university-handle-chatgpt 
[2] GPTZero, Retrieved ian 2023. https://gptzero.me/team 
[3] Michael Elsen-Rooney, NYC education department blocks ChatGPT on school devices, networks. 
Retrieved ian 2023. https://ny.chalkbeat.org/2023/1/3/23537987/nyc-schools-ban-chatgpt-writing-
artificial-intelligence  
[4] Chris Stokel-Walker. ChatGPT listed as author on research papers: many scientists disapprove. In 
Nature Articles. Retrieved ian 2023.https://www.nature.com/articles/d41586-023-00107-z 
[5] Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and 
Lukasiewicz, Thomas and Petersen, Philipp Christian and Chevalier, Alexis and Berner, Julius. 
Mathematical Capabilities of ChatGPT. 2023. https://arxiv.org/abs/2301.13867 
[6] Jalil, Sajed and Rafi, Suzzana and LaToza, Thomas D. and Moran, Kevin and Lam, Wing. ChatGPT 
and Software Testing Education: Promises and Perils. 2023. https://arxiv.org/abs/2302.03287 
[7] OpenAI ChatGPT. Retrieved ian 2023. https://openai.com/blog/chatgpt 
[8] Mitrović, Sandra and Andreoletti, Davide and Ayoub, Omran. ChatGPT or Human? Detect and 
Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated 
Text. 2023. https://arxiv.org/abs/2301.13852 
[9] Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, et al. Evaluating Large Language 
Models Trained on Code. 2021. https://arxiv.org/abs/2107.03374 
[10] OpenAI Scala Client. https://github.com/cequence-io/openai-scala-client 
[11] ScalaMeta. https://github.com/scalameta/scalameta. 
[12] Sobania, Dominik and Briesch, Martin and Hanna, Carol and Petke, Justyna. An Analysis of the 
Automatic Bug Fixing Performance of ChatGPT. 2023. https://arxiv.org/abs/2301.08653 
[13] Stephanie Glen, ChatGPT writes code, but won’t replace developers. Retrieved ian 2023. 
https://www.techtarget.com/searchsoftwarequality/news/252528379/ChatGPT-writes-code-but-
wont-replace-developers 
[14] A, Subaveerapandiyan and A, Vinoth and Tiwary, Neelam. Netizens, Academicians, and 
Information Professionals' Opinions About AI With Special Reference To ChatGPT. 2023. 
https://arxiv.org/abs/2302.07136 
[15] Odersky, M. & al. (2004), 'An Overview of the Scala Programming Language' (IC/2004/64) , 
Technical report, EPFL Lausanne, Switzerland . 
[16] ChatGPT dataset used in our evaluation. https://github.com/pdmatei/ChatGPTinEducation. 
[17] Functional Programming lecture, taught in 2022. https://ocw.cs.pub.ro/ppcarte/doku.php?id=fp2022  
 
","This study draws upon previous research that has explored the impact and potential of ChatGPT in education. Related works have assessed ChatGPT's performance on coding tasks, evaluating its bug-fixing capabilities, and studying its impact in testing courses. However, there is limited research on using ChatGPT as a tool for code review, which is investigated in this study.nan"
"Deep learning-based joint source-channel coding (DJSCC) exhibits various promising properties and is critical to next-generation wireless networks. However, conventional DJSCC schemes lack channel adaptability, hindering their performance in practical applications. To address this challenge, we propose a generic framework for channel-adaptive DJSCC utilizing hypernetworks. To ensure compatibility with communication systems, we introduce a scalable and memory-efficient hypernetwork parameterization, leading to the development of a channel-adaptive DJSCC network, Hyper-AJSCC. Extensive experiments demonstrate the superior adaptability to channel conditions and higher memory efficiency of Hyper-AJSCC compared to state-of-the-art baselines.","Deep learning has revolutionized various domains, and it is anticipated to transform next-generation communications, particularly in conjunction with artificial intelligence (AI) technology. Deep learning-based joint source-channel coding (DJSCC) schemes have emerged as key enablers for ubiquitous intelligent devices and AI services, offering advantages such as data reconstruction enhancements and graceful performance loss under degrading channel conditions. However, existing DJSCC schemes face challenges in channel adaptability, as they are typically trained under specific channel conditions, resulting in significant performance degradation when channel conditions change during deployment. To address this issue, attention mechanisms and transformer-based methods have been explored, but they suffer from computational complexity and compatibility issues with existing DJSCC networks. This work proposes a generic channel-adaptive framework that can be seamlessly integrated into any DJSCC network, enhancing their adaptability to channel variations.","To achieve channel-adaptive DJSCC, we propose a generic framework that utilizes hypernetworks to generate the parameters of the optimal encoder/decoder according to the channel conditions. We develop a scalable and memory-efficient hypernetwork parameterization called Hyper-AJSCC, which offers several advantages over attention-based methods, including significantly fewer additional parameters and seamless integration into existing DJSCC schemes without compromising their core structures. Our approach ensures channel adaptability without sacrificing the integrity or functionality of the original neural network backbones.","Extensive experiments are conducted on image transmission and classification tasks to evaluate the performance of our proposed Hyper-AJSCC scheme. The results demonstrate that Hyper-AJSCC outperforms state-of-the-art baselines in terms of adaptability to channel conditions and memory efficiency. Hyper-AJSCC achieves the optimal performance of BDJSCC schemes trained with different values of SNRtrain, indicating its ability to adapt across various SNR values. Moreover, Hyper-AJSCC shows comparable or slightly better performance compared to the ADJSCC method with reduced storage overhead. In task-oriented communications, Hyper-AJSCC outperforms BDJSCC schemes, proving its effectiveness in adaptive image classification tasks.","Our work addresses the channel adaptability challenge of DJSCC by introducing a generic framework that leverages hypernetworks. The proposed Hyper-AJSCC scheme offers several advantages, including superior adaptability, lower memory requirements, and seamless integration with various DJSCC networks. Comprehensive experiments validate the effectiveness of Hyper-AJSCC in image transmission and classification tasks. The success of Hyper-AJSCC demonstrates the potential of hypernetworks in adaptive DJSCC, opening up new avenues for developing channel-adaptive schemes that can seamlessly adapt to data distributions and channel conditions.",Deep Learning-Based Adaptive Joint Source-Channel Coding using Hypernetworks,"Songjie Xie, Hengtao He, Hongru Li, Shenghui Song, Jun Zhang, Ying-Jun Angela Zhang, Khaled B. Letaief","Deep Learning-Based Adaptive Joint
Source-Channel Coding using Hypernetworks
Songjie Xie∗, Hengtao He∗, Hongru Li∗, Shenghui Song∗, Jun Zhang∗, Fellow, IEEE,
Ying-Jun Angela Zhang†, Fellow, IEEE, and Khaled B. Letaief∗, Fellow, IEEE
∗Dept. of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong
†Dept. of Information Engineering, The Chinese University of Hong Kong, Hong Kong
Email: {sxieat, hlidm}@connect.ust.hk, {eehthe, eeshsong, eejzhang, eekhaled}@ust.hk, yjzhang@ie.cuhk.edu.hk
Abstract—Deep learning-based joint source-channel coding
(DJSCC) is expected to be a key technique for the next-generation
wireless networks. However, the existing DJSCC schemes still face
the challenge of channel adaptability as they are typically trained
under specific channel conditions. In this paper, we propose
a generic framework for channel-adaptive DJSCC by utilizing
hypernetworks. To tailor the hypernetwork-based framework for
communication systems, we propose a memory-efficient hyper-
network parameterization and then develop a channel-adaptive
DJSCC network, named Hyper-AJSCC. Compared with existing
adaptive DJSCC based on the attention mechanism, Hyper-
AJSCC introduces much fewer parameters and can be seamlessly
combined with various existing DJSCC networks without any
substantial modifications to their neural network architecture.
Extensive experiments demonstrate the better adaptability to
channel conditions and higher memory efficiency of Hyper-
AJSCC compared with state-of-the-art baselines.
Index Terms—Joint source-channel coding, deep learning, deep
neural network, hypernetworks
I. INTRODUCTION
With the widespread success and effectiveness of artificial
intelligence (AI) in various domains, it is anticipated that the
next-generation communications will be revolutionized by an
in-depth integration of advancements in AI technology [1]–
[4]. Recently, deep learning-based joint source-channel coding
(DJSCC) schemes have been developed to support ubiqui-
tous connected intelligent devices and AI services. Compared
with the conventional separate source-channel coding strat-
egy, the recently proposed DJSCC schemes exhibit numerous
appealing properties, including substantial enhancements in
data reconstruction [5] and graceful performance loss with
degrading channel quality [6]. These advantages not only
benefited conventional data-oriented communication systems
but also facilitated emerging paradigms such as semantic and
task-oriented communication [7]–[12].
Despite the empirical success of the existing DJSCC
schemes, they still face the challenge of channel adaptability.
In particular, the existing DJSCC schemes proposed for image
and text transmission typically adopt a deep learning-based
autoencoder with a non-trainable layer to simulate the noisy
channel. Then, the encoder and decoder are optimized in an
end-to-end manner under particular channel conditions. Conse-
quently, the mismatch between the channel conditions during
the training and deployment stages results in a significant
performance degradation [5]. One solution is to train multiple
networks for different channel conditions and select the suited
one for data transmission according to the channel conditions.
However, this strategy requires an extremely high storage
memory to store multiple networks, thereby limiting its practi-
cal applications, especially in resource-constrained scenarios.
The ideal approach for solving the adaptability challenge of
DJSCC is to design a single network that can adjust its pa-
rameters to different channel conditions. To achieve this goal,
recent research [13] proposed to employ attention mechanisms
to adjust intermediate features according to channel conditions,
and has been extended to various DJSCC scenarios [14],
[15]. More recently, the transformer-based method [16] was
utilized to leverage the intrinsic self-attention mechanism to
improve channel adaptability. However, the attention-based
approaches suffer from several limitations when integrated
into existing DJSCC schemes. Firstly, attention mechanisms
can be computationally expensive due to their involvement
in the computation of multiple neural network layers. On the
other hand, introducing attention modules to existing DJSCC
networks disrupts their original structures. This disruption
impacts the overall design and functionality of the original
DJSCC networks, which can result in compatibility issues.
To address these problems, we propose a generic channel
adaptive framework that can be directly employed in any
DJSCC network to enhance their adaptability to channel
variations. Hypernetworks [17], [18] have been proven ef-
fective in enhancing the flexibility and adaptability of neural
networks due to their ability to generate network parameters
dynamically. Thus, we adopt them to generate the parameters
of the optimal encoder/decoder according to the channel con-
ditions. To make the proposed hypernetwork-based framework
compatible with communication systems, we propose a scal-
able and memory-efficient hypernetwork parameterization and
further develop a channel-adaptive DJSCC scheme, namely
Hyper-AJSCC. The proposed Hyper-AJSCC approach offers
several advantages over attention-based methods. It intro-
duces significantly fewer parameters and can be seamlessly
integrated into a wide range of existing DJSCC schemes.
More importantly, this integration does not compromise the
consistency or fundamental structure of the original neural
network backbones. To verify the performance of our method
in data/task-oriented communication paradigms, we conduct
extensive experiments on image transmission and classification
arXiv:2401.11155v1  [cs.IT]  20 Jan 2024
Channel
!!((0|0)
Encoder
!""(#|%)
'
/
(/
0
(0
Channel
!!((0|0)
/
(/
0
(0
Decoder
!!()*|+,)
Encoder
!""($)(#|%)
Decoder
!!($)()*|+,)
Fig. 1. The considered system model of point-to-point communication with
known channel condition at the transmitter and receiver.
tasks. The results demonstrate the advantages of the proposed
Hyper-AJSCC schemes in improving the adaptability of the
network to channel conditions.
II. SYSTEM MODEL AND PROBLEM FORMULATION
A. System Model
As shown in Fig. 1, we consider a point-to-point DJSCC
system consisting of a single encoder and a decoder, both
of which are parameterized by neural networks. The channel
conditions are known by both the DJSCC encoder and decoder.
It constitutes a general model that can be implemented in data-
oriented and task-oriented communication systems. A data
source generates the observable data x ∈ Rn with distribution
p(x) and forms a dataset {x(i)}N
i=1 consisting of N inde-
pendent and identically distributed (i.i.d.) data points. At the
transmitter side, the input data x is encoded into d-dimensional
channel input symbols z ∈ Cd using a probabilistic encoder
pϕ(z|x) parameterized by the trainable parameters ϕ of neural
networks.
The encoded representation z is then transmitted over a
noisy channel. In this work, we consider the additive white
Gaussian noise (AWGN) channel. The additive noise vector
ϵ is sampled from an isotropic Gaussian distribution with
variance σ2, i.e., ϵ ∼ CN(0, σ2I). After transmitting over
a noisy channel, the noisy symbols received by the receiver
can be expressed by
ˆz = z + ϵ.
(1)
The considered AWGN channel can be fully characterized
by the channel SNR ω ∈ Ω, where Ω is a set of possible
values of ω1. The condition ω is assumed to be perfectly
estimated at the receiver side and fedback to the transmitter.
Formally, the channel effect can be represented by the condi-
tional distribution pω(ˆz|z). At the receiver side, the decoder
pθ(ˆx|ˆz) leverages the received noisy signal ˆz to produce a
reconstruction of the input ˆx ∈ X, where θ is the trainable
and adjustable parameters of the decoder. After introducing
the above random variables, we can establish the following
Markov chain to represent the whole encoding and decoding
process,
X
ϕ
←→ Z
ω
←→ ˆZ
θ
←→ ˆX.
(2)
1Although we assume an AWGN channel and use SNR to represent the
channel conditions for simplicity, this model can be extended to other channel
models as long as the channel conditions can be estimated by the receiver
and fedback to the transmitter.
Note that this system model can be generalized to task-oriented
communication by introducing the target variable Y into the
data source p(x, y). In particular, the decoder pθ(ˆy|ˆz) just
leverages ˆz and outputs the target estimation ˆy ∈ Y. Then, we
can also establish the following Markov chain for the encoding
and decoding process,
Y ←→ X
ϕ
←→ Z
ω
←→ ˆZ
θ
←→ ˆY .
(3)
B. Problem Formulation
With the system model illustrated in Fig. 1, our objective is
to develop a scalable and computationally efficient framework
for learning the optimal DJSCC schemes for various channel
conditions in a single training round. Specifically, given the
encoder pϕ(z|x), the channel model pω(ˆz|z), and the decoder
pθ(ˆx|ˆz), the objective of DJSCC is to minimize the following
objective function,
L(ϕ, θ; ω) = Ep(x)

Epϕ(z|x)pω(ˆz|z) [− log pθ(x|ˆz)]

.
(4)
The distortion Epϕ(z|x)pω(ˆz|z)[− log pθ(x|ˆz)] in (4) is ex-
pressed in a general probabilistic format. The decoder pθ(x|z)
is based on a spherical Gaussian observation model, and
the distortion is measured as the mean squared error (MSE)
between the input data x and the reconstruction ˆx. For task-
oriented communication schemes with probability model (3),
the objective function L(ϕ, θ; ω) becomes,
L(ϕ, θ; ω) = Ep(x,y)

Epϕ(z|x)pω(ˆz|z) [− log pθ(y|ˆz)]

.
(5)
If the target y ∈ {1, 2, . . . , K} is classified into K classes
and the decoder pθ(y|ˆz) outputs the probability vectors for the
K possible classes, the distortion is calculated as the cross-
entropy.
Given the channel condition ω, the adaptive DJSCC
schemes adaptively adjust their parameters to the optimal
parameters ϕ∗(ω) and θ∗(ω) that minimize the objective
L(ϕ, θ; ω). That is,
ϕ∗(ω), θ∗(ω) = argmin
ϕ,θ
L(ϕ, θ; ω).
(6)
In the next section, we will propose a single model for DJSCC
schemes that adapts to any channel conditions ω within one
training round.
III. ADAPTIVE DJSCC USING HYPERNETWORKS
In this section, we first develop a general framework to
achieve adaptive DJSCC by utilizing hypernetworks. These
hypernetworks generate optimal parameters (ϕ∗(ω), θ∗(ω))
for the given channel conditions ω. Subsequently, we propose a
scalable and memory-efficient hypernetwork parameterization
to reduce the additional storage space, named Hyper-AJSCC.
A. Hypernetworks for DJSCC
The concept of hypernetwork was proposed in the seminal
work [17] to utilize a single neural network to generate the
parameters for other networks called target networks. This
approach offers several benefits, including weight sharing,
dynamic architecture, and adaptive neural networks. By using
Channel
!!((0|0)
Encoder
!""(#|%)
'
/
(/
0
(0
Channel
!!((0|0)
Hypernetwork
(#(')
/
(/
0
(0
Decoder
!!()*|+,)
Encoder
!""(%)(#|%)
Decoder
!!(%)()*|+,)
'
(- ' , / ' )
- '
/ '
Fig. 2.
The proposed hypernetwork-based framework: A hypernetwork H
takes channel conditions ω as input and generates the parameters ϕ(ω) and
θ(ω) of the encoder and decoder.
hypernetworks, we can avoid the need for computationally
expensive training processes of multiple neural networks for
different scenarios. This key characteristic of hypernetworks
provides us with the opportunity to develop adaptive DJSCC
schemes tailored to various channel conditions, without neces-
sitating the retraining or storage of multiple neural networks.
The proposed framework based on hypernetworks is illus-
trated in Fig. 2. We regard the encoder and decoder as the
target networks and propose to utilize a hypernetwork Hψ to
generate their parameters ϕ(ω) and θ(ω) with the input of the
channel condition ω as
(ϕ(ω), θ(ω)) = Hψ(ω),
(7)
where Hψ : Ω → Φ × Θ that maps the channel condition ω
to (ϕ(ω), θ(ω)), where ψ represents the meta parameters of
the hypernetwork.
In the conventional DJSCC methods, the parameters (ϕ, θ)
of the encoder and decoder are directly optimized in an
end-to-end manner. However, in the proposed hypernetwork-
based method, we instead optimize the hypernetwork Hψ to
generate optimal solutions (ϕ∗(ω), θ∗(ω)) that minimize the
objective function L(ϕ(ω), θ(ω); ω). In particular, the meta
parameters ψ of the hypernetwork Hψ is trained to minimize
the following objective function
H(ψ) = Ep(ω)[L(Hψ(ω); ω)],
(8)
where the channel condition ω is sampled from a prior
distribution p(ω) over Ω during training. Then, the optimal
parameters ϕ∗(ω) and θ∗(ω) are obtained by the optimized
hypernetwork:
ϕ∗(ω), θ∗(ω) = Hψ∗(ω),
(9)
where ψ∗ = argmin
ψ
H(ψ) is the optimized meta parameters
of the hypernetwork.
B. Hyper-AJSCC
Directly applying hypernetworks into the DJSCC requires
additional storage space for the deployment of the introduced
hypernetwork Hψ and the additional step to generate the
parameters ϕ(ω) and Θ(ω) for the encoder and decoder.
Inspired by the applications of hypernetworks in hyperparam-
eter optimization [18], we integrate the hypernetwork into
the encoder and decoder by designing a memory-efficient
and scalable hypernetwork parameterization. The proposed
adaptive DJSCC scheme is named Hyper-AJSCC, which can
be easily extended to other DJSCC networks by introducing
very limited additional parameters and without destroying the
consistency of the original backbone of neural networks.
Firstly, we consider the l-th layer of the DJSCC network,
which takes the feature f (l) ∈ RDl produced from the previous
layer and outputs the feature f (l+1) ∈ RDl+1. As the trainable
parameters of the l-th layer, weight and bias, can be expressed
as W(l) ∈ RDl+1×Dl and b(l) ∈ RDl+1, respectively. Thus,
the obtained features from the l-th layer are expressed by,
f (l+1) = σ(l)(W(l)f (l) + b(l)),
(10)
where σ(l)(·) denotes the activation function of the l-th layer.
Next, we present how to model the adaptive parameters of
the l-th layer, W(l)(ω) and b(l)(ω), by using the following
hypernetwork parameterization
W(l)(ω) = (ω · ν(l) + c(l)) ⊙row W(l)
0 ,
(11)
b(l)(ω) = (ω · ν(l) + c(l)) ⊙ b(l)
0 ,
(12)
where ⊙ and ⊙row denote the element-wise multiplication
for vectors and row-wise multiplication for matrices, respec-
tively. Note that the meta parameters for the l-th layer are
ψ(l) = {ν(l), c(l), W(l)
0 , b(l)
0 }. To develop a memory-efficient
and scalable hypernetwork-based scheme, we further derive
the features f (l+1) produced by the adaptive l-th layer as
follows,
f (l+1)(ω) = σ(l)(W(l)(ω)f (l) + b(l)(ω))
(13)
= σ(l)((ω · ν(l) + c(l))
|
{z
}
Element-wise scaling
⊙ (W(l)
0 f (l) + b(l)
0 )
|
{z
}
Basic module
). (14)
As shown in (14), we observe that the proposed hypernetwork-
based network architecture can be decomposed into two main
parts, Element-wise scaling and Basic module. Specifically,
the basic module has the same form as the original neural
network backbone in (10), and the element-wise scaling can
be easily achieved with a linear transformation. Therefore,
the hypernetwork for the l-th adaptive layer can be directly
implemented by adding a linear transformation on the existing
module, as illustrated in Fig. 3.
The above method is based on fully connected architecture,
but the proposed hypernetwork parameterization can be easily
extended to other neural network architectures such as convo-
lutional layers and resnet blocks as follows.
a) Convolutional layers:
We consider the l-th con-
volutional layer, which receives input features f (l−1)
∈
Rcl−1×hl−1×wl−1 and is equipped with filters characterized by
kernels C(l) ∈ Rcl−1×Ki×Ki and bias b(l) ∈ R. Analogous to
!(&)
'-th NN layer 
parameters
⨀
""
"" # ( ! + )(!)
"" !
!(&$%)
'-th adaptive 
NN layer
!(&)
""
!(&$%)
Fig. 3.
The proposed hypernetwork parameterization for the l-th layer of
DJSCC schemes. The gray panel represents the basic module, which maintains
the original neural network backbone.
the aforementioned parameterization, the adaptive parameters
C(l)(ω) and b(l)(ω) are formulated as follows:
C(l)(ω) = (ω · ν(l) + c(l)) ⊙row C(l)
0 ,
(15)
b(l)(ω) = (ω · ν(l) + c(l)) ⊙ b(l)
0 .
(16)
b) Resnet blocks:
The parameterization for ResNet
blocks can be readily extended by applying the above param-
eterization techniques to all convolutional layers within the
ResNet blocks.
C. Training Algorithm
By employing the proposed hypernetwork parameterization,
the Hyper-AJSCC scheme can effectively incorporate and
adapt to different channel conditions. Next, we aim to develop
a training process for Hyper-AJSCC, which is expected to
learn a mapping from any channel conditions ω to the optimal
parameters (ϕ∗(ω), θ∗(ω)). Thus, we take a prior distribution
p(ω) over Ω and train Hyper-AJSCC to minimize the loss
H(ψ) presented in (9) by sampling ω ∼ p(ω). Specifically,
by sampling L realizations of ω from p(ω), we can form the
Monte Carlo estimation ˜H(ψ) ≃ H(ψ)
˜H(ψ) = 1
L
L
X
l=1
L(ϕ(l), θ(l); ω(l)),
(17)
where (ϕ(l), θ(l)) = Hψ(ω(l)) and ω(l) ∼ p(ω). The training
process for Hyper-AJSCC is outlined in Algorithm 1. Al-
though adopting a prior distribution p(ω) that aligns with real-
world channel condition distributions can enhance the training
process, it is challenging to obtain such distribution. In our
empirical evaluation, we demonstrate that Hyper-AJSCC can
achieve optimal performance by simply utilizing a uniform
prior p(ω).
IV. EXPERIMENTS
In this section, we evaluate the performance of the pro-
posed hyper-DJSCC in data/task-oriented communications by
Algorithm 1 Training Hyper-AJSCC
Input: T (number of epochs), batch size N, sampling distribution
for channel condition p(ω).
1: while epoch t = 1 to T do
2:
Sample a mini-batch of data samples {x(i)}N
i=1
3:
Sample a mini-batch of channel conditions {ω(i)}N
i=1 ∼ p(ω)
4:
Generate
channel
models
{pω(i)(ˆz|z)}N
i=1
according
to
{ω(i)}N
i=1
5:
while i = 1 to N do
6:
Compute z(i) by inputting x(i) and ω(i) to the encoder
7:
Estimate the received symbols ˆz(i) from pω(i)(ˆz|z)
8:
Estimate the outputs by inputting ˆz(i) and ω(i) to the
decoder
9:
end while
10:
Compute the loss ˜
H(ψ) and update the parameters ψ through
backpropagation.
11: end while
TABLE I
THE BDJSCC NETWORK ARCHITECTURE FOR IMAGE TRANSMISSION
Layer
Output
Decoder
Conv × 4
256 × 8 × 8
Conv + Power normalization
d
Decoder
Deconv × 4
256 × 16 × 16
Deconv + Tanh
3 × 32 × 32
performing a series of experiments on image transmission and
image classification tasks2.
A. Implementation Details
1) Baselines and Dataset: We select representative DJSCC
schemes for image transmission and cooperative inference
as the basic DJSCC (BDJSCC) neural network architectures.
The corresponding BDJSCC network architectures for image
transmission [6] and cooperative inference [9] are shown in
Table I and Table II, respectively. Moreover, we adopt the
neural network architecture of BDJSCC as the backbone of our
proposed Hyper-AJSCC for a fair comparison. All experiments
are conducted using the benchmark dataset CIFAR-10 [19],
which consists of a collection of 32 × 32 color images
categorized into 10 classes. The dataset includes a training
set with 50,000 images and a test set with 10,000 images.
2) Performance Metrics:
Following the DJSCC litera-
ture [5], [13], we use the compression ratio R = d/n
to characterize the communication efficiency of the system,
where n and d are the source bandwidth (the dimension of
x) and channel bandwidth (the dimension of z), respectively.
The performance is evaluated by the peak signal-to-noise ratio
(PSNR), which is a standard performance metric for image
reconstruction. The PSNR is defined as,
PSNR = 10 log10
MAX(x)2
MSE(x, ˆx),
(18)
2The
source
code
of
the
proposed
Hyper-AJSCC
is
available
at:
https://github.com/SongjieXie/Hyper-AJSCC.
TABLE II
THE BDJSCC NETWORK ARCHITECTURE FOR IMAGE CLASSIFICATION
Layer
Outputs
Encoder
Conv × 2 + ResBlock
256 × 16 × 16
Conv × 3
4 × 4 × 4
Reshape + Fully-connected layer
d
Decoder
Fully-connected Layer × 3
4 × 4 × 4
Conv + Resblock
512 × 4 × 4
Pooling layer
512
Fully-connected + Softmax
10
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
SNRtest (dB)
16
18
20
22
24
26
28
30
PSNR (dB)
R = 1/12
Hyper-AJSCC
BDJSCC (SNRtrain=1dB)
BDJSCC (SNRtrain=4dB)
BDJSCC (SNRtrain=7dB)
BDJSCC (SNRtrain=10dB)
BDJSCC (SNRtrain=13dB)
BDJSCC (SNRtrain=16dB)
BDJSCC (SNRtrain=19dB)
(a)
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
SNRtest (dB)
17.5
20.0
22.5
25.0
27.5
30.0
32.5
35.0
PSNR (dB)
R = 1/6
Hyper-AJSCC
BDJSCC (SNRtrain=1dB)
BDJSCC (SNRtrain=4dB)
BDJSCC (SNRtrain=7dB)
BDJSCC (SNRtrain=10dB)
BDJSCC (SNRtrain=13dB)
BDJSCC (SNRtrain=16dB)
BDJSCC (SNRtrain=19dB)
(b)
Fig. 4. Performance of the proposed Hyper-AJSCC compared to baseline BD-
JSCCs under varying training SNR with compression ratios (a) R = 1/12 and
(b) R = 1/6. The outlined markers represent the performance of BDJSCCs
when the test SNR matches their training SNR, i.e., SNRtrain = SNRtest.
where MAX(x) represents the maximum pixel value in the
image x, and MSE(x, ˆx) denotes the MSE between the
original image x and the reconstructed image ˆx. The exper-
iments on task-oriented communications are performed with
classification tasks using the CIFAR-10 benchmark datasets.
For a fair comparison, the channel symbols z encoded by all
the evaluated methods have the same dimensionality d, and
the standard metric of top-1 accuracy is employed to evaluate
the classification results.
B. Experimental Results on Data-Oriented Communications
We
first
evaluate
the
effectiveness
of
our
proposed
method
on
image
transmission.
All
BDJSCC
schemes
are
trained
at
specific
SNRs,
denoted
as
SNRtrain
∈
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
SNRtest (dB)
22
24
26
28
30
32
34
PSNR (dB)
Hyper-AJSCC (R=1/6)
ADJSCC (R=1/6)
Hyper-AJSCC (R=1/12)
ADJSCC (R=1/12)
Fig. 5.
Performance of the proposed Hyper-AJSCC compared to ADJSCC
with different compression ratios R.
TABLE III
INTRODUCED PARAMETERS AND ADDITIONAL STORAGE REQUIREMENTS
FOR EVALUATED METHODS
Method
# parameters
Storage
ADJSCC
67840
265 KB
Hyper-AJSCC
4118
16 KB
{1dB, 4dB, 7dB, 10dB, 13dB, 16dB, 19dB}. In contrast, our
Hyper-AJSCC scheme is trained under the uniform distribution
of SNRtrain ∈ [0dB, 20dB]. Subsequently, we evaluate the
performance of BDJSCCs and Hyper-AJSCC over a range of
SNRs varying from 0dB to 20dB. The experimental results
shown in Fig. 4 indicate the performance with compression
ratios R = 1/12 and R = 1/6, respectively. The outlined
markers represent the optimal performance of BDJSCCs when
the SNRtest is the same for the testing SNR (i.e., SNRtrain =
SNRtest). We observe that Hyper-AJSCC achieves the optimal
performance of BDJSCCs trained with different values of
SNRtrain, except for a small performance gap in the high SNR
regime. This indicates that our method adapts well to SNR
variations across different SNR values.
We further compare Hyper-AJSCC with the state-of-the-
art method, ADJSCC [13], under an identical setting3. As
illustrated in Fig. 5, Hyper-AJSCC shows a slight performance
improvement when compared to ADJSCC, especially in the
high-SNR regime. Furthermore, we compute the additional
storage overhead introduced by the ADJSCC and Hyper-
AJSCC models on the basis of the BDJSCC backbone in
Table. III. It is shown that our Hyper-AJSCC scheme only
introduces less than one-tenth of the parameters introduced by
ADJSCC. Because of the small additional storage overhead of
Hyper-AJSCC, it is easy to extend our framework to various
existing DJSCC schemes to enable their adaptation to channel
variations.
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
SNRtest (dB)
80
82
84
86
88
90
92
Accuracy (%)
d = 8
Hyper-AJSCC
BDJSCC (SNRtrain=1dB)
BDJSCC (SNRtrain=4dB)
BDJSCC (SNRtrain=7dB)
BDJSCC (SNRtrain=10dB)
BDJSCC (SNRtrain=13dB)
BDJSCC (SNRtrain=16dB)
BDJSCC (SNRtrain=19dB)
(a)
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
SNRtest (dB)
80
82
84
86
88
90
92
Accuracy (%)
d = 16
Hyper-AJSCC
BDJSCC (SNRtrain=1dB)
BDJSCC (SNRtrain=4dB)
BDJSCC (SNRtrain=7dB)
BDJSCC (SNRtrain=10dB)
BDJSCC (SNRtrain=13dB)
BDJSCC (SNRtrain=16dB)
BDJSCC (SNRtrain=19dB)
(b)
Fig. 6. Performance of the proposed Hyper-AJSCC compared to baseline BDJSCCs under varying training SNR for image classification tasks, with (a) d = 8
and (b) d = 16.
C. Experimental Results on Task-Oriented Communications
To further verify the performance of our method in task-
oriented communications, we apply the proposed Hyper-
AJSCC scheme to cooperative inference. Following the same
experimental setup employed for data-oriented communica-
tions experiments, we show the experimental results in Fig. 6.
We observe that the proposed Hyper-AJSCC scheme outper-
forms the BDJSCC schemes, particularly when the value of
SNRtest is relatively small. Our proposed Hyper-AJSCC can
outperform the performance of BDJSCC with perfect SNR
(e.g., the makers) except in the high SNR regime. This is
because channel adaptability in task-oriented communication
is more intricate due to the inherent tradeoff between informa-
tiveness and robustness [10], and there does not exist an overall
optimal performance for channel-adaptive DJSCC schemes in
task-oriented communications.
V. CONCLUSIONS
In this work, we investigated the channel adaptability prob-
lems for DJSCC and proposed a generic framework to achieve
channel-adaptive DJSCC by leveraging hypernetworks. Subse-
quently, we proposed a hypernetwork-based adaptive DJSCC
and further proposed a scalable and memory-efficient scheme
by introducing a limited number of hyperparameters into
each layer of the neural network. The proposed framework
can be seamlessly integrated into any conventional network
architecture of DJSCC. Extensive experiments demonstrated
the superior performance and less storage requirement of the
Hyper-AJSCC compared to state-of-the-art baselines on the
task of image transmission and cooperative inference. Our
work has demonstrated the potential of hypernetworks in
adaptive DJSCC, and a promising future direction is to further
explore the hypernetwork-based framework for incorporating
various data distributions, thus enabling the development of
3To ensure a fair comparison in the experiments of image transmission,
the ADJSCC, as it originally proposed in [13], adopts an identical neural
network architecture as BDJSCC. Consequently, BDJSCC, ADJSCC, and our
Hyper-AJSCC share the same neural network backbone.
DJSCC schemes that are adaptive to both data sources and
channels.
REFERENCES
[1] K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y.-J. A. Zhang, “The
roadmap to 6G: AI empowered wireless networks,” IEEE Commun.
Mag., vol. 57, no. 8, pp. 84–90, 2019.
[2] H. He, C.-K. Wen, S. Jin, and G. Y. Li, “Model-driven deep learning for
MIMO detection,” IEEE Trans. Signal Process., vol. 68, pp. 1702–1715,
2020.
[3] W. Yu, Y. Shen, H. He, X. Yu, S. Song, J. Zhang, and K. B. Letaief,
“An adaptive and robust deep learning framework for thz ultra-massive
mimo channel estimation,” IEEE J. Sel. Topics Signal Process., vol. 17,
no. 4, pp. 761–776, 2023.
[4] H. He, X. Yu, J. Zhang, S. Song, and K. B. Letaief, “Message passing
meets graph neural networks: A new paradigm for massive mimo
systems,” IEEE Trans. Wireless Commun., to appear, 2023.
[5] E. Bourtsoulatze, D. B. Kurka, and D. G¨und¨uz, “Deep joint source-
channel coding for wireless image transmission,” IEEE Trans. Cogn.
Commun. Netw., vol. 5, no. 3, pp. 567–579, 2019.
[6] D. B. Kurka and D. G¨und¨uz, “Deepjscc-f: Deep joint source-channel
coding of images with feedback,” IEEE J. Sel. Areas Inf. Theory, vol. 1,
no. 1, pp. 178–193, 2020.
[7] H. Xie, Z. Qin, G. Y. Li, and B.-H. Juang, “Deep learning enabled
semantic communication systems,” IEEE Trans. Signal Process., vol. 69,
pp. 2663–2675, 2021.
[8] J. Dai, S. Wang, K. Tan, Z. Si, X. Qin, K. Niu, and P. Zhang, “Nonlinear
transform source-channel coding for semantic communications,” IEEE
J. Sel. Areas Commun., vol. 40, no. 8, pp. 2300–2316, 2022.
[9] J. Shao, Y. Mao, and J. Zhang, “Learning task-oriented communication
for edge inference: An information bottleneck approach,” IEEE J. Sel.
Areas Commun., vol. 40, no. 1, pp. 197–211, 2021.
[10] S. Xie, S. Ma, M. Ding, Y. Shi, M. Tang, and Y. Wu, “Robust information
bottleneck for task-oriented communication with digital modulation,”
IEEE J. Sel. Areas Commun., vol. 41, no. 8, pp. 2577–2591, 2023.
[11] Y. Shi, Y. Zhou, D. Wen, Y. Wu, C. Jiang, and K. B. Letaief, “Task-
oriented communications for 6g: Vision, principles, and technologies,”
IEEE Wireless Commun., vol. 30, no. 3, pp. 78–85, 2023.
[12] H. Li, W. Yu, H. He, J. Shao, S. Song, J. Zhang, and K. B. Letaief,
“Task-oriented communication with out-of-distribution detection: An
information bottleneck framework,” arXiv preprint arXiv:2305.12423,
2023.
[13] J. Xu, B. Ai, W. Chen, A. Yang, P. Sun, and M. Rodrigues, “Wireless
image transmission using deep source channel coding with attention
modules,” IEEE Trans. Circuits Syst. Video Technol., vol. 32, no. 4, pp.
2315–2328, 2021.
[14] M. Yang and H.-S. Kim, “Deep joint source-channel coding for wireless
image transmission with adaptive rate control,” in Proc. IEEE Int. Conf.
Acoust., Speech Signal Process. (ICASSP), 2022, pp. 5193–5197.
[15] H. Wu, Y. Shao, K. Mikolajczyk, and D. G¨und¨uz, “Channel-adaptive
wireless image transmission with OFDM,” IEEE Wirel. Commun. Lett.,
vol. 11, no. 11, pp. 2400–2404, 2022.
[16] H. Wu, Y. Shao, C. Bian, K. Mikolajczyk, and D. G¨und¨uz, “Vision
transformer for adaptive image transmission over MIMO channels,”
arXiv preprint arXiv:2210.15347, 2022.
[17] D. Ha, A. M. Dai, and Q. V. Le, “Hypernetworks,” in Proc. Int. Conf.
Learn. Representations, 2017, pp. 1–18.
[18] J. Bae, M. R. Zhang, M. Ruan, E. Wang, S. Hasegawa, J. Ba, and
R. Grosse, “Multi-rate vae: Train once, get the full rate-distortion curve,”
in Proc. Int. Conf. Learn. Representations, 2022, pp. 1–14.
[19] A. Krizhevsky and G. Hinton, “Learning multiple layers of features from
tiny images,” University of Toronto, Toronto, Ontario, Tech. Rep. 0,
2009.
","nanRecent research efforts have focused on addressing the adaptability challenges of DJSCC. One approach is to employ attention mechanisms to adjust intermediate features according to channel conditions. However, attention-based methods suffer from computational complexity and disrupt the original DJSCC network structures. Another approach utilizes transformer-based methods to leverage intrinsic self-attention mechanisms for improved channel adaptability. Despite these advancements, there is a need for a generic framework that can be directly employed in various DJSCC networks to enhance their adaptability to channel conditions while maintaining the consistency and functionality of the original neural network architectures."
"With the rise of augmented reality (AR) and virtual reality (VR) devices, real-time 3D hand skeleton data is accessible and consistent across various devices and sensors. This research focuses on gesture classification and localization using skeleton data. Annotation encompasses classifying gestures and determining their temporal range. However, manual data annotation is costly and requires substantial human effort.","Hand gesture recognition technology is prevalent in fields like augmented reality (AR) and virtual reality (VR). Different types of hand gesture data, such as RGB, depth, and 3D skeletons, are used for recognition. To address the challenge of data sparsity in gesture recognition, researchers have used data augmentation techniques like Generative Adversarial Networks for gesture data transformation and unrealistic distortions like cutout and mixup. Approaches like few-shot learning have also been explored to reduce dataset size needs. However, the reliance on existing annotated datasets and the associated annotation costs remain significant concerns.","We introduce an annotation model that can predict unlabeled gesture data classification and localization. This model allows for large-scale, high-quality annotations without significant human intervention, serving as a foundation for real-time gesture recognition systems. A-ResLSTM is chosen as the backbone of the proposed model and trained with the Connectionist Temporal Classification (CTC) Loss. As the output of the model includes unsegmented inputs aligned with outputs, a dynamic adjustment was introduced to get the gesture's nucleus location.",Our ablation study demonstrates that our annotation model design surpasses the baseline in terms of both gesture classification accuracy (3-4% improvement) and localization accuracy (71-75% improvement). We consider this the first attempt at developing an automatic model for simultaneous gesture classification and localization.,"We propose an automatic annotation model capable of gesture classification and localization. Our model design significantly surpasses the baseline, achieving a 4.3% higher class labeling accuracy and a 71.4% improvement in nucleus localization accuracy on the SHREC’2021 dataset (3.4% and 75.0% respectively on the Online DHG dataset).",Simultaneous Gesture Classification and Localization with an Automatic Gesture Annotation Model,"Junxiao Shen, Xuhai Xu, Ran Tan, Amy Karlson, Evan Strasnick","SIMULTANEOUS GESTURE CLASSIFICATION AND LOCALIZATION WITH AN
AUTOMATIC GESTURE ANNOTATION MODEL
Junxiao Shen⋆
Xuhai Xu⋆
Ran Tan⋆
Amy Karlson⋆
Evan Strasnick⋆
⋆ Meta Reality Labs Research
ABSTRACT
Training a real-time gesture recognition model heavily relies
on annotated data. However, manual data annotation is costly
and demands substantial human effort. In order to address this
challenge, we propose a novel annotation model that can auto-
matically annotate gesture classes and identify their temporal
ranges. Our ablation study demonstrates that our annotation
model design surpasses the baseline in terms of both gesture
classification accuracy (3-4% improvement) and localization
accuracy (71-75% improvement). We believe that this anno-
tation model has immense potential to improve the training
of downstream gesture recognition models using unlabeled
datasets.
Index Terms— Gestural input, machine learning, anno-
tation model
1. INTRODUCTION
Hand gesture recognition technology is prevalent in fields like
augmented reality (AR) and virtual reality (VR). Different
types of hand gesture data, such as RGB, depth, and 3D skele-
tons, are used for recognition. With the rise of AR and VR
head-mounted devices (HMDs), real-time 3D hand skeleton
data is accessible and consistent across various devices and
sensors [1]. In this paper, we focus on gesture classification
and localization using skeleton data.
Building a gesture recognition model generally involves
data collection, annotation, and training. Annotation encom-
passes classifying gestures and determining their temporal
range. As deep-learning techniques dominate the state-of-
the-art gesture recognition models [2], there’s a substantial
need for labeled data. Insufficient data could lead to over-
fitting in deep neural networks [3].
The challenge is that
data annotation, especially detailed frame-wise annotation, is
time-intensive and expensive.
To combat data sparsity in gesture recognition, researchers
have used data augmentation techniques like Generative Ad-
versarial Networks for gesture data transformation [3] and
unrealistic distortions like cutout [4] and mixup [5].
Ap-
proaches like few-shot learning have also been explored to
reduce dataset size needs [6]. However, the reliance on ex-
isting annotated datasets and the associated annotation costs
remain significant concerns.
The potential of leveraging
large unlabeled datasets and the automation of the annotation
process remains largely untapped.
We introduce an annotation model that can predict unla-
beled gesture data classification and localization. This model
allows for large-scale, high-quality annotations without sig-
nificant human intervention, serving as a foundation for real-
time gesture recognition systems.
Using the SHREC’2021 [7] and Online DHG [8] datasets,
we conducted thorough tests on our model. An ablation study
revealed our model’s superior performance over the baseline
model. To our knowledge, this is the first attempt at present-
ing an automatic model for simultaneous gesture classifica-
tion and localization.
2. RELATED WORK
Traditionally, manual annotation software has been employed
to annotate gestures, with human annotators manually de-
tecting the start and end points of each gesture. However,
this process is time-consuming and requires significant la-
bor. As a result, there has been growing interest in devel-
oping automatic annotation tools. While various fields have
explored this idea (e.g., [9, 10, 11]), relatively fewer works
have focused on gesture data specifically. One relevant work
by Kratz et al. [12] presents preliminary research on automat-
ically segmenting motion gestures tracked by IMUs. They
suggest that by recognizing gesture execution phases from
motion data, it might be possible to automatically identify the
start and end points of gestures. However, their work primar-
ily focuses on gesture localization and does not address ges-
ture classification. More closely related to our work, Lenaga
et al.[13] propose the use of an Active Learning (AL)[14]
framework to automatically detect sign language gesture oc-
currences in RGB videos. Their approach requires manual
annotation for only a small subset of the videos, benefiting
researchers studying multimodal communication. However,
their primary application area is sign language gestures in
RGB videos, which predominantly focuses on spatial data.
In contrast, our model focuses on temporal data for gesture
annotation.
arXiv:2401.11150v1  [cs.CV]  20 Jan 2024
3. PROBLEM FORMULATION
This section formulates gesture annotation and gesture recog-
nition and discusses their difference. We also explain why
simply using a conventional gesture recognition model does
not suit data annotation and why an annotation model is nec-
essary.
It is important to clarify that when referring to gesture
recognition, we specifically focus on real-time gesture recog-
nition. In this context, real-time gesture recognition involves
identifying gestures within a realistic sequence that includes
multiple gesture classes as well as background activities (no
gestures), commonly observed in a sensor stream.
To achieve real-time gesture recognition, a typical ap-
proach is to utilize a sliding-window-based technique.
At
each sliding step, a window is fed into the model, produc-
ing class-conditional probabilities.
The predicted gesture
class within the window is determined by taking the maxi-
mum value from the probabilities. However, the conventional
real-time gesture recognition model is not well-suited for
data annotation, particularly for gesture nucleus localization.
Post-processing techniques need to be employed to localize
the gesture nucleus.
However, these post-processing steps
often rely on heuristic methods (e.g., [1]), which may be sus-
ceptible to variations in gestures and contextual differences.
Furthermore, although both gesture annotation and real-
time gesture recognition aim for accurate gesture classifica-
tion, they have different objectives. While real-time gesture
recognition models prioritize detecting gestures as quickly as
possible, gesture annotation additionally focuses on identify-
ing the nucleus of the gesture as accurately as possible. In
contrast, an annotation model can incorporate gesture nucleus
localization as an inherent training objective since it does not
need to optimize for recognition latency. This enables better
architectural design choices to improve the performance of
the annotation task.
4. PROPOSED MODEL
In this section, we describe our model for annotating gesture
data.
4.1. Design Considerations
We propose an annotation model optimized for gesture classi-
fication and localization and address four key design consid-
erations in our architecture.
1. Small vs Large Window Size: Conventionally, small win-
dows ensure accurate classification by focusing on a single
gesture. Although small windows lead to low recognition la-
tency, they have limited temporal context. Hence, we utilize
a larger window size with the sliding-window technique to
process multiple gestures concurrently.
~
-
Activation Layer
Output (length: T)
CTC Loss
True Label: {1, -, 3, -, 2}
Input (length: T)
~
-
~
-
~
1
~
1
~
1
…
…
~
-
~
-
~
-
…
…
~
3
~
3
~
3
…
…
~
-
~
2
~
2
…
…
~
-
~
-
…
…
Gesture: 1
Gesture: 3
Gesture: 2
Classification
Localization
A-ResLSTM
Fig. 1: Due to the extended input window of the annotation
model, the true label has the capacity to encompass multi-
ple gestures simultaneously. In the illustrated case, the true
labels are {1, - , 3, - ,2}, where “-” represents background
activities (no gesture). The output of the annotation model
is a sequence of predicted labels that has the same length as
inputs. The loss function for the proposed annotation model
is a Connectionist Temporal Classification (CTC) loss. The
backbone of the model is an A-ResLSTM we adopted from
Shen et al. [1].
2. One Prediction vs Multiple Predictions Per Frame:
Standard classification models provide a single vector of
class-conditional probabilities per frame. This many-to-one
mapping can lose fine-grained temporal information. Con-
versely, our many-to-many architecture retains richer tem-
poral information, enabling dynamic adjustments between
windows, reducing prediction noise.
3. Strongly-Segmented vs Weakly-Segmented Training
Data: While models trained using cross-entropy loss need
strongly-segmented data, obtaining such data is labor-intensive.
We employ Connectionist Temporal Classification (CTC)
loss, aligning unsegmented inputs with outputs without re-
quiring strong segmentation, a technique found effective in
seq2seq models.
4. Heuristic Parameters vs Automation: Traditional mod-
els like Shen et al. [1] employ heuristic threshold parameters
to pinpoint gesture locations. As these parameters can affect
localization, we favor a model devoid of heuristic parameters.
Leveraging CTC loss, we directly localize the gesture nucleus
by identifying the spike position in the CTC’s output without
post-processing.
4.2. Annotation Model
After considering these four design factos, we now introduce
our model’s individual components in detail.
0.5
1.0
0.0
Ground truth
0.5
1.0
0.0
CTC Loss
0.5
1.0
0.0
CE Loss
Fig. 2: Demonstration of the network output probabilities
from a CTC and CE (cross-entropy) trained network versus
the ground truth [18]. The spike of CTC loss clearly cap-
tures the gesture nucleus, while the curve of CE loss needs
post-processing. For example, the CTC loss successfully dis-
tinguishes two consecutive same gestures, while the CE loss
confuses them together.
4.2.1. Seq2seq Model
We design a seq2seq model that is a many2many model. It
has an input window W of frame length L (window size) and
an output which is a matrix of probabilities M ∈ RL×(K+1).
It defines the probabilities of detecting a gesture (or no ges-
ture) k at time t in an input window W: p(k, t | W) =
Mt
k∀t ∈ [0, N). The backbone of our seq2seq model is an
A-ResLSTM model we adopted from Shen et al. [1], which
is one of the state-of-the-art neural network architectures for
gesture recognition. This network is composed of residual
blocks [15] and bi-directional LSTM layers [16] with an at-
tention layer [17].
4.2.2. Connectionist temporal classification (CTC)
Compared to conventional cross-entropy (CE) loss, CTC loss
has the benefit of producing output with distinct, sharp predic-
tions that can accurately capture consecutive gestures. In con-
trast, a model trained with CE tends to blend predictions of the
same class together (see Figure 2). This means that in order to
correctly identify when one gesture has been performed, the
output from a CE-trained classification model must be pro-
cessed further with some heuristic methods with errors (e.g.,
a single-time activation algorithm [1]). However, with CTC,
the sharp nature of the predictions automatically eliminates
such error-prone step [18, 19, 20].
SHREC’2021 [7]
Online DHG [8]
Static
one - four, OK, menu
NA
Dynamic
left, right, circle, v, cross
rotation (counter-)clockwise,
right/left, up/down,
cross, plus, v, shake
Fine Dynamic
grab, pinch, tab, deny,
knob, expand
grab, pinch, tab, expand
Size
180 seqs of 3-5 gestures
occurring sequentially
280 seqs of 10 gestures
occurring sequentially
Table 1: Contents of the datasets. Static gestures are charac-
terized by keeping a fixed hand pose for a minimum amount
of time, while dynamic gestures are characterized by a single
trajectory with an unchanged hand pose or with finger articu-
lation over time. Fine dynamic gestures are characterized by
a single trajectory with changing hand pose.
4.2.3. Dynamic Adjustment
Due to the sliding-window fashion, for a window W of
length L sliding at step N, the model outputs M for each
window. M consists of L vectors of class-conditional prob-
abilities p. Therefore, the model will produce L/N times
class-conditional probabilities p at each step/frame, form-
ing a sequence (p1, p2, ..., pL/N). We perform a dynamic
adjustment on labeling and nucleus localization.
Specifi-
cally, we average these predictions to form one vector of
class-conditional probabilities for each step, i.e. paverage =
average(p1, p2, ..., pL/N) We determine the location of the
gesture’s nucleus by identifying the position of the highest
point in the gesture’s prediction.
4.2.4. Decoding
We use greedy search for the dynamic adjustment output,
which approximates the solution by taking the most likely
class at each step in the matrix M. It is efficient to compute
as it simply concatenates the most active outputs at each step.
5. EXPERIMENTS AND ANALYSIS
We conducted a series of experiments to evaluate our pro-
posed annotation model.
5.1. Evaluation Datasets
In order to ensure a thorough evaluation of our Model, we
perform our experiments on two publicly available datasets,
SHREC’2021 [7] and Online DHG [8]. These datasets consist
of sequences of unsegmented gesture data, encompassing var-
ious types of gestures. The specific details of the two datasets
are as follows: Both datasets already provided a predefined
split between training and testing data. Thus, we conducted
evaluations on the designated testing sets.
SHREC’2021 [7]
Online DHG [8]
Accuracy
NNLE
Accuracy
NNLE
A-ResLSTM [1] w/ CE Loss (Baseline Model)
88.3 (± 2.34)
0.42 (± 0.07)
89.8 (± 3.12)
0.44 (± 0.03)
A-ResLSTM w/ CTC loss
90.6 (± 1.45)
0.17 (± 0.03)
91.5 (± 3.35)
0.16 (± 0.04)
A-ResLSTM w/ CTC loss & many2many
91.9 (± 1.12)
0.14 (± 0.03)
92.7 (± 3.35)
0.15 (± 0.04)
A-ResLSTM w/ CTC loss & many2many & dynamic adjustment
92.6 (± 1.58)
0.12 (± 0.02)
93.2 (± 1.76)
0.11 (± 0.03)
Table 2: Ablation study results by adding our multiple design parts step by step. NNLE is our metric for gesture localization
(Normalized Nucleus Labeling Error). The numbers in the brackets indicate std.
5.2. Evaluation Metrics
We introduce our metrics to evaluate the tasks of gesture clas-
sification and localization.
1. Gesture Classification Accuracy:
Gesture annotation
would generate a sequence of classification output. We use
the Levenshtein distance (also known as minimum edit dis-
tance) to evaluate the gesture classification performance. It is
a metric defined as the minimum number of single-character
(in our case, classification output of each frame) insertions,
deletions, and substitutions required to transform one string
into another. The accuracy for recognition performance is
defined as:
Accuracy = 1 − levenshtein(ypredict, ytrue)
length(ytrue)
(1)
where ypredict and ytrue are the predicted and true list of la-
bels of the gestures, respectively.
2. Nucleus Localization Error: We propose a metric Nor-
malized Nucleus Localization Error (NNLE) to measure how
accurately our model can locate the gesture nucleus. When
a gesture is recognized, we define the time for the start/end
of the gesture as idxstart/idxend, and the detected location of
gesture nucleus as idxnucleus. For a accurate nucleus local-
ization, idxstart ≤ idxnucleus ≤ idxend. NNLE is defined
as:
NNLE = idxactivation − (idxstart + idxend)/2 + 1
idxend − idxstart + 1
(2)
A smaller NNLE means our annotation model is more accu-
rate for gesture localization (i.e., the nucleus is closer to the
center of the gesture).
5.3. Training Details
Our implementation was based on TensorFlow 2. We utilized
the Adam optimizer with a starting learning rate of 0.0001.
To prevent overfitting, we employed early stopping with a
patience of 5. For both the Online DHG and SHREC’2021
datasets, we used a window length of 200 for our model. It
is important to note that the length of an individual gesture
within the datasets ranged from 20 to 50 frames, correspond-
ing to a duration of approximately 0.4 to 1 second.
5.4. Ablation Study
Our novel annotation model essentially consists of multiple
design blocks: (1) using the CTC loss instead of a basic CE
loss, (2) using a many-to-many architecture (i.e., seq2seq) in-
stead of a many-to-one architecture, and (3) using dynamic
adjustment on labeling and nucleus localization. To evaluate
the effectiveness of each design block, we performed an abla-
tion study through a step-by-step addition process.
Table 2 illustrates the ablation study results. Compared to
the baseline (A-ResLSTM trained with Cross-Entropy (CE)
loss), our model significantly reduces the gesture localization
error by 0.3 (71.4%) and 0.33 (75.0%). Regarding gesture
classification accuracy, our model design achieves improve-
ments of 4.3% on the SHREC’2021 dataset and 3.4% on the
Online DHG dataset compared to the baseline.
Each of the three blocks contributes approximately equally
to the overall gesture classification accuracy improvement.
For gesture nucleus localization, the main contribution stems
from the application of the Connectionist Temporal Classifi-
cation (CTC) loss. This highlights the unique character of the
CTC-trained model in producing outputs with a spiky nature,
eliminating the need for complex post-processing techniques
(see Figure 2).
In contrast, CE-trained networks require
post-processing to determine the final label, often relying on
heuristic methods.
6. CONCLUSION
This paper presents a model that enables accurate and au-
tomated annotation of gesture data, encompassing gesture
classification and localization. The ablation study reveals that
this novel annotation model design surpasses the baseline
model, achieving a 4.3% higher class labeling accuracy and a
71.4% improvement in nucleus localization accuracy on the
SHREC’2021 dataset (3.4% and 75.0% respectively on the
Online DHG dataset).
7. REFERENCES
[1] Junxiao Shen, John J Dudley, Mo George, and Per Ola
Kristensson, “Gesture spotter: A rapid prototyping tool
for key gesture spotting in virtual and augmented reality
applications,” in IEEE transactions on visualization and
computer graphics, 2022.
[2] Jianbo Liu, Yongcheng Liu, Ying Wang, Veronique
Prinet, Shiming Xiang, and Chunhong Pan,
“Decou-
pled representation learning for skeleton-based gesture
recognition,” in Proceedings of the IEEE/CVF confer-
ence on computer vision and pattern recognition, 2020,
pp. 5751–5760.
[3] Junxiao Shen, John Dudley, and Per Ola Kristensson,
“The imaginative generative adversarial network: Au-
tomatic data augmentation for dynamic skeleton-based
hand gesture and human action recognition,” in 2021
16th IEEE International Conference on Automatic Face
and Gesture Recognition (FG 2021). 2021, p. 1–8, IEEE
Press.
[4] Terrance DeVries and Graham W Taylor,
“Improved
regularization of convolutional neural networks with
cutout,” arXiv preprint arXiv:1708.04552, 2017.
[5] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and
David Lopez-Paz, “mixup: Beyond empirical risk min-
imization,” arXiv preprint arXiv:1710.09412, 2017.
[6] Xuhai Xu, Jun Gong, Carolina Brum, Lilian Liang,
Bongsoo Suh, Kumar Gupta, Yash Agarwal, Lau-
rence Lindsey, Runchang Kang, Behrooz Shahsavari,
Tu Nguyen, Heriberto Nieto, Scott E. Hudson, Char-
lie Maalouf, Seyed Mousavi, and Gierad Laput, “En-
abling hand gesture customization on wrist-worn de-
vices,” 2022.
[7] Ariel Caputo, Andrea Giachetti, Simone Soso, Deb-
orah Pintani, Andrea D’Eusanio, Stefano Pini, Guido
Borghi, Alessandro Simoni, Roberto Vezzani, Rita Cuc-
chiara, et al.,
“Shrec 2021: Track on skeleton-based
hand gesture recognition in the wild,” arXiv preprint
arXiv:2106.10980, 2021.
[8] Quentin De Smedt, Hazem Wannous, Jean-Philippe
Vandeborre, Joris Guerry, Bertrand Le Saux, and David
Filliat, “SHREC’17 Track: 3D Hand Gesture Recog-
nition Using a Depth and Skeletal Dataset,” in 3DOR
- 10th Eurographics Workshop on 3D Object Retrieval,
I. Pratikakis, F. Dupont, and M. Ovsjanikov, Eds., Lyon,
France, Apr. 2017, pp. 1–6.
[9] Dengsheng Zhang, Md Monirul Islam, and Guojun Lu,
“A review on automatic image annotation techniques,”
Pattern Recognition, vol. 45, no. 1, pp. 346–362, 2012.
[10] Deva Ramanan and David Forsyth, “Automatic annota-
tion of everyday movements,” Advances in neural infor-
mation processing systems, vol. 16, 2003.
[11] Olivier Duchenne, Ivan Laptev, Josef Sivic, Francis
Bach, and Jean Ponce,
“Automatic annotation of hu-
man actions in video,” in 2009 IEEE 12th International
Conference on Computer Vision. IEEE, 2009, pp. 1491–
1498.
[12] Sven Kratz and Maribeth Back, “Towards accurate au-
tomatic segmentation of imu-tracked motion gestures,”
2015, CHI EA ’15, Association for Computing Machin-
ery.
[13] Naoto Ienaga, Alice Cravotta, Kei Terayama, Bryan
Scotney, Hideo Saito, and Maria Grazia Busa, “Semi-
automation of gesture annotation by machine learning
and human collaboration,”
Language Resources and
Evaluation, vol. 56, 09 2022.
[14] Burr Settles, “Active learning literature survey,” 2009.
[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun, “Deep residual learning for image recognition,” in
Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[16] Sepp Hochreiter and J¨urgen Schmidhuber, “Lstm can
solve hard long time lag problems,” Advances in neural
information processing systems, pp. 473–479, 1997.
[17] Minh-Thang Luong, Hieu Pham, and Christopher D
Manning,
“Effective
approaches
to
attention-
based neural machine translation,”
arXiv preprint
arXiv:1508.04025, 2015.
[18] Maarten
Vandersteegen,
Wouter
Reusen,
Kristof
Van Beeck, and Toon Goedem´e,
“Low-latency hand
gesture recognition with a low-resolution thermal im-
ager,” in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition Workshops,
2020, pp. 98–99.
[19] Pavlo Molchanov, Xiaodong Yang, Shalini Gupta, Kih-
wan Kim, Stephen Tyree, and Jan Kautz, “Online de-
tection and classification of dynamic hand gestures with
recurrent 3d convolutional neural network,” in Proceed-
ings of the IEEE conference on computer vision and pat-
tern recognition, 2016, pp. 4207–4215.
[20] Alex Graves, Santiago Fern´andez, Faustino Gomez, and
J¨urgen Schmidhuber,
“Connectionist temporal classi-
fication: labelling unsegmented sequence data with re-
current neural networks,” in Proceedings of the 23rd in-
ternational conference on Machine learning, 2006, pp.
369–376.
","nanTraditionally, manual annotation software has been employed to annotate gestures, with human annotators manually detecting the start and end points of each gesture. However, this process is time-consuming and requires significant labor. As a result, there has been growing interest in developing automatic annotation tools."
"Document set expansion identifies relevant documents from a vast collection based on a small subset of fine-grained topics. This work explores the limitations of PU learning methods for DSE in transductive experimental settings and proposes a novel PU framework called puDE. Unlike earlier methods, puDE does not depend on SCAR assumptions or require class prior knowledge. Experiments demonstrate its effectiveness and superiority for DSE.","The focus of this research is document set expansion (DSE), where a small number of documents related to a specific topic are given, and the goal is to identify all relevant documents from a sizable collection. Methods based on information retrieval often fail to capture the connections between the seed documents and the relevant words. Positive-unlabeled (PU) learning, which trains binary classifiers using positive and unlabeled data, proves a promising approach. Yet, PU methods face challenges such as unknown class prior and imbalanced data. Besides, traditional PU approaches are not suitable for transductive DSE, where the unlabeled set is used both for training and testing. Furthermore, SCAR labeling assumptions, commonly used in PU methods, may not hold in many applications. Therefore, a novel transductive PU learning framework is proposed in this paper, which does not rely on SCAR assumptions and handles imbalanced data.","To address the limitations of prior PU approaches for DSE, this paper introduces a new PU learning framework called puDE, which does not depend on SCAR assumptions or require class prior knowledge. It focuses on the case-control scenario, where the labeled positive data is generated from the distribution of all positive data, but does not follow the SCAR assumption, i.e., it allows for different distributions of labeled positive data and positive data. To estimate the densities P(X|Y = 1) and P(X), nonparametric (KDE) and parametric (EBM) density estimation techniques are employed.","Experiments are conducted on real-world datasets to assess the effectiveness of the proposed puDE method. It outperforms state-of-the-art PU approaches, demonstrating its suitability for the DSE task. The transductive version of nnPU performs poorly, suggesting that the PU solutions proposed earlier are not as effective as claimed for DSE. The proposed puDE methods show significant improvement over nnPU and achieve the best results.","The paper highlights the limitations of PU solutions for DSE and demonstrates that inductive experimental results do not accurately translate to real-world transductive DSE scenarios. A novel PU learning framework called puDE is proposed, which is not constrained by SCAR assumptions and does not require class prior knowledge. Empirical results validate the effectiveness of puDE, positioning it as a superior solution for the DSE task.",Document Set Expansion with Positive-Unlabeled Learning: A Density Estimation-based Approach,"Haiyang Zhang, Qiuyi Chen, Yuanjie Zou, Yushan Pan, Jia Wang, Mark Stevenson","Document Set Expansion with Positive-Unlabeled Learning: A Density
Estimation-based Approach
Haiyang Zhang1∗, Qiuyi Chen1, Yuanjie Zou1, Yushan Pan1, Jia Wang1, Mark Stevenson2
1Xi’an Jiaotong Liverpool University
2University of Sheffield
∗Haiyang.zhang@xjtlu.edu.cn
Abstract
Document set expansion aims to identify rele-
vant documents from a large collection based
on a small set of documents that are on a fine-
grained topic. Previous work shows that PU
learning is a promising method for this task.
However, some serious issues remain unre-
solved, i.e. typical challenges that PU methods
suffer such as unknown class prior and imbal-
anced data, and the need for transductive exper-
imental settings. In this paper, we propose a
novel PU learning framework based on density
estimation, called puDE, that can handle the
above issues. The advantage of puDE is that
it neither constrained to the SCAR assumption
and nor require any class prior knowledge. We
demonstrate the effectiveness of the proposed
method using a series of real-world datasets and
conclude that our method is a better alternative
for the DSE task.
1
Introduction
We focus on the task of document set expansion
(DSE), as proposed in (Jacovi et al., 2021), where a
small set of documents belonging to a fine-grained
topic is available, and we aim to find all documents
on this topic from a large collection. This kind of
task often arises in the screening process of litera-
ture curation. In this process, human experts need
to carefully go through a larger pool of candidate
documents obtained from typical databases to iden-
tify relevant documents (Wang et al., 2023). It is
natural for the experts to be aware of the existence
of a small set of relevant documents, known as
‘seed studies’, before initiating the screening pro-
cess (Wang et al., 2022a). Common methods for
modeling this problem involve treating the set of
documents as an extended query and making use
of information retrieval techniques to re-rank the
candidate documents (Lee and Sun, 2018; Wang
et al., 2022b). However, such methods fail to cap-
ture the local or global connections between words
and seed studies (Jacovi et al., 2021).
Jacovi et al. (2021) proposes to model the DSE
task as a positive and unlabeled (PU) learning prob-
lem and the aim of which is to train a binary classi-
fier with only positive and unlabeled data (Bekker
and Davis, 2020; Plessis et al., 2015; Kiryo et al.,
2017). Their study identifies the challenges of state-
of-the-art PU method suffer, such as unknown class
prior and imbalanced data. And they propose prac-
tical solutions to overcome such challenges. How-
ever, some important issues remain unresolved:
• Although the solution introduced in Jacovi
et al. (2021) shows empirical improvement
over typical Non-negative PU (nnPU) (Kiryo
et al., 2017) method, they still fail to address
the inherent problems PU methods face except
by exploiting the tricks in model implemen-
tation, i.e. BER optimization, proportional
batching, and use of pre-trained embedding.
• DSE is a transductive problem since we aim
to identify all positive documents from the
unlabeled set (U). In this case, the unlabeled
set should be used for both training and testing.
However, in Jacovi et al. (2021), U is split
into training, validation, and test sets, with
only samples in the test set being classified.
Such experimental settings cannot reflect the
ground truth performance of the model for the
DSE task.
• PU methods that rely on risk estimators, such
as nnPU, are based on the assumption of se-
lected completely at random (SCAR) labelling
mechanism (Bekker and Davis, 2020), which
assumes that the labeled positive data is identi-
cally distributed as the positive data. However,
in the DSE scenario, the SCAR assumption
does not hold, i.e. the known positive samples
is influenced by experts’ prior knowledge and
selected with bias.
To address these issues, we propose a novel PU
arXiv:2401.11145v1  [cs.LG]  20 Jan 2024
learning framework that is not constrained to the
SCAR labeling mechanism assumptions. Similar
to SCAR, we focus on the case-control scenario,
assuming that the positive and unlabeled data orig-
inated from two independent datasets and the un-
labeled set is sampled from the real distribution
(Bekker and Davis, 2020). However, we do not
make SCAR’s assumption about how the labeled
positives data are selected, i.e., the data distribu-
tions of labeled positives and positives dosen’t need
to be identical. The primary contributions of this
work are: 1) the limitations of the PU solutions pro-
posed in Jacovi et al. (2021) for DSE scenario are
identified; 2) a new PU learning framework based
on the density estimation is proposed, called puDE,
that is not constrained to the SCAR assumption and
doesn’t require any knowledge of class prior; and
3) the proposed method outperform state-of-the-art
PU methods on real-world datasets and we con-
culde that our method is a better solution for the
DSE task. To our knowledge, this is the first work
applying PU methods to transductive learning.
2
Preliminary
In binary classification, we aim to learn a decision
function f : X → Y that can classify X ∈ Rd
into one of the classes Y ∈ {+1, −1}. P(x, y) is
the joint probability density of distribution (X, Y )
and π = P(x|Y = 1) is the marginal probability
density of x given Y = 1, known as class prior.
The setting of PU, where only a small portion
of the positive data is available, is a special case of
binary classification (Bekker and Davis, 2020). The
training set X can be seen as the combination of the
labeled positive set XLP , the unlabeled positive set
XUP , and the unlabeled negative set XUN, such
that X = XLP ∪ XUP ∪ XUN. Let s ∈ {1, 0} be
the label status of y (s = 1 if labeled, otherwise
s = 0), there will be:
XLP = {x|s = 1, Y = +1},
XUP = {x|s = 0, Y = +1}
XUN = {x|s = 0, Y = −1},
XU = {x|s = 0}
The label frequency can be represented as c =
P(s = 1|Y = +1) (Elkan and Noto, 2008).
Existing PU models can be divided into two cat-
egories based on sampling schemes: censoring sce-
nario and case-control scenario. We here focus on
the latter scenario since it is more general than the
former one (Niu et al., 2016). Case-control sce-
nario assumes a set of positive data and a set of
unlabeled data are drawn from P(x|Y = 1) and
P(x), respectively. In the case-control scenario, the
most widely used labeling assumption is SCAR. It
assumes that the positive labeled data are randomly
selected from the set of positive data and are iden-
tically distributed with the positive unlabeled data,
i.e. P(x|s = 1, Y = +1) = P(x|s = 0, Y = +1)
(Elkan and Noto, 2008). Many existing PU meth-
ods are proposed based on the SCAR assumption
and show their efficient for PU problems (Plessis
et al., 2015; Kiryo et al., 2017; Chen et al., 2020).
However, as aforementioned, the SCAR hypothesis
may not be suitable for many PU applications, e.g.
in the DSE task, the set of known documents is
biased to experts’ prior knowledge.
In this paper, we consider the case-control sce-
nario, i.e. the labeled positive examples are sam-
pled from P(x|Y = 1), but not the SCAR assump-
tion, i.e. P(x|Y = +1) may be different from
P(x|s = 1, Y = +1). In such case, P(x|Y = +1)
can be estimated based on the labeled positive ex-
amples using density estimation methods without
relying on any distributional assumptions.
3
Proposed Methods
3.1
Task Formulation
According to Jacovi et al. (2021), we consider the
following task: we have a set of labeled positive
documents XLP on a fine-grained topic and want
to find more documents about that topic from a
large collection XU. This task is essentially the
screening prioritisation (Wang et al., 2022a) task
for literature curation, where some seed studies are
known based on the experts’s kwnoledge, and the
goal is to rank all studies in XU.
3.2
PU Learning with Density Estimation
Due to the shortcomings of PU methods that rely
on SCAR assumption (Jacovi et al., 2021), we pro-
pose a new method for PU learning based on the
density estimation technique called puDE. It is not
constrained to the SCAR labeling mechanism as-
sumptions and do not require any knowledge of
the class prior. Given XLP and XU, the objec-
tive of puDE is to learn a function to approximate
P(Y = +1|x). According to the Bayesian rule, we
have:
P(Y = 1|X) = P(X|Y = 1)P(Y = 1)
P(X)
(1)
Let p : Rd → [0, 1] and q : Rd → [0, 1] be two
trained generative models to approximate the like-
lihood distributions P(X|Y = 1) and evidence
distribution P(X) respectively. Then, P(Y = 1|x)
can be estimated by:
f(x) = p(x) · π
q(x)
(2)
Note that π is a constant prior for each x which can
be ignored in the calculation of f(x) in practice.
This is the key advantages of puDE. Thus, f(x) can
be calculated by estimating p(x) and q(x). Under
case-control case, labeled positives are samples
from all positive set. Therefore, we can estimate the
density of p(x) using samples from XLP . In this
paper, we use both nonparametric and parametric
density estimation methods to accomplish this task.
3.2.1
Nonparametric Density Estimation
Kernel Density Estimation (KDE) is a nonpara-
metric density estimation technique, which has
been applied in recommender systems and infor-
mation retrieval (Chakraborty et al., 2022). An
important benefit of KDE is its ability to estimate
density without making assumptions about the un-
derlying data distribution. For the given dataset
{x1, x2, · · · xn}, the estimated density ˆf at x is de-
fined as: bfh(x) =
1
nh
Pn
i=1 K
dataset
|LP|
NU
NUP
NUN
Pubmed-topic1
20
10012
1844
8168
50
10027
2568
7459
Pubmed-topic2
20
10012
2881
7131
50
10027
3001
7026
Pubmed-topic3
20
7198
1201
5997
50
10025
1916
8109
Covid
{47..4722}
4722
2310
2412
Table 1: Statistics of XU for each set, where NU, NUP
and NUN, the total number of unlabeled samples, the
number of true positive samples and true negatives in
the training set. topic 1,2 and 3 correspond to the topics
on Animals+Brain+Rats, Adult+Middle Aged+HIV in-
fections and Renal Dialysis + Chronic Kidney Failure+
Middle Aged from (Jacovi et al., 2021).
both training and testing (XLP and XU for train-
ing and XU for testing). Following Jacovi et al.
(2021), the number of labeled positives |LP| is set
to {20, 50} for training on Pubmed datasets. The
labeled positives on covid dataset is randomly sam-
pled from their positive training set, and the value
of |LP| is set with respect to the ratio of XLP over
XU, ranging from 0.01 to 1. The statistics of each
set is summarized in Table 1.
4.2
Results
We use puDE-kde and puDE-em to denote the pro-
posed PU models that based KDE and EBM, re-
spectively. For puDE-kde, the bandwidth is set to
1.9 for both Dp(x) and D(x), and Gaussian func-
tion is used as the kernel. To accommodate the
high-dimensional data, we implement a VAE with
256 hidden dimensions and 50 latent dimensions.
For puDE-em, the Langevin sampling involves 100
steps with a step size of 0.01. The weights for the
total loss function are set as α = 1, β = 1, and
γ = 1.
nnPU is used as the main competitor in our ex-
periments and we implement a transductive version
of nnPU using the tricks from Jacovi et al. (2021),
denoted as nnPU-trans. BM25 is act as the baseline
for ranking and its results are directly taken from
(Jacovi et al., 2021). All models, except puDE-kde,
are implemented using a 6-layer neural network
with 200 hidden states per layer. Batch normaliza-
tion (Ioffe and Szegedy, 2015) and leaky ReLU
(Maas et al., 2013) are applied for each hidden
layer. The Adamax optimizer with a learning rate
of 1e-3 is employed.
According to Table 2, we can notice that the per-
formance of nnPU-trans is much worse than that
reported in (Jacovi et al., 2021) and is similar to
BM25, which indicate that the PU solutions pro-
|LP|
Topic
BM25 nnPU-
trans.
puDE-
kde
puDE-
em
20
topic1
32.25
33.03
37.31
40.59
topic2
26.75
31.30
36.18
39.67
topic3
41.23
27.76
36.63
35.59
50
topic1
32.80
38.76
44.65
44.91
topic2
31.85
34.16
44.03
46.22
topic3
35.78
32.84
36.63
36.57
Table 2: F1 comparison against baseline and state-of-
the-art DES methods.
Figure 1: F1 comparison on covid dataset with respect
to the ratio of |LP| over |U| ranging from 0.01 to 1.
posed in Jacovi et al. (2021) is not as effective as
they stated for the DSE task. Both puDE meth-
ods outperform other methods, with one exception
where BM25 get the best result on topic 3 when
|LP| equals 20, and show significant improvement
over nnPU-trans, demonstrating that the proposed
PU framework based on density estimation is a
better alternative for the DSE task.
Figure 1 demonstrates the F1 results for all
model on Covid set, with the ratio of |LP| over
|U| ranging from 0.01 to 1. It can be seen that all
models get stable results if more than 10% of la-
belled data is avaiable, and both puDE methods
consistently shown significant improvements over
nnPU with the increase of labeled data.
5
Conclusion
In this paper, we aim to highlight the limitations
of PU solutions propose by Jacovi et al. (2021),
and demonstrate that the experimental results in in-
ductive setting cannot be transferred to real-world
transductive DSE case. We propose a novel PU
learning framework that incorporate two density es-
timator with the help of Bayesian inference, called
puDE. It is not constrained to the SCAR assump-
tion and doesn’t require any knowledge of class
prior. Empirical experiments verify the effective-
ness of our methods. We conclude that our methods
is a better solution for the DSE task.
References
Jessa Bekker and Jesse Davis. 2020. Learning from
positive and unlabeled data: A survey.
Machine
Learning, 109:719–760.
Anirban Chakraborty, Debasis Ganguly, Annalina Ca-
puto, and Gareth JF Jones. 2022. Kernel density
estimation based factored relevance model for multi-
contextual point-of-interest recommendation. Infor-
mation Retrieval Journal, 25(1):44–90.
Hui Chen, Fangqing Liu, Yin Wang, Liyue Zhao, and
Hao Wu. 2020. A variational approach for learning
from positive and unlabeled data. Advances in Neural
Information Processing Systems, 33:14844–14854.
Charles Elkan and Keith Noto. 2008. Learning clas-
sifiers from only positive and unlabeled data. In
Proceedings of the 14th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, KDD ’08, page 213–220, New York, NY, USA.
Association for Computing Machinery.
Laurent Girin, Simon Leglaive, Xiaoyu Bie, Julien Di-
ard, Thomas Hueber, and Xavier Alameda-Pineda.
2020. Dynamical variational autoencoders: A com-
prehensive review. arXiv preprint arXiv:2008.12595.
Sergey Ioffe and Christian Szegedy. 2015. Batch nor-
malization: Accelerating deep network training by re-
ducing internal covariate shift. In International con-
ference on machine learning, pages 448–456. pmlr.
Alon Jacovi, Gang Niu, Yoav Goldberg, and Masashi
Sugiyama. 2021. Scalable evaluation and improve-
ment of document set expansion via neural positive-
unlabeled learning. In Proceedings of the 16th Con-
ference of the European Chapter of the Association
for Computational Linguistics: Main Volume, pages
581–592, Online. Association for Computational Lin-
guistics.
Diederik P Kingma and Max Welling. 2013.
Auto-
encoding
variational
bayes.
arXiv
preprint
arXiv:1312.6114.
Ryuichi Kiryo, Gang Niu, Marthinus C. du Plessis, and
Masashi Sugiyama. 2017. Positive-unlabeled learn-
ing with non-negative risk estimator. In Proceed-
ings of the 31st International Conference on Neu-
ral Information Processing Systems, NIPS’17, page
1674–1684, Red Hook, NY, USA. Curran Associates
Inc.
Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato,
and Fujie Huang. 2006. A tutorial on energy-based
learning. Predicting structured data, 1(0).
Grace E. Lee and Aixin Sun. 2018. Seed-driven doc-
ument ranking for systematic reviews in evidence-
based medicine. In The 41st International ACM SI-
GIR Conference on Research & Development in In-
formation Retrieval, SIGIR ’18, page 455–464, New
York, NY, USA. Association for Computing Machin-
ery.
Andrew L Maas, Awni Y Hannun, Andrew Y Ng, et al.
2013. Rectifier nonlinearities improve neural net-
work acoustic models. In Proc. icml, volume 30,
page 3. Atlanta, Georgia, USA.
Gang Niu, Marthinus C. du Plessis, Tomoya Sakai,
Yao Ma, and Masashi Sugiyama. 2016. Theoretical
comparisons of positive-unlabeled learning against
positive-negative learning. In Proceedings of the
30th International Conference on Neural Informa-
tion Processing Systems, NIPS’16, page 1207–1215,
Red Hook, NY, USA. Curran Associates Inc.
George Papamakarios, Theo Pavlakou, and Iain Murray.
2017. Masked autoregressive flow for density esti-
mation. Advances in neural information processing
systems, 30.
Marthinus Du Plessis,
Gang Niu,
and Masashi
Sugiyama. 2015. Convex formulation for learning
from positive and unlabeled data. In Proceedings
of the 32nd International Conference on Machine
Learning, volume 37 of Proceedings of Machine
Learning Research, pages 1386–1394, Lille, France.
PMLR.
Ian Shemilt, Anna Noel-Storr, James Thomas, Robin
Featherstone, and Chris Mavergames. 2022. Ma-
chine learning reduced workload for the cochrane
covid-19 study register: development and evaluation
of the cochrane covid-19 study classifier. Systematic
Reviews, 11(1):1–8.
B.W. Silverman. 2018. Density Estimation for Statistics
and Data Analysis. Routledge.
Shuai Wang, Harrisen Scells, Justin Clark, Bevan Koop-
man, and Guido Zuccon. 2022a. From little things
big things grow: A collection with seed studies for
medical systematic review literature search. In Pro-
ceedings of the 45th International ACM SIGIR Con-
ference on Research and Development in Information
Retrieval, SIGIR ’22, page 3176–3186, New York,
NY, USA. Association for Computing Machinery.
Shuai Wang, Harrisen Scells, Bevan Koopman, and
Guido Zuccon. 2023. Neural rankers for effective
screening prioritisation in medical systematic review
literature search. In Proceedings of the 26th Aus-
tralasian Document Computing Symposium, ADCS
’22, New York, NY, USA. Association for Computing
Machinery.
Shuai Wang, Harrisen Scells, Ahmed Mourad, and
Guido Zuccon. 2022b. Seed-driven document rank-
ing for systematic reviews: A reproducibility study.
In Advances in Information Retrieval, pages 686–700,
Cham. Springer International Publishing.
","Jacovi et al. (2021) explored the applicability of PU learning to DSE and addressed some challenges in state-of-the-art PU methods. However, they did not tackle the inherent issues of PU methods, relied on model implementation tricks, and employed inductive experimental settings instead of the transductive setting necessary for DSE. They also assumed the SCAR labeling mechanism, which might not be appropriate for DSE scenarios.nan"
"This paper investigates a near-field wideband beamforming scheme in reconfigurable intelligent surface (RIS)-aided multiple-input multiple-output (MIMO) systems. To mitigate the double beam split effect caused by the frequency-independent analog precoding at the base station (BS) and phase-shifting at the RIS, the authors propose a deep learning-based end-to-end (E2E) beamforming optimization framework to maximize the system spectral efficiency. Furthermore, they design an efficient signal-guided beamforming network architecture based on the proposed E2E optimization framework, which integrates advanced neural network architectures and classical communication signal processing methods.","The increasing demand for high throughput, massive connectivity, and energy efficiency in 6G wireless networks calls for extremely large scale antenna arrays (ELAAs) and high frequencies. Reconfigurable intelligent surface (RIS) technology has emerged as one of the promising solutions to construct a smart radio environment. In this context, the near-field boundary in 6G communications will be significantly extended due to the increase of Rayleigh distance. Then, near-field wideband RIS communications, characterized by the double beam split effect, pose new challenges for beamforming design.","The proposed beamforming framework consists of an uplink channel training (UL-CT) module and a downlink beamforming (DL-BF) module. The UL-CT module is designed to learn the channel semantics with a trainable wideband phase-shifting tensor at the RIS and a combining matrix at the BS. The DL-BF module is composed of a low-level shared network and multiple sub-networks, which are used to jointly design the near-field wideband beamforming. The proposed signal-guided shared network architecture incorporates Fourier transform and learnable filters for efficient feature extraction and transformation. The high-level sub-networks are constructed with stacked linear layers to design the frequency-dependent phase-shifting at the TTD-RIS and SA-RIS architectures, as well as the hybrid beamforming at the BS.","Numerical results demonstrate the superiority of the proposed E2E models over conventional beamforming benchmarks. The proposed E2E models can effectively mitigate the near-field double beam split effect and achieve superior beamforming performance. Furthermore, the tradeoff between the beamforming gain and the hardware complexity is investigated under different frequency-dependent RIS architectures.","In this paper, a deep learning-enabled near-field wideband beamforming scheme in RIS-aided MIMO systems was proposed. The proposed approach alleviates the beamforming performance loss caused by the near-field double beam split effect. Two specific RIS architectures, i.e., TTD-RIS and SA-RIS, were exploited to achieve the frequency-dependent passive beamforming. The E2E beamforming optimization framework was proposed to jointly design the high-dimensional channel estimation and the frequency-dependent wideband beamforming. Moreover, to accelerate the convergence of the proposed E2E model, advanced deep learning architectures and the classical communication signal processing theory were integrated to develop an efficient beamforming network backbone. Numerical results showed the proposed E2E models without the explicit CSI had superior beamforming performance and robustness to the existing wideband beamforming benchmarks.",Wideband Beamforming for RIS Assisted Near-Field Communications,"Ji Wang, Jian Xiao, Yixuan Zou, Wenwu Xie, Yuanwei Liu","1
Wideband Beamforming for RIS Assisted
Near-Field Communications
Ji Wang, Jian Xiao, Yixuan Zou, Wenwu Xie, and Yuanwei Liu, Fellow, IEEE
Abstract—A near-field wideband beamforming scheme is in-
vestigated for reconfigurable intelligent surface (RIS) assisted
multiple-input multiple-output (MIMO) systems, in which a
deep learning-based end-to-end (E2E) optimization framework
is proposed to maximize the system spectral efficiency. To deal
with the near-field double beam split effect, the base station
is equipped with frequency-dependent hybrid precoding archi-
tecture by introducing sub-connected true time delay (TTD)
units, while two specific RIS architectures, namely true time
delay-based RIS (TTD-RIS) and virtual subarray-based RIS
(SA-RIS), are exploited to realize the frequency-dependent pas-
sive beamforming at the RIS. Furthermore, the efficient E2E
beamforming models without explicit channel state information
are proposed, which jointly exploits the uplink channel training
module and the downlink wideband beamforming module. In the
proposed network architecture of the E2E models, the classical
communication signal processing methods, i.e., polarized filtering
and sparsity transform, are leveraged to develop a signal-guided
beamforming network. Numerical results show that the proposed
E2E models have superior beamforming performance and robust-
ness to conventional beamforming benchmarks. Furthermore,
the tradeoff between the beamforming gain and the hardware
complexity is investigated for different frequency-dependent RIS
architectures, in which the TTD-RIS can achieve better spectral
efficiency than the SA-RIS while requiring additional energy
consumption and hardware cost.
Index Terms—Deep learning, near-field communications, re-
configurable intelligent surface, wideband beamforming.
I. INTRODUCTION
T
HE sixth-generation (6G) wireless networks aim to fur-
ther deliver high throughput, achieve massive connectiv-
ity, and enhance energy efficiency. In order to accomplish these
promising objectives, extremely large scale antenna arrays
(ELAAs) and tremendously high frequencies form a pair of
prospective technological solutions. In particular, as a new type
of metamaterial antenna, reconfigurable intelligent surface
(RIS) technology has been regarded as one of the highly
anticipated candidate ELAA solution to construct a smart
radio environment [1]. In this case, the near-field boundary
in 6G communications will be significantly extended due to
the increase of Rayleigh distance that is positively correlated
with the array aperture and the communication frequency [2].
Considering a large number of available bandwidth in high
frequencies, e.g., millimeter wave (mmWave) and Terahertz
(THz), the near-field wideband RIS communications is becom-
ing an up-and-coming communication paradigm in 6G era [3].
In near-field wideband RIS systems, new electromagnetic
(EM) characteristics need to be considered compared to the
classic far-field narrowband systems. Firstly, in contrast to the
planar wavefront assumption in the far-field channel modeling,
the near-field channel involves both angle and distance dimen-
sions due to the spherical wavefront in the near-field radiation,
which results in the near-field beamfocusing effect instead
of the far-field beamsteering [4], [5]. Secondly, the near-
field wideband channels can be strongly frequency-dependent
due to the large bandwidth between different subcarriers.
However, for the popular hybrid beamforming architecture in
ELAA systems, the typical analog beamformer is frequency-
independent. Consequently, the beams generated in different
frequencies may be focused at different locations, which
is termed as the beam split effect [6]. Especially, in RIS
enabled wideband communications, since reflection units at
the RIS only carry out the passive phase-shifting operation, the
impinging and reflected beams at the RIS will be also split into
different physical directions for different frequencies. In this
case, the specific property of the frequency-independent analog
precoding at the base station (BS) and phase-shifting at the RIS
cause the unique double beam split effect [7]. Consequently,
efficient frequency-dependent beamforming architectures and
optimization schemes are urgently expected to investigate for
near-field wideband RIS systems.
A. Prior works
1) Wideband RIS Communications: To deal with the beam
split effect in RIS-aided mmWave/THz systems, distributed
RISs and delay adjustable RISs are two feasible solutions. In
[8], the distributed RIS deployment strategy was proposed to
relieve the beam split effect, which required the high deploy-
ment cost and still relied on the frequency-independent phase-
shifting architecture [9]. In order to completely break through
this limitation of the analog phase-shifting circuit at the RIS,
the proposed true time delay (TTD) module in the wideband
hybrid precoder architecture was extended to the classic RIS
architecture. Specifically, in [10], the RIS element can realize
the frequency-selective operation by introducing TTD units,
in which a sub-surface architecture of RIS was provided to
balance the power gain and the hardware cost. Furthermore,
the authors of [7] proposed a sub-connected phase-delay-phase
RIS architecture to provide an energy-efficient implementation
for the frequency-dependent wideband phase-shifting scheme.
Moreover, the emerging simultaneously transmitting and re-
flecting RIS (STAR-RIS) architecture has been explored in
THz wideband communications [11], [12].
2) Near-Field Wideband RIS Communications: In near-
field wideband communications, the near-field beamfocusing
and wideband beam split will be deeply coupled, which
further increases the optimization difficulty for the efficient
arXiv:2401.11141v1  [cs.IT]  20 Jan 2024
2
beamforming scheme. For RIS enabled near-field wideband
systems, the design of beamforming optimization schemes
is still at a preliminary stage. In [13], the delay adjustable
metasurface technique in [14] that can adjust the delays of
signals reflected by different RIS elements was applied to
alleviate the beam split effect. However, the fully-connected
TTD module in [13] will lead to excessive hardware cost
and power consumption, which requires the number of delay
units has to be equal to the number of massive RIS elements.
Considering the uplink achievable rate optimization in THz
RIS systems, the authors of [15] divided the RIS into multiple
virtual subarrays, in which the phase shift of each subarray was
optimized according to the corresponding subcarrier channel.
In this way, the RIS was endowed with the ability to carry
out the frequency-dependent passive beamforming at different
sub-bandwidths. However, the effective aperture of RIS will
be shrink for the virtual subarray architecture, which results
in the significant energy loss of received signals at the RIS
and hence restricts the system performance.
B. Motivations and Contributions
While a few of research efforts have been devoted to
investigate the near-field wideband RIS systems, the necessary
prior assumptions, such as the known array manifold [13]
and line-of-sight (LOS)-dominant channel [15], were required
for the RIS phase-shifting derivation. In addition, in the
aforementioned works, the authors only focus on the phase-
shifting design at the RIS, while the BS was assumed to
be equipped with single-antenna or the predetermined fully
digital precoder. Consequently, the comprehensive solution
need to be further investigated for the joint passive and active
beamforming optimization, which involves the coupled non-
convex optimization in the wideband hybrid beamforming at
the BS and phase-shifting at the RIS. Moreover, when the
RIS and the BS are equipped with large-scale antenna arrays,
the required high-dimensional channel acquisition is also an
intractable challenge for the beamforming optimization.
Against the above background, in this work, we investigate
the near-field wideband beamforming design for RIS-aided
multiple-input multiple-output orthogonal frequency division
multiplexing (MIMO-OFDM) systems. Our main contributions
are summarized as follows.
• We investigate frequency-dependent hybrid precoding and
phase-shifting architecture for near-field wideband RIS
systems, aiming for alleviating the beamforming perfor-
mance loss caused by the near-field double beam split
effect. Specifically, the BS is equipped with frequency-
dependent hybrid precoding architecture by introducing
sub-connected TTD units, to deal with the near-field
beam split effect at the BS. Furthermore, considering
the wideband beam split effect at the RIS, two specific
RIS architectures, namely true time delay-based RIS
(TTD-RIS) and virtual subarray-based RIS (SA-RIS),
are exploited to realize the frequency-dependent passive
beamforming at the RIS.
• We propose a deep learning-based end-to-end (E2E)
beamforming optimization framework to maximize the
effective spectral efficiency in RIS-aided MIMO-OFDM
systems. The proposed E2E model is composed of the up-
link channel training (UL-CT) module and the downlink
beamforming (DL-BF) module, in which the learnable
combining matrix at the BS and phase-shifting at the
RIS are designed to realize the joint optimization of
beamforming and channel estimation with limited pilot
overhead. In contrast to the pre-defined combining matrix
and reflection pattern in traditional channel estimators, the
combining matrix and phase-shifting in the proposed UL-
CT module can be adaptively tuned according to dynamic
wireless environments.
• We exploit an efficient signal-guided beamforming net-
work architecture based on the proposed E2E optimiza-
tion framework, which integrates advanced neural net-
work architectures and classical communication signal
processing methods. Specifically, in the proposed UL-
CT module, we design a polar attention architecture to
imitate the typical communication signal filtering in the
frequency domain and time-spatial domain, which can
finely learn effective latent channel semantic information
from the received pilots. Motivated by the natural channel
sparsity for high-frequency ELAA systems, a learnable
discrete Fourier transform (DFT) is introduced into the
proposed DL-BF module, which guides and accelerates
the convergence of the beamforming network.
• Our numerical results reveal that a superior beamform-
ing performance can be achieved by the proposed E2E
models over the conventional beamforming benchmarks.
Specifically, compared with the conventional hybrid pre-
coding and the classic RIS architecture, the proposed
TTD-RIS and SA-RIS can effectively mitigate the near-
field double beam split effect. Furthermore, the proposed
E2E models can jointly optimize the active and passive
beamforming with the implicit CSI, which reduces the
required training overhead and improves the effective
spectral efficiency. Moreover, the robustness and general-
ization of the proposed E2E models are evaluated under
various system setups.
C. Organizations and Notations
The remainder of this paper is organized as follows. Sec-
tion II introduces the near-field wideband channel modeling
and system model in RIS assisted MIMO-OFDM systems.
In Section III, the deep learning-based near-field wideband
beamforming framework is proposed. Furthermore, the signal-
guided network architecture is presented in Section IV. Section
V provides numerical results of the proposed E2E models. In
Section VI, this paper is comprehensively summarized.
Notations: Lower-case and upper-case boldface letters de-
note a vector and a matrix, respectively; A𝑇 and A𝐻 denote the
transpose and conjugate transpose of matrix 𝐴, respectively; 𝑎∗
denotes the conjugate of complex number 𝑎; diag(a) denotes
the diagonal matrix with the vector a on its diagonal; I𝑎 is a
𝑎 × 𝑎 identity matrix, while 1𝑎 is a 𝑎 × 1 vector, satisfying
1𝑖 = 1, ∀𝑖 = {1, . . . , 𝑎}; Symbols |·|, ∥·∥, and ∥·∥𝐹 denote
the ℓ1, ℓ2, and Frobenius norm, respectively; ∝ denotes the
3
Fig. 1. Near-field wideband systems assisted by different frequency-dependent RIS architectures. (a) The TTD-RIS architecture; (b) The SA-RIS architecture.
proportionality relation. ⊙ and ⊗ denote the Hadamard product
and Kronecker product, respectively. ℜ(A) and ℑ(A) denote
the real and imaginary components of the complex-value
matrix A. det(A) denote the determinant of the matrix A.
Symbol j denotes the imaginary number.
II. SYSTEM MODEL AND PROBLEM FORMULATION
As shown in Fig. 1, we consider an 𝑁-element RIS assisted
mmWave MIMO-OFDM systems with 𝑀 transmit and 𝑈
receive antennas. Both transmit antennas at the BS and the
receive antennas at the user equipment (UE) are placed in
uniform linear arrays (ULAs), while the reflection elements
at the RIS are placed in uniform plane arrays (UPAs), i.e.,
𝑁 = 𝑁1 × 𝑁2. Considering the high susceptibility in mmWave
communications and practical complex wireless environments,
we assume that the LOS path between the BS and the UE
is completely blocked, while the non-LOS (NLOS) paths
are constructed by limited clustered scatterers. To enhance
mmWave communications, the RIS is introduced to provide
the virtual LOS path between the BS and the UE.
To deal with the double beam split effect caused by the
coupling of wideband beam split at the BS and the RIS, we
introduce the newly fashionable frequency-dependent beam-
forming architecture. Firstly, the sub-connected TTD mod-
ule is introduced to the hybrid beamforming architecture at
the BS, which is composed of 𝐾 TTDs and 𝑀RF ≪ 𝑀
radio frequency (RF) chains. Specifically, each RF chain is
connected to 𝐾 TTDs, and then each TTD is connected to
𝑃 = 𝑀/𝐾 phase-shifters (PSs). By utilizing the TTD module,
the traditional analogy beamforming will evolve into the
frequency-dependent analogy beamforming at the BS. Then,
for the wideband RIS architecture, we provide two feasible
candidate solutions, i.e., sub-connected TTD-RIS in Fig. 1(a)
and virtual SA-RIS architecture in Fig. 1(b), whose detailed
design guidelines are presented in Section II.C.
A. Near-Field Boundary in RIS-Aided MIMO Systems
In the specific communication scenarios, the near-field crite-
rion need to be re-derived due to different EM characteristics.
Specifically, the Rayleigh distance 𝑅 is a widely used criterion
to define the near-field boundary, which is given by [16]
𝑅 = 2𝐷2
𝜆 ,
(1)
where 𝐷 and 𝜆 denote the antenna aperture and the wave-
length, respectively. In multiple-input single-output (MISO)
systems, the near-field boundary can be defined according to
(1). With the increase of antenna array and communication
frequency, the near-field region will be significantly extended.
In RIS-aided MIMO communications, the near-field cri-
terion is different for the BS→UE direct link and the
BS→RIS→UE cascaded link. For the BS→UE MIMO com-
munications, the near-field boundary is given by [2]
𝑅 = 2(𝐷B + 𝐷U)2
𝜆
,
(2)
where 𝐷B and 𝐷U denote the antenna aperture of the BS and
the UE, respectively.
In contrast to MISO/MIMO channels in conventional com-
munication systems, the cascaded BS→RIS→UE reflection
link comprises the BS→RIS and RIS→UE links in RIS
systems. According to the near-field criterion in [2], the near-
field region in RIS systems can be expressed as
𝑟1𝑟2
𝑟1 + 𝑟2
< 2𝐷2
𝜆 ,
(3)
where 𝑟1 and 𝑟2 denote the BS→RIS and RIS→UE distance,
respectively. We observe that the near-field region in RIS
systems is determined by the harmonic mean of 𝑟1 and 𝑟2.
In other words, as long as any of 𝑟1 and 𝑟2 is shorter than
Rayleigh distance, the near-field communications will occur
in RIS systems due the passive property of the RIS.
4
B. Near-Field Wideband Channel Model
Considering the three-dimensional Cartesian coordinate sys-
tem in Fig. 2, we assume that both BS and RIS lie on
the 𝑥𝑧-plane, whose array center coordinate are set to cB =
5
(8) includes an additional coupled component, i.e., G𝑥
𝑐 ⊗ G𝑧
𝑐,
which can be expressed as

G𝑥
𝑐

𝑛2 = 𝑒− 𝑗 2𝜋 𝑓𝑏
𝑐𝑟BR ¯𝑛2𝑑2(1−𝜁 2
LOS),
(10a)

G𝑧
𝑐

𝑛1,𝑚 = 𝑒− 𝑗 2𝜋 𝑓𝑏
𝑐𝑟BR ¯𝑛1𝑚𝑑2 sin2 𝜑BR
LOS.
(10b)
Due to the presence of the above coupled component, near-
field LOS MIMO channels exhibit higher degree of freedoms
(DoFs) than far-field LOS MIMO channels. Hence, the higher
near-field DoFs can be exploited by constructing the virtual
LOS path in RIS systems.
The NLOS channel GNLOS[𝜏] between the BS and the RIS
at the 𝜏-th delay can be expressed as
GNLOS[𝜏] = 𝛾BR
𝐶s
∑︁
𝑐=1
𝑆𝑐
∑︁
𝑠=1
¯𝜍BR
𝑐,𝑠bBR
𝑐,𝑠(aBR
𝑐,𝑠)𝑇𝛿(𝜏𝑇𝑠 − 𝜏BR
𝑐,𝑠),
(11)
where 𝛾BR is a normalization factor for scatterer paths, and
parameter ¯𝜍BR
𝑐,𝑠 = 𝜍BR
𝑐,𝑠
√︃
𝐺B𝐺R𝐿BR
𝑐,𝑠 is composed of the complex
gain, the array gain and the path loss for scatterer (𝑐, 𝑠) in the
BS→RIS link. aBR
𝑐,𝑠 ∈ C𝑀×1 denotes the transmitting array
response at the BS for the BS→RIS NLOS path, and bBR
𝑐,𝑠 =
b𝑥( 𝑓𝑏, 𝜙R
𝑐,𝑠, 𝜑R
c,s, 𝑟R
𝑐,𝑠) ⊗ b𝑧( 𝑓𝑏, 𝜑R
𝑐,𝑠, 𝑟R
𝑐,𝑠) ∈ C𝑁 ×1 denotes the
receiving response at the RIS. Parameters 𝜙R
𝑐,𝑠 and 𝜑R
𝑐,𝑠 denote
the azimuth and elevation angle of AOA for scatterer (𝑐, 𝑠) at
the RIS, respectively. 𝑟R
𝑐,𝑠 =
cR − cS
𝑐,𝑠
 and 𝜏BR
𝑐,𝑠 denotes the
path delay of scatterer (𝑐, 𝑠) in the BS→RIS link.
By utilizing the DFT, the frequency-domain channel G[𝑏]
at the 𝑏-th subcarrier is given by
G[𝑏]= ¯𝜍BR
LOSbBR
LOS(aBR
LOS)𝑇 ⊙ 6
refection phase-shifting matrix at subcarrier 𝑏 for the TTD-
RIS can be expressed as
¯𝚯𝑏 = 𝚯1𝚲𝑏𝚯2,
(16)
where 𝚯1
=
diag(θ1), 𝚯2
=
diag(θ2), and 𝚲𝑏
=
diag(𝚲𝑏,1, . . . , 𝚲𝑏,𝑆). The time delay vector 𝚲𝑏,𝑠 ∈ C ¯𝑆×1 at
the 𝑠-th subarray is given by 𝚲𝑏,𝑠 = 1 ¯𝑆 ⊗ 𝑒− 𝑗2𝜋 𝑓𝑏𝜈𝑠.
3) Virtual Subarray-Based Phase-Shifting at the RIS: In
the above TTD-RIS architecture, the additional TTD units
and double-layer phase-shifting circuit are required, which
increases the hardware cost and energy consumption in RIS
systems. In Fig. 1(b), we present an SA-RIS architecture
by dividing the RIS into 𝐵 virtual subarrays, in which the
reflection coefficients ˜θ𝑏 ∈ C
𝑁
𝐵 ×1 at subarray 𝑏 is optimized
according to the channels D[𝑏], G[𝑏] and H[𝑏] at subcarrier
𝑏. In this case, the refection phase-shifting matrix at the SA-
RIS is given by ˜𝚯 = diag( ˜θ1, . . . , ˜θ𝐵).
Remark 1: On the one hand, compared to the TTD-RIS
architecture, the SA-RIS architecture does not require the
additional hardware cost, while the beamforming gain will
be reduced due to the RIS aperture shrinkage at the specific
subcarrier. On other hand, for the specific design of opti-
mization algorithms, the frequency-dependent phase-shifting
composed of 𝚯1, 𝚯2 and 𝚲𝑏 at the TTD-RIS architecture is
more complex, while the dimension of phase-shifting at the
SA-RIS architecture is similar to the classic RIS architecture.
D. Problem Formulation
In the downlink signal transmission at the 𝑞-th slot, the
received signal y𝑞,𝑏 ∈ C𝑈×1 of UE at subcarrier 𝑏 can be
expressed as
y𝑞,𝑏 =
√︁
𝑃𝑡

H𝑏𝚯 𝑓
𝑞,𝑏G𝑏 + D𝑏

x𝑞,𝑏 + n𝑞,𝑏,
(17)
where 𝑃𝑡 is the transmission power per stream and n𝑞,𝑏 ∼
CN (0, 𝜎2
𝑏I𝑈) denotes complex Gaussian noise. According to
different RIS architectures, 𝚯 𝑓
𝑞,𝑏 = diag(θ 𝑓
𝑞,𝑏,1, . . . , θ 𝑓
𝑞,𝑏,𝑁),
∀ 𝑓
∈ {P, T, V}, denotes the corresponding RIS reflection
coefficients at slot 𝑞, in which the indicator symbol P, T,
and V are associated with the frequency-independent RIS, the
TTD-RIS, and the SA-RIS, respectively.
In this work, we aim to maximize the spectral efficiency
of near-field wideband RIS systems by optimizing the TTD-
based hybrid beamforming at the BS and the frequency-
dependent phase-shifting at the RIS. Considering the widely
used block fading channel assumption in RIS systems [19],
the channels remain constant within each channel coherent
block that consists of 𝑄 symbol durations. The achievable
communication rate of UE at subcarrier 𝑏 within each channel
coherent block is given by
𝑅𝑏 = log2 det

I𝑈 +
𝑃𝑡
𝑁s𝛿2 Z𝑏A𝑏A𝐻
𝑏 Z𝐻
𝑏

,
(18)
where Z𝑏 = H𝑏𝚯 𝑓
𝑞G𝑏 + D𝑏 and A𝑏 = FPST𝑏FBB,𝑏.
In the existing near-field wideband beamforming schemes
in RIS systems [13], [15], the CSI is assumed to be perfectly
known when optimizing the involved beamforming variables.
In fact, for near-field wideband RIS systems, the accurate
channel acquisition is challenging due to the extremely large-
scale antenna arrays and the passive characteristic of RIS.
Considering the typical division duplex systems with the
channel reciprocity, the downlink channel can be obtained by
estimating the uplink channel. Hence, the effective spectral
efficiency can be expressed as
𝑅 =
𝑄 − 𝑄tr
𝑄(𝐿CP + 𝐵)
𝐵
∑︁
𝑏=1
𝑅𝑏,
(19)
where 𝑄tr ≤ 𝑄 denotes the number of symbol durations for the
channel training, and 𝐿CP denotes the length of cyclic prefix
in OFDM systems.
Remark 2: In the considered near-field wideband RIS
systems, 𝐵𝑀𝑈(𝑁+1) unknown entries need to be estimated in
the channel estimation, which requires the high pilot training
overhead 𝑄tr. In spite of the fact that several low-overhead
channel estimation schemes have been investigated for far-
field or narrowband RIS systems [19], e.g., the compressed
sensing approach by exploiting the channel sparsity and the
deep learning-based intelligent channel estimation scheme
[20], the aforementioned channel estimation approaches are
hard to directly extended to near-field wideband RIS systems
due to the specific near-field radiation and beam split effect.
Consequently, the optimization of effective spectral efficiency
not only depends on the beamforming design, but is also
related to the channel estimation scheme.
To sum up, the spectral efficiency maximization problem in
near-field wideband RIS systems can be formulated as follows.
max
FPS,T𝑏,FBB,𝑏,
𝚯 𝑓
𝑏,𝑄tr
𝑅

FPS, T𝑏, FBB,𝑏, 𝚯 𝑓
𝑏, 𝑄tr

(20a)
s.t.
FPST𝑏FBB,𝑏
2
𝐹 = 𝜌, ∀𝑏,
(20b)
|f𝑚RF,𝑘| = 1, ∀𝑚RF, ∀𝑘,
(20c)
|[θ 𝑓
𝑏]𝑖| = 1, 𝑖 = {1, . . . , 𝑁},
(20d)
T𝑏 ∈ T𝑏, ∀𝑏,
(20e)
where 𝜌 denotes the transmit power available of the precoder
for each subcarrier at the BS. T𝑏 is a feasible set of the
TTD-based analog beamformers imposed by the structure
in (14) and the maximum time delay constraint. Note that
the frequency-dependent phase-shifting 𝚯T
𝑏 at the TTD-RIS
architecture involves three coupled variables, i.e., 𝚯1, 𝚯2 and
𝚲𝑏, to be optimized, while the optimization of 𝚯V
𝑏 is composed
of 𝐵 independent phase-shifting subarrays for the SA-RIS
architecture.
III. DEEP LEARNING BASED END-TO-END
BEAMFORMING FRAMEWORK
To solve the non-convex and high-dimensional optimization
problem in (20), we develop an E2E beamforming optimiza-
tion framework by leveraging the powerful non-linear mapping
ability of the deep learning model. As illustrated in Fig. 3, the
overall E2E framework can be divided into the UL-CT module
in the uplink pilot transmission stage and the DL-BF module
in the downlink signal transmission.
7
Fig. 3. The proposed E2E beamforming framework in near-field wideband RIS systems.
A. Deep Learning-Based Uplink Channel Training
For the design of channel estimation scheme in RIS systems,
the channel estimation performance is related to the joint
design of the channel estimator and the RIS reflection protocol.
For instance, in [21], the DFT-based reflection protocol has
been proven to be optimal for the classic minimum vari-
ance unbiased estimator in narrowband far-field RIS systems.
However, the existing reflection protocol need to be further
developed for near-field wideband RIS systems. Firstly, the
assumption of planar wavefront in far-field communications
is no longer applicable for near-field systems, while the RIS
reflection protocol need to match the spherical wavefront
characteristics instead of the far-field assumption of planar
wavefront. Secondly, in the reflection protocol design for wide-
band RIS systems, the frequency-dependent hybrid beamform-
ing and phase-shifting involve the new time-delay dimension.
Thirdly, the key characteristic of deep learning estimator is
the adaptive learning ability for the latent representation of
the wireless signal, while the advantage of RIS is to operate
the wireless environment as a passive reflector. However,
for the deep learning-based channel estimator, the reflection
protocol design in near-field wideband RIS systems has not
been investigated.
Consequently, in the proposed E2E optimization frame-
work, we develop a learnable UL-CT module to learn high-
dimensional channel semantics, in which the trainable wide-
band phase-shifting at the RIS and the combining matrix at the
BS are designed. In contrast to the pre-defined RIS reflection
pattern in the existing channel estimation works [19], [21],
the phase-shifting and combining matrix in the proposed E2E
model can be adaptively tuned according to dynamic wireless
environments. Suppose 𝑄tr OFDM pilots are used for the
channel training, the received pilot signal Y𝑞,𝑏 ∈ C𝑀RF×1 at
slot 𝑞(1 ≤ 𝑞 ≤ 𝑄tr) in subcarrier 𝑏 of the BS is given by
Y𝑞,𝑏 = W𝑞,𝑏

H𝑏𝚯 𝑓
𝑏G𝑞,𝑏 + D𝑏

Xtr
𝑞,𝑏 + ntr
𝑞,𝑏,
(21)
where Xtr
𝑞,𝑏 ∈ C𝑈×1 denotes the pilot signal sent by the UE at
slot 𝑞 in subcarrier 𝑏, W𝑞,𝑏 ∈ C𝑀RF×𝑀 denotes the uplink
combining matrix in subcarrier 𝑏 at the BS, and complex
Gaussian noise follows ntr
𝑞,𝑏 ∼ CN (0, 𝜎2
𝑏I𝑀RF). In this work,
the phase-shifting 𝚯 𝑓
𝑞,𝑏, ∀ 𝑓 ∈ {P, T, V} and the combining
matrix W𝑞,𝑏 are designed the trainable tensors, which are
optimized by utilizing the massive training data.
In near-field wideband RIS systems, 𝚯 𝑓
𝑞,𝑏 and W𝑞,𝑏 need
to be restricted by the specific constraint. Specifically, for the
TTD-RIS architecture as illustrated in (16), the frequency-
dependent phase-shifting 𝚯T
𝑞 at slot 𝑞 consists of the learnable
phase-shifting tensor b𝚯𝑞,1 ∈ C𝑁 ×𝑁, b𝚯𝑞,2 ∈ C𝑁 ×𝑁, and time
delay tensor b𝚲𝑞 ∈ C𝑆×𝐵. The diagonal elements in b𝚯𝑞,1 and
b𝚯𝑞,2 should satisfy the unit modular constraint. Thus, the
complex exponent function exp(j·) is applied to obtain the
desired uplink b𝚯
up
𝑞,1 and b𝚯
up
𝑞,2, which is given by


b𝚯
up
𝑞,1 = exp

j · b𝚯𝑞,1

,
b𝚯
up
𝑞,2 = exp

j · b𝚯𝑞,2

, ∀𝑞.
(22)
Due to the maximum time-delay constraint in the TTD
unit, each learnable time delay element b𝜈𝑠,𝑏 in b𝚲𝑞 need to
be normalized by the maximum delay 𝑡max, which is given by
b𝜈up
𝑠,𝑏 = 𝑡max
1
1 + 𝑒−b𝜈𝑠,𝑏 , ∀𝑠, 𝑏.
(23)
In the SA-RIS without TTD units, the uplink phase-shifting
b𝚯
up,V
𝑞
is directly normalized by utilizing the complex exponent
function. For the learnable uplink combining tensor at the BS,
the uplink Wup
𝑞,𝑏 should satisfy the constant modular constraint,
which is given by [22]
Wup
𝑞,𝑏 =
1
√
𝑀
exp 8
implicit CSI learning network. In Section VI-A, the detailed
network architecture of the proposed UL-CT module F C(·)
will be elaborated.
B. Deep Learning-Based Downlink Wideband Beamforming
The proposed DL-BF module F B(·) is composed of a
low-level shared network F B
sh (·) and 𝑃 sub-networks F B
𝑝 (·),
1 ≤ 𝑝 ≤ 𝑃. In the pipeline of information flow, the extracted
CSI semantic 𝛀 in the UL-CT module is delivered to the
shared network at first, which generates the shared features
𝚽 = F B
sh (𝜔B
sh, 𝛀) ∈ C𝑀×𝐵. Then, the downlink frequency-
dependent phase-shifting at the RIS and the hybrid beam-
forming at the BS is obtained from different sub-networks,
respectively, which is given by


b𝚯
down, 𝑓 = exp 9
polarized self-attention (PSA) mechanism to characterize the
implicit CSI semantics, which leverages the specific physical
knowledge of wireless communications data.
In contrast to the dataset in computer vision or nature
language models, each dimension of input tensor ¯Y𝑃 in the
proposed UL-CT module has the specific physical implica-
tions, which represents time, frequency, and antenna domains,
respectively. In the vanilla self-attention mechanism, the atten-
tion operation is only carried out in the spatial domain of input
tensor, i.e., the dimension 2𝑀RF ×𝑄tr in ¯Y𝑃. In this work, the
self-attention mechanism is introduced into the frequency and
time-spatial domain of ¯Y𝑃 by designing the dedicated PSA
module [25], respectively. In Fig. 4, we present the detailed
operation of the PSA module, which consists of the feature
extraction branches in the frequency and time-spatial domain.
Specifically, in the frequency feature extraction branch, the
output features XF ∈ R𝐵×1×1 can be expressed as
XF = Sig

W𝑧(Re(W𝑣( ¯Y𝑃)) × Soft(Re(W𝑞( ¯Y𝑃)))

,
(31)
where W𝑖, 𝑖 = {𝑞, 𝑣, 𝑧} denotes 1 × 1 convolution layer to
reduce or increase the frequency-domain dimension of ¯Y𝑃,
and Re(·) represents the tensor reshape operator to adjust
the dimension of different feature tensors. Functions Soft(·)
and Sig(·) denote Softmax and Sigmoid activation function,
respectively, which can be expressed as
Soft(x) =
𝑒x𝑖
Í𝐿
𝑖=1 𝑒x𝑖 ,
(32)
Sig(x) =
1
1 + 𝑒−x𝑖 ,
(33)
where x ∈ R𝐿×1 denotes a feature tensor.
Similarly, the output features in the time-spatial feature
extraction branch XT ∈ R1×2𝑀RF×𝑄tr can be expressed as
XF = Sig

Re(W𝑣( ¯Y𝑃)) × Soft(G(W𝑞( ¯Y𝑃))

,
(34)
where G(·) denotes the global average pooling operator. For
the feature tensor FT = W𝑞( ¯Y𝑃) ∈ R𝐵/2×2𝑀RF×𝑄tr obtained by
a convolutional layer with the 1 × 1 kernel, the feature vector
z =

𝑧1, · · · , 𝑧𝑏, · · · , 𝑧𝐵/2

∈ R𝐵/2×1 after pooling operation
G(FT) is given by
𝑧𝑏 = G(FT) =
1
2𝑀RF × 𝑄tr
2𝑀RF
∑︁
𝑚=1
𝑄tr
∑︁
𝑞=1
FT
𝑏(𝑚, 𝑞).
(35)
Finally, the frequency and time-spatial features are fused in
the UL-CT module, which can be expressed as
𝛀 = XF ⊙F ¯YP + XT ⊙T ¯YP,
(36)
where ⊙𝑖, 𝑖 ∈ {F, T} denotes a channel-wise or spatial-wise
multiplication operator, respectively. Note that compared to the
classic self-attention mechanism, the PSA module has lower
computational complexity due to the separable dual branch
attention architecture.
B. Signal-Guided Network for Beamforming Design
The DL-BF network consists of the low-level shared net-
work to extract the shared embedded features and multiple in-
Fig. 5. Signal-guided shared network architecture for beamforming design in
the DL-BF module.
dependent sub-networks to jointly design near-field wideband
beamforming.
1) Signal-Guided Shared Network Architecture:
In the
large-scale array communications at high frequencies, wireless
channels present the natural sparsity due to limited scatterer
paths. Considering the severe energy spreading effect, the
sparsity representation in the far-field channel, such as the DFT
transform-based angular domain sparsity [26], may no longer
be applicable to the near-field channel. However, as a classic
digital signal processing tool, the DFT principle is still useful
for guiding the network architecture design [27], especially
for the dedicated network in wireless communications. In the
proposed DL-BF module, we incorporate Fourier transform
to the conventional self-attention mechanism and employ
learnable filters to interchange information globally among the
feature tokens in the Fourier domain, which is termed as a
signal-guided deep learning approach.
As shown in Fig. 5, for the feature 𝛀 obtained by the UL-
CT module in Fig. 4, the two-dimensional DFT is carried out
at first, which can be expressed as
FDFT
𝑏
[𝑢, 𝑣] = F (𝛀𝑏) =
2𝑀RF−1
∑︁
𝑚=0
𝑄tr−1
∑︁
𝑞=0
𝛀𝑏[𝑚, 𝑞]𝑒− 𝑗2𝜋

𝑢𝑚
2𝑀RF + 𝑣𝑞
𝑄tr

.
(37)
Since the DFT of real input tensor 𝛀𝑏[𝑚, 𝑞] satisfies
the conjugate symmetry property, i.e., FDFT
𝑏
[2𝑀RF − 𝑢, 𝑄tr −
𝑣] = 10
the feature FM into the high-dimension representation space.
The second linear layer W2 ∈ R𝜐𝐵×𝐵 is used to recover the
desired channel dimension again. Function GeLU(·) denotes
the Gaussian error linear unit activation function to provide the
non-linearity of feature transformation. Finally, Af is converted
into a 𝐵 × 𝑁 feature tensor 𝛀 by a linear layer, which is used
as the input tensor for subsequent beamforming sub-networks.
2) High-Level Sub-Network Architecture: Considering the
network complexity and the convenience of tensor operation
in different sub-networks, the stacked linear layers are used as
the basic component of sub-network architecture [28]. For the
frequency-dependent phase-shifting at the TTD-RIS architec-
ture, three parallel linear layers are used to construct the output
𝚯down
1
, 𝚯down
2
and 𝚲down
𝑏
, and are normalized according to (22)
and (23), respectively. Then, the frequency-dependent phase-
shifting 𝚯T
𝑏 is obtained by aggregating 𝚯down
1
, 𝚯down
2
and ¯Tdown
𝑏
in (16). In the SA-RIS architecture, we utilize a linear layer
with 𝑁 neurons to obtain 𝚯V, in which 𝑁 neurons are divided
into 𝐵 groups and each group consists of 𝑁/𝐵 neurons to map
the phase-shifting of a RIS subarray. Similarly, the frequency-
dependent hybrid precoding matrices at the BS composed of
the analog beamformer Fdown
PS
, the time-delay vector Tdown
𝑏
and
the digital beamformer Fdown
BB,𝑏, are obtained by constructing
three sub-networks with the specific constraints in (26).
V. NUMERICAL RESULTS
In this section, we first introduce the simulation setups
of the formulated near-field wideband systems and training
hyper-parameters of the proposed models. Then, we compare
the spectral efficiency of the proposed E2E models with the
existing benchmarks, and further evaluate the beamforming
performance under various system setups.
A. Simulation Setups
In the simulation, we set 𝑀
= 128, 𝑁
= 16 × 32,
𝑈 = 𝑀RF = 𝑁s = 4, 𝐵 = 16 and 𝐿CP = 4. The carrier
frequency is set to 𝑓𝑐 = 73 GHz and the communication
bandwidth is 𝑊 = 7 GHz in OFDM systems. The coordinates
of BS and RIS are set to cB = 11
-10
-5
0
5
10
15
20
25
30
SNRT [dB]
0
5
10
15
20
25
30
Ideal spectral efficiency [bits/s/Hz]
Fully-digtal BS
& ideal RIS
Conventional 
benchmarks
Fig. 7. Spectral efficiency versus downlink SNRT for different beamforming
schemes, in which the perfect CSI is assumed to be known.
models for the proposed TTD-RIS and SA-RIS architectures,
in which the average loss of validation dataset in each training
epoch is computed according to (27). Compared to the E2E
model with SA-RIS architecture, the optimization of 𝚯 𝑓
𝑏 in
the TTD-RIS architecture is more complex, which increases
the network scale of the DL-BF module in the E2E model.
Due to the simplified network components, the convergence
speed of the SA-RIS architecture is faster than the TTD-RIS
architecture. However, with the increase of training epochs,
the superior convergence performance can be obtained for the
E2E model with TTD-RIS architecture.
In Fig. 7, we present the spectral efficiency of the proposed
E2E models and the ideal beamforming benchmarks with the
perfect CSI. Note that for the proposed E2E models, i.e., the
proposed TTD-RIS and SA-RIS in Fig. 7, the UL-CT module
is exploited to learn the implicit CSI instead of the prior
assumption of the perfect CSI. For the existing beamforming
benchmarks, the near-field double beam split will degrade the
efficient beamforming gain. Specifically, the AMOP method
adopt the conventional hybrid beamformer architecture, which
cannot design the frequency-dependent analog beamformer at
the BS and the phase-shifting at the RIS. In ADPP method,
the BS is equipped with 𝑀RF𝐾 TTD units to construct the
frequency-dependent hybrid-beamforming at the BS, while the
PGDP method adopt the fully digital precoding architecture at
BS to avoid the wideband beam split at the BS. However,
the wideband beam split at the RIS cannot be addressed
pertinently for the ADPP and PGDP methods. Under the
perfect CSI assumption, the ideal PGDP methods can obtain
the performance upper bound, while the ideal RIS architecture
cannot be implemented in practical communication systems. In
the proposed E2E models, by exploiting frequency-dependent
RIS architectures, i.e., the TTD-RIS and the SA-RIS, and
developing deep learning-based beamforming networks, the
beamforming gain of the proposed E2E models is superior
to the conventional beamforming benchmarks. In the SA-RIS
architecture, the effective array aperture will be shrunk due to
the virtual subarray division strategy, and hence the frequency-
dependent beamforming gain will be reduced compared to the
TTD-RIS architecture.
-10
-5
0
5
10
15
20
25
30
SNRT [dB]
0
5
10
15
20
25
30
Effective spectral efficiency [bits/s/Hz]
0
5
10
5
10
15
Fig. 8. Spectral efficiency versus downlink SNRT for different beamforming
schemes, in which the uplink SNR is set to SNRR = 10 dB.
-10
-5
0
5
10
15
20
25
30
SNRR [dB]
0
5
10
15
20
25
Effective spectral efficiency [bits/s/Hz]
Fig. 9.
Spectral efficiency versus uplink SNRR for different beamforming
schemes, in which the downlink SNR is set to SNRT = 20 dB.
In Fig. 8, we further compare the effective spectral ef-
ficiency of the proposed E2E models with the practical
beamforming benchmarks with the estimated CSI. Since the
channel estimation error and the large pilot overhead, the
effective spectral efficiency will be significantly decreased for
the conventional beamforming schemes. In the proposed E2E
models with less pilot overhead, the available effective spectral
efficiencies of both TTD-RIS and SA-RIS architectures are
superior to the existing beamforming benchmarks.
In Fig. 9, we compare the spectral efficiency of the proposed
E2E models with the existing beamforming benchmarks under
different uplink SNRR. With the increase of SNRR, the beam-
forming gain of all algorithms can be improved due to more
accurate CSI, while the proposed E2E models are superior to
the conventional beamforming benchmarks. Since the specific
latent representation can be learned from the massive com-
munication data, the proposed E2E models is robust for some
disturbances of input data, i.e., the communication noise.
In Fig. 10, we compare the spectral efficiency of the pro-
posed E2E models with the existing beamforming benchmarks
under different communication bandwidths 𝑊. For the ideal
PGDP algorithm, the BS precoding and RIS phase-shifting can
be independently designed according to the specific subcarrier
12
1
2
3
4
5
6
7
8
9
Bandwidth [Hz]
109
6
8
10
12
14
16
18
20
22
24
Effective spectral efficiency [bits/s/Hz]
Fully-digtal BS
& ideal RIS
Fig. 10. Spectral efficiency versus bandwidth 𝑊 for different beamforming
schemes.
-10
-5
0
5
10
15
20
25
30
SNRT [dB]
5
10
15
20
25
Effective spectral efficiency [bits/s/Hz]
Low cost & energy
High cost & energy
Fig. 11. Spectral efficiency versus downlink SNRT for different RIS setups.
channel, and hence the beamforming gain is independent of
bandwidth 𝑊. However, for conventional hybrid beamforming
architectures, the wideband beam split effect will be aggra-
vated with the increase of 𝑊, which results in the beam-
forming performance degradation. Compared to the existing
beamforming benchmarks, the proposed TTD-RIS and SA-
RIS architectures have superior generalization for the large
communication bandwidth.
C. Comparison for Different RIS Setups
In Fig. 11 and Fig. 12, we present the spectral efficiency of
the proposed E2E models under different RIS setups versus
downlink and uplink SNR, respectively. With the increase
of the number of TTD units 𝐾 at the BS, the beamforming
performance of both TTD-RIS and SA-RIS architectures has
been enhanced. For the TTD-RIS architecture, the spectral
efficiency can be further upgraded by increasing the number of
TTD units 𝑆 at the RIS, while the number of virtual subarrays
at the SA-RIS architecture is fixed as the number of subcarriers
𝐵. Note that the introduction of TTD units and double-layer
phase-shifting circuits in the TTD-RIS architecture require the
additional energy consumption and hardware cost.
In Fig. 13, we investigate the influence of the uplink SNR
setting in the training stage for the proposed E2E models with
-10
-5
0
5
10
15
20
25
30
SNRR [dB]
10
12
14
16
18
20
22
Effective spectral efficiency [bits/s/Hz]
Low cost & energy
High cost & energy
Fig. 12. Spectral efficiency versus uplink SNRR for different RIS setups.
-10
-5
0
5
10
15
20
25
30
SNRT [dB]
12
13
14
15
16
17
18
19
Effective spectral efficiency [bits/s/Hz]
Fig. 13.
Spectral efficiency of the proposed TTD-RIS architecture versus
downlink SNRT for different training SNR setups.
the TTD-RIS architecture, in which the number of units at the
BS and the RIS are set to 𝐾 = 8 and 𝑆 = 32, respectively.
By utilizing a dynamic training SNR setup, i.e., training
SNRR ∈ [0, . . . , 20] dB in the UL-CT module, the stable
beamforming performance can be obtained in the test stage,
which is more robust against the communication noise than the
model trained by the fixed training SNR. For the trained model
by using the fixed SNR setting, the model has satisfactory
performance for the given SNR in the test stage, while the
trained model lacks the robustness for the dynamic SNR range.
Specifically, for the trained model with training SNRR = 20
dB, the performance degradation of the model will be severe
with the SNR decrease in the test stage. On the contrary, for the
trained model with training SNRR = 0 dB, the beamforming
performance is worse under the high SNR case, in which the
serve noise component in the training data is not conducive to
learn effective features for the E2E model. In the proposed
training strategy, the training sample space is enriched by
introducing different levels of noise components. In essence,
this training strategy resembles the data augmentation method
in the traditional deep learning field, which can be extended
to various deep learning-empowered communication scenarios,
such as mmWave MIMO channel estimation [33], [34].
13
VI. CONCLUSIONS
In this paper, a deep learning enabled near-field wideband
beamforming scheme in RIS-aided MIMO systems was pro-
posed, aiming for alleviating the beamforming performance
loss caused by the near-field double beam split effect. Firstly,
two specific RIS architectures, i.e., TTD-RIS and SA-RIS,
were exploited to achieve the frequency-dependent passive
beamforming. Compared to the SA-RIS architecture, the TTD-
RIS architecture can obtain superior beamforming perfor-
mance, while requiring more energy consumption and hard-
ware cost due to the introduction of TTD units. Furthermore,
the E2E beamforming optimization framework was proposed
to jointly design the high-dimensional channel estimation and
the frequency-dependent wideband beamforming. Moreover,
to accelerate the convergence of the proposed E2E model, the
advanced deep learning architectures and the classical commu-
nication signal processing theory were integrated to develop
an efficient beamforming network backbone. Numerical results
showed the proposed E2E models without the explicit CSI
had superior beamforming performance and robustness to the
existing wideband beamforming benchmarks.
REFERENCES
[1] M. Di Renzo, A. Zappone, M. Debbah, M.-S. Alouini, C. Yuen,
J. de Rosny, and S. Tretyakov, “Smart radio environments empowered
by reconfigurable intelligent surfaces: How it works, state of research,
and the road ahead,” IEEE J. Sel. Areas Commun., vol. 38, no. 11, pp.
2450–2525, Nov. 2020.
[2] M. Cui, Z. Wu, Y. Lu, X. Wei, and L. Dai, “Near-field MIMO
communications for 6G: Fundamentals, challenges, potentials, and future
directions,” IEEE Commun. Mag., vol. 61, no. 1, pp. 40–46, Jan. 2023.
[3] X. Mu, J. Xu, Y. Liu, and L. Hanzo, “Reconfigurable intelligent surface-
aided near-field communications for 6G: Opportunities and challenges,”
IEEE Veh. Technol. Mag., Jan. 2024.
[4] Y. Liu, Z. Wang, J. Xu, C. Ouyang, X. Mu, and R. Schober, “Near-
field communications: A tutorial review,” IEEE Open J. Commun. Soc.,
vol. 4, pp. 1999–2049, Aug. 2023.
[5] Z. Wang, X. Mu, and Y. Liu, “Near-field integrated sensing and
communications,” IEEE Commun. Lett., vol. 27, no. 8, pp. 2048–2052,
Aug. 2023.
[6] L. Dai, J. Tan, Z. Chen, and H. V. Poor, “Delay-phase precoding
for wideband THz massive MIMO,” IEEE Trans. Wireless Commun.,
vol. 21, no. 9, pp. 7271–7286, Sep. 2022.
[7] R. Su, L. Dai, and D. W. Ng, “Wideband precoding for RIS-aided THz
communications,” IEEE Trans. Commun., vol. 71, no. 6, pp. 3592–3604,
Jun. 2023.
[8] W. Yan, W. Hao, C. Huang, G. Sun, O. Muta, H. Gacanin, and C. Yuen,
“Beamforming analysis and design for wideband THz reconfigurable
intelligent surface communications,” IEEE J. Sel. Areas Commun.,
vol. 41, no. 8, pp. 2306–2320, Aug. 2023.
[9] W. Hao, F. Zhou, M. Zeng, O. A. Dobre, and N. Al-Dhahir, “Ultra
wideband THz IRS communications: Applications, challenges, key
techniques, and research opportunities,” IEEE Network, vol. 36, no. 6,
pp. 214–220, Dec. 2022.
[10] H. Sun, S. Zhang, J. Ma, and O. A. Dobre, “Time-delay unit based beam
squint mitigation for RIS-aided communications,” IEEE Commun. Lett.,
vol. 26, no. 9, pp. 2220–2224, Sep. 2022.
[11] X. Mu, Y. Liu, L. Guo, J. Lin, and R. Schober, “Simultaneously
transmitting and reflecting (STAR) RIS aided wireless communications,”
IEEE Trans. Wireless Commun., vol. 21, no. 5, pp. 3083–3098, May
2022.
[12] Z. Wang, X. Mu, J. Xu, and Y. Liu, “Simultaneously transmitting and
reflecting surface (STARS) for Terahertz communications,” IEEE J. Sel.
Top. Signal Process., vol. 17, no. 4, pp. 861–877, Jul. 2023.
[13] W. Hao, X. You, F. Zhou, Z. Chu, G. Sun, and P. Xiao, “The far-/near-
field beam squint and solutions for THz intelligent reflecting surface
communications,” IEEE Trans. Veh. Technol., vol. 72, no. 8, pp. 10 107–
10 118, Aug. 2023.
[14] J. An, C. Xu, D. W. K. Ng, C. Yuen, L. Gan, and L. Hanzo, “Recon-
figurable intelligent surface-enhanced OFDM communications via delay
adjustable metasurface,” arXiv preprint arXiv:2110.09291, 2021.
[15] Y. Cheng, C. Huang, W. Peng, M. Debbah, L. Hanzo, and C. Yuen,
“Achievable rate optimization of the RIS-aided near-field wideband
uplink,” IEEE Trans. Wireless Commun., 2023.
[16] J. D. Kraus and R. J. Marhefka, “Antennas for all applications,” Antennas
for all applications, 2002.
[17] E. Basar, I. Yildirim, and F. Kilinc, “Indoor and outdoor physical channel
modeling and efficient positioning for reconfigurable intelligent surfaces
in mmWave bands,” IEEE Trans. Wireless Commun., vol. 69, no. 12,
pp. 8600–8611, Dec. 2021.
[18] S. Tarboush, H. Sarieddeen, H. Chen, M. H. Loukil, H. Jemaa, M.-S.
Alouini, and T. Y. Al-Naffouri, “TeraMIMO: A channel simulator for
wideband ultra-massive MIMO Terahertz communications,” IEEE Trans.
Veh. Technol., vol. 70, no. 12, pp. 12 325–12 341, Dec. 2021.
[19] B. Zheng, C. You, W. Mei, and R. Zhang, “A survey on channel estima-
tion and practical passive beamforming design for intelligent reflecting
surface aided wireless communications,” IEEE Commun. Surveys Tuts.,
vol. 24, no. 2, pp. 1035–1071, Secondquarter 2022.
[20] J. Xiao, J. Wang, Z. Wang, W. Xie, and Y. Liu, “Multi-scale attention
based channel estimation for RIS-aided massive MIMO systems,” IEEE
Trans. Wireless Commun., pp. 1–1, 2023.
[21] T. L. Jensen and E. De Carvalho, “An optimal channel estimation scheme
for intelligent reflecting surfaces based on a minimum variance unbiased
estimator,” in ICASSP 2020 - 2020 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), May 2020, pp.
5000–5004.
[22] M. Wu, Z. Gao, Y. Huang, Z. Xiao, D. W. K. Ng, and Z. Zhang,
“Deep learning-based rate-splitting multiple access for reconfigurable
intelligent surface-aided Terahertz massive MIMO,” IEEE J. Sel. Areas
Commun., vol. 41, no. 5, pp. 1431–1451, May 2023.
[23] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
[24] Z. Liu, L. Zhang, and Z. Ding, “Overcoming the channel estimation
barrier in massive MIMO communication via deep learning,” IEEE
Wireless Commun., vol. 27, no. 5, pp. 104–111, Oct. 2020.
[25] H. Liu, F. Liu, X. Fan, and D. Huang, “Polarized self-attention: Towards
high-quality pixel-wise regression,” arXiv preprint arXiv:2107.00782,
2021.
[26] Z. Gao, M. Wu, C. Hu, F. Gao, G. Wen, D. Zheng, and J. Zhang,
“Data-driven deep learning based hybrid beamforming for aerial massive
MIMO-OFDM systems with implicit CSI,” IEEE J. Sel. Areas Commun.,
vol. 40, no. 10, pp. 2894–2913, Oct. 2022.
[27] Y. Rao, W. Zhao, Z. Zhu, J. Lu, and J. Zhou, “Global filter networks
for image classification,” Advances in Neural Information Processing
Systems, vol. 34, 2021.
[28] I. O. Tolstikhin, N. Houlsby, A. Kolesnikov, L. Beyer, X. Zhai,
T. Unterthiner, J. Yung, A. Steiner, D. Keysers, J. Uszkoreit et al.,
“MLP-Mixer: An all-MLP architecture for vision,” Advances in neural
information processing systems, vol. 34, pp. 24 261–24 272, 2021.
[29] N. S. Perovi´c, L.-N. Tran, M. Di Renzo, and M. F. Flanagan, “Achievable
rate optimization for MIMO systems with reconfigurable intelligent
surfaces,” IEEE Trans. Wireless Commun., vol. 20, no. 6, pp. 3865–
3882, Jun. 2021.
[30] H. Wang, J. Fang, and H. Li, “Joint beamforming and channel re-
configuration for RIS-assisted millimeter wave massive MIMO-OFDM
systems,” IEEE Trans. Veh. Technol., vol. 72, no. 6, pp. 7627–7638, Jun.
2023.
[31] G. T. de Araújo, A. L. F. de Almeida, and R. Boyer, “Channel estimation
for intelligent reflecting surface assisted MIMO systems: A tensor
modeling approach,” IEEE J. Sel. Top. Signal Process., vol. 15, no. 3,
pp. 789–802, Apr. 2021.
[32] L. Wei, C. Huang, G. C. Alexandropoulos, C. Yuen, Z. Zhang, and
M. Debbah, “Channel estimation for RIS-empowered multi-user MISO
wireless communications,” IEEE Trans. Commun., vol. 69, no. 6, pp.
4144–4157, Jun. 2021.
[33] J. Xiao, J. Wang, Z. Chen, and G. Huang, “U-MLP-based hybrid-
field channel estimation for XL-RIS assisted millimeter-wave MIMO
systems,” IEEE Wireless Commun. Lett., vol. 12, no. 6, pp. 1042–1046,
Jun. 2023.
[34] X. Wei, C. Hu, and L. Dai, “Deep learning for beamspace channel
estimation in millimeter-wave massive MIMO systems,” IEEE Trans.
Commun., vol. 69, no. 1, pp. 182–193, Jan. 2021.
","Prior works on wideband RIS communications mainly focus on the distributed RIS deployment and true time delay (TTD) module to achieve beam split alleviation. However, these works assume known array manifold or line-of-sight (LOS)-dominant channel, and only focus on the RIS phase-shifting design without considering the BS hybrid beamforming optimization. To address these limitations, the authors propose a comprehensive near-field wideband beamforming framework with the consideration of implicit channel state information (CSI) acquisition.nan"
"Few-shot object detection(FSOD) aims to adapt object detectors with only a few labeled instances. Fine-tuning is a simple and effective approach to adapt detectors in FSOD. However, previous fine-tuning methods ignore the stability-plasticity contradiction between different modules in the detector, which limits the generalization capability. In this paper, we propose a novel three-stage fine-tuning procedure to alleviate the contradiction. We also introduce a multi-source ensemble technique to regularize the detector in the final fine-tuning stage. Extensive experiments verify the effectiveness of our method in improving the FSOD performance.","Object detection is a fundamental task in computer vision with wide applications. Many methods have been proposed to improve the detection accuracy, but most of them heavily rely on a large amount of labeled data. Few-shot object detection (FSOD) aims to adapt object detectors with only a few labeled instances. Fine-tuning is a simple and effective approach, but previous methods often take the two-stage transfer procedure and ignore the stability-plasticity contradiction.","Some end-to-end detectors are proposed and perform competitively recently. Among them, the design of Sparse R-CNN has the advantages of efficient training convergence and high interpretability. It takes an relatively explicit object encoding correlation method by interacting with backbone feature maps through ROI pooling. These attract us to explore the FSOD performance of it. In this paper, we find the stability-plasticity contradiction between these linear classifiers and other modules in FSOD, inspired by stability-plasticity dilemma in continual learning works. The FSOD performance of Sparse R-CNN suffer much from this contradiction due to its multi-classifier architecture. We propose to split the classical two-stage transfer procedure into a new three-stage one. Speicifically, following the base stage, an exclusive stage which focuses on fine-tuning classifiers in Sparse R-CNN sufficiently is introduced. In this stage, we freeze all modules except these re-initialized classifiers of these cascaded heads. And we set a sufficient long schedule to initialize and adapt these classifiers with novel samples. This meets the demand of plasticity of classifiers without concerning the risk of over-fitting. Then in the following novel fine-tuning stage, we propose an ensemble aggregation method to reserve the generalization stability of the detector. We regularise the detector by aggregating prediction results predicted by models with weights which are trained in diverse configurations.","In this paper, we propose a novel stability-plasticity decoupled fine-tuning framework for Sparse R-CNN in FSOD setting. In the first stage, we freeze the other modules and offer sufficient plasticity to the re-initialized classifiers to alleviate over-fitting to the novel samples. In the second stage, we decouple the optimization of the whole detector by freezing the backbone. Moreover, we introduces a multi-source ensemble regularization technique to boost the generalization capability. Extensive experiments verify the effectiveness of our method in improving the FSOD performance.","In this paper, we analyze the stability-plasticity contradiction between linear classifiers and other modules in Sparse R-CNN during Fine-tuning in the FSOD scenario. We propose a new three-stage transfer procedure by introducing an additional classifier plasticity fine-tuning stage for Spase R-CNN. Moreover, we design a an ensemble technique to further regularise the detector. The implicit stability plasticity contradiction is mitigated with our method. Experiments verify the effectiveness of the proposed method.",Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection,"Yuantao Yin, Ping Yin","STABILITY PLASTICITY DECOUPLED FINE-TUNING FOR FEW-SHOT END-TO-END
OBJECT DETECTION
Yuantao Yin, Ping Yin*
Inspur
generalvision@foxmail.com, generalvisionyyt@gmail.com
ABSTRACT
Few-shot object detection(FSOD) aims to design methods
to adapt object detectors efficiently with only few annotated
samples.
Fine-tuning has been shown to be an effective
and practical approach. However, previous works often take
the classical base-novel two stage fine-tuning procedure but
ignore the implicit stability-plasticity contradiction among
different modules.
Specifically, the random re-initialized
classifiers need more plasticity to adapt to novel samples. The
other modules inheriting pre-trained weights demand more
stability to reserve their class-agnostic knowledge. Regular
fine-tuning which couples the optimization of these two parts
hurts the model generalization in FSOD scenarios. In this pa-
per, we find that this problem is prominent in the end-to-end
object detector Sparse R-CNN for its multi-classifier cas-
caded architecture. We propose to mitigate this contradiction
by a new three-stage fine-tuning procedure by introducing
an addtional plasticity classifier fine-tuning(PCF) stage. We
further design the multi-source ensemble(ME) technique to
enhance the generalization of the model in the final fine-
tuning stage. Extensive experiments verify that our method
is effective in regularizing Sparse R-CNN, outperforming
previous methods in the FSOD benchmark.
Index Terms— Object Detection, Few-Shot Learning,
Fine-tuning, Stability-Plasticity, Few-Shot Object Detection
1. INTRODUCTION
As a fundamental task in computer vision, object detection
is applied in various scenarios.
Existing object detection
methods[1, 2] rely on sufficient annotated samples to perform
well, which may not be available in practical applications.
They still suffer from poor generalization or over-fitting when
only few annotated examples are offered.
Few-shot object detection(FSOD) is proposed to focus on
how to efficiently adapt to novel downstream tasks with lim-
ited instances. Prior work TFA[3] propose that fine-tuning is
a simple yet effective but ignored approach to adapt detectors
if freezing protection is conducted to prevent over-fitting. In
* means the corresponding author.
Fine-tuning coupling gradient flow and schedule
Stability Demand: Regularized Adaptation
Cascaded Detector Heads
Plasticity Demand: Sufficient Initialization and Adaptation
Re-Initialized
Classifiers
Parameters
Backbone
Pre-trained
Inherited
Parameters
Fine-tuning
Fine-tuning
Localization 
Classification
Gradient
Flow
Fig. 1: Stability-Plasticity contradiction in Sparse R-CNN[1].
During fine-tuning in regular two-stage procedure,
re-
initialized classifiers and other modules actually have con-
tradictory stability-plasticity demand. However, fine-tuning
coupling them together can only achieve sub-optimal FSOD
performance for Sparse R-CNN.
TFA, a two-stage transfer procedure is proposed and is pop-
ularly used by many FSOD methods. In the first stage, suf-
ficient annotated instances which belong to base classes are
available for pre-training the detector. In the following stage,
only few fixed number of annotated instances of each novel
class are available for adapting the detector. Base classes and
novel classes have no intersection.
Many methods use this two-stage transfer procedure and
take Faster R-CNN[2] as their detector whose architecture is
effective and interpretable. They find and tackle many prob-
lems during fine-tuning from various views. MPSR[4] tackles
the scale variation problem. FSCE[5] updates the freezing
strategy and propose a contrastive loss to alleviate confu-
sion. FADI[6] presents an association and discrimination loss
based on the semantic similarity. However, the limitations
of this two-stage transfer procedure is still less discussed.
And there is no work explore the fine-tuning efficiency from
arXiv:2401.11140v1  [cs.CV]  20 Jan 2024
the perspective of implicit plasticity-stability contradiction
among different modules.
Some end-to-end detectors[7, 1] are proposed and per-
form competitively recently. Among them, typically, the de-
sign of Sparse R-CNN[1] has the advantages of efficient train-
ing convergence and high interpretability. It takes an rela-
tively explicit object encoding correlation method by inter-
acting with backbone feature maps through ROI pooling[2].
These attract us to explore the FSOD performance of it. Simi-
lar with DETR[7], the architecture of Sparse R-CNN consists
of a stack of cascaded detector heads which refine the results
progressively. Each head has a pair of linear classifier and re-
gressor to predict the category and localization of instances.
Thus the parameter number of these multiple linear classifiers
are much more than Faster R-CNN which has only single lin-
ear classifier, considering the number of cascade stages is of-
ten 6 in Sparse R-CNN.
In this paper, we find the stability-plasticity contradiction
between these linear classifiers and other modules in FSOD,
inspired by stability-plasticity dilemma in continual learning
works[8]. The FSOD performance of Sparse R-CNN suffer
much from this contradiction due to its multi-classifier archi-
tecture. As shown in Fig.1, when we fine-tune Sparse R-CNN
with the two-stage procedure, after the first base stage, we
have to re-initialize the weights of all these linear classifiers
to random values due to the change of class number. Thus
these classifiers demand more plasticity to initialize first and
then adapt to novel tasks during optimization. This demand
is greater when multiple classifiers exist. In contrast, other
modules just optimize to adapt the pre-trained weights with
novel samples. Considering the much larger number of pa-
rameters, they require more stability to avoid the risk of over-
fitting. However, these two parts of modules with inconsistent
stability-plasticity demand are unreasonably coupled during
optimization in the novel fine-tuning stage of the popularly
used transfer procedure by previous works. This compromis-
ing optimization often converges to the model weights whose
output features are distorted[9]. Among them, classifiers tend
to be under-fitted while others tend to be over-fitted simul-
taneously. Thus this coupling scheme hurts the generaliza-
tion of the detector in FSOD. And this problem is especially
prominent in Sparse R-CNN for its much larger number of
parameters in classifiers.
To address the above issues, we propose to split the clas-
sical two-stage transfer procedure into a new three-stage one.
Speicifically, following the base stage, an exclusive stage
which focuses on fine-tuning classifiers in Sparse R-CNN
sufficiently is introduced. In this stage, we freeze all mod-
ules except these re-initialized classifiers of these cascaded
heads.
And we set a sufficient long schedule to initialize
and adapt these classifiers with novel samples. This meets
the demand of plasticity of classifiers without concerning the
risk of over-fitting. Then in the following novel fine-tuning
stage, we propose an ensemble aggregation method to reserve
the generalization stability of the detector. We regularise the
detector by aggregating prediction results predicted by mod-
els with weights which are trained in diverse configurations.
Extensive experiments are conducted to verify the validity
of these measures to boost FSOD performance of Sparse
R-CNN against its baseline.
2. RELATED WORKS
2.1. Few-Shot Object Detection
There are two branches in the FSOD research field.
One
is the meta-learning branch. The typical methods includes
FSRW[10], Meta-RCNN[11], FsDetView[12], Meta-DETR[13].
The other is the fine-tuning transfering branch. The typical
works are TFA[3], DeFRCN[14], FADI[6]. DeFRCN[14] dis-
covers the implicit multi-stage and multi-task contradiction
which is exaggerated in the FSOD setting and propose affine
adapter layers. Recently, some FSOD works start to utilize
end-to-end detectors.
Meta-DETR[13] incorporates corre-
lational aggregation for meta-learning with the Deformable
DETR[15] detector. COCO-RCNN[16] proposes contrastive
loss to regularise Sparse R-CNN to improve its consistent
concentration.
Our approach follows the paradigm of fine-tuning, and
take an end-to-end paradigm model Sparse R-CNN as our
detector. But we focus on analysing its implicit plasticity-
stability contradiction and propose corresponding techniques
to alleviate it, which is still not discussed in previous FSOD
works.
2.2. Stability-plasticity Dilemma
The stability-plasticity dilemma is a well-known contradic-
tion in both artificial and biological neural systems. Unbal-
anced stability-plasticity strategy in continual learning set-
tings often lead to catastrophic forgetting when the model
learn multiple tasks in sequence. If memory stability is em-
phasized too much, the model suffers from low efficiency to
adapt to novel tasks. Vice versa, if learning plasticity has no
regularization constraints, the neural network disrupts the pre-
vious knowledge when assimilate new information[17]. In
continual learning, Some works[18, 19] solves this dilemma
by weight regularization. Some works[20, 21, 22] explores
the modular-based approach.
In this work, as far as we know, it is the first time to
introduce this stability-plasticity perspective into FSOD set-
ting. Here we focus on not protecting knowledge of previous
tasks but on reserving class-agnostic generalization knowl-
edge from upstream pre-training. To differentiate with the
concept in continual learning, we call it as stability-plasticity
contradiction here.
3. METHODS
3.1. Preliminaries
We clarify the two-stage transfer procedure proposed by the
previous work[3] first and then formalize the pipeline of
Sparse R-CNN.
In the base stage, a base dataset Dbase with abundant an-
notated instances whose classes is Cbase is offered for trans-
ferable knowledge extraction.
In the novel stage, a novel
dataset Dnovel with limited but balanced K-shot annotated in-
stances is offered for fine-tuning transfer. The classes of the
instances in Dnovel are Cnovel. And the base classes Cbase
in Dbase are strictly exclusive with the novel classes Cnovel
in Dnovel, namely, Cnovel ∩ Cbase = ϕ. When evaluating,
a test dataset Dtest is offered. The classes of the annotated
instances in Dtest is Cnovel.
The detection pipeline of Sparse R-CNN can be formu-
lated as:
xF P N
= BF P N(I),
(1a)
xi
= Rpool(xF P N, bi−1),
(1b)
qi
= Ai(qi−1, xi),
(1c)
ui
= Dbox
i
(qi),
(1d)
vi
= Dcls
i (qi),
(1e)
bi
= F box
i
(ui),
(1f)
ci
= F cls
i
(vi),
(1g)
(1)
where q denotes object encoding vectors. xF P N denotes the
output features of BF P N the backbone model with FPN neck.
b denotes the predicted box. c denotes the predicted classifi-
cation label. Rpool denotes RoI pooling operation. A denotes
the attention correlation module. D denotes the modules de-
coding object encodings into regression or classification fea-
tures. F cls denotes the linear classifier. F box denotes the
linear regressor. i ∈ {1...NH}. NH is often 6. b0 and q0 are
trainable parameters in the model.
3.2. Plasticity Classifier Fine-tuning
We propose to insert an independent plasticity classifier fine-
tuning(PCF) initialization stage after the base stage and be-
fore the novel stage for Sparse R-CNN during fine-tuning in
the FSOD setting. In this stage, the available samples are the
same with the novel stage. The regular base-novel procedure
is updated to a base-init-novel procedure.
We define C = {P(F cls
i
)|i ∈ 1...NH} as the parameters
of all linear classifiers in all stages in Sparse R-CNN. P(·)
denotes the operator to get the parameters of the input mod-
ule. We define E = {P(BF P N, Ai, Dbox
i
, Dcls
i , F box
i
)|i ∈
1...NH} as the parameters of all other modules in Sparse R-
CNN.
At the beginning of this stage, C are all random initialized.
C has no demand to reserve inherited knowledge. It requires
sufficient initialization and adaptation during transfer instead.
Therefore, sufficient plasticity is necessary to be offered to
facilitate its optimization convergence. Otherwise, C under-
fits to Dnovel.
Since the number of available samples Dnovel is rather
limited, these samples have strong sample selection bias.
Considering Cnovel ∩ Cbase = ϕ, so they have both out-of-
distribution shifts from Dtest and from Dbase. Therefore, the
gradients generated with Dnovel during fine-tuning can only
adapt features which are not orthogonal to the distribution
of Dnovel. Positive transferable knowledge extracted from
distribution of Dbase in E which can generalize to Dtest but
are orthogonal to the subspace of Dnovel is easy to be dis-
torted and forgotten[9]. E over-fits to Dnovel if no protection
constraints are imposed.
Moreover, Sparse R-CNN takes the cascaded architecture
rather than the parallel one like Faster R-CNN. The gradient
flow through C and E are coupled during optimization. More-
over, the gradient descent optimization tend to automatically
balance the weights between different layers[23]. So during
the plasticity classifier optimization, parameters in E deviates
from its pre-trained weights concomitantly with the optimiza-
tion of C if E is not constrained. This leads to severe forgetting
of positive transferable knowledge in E.
Considering these, in this exclusive stage, we decouple
the optimization schedule to offer high plasticity to C but pro-
tect E strictly. We separate the necessary adaptation of E from
here and leave it to the following stage. We set long optimiza-
tion schedule to assure the sufficient fitting of C without wor-
rying the over-fitting of E. No regularization and constraints
are imposed to C while full protection is conducted on param-
eters in E by freezing. The checkpointed model weights of
this stage are then used in the following step.
3.3. Stability Regularisation
Class-specific and class-agnostic knowledge are mixed in
parameters E.
Apparently full freezing E in the previous
stage is too strong that necessary class-specific adaptation
to novel tasks of Cnovel is inhibited.
So following that,
the novel fine-tuning is still necessary to adapt these class-
specific knowledge further. On the other hand, considering
the stability demand of E to reserve the class-agnostic gen-
eralization of the original pre-trained weights. During this
fine-tuning, we freeze the two bottom blocks of backbone
BF P N.
Furthermore, we propose a method called Multi-
source Ensemble(ME) to regularise the detector after this
adaptation.
Inspired by previous works[24, 25, 14], model weights
before fine-tuning can often provide extra diversity and ro-
bustness to rectify the weights deviation and increase the gen-
eralization. WISE-FT[25] demonstrates effective generaliza-
tion ensemble method from the weight space view by linearly
interpolating weights before and after fine-tuning. However,
this view relies on mode connectivity theory[26] to require
the model to have zero-shot classifiers, which is not satisfied
Method
BackboneDet
Shot Number
1
2
3
5
10
30
TFA w/cos[3]
FRCN-R101
3.4
4.6
6.6
8.3
10.0
13.7
MPSR[4]
FRCN-R101
2.3
3.5
5.2
6.7
9.8
14.1
Attention-RPN[27]
FRCN-R101
4.2
6.6
8.0
6.7
9.8
14.1
FSCE[5]
FRCN-R101
-
-
-
-
11.1
15.3
FADI[6]
FRCN-R101
5.7
7.0
8.6
10.1
12.2
16.1
TIP[28]
FRCN-R101
5.7
7.0
8.6
10.1
12.2
16.1
Meta Faster R-CNN[29]
FRCN-R101
5.1
7.6
9.8
10.8
12.7
16.6
SPRCNN-ft-full
SPR-R101
1.3
2.9
4.5
7.3
9.7
16.8
COCO-RCNN[16]
SPR-R101
5.2
-
-
-
16.4
19.2
Ours
SPR-R101
6.5
9.6
11.7
14.7
17.6
23.1
Table 1: Performance comparison with the baseline and some
previous FSOD methods on COCO benchmark(novel mAP).
We list their backbone models and detectors and align them
in separate groups for fair comparison.
here.
Here we propose an ensemble regularization method to
further regularize the transfer. We introduce an array of proto-
types using the offered ImageNet pre-trained backbone model
BIm which is neither fine-tuned nor pre-trained in the base
stage. The image xsp
j is input into BIm to extract the feature
map. Then we crop the representation vector uj of each in-
stance by using ROIAlign with bsp
j to get uj. We calculate the
prototypes Q = {rIm
c
|c ∈ {1...N}} as:
rIm
c
=
1
|Sc|
X
ysp
j ∈Sc
uj, where uj ← R(BIm(xsp
j ), bsp
j ) (2)
where the operator R(·) denotes ROIAlign.
Given an object proposal ˆyk
= (ck, sk, bk) predicted
by the detector with image ˆxk during inference, where
ck, sk, bk denotes the category label,confidence score and
bounding box correspondingly. We get its feature zIm
k
=
Rpool(BIm(ˆxk), bk) using the member BIm.
Then we
calculate its cosine similarity with prototypes in Q as:
sIm
k
= cos(zIm
k , rIm
c
), where the operator cos(·) denotes
cosine similarity operation. At last, we ensemble sIm
k
with
sk to rectify the prediction results sk of the detector as:
sens = α · sk + β · sIm
k ,
α + β = 1
(3)
where α, β are hyper-parameters to aggregate the ensemble
results from each member.
4. EXPERIMENTS
4.1. Datasets
We use the dataset MS COCO-2014 as in works [6, 3, 5] to
evaluate the FSOD performance of our method. For COCO
dataset, the 60 categories non-overlapping with PASCAL
VOC dataset are treated as base classes, and the remaining 20
classes are selected as novel classes. We report the detection
Detector
Method
10shot
SPRCNN
PCF
ME
AP
AP50
AP75
✓
9.7
15.9
9.7
✓
✓
13.5
21.0
13.9
✓
✓
11.9
19.3
11.9
✓
✓
✓
17.7
27.8
18.0
Table 2: Ablation study of the effectiveness of proposed
methods in 10-shot setting on MS-COCO benchmark. PCF,
ME denotes Plasticity Classifier Fine-tuning, and Multi-
source Ensemble respectively.
accuracy for AP,AP50,AP75 on the test set consisting of 5k
images with shot settings at 1,2,3,5,10 and 30.
4.2. Implementation Details
We use the typical end-to-end object detecotr Sparse R-
CNN[1] as the base framework. And we use ResNet-101[30]
as our backbone model as previous works. AdamW is utilized
as the optimizer with the weight decay of e−4. We use a batch
size of 8 on four GPUs.
4.3. Benchmark Results
We compare the proposed method with previous works and
show the results in Tab.1. For fairness consideration, we show
the baseline performance by fully fine-tuning Sparse R-CNN
without any regularization to rule out the difference brought
by the detector itself. Our method achieves improvements
7.2%, 7.4%, 7.9%, 6.3% mAP in 3,5,10,30-shot settings re-
spectively in comparison with its baseline performance.
4.4. Ablation Study
Ablation experiments are conducted on 10 shot settings of the
MS-COCO benchmark to analyze the contributions of each
component of the proposed methods.
All results are shown in Tab.2. Specifically, we see in
the first row of this table that if we fine-tune plain Sparse
R-CNN naively without any proposed techniques, it only
achieves 9.7% mAP for the 10-shot setting. This poor FSOD
performance indicates that the existence of implicit plasticity-
stability contradiction in the detector Sparse R-CNN leads to
severe over-fitting to the limited samples.
Follwing that, we see if we introduce the plasticity clas-
sifier fine-tuning technique, the FSOD performance improves
dramatically from 9.7% to 13.5% mAP on this 10-shot set-
ting. This shows decoupling the plasticity fine-tuning stage
from the regular novel fine-tuning stage is greatly beneficial
in balancing the stability-plasticity trade-off to reserve more
generalization robustness of the detector.
Next, in the third and fourth line, we can see the effective-
ness of the proposed multi-source ensemble method indepen-
dently and when it works jointly with the plasticity classifier
fine-tuning method. It pushes the FSOD performance from
9.7% to 11.9% independently by mitigating the negative de-
viation of the detector from its pre-trained weights. When ap-
plied jointly, 10-shot FSOD performance is further improved
to 17.7% mAP.
5. CONCLUSION
In this paper, we analyze the stability-plasticity contradic-
tion between linear classifiers and other modules in Sparse
R-CNN during Fine-tuning in the FSOD scenario. We pro-
pose a new three-stage transfer procedure by introducing an
additional classifier plasticity fine-tuning stage for Spase R-
CNN. Moreover, we design a an ensemble technique to fur-
ther regularise the detector. The implicit stability plasticity
contradiction is mitigated with our method. Experiments ver-
ify the effectiveness of the proposed method.
6. REFERENCES
[1] Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chen-
feng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Ze-
huan Yuan, Changhu Wang, et al., “Sparse r-cnn: End-
to-end object detection with learnable proposals,”
in
Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition, 2021, pp. 14454–14463.
1, 2, 4
[2] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian
Sun, “Faster r-cnn: Towards real-time object detection
with region proposal networks,” Advances in neural in-
formation processing systems, vol. 28, 2015. 1, 2
[3] Xin Wang, Thomas E. Huang, Trevor Darrell, Joseph E.
Gonzalez, and Fisher Yu,
“Frustratingly simple few-
shot object detection,” 37th International Conference
on Machine Learning, ICML 2020, vol. PartF168147-
13, pp. 9861–9870, 2020. 1, 2, 3, 4
[4] Jiaxi Wu, Songtao Liu, Di Huang, and Yunhong Wang,
“Multi-scale positive sample refinement for few-shot
object detection,” in European conference on computer
vision. Springer, 2020, pp. 456–472. 1, 4
[5] Bo Sun, Banghuai Li, Shengcai Cai, Ye Yuan, and Chi
Zhang,
“FSCE: Few-Shot Object Detection via Con-
trastive Proposal Encoding,” Proceedings of the IEEE
Computer Society Conference on Computer Vision and
Pattern Recognition, pp. 7348–7358, 2021. 1, 4
[6] Yuhang Cao, Jiaqi Wang, Ying Jin, Tong Wu, Kai Chen,
Ziwei Liu, and Dahua Lin, “Few-shot object detection
via association and discrimination,” Advances in Neural
Information Processing Systems, vol. 34, 2021. 1, 2, 4
[7] Nicolas Carion, Francisco Massa, Gabriel Synnaeve,
Nicolas Usunier,
Alexander Kirillov,
and Sergey
Zagoruyko,
“End-to-end object detection with trans-
formers,” in European conference on computer vision.
Springer, 2020, pp. 213–229. 2
[8] Liyuan Wang, Xingxing Zhang, Hang Su, and Jun
Zhu,
“A comprehensive survey of continual learn-
ing: Theory, method and application,” arXiv preprint
arXiv:2302.00487, 2023. 2
[9] Ananya Kumar, Aditi Raghunathan, Robbie Matthew
Jones, Tengyu Ma, and Percy Liang,
“Fine-tuning
can distort pretrained features and underperform out-of-
distribution,” in International Conference on Learning
Representations, 2021. 2, 3
[10] Bingyi Kang, Zhuang Liu, Xin Wang, Fisher Yu, Jiashi
Feng, and Trevor Darrell, “Few-shot object detection
via feature reweighting,” Proceedings of the IEEE In-
ternational Conference on Computer Vision, vol. 2019-
October, pp. 8419–8428, 2019. 2
[11] Xiaopeng Yan, Ziliang Chen, Anni Xu, Xiaoxi Wang,
Xiaodan Liang, and Liang Lin,
“Meta R-CNN: To-
wards general solver for instance-level low-shot learn-
ing,” Proceedings of the IEEE International Conference
on Computer Vision, vol. 2019-October, pp. 9576–9585,
2019. 2
[12] Yang Xiao and Renaud Marlet, “Few-shot object detec-
tion and viewpoint estimation for objects in the wild,”
in European conference on computer vision. Springer,
2020, pp. 192–210. 2
[13] Gongjie Zhang, Zhipeng Luo, Kaiwen Cui, and Shi-
jian Lu,
“Meta-detr: Few-shot object detection via
unified image-level meta-learning,”
arXiv preprint
arXiv:2103.11731, vol. 2, no. 6, 2021. 2
[14] Limeng Qiao, Yuxuan Zhao, Zhiyuan Li, Xi Qiu, Jianan
Wu, and Chi Zhang, “DeFRCN: Decoupled Faster R-
CNN for Few-Shot Object Detection,” ICCV2021, 2021.
2, 3
[15] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang
Wang, and Jifeng Dai, “Deformable detr: Deformable
transformers for end-to-end object detection,”
in In-
ternational Conference on Learning Representations,
2020. 2
[16] Jiawei Ma, Guangxing Han, Shiyuan Huang, Yuncong
Yang, and Shih-Fu Chang, “Few-shot end-to-end object
detection via constantly concentrated encoding across
heads,” in European Conference on Computer Vision.
Springer, 2022, pp. 57–73. 2, 4
[17] German I Parisi, Ronald Kemker, Jose L Part, Christo-
pher Kanan, and Stefan Wermter, “Continual lifelong
learning with neural networks: A review,” Neural net-
works, vol. 113, pp. 54–71, 2019. 2
[18] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz,
Joel Veness, Guillaume Desjardins, Andrei A Rusu,
Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al., “Overcoming catastrophic
forgetting in neural networks,” Proceedings of the na-
tional academy of sciences, vol. 114, no. 13, pp. 3521–
3526, 2017. 2
[19] Rahaf Aljundi, Francesca Babiloni, Mohamed Elho-
seiny, Marcus Rohrbach, and Tinne Tuytelaars, “Mem-
ory aware synapses: Learning what (not) to forget,” in
Proceedings of the European conference on computer
vision (ECCV), 2018, pp. 139–154. 2
[20] Mustafa Burak Gurbuz and Constantine Dovrolis,
“Nispa:
Neuro-inspired stability-plasticity adaptation
for continual learning in sparse networks,”
arXiv
preprint arXiv:2206.09117, 2022. 2
[21] Liyuan Wang, Xingxing Zhang, Qian Li, Jun Zhu, and
Yi Zhong, “Coscl: Cooperation of small continual learn-
ers is stronger than a big one,” in European Conference
on Computer Vision. Springer, 2022, pp. 254–271. 2
[22] Joan Serra, Didac Suris, Marius Miron, and Alexandros
Karatzoglou, “Overcoming catastrophic forgetting with
hard attention to the task,” in International conference
on machine learning. PMLR, 2018, pp. 4548–4557. 2
[23] Simon S Du, Wei Hu, and Jason D Lee, “Algorithmic
regularization in learning deep homogeneous models:
Layers are automatically balanced,” Advances in neu-
ral information processing systems, vol. 31, 2018. 3
[24] Jake Snell, Kevin Swersky, and Richard Zemel, “Pro-
totypical networks for few-shot learning,”
Advances
in Neural Information Processing Systems, vol. 2017-
December, pp. 4078–4088, 2017. 3
[25] Mitchell Wortsman,
Gabriel Ilharco,
Jong Wook
Kim, Mike Li, Simon Kornblith, Rebecca Roelofs,
Raphael Gontijo Lopes,
Hannaneh Hajishirzi,
Ali
Farhadi, Hongseok Namkoong, et al.,
“Robust fine-
tuning of zero-shot models,”
in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2022, pp. 7959–7971. 3
[26] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel
Roy, and Michael Carbin, “Linear mode connectivity
and the lottery ticket hypothesis,” in International Con-
ference on Machine Learning. PMLR, 2020, pp. 3259–
3269. 3
[27] Qi Fan, Wei Zhuo, Chi-Keung Tang, and Yu-Wing Tai,
“Few-shot object detection with attention-rpn and multi-
relation detector,”
in Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition,
2020, pp. 4013–4022. 4
[28] Aoxue Li and Zhenguo Li,
“Transformation invari-
ant few-shot object detection,”
in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2021, pp. 3094–3102. 4
[29] Guangxing Han, Shiyuan Huang, Jiawei Ma, Yicheng
He, and Shih-Fu Chang, “Meta faster r-cnn: Towards
accurate few-shot object detection with attentive feature
alignment,” in Proceedings of the AAAI Conference on
Artificial Intelligence, 2022, vol. 36, pp. 780–789. 4
[30] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun, “Deep residual learning for image recognition,” in
Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778. 4
","Prior work, TFA, propose that fine-tuning is a simple yet effective approach to adapt detectors. TFA proposes a two-stage transfer procedure, which is popularly used by many FSOD methods. In the first stage, sufficient annotated instances which belong to base classes are available for pre-training the detector. In the following stage, only a few fixed number of annotated instances of each novel class are available for adapting the detector. Base classes and novel classes have no intersection.
Many methods use this two-stage transfer procedure and take Faster R-CNN as their detector. They find and tackle many problems during fine-tuning from various views. MPSR tackles the scale variation problem. FSCE updates the freezing strategy and propose a contrastive loss to alleviate confusion. FADI presents an association and discrimination loss based on the semantic similarity. However, the limitations of this two-stage transfer procedure is still less discussed. And there is no work explore the fine-tuning efficiency from the perspective of implicit plasticity-stability contradiction among different modules.nan"
"Multitask learning (MTL) has gained prominence for its ability to jointly predict multiple tasks, achieving better per-task performance while using fewer per-task model parameters than single-task learning. Recently, decoder-focused architectures have improved MTL performance by refining task predictions using the features of other related tasks. Our model, Efficient Multitask Affinity Learning Network (EMA-Net), is a lightweight framework that enhances the task refinement capabilities of multitask networks. EMA-Net captures local, global, and cross-task interactions using our novel Cross-Task Affinity Learning (CTAL) module.","Modern AI research integrates into daily life, but most cutting-edge models are massive and rely on remote access. For many applications, models that operate locally without network dependence highlight the importance of balancing performance with parameter efficiency in model design. MTL, also known as parameter-efficient learning, can outperform STL. MTL involves using a single network to learn multiple tasks by jointly optimizing multiple loss functions. In many dense prediction cases, sharing features across tasks has been proven to improve per-task performance while using fewer per-task model parameters. We explore the optimization strategy and the design of the deep multitask architecture to enhance the state-of-the-art. We can categorize the research directions for modern MTL methods into two groups: optimization strategy and deep architecture design. As its name suggests, decoder-focused models employ feature-sharing mechanisms within the decoder(s). Decoder-focused architectures introduce mechanisms to refine task predictions by capturing feature patterns between tasks. Task prediction distillation is also known as capturing these inter-task relationships. Decoder-focused architectures consistently achieve state-of-the-art performance in MTL and can be regarded as the prevailing research direction for multitask architecture design.","In the literature, there are two prevailing approaches to applying an attention map to a set of image features generated by CCN-based architectures. The first approach involves using convolutional blocks to process the features and obtain an attention mask with the same shape. The attention mask undergoes an activation (i.e., Sigmoid) to set all values to be between 0 and 1. The resulting attention map is applied to the features via element-wise multiplication, which has been applied in STL and MTL. We will refer to this as element-wise multiplication attention (EM attention). The second approach aims to explicitly model long-range dependencies of features by computing the Gram matrix (inner products of all pairs of column vectors) of the features after flattening them along the spatial dimensions. The corresponding matrix (i.e., affinity matrix) is then diffused to the original features via matrix multiplication. We will refer to this method as matrix multiplication attention (MM attention). In MTL, the EM attention from PAD-Net and the MM attention from PAP-Net achieve almost identical results. However, PAP-Net uses considerably fewer model parameters at the cost of more floating point operations (FLOPs). Their comparable performance is likely attributed to the fact that the affinity matrices explicitly capture long-range dependencies between every feature pair and diffuse them across all features using MM attention; whereas EM attention approaches only learn long-range dependencies implicitly by training convolutional filters that process local patches throughout the entire spatial dimension. The fact that MM attention in PAP-Net achieves almost identical performance to EM attention using a simple weighted sum for cross-task fusion is astonishing. We believe that there is substantial untapped potential in these affinity representations and therefore, we were inspired to develop a parameter-efficient cross-task attention mechanism to optimally model local and global interactions.","The results of EMA-Net SS and MS against all our baselines are shown in the table. As we can see, for both datasets, we achieve considerably higher performance for all task metrics in SS and MS configurations. We can even see that our EMA-Net (SS) is competitive to MTI-Net in NYUv2 despite being at a disadvantage by not having deep supervision on task predictions from multiple scales. On Cityscapes, we can also see that MTI-Net struggles in the simpler 2-task setting with smaller input image scales. The results of MTI-Net have likely not been reported previously on Cityscapes as it is susceptible to overfitting. We argue in favor of this trade-off because there are more optimization opportunities at various levels to reduce the effect of additional FLOPs compared to model parameters. For example, we can optimize algorithmically, improve hardware utilization, leverage sparse matrix operations (if applicable), and manipulate feature scales. We further demonstrate that by adjusting our feature scale, we can significantly reduce the number of FLOPs we introduce while still outperforming competitors at higher feature scales.","We proposed the EMA-Net multitask architecture, incorporating the novel CTAL module for task prediction distillation. Our network is the first CNN-based architecture that can explicitly and exhaustively model all feature-pair relationships intra- and inter-task. Impressively, we accomplish this using significantly fewer model parameters than competing STL and MTL models while achieving better multitasking performance on complex indoor and outdoor scenes. We have also demonstrated that by adjusting our feature scale, we can significantly reduce the number of FLOPs we introduce while still outperforming competitors at higher feature scales. As mentioned, we believe that the performance improvements with the massive reduction in model parameters justify the additional FLOPs, especially since there are more opportunities for optimization compared to reducing model capacity.",EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions,"Dimitrios Sinodinos, Narges Armanfard","EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions
Dimitrios Sinodinos1,2 , Narges Armanfard1,2
1McGill University
2Mila Quebec
dimitrios.sinodinos@mail.mcgill.ca, narges.armanfard@mcgill.ca
Abstract
Multitask learning (MTL) has gained prominence
for its ability to jointly predict multiple tasks,
achieving better per-task performance while using
fewer per-task model parameters than single-task
learning. More recently, decoder-focused architec-
tures have considerably improved multitask perfor-
mance by refining task predictions using the fea-
tures of other related tasks. However, most of these
refinement methods fail to simultaneously capture
local and global task-specific representations, as
well as cross-task patterns in a parameter-efficient
manner. In this paper, we introduce the Efficient
Multitask Affinity Learning Network (EMA-Net),
which is a lightweight framework that enhances
the task refinement capabilities of multitask net-
works. EMA-Net adeptly captures local, global,
and cross-task interactions using our novel Cross-
Task Affinity Learning (CTAL) module. The key
innovation of CTAL lies in its ability to manipu-
late task affinity matrices in a manner that is opti-
mally suited to apply parameter-efficient grouped
convolutions without worrying about information
loss.
Our results show that we achieve state-of-
the-art MTL performance for CNN-based decoder-
focused models while using substantially fewer
model parameters. Our code is publicly available
at https://github.com/Armanfard-Lab/EMA-Net.
1
Introduction
Modern AI research is rapidly integrating into our daily lives.
However, most cutting-edge models are massive and rely on
remote access since they cannot be easily deployed on edge
devices such as mobile phones, smart accessories, or wear-
able medical equipment. For many applications, the need for
models to operate locally without network dependence high-
lights the importance of balancing performance with parame-
ter efficiency in model design.
In recent years, multitask learning (MTL) [Caruana, 1997]
has emerged as a parameter-efficient learning paradigm that
can also outperform traditional single-task learning (STL).
Generally, MTL involves a single network that can learn mul-
tiple tasks by jointly optimizing multiple loss functions. Con-
sequently, using a single network means that several lay-
ers or features are being shared between tasks.
In many
dense prediction cases, sharing features across tasks has
been proven to improve per-task performance, while using
fewer per-task model parameters. This is the result of im-
proved generalization by leveraging domain-specific knowl-
edge between related tasks [Kendall et al., 2018].
The
prominent research directions for modern MTL methods ex-
plore either the optimization strategy [Chen et al., 2018;
Liu et al., 2022; Xin et al., 2022] or the design of the deep
multitask architecture [Misra et al., 2016; Gao et al., 2019;
Sinodinos and Armanfard, 2022]. Within the vein of deep
architecture design, Vandenhende et al. [2022] further frag-
ment the designs into encoder-focused and decoder-focused
architectures. As the name suggests, decoder-focused models
employ feature-sharing mechanisms within the decoder(s).
Specifically, decoder-focused architectures introduce mech-
anisms to refine task predictions by capturing feature pat-
terns between tasks. An example of a pattern between tasks
would be the alignment of segmentation edges with disconti-
nuities in depth values. This refinement process is also called
task prediction distillation [Xu et al., 2018]. By capturing
these inter-task relationships, decoder-focused architectures
consistently achieve state-of-the-art performance in MTL and
can be regarded as the prevailing research direction for mul-
titask architecture design.
A foundational decoder-focused method, PAP-Net [Zhang
et al., 2019], introduces the notion of “task affinity”, which is
a measure of similarity between pairs of features for a given
task. Specifically, they construct affinity matrices to store the
similarity information between every possible pair of features
for a given task. The benefit of working with affinity matrices
is that they capture long-range dependencies and introduce
very few additional model parameters. To perform task pre-
diction distillation, they combine affinity matrices from all
tasks using a weighted sum, and then diffuse this similar-
ity information into the features of each initial task predic-
tion. A problem with this approach is that learning a single
weight per affinity matrix suggests that all pairwise similar-
ity patterns in the feature space are equally important. How-
ever, we hypothesize that cross-task patterns are nuanced and
vary in importance throughout the feature space. This sim-
ple cross-task mechanism was likely used because processing
these matrices can be expensive, especially at larger feature
This work has been submitted to the IEEE for possible publication.
Copyright may be transferred without notice, after which this vers-
ion may no longer be accessible.
arXiv:2401.11124v1  [cs.CV]  20 Jan 2024
scales. Grounded by our hypothesis, we believe that there is
substantial untapped potential in affinity representations
(i).
A more recent work, MTI-Net [Vandenhende et al., 2020],
claims that tasks with high affinities at a certain feature scale
are not guaranteed to have high affinities at different scales.
Consequently, they model task interactions at multiple scales
to perform “multi-scale multi-modal distillation”; which sig-
nificantly improves performance. However, this performance
improvement comes at the cost of additional parameters for
deep supervision at multiple scales; which makes this ap-
proach susceptible to overfitting on simpler datasets. There-
fore, we believe that there is a need for a more parameter-
efficient framework that can still leverage the benefits of
multiscale processing (ii).
InvPT [Ye and Xu, 2022] and TaskPrompter [Ye and Xu,
2023] continue the trend of improving performance with
more model capacity by moving away from the CNN archi-
tecture for one based on the Vision Transformer (ViT) [Doso-
vitskiy et al., 2020]. They argue that current multitask atten-
tion mechanisms in CNN-based models have limited scope in
their cross-task pattern modelling. Their multitask attention
methods can capture local, global, and cross-task relation-
ships, but mainly because they operate on more compressed
features as a consequence of using feature extractors with sig-
nificantly higher parameter budgets. However, modelling lo-
cal, global, and cross-task relationships has yet to be ac-
complished using lightweight CNN-based feature extrac-
tors (iii).
Despite their recent success, current decoder-focused
methods have yet to address (i), (ii), and (iii). We solve all
of these issues by introducing the Efficient Multitask Affinity
Learning Network (EMA-Net), which uses our novel Cross-
Task Affinity Learning (CTAL) module for improved task
prediction distillation. CTAL strategically aligns the affin-
ity matrices using careful reshaping and interleaved concate-
nations, which allows us to leverage grouped convolutions
to realize massive reductions in model parameters.
Addi-
tionally, since we exhaustively model every pairwise feature
relationship within a task and across all tasks, we can use
these grouped convolutions without fear of information loss.
This effectively solves issue (i), as we can tap into the full
potential of affinity matrix representations. Simultaneously,
we also solve issue (iii), since our cross-task attention mech-
anism explicitly models all pairwise interactions intra- and
inter-task using only a lightweight CNN-based architecture.
Our method also extends to a multiscale framework by ap-
plying deep supervision to initial task predictions at multiple
scales. However, unlike MTI-Net, we fuse the initial task
predictions from every scale and then perform task predic-
tion distillation at a single scale. Consequently, our multi-
scale EMA-Net framework is more parameter efficient, and
addresses issue (ii). Therefore, we can summarize our contri-
butions as follows:
1. A method to process affinity matrices in a parameter-
efficient manner while exhaustively modelling all intra-
and inter-task relationships in CNN-based architectures.
This addresses (i, iii).
2. A light-weight multiscale framework that yields the ben-
efits of multiscale deep supervision, while only needing
a single scale for task-prediction distillation. This ad-
dresses (ii).
As a result of our contributions, we achieve significant multi-
task performance improvements using a fraction of the learn-
able parameters compared to other decoder-focused tech-
niques.
2
Related Works
PAD-Net [Xu et al., 2018] is the first work to popularize the
idea of refining task predictions by distilling their feature in-
formation between tasks. They refer to this process as “task
prediction distillation”.
PAP-Net [Zhang et al., 2019] ex-
plicitly models feature similarities, known as “task affinity”,
and distills this information between tasks. MTI-Net [Van-
denhende et al., 2020] extends distillation to multiple feature
scales, which is known as “multi-scale multi-modal” distilla-
tion. Other recent works include ATRC [Br¨uggemann et al.,
2021], InvPt [Ye and Xu, 2022], and TaskPrompter [Ye and
Xu, 2023]. ATRC applies a neural architecture search (NAS)
to learn a branching structure that considers the global fea-
tures, local features, source label, and target labels between
every possible combination of task pairs. Although this study
provides interesting insights into optimal task interactions, it
is difficult to justify its use in a real-world setting because it
takes an incredible amount of resources to train, and scales
very poorly with more tasks. Hanrong Ye and Dan Xu [2022;
2023] create their own multitask network based on the Vi-
sion Transformer (ViT) [Dosovitskiy et al., 2020]. The added
model capacity allows them to explicitly model local and
global relationships between tasks.
The attention mechanism [Vaswani et al., 2017] allows net-
works to place greater emphasis on certain parts of an in-
put that are important for the downstream task. For dense
vision tasks, it has been shown that attending to features
in the spatial and/or channel dimensions leads to signifi-
cant performance improvements [Woo et al., 2018; Fu et al.,
2019]. Consequently, these notions have been extended to
the MTL domain, which explored different ways of mod-
elling cross-task patterns using attention [Liu et al., 2019;
Xu et al., 2018; Zhang et al., 2019; Vandenhende et al., 2020;
Sinodinos and Armanfard, 2022].
3
EMA-Net
In the literature, there are two prevailing approaches to ap-
plying an attention map to a set of image features generated
by CCN-based architectures. The first approach involves us-
ing convolutional blocks to process the features and obtain
an attention mask with the same shape. The attention mask
undergoes an activation (i.e., Sigmoid) to set all values to be
between 0 and 1. The resulting attention map is applied to
the features via element-wise multiplication, which has been
applied in STL [Woo et al., 2018], and MTL [Liu et al., 2019;
Xu et al., 2018]. We will refer to this as element-wise multi-
plication attention (EM attention). The second approach aims
to explicitly model long-range dependencies of features by
computing the Gram matrix (inner products of all pairs of
Figure 1: A diagram of the Cross-Task Affinity Learning (CTAL) module that is comprised of three stages: Intra-Task, Inter-Task, and Task-
Specific Diffusion. We compute the Gram matrix of the flattened and normalized views of the initial task prediction features F i
tk to obtain
the task-specific affinity matrices Ai
tk. We then reshape Ai
tk to the original spatial dimensions and perform an interleaved concatenation of
all HW channels for each task to obtain the joint affinity matrix M. Each of the HW sets of N channels is processed by a task-specific
grouped convolution (G Convtk) and then diffuses its information to a projected view of F i
tk via matrix multiplication and an element-wise
weighted sum to obtain the final refined features F r
tk.
Figure 2: An illustration of the interleave concatenation procedure
used to align the channels for grouped convolutions in a two-task
scenario.
column vectors) of the features after flattening them along
the spatial dimensions. The corresponding matrix (i.e., affin-
ity matrix) is then diffused to the original features via ma-
trix multiplication. We will refer to this method as matrix
multiplication attention (MM attention). MM attention has
also been used in STL [Fu et al., 2019], and MTL [Zhang
et al., 2019].
In MTL, the EM attention from PAD-Net
and the MM attention from PAP-Net achieve almost iden-
tical results.
However, PAP-Net uses considerably fewer
model parameters at the cost of more floating point opera-
tions (FLOPs). Their comparable performance is likely at-
tributed to the fact that the affinity matrices explicitly capture
long-range dependencies between every feature pair and dif-
fuse them across all features using MM attention; whereas
EM attention approaches only learn long-range dependencies
implicitly by training convolutional filters that process local
patches throughout the entire spatial dimension.
The fact that MM attention in PAP-Net achieves al-
most identical performance to EM attention using a simple
weighted sum for cross-task fusion is astonishing. We be-
lieve that there is substantial untapped potential in these affin-
ity representations, and therefore, we were inspired to de-
velop a parameter-efficient cross-task attention mechanism to
optimally model local and global interactions. For param-
eter efficiency, we aim to employ MM attention, which in-
volves processing large affinity matrices. Therefore the chal-
lenge lies in minimizing the parameters introduced to process
these matrices. We propose our EMA-Net framework to ef-
ficiently and exhaustively model all cross-task patterns using
CTAL; which is comprised of three stages: intra-task mod-
elling, inter-task modelling, and task-specific diffusion.
3.1
Intra-Task Modelling
As seen in Figure 1, for a given task tk {k ∈ [1, N]}, we
follow the standard procedure to generate the affinity matri-
ces, Atk ∈ RHW,HW . This involves taking the features of
the initial predictions, Ftk ∈ RC,H,W , flattening the spatial
dimensions, performing L2 normalization for each column,
and computing the Gram matrix (the inner products of all
pairs of column vectors). At this point, every row in Atk con-
tains the cosine similarities of a feature, x ∈ Ftk, with every
other feature in Ftk. Next, we reshape Atk into RHW,H,W .
This restores the original spatial dimensions of the features,
but now the HW channels at a given 2-dimensional position
(i ∈ [1, H], j ∈ [1, W]) contain the cosine similarities of the
feature xi,j with all other features. Therefore, in this config-
uration, the entire first channel corresponds to the similarities
of all xi,j with x1,1, which is also aligned at position (i, j).
Figure 3: A network diagram of EMA-Net using deep supervision at multiple feature scales and using the CTAL module after cross-scale
fusion for task-refinement. An input image is passed through a shared encoder to generate a set of features at 4 different scales relative to
the input. We compute the initial predictions using each feature scale and then upsample all task-specific feature maps to the highest scale
and combine them in the cross-scale fusion blocks. Finally, the output of each task-specific cross-scale fusion is passed as input to the CTAL
module, where the features are refined and then processed by task-specific decoders to obtain the final predictions.
This is a useful property for maintaining spatial coherence
during subsequent processing.
3.2
Inter-Task Modelling
Next, to fuse the reshaped affinity matrices, we first perform
an interleave concatenation operation. As seen in Figure 2,
this involves concatenating the first channel of each Atk (i.e.
D1
t1 and D1
t2), and then the second channels, and so on for
all HW channels of each Atk. This gives us the joint affin-
ity matrix, M ∈ RNHW,H,W , where N is the number of
tasks in the MTL system. Depending on the spatial dimen-
sions of the data, this M can be very large, so processing
it using standard convolutions would be very expensive. In-
stead, we aim to leverage parameter-efficient grouped convo-
lutions [Xie et al., 2017; Chollet, 2017; Sandler et al., 2018].
The way we strategically organized M strongly justifies the
use of grouped convolutions to perform our multitask fusion
without the fear of losing important cross-task information.
This is because every group of N channels already contains
task interactions between a given feature xi,j with every other
feature across all tasks. So not only does this significantly re-
duce the number of model parameters required to fuse M for
every task, but it also allows us to learn HW spatially co-
herent kernels that specifically focus on learning the relation-
ships of a given feature xi,j with all other features across all
tasks. When considering a traditional convolution on M, we
would require HW kernels of size NHW × f × f, whereas
our approach only requires HW kernels of size N × f × f,
where f is the size of the convolutional filter. This translates
to HW times fewer parameters used. For example, working
with 3 tasks at 72×96 feature size and f = 3, for the NYUv2
dataset, we use only 187K parameters compared to the 1.29B
parameters needed for a single standard convolutional layer.
After processing the shared M for every task, we obtain
N matrices and reshape each of them back into HW × HW
to obtain each Gtk ∈ RHW,HW . Now, in a given Gtk, each
row contains information about the relationship of a single
feature with every other feature across all tasks. Since we
use f × f kernels where f > 1, we also embed cross-task
spatial interaction patterns. Next, we transpose the matrix
so that the row containing all pertinent information for xi,j
is stored at location (i, j) after the diffusion process, which
perfectly maintains spatial coherence throughout the entire
attention process.
3.3
Task-Specific Diffusion
The subsequent diffusion process involves performing a ma-
trix multiplication to obtain the diffused features, F d
tk
∈
RC,HW :
F d
tk = F p
tk × G⊤
tk,
(1)
where F p
tk ∈ RC,HW is the reshaped convolution projection
of F i
tk. Through this matrix multiplication, every value in F d
tk
is the result of the dot product between a row vector in F p
tk
containing values from all HW features and a column vector
in G⊤
tk containing cross-task affinity pattern information be-
tween a feature xi,j and all other HW features. When there
is a high-affinity pattern across tasks, the value of xi,j will
become larger relative to other features with lower-affinity
patterns, similar to the scaling behaviour from EM attention.
As seen in Equation 2, the diffused features are then blended
with the original features using element-wise addition with
scalar weighing parameter γ to obtain the refined features
F r
tk ∈ RC,H,W . This blending ensures the refined features
do not deviate too far from the original features.
F r
tk = γ ∗ F d
tk + (1 − γ) ∗ F i
tk
(2)
3.4
Multiscale EMA-Net
There are two variants of the proposed EMA-Net architec-
ture. The first variant makes initial predictions using a sin-
gle feature scale (SS) and the other using multiple feature
scales (MS). The latter is illustrated in Figure 3, which is used
to compete with multi-scale multi-modal distillation meth-
ods like MTI-Net [Vandenhende et al., 2020]. However, our
model is more efficient and scalable as we only need a sin-
gle distillation module (i.e. CTAL) rather than having one
module for every scale. We accomplish this by combining
the initial prediction features from each scale with the cross-
scale fusion (CSF) blocks prior to performing task predic-
tion distillation in CTAL. For cross-scale fusion, we follow
the same procedure as [Vandenhende et al., 2020], which in-
volves up-sampling all features to the 1/4 input scale, con-
catenating them along the channel dimension, and combining
them through a convolutional block. For comparison with
other methods that operate on a single feature scale, we per-
form the same cross-scale fusion on the multi-scale features
generated by the shared encoder and generate only a single
set of initial predictions.
4
Experimental Setup
4.1
Datasets
We perform our experiments on NYUv2 [Nathan Silber-
man and Fergus, 2012] and Cityscapes [Cordts et al., 2016]
datasets, which are both very popular for multitask learning.
NYUv2 contains 1449 densely labelled RGB-depth images of
indoor scenes. The raw dataset contains images with incom-
plete depth values; which are masked during training. The
tasks associated with this dataset are 13-label semantic seg-
mentation, depth estimation, and surface normals prediction.
The dataset does not contain surface normal labels out-of-
the-box, so we used the pseudo ground surface normals data
obtained from [Eigen and Fergus, 2015], which include some
incomplete values at the same locations as the corresponding
depth maps. The training and validation sets contain 795 and
654 images respectively, and the resolution of the images is
288 × 384. Cityscapes is a larger dataset containing 3475
outdoor urban street scenes with fine annotations taken from
50 cities over several months of the year. From the set of fine
annotations, we have 2975 train and 500 validation images.
The tasks associated with this dataset are 19-label semantic
segmentation and depth estimation. The labels used are from
their official documentation that group several labels into a
void class, and specify 19 other labels that should be used
during training. The resolution of the images is 128 × 256.
For both datasets, we use publicly available preprocessed
versions courtesy of [Liu et al., 2019].
4.2
Tasks and Performance Metrics
Semantic Segmentation involves assigning a class label to
each pixel in an image. During training, the objective is to
minimize the depth-wise cross-entropy loss between the pre-
dicted labels ˆy, and the targets y, for all pixels. We also eval-
uate our models on mean intersection over union (mIoU) and
absolute pixel accuracy. However, mIoU is a much better in-
dicator of semantic understanding.
Depth Estimation involves predicting a depth value for each
pixel. During training, we aim to minimize the absolute error
(L1 norm) of the predicted values ˆd, and the targets d. We
also report on the relative depth error.
Surface Normals prediction involves estimating the direc-
tion perpendicular to the surface of objects in an image; mak-
ing it useful for acquiring geometric and structural scene in-
formation. We train the model to minimize the element-wise
dot product between the normalized predictions ˆs, and the tar-
gets s. For evaluation, we consider the mean angular distance
between ˆs and s. We also report the proportion of predictions
that fall within 11.25, 22.5, and 30.0 degrees of error.
Finally, MTL Gain [Maninis et al., 2019] is an aggregate
measure of the overall multitask improvement of method m
with respect to a single task learning baseline b for all tasks
t ∈ [1, N], as seen in Equation 3.
∆m = 1
N
N
X
t
(−1)lt(Mm,t − Mb,t)/Mb,t
(3)
where lt = 1 if a lower value of metric M is favorable, and
0 otherwise. We will treat ∆m as a percentage in our eval-
uation. Although we use multiple metrics per task through-
out our evaluations, we want to make sure that every task is
weighed evenly when calculating ∆m by selecting a single
metric per task that best demonstrates generalization perfor-
mance. Consequently, to compute ∆m, we will use mIoU
for segmentation, the relative error for depth, and the mean
angular distance for surface normals. We also show that we
still achieve superior MTL gain using other combinations of
metrics in the appendix.
In our results,
the metrics where larger values are
favourable are denoted with (↑) and smaller values with (↓).
The formulas for each task-specific performance metric can
also be found in the appendix.
4.3
Baselines
It is standard practice in MTL to compare against the tradi-
tional STL and MTL baselines. The STL baseline involves
using a single network for each task, where each network
uses a comparable backbone and output heads as the proposed
model for a fair comparison. The MTL baseline uses a hard
parameter sharing network [Vandenhende et al., 2022], which
involves sharing the backbone layers across all tasks, and then
feeding the shared feature representation to each task-specific
output head. To make these baselines even more competi-
tive, and to be consistent with the state-of-the-art [Vanden-
hende et al., 2020], we equip them with a high-resolution
network backbone (HRNet18) [Wang et al., 2020] to gener-
ate multi-scale features that are processed by scale-specific
output heads and aggregated for the final outputs.
Since we are proposing a novel cross-task attention learn-
ing mechanism for CNN-based architectures, we must com-
pare with the current best approaches in this domain. There-
fore, we will be evaluating against PAD-Net and PAP-Net,
which will serve as the EM attention and MM attention base-
lines, respectively. Additionally, they also serve as our single-
scale baselines. Next, we will also compare against MTI-Net,
since it is the current state-of-the-art for CNN-based decoder-
focused models. This will serve as our multi-scale baseline.
All experiments for our models and the baselines are per-
formed 3 times using a different seed for each experiment.
The same set of 3 seeds is used across all models for con-
sistency. The results in all tables contain the average of the
converged values across all 3 experiments for each model.
4.4
Implementation Details
Networks: EMA-Net and all baselines are equipped with
a pre-trained HRNet18 [Wang et al., 2020] multiscale fea-
NYUv2
Cityscapes
Sem. Seg.
Depth
Normals
∆m ↑
Sem. Seg.
Depth
∆m ↑
Model
mIoU ↑ pixAcc ↑
relErr ↓ mErr ↓
mErr ↓ 11.25 ↑ 22.5 ↑
30 ↑
mIoU ↑
relErr ↓
STL
49.23
72.83
0.1636
0.3853
23.15
35.18
62.50
73.48
+0.00
48.89
29.91
+0.00
MTL
49.25
72.90
0.1658
0.3896
24.16
30.80
57.92
70.41
-1.89
49.78
31.80
-2.25
PAP-Net
50.00
73.25
0.1615
0.3876
23.78
31.90
58.89
71.22
+0.04
50.82
26.97
+6.89
PAD-Net
50.23
73.46
0.1622
0.3814
23.63
32.44
59.51
71.68
+0.27
50.67
27.37
+6.07
EMA-Net (SS)
51.59
74.14
0.1607
0.3808
22.84
35.14
62.06
73.40
+2.64
51.36
23.84
+12.67
MTI-Net
51.51
74.50
0.1538
0.3650
23.50
34.16
60.85
72.31
+3.04
51.77
29.90
+2.96
EMA-Net (MS)
52.70
75.09
0.1529
0.3630
22.99
35.59
62.25
73.28
+4.76
51.94
22.89
+14.85
Table 1: Validation set performance taken across all tasks on NYUv2 and Cityscapes. Values in bold indicate the best value in a given column
for multitask models in SS and MS configurations.
ture extractor backbone. The single-scale variants of EMA-
Net and the baselines will use a fused version of the input
features following the aforementioned CSF procedure. The
output heads for the initial predictions include two residual
blocks [He et al., 2016] followed by an output convolution
layer. The initial predictions used for task-prediction distil-
lation are the outputs of the second residual block. The final
output heads for the single-scale models use the same archi-
tecture as the heads used for the initial predictions. For multi-
scale baselines, we up-sample all outputs to 1/4 input scale,
concatenate them along the channel dimension, and process
them through a two-layer convolution block to get the final
predictions. The implementation code for all baseline net-
works is taken from [Vandenhende et al., 2020], except for
PAP-Net which we implemented ourselves.
Hyper-parameters:
We train our models using an
Adam [Kingma and Ba, 2014] optimizer with a weight decay
of 1×10−4. The learning rates are 1×10−4 and 5×10−4 for
NYUv2 and Cityscapes respectively. We performed a small
learning rate search for each model to ensure that this config-
uration was favourable for all baselines. We also use a cosine
annealing learning rate scheduler for smooth convergence.
Multi-scale models tend to converge early for Cityscapes, so
for them, we used a cosine annealing learning rate scheduler
with warm restarts [Loshchilov and Hutter, 2016] to promote
exploration and escape local minima. For both datasets, we
use a batch size of 8, a blending factor γ = 0.05 (like PAP-
Net) and filter size f = 3 for all our models. The values for γ
and f were not tuned for each dataset, and our models show
little sensitivity to these parameters (see appendix). We train
for 200 and 75 epochs on NYUv2 and Cityscapes respectively
using a single NVIDIA RTX A5000 GPU.
5
Results
5.1
Ablation Study
To observe the effects of CTAL in our SS and MS configu-
rations, we first evaluate the performance of the base EMA-
Net architecture without CTAL or the CSF blocks. There-
fore, it only contains a single projection layer for the ini-
tial prediction features and the corresponding task-specific
decoder heads. Next, we evaluate the performance change
from adding CTAL in the single-scale variation, and then with
cross-scale fusion in the multi-scale variation. As we can
NYUv2
Cityscapes
Model
Sem. Seg. Depth Normals ∆m ↑ Sem. Seg. Depth ∆m ↑
mIoU ↑
relErr ↓ mErr ↓
mIoU ↑
relErr ↓
STL
49.23
0.1636
23.15
+0.00
48.89
29.91
+0.00
EMA-Net (Base)
50.01
0.1634
23.65
-0.15
50.33
26.92
+6.47
+CTAL
51.59
0.1607
22.84
+2.64
51.36
23.84 +12.67
+CTAL+CSF
52.70
0.1529
22.99
+4.76
51.94
22.89 +14.85
Table 2: Effectiveness of the different configurations of EMA-Net
for both NYUv2 and Cityscapes datasets.
see in Table 2, EMA-Net without CTAL does not outperform
the STL baseline for NYUv2 and achieves a +6.47% MTL
gain on Cityscapes. Adding CTAL, we can see a +2.64% and
+12.67% improvement in the MTL gain for each dataset com-
pared to the STL baseline. Finally, having CTAL with deep
supervision at multiple scales with CSF, we see further MTL
gains with +4.76% and +14.85% on NYUv2 and Cityscapes
respectively. Overall, we see large MTL gains across both
datasets using our SS and MS configurations.
5.2
Comparison to State-of-the-Art
Table 1 shows the results of EMA-Net SS and MS against
all our baselines. The tables are divided into 3 sections to
separate the traditional STL and MTL baselines, the SS mod-
els, and the MS models. As we can see, for both datasets,
we achieve considerably higher performance for all task met-
rics in SS and MS configurations. We can even see that our
EMA-Net (SS) is competitive to MTI-Net in NYUv2 despite
being at a disadvantage by not having deep supervision on
task predictions from multiple scales. On Cityscapes, we can
also see that MTI-Net struggles in the simpler 2-task setting
with smaller input image scales. The results of MTI-Net have
likely not been reported previously on Cityscapes as it is sus-
ceptible to overfitting. Despite our efforts to mitigate over-
fitting (i.e. spatial dropout, warm restart scheduler, data aug-
mentation, architectural modifications, hyperparameter tun-
ing), we were unable to achieve better performance than what
is seen in Table 1. However, our EMA-Net (MS), which also
employs deep supervision on multiscale initial predictions,
does not exhibit the same overfitting behaviour. In fact, we
further improve performance over EMA-Net (SS).
Since this study targets light-weight CNN-based ap-
proaches, we do not compare with the transformer-based
models in this parameter regime. However, we would like to
note that when equipped with comparable Transformer back-
bones, the current CNN-based baselines perform very simi-
larly to the InvPT and TaskPrompter [Ye and Xu, 2023].
5.3
Resource Analysis
As mentioned earlier, the trade-off for using significantly
fewer model parameters is that we introduce additional
FLOPs. We argue in favor of this trade-off because there are
more optimization opportunities at various levels to reduce
the effect of additional FLOPs compared to model parame-
ters. For example, we can optimize algorithmically [Fawzi
et al., 2022], improve hardware utilization [Kljucaric and
George, 2023], leverage sparse matrix operations [Gao et al.,
2023] (if applicable), and manipulate feature scales. Table 3
summarizes the resources used for each model on NYUv2
and we can see that we drastically reduce the number of
FLOPs by simply reducing the scale at which we perform task
prediction distillation. We also see that we can easily reduce
the wall clock time to be on par or lower than other methods.
We observe that in the SS setting, we outperform PAD-Net
with less than half the number of parameters and with even
fewer FLOPs. In the MS setting, we use fewer model param-
eters and still achieve better multitasking performance, even
with smaller feature scales.
Model
Scale
Rel
FLOPs Time (s) ∆m ↑
Param.
MTL
1/4
0.346
42G
2.82
-1.89
PAP-Net
1/4
0.404
521G
17.73
+0.04
PAD-Net
1/4
1.023
484G
6.13
+0.27
EMA-Net (SS)
1/4
0.513
537G
13.85
+2.64
1/6
0.504
194G
5.97
+1.70
1/8
0.500
124G
4.37
+1.50
MTI-Net
1/4
1.070
65G
4.45
+3.04
EMA-Net (MS)
1/4
0.944
525G
14.26
+4.76
1/6
0.935
190G
6.48
+3.62
1/8
0.932
117G
5.23
+3.43
Table 3: Resource analysis of SS and MS models on NYUv2.
“Scale” represents the highest feature scale used for task-prediction
distillation. “Rel Param.” represents the number of parameters rela-
tive to the STL baseline. “FLOPs” represents the number of floating-
point operations used in a forward pass. “Time” refers to the wall
clock time required to process the entire validation set in seconds.
Finally, “∆m” represents the MTL gain relative to the STL base-
line.
Overall, the results demonstrate several efficiency benefits
from our proposed method. This can be attributed to how
we organize the features to allow for more efficient param-
eter usage. This also reduces the risk of overfitting, as seen
in the results of the Cityscapes dataset. In general, as the
trend of using more model capacity for better performance
persists, we must be more conscious of how we can optimize
efficiency so that these models can be deployed in real-world
settings with much stricter memory limitations [Menghani,
2023].
Figure 4: A visual comparison of the predictions from the single
task baseline (STL) and EMA-Net (Ours). The two images and the
ground truths (GT) are from the validation set of NYUv2.
5.4
Qualitative Analysis
Figure 4 is a visualization of the predictions of our EMA-Net
(MS) and the STL baseline on images from the validation
set of NYUv2. As we can see, our model produces signif-
icantly fewer artifacts in the segmentation maps. Also, our
model generates smoother and more granular depth and sur-
face normal maps compared to STL. For instance, we can see
our model doesn’t warp structures as much as STL, as seen
for the cabinets in the second image. Also, our model gen-
eralizes better in undefined regions of the depth and normals
tasks, like for the window in the first image.
6
Conclusion
We proposed our EMA-Net multitask architecture, incorpo-
rating the novel CTAL module for task prediction distillation.
Our network is the first CNN-based architecture that can ex-
plicitly and exhaustively model all feature-pair relationships
intra- and inter-task. Impressively, we accomplish this using
significantly fewer model parameters than competing STL
and MTL models while achieving better multitasking perfor-
mance on complex indoor and outdoor scenes. We have also
demonstrated that by adjusting our feature scale, we can sig-
nificantly reduce the number of FLOPs we introduce while
still outperforming competitors at higher feature scales. As
mentioned, we believe that the performance improvements
with the massive reduction in model parameters justify the
additional FLOPs, especially since there are more opportu-
nities for optimization compared to reducing model capac-
ity. Looking ahead, exploring techniques to further mitigate
the impact of FLOPs on wall-clock time, such as sparsifying
affinity matrices, would be intriguing.
References
[Br¨uggemann et al., 2021] David Br¨uggemann,
Menelaos
Kanakis, Anton Obukhov, Stamatios Georgoulis, and Luc
Van Gool.
Exploring relational context for multi-task
dense prediction.
In Proceedings of the IEEE/CVF in-
ternational conference on computer vision, pages 15869–
15878, 2021.
[Caruana, 1997] Rich Caruana. Multitask learning. Machine
learning, 28(1):41–75, 1997.
[Chen et al., 2018] Zhao
Chen,
Vijay
Badrinarayanan,
Chen-Yu Lee, and Andrew Rabinovich.
Gradnorm:
Gradient normalization for adaptive loss balancing in
deep multitask networks. In International conference on
machine learning, pages 794–803. PMLR, 2018.
[Chollet, 2017] Francois Chollet. Xception: Deep learning
with depthwise separable convolutions.
In Proceedings
of the IEEE conference on computer vision and pattern
recognition, pages 1251–1258, 2017.
[Cordts et al., 2016] Marius Cordts, Mohamed Omran, Se-
bastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo
Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
The cityscapes dataset for semantic urban scene under-
standing. In Proc. of the IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), 2016.
[Dosovitskiy et al., 2020] Alexey Dosovitskiy, Lucas Beyer,
Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias Min-
derer, Georg Heigold, Sylvain Gelly, et al. An image is
worth 16x16 words: Transformers for image recognition
at scale. arXiv preprint arXiv:2010.11929, 2020.
[Eigen and Fergus, 2015] David Eigen and Rob Fergus. Pre-
dicting depth, surface normals and semantic labels with a
common multi-scale convolutional architecture. In Pro-
ceedings of the IEEE international conference on com-
puter vision, pages 2650–2658, 2015.
[Fawzi et al., 2022] Alhussein Fawzi,
Matej Balog,
Aja
Huang, Thomas Hubert, Bernardino Romera-Paredes, Mo-
hammadamin Barekatain, Alexander Novikov, Francisco J
R Ruiz, Julian Schrittwieser, Grzegorz Swirszcz, et al.
Discovering faster matrix multiplication algorithms with
reinforcement learning. Nature, 610(7930):47–53, 2022.
[Fu et al., 2019] Jun Fu, Jing Liu, Haijie Tian, Yong Li,
Yongjun Bao, Zhiwei Fang, and Hanqing Lu.
Dual at-
tention network for scene segmentation. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition, pages 3146–3154, 2019.
[Gao et al., 2019] Yuan Gao, Jiayi Ma, Mingbo Zhao, Wei
Liu, and Alan L Yuille. Nddr-cnn: Layerwise feature fus-
ing in multi-task cnns by neural discriminative dimension-
ality reduction. In Proceedings of the IEEE/CVF confer-
ence on computer vision and pattern recognition, pages
3205–3214, 2019.
[Gao et al., 2023] Jianhua Gao, Weixing Ji, Fangli Chang,
Shiyu Han, Bingxin Wei, Zeming Liu, and Yizhuo Wang.
A systematic survey of general sparse matrix-matrix mul-
tiplication. ACM Computing Surveys, 55(12):1–36, 2023.
[He et al., 2016] Kaiming He, Xiangyu Zhang, Shaoqing
Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 770–778, 2016.
[Kendall et al., 2018] Alex Kendall, Yarin Gal, and Roberto
Cipolla. Multi-task learning using uncertainty to weigh
losses for scene geometry and semantics. In Proceedings
of the IEEE conference on computer vision and pattern
recognition, pages 7482–7491, 2018.
[Kingma and Ba, 2014] Diederik P Kingma and Jimmy Ba.
Adam:
A method for stochastic optimization.
arXiv
preprint arXiv:1412.6980, 2014.
[Kljucaric and George, 2023] Luke Kljucaric and Alan D
George. Deep learning inferencing with high-performance
hardware accelerators. ACM Transactions on Intelligent
Systems and Technology, 14(4):1–25, 2023.
[Liu et al., 2019] Shikun Liu, Edward Johns, and Andrew J
Davison. End-to-end multi-task learning with attention.
In Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition, pages 1871–1880, 2019.
[Liu et al., 2022] Shikun Liu, Stephen James, Andrew J
Davison, and Edward Johns.
Auto-lambda:
Disen-
tangling dynamic task relationships.
arXiv preprint
arXiv:2202.03091, 2022.
[Loshchilov and Hutter, 2016] Ilya Loshchilov and Frank
Hutter.
Sgdr: Stochastic gradient descent with warm
restarts. arXiv preprint arXiv:1608.03983, 2016.
[Maninis et al., 2019] Kevis-Kokitsi
Maninis,
Ilija
Ra-
dosavovic, and Iasonas Kokkinos. Attentive single-tasking
of multiple tasks. In Proceedings of the IEEE/CVF con-
ference on computer vision and pattern recognition, pages
1851–1860, 2019.
[Menghani, 2023] Gaurav Menghani. Efficient deep learn-
ing: A survey on making deep learning models smaller,
faster, and better. ACM Computing Surveys, 55(12):1–37,
2023.
[Misra et al., 2016] Ishan Misra, Abhinav Shrivastava, Ab-
hinav Gupta, and Martial Hebert. Cross-stitch networks
for multi-task learning. In Proceedings of the IEEE con-
ference on computer vision and pattern recognition, pages
3994–4003, 2016.
[Nathan Silberman and Fergus, 2012] Pushmeet
Kohli
Nathan Silberman, Derek Hoiem and Rob Fergus. Indoor
segmentation and support inference from rgbd images. In
ECCV, 2012.
[Sandler et al., 2018] Mark Sandler, Andrew Howard, Men-
glong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.
Mobilenetv2: Inverted residuals and linear bottlenecks. In
Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 4510–4520, 2018.
[Sinodinos and Armanfard, 2022] Dimitrios Sinodinos and
Narges Armanfard. Attentive task interaction network for
multi-task learning. In 2022 26th International Conference
on Pattern Recognition (ICPR), pages 2885–2891. IEEE,
2022.
[Vandenhende et al., 2020] Simon Vandenhende, Stamatios
Georgoulis, and Luc Van Gool. Mti-net: Multi-scale task
interaction networks for multi-task learning. In Computer
Vision–ECCV 2020: 16th European Conference, Glasgow,
UK, August 23–28, 2020, Proceedings, Part IV 16, pages
527–543. Springer, 2020.
[Vandenhende et al., 2022] Simon Vandenhende, Stamatios
Georgoulis, Wouter Van Gansbeke, Marc Proesmans,
Dengxin Dai, and Luc Van Gool. Multi-task learning for
dense prediction tasks: A survey. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 44(7):3614–
3633, 2022.
[Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia Polosukhin. Attention is all you
need. Advances in neural information processing systems,
30, 2017.
[Wang et al., 2020] Jingdong Wang,
Ke Sun,
Tianheng
Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu,
Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep
high-resolution representation learning for visual recogni-
tion. IEEE transactions on pattern analysis and machine
intelligence, 43(10):3349–3364, 2020.
[Woo et al., 2018] Sanghyun Woo, Jongchan Park, Joon-
Young Lee, and In So Kweon. Cbam: Convolutional block
attention module. In Proceedings of the European confer-
ence on computer vision (ECCV), pages 3–19, 2018.
[Xie et al., 2017] Saining Xie, Ross Girshick, Piotr Doll´ar,
Zhuowen Tu, and Kaiming He. Aggregated residual trans-
formations for deep neural networks. In Proceedings of the
IEEE conference on computer vision and pattern recogni-
tion, pages 1492–1500, 2017.
[Xin et al., 2022] Derrick Xin, Behrooz Ghorbani, Justin
Gilmer, Ankush Garg, and Orhan Firat.
Do current
multi-task optimization methods in deep learning even
help?
Advances in Neural Information Processing Sys-
tems, 35:13597–13609, 2022.
[Xu et al., 2018] Dan Xu, Wanli Ouyang, Xiaogang Wang,
and Nicu Sebe. Pad-net: Multi-tasks guided prediction-
and-distillation network for simultaneous depth estimation
and scene parsing. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 675–
684, 2018.
[Ye and Xu, 2022] Hanrong Ye and Dan Xu. Inverted pyra-
mid multi-task transformer for dense scene understanding.
In ECCV, 2022.
[Ye and Xu, 2023] Hanrong Ye and Dan Xu. Taskprompter:
Spatial-channel multi-task prompting for dense scene un-
derstanding. In ICLR, 2023.
[Zhang et al., 2019] Zhenyu Zhang, Zhen Cui, Chunyan Xu,
Yan Yan, Nicu Sebe, and Jian Yang.
Pattern-affinitive
propagation across depth, surface normal and semantic
segmentation. In Proceedings of the IEEE/CVF confer-
ence on computer vision and pattern recognition, pages
4106–4115, 2019.
","A foundational decoder-focused method, PAP-Net, introduces the notion of “task affinity,” which is a measure of similarity between pairs of features for a given task. Specifically, they construct affinity matrices to store the similarity information between every possible pair of features for a given task. The benefit of working with affinity matrices is that they capture long-range dependencies and introduce very few additional model parameters. To perform task prediction distillation, they combine affinity matrices from all tasks using a weighted sum, and then diffuse this similarity information into the features of each initial task prediction. However, there are limitations in this approach. Learning a single weight per affinity matrix suggests that all pairwise similarity patterns in the feature space are equally important. However, we hypothesize that cross-task patterns are nuanced and vary in importance throughout the feature space. A more recent work, MTI-Net, claims that tasks with high affinities at a certain feature scale are not guaranteed to have high affinities at different scales. Consequently, they model task interactions at multiple scales to perform “multi-scale multi-modal distillation,” which significantly improves performance. However, this performance improvement comes at the cost of additional parameters for deep supervision at multiple scales; which makes this approach susceptible to overfitting on simpler datasets. InvPT and TaskPrompter continue the trend of improving performance with more model capacity by moving away from the CNN architecture for one based on the Vision Transformer (ViT). They argue that current multitask attention mechanisms in CNN-based models have limited scope in their cross-task pattern modelling. Their multitask attention methods can capture local, global, and cross-task relationships, but mainly because they operate on more compressed features as a consequence of using feature extractors with significantly higher parameter budgets. Despite their recent success, current decoder-focused methods have yet to address three issues. We solve all of these issues by introducing the Efficient Multitask Affinity Learning Network (EMA-Net), which uses our novel Cross-Task Affinity Learning (CTAL) module for improved task prediction distillation.nan"
"We propose a lightweight uncertainty-aware information propagation based Mobile-Former network for efficient pattern recognition, which aggregates the MobileNet and Transformer network effectively. Extensive experiments on multiple event-based recognition datasets fully validated the effectiveness of our model.","Mainstream human activity recognition (HAR) algorithms are developed based on RGB cameras, which are easily influenced by low-quality images (e.g., low illumination, motion blur). Meanwhile, the privacy protection issue caused by ultra-high definition (HD) RGB cameras aroused more and more people’s attention. Inspired by the success of event cameras which perform better on high dynamic range, no motion blur, and low energy consumption, we propose to recognize human actions based on the event stream.","We first stack the event streams into multiple event images due to their simplicity and effectiveness. Specifically, we first split the event streams into a fixed number of tensor tubes Ti, i ₂ {1, 2, ..., M}, then, each split is transformed into one event frame Fi, i ₂ {1, 2, ..., M}. The obtained event images are visualized in Fig. 3.
After we get the event images, we resize them into a fixed resolution 224 × 224 and design a StemNet to project them into feature embeddings.","On this benchmark dataset, our proposed method achieves 0.999, which is a new SOTA performance. The compared method M-LSTM which adopts learnable event representation is still inferior to our method. Some graph-based event recognition models are also worse than ours, including EV-VGCNN, VMV-GCN, and Ev-Gait-3DGraph. Therefore, we can draw the conclusion that our proposed lightweight model is effective for event-based pattern recognition.","In this work, we propose to recognize objects based on the event streams. we propose a lightweight uncertainty-aware information propagation based Mobile-Former network for efficient pattern recognition, which aggregates the MobileNet and Transformer network effectively. Extensive experiments on multiple event-based recognition datasets fully validated the effectiveness of our model. In our future works, we will consider a knowledge distillation strategy to further enhance the final recognition performance.",Uncertainty-aware Bridge based Mobile-Former Network for Event-based Pattern Recognition,"Haoxiang Yang, Chengguo Yuan, Yabin Zhu, Lan Chen, Xiao Wang, Jin Tang","Uncertainty-aware Bridge based Mobile-Former Network for
Event-based Pattern Recognition
Haoxiang Yang†1, Chengguo Yuan†1, Yabin Zhu1,2, Lan Chen2, Xiao Wang1, Jin Tang1
1 School of Computer Science and Technology, Anhui University, Hefei 230601, China
2 School of Electronic and Information Engineering, Anhui University, Hefei 230601, China
Abstract— The
mainstream
human
activity
recognition
(HAR) algorithms are developed based on RGB cameras, which
are easily influenced by low-quality images (e.g., low illumi-
nation, motion blur). Meanwhile, the privacy protection issue
caused by ultra-high definition (HD) RGB cameras aroused
more and more people’s attention. Inspired by the success of
event cameras which perform better on high dynamic range,
no motion blur, and low energy consumption, we propose to
recognize human actions based on the event stream. We pro-
pose a lightweight uncertainty-aware information propagation
based Mobile-Former network for efficient pattern recognition,
which aggregates the MobileNet and Transformer network
effectively. Specifically, we first embed the event images using
a stem network into feature representations, then, feed them
into uncertainty-aware Mobile-Former blocks for local and
global feature learning and fusion. Finally, the features from
MobileNet and Transformer branches are concatenated for
pattern recognition. Extensive experiments on multiple event-
based recognition datasets fully validated the effectiveness of
our model. The source code of this work will be released at
https://github.com/Event-AHU/Uncertainty aware MobileFormer.
I. INTRODUCTION
Human Activity Recognition (HAR) is one of computer
vision’s most critical tasks and developed significantly in
recent years [1], [23] with the help of deep learning. Usually,
these models are designed for video frames captured using
RGB cameras and are widely used in practical applications.
For example, we can achieve pre-prevention, in-process
monitoring, and post-inspection in security monitoring field,
intelligent referee in sports through the analysis of human
behavior. Although the RGB cameras based HAR works
well in simple scenarios, however, the issues caused by its
imaging quality may limit the applications of HAR severely,
such as low illumination and fast motion. On the other hand,
the privacy protection is also widely discussed in the human-
centered research. Awkwardly, the ethical problems caused
by high-quality data and the data quality problems caused
by low-quality video both require new behavior recognition
paradigms.
Recently, the event camera (also termed Dynamic Vision
Sensors, DVS) which is a bio-inspired sensor draws more
and more attention from researchers [41] [42] [40]. Different
from the RGB camera which records the scene into video
frames in a synchronous way, each pixel in the event camera
is triggered asynchronously by saving an event point if and
† The first two authors contribute equally to this work.
• Extensive experiments conducted on multiple widely
used event-based recognition benchmark datasets fully
demonstrate the effectiveness of the proposed model.
II. RELATED WORK
In this section, we will introduce the related works about
Event-based Recognition and Uncertainty-aware Learning.
A. Event-based Recognition
Current works can be divided into three streams for the
event-based recognition, including the CNN based [43], SNN
based [15], [13], GNN based models [4], [5], due to the
flexible representation of event streams. For the CNN based
models, Wang et al. [43] propose to identify human gaits
using event camera and design a CNN model for recognition.
As the third generation of neural networks, the SNN is
also adopted to encode the event stream for energy-efficient
recognition. To be specific, Peter et al. [11] propose the
weight and threshold balancing method to achieve efficient
ANN-to-SNN conversion. Nicolas et al. [32] propose a sparse
backpropagation method for SNNs and achieve faster and
more memory efficient.
For the point cloud based representation, Wang et al. [39]
treat the event stream as space-time event clouds and adopt
PointNet [33] as their backbone for gesture recognition. Sai
et al. propose the event variational auto-encoder (eVAE) [37]
to achieve compact representation learning from the asyn-
chronous event points directly. Fang et al. [14] propose SEW
(spike-element-wise) residual learning for deep SNNs which
addresses the vanishing/exploding gradient problems effec-
tively. Meng et al. [29] propose an accurate and low latency
SNN based on the Differentiation on Spike Representation
(DSR) method. TORE [2] is short for Time-Ordered Recent
Event (TORE) volumes, which compactly stores raw spike
timing information. VMV-GCN [48] is proposed by Xie et al.
which is a voxel-wise graph learning model to fuse multi-
view volumetric. Li et al. [26] introduce the Transformer
network to learn event-based representation in a native vec-
torized tensor way. Different from these works, in this paper,
we design a novel uncertainty-aware MobileFormer network
that effectively aggregates the CNN and Transformer.
B. Uncertainty-aware Learning
Uncertainty-aware learning is widely exploited in machine
learning and computer vision tasks. Specifically, [25] pro-
pose a dual uncertainty-aware pseudo-labeling method for
self-training to achieve knowledge transfer. [38] propose
an uncertainty-aware clustering framework for unsupervised
domain adaptive task. Qin et al. [34] adopts an uncertainty-
aware method for federated Open set domain adaptation
algorithm to generate a global model from all client models.
Fang et al. [16] propose a novel uncertainty-aware salient ob-
ject detection model, which use multiple supervision signals
to teach the networks not only to focus on saliency regions
but also pixels surrounding the contour of salient objects.
Zhang et al. [50] propose a unified blind image quality as-
sessment (BIQA) model and also propose a hinge constraint
to regularize uncertainty estimation when optimizing their
model. Le et al. [24] propose an uncertainty-aware label
distribution learning approach for the improvement of the
robustness of deep models against uncertainty and ambiguity
for facial expression recognition. Different from existing
works, we model the message propagation between CNN
and Transformer networks using an uncertainty-aware learn-
ing approach which further improves the final recognition
performance.
III. METHODOLOGY
A. Overview
As shown in Fig. 1, given the event streams, we first stack
them into event images and extract their features using Stem-
Net. The uncertainty-aware MobileFormer block is proposed
and stacked as the backbone network. Specifically, we adopt
the MobileNet as the CNN branch to extract the local features
and utilize the Transformer to model the long-range relations.
Note that, the Transformer takes the randomly initialized
tokens as the input. To boost the interaction between the
dual branches, we propose a novel uncertainty-aware bridge
module to control the message passing. For the feature flows
from CNN to the Transformer branch, we propose two MLPs
to predict the Gaussian distribution using the output mean
and variance values. Then, we sample a feature vector from
the Gaussian distribution via re-parameterization tricks and
aggregate it with the input of Transformer branch using
cross-attention mechanism. Similar operations are conducted
for the controllable information flow from the Transformer to
CNN branch. The output of CNN and Transformer branches
of the last uncertainty-aware Mobile-Former block are con-
catenated as the final feature representation. A classification
head consisting of two dense layers is used for classification.
B. Network Architecture
Input Representation and Embedding.
Each point in
the event stream E is usually represented as a tuple e =
{x, y, t, p}, where x, y are spatial coordinates, t is the
timestamp, and p denotes the polarity (e.g., +1 and -1 denotes
positive and negative event point). In this work, we stack
the event streams into multiple event images due to their
simplicity and effectiveness. Specifically, we first split the
event streams into a fixed number of tensor tubes Ti, i ∈
{1, 2, ..., M}, then, each split is transformed into one event
frame Fi, i ∈ {1, 2, ..., M}. The obtained event images are
visualized in Fig. 3.
After we get the event images, we resize them into a fixed
resolution 224 × 224 and design a StemNet to project them
into feature embeddings. Specifically, a 3D convolutional
layer (kernel size: 3 × 3 × 3) is proposed to achieve this
embedding and get feature maps Femb ∈ R4×112×112×24.
Uncertainty-aware Bridge based Mobile-Former.
Given
the feature embeddings of event streams, we design a
novel uncertainty-aware Mobile-Former network that con-
sists of lightweight mobile layers, Transformer layers, and
uncertainty-aware bridge (UA-Bridge) modules. As shown in
Fig. 1, the event feature embeddings are fed into a 1 × 1 × 1
Fig. 1: An overview of our proposed uncertainty-aware
bridge based Mobile-Former framework for event-based pat-
tern recognition.
3D convolutional layer and dynamic ReLU (DY-ReLU) layer.
Then, two depth-wise 3D convolutional layers (kernel size:
3 × 3 × 3) are utilized for local feature mining. The output
will pass through a new DY-ReLU layer and two 1 × 1 × 1
3D convolutional layers. Note that, the local feature learning
in the MobileNet branch also considers the information from
the Transformer branch by dynamically updating the ReLU
layer.
The input feature embeddings are also passed into the
UA-Bridge module which contains two MLPs for Gaussian
distribution estimation. This module will adaptively control
the message propagation between the dual branches. Mathe-
matically, the mean and the variance of the predicted message
passing can be written as:
µ = MLP1(Femb),
σ = MLP2(Femb)
(1)
Then, a multi-variate Gaussian distribution can be built using
the predicted mean and variance. The filtered features Fmf
from MobileNet to Transformer branch can be sampled
from the Gaussian distribution using the reparameterization
trick [22]:
Fmf = µ + ε ∗ σ,
ε ∼ N(0, I)
(2)
After that, we adopt a cross-attention layer to aggregate the
Fmf with Transformer tokens Zi, i = {1, 2, ..., N}, which
can be formulated as:
CrossAtten(Q, K, V ) = softmax(QKT
√
d
)V.
(3)
where d is the dimension of input feature vectors. For the
cross-attention from MobileNet to Transformer, in our case,
the Fmf is reshaped into a feature vector and treated as
Query (Q) and Key (K), and Zi is the Value (V ). For the
opposite direction, the global tokens of Transformer are used
as the Query and Key and the local CNN features are the
Value.
For the Transformer branch, we take the randomly initial-
ized tokens as the input and fuse them with CNN features
using a cross-attention layer as mentioned above. Then, the
standard multi-head self-attention (MHSA) and feed-forward
networks are adopted for long-range global feature learning.
The output tokens will be used for parameter updating in the
ReLU layer and also the UA-Bridge module for aggregation
with CNN features. Similar operations are also conducted in
subsequent Mobile-Former blocks.
Classification Head and Loss Function. The local features
and global features from CNN and Transformer blocks
are concatenated and fed into two fully connected layers
for pattern recognition. The cross entropy-loss function is
adopted for the training of our whole framework in an end-
to-end manner which can be formulated as:
Loss = − 1
B
B
X
b=1
N
X
n=1
YbnlogPbn
(4)
where B denotes the batch size, Ndenotes the number of
event classes. Y
and P represent the ground truth and
predicted class labels of the event sample, respectively.
IV. EXPERIMENTS
A. Dataset and Evaluation Metric
In this paper, our experiments are conducted on the
ASL-DVS [5], N-Caltech101 [30], DVS128-Gait-Day [46]
dataset. The top-1 accuracy is adopted as the evaluation
metric for the evaluation of our proposed model and other
SOTA pattern recognition algorithms.
B. Implementation Details
Our proposed lightweight uncertainty-aware bridge based
Mobile-Former framework can be optimized in an end-to-
end manner. The learning rate and weight decay are set as
0.0001 and 0.1, respectively. The AdamW [27] is selected
as the optimizer and trained for a total of 60 epochs. In our
implementations, 12 blocks are stacked as our backbone net-
work. For the input of the Transformer branch, we randomly
initialized 6 tokens and also tested other settings which will
be discussed in experiments. We select 8 event frames as
the input of MobileNet branch. Our code is implemented
based on PyTorch [31] framework and the experiments are
conducted on a server with GPU V100.
C. Comparison with Other SOTA Algorithms
Results on ASL-DVS [5].
As shown in Table I, our
proposed method achieves 99.9% on this benchmark dataset
which is a new SOTA performance. The compared method
M-LSTM which adopts learnable event representation is still
inferior to our method. Some graph-based event recognition
models are also worse than ours, including EV-VGCNN,
VMV-GCN, and Ev-Gait-3DGraph. Therefore, we can draw
the conclusion that our proposed lightweight model is effec-
tive for event-based pattern recognition.
TABLE I: Results on the ASL-DVS dataset.
EST
[18]
AMAE
[10]
M-LSTM
[3]
MVF-Net
[9]
EventNet
[35]
0.979
0.984
0.980
0.971
0.833
RG-CNNs
[5]
EV-VGCNN
[8]
VMV-GCN
[49]
EV-Gait-3DGraph
[44]
Ours
0.901
0.983
0.989
0.738
0.999
Results on N-Caltech101 [30].
As shown in Table II,
our model achieves 0.798 on the top-1 accuracy on this
benchmark dataset which is significantly better than the
compared methods. To be specific, our model outperforms
the ResNet50 by +16.1% on the top-1 metric and beats the
VMV-GCN by +2% which ranks the second place. Thanks to
the uncertainty-aware local and global feature learning, our
model achieves superior performance which fully validated
its effectiveness.
TABLE II: Results on N-Caltech101 dataset.
EventNet
[35]
Gabor-SNN
[36]
RG-CNNs
[5]
VMV-GCN
[49]
EV-VGCNN
[8]
EST
[18]
0.425
0.196
0.657
0.778
0.748
0.753
ResNet-50
[28]
MVF-Net
[9]
M-LSTM
[3]
AMAE
[10]
HATS
[36]
Ours
0.637
0.687
0.738
0.694
0.642
0.798
Results on DVS128-Gait-Day [46]. This dataset is specifi-
cally proposed for human gait recognition by Wang et al., as
shown in Table III, we can find that the EVGait-3DGraph
already achieves 94.9% on this dataset. In contrast, our
proposed method obtains 95.9% which is better than this
3D graph based recognition model. The superior results on
this dataset fully demonstrate that our model works well on
event-based recognition.
TABLE III: Results on the DVS128-Gait-Day dataset.
EVGait-3DGraph [44]
2DGraph-3DCNN [5]
EV-Gait-IMG [45]
94.9
92.2
87.3
LSTM-CNN [47]
SVM-PCA [20]
Ours
86.5
78.05
95.9
D. Ablation Study
To help the readers better understand the effectiveness
of aggregating MobileNet and Transformer branches, as
shown in Table IV, we isolate these components separately
to validate their effectiveness. To be specific, when only
MobileNet or Transformer is used for recognition, the results
are 76.53% and 58.01%, respectively. When both branches
are aggregated using the cross-attention mechanism, the
results can be improved to 76.83%, which demonstrates that
it is effective when fusing the local and global features for
event-based recognition. For the ReLU activation layer, it is
possible to predict its parameters using MLPs in an online
manner to attain greater flexibility and robustness. We can
find that the results can be improved to 77.94% when the
dynamic ReLU (DY-ReLU) is adopted.
In this work, we exploit the uncertainty-aware message
propagation between MobileNet and Transformer branch to
achieve effective feature aggregation. As shown in Table IV,
we can find that the results can be improved to 79.80%
when this module is adopted. This experiment fully validated
the effectiveness of controllable information propagation for
event-based recognition.
E. Parameter Analysis
When building our network, there are multiple flexible
design choices that can enhance the final recognition results.
TABLE IV: Component analysis on N-Caltech101 dataset.
UAB and CA denote the Uncertainty-aware Bridge and Cross
Attention module, respectively.
No.
Mobile
Former
UAB
CA
DY-ReLU
Results
1
✓
76.53
2
✓
58.01
3
✓
✓
✓
76.83
4
✓
✓
✓
✓
77.94
5
✓
✓
✓
✓
✓
79.80
Fig. 2: Ablation study on parameter analysis.
This section will explore the following aspects and report
the corresponding results on N-Caltech101 dataset in Fig. 2.
1). Number and Dimension of input tokens for Transformer:
We changed the dimension of input tokens into multiple
versions, including 64, 128, 192, and 256. From Fig. 2 (a),
it is easy to find that the best performance can be achieved
when the 192 is used. For the number of input tokens, we
set it as 1, 3, 6, 9, and the corresponding results are 74.56,
76.47, 79.85, 73.72 on the top-1 accuracy, as shown in Fig. 2
(b).
2). Number of input frames for MobileNet: We try to input
4, 8, and 12 event frames into the MobileNet branch, and the
corresponding results are 78.16, 79.85, and 71.01, as shown
in Fig. 2 (c). One can find that a better result can be obtained
when eight frames are used for MobileNet. Introducing more
video frames can bring in a substantial amount of redundant
information, making it challenging for the model to extract
useful features. An excessive number of frames might lead
to model complexity, making training more difficult and po-
tentially increasing the risk of overfitting. This phenomenon
is also referred to as information overload.
3). Number of uncertainty-aware bridge based Mobile-
Former blocks: When building our backbone network, dif-
ferent uncertainty-aware Mobile-Former layers can be used.
In this part, we exploit 9, 12, and 14 layers and get the top-1
results 74.22, 79.85, 72.87, as shown in Fig. 2 (d).
F. Visualization
In addition to the aforementioned quantitative experi-
mental analysis, we also provide visualizations to better
assist readers in comprehending the effectiveness of our
Fig. 3: Visualization of the CNN features using our model
on the N-Caltech101 dataset.
Fig. 4: Visualization of the top-5 predicted categories using
our model on the N-Caltech101 dataset.
model. As shown in Fig. 3, we first give a visualization
of MobileNet feature maps. One can find that our model
performs well in capturing the active event regions. As shown
in Fig. 4, we also present the top-5 recognition results and
their corresponding confidence scores for model predictions.
It is evident that our approach can accurately identify the
patterns captured by the event camera. As shown in Fig. 5,
we randomly select 10 classes of samples from N-Caltech101
dataset and project the features into 2D spaces. It is easy
to find that our model performs well in separating these
categories.
V. CONCLUSION
In this work, we propose to recognize objects based on the
event streams. we propose a lightweight uncertainty-aware
information propagation based Mobile-Former network for
efficient pattern recognition, which aggregates the MobileNet
and Transformer network effectively. Extensive experiments
on multiple event-based recognition datasets fully validated
the effectiveness of our model. In our future works, we will
consider a knowledge distillation strategy to further enhance
the final recognition performance.
REFERENCES
[1] T. Ahmad, L. Jin, X. Zhang, L. Lin, and G. Tang. Graph convolutional
neural network for action recognition: A comprehensive survey. IEEE
Transactions on Artificial Intelligence, 2021.
[2] R. Baldwin, R. Liu, M. M. Almatrafi, V. K. Asari, and K. Hirakawa.
Time-ordered recent event (tore) volumes for event cameras. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 2022.
Fig. 5: Visualization of our feature distribution on N-
Caltech101.
[3] A. Behera, A. Keidel, and B. Debnath. Context-driven multi-stream
lstm (m-lstm) for recognizing fine-grained activity of drivers.
In
German Conference on Pattern Recognition, pages 298–314. Springer,
2018.
[4] Y. Bi, A. Chadha, A. Abbas, E. Bourtsoulatze, and Y. Andreopoulos.
Graph-based object classification for neuromorphic vision sensing. In
Proceedings of the IEEE/CVF International Conference on Computer
Vision, pages 491–501, 2019.
[5] Y. Bi, A. Chadha, A. Abbas, E. Bourtsoulatze, and Y. Andreopoulos.
Graph-based spatio-temporal feature learning for neuromorphic vision
sensing.
IEEE Transactions on Image Processing, 29:9084–9098,
2020.
[6] S. Chen and M. Guo. Live demonstration: Celex-v: a 1m pixel multi-
mode event-based sensor. In 2019 IEEE/CVF Conference on Computer
Vision and Pattern Recognition Workshops (CVPRW), pages 1682–
1683. IEEE, 2019.
[7] Y. Chen, X. Dai, D. Chen, M. Liu, X. Dong, L. Yuan, and Z. Liu.
Mobile-former: Bridging mobilenet and transformer. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition, pages 5270–5279, 2022.
[8] Y. Deng, H. Chen, H. Chen, and Y. Li. Evvgcnn: A voxel graph cnn
for event-based object classification. arXiv preprint arXiv:2106.00216,
1(2):6, 2021.
[9] Y. Deng, H. Chen, and Y. Li. Mvf-net: A multi-view fusion network
for event-based object classification. IEEE Transactions on Circuits
and Systems for Video Technology, 32(12):8275–8284, 2021.
[10] Y. Deng, Y. Li, and H. Chen. Amae: Adaptive motion-agnostic encoder
for event-based object classification. IEEE Robotics and Automation
Letters, 5(3):4596–4603, 2020.
[11] P. U. Diehl, D. Neil, J. Binas, M. Cook, S.-C. Liu, and M. Pfeiffer.
Fast-classifying, high-accuracy spiking deep networks through weight
and threshold balancing. In 2015 International joint conference on
neural networks (IJCNN), pages 1–8. ieee, 2015.
[12] C. Doersch.
Tutorial on variational autoencoders.
arXiv preprint
arXiv:1606.05908, 2016.
[13] H. Fang, A. Shrestha, Z. Zhao, and Q. Qiu. Exploiting neuron and
synapse filter dynamics in spatial temporal learning of deep spiking
neural network. In Proceedings of the Twenty-Ninth International Con-
ference on International Joint Conferences on Artificial Intelligence,
pages 2799–2806, 2021.
[14] W. Fang, Z. Yu, Y. Chen, T. Huang, T. Masquelier, and Y. Tian. Deep
residual learning in spiking neural networks. NeurIPS, 2021.
[15] W. Fang, Z. Yu, Y. Chen, T. Masquelier, T. Huang, and Y. Tian.
Incorporating learnable membrane time constant to enhance learning
of spiking neural networks. In Proceedings of the IEEE/CVF Interna-
tional Conference on Computer Vision (ICCV), 2021.
[16] Y. Fang, H. Zhang, J. Yan, W. Jiang, and Y. Liu. Udnet: Uncertainty-
aware deep network for salient object detection. Pattern Recognition,
134:109099, 2023.
[17] G. Gallego, T. Delbr¨uck, G. Orchard, C. Bartolozzi, B. Taba, A. Censi,
S. Leutenegger, A. J. Davison, J. Conradt, K. Daniilidis, et al. Event-
based vision: A survey. IEEE transactions on pattern analysis and
machine intelligence, 44(1):154–180, 2020.
[18] D. Gehrig, A. Loquercio, K. G. Derpanis, and D. Scaramuzza. End-to-
end learning of representations for asynchronous event-based data. In
Proceedings of the IEEE/CVF International Conference on Computer
Vision, pages 5633–5643, 2019.
[19] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang,
T. Weyand, M. Andreetto, and H. Adam.
Mobilenets: Efficient
convolutional neural networks for mobile vision applications. arXiv
preprint arXiv:1704.04861, 2017.
[20] A. Khamparia, S. K. Singh, and A. K. Luhach.
Svm-pca based
handwritten devanagari digit character recognition. Recent Advances
in Computer Science and Communications (Formerly: Recent Patents
on Computer Science), 14(1):48–53, 2021.
[21] S. Khan, M. Naseer, M. Hayat, S. W. Zamir, F. S. Khan, and M. Shah.
Transformers in vision: A survey. arXiv preprint arXiv:2101.01169,
2021.
[22] D. P. Kingma, T. Salimans, and M. Welling. Variational dropout and
the local reparameterization trick.
Advances in neural information
processing systems, 28, 2015.
[23] Y. Kong and Y. Fu.
Human action recognition and prediction: A
survey. arXiv preprint arXiv:1806.11230, 2018.
[24] N. Le, K. Nguyen, Q. Tran, E. Tjiputra, B. Le, and A. Nguyen.
Uncertainty-aware label distribution learning for facial expression
recognition. In Proceedings of the IEEE/CVF Winter Conference on
Applications of Computer Vision, pages 6088–6097, 2023.
[25] D. Li, Z. Zhang, C. Shan, and L. Wang.
Incremental pedestrian
attribute recognition via dual uncertainty-aware pseudo-labeling. IEEE
Transactions on Information Forensics and Security, 2023.
[26] Z. Li, M. S. Asif, and Z. Ma.
Event transformer.
arXiv preprint
arXiv:2204.05172, 2022.
[27] I. Loshchilov and F. Hutter. Decoupled weight decay regularization.
2017. doi: 10.48550. arXiv preprint ARXIV.1711.05101, 2023.
[28] S. Mascarenhas and M. Agarwal.
A comparison between vgg16,
vgg19 and resnet50 architecture frameworks for image classification.
In 2021 International conference on disruptive technologies for multi-
disciplinary research and applications (CENTCON), volume 1, pages
96–99. IEEE, 2021.
[29] Q. Meng, M. Xiao, S. Yan, Y. Wang, Z. Lin, and Z.-Q. Luo. Training
high-performance low-latency spiking neural networks by differentia-
tion on spike representation. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pages 12444–
12453, 2022.
[30] G. Orchard, A. Jayawant, G. K. Cohen, and N. Thakor. Converting
static image datasets to spiking neuromorphic datasets using saccades.
Frontiers in neuroscience, 9:437, 2015.
[31] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf,
E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-
performance deep learning library. In Advances in Neural Information
Processing Systems 32, pages 8024–8035. Curran Associates, Inc.,
2019.
[32] N. Perez-Nieves and D. Goodman. Sparse spiking gradient descent.
Advances in Neural Information Processing Systems, 34:11795–11808,
2021.
[33] C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning
on point sets for 3d classification and segmentation. In Proceedings
of the IEEE conference on computer vision and pattern recognition,
pages 652–660, 2017.
[34] Z. Qin, L. Yang, F. Gao, Q. Hu, and C. Shen. Uncertainty-aware aggre-
gation for federated open set domain adaptation. IEEE Transactions
on Neural Networks and Learning Systems, 2022.
[35] Y. Sekikawa, K. Hara, and H. Saito. Eventnet: Asynchronous recursive
event processing.
In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pages 3887–3896, 2019.
[36] A. Sironi, M. Brambilla, N. Bourdis, X. Lagorce, and R. Benosman.
Hats: Histograms of averaged time surfaces for robust event-based
object classification.
In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages 1731–1740, 2018.
[37] S. Vemprala, S. Mian, and A. Kapoor. Representation learning for
event-based visuomotor policies.
Advances in Neural Information
Processing Systems, 34:4712–4724, 2021.
[38] P. Wang, C. Ding, W. Tan, M. Gong, K. Jia, and D. Tao.
Uncertainty-aware clustering for unsupervised domain adaptive object
re-identification. IEEE Transactions on Multimedia, 2022.
[39] Q. Wang, Y. Zhang, J. Yuan, and Y. Lu.
Space-time event clouds
for gesture recognition: From rgb cameras to event cameras. In 2019
IEEE Winter Conference on Applications of Computer Vision (WACV),
pages 1826–1835. IEEE, 2019.
[40] X. Wang, J. Li, L. Zhu, Z. Zhang, Z. Chen, X. Li, Y. Wang, Y. Tian,
and F. Wu.
Visevent: Reliable object tracking via collaboration of
frame and event flows. IEEE Transactions on Cybernetics, 2023.
[41] X. Wang, Y. Rong, S. Wang, Y. Chen, Z. Wu, B. Jiang, Y. Tian, and
J. Tang. Unleashing the power of cnn and transformer for balanced
rgb-event video recognition. arXiv preprint arXiv:2312.11128, 2023.
[42] X. Wang, Z. Wu, Y. Rong, L. Zhu, B. Jiang, J. Tang, and Y. Tian.
Sstformer: bridging spiking neural network and memory support
transformer for frame-event based recognition.
arXiv preprint
arXiv:2308.04369, 2023.
[43] Y. Wang, B. Du, Y. Shen, K. Wu, G. Zhao, J. Sun, and H. Wen. Ev-
gait: Event-based robust gait recognition using dynamic vision sensors.
In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 6358–6367, 2019.
[44] Y. Wang, B. Du, Y. Shen, K. Wu, G. Zhao, J. Sun, and H. Wen. Ev-
gait: Event-based robust gait recognition using dynamic vision sensors.
In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 6358–6367, 2019.
[45] Y. Wang, X. Zhang, Y. Shen, B. Du, G. Zhao, L. Cui, and H. Wen.
Event-stream representation for human gaits identification using deep
neural networks. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 44(7):3436–3449, 2021.
[46] Y. Wang, X. Zhang, Y. Shen, B. Du, G. Zhao, L. C. C. Lizhen, and
H. Wen. Event-stream representation for human gaits identification
using deep neural networks. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 2021.
[47] K. Xia, J. Huang, and H. Wang. Lstm-cnn architecture for human
activity recognition. IEEE Access, 8:56855–56866, 2020.
[48] B. Xie, Y. Deng, Z. Shao, H. Liu, and Y. Li. Vmv-gcn: Volumetric
multi-view based graph cnn for event stream classification.
IEEE
Robotics and Automation Letters, 7(2):1976–1983, 2022.
[49] B. Xie, Y. Deng, Z. Shao, H. Liu, and Y. Li. Vmv-gcn: Volumetric
multi-view based graph cnn for event stream classification.
IEEE
Robotics and Automation Letters, 7(2):1976–1983, 2022.
[50] W. Zhang, K. Ma, G. Zhai, and X. Yang. Uncertainty-aware blind im-
age quality assessment in the laboratory and wild. IEEE Transactions
on Image Processing, 30:3474–3486, 2021.
","Recently, the event camera (also termed Dynamic Vision Sensors, DVS) which is a bio-inspired sensor draws more and more attention from researchers [41] [42] [40]. Different from the RGB camera which records the scene into video frames in a synchronous way, each pixel in the event camera is triggered asynchronously by saving an event point if and only if the intensity of this pixel changed from i to i₁ (i ≠ i₁).nan"
"Unmanned Aerial Vehicles (UAVs) have recently gained attention for their potential in providing wireless services and collecting data in critical emergencies. This work introduces an optimization model seeking to minimize total energy consumption and provide the optimal path planning of UAVs under constraints of minimum completion time and transmit power. The formulated optimization is NP-hard, making it not applicable for real-time decision making. Therefore, a light-weight meta-reinforcement learning solution is introduced to cope with sudden changes in the environment through fast convergence.","Unmanned aerial vehicles (UAVs) have been widely used as flying wireless communication base stations due to their advantages over traditional platforms. These advantages lead to the wide adoption of UAVs in critical applications, including surveillance, forest fire detection, object tracking, and wireless communication services in catastrophic disasters. UAV-based solutions for data collection from IoT devices can optimize the mission's path, energy consumption, and completion time.","The system model consists of a UAV swarm navigating an area to collect data from IoT devices distributed in the ground. A grid divides the covered area into equal-sized cells, and each cell is monitored by one UAV. U UAVs denoted as u = {1, 2, . . . , U} navigate to cover the area focusing on strategic locations in the area. In particular, U UAVs navigate for data collection from N ≫ 1 ground IoT devices where i = {1, 2, . . . , N}. The positions of the ground IoT devices are denoted by i, Qi = [xi, yi, 0], where i ∈ N are supposed to be known using global positioning systems (GPS). The movements of UAVs and their directions are optimized using a ground station (control center).",The simulation results prove that the introduced approach is better than the three state-of-the-art algorithms in providing coverage to strategic locations with fast convergence.,"This work addresses the problem of UAVs' path planning that provides the minimum energy consumption of UAVs while guaranteeing the minimum data rate is ensured by using meta-RL algorithms for coping with dynamic environments through rapid convergence. The proposed system model is validated through extensive simulations proving its performance by testing it on various parameters such as changing the number of UAVs in the grid and comparing the meta-RL solution with three state-state-of-art algorithms, namely reinforcement learning with proximal policy optimization (PPO), actor-critic algorithm, and DQN algorithm, and shows that the introduced Meta-RL algorithm provides better demand service satisfaction to the strategic locations than the other competitive algorithms.",Meta Reinforcement Learning for Strategic IoT Deployments Coverage in Disaster-Response UAV Swarms,"Marwan Dhuheir, Aiman Erbad, Ala Al-Fuqaha","Meta Reinforcement Learning for Strategic IoT
Deployments Coverage in Disaster-Response UAV
Swarms
Marwan Dhuheir∗, Aiman Erbad∗, Ala Al-Fuqaha∗
∗Division of Information and Computing Technology, College of Science and Engineering,
Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar.
Abstract—In the past decade, Unmanned Aerial Vehicles (UAVs)
have grabbed the attention of researchers in academia and indus-
try for their potential use in critical emergency applications, such
as providing wireless services to ground users and collecting data
from areas affected by disasters, due to their advantages in terms
of maneuverability and movement flexibility. The UAVs’ limited
resources, energy budget, and strict mission completion time have
posed challenges in adopting UAVs for these applications. Our
system model considers a UAV swarm that navigates an area
collecting data from ground IoT devices focusing on providing
better service for strategic locations and allowing UAVs to join
and leave the swarm (e.g., for recharging) in a dynamic way.
In this work, we introduce an optimization model with the
aim of minimizing the total energy consumption and provide
the optimal path planning of UAVs under the constraints of
minimum completion time and transmit power. The formulated
optimization is NP-hard making it not applicable for real-time
decision making. Therefore, we introduce a light-weight meta-
reinforcement learning solution that can also cope with sudden
changes in the environment through fast convergence. We conduct
extensive simulations and compare our approach to three state-
of-the-art learning models. Our simulation results prove that
our introduced approach is better than the three state-of-the-art
algorithms in providing coverage to strategic locations with fast
convergence.
Index Terms—Optimization; QoS; UAVs positions; energy con-
sumption; meta-reinforcement learning; reinforcement learning;
UAVs; strategic locations.
I. INTRODUCTION
Unmanned aerial vehicles (UAVs) are playing a key role
in many applications. Recently, UAVs have been widely used
as flying wireless communication base stations due to their
advantages over traditional platforms. The UAVs advantages
include effective cost, flexibility, easy maneuverability, scal-
ability, and line of sight (LoS) service. These advantages
led to the wide adoption of UAVs in critical applications,
including surveillance, forest fire detection, object tracking, and
wireless communication services in catastrophic disasters (e.g.,
earthquakes, hurricanes, and floods affected areas) [1], [2].
Furthermore, UAVs can provide a cost-effective and reliable
solution to collect data from dispatched IoT users over a wide
geographical area with terrestrial infrastructure impacted by
natural or man-made disasters.
UAVs have many advantages over traditional platforms al-
lowing them to effectively accomplish their mission with less
energy consumption and within the time constraints [3]. In this
way, UAVs can work as data aggregators, which are flying
base stations that provide wireless communication services to
ground users that cannot be reached with terrestrial base sta-
tions. Nevertheless, several challenges need to be addressed to
effectively use UAVs, including optimizing mission trajectory,
energy consumption, resource allocation, and the completion
time of missions.
UAV-based solutions for data collection from IoT devices
can optimize the mission’s path, energy consumption, and
completion time [4]–[6]. The authors in [4] propose to jointly
optimize the UAV’s positions and the transmit power for
reliable information transmission and rapid data collection from
ground users. In [5], the authors introduce a joint position and
travel path optimization to consume less energy in gathering
data. The trajectory path planning optimization aims to collect
more user data under energy consumption constraints. In [6],
the authors used deep reinforcement learning of UAVs’ tra-
jectory planning optimization. The authors of this study focus
on finding the optimal paths of UAVs under time constraints
in which the UAVs need to deliver their collected data to
a central station before the data becomes irrelevant. All the
above-mentioned studies [4]–[6] focus on optimizing the UAVs
path planning to reduce energy and maximizing the coverage
to include a larger number of users and collect more data.
However, none of these studies investigated planning the UAV
paths to cover the affected areas with a focus on the most
vulnerable spots to ensure the UAVs plan their trajectories and
collect data from the most affected ground IoT devices and
upload the data into a remote base stations. Particularly, the
UAVs can navigate into the whole area and focus on their
trajectories in some strategic locations while maintaining the
minimum data rate that guarantees reliable data transmission
to other UAVs within the swarm.
Machine learning-based solutions to optimize the path plan-
ning of UAVs in dynamic solutions have been addressed in
some research studies [7]–[10]. The works in [7], [8] investi-
gate using UAVs path optimization to reduce the latency and
arXiv:2401.11118v1  [cs.LG]  20 Jan 2024
improve the reliability of the transmission by considering deep
reinforcement learning approach. The authors in [9] proposed
a machine learning solution to provide on-demand services to
ground users. In [10], the authors use multi-agent reinforcement
learning using a Q-learning approach to choose the trajectories
of UAVs based on predicting the user movements. Nevertheless,
these two studies are not suitable in case of rapid changes
in the environment, especially since the UAV path parameters
are constantly changing during the mission in dynamic envi-
ronments. For example, UAVs can join and leave the swarm
dynamically for recharging and due to other urgent issues (e.g.,
damage, malfunction). Due to the complexity of the problem,
conventional RL algorithms are slow to converge again to
respect the constraints of path planning; hence, we propose
meta-learning to quickly adapt neural networks performing in
new environments with high efficiency across related tasks [11].
In this work, we aim to address the problem of UAVs’ path
planning that provides the minimum energy consumption of
UAVs while guaranteeing the minimum data rate is ensured
for reliably sending the data to the UAVs by using meta-
RL algorithms for coping with dynamic environments through
rapid convergence. In our approach, we define strategic lo-
cations in the covered geographical area that UAVs need to
visit more. These strategic locations represent more affected
buildings/neighbourhoods after a disaster or areas with more
victims so the UAVs need to plan their trajectory to traverse
through these buildings/neighbourhoods more often to ensure
timely data collection from severely affected victims. However,
our approach is general enough to include wide UAV applica-
tions like object tracking and wireless communication services
in condensed areas. Our contributions can be summarized as
follows:
• We develop a system model containing a UAV swarm nav-
igating an area to collect data from IoT devices distributed
in the ground. The covered area contains some strategic
locations that need better service from the UAV swarm.
• We delineate the approach as an optimization problem
that seeks to minimize the total energy consumption of
the UAVs in the grid while having some constraints
ensuring the reliable data delivery among UAVs, minimum
energy consumption, optimal path planning with strategic
locations.
• We investigate the proposed system model through exten-
sive simulations to prove its performance by testing it on
various parameters such as changing the number of UAVs
in the grid and comparing our meta-RL solution with
three state-state-of-art algorithms, namely reinforcement
learning with proximal policy optimization (PPO), actor-
critic algorithm, and DQN algorithm, and show that our
introduced Meta-RL algorithm provides better demand
service satisfaction to the strategic locations than the other
competitive algorithms.
The rest of this article is organized as follows: section II
presents the description of our system model. In Section III,
we delineate the problem formulation. Section V explains the
implementation results of the proposed approach. At the end,
section VI concludes and discusses future research directions.
II. SYSTEM MODEL
We divide the covered area into equal-sized cells, in which
each cell is monitored by one UAV for data collection from
the IoT devices that are distributed in the area as shown in
Figure 1. According to this approach, U UAVs denoted as
u = {1, 2, . . . , U} navigate to cover the area focusing on
strategic locations in the area. In particular, U UAVs navigate
for data collection from N ≫ 1 ground IoT devices where
i = {1, 2, . . . , N}. The positions of the ground IoT devices
are denoted by i, Qi = [xi, yi, 0], where i ∈ N are supposed
to be known using global positioning systems (GPS). As shown
in Figure 1, the movements of UAVs and their directions are
optimized using a ground station (control center).
Fig. 1. System Model for multi-UAVs covering an area with strategic locations.
The UAVs mission is data collection from ground devices.
Let us suppose that UAVs operate at time frame T where
T > 0 in seconds (s). The time frame T is divided into small
time intervals t, such that 0 ≤ t ≤ T, thus the 3D positions
of UAV u at the specific time instance t can be described
as Qu(t) = [xu(t), yu(t), hu(t)] ∈ R3, u ∈ U is a set of
UAVs. Moreover, we further assume that the duration time
frame T is divided into M equal time slots, determined by
the set of m = {1, . . . , M}. Each time slot m is defined
by the time length of µ =
T
M , which is small enough
to provide a stable time duration of the UAV 3D location
[12]. Accordingly, the UAVs’ 3D position can be rewritten
as Qu[m] = [xu(t), yu(t), hu(t)], m ∈ M. The gathered data
from ground devices is sent to the ground base station after the
UAVs complete a one-time frame T.
A. Wireless Channel Model
In our approach and for practical scenarios, the obstacles
information, including their number, height, and locations,
might not be known; hence the randomness of the availability
of line of sight (LoS) and non-line of sight (NLoS) channels
of the air-to-ground link between UAVs and IoT devices are
considered. Note that the LoS and NLoS depend on the type
of environment (e.g., rural, urban, suburban, etc.), the location
of UAVs and IoT devices, and the altitude of the flying UAVs.
Hence, the probability of LoS expression is given by [3]:
P LoS
ui
=
1
1 + ω1 exp −ω2[θui − ω1]
(1)
where ω1 and ω2 are constant parameters and their values
are specified based on the type of the environment, θui
represents the elevation angle between the UAV u and the
IoT device i. Particularly, θ =
180
π
× sin−1( hi
dui), where
dui =
p
(xi − xu)2 + (yi − yu)2 + h2
i is the distance between
the UAV u and the device i. The probability of NLoS is given
by, P NLoS
ui
= 1 − P LoS
ui
.
The path loss models of LoS and NLoS are expressed as
follows [3]:
Lui
LoS = ψLoS(4πfcdui
c
)2
(2)
Lui
NLoS = ψNLoS(4πfcdui
c
)2
(3)
where fc is denoted as the carrier frequency and c is the speed
of light. ψLoS and ψNLoS are denoted to the excessive path
loss related to free-space propagation loss for LoS and NLoS,
respectively.
The total average path of the communication link between
the UAVs and the IoT devices is given by:
¯Lui = P LoS
ui
Lui
LoS + P NLoS
ui
Lui
NLoS
(4)
Moreover, the average channel gain of the communication
link between IoT devices and UAVs is ¯gui = (1/¯Lui). The
threshold of minimum data rate for successful transmission is
expressed as:
ρu,i(lb) = Bu,i log2(1 + Pr
σ2 )
(5)
where Bu,i is the transmission bandwidth between the UAV u
and IoT device i, Pr is the received power at the UAV u, and
Pr = Pi × ¯gui, Pi is denoted to the transmit power at device i,
and σ2 represents the thermal noise power. Hence, to achieve
a reliable collection time from UAVs from IoT devices, the
following condition need to be satisfied:
ρu,i[m] ≥ ρu,i(lb)
(6)
To satisfy a reliable transmission of data from IoT devices
to the flying UAVs, the maximum altitude of UAVs needs to
satisfy the minimum SNR Γ as follows [13]:
hi ≤

Pmax
ΓF 2
0 σ2ψLoS

(7)
where F0 = 4πfc
c , and Pmax is maximum transmit power of
each UAV.
B. Device-to-Device (D2D) Time Delay Model
D2D time is the time delay to complete the data collection
and send it to the central station. The completion time contains
the time required to transfer the data from IoT devices (Ddata)
and the time required by the UAVs to accomplish the mission
(Dcom). The time is given by:
Ddata =
X
i∈N
Ki
ρi,k[M]
(8)
Dcom =
X
u∈U
M
X
m=1
τu,m
(9)
where Ki is the IoT’s data packets, and τu,m is the uth
UAV’s travelling time between two successive time-slots m
and m + 1 which is calculated by:
τu,m = ∥Qu[m + 1] − Qu[m]∥
V
, m = 1, . . . , M
(10)
where V is the average speed of uth UAV travelling between
two consecutive locations.
Then, the total completion time of uth UAV mission is given
by:
Dtot = Ddata + Dcom
(11)
To satisfy the limitation of completing time, the total com-
pletion time should satisfy the following inequalities:
Dtot ≤ Tmax
(12)
where Tmax is the maximum time for UAV to complete its
mission.
C. Energy Consumption Model
The energy consumption of UAV is the total energy con-
sumed by each UAV. The energy consumed by uth UAV can
be expressed as:
εu = Pu,operDtot + Pm,commDdata
(13)
where Pu,oper and Pu,comm are the UAV’s operating power
and UAV’s communication power. This energy is designed
to calculate the energy consumed by the UAV to follow its
planned trajectory and collect data while focusing on strategic
locations such that at each time T, all strategic locations need
to be visited at least one time. Then, the total energy consumed
by all the UAVs (in Joules) in the swarm is expressed as:
εtot =
X
u∈U
δu,i,q . εu
(14)
where δu,i,q is a binary constraint to encourage UAVs pass
through strategic locations and exploit their energy collecting
data from the IoT devices, and it is defined as:
δu,i,q =



1 if UAV u is collecting data from IoT i that is
in strategic location qi,
0 otherwise
(15)
III. PROBLEM FORMULATION
The main objective is to minimize the total energy con-
sumption of UAVs in the swarm presented in equation (14)
by finding the optimal positions of UAVs while respecting
the maximum completion time, and minimum achievable data
rate for reliable data collection. The problem formulation is
expressed as follows:
min
Q
εtot
(16)
s.t. (6), (7), (12)
∀u ∈ U, ∀q ∈ Q,
N
X
i=1
δu,i,q ≥ 1
(17)
δu,i,q ∈ {0, 1}
(18)
The objective function in equation (16) aims to minimize
the total energy consumption of UAVs in the swarm by finding
the optimal UAVs paths and optimal transmit power while
navigating to cover the area, focusing on visiting strategic
locations and collecting data from IoT devices. The mission
needs to consider some constraints, including the maximum
completion time, the minimum data rate, and the maximum
altitude for the UAVs for reliable data transmission from IoT
devices into the flying UAVs.
The objective function in equation (16) is NP-hard due
the non-linearity in constraints (6), and (7). Hence, we use
meta-reinforcement learning to solve the objective function
of the optimization problem and its constraints to provide an
efficient sub-optimal solution, which will be described in the
next sections.
IV. META-REINFORCEMENT LEARNING FOR EFFICIENT
ENERGY CONSUMPTION AND PATH PLANNING
The model handles a dynamic UAV swarm, i.e., at any mo-
ment, UAVs can join and leave the swarm (e.g., for recharging);
hence, the approach needs to be flexible to these unforeseen
changes and can respect the constraints while flying to collect
data from the area. Due to the complexity of the problem,
conventional RL algorithms are slow to converge again to
respect the constraints of path planning; hence, meta-learning
is adapted to quickly adapt in new environments with high
efficiency across related tasks [11]. In particular, one model
can be trained to learn new tasks more effectively and converge
quickly than working correctly with only one single task.
Meta-RL applies meta-learning to reinforcement learning
and aims to make the agents learn the general policy of related
tasks. A task consists of a set of states and actions, dynamics,
and rewards [11]. In particular, meta-RL agents do not aim
to learn the optimal policy of a specific task; instead, they
aim to learn the general policy that can be applied to new
environments with the same family of tasks. The benefit is that
it enables the agents to quickly reach to the optimal policy of
new environments with minimum number of episodes.
In our RL approach, one episode contains a set of time
steps, and in each step, the algorithm needs to choose the 3D
position of each UAV. The decision to select the best position
of a UAV in the swarm is abased on several factors, including
minimizing the energy consumption, and ensuring the data is
sent successfully from the ground IoT device to the UAV. Our
RL approach is represented by a Markov Decision Process
(MDP) as (S, A, P, R, γ), where S is the environment state, A
is the action vector which contains two parts (path planning),
P is the probability of the possible transition, R represents the
rewards that the agent gets for each action, and γ is denoted
to the discount learning factor.
1) Environment Modeling: The environment is a swarm
of UAVs navigating the covered area with focusing on
strategic locations. Let’s define the π as the optimal
stochastic policy that the agent tries to learn where
π : S × A → [0, 1]. The RL algorithm receives the
details from a centralized agent that interacts with the
environment, takes action A, gets either reward/penalty
of that action, and reaches the optimal policy π∗ by the
received reward R at each time step t. The algorithm
tries to reach to the optimal policy π∗ with the maximum
vπ∗(s) for all parameters s ∈ S. The value set of
vπ(s) is denoted to the feedback from the reward after
implementing action a on state s, where E is denoted to
the expected value and it can be illustrated by:
vπ(s) = Eat,st+1
 ∞
X
k=1
γk−tRk|St = s
!
,
(19)
2) States and Actions: The RL agents needs helpful hints
about the environment to improve the system perfor-
mance. The state vector in our approach consists of the
positions of UAVs and strategic locations and the visited
cells in the grid. The action of the agent is the UAV
direction focusing on strategic locations.
3) Reward function: The reward is a crucial factor to help
the algorithm learn the optimal policy. In our algorithm,
the agent is positively rewarded when UAV’s direction is
chosen such that it visited one of the strategic locations
and consumes less energy. The agent gets a negative
reward if the agent’s next UAV position is higher than
the minimum derived data rate or collides with other
UAVs. The UAVs need to pass through strategic locations
and collect data from the IoT devices. Particularly, each
strategic location has different demand services based on
its importance that UAVs need to pass through and satisfy
part of this demand service factor which represents the
quality of services (QoS) in these strategic locations.
When UAVs pass through these strategic locations, it
satisfies part of the demand service denoted by ϕΩ.
Therefore, we define the rewards of satisfying the number
of visits to these strategic locations as done in [7] by:
RΩ =
1
1 + PΩ
i=1 ϕΩ(t)
(20)
Algorithm 1 delineates the steps of meta-RL algorithm
for converging and respecting the constraints related to the
objective function in (16). According to this algorithm, if the
UAV does not collide with other UAVs, it gets a reward (lines
10-12). Then, if the UAV chooses the next step producing less
energy, above the limit of minimum data rate and less than
the maximum expected time completion, it also gets a reward.
The agent will get an extra reward if it visits one strategic
location at that time, encouraging UAVS to collect data from
the strategic locations (lines 13-16).
Algorithm 1 Meta-RL
1: Q-network parameters initialization θ and θv.
2: old Q-network parameters initialization θ′ and θ′
v
3: for each episode r ∈ R do
4:
gradient initialization: dθ ← 0 and dθv ← 0
5:
Q-network initialization: θ′ = θ and θ′
v = θv
6:
for each t ∈ T do
7:
for each u ∈ {1, 2, 3, ..., U} do
8:
S(u) = {Su[m], SSL[m]}
9:
choose action Ai based on ϵ
10:
if Qu[t] /∈ Qu[T] and (6), (7), (12) then
11:
Rt = Rt + 1
12:
if Su ∈ StrategicLosaction then
13:
energyEpisode + = εtot(Q, Ni) equation (16)
14:
Rt = Rt + RΩ
equation (20)
15:
observe Si+1
16:
observe Rt
17:
system reset with new UAVs positions
18:
save (Si, Ai, ri, Si+1) in replay memory
19:
taking a minibatch of (Si, Ai, ri, Si+1)
20:
gradient accumulation wrtθ′ : dθ ← dθ+
∇θ′ log π(ai|si; θ′)(R − V (si; θ′
v))
21:
gradient accumulation wrtθ′
v : dθ ← dθ+
∂(R − V (si; θ′
v))2/∂θ′
v
22:
asynchronous update of θ using dθ and θv using dθv
V. SIMULATION RESULTS AND ANALYSIS
In our approach, we used 440 m × 440 m with 25 equal-
sized cells. Among these 25 cells, we have three strategic lo-
cations located in different places on the grid. For environment
type, we used urban area with parameters of ω1 and ω2 as
11.95 and 0.14, respectively. The ψLoS and ψNLoS are 3 dB
and 23 dB, respectively. The list of parameters is summarized
in table I.
Figure 2 expresses the number of visitations to strategic
locations compared to non-strategic locations in a one-time
frame T. As shown in the figure, our approach can successfully
encourage the UAVS to pass through these strategic locations
more often than the other locations.
We investigate a practical scenario when the number of
UAVs joins and disconnects the swarm during the learning.
Figure 3 shows the related implementation of the average
reward convergence. The simulation started with a swarm of
four UAVs, and we highlight that Meta-RL converges rapidly
to the maximum expected reward, and it takes 900 episodes
TABLE I
SIMULATION PARAMETERS.
Parameters
Description
Value
max transmit power
Pmax
200 mW
σ2
noise power
-170 dBm
γ
Discount factor
0.85
α
Learning rate
0.0001
Bu
Bandwidth
1 MHz
Ki
IoT’s data packet size
1 Mbits
V
average flight speed
10 m/s
operating power
P oper
u
300W
communication power
P comm
u
5W
Fig. 2. The number of visitations to strategic locations in one time frame T.
Fig. 3. Adaptivity of Meta-RL algorithm to the environment changes of the
learning. The algorithm started with 4 UAVs, then 1 more UAV joined the
swarm, and after that, 2 UAVs left the swarm. Meta-RL algorithm learns the
optimal policy quickly and converges to its maximum expected reward.
to converge into the maximum expected reward. During the
learning, one UAV joined the swarm, and Meta-RL can adapt to
the new changes in the environment and converge very quickly
to the maximum expected reward. After that, two UAVs depart
the swarm (e.g., for recharging), and Meta-RL can converge to
the maximum expected reward.
Figures 4(a) and 4(b) compare the Meta-RL solution and
(a)
(b)
(c)
(d)
Fig. 4. Energy consumption of different algorithms in terms of strategic locations and no-strategic locations, convergence speed, and demand service satisfaction.
traditional RL algorithms in case of energy consumption in
strategic and non-strategic locations when the number of UAVs
changes in the swarm. As shown in the figures, Meta-RL
tends to spend more energy than others on strategic locations
and lower energy consumption on non-strategic locations as
its priority is to serve strategic locations. Nevertheless, Meta-
RL outperforms the traditional RL algorithms in terms of
successfully satisfying the demand service needs of strategic
locations, reaching 96% when 7 UAVs are used, as shown
in Figure 4(c). Meta-RL also outperforms the traditional RL
algorithms regarding convergence speed, as shown in Figure
4(d). The Meta-RL algorithm needs fewer episodes than the
other algorithms to learn the optimal policy and hence the
ability to learn faster.
VI. CONCLUSION
In this article, we investigated the optimization of path
planning and energy consumption of UAV swarms in the
task of collecting data from IoT devices while focusing on
strategic locations to visit more often than the other areas in the
grid. We formulated the problem as an optimization problem
that seeks the minimum energy consumption by controlling
the UAV deployments and ensuring the minimum data rate.
We propose an efficient sub-optimal solution using meta-
reinforcement learning for dealing with dynamic environments
and for fast convergence. We compared our proposed solution
with three competitive solutions and showed the effective of
our approach in providing better service demand in strategic
locations. Our simulation results demonstrated the effectiveness
of the proposed method in terms of environment adaptive
to sudden changes and fast convergence into the maximum
rewards. In future work, we plan to study the interference and
the Doppler effect on UAV movements.
ACKNOWLEDGMENT
This work was made possible by NPRP grant # NPRP13S-
0205-200265 from the Qatar National Research Fund (a mem-
ber of Qatar Foundation). The findings achieved herein are
solely the responsibility of the authors.
REFERENCES
[1] Q. Wu, J. Xu, Y. Zeng, D. W. K. Ng, N. Al-Dhahir, R. Schober, and A. L.
Swindlehurst, “A comprehensive overview on 5g-and-beyond networks
with uavs: From communications to sensing and intelligence,” IEEE
Journal on Selected Areas in Communications, vol. 39, no. 10, pp. 2912–
2945, 2021.
[2] J.-C. Padr´o, F.-J. Mu˜noz, J. Planas, and X. Pons, “Comparison of
four uav georeferencing methods for environmental monitoring purposes
focusing on the combined use with airborne and satellite remote sens-
ing platforms,” International journal of applied earth observation and
geoinformation, vol. 75, pp. 130–140, 2019.
[3] M. Mozaffari, W. Saad, M. Bennis, and M. Debbah, “Mobile unmanned
aerial vehicles (uavs) for energy-efficient internet of things communica-
tions,” IEEE Transactions on Wireless Communications, vol. 16, no. 11,
pp. 7574–7589, 2017.
[4] Z. Huang, C. Chen, and M. Pan, “Multiobjective uav path planning for
emergency information collection and transmission,” IEEE Internet of
Things Journal, vol. 7, no. 8, pp. 6993–7009, 2020.
[5] M. B. Ghorbel, D. Rodr´ıguez-Duarte, H. Ghazzai, M. J. Hossain, and
H. Menouar, “Joint position and travel path optimization for energy
efficient wireless data gathering using unmanned aerial vehicles,” IEEE
Transactions on Vehicular Technology, vol. 68, no. 3, pp. 2165–2175,
2019.
[6] S. Wan, J. Lu, P. Fan, and K. B. Letaief, “Toward big data processing
in iot: Path planning and resource management of uav base stations in
mobile-edge computing system,” IEEE Internet of Things Journal, vol. 7,
no. 7, pp. 5995–6009, 2020.
[7] M. A. Dhuheir, E. Baccour, A. Erbad, S. S. Al-Obaidi, and M. Hamdi,
“Deep reinforcement learning for trajectory path planning and distributed
inference in resource-constrained uav swarms,” IEEE Internet of Things
Journal, vol. 10, no. 9, pp. 8185–8201, 2023.
[8] M. Dhuheir, A. Erbad, and S. Sabeeh, “Llhr: Low latency and high
reliability cnn distributed inference for resource-constrained uav swarms,”
in 2023 IEEE Wireless Communications and Networking Conference
(WCNC).
IEEE, 2023, pp. 1–6.
[9] Q. Zhang, W. Saad, M. Bennis, X. Lu, M. Debbah, and W. Zuo,
“Predictive deployment of uav base stations in wireless networks: Ma-
chine learning meets contract theory,” IEEE Transactions on Wireless
Communications, vol. 20, no. 1, pp. 637–652, 2021.
[10] X. Liu, Y. Liu, Y. Chen, and L. Hanzo, “Trajectory design and power
control for multi-uav assisted wireless networks: A machine learning
approach,” IEEE Transactions on Vehicular Technology, vol. 68, no. 8,
pp. 7957–7969, 2019.
[11] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for fast
adaptation of deep networks,” in International conference on machine
learning.
PMLR, 2017, pp. 1126–1135.
[12] Y. Zeng, X. Xu, and R. Zhang, “Trajectory design for completion
time minimization in uav-enabled multicasting,” IEEE Transactions on
Wireless Communications, vol. 17, no. 4, pp. 2233–2246, 2018.
[13] K. Chen, Y. Wang, J. Zhao, X. Wang, and Z. Fei, “Urllc-oriented joint
power control and resource allocation in uav-assisted networks,” IEEE
Internet of Things Journal, vol. 8, no. 12, pp. 10 103–10 116, 2021.
","nanSeveral studies have investigated planning UAV paths to cover affected areas with a focus on the most vulnerable spots to ensure UAVs plan their trajectories and collect data from the most affected ground IoT devices and upload the data into remote base stations. Machine learning-based solutions to optimize the path planning of UAVs in dynamic solutions have been addressed in some research studies. However, these studies are not suitable in case of rapid changes in the environment, especially since the UAV path parameters are constantly changing during the mission in dynamic environments."
