{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_22004\\2069252543.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import fitz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data =[]\n",
    "count = 0\n",
    "num = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=&terms-0-field=title&classification-computer_science=y&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first&start=1000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Article 0 extracted\n",
      "Article 1 extracted\n",
      "Article 2 extracted\n",
      "Article 3 extracted\n",
      "Article 4 extracted\n",
      "Article 5 extracted\n",
      "Article 6 extracted\n",
      "Article 7 extracted\n",
      "Article 8 extracted\n",
      "Article 9 extracted\n",
      "Article 10 extracted\n",
      "Article 11 extracted\n",
      "Article 12 extracted\n",
      "Article 13 extracted\n",
      "Article 14 extracted\n",
      "Article 15 extracted\n",
      "Article 16 extracted\n",
      "Article 17 extracted\n",
      "Article 18 extracted\n",
      "Article 19 extracted\n",
      "Article 20 extracted\n",
      "Article 21 extracted\n",
      "Article 22 extracted\n",
      "Article 23 extracted\n",
      "Article 24 extracted\n",
      "Article 25 extracted\n",
      "Article 26 extracted\n",
      "Article 27 extracted\n",
      "Article 28 extracted\n",
      "Article 29 extracted\n",
      "Article 30 extracted\n",
      "Article 31 extracted\n",
      "Article 32 extracted\n",
      "Article 33 extracted\n",
      "Article 34 extracted\n",
      "Article 35 extracted\n",
      "Article 36 extracted\n",
      "Article 37 extracted\n",
      "Article 38 extracted\n",
      "Article 39 extracted\n",
      "Article 40 extracted\n",
      "Article 41 extracted\n",
      "Article 42 extracted\n",
      "Article 43 extracted\n",
      "Article 44 extracted\n",
      "Article 45 extracted\n",
      "Article 46 extracted\n",
      "Article 47 extracted\n",
      "Article 48 extracted\n",
      "Article 49 extracted\n",
      "https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=&terms-0-field=title&classification-computer_science=y&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first&start=1050\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Article 50 extracted\n",
      "Article 51 extracted\n",
      "Article 52 extracted\n",
      "Article 53 extracted\n",
      "Article 54 extracted\n",
      "Article 55 extracted\n",
      "Article 56 extracted\n",
      "Article 57 extracted\n",
      "Article 58 extracted\n",
      "Article 59 extracted\n",
      "Article 60 extracted\n",
      "Article 61 extracted\n",
      "Article 62 extracted\n",
      "Article 63 extracted\n",
      "Article 64 extracted\n",
      "Article 65 extracted\n",
      "Article 66 extracted\n",
      "Article 67 extracted\n",
      "Article 68 extracted\n",
      "Article 69 extracted\n",
      "Article 70 extracted\n",
      "Article 71 extracted\n",
      "Article 72 extracted\n",
      "Article 73 extracted\n",
      "Article 74 extracted\n",
      "Article 75 extracted\n",
      "Article 76 extracted\n",
      "Article 77 extracted\n",
      "Article 78 extracted\n",
      "Article 79 extracted\n",
      "Article 80 extracted\n",
      "Article 81 extracted\n",
      "Article 82 extracted\n",
      "Article 83 extracted\n",
      "Article 84 extracted\n",
      "Article 85 extracted\n",
      "Article 86 extracted\n",
      "Article 87 extracted\n",
      "Article 88 extracted\n",
      "Article 89 extracted\n",
      "Article 90 extracted\n",
      "Article 91 extracted\n",
      "Article 92 extracted\n",
      "Article 93 extracted\n",
      "Article 94 extracted\n",
      "Article 95 extracted\n",
      "Article 96 extracted\n",
      "Article 97 extracted\n",
      "Article 98 extracted\n",
      "Article 99 extracted\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    url=f'https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=&terms-0-field=title&classification-computer_science=y&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first&start={str(num)}'\n",
    "    print(url+'\\n\\n\\n\\n\\n')\n",
    "    response = requests.get(url)\n",
    "    response = response.content\n",
    "\n",
    "    soup = BeautifulSoup(response,'html.parser')\n",
    "\n",
    "    papers = soup.find_all('li', class_='arxiv-result')\n",
    "    for i in range(len(papers)):\n",
    "        title = papers[i].find('p',class_='title')\n",
    "        authors = papers[i].find_all('p',class_='authors')\n",
    "        noob_authors = []\n",
    "        single = ''\n",
    "        for author in authors:\n",
    "            author_names = author.find_all('a')\n",
    "            for author_name in author_names:\n",
    "                noob_authors.append(author_name.text)\n",
    "        abstracts = papers[i].find('span',class_='abstract-full')\n",
    "        single = ', '.join(noob_authors)\n",
    "        \n",
    "        pdf_link = papers[i].find('span')\n",
    "        pdf_link = pdf_link.find('a')\n",
    "        noob_data = {'title':'','authors':'','abstract':'','pdf_link':'','textdata':''}\n",
    "        noob_data['title'] = title.text.strip()\n",
    "        noob_data['authors'] = single\n",
    "        noob_data['abstract'] = abstracts.text\n",
    "        # if noob_data['pdf_link']:\n",
    "        try:\n",
    "            noob_data['pdf_link'] = pdf_link['href']\n",
    "        except:\n",
    "            noob_data['pdf_link'] = 'No link'\n",
    "            \n",
    "        print(f\"Article {count} extracted\")\n",
    "        count +=1\n",
    "        # print(noob_data)\n",
    "        all_data.append(noob_data)\n",
    "        \n",
    "    num+=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame().from_dict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Text Extracted from Text Region Multiple Information Perception Network for Scene Text Detection\n",
      "2. Text Extracted from Gender Bias in Machine Translation and The Era of Large Language Models\n",
      "3. Text Extracted from Towards Hierarchical Spoken Language Dysfluency Modeling\n",
      "4. Text Extracted from Optimizing Medication Decisions for Patients with Atrial Fibrillation through Path Development Network\n",
      "5. Text Extracted from CPCL: Cross-Modal Prototypical Contrastive Learning for Weakly Supervised Text-based Person Re-Identification\n",
      "6. Text Extracted from An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos\n",
      "7. Text Extracted from Attack tree metrics are operad algebras\n",
      "8. Text Extracted from Spintronic logic: from transducers to logic gates and circuits\n",
      "9. Text Extracted from Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation\n",
      "10. Text Extracted from Distantly Supervised Morpho-Syntactic Model for Relation Extraction\n",
      "11. Text Extracted from BPDO:Boundary Points Dynamic Optimization for Arbitrary Shape Scene Text Detection\n",
      "12. Text Extracted from Developing an AI-based Integrated System for Bee Health Evaluation\n",
      "13. Text Extracted from A-KIT: Adaptive Kalman-Informed Transformer\n",
      "14. Text Extracted from FLex&Chill: Improving Local Federated Learning Training with Logit Chilling\n",
      "15. Text Extracted from WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens\n",
      "16. Text Extracted from Gradable ChatGPT Translation Evaluation\n",
      "17. Text Extracted from Multiobjective Optimization Analysis for Finding Infrastructure-as-Code Deployment Configurations\n",
      "18. Text Extracted from Ventricular Segmentation: A Brief Comparison of U-Net Derivatives\n",
      "19. Text Extracted from False Discovery Rate Control for Gaussian Graphical Models via Neighborhood Screening\n",
      "20. Text Extracted from Material-Response-Informed DeepONet and its Application to Polycrystal Stress-strain Prediction in Crystal Plasticity\n",
      "21. Text Extracted from Accelerated Bounded Model Checking\n",
      "22. Text Extracted from Better Explain Transformers by Illuminating Important Information\n",
      "23. Text Extracted from Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access\n",
      "24. Text Extracted from Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection\n",
      "25. Text Extracted from When Neural Code Completion Models Size up the Situation: Attaining Cheaper and Faster Completion through Dynamic Model Inference\n",
      "26. Text Extracted from CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects\n",
      "27. Text Extracted from A Comprehensive Scalable Framework for Cloud-Native Pattern Detection with Enhanced Expressiveness\n",
      "28. Text Extracted from Most General Winning Secure Equilibria Synthesis in Graph Games\n",
      "29. Text Extracted from Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification\n",
      "30. Text Extracted from SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning\n",
      "31. Text Extracted from HGAttack: Transferable Heterogeneous Graph Adversarial Attack\n",
      "32. Text Extracted from WindSeer: Real-time volumetric wind prediction over complex terrain aboard a small UAV\n",
      "33. Text Extracted from Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance Sparse Information Aggregation\n",
      "34. Text Extracted from Multi-task Learning for Joint Re-identification, Team Affiliation, and Role Classification for Sports Visual Tracking\n",
      "35. Text Extracted from Biases in Expected Goals Models Confound Finishing Ability\n",
      "36. Text Extracted from ICGNet: A Unified Approach for Instance-Centric Grasping\n",
      "37. Text Extracted from From Cash to Cashless: UPI's Impact on Spending Behavior among Indian Users\n",
      "38. Text Extracted from MAMBA: Multi-level Aggregation via Memory Bank for Video Object Detection\n",
      "39. Text Extracted from BlenDA: Domain Adaptive Object Detection through diffusion-based blending\n",
      "40. Text Extracted from Probabilistic Truly Unordered Rule Sets\n",
      "41. Text Extracted from Enabling On-device Continual Learning with Binary Neural Networks\n",
      "42. Text Extracted from Qadence: a differentiable interface for digital-analog programs\n",
      "43. Text Extracted from Deep Back-Filling: a Split Window Technique for Deep Online Cluster Job Scheduling\n",
      "44. Text Extracted from BUMP: A Benchmark of Reproducible Breaking Dependency Updates\n",
      "45. Text Extracted from Interplay between depth and width for interpolation in neural ODEs\n",
      "46. Text Extracted from XAI-Enhanced Semantic Segmentation Models for Visual Quality Inspection\n",
      "47. Text Extracted from Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations\n",
      "48. Text Extracted from Experimental Shake Gesture Detection API for Apple Watch\n",
      "49. Text Extracted from Skeleton-Guided Instance Separation for Fine-Grained Segmentation in Microscopy\n",
      "50. Text Extracted from A Survey on Hardware Accelerators for Large Language Models\n",
      "51. Text Extracted from Cooperative Edge Caching Based on Elastic Federated and Multi-Agent Deep Reinforcement Learning in Next-Generation Network\n",
      "52. Text Extracted from Source Code Clone Detection Using Unsupervised Similarity Measures\n",
      "53. Text Extracted from Question-Answer Cross Language Image Matching for Weakly Supervised Semantic Segmentation\n",
      "54. Text Extracted from GA-SmaAt-GNet: Generative Adversarial Small Attention GNet for Extreme Precipitation Nowcasting\n",
      "55. Text Extracted from Attention-Based Recurrent Neural Network For Automatic Behavior Laying Hen Recognition\n",
      "56. Text Extracted from Accurate and Scalable Many-Node Simulation\n",
      "57. Text Extracted from Reconciling Spatial and Temporal Abstractions for Goal Representation\n",
      "58. Text Extracted from Boosting Few-Shot Segmentation via Instance-Aware Data Augmentation and Local Consensus Guided Cross Attention\n",
      "59. Text Extracted from Improving fine-grained understanding in image-text pre-training\n",
      "60. Text Extracted from Evolutionary Multi-Objective Optimization of Large Language Model Prompts for Balancing Sentiments\n",
      "61. Text Extracted from Temporal Insight Enhancement: Mitigating Temporal Hallucination in Multimodal Large Language Models\n",
      "62. Text Extracted from Succinctness of Cosafety Fragments of LTL via Combinatorial Proof Systems (extended version)\n",
      "63. Text Extracted from Improving the Accuracy of Analog-Based In-Memory Computing Accelerators Post-Training\n",
      "64. Text Extracted from The Distortion of Threshold Approval Matching\n",
      "65. Text Extracted from EDAF: An End-to-End Delay Analytics Framework for 5G-and-Beyond Networks\n",
      "66. Text Extracted from A Survey on Energy Consumption and Environmental Impact of Video Streaming\n",
      "67. Text Extracted from Enhancing the Fairness and Performance of Edge Cameras with Explainable AI\n",
      "68. Text Extracted from Behavioral Simulation: Exploring A Possible Next Paradigm for Science\n",
      "69. Text Extracted from FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction\n",
      "70. Text Extracted from MatSciRE: Leveraging Pointer Networks to Automate Entity and Relation Extraction for Material Science Knowledge-base Construction\n",
      "71. Text Extracted from CATMA: Conformance Analysis Tool For Microservice Applications\n",
      "72. Text Extracted from Exploring Latent Cross-Channel Embedding for Accurate 3D Human Pose Reconstruction in a Diffusion Framework\n",
      "73. Text Extracted from Slicer Networks\n",
      "74. Text Extracted from Measuring Object Rotation via Visuo-Tactile Segmentation\n",
      "75. Text Extracted from Enhanced Automated Quality Assessment Network for Interactive Building Segmentation in High-Resolution Remote Sensing Imagery\n",
      "76. Text Extracted from Boosting Few-Shot Semantic Segmentation Via Segment Anything Model\n",
      "77. Text Extracted from Conning the Crypto Conman: End-to-End Analysis of Cryptocurrency-based Technical Support Scams\n",
      "78. Text Extracted from Enhancing Small Object Encoding in Deep Neural Networks: Introducing Fast&Focused-Net with Volume-wise Dot Product Layer\n",
      "79. Text Extracted from PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path Planning\n",
      "80. Text Extracted from Simple and effective data augmentation for compositional generalization\n",
      "81. Text Extracted from SensoDat: Simulation-based Sensor Dataset of Self-driving Cars\n",
      "82. Text Extracted from Clickbait vs. Quality: How Engagement-Based Optimization Shapes the Content Landscape in Online Platforms\n",
      "83. Text Extracted from Multilingual Visual Speech Recognition with a Single Model by Learning with Discrete Visual Speech Units\n",
      "84. Text Extracted from All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks\n",
      "85. Text Extracted from A Fast, Performant, Secure Distributed Training Framework For Large Language Model\n",
      "86. Text Extracted from A Comparative Analysis on Metaheuristic Algorithms Based Vision Transformer Model for Early Detection of Alzheimer's Disease\n",
      "87. Text Extracted from Wavelet-Guided Acceleration of Text Inversion in Diffusion-Based Image Editing\n",
      "88. Text Extracted from PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection\n",
      "89. Text Extracted from BreastRegNet: A Deep Learning Framework for Registration of Breast Faxitron and Histopathology Images\n",
      "90. Text Extracted from A Semantic Approach for Big Data Exploration in Industry 4.0\n",
      "91. Text Extracted from Querying Easily Flip-flopped Samples for Deep Active Learning\n",
      "92. Text Extracted from Adaptive Self-training Framework for Fine-grained Scene Graph Generation\n",
      "93. Text Extracted from Instant Answering in E-Commerce Buyer-Seller Messaging\n",
      "94. Text Extracted from Leveraging Biases in Large Language Models: \"bias-kNN'' for Effective Few-Shot Learning\n",
      "95. Text Extracted from Controllable Decontextualization of Yes/No Question and Answers into Factual Statements\n",
      "96. Text Extracted from On the Audio Hallucinations in Large Audio-Video Language Models\n",
      "97. Text Extracted from SEINE: Structure Encoding and Interaction Network for Nuclei Instance Segmentation\n",
      "98. Text Extracted from Robotic Test Tube Rearrangement Using Combined Reinforcement Learning and Motion Planning\n",
      "99. Text Extracted from Reliability-based G1 Continuous Arc Spline Approximation\n",
      "100. Text Extracted from Towards Learning from Graphs with Heterophily: Progress and Future\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# textdata = []\n",
    "for item in all_data:\n",
    "    count+=1\n",
    "    if count == 100:\n",
    "        break\n",
    "    pdf_link = item['pdf_link']\n",
    "    response = requests.get(pdf_link)\n",
    "    response.raise_for_status()\n",
    "    pdf_document = fitz.open(stream=response.content, filetype=\"pdf\")\n",
    "            \n",
    "    # Initialize an empty string to store text\n",
    "    text = ''\n",
    "    textdict = {'textData':''}\n",
    "    # Iterate over pages and extract text\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]\n",
    "        text += page.get_text()\n",
    "    all_data[count-1]['textdata'] = text\n",
    "    # noob_data['textdata'][count-1]= text\n",
    "    # textdata.append(textdict)\n",
    "    print(f\"{count}. Text Extracted from {item['title']}\")\n",
    "    # print(text)\n",
    "    # Close the PDF file\n",
    "    pdf_document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame().from_dict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>textdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, authors, abstract, pdf_link, textdata]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check no link\n",
    "df['title'] = df['title'].astype(str)\n",
    "df['title' == df['title'].isin(['No link'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset(1100-1200).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
