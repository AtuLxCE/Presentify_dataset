abstract,introduction,literature review,methodology,results,conclusion,title,author,textdata
"Controllable generation of 3D human motions becomes an important topic as the world embraces digital transforma-tion. Existing works, though making promising progress with the advent of diffusion models, heavily rely on meticulously captioned and annotated (e.g., text) high-quality motion corpus, a resource-intensive endeavor in the real world. This motivates our proposed MotionMix, a simple yet effective weakly-supervised diffusion model that leverages both noisy annotated motions and unannotated motions. Specifically, we separate the denoising objectives of a diffusion model into two stages: obtaining conditional rough motion approximations in the initial T ≠ T ≤ ∂ steps by learning the noisy annotated motions, followed by the unconditional refinement of these preliminary motions during the last T ≤ steps using unannotated motions. Notably, though learning from two sources of imperfect data, our model does not compromise motion generation quality compared to fully supervised approaches that access gold data. Extensive experiments on several benchmarks demonstrate that our MotionMix, as a versatile frame-work, consistently achieves state-of-the-art performances on text-to-motion, action-to-motion, and music-to-dance tasks.nan","The rapidly arising attention and interest in digital humans bring up the great demand for human motion generation, in a wide range of fields such as industrial game and movie animation (Ling et al. 2020), human-machine interaction (Koppula and Saxena 2013), VR/AR and metaverse development (Lee et al. 2021). Over the years, automated generation of human motions that align with user preferences, spanning aspects such as prefix poses (Ruiz, Gall, and Moreno-Noguer 2018; Guo et al. 2022c), action classes (Petrovich, Black, and Varol 2021; Cervantes et al. 2022), textual descriptions (Petrovich, Black, and Varol 2022; Ahuja and Morency 2019; Tevet et al. 2022), or music (Li et al. 2020; Aristidou et al. 2021; Siyao et al. 2022; Gong et al. 2023), has been a focal point of research. Recently, building upon the advancement of diffusion models, human motion generation has experienced a notable improvement in quality and controllability. However, these prior diffusion models are commonly trained on well-crafted motions that come with explicit annotations like textual descriptions. While capturing motions from the real world is a laborious effort, annotating these motion sequences further urges the matter.nan","Diffusion models have recently emerged as a powerful class of generative models that have shown promising results in various domains such as image synthesis, text generation, and audio generation. In the context of human motion generation, diffusion models have also been explored, demonstrating their ability to produce high-quality and diverse motions conditioned on various forms of input, such as text, actions, or music. However, most existing diffusion models for human motion generation rely on high-quality motion datasets with detailed annotations, which can be challenging and time-consuming to obtain. To address this limitation, recent research has investigated weakly-supervised diffusion models that can learn from both annotated and unannotated data. For example, Make-An-Animation (Azadi et al. 2023) proposes a diffusion model that can generate human motions from text descriptions using a combination of annotated and unannotated motion data. However, this approach focuses primarily on text-driven motion generation and does not explore other conditioning modalities such as actions or music.nannan","Our proposed MotionMix approach effectively addresses the key challenge of training diffusion models with limited annotated data and abundant unannotated data. The methodology is underpinned by the following key aspects:

1. **Data Separation:** We strategically divide the training data into two distinct sets: (a) noisy annotated motion sequences and (b) clean unannotated motion sequences. The noisy annotations mimic real-world data where annotations may contain errors or inconsistencies, while the clean unannotated data provides additional information that can guide the generation process.

2. **Two-Stage Denoising:** We leverage a diffusion model as the foundation for motion generation. However, instead of using a conventional single-step diffusion process, we propose a novel two-stage denoising strategy. In the first stage, the diffusion model focuses on learning from the noisy annotated data, gradually refining the motion sequences to obtain rough approximations. In the second stage, the model utilizes the clean unannotated data to further denoise and improve the quality of the generated motions.

3. **Classifier-Free Guidance:** To enhance the generation process, we employ a classifier-free guidance technique during the denoising steps. This approach involves combining unconditional and conditionally generated samples with a carefully tuned weight, allowing the model to explore both global and conditional aspects of the data distribution. This technique promotes the production of diverse and realistic motion sequences.nan","The effectiveness of our MotionMix approach is thoroughly evaluated across a diverse range of benchmarks and applications:

1. **Text-to-Motion:** Comprehensive experiments on the HumanML3D and KIT-ML datasets demonstrate MotionMix's capability of generating high-quality and diverse motions from textual descriptions. Our approach outperforms several strong baselines, including language-based and diffusion-based methods, achieving state-of-the-art results in terms of motion quality, multimodal consistency, and diversity.

2. **Action-to-Motion:** We evaluate MotionMix on the HumanAct12 and UESTC datasets for action-to-motion generation. MotionMix consistently outperforms existing methods, including supervised and unsupervised approaches, across various evaluation metrics. This showcases its ability to generate plausible and diverse motions conditioned on action classes.

3. **Music-to-Dance:** Using the AIST++ dataset, we demonstrate that MotionMix excels in music-driven dance generation. Our approach surpasses previous methods in key metrics such as physical foot contact, beat alignment, and diversity. These results highlight MotionMix's ability to capture the rhythmic and expressive qualities of music and generate realistic dance motions.

4. **Ablation Studies:** We conduct extensive ablation experiments to analyze the impact of hyperparameters and training strategies on MotionMix's performance. The results provide insights into the effects of the denoising pivot (T ≤), the ratio of noisy to clean data, and the noisy range used to approximate noisy data. These studies validate the robustness of MotionMix and offer guidance for future research.nan","MotionMix, our proposed weakly-supervised diffusion model for conditional human motion generation, has demonstrated remarkable results across various tasks and benchmarks. It effectively addresses the challenge of training with limited annotated data by leveraging both noisy annotated and clean unannotated motion sequences. Through extensive experiments and ablation studies, we have comprehensively evaluated MotionMix and provided insights into its effectiveness, versatility, and robustness. We believe that MotionMix opens up new avenues for future research in the realm of data-efficient human motion generation. Moreover, its potential applications span a wide range of domains, including entertainment, gaming, and human-computer interaction, where the generation of realistic and diverse motions is crucial.nan",MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation,"Nhat M. Hoang, Kehong Gong, Chuan Guo, Michael Bi Mi","MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation
Nhat M. Hoang1,2*, Kehong Gong1†, Chuan Guo1*, Michael Bi Mi1
1Huawei Technologies Co., Ltd.,
2Nanyang Technological University
nhat005@e.ntu.edu.sg, gongkehong@u.nus.edu, cguo2@ualberta.ca, michaelbimi@yahoo.com
Figure 1: Examples of applying MotionMix on text-to-motion generation. Unlike previous works, our training data are only
comprised of noisy annotated motions and unannotated motions. https://nhathoang2002.github.io/MotionMix-page/
Abstract
Controllable generation of 3D human motions becomes an
important topic as the world embraces digital transforma-
tion. Existing works, though making promising progress with
the advent of diffusion models, heavily rely on meticulously
captured and annotated (e.g., text) high-quality motion cor-
pus, a resource-intensive endeavor in the real world. This
motivates our proposed MotionMix, a simple yet effective
weakly-supervised diffusion model that leverages both noisy
*Work done during an internship at Huawei
†Corresponding author
Copyright © 2024, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
and unannotated motion sequences. Specifically, we sepa-
rate the denoising objectives of a diffusion model into two
stages: obtaining conditional rough motion approximations
in the initial T − T ∗ steps by learning the noisy annotated
motions, followed by the unconditional refinement of these
preliminary motions during the last T ∗ steps using unanno-
tated motions. Notably, though learning from two sources of
imperfect data, our model does not compromise motion gen-
eration quality compared to fully supervised approaches that
access gold data. Extensive experiments on several bench-
marks demonstrate that our MotionMix, as a versatile frame-
work, consistently achieves state-of-the-art performances on
text-to-motion, action-to-motion, and music-to-dance tasks.
arXiv:2401.11115v1  [cs.CV]  20 Jan 2024
1
Introduction
The rapidly arising attention and interest in digital humans
bring up the great demand for human motion generation, in
a wide range of fields such as industrial game and movie ani-
mation (Ling et al. 2020), human-machine interaction (Kop-
pula and Saxena 2013), VR/AR and metaverse development
(Lee et al. 2021). Over the years, automated generation
of human motions that align with user preferences, span-
ning aspects such as prefix poses (Ruiz, Gall, and Moreno-
Noguer 2018; Guo et al. 2022c), action classes (Petrovich,
Black, and Varol 2021; Cervantes et al. 2022), textual de-
scriptions (Petrovich, Black, and Varol 2022; Ahuja and
Morency 2019; Tevet et al. 2022), or music (Aristidou et al.
2021; Siyao et al. 2022; Gong et al. 2023), has been a focal
point of research. Recently, building upon the advancement
of diffusion models, human motion generation has experi-
enced a notable improvement in quality and controllability.
However, these prior diffusion models are commonly trained
on well-crafted motions that come with explicit annotations
like textual descriptions. While capturing motions from the
real world is a laborious effort, annotating these motion se-
quences further urges the matter.
In contrast, motions with lower fidelity or fewer anno-
tations are more accessible in the real world. For exam-
ple, 3D human motions are readily extracted from monoc-
ular videos through video-based pose estimation (Kanazawa
et al. 2017; Kocabas, Athanasiou, and Black 2019; Choutas
et al. 2020). Meanwhile, a wealth of unannotated motion se-
quences, such as those available from Mixamo (Inc. 2021)
and AMASS (Mahmood et al. 2019), remains largely un-
tapped. This brings up the question we are investigating in
this work, as illustrated in Figure 1. Can we learn reliable
diffusion models for controllable motion generation based
on the supervision of noisy and the unannotated motion se-
quences?
Fortunately, with the inherent denoising mechanism of
diffusion models, we are able to answer this question with
a simple yet effective solution that applies separate diffu-
sion steps regarding the source of training motion data, re-
ferred to as MotionMix. To demonstrate our application and
approach, we split each gold annotated motion dataset into
two halves: the first half of the motions are injected with
random-scale Gaussian noises (noisy half), and the second
half is deprived of annotations (clean half). As in Figure 2,
the diffusion model bases on the clean samples for diffusion
steps in [1, T ∗], with condition input erased. Meanwhile,
noisy motions supervise the model with explicit conditions
for the rest of steps [T ∗ + 1, T]. Note T ∗ is an experimen-
tal hyper-parameter, with its role analyzed in later ablation
studies. Our key insight is that, during sampling, starting
from Gaussian noises, the model first produces rough mo-
tion approximations with conditional guidance in the initial
T −T ∗ steps; afterward, these rough approximations are fur-
ther refined by unconditional sampling in the last T ∗ steps.
Yet learning with weak supervision signals, our proposed
MotionMix empirically facilitates motion generation with
higher quality than fully supervised models on multiple ap-
plications. Benefiting from the conciseness of design, Mo-
tionMix finds its place in many applications. In this work,
we thoroughly examine the effectiveness and flexibility of
the proposed approach through extensive experiments on
benchmarks of text-to-motion, music-to-dance, and action-
to-motion tasks.
The main contributions of our work can be summarized
as follows:
• We present MotionMix, the first weakly-supervised ap-
proach for conditional diffusion models that utilizes both
noisy annotated and clean unannotated motion sequences
simultaneously.
• We demonstrate that by training with these two sources
of data simultaneously, MotionMix can improve upon prior
state-of-the-art motion diffusion models across various tasks
and benchmarks, without any conflict.
• Our approach opens new avenues for addressing the
scarcity of clean and annotated motion sequences, paving
the way for scaling up future research by effectively har-
nessing available motion resources.
2
Related Work
2.1
Weakly-Supervised Learning
To tackle the limited availability of annotated data, re-
searchers have been exploring the use of semi-supervised
generative models, using both annotated and unannotated
data (Kingma et al. 2014; Li et al. 2017; Lucic et al.
2019). However, the investigation of semi-supervised dif-
fusion models remains limited (You et al. 2023), possibly
due to the significant performance gap observed between
conditional and unconditional diffusion models (Bao et al.
2022; Dhariwal and Nichol 2021; Tevet et al. 2022). More-
over, many state-of-the-art models, such as Stable Diffusion
(Rombach et al. 2021), implicitly assume the availability of
abundant annotated data for training (Chang, Koulieris, and
Shum 2023; Kawar et al. 2023). This assumption poses a
challenge when acquiring high-quality annotated data is ex-
pensive, particularly in the case of 3D human motion data.
Recent interest has emerged in developing data-efficient
approaches for training conditional diffusion models with
low-quality data (Daras et al. 2023; Kawar et al. 2023),
or utilizing unsupervised (Tur et al. 2023), semi-supervised
(You et al. 2023), self-supervised methods (Miao et al.
2023). These approaches have exhibited promising results
across various domains and hold potential for future explo-
ration of diffusion models when handling limited annotated
data. However, in the domain of human motion generation,
efforts toward these approaches have been even more lim-
ited. One related work, Make-An-Animation (Azadi et al.
2023), trains a diffusion model utilizing unannotated mo-
tions in a semi-supervised setting. In contrast, our work in-
troduces a unique aspect by training with noisy annotated
motion and clean unannotated motion.
2.2
Conditional Motion Generation
Over the years, human motion generation has been exten-
sively studied using various signals, including prefix poses
(Ruiz, Gall, and Moreno-Noguer 2018; Guo et al. 2022c;
Petrovich, Black, and Varol 2021), action classes (Guo et al.
2020; Petrovich, Black, and Varol 2021; Cervantes et al.
MotionMix
Clean
Motion
Supervision
Supervision
Noisy
Motion
MotionMix
MotionMix
Stage 1: Conditional Denoising
MotionMix
MotionMix
Stage 2: Unconditional Denoising
Figure 2: (Left) Training Process. The model is trained with a mixture of noisy and clean data. A noise timestep in ranges of
[1, T ∗] and [T ∗ + 1, T] is sampled respectively for each clean and noisy data. Here, T ∗ is a denoising pivot that determines the
starting point from which the diffusion model refines the noisy motion sequences into clean ones without any guidance. (Right)
Sampling Process. The sampling process consists of two stages. In Stage-1 from timestep T to T ∗ + 1, the model generates
the rough motion approximations, guided by the conditional input c. In Stage-2 from timestep T ∗ to 1, the model refines these
approximations to high-quality motion sequences while the input c is masked.
2022), textual descriptions (Guo et al. 2022b; Petrovich,
Black, and Varol 2022; Ghosh et al. 2021; Guo et al. 2022a;
Ahuja and Morency 2019; Bhattacharya et al. 2021), or mu-
sic (Li et al. 2020; Aristidou et al. 2021; Li et al. 2021;
Siyao et al. 2022; Gong et al. 2023). However, it is non-
trivial for these methods to align the distributions of mo-
tion sequences and conditions such as natural languages or
speech (Chen et al. 2022). Diffusion models resolve this
problem using a dedicated multi-step gradual diffuse and
denosing process(Ramesh et al. 2022a; Saharia et al. 2022;
Ho et al. 2022). Recent advancements, such as MDM (Tevet
et al. 2022), MotionDiffuse (Zhang et al. 2022), MLD (Chen
et al. 2022), have demonstrated the ability of diffusion-based
models to generate plausible human motion, guided by tex-
tual descriptions or action classes. In the domain of music,
EDGE (Tseng, Castellon, and Liu 2022) showcased high-
quality dance generation in diverse music categories. Never-
theless, these works still rely on high-quality motion datasets
with annotated guidance.
3
Method
3.1
Problem Formulation
Conditional motion generation involves generating high-
quality and diverse human motion sequences based on a de-
sired conditional input c. This input can take various forms,
such as a textual description w1:N of N words (Guo et al.
2022b), an action class a ∈ A (Guo et al. 2020), music audio
m (Li et al. 2021), or even an empty condition c = ∅ (uncon-
ditional input) (Raab et al. 2022). Our goal is to train a diffu-
sion model in a weakly-supervised manner, using both noisy
motion sequences with conditional inputs c = {∅, a, w, c}
(where ∅ is used when the classifier-free guidance (Ho and
Salimans 2022) is applied) and clean motion sequences with
unconditional input c = ∅. Despite being trained with noisy
motions, our model can consistently generate plausible mo-
tion sequences. To achieve this, we propose a two-stage re-
verse process, as illustrated in Figure 2.
3.2
Diffusion Probabilistic Model
The general idea of a diffusion model, as defined by the
denoising diffusion probabilistic model (DDPM) (Ho, Jain,
and Abbeel 2020), is to design a diffusion process that grad-
ually adds noise to a data sample and trains a neural model
to learn a reverse process of denoising it back to a clean
sample. Specifically, the diffusion process can be modeled
as a Markov noising process with {xt}T
t=0 where x0 ∼ p(x)
is the clean sample drawn from the data distribution. The
noised xt is obtained by applying Gaussian noise ϵt to x0
through the posterior:
q(xt|x0) = N(xt; √¯αtx0, (1 − ¯αt)I)
(1)
where ¯αt ∈ (0, 1) are constants which follow a monotoni-
cally decreasing scheduler. Thus, when ¯αt is small enough,
we can approximate xT ∼ N(0, I).
In the reverse process, given the condition c, a neural
model fθ is trained to estimate the clean sample x0 (Ramesh
et al. 2022b) or the added noise ϵt (Ho, Jain, and Abbeel
2020) for all t. The model parameters θ are optimized using
the “simple” objective introduced by Ho, Jain, and Abbeel:
Lsimple = Et∼[1,T ],st
h
∥st − fθ(xt, t, c)∥2i
(2)
where the target objective st refers to either x0 or ϵt for ease
of notation.
3.3
Training
We propose a novel weakly-supervised learning approach
that enables a diffusion model to effectively utilize both
noisy and clean motion sequences. During the training
phase, we construct batches comprising both noisy and clean
samples, each coupled with a corresponding guidance condi-
tion c, as further detailed in Subsection 3.5. To learn the de-
noising process, we apply the diffusion process to this batch
using Equation 1 with varying noise timesteps. In contrary
to the conventional training, where both noisy and clean mo-
tion sequences are treated as the ground truth x0 with dif-
fusion steps spanning [1, T], our approach adopts separate
ranges for different data types. For noisy samples, we ran-
domly select noise timesteps t ∈ [T ∗+1, T], while for clean
samples, we confine them to t ∈ [1, T ∗]. Here, T ∗ serves
as a denoising pivot, determining when the diffusion model
starts refining noisy motion sequences into cleaner versions.
This pivot is especially crucial in real-world applications,
where motion capture data might be corrupted by noise due
to diverse factors. This denoising strategy for noisy motions
draws inspiration from (Nie et al. 2022), which purified ad-
versarial images by diffusing them up to a specific timestep
T ∗ before denoising to clean images. The determination of
T ∗ typically relies on empirical estimation, its impact on
generation quality is further analyzed in Table 4.
Through this training process, the model becomes adept
at generating initial rough motions from T to T ∗ + 1, and
subsequently refining these rough motions into high-quality
ones from T ∗ to 1. By dividing into two distinct time ranges,
the model can effectively learn from both noisy and clean
motion sequences as ground truth without any conflict.
3.4
Two-stage Sampling and Guidance
Our approach introduces a modification to the conventional
DDPM sampling procedure, which commonly relies on the
same explicit conditional input c to guide the denoising op-
eration at each time step t, initiating from T and denois-
ing back to the subsequent time step t − 1 until reaching
t = 0. However, it is important to note that our work specifi-
cally focuses on clean, unannotated samples. As discussed in
Subsection 3.3, these samples are trained using an identical
guidance condition c = ∅ confined within the time interval
[1, T ∗]. Consequently, if the conventional DDPM sampling
process is employed within this temporal range, it could po-
tentially lead to jittering or the generation of unrealistic mo-
tions. This occurs because the model is not trained to handle
varying conditions within this specific range. To tackle this
issue, we adopt a distinct strategy to align the sampling pro-
cess accordingly. Specifically, when the model reaches the
denoising pivot T ∗ during the sampling, we substitute the
conditional input with c = ∅ starting from T ∗.
In the case of using classifier-free guidance (Ho and Sal-
imans 2022), guided inference is employed for all t, which
involves generating motion samples through a weighted sum
of unconditionally and conditionally generated samples:
ˆs(xt, t, c) = w · fθ(xt, t, c) + (1 − w) · fθ(xt, t, ∅)
(3)
where w is the guidance weight during sampling.
3.5
Data Preparation
To facilitate our setting, we randomly partition an existing
training dataset into two subsets. In one subset, we retain the
annotated condition and introduce noise to the motion se-
quences to approximate the real noisy samples. In the other
subset, we reserve the cleanliness of the data and discard the
annotated conditions by replacing them as c = ∅.
Motivated by the use of Gaussian noises in approximat-
ing noisy samples in previous works (Tiwari et al. 2022;
Fiche et al. 2023), we apply the Equation 1 to gradually in-
troduce noise to the clean samples. Since the precise noise
schedule in real-world motion capture data is unknown, we
address this uncertainty by applying a random noising step
sampled from the range [T1, T2], where T1 and T2 are hyper-
parameters simulating the level of disruption in real noisy
motions. Interestingly, our experiments (Tab. 6) show that
neither smaller value of T1, T2 nor small T2 − T1 relates
to better final performance. Due to page limit, examples of
noisy motions for training are delegated to present in sup-
plementary videos.
It is worth noting that the processes of dividing the train-
ing dataset and preparing noisy samples, and unannotated
samples only take place on the side of the training dataset.
The remaining evaluation dataset, diffusion models, and
training process are kept unchanged as in previous works.
4
Experiments
We thoroughly experiment our MotionMix in diverse tasks
using different conditional motion generation diffusion
models as backbones: (1) MDM (Tevet et al. 2022) for
text-to-motion task on HumanML3D (Guo et al. 2022b),
KIT-ML (Plappert, Mandery, and Asfour 2016), as well as
action-to-motion task on HumanAct12 (Guo et al. 2020) and
UESTC (Ji et al. 2018); (2) MotionDiffuse (Zhang et al.
2022) for text-to-motion task; and (3) EDGE (Tseng, Castel-
lon, and Liu 2022) for music-to-dance task on AIST++ (Li
et al. 2021).
4.1
Models
• MDM (Tevet et al. 2022) MDM is a lightweight diffusion
model that utilizes a transformer encoder-only architecture
(Vaswani et al. 2017). Its training objective is to estimate
the clean sample x0 (Ramesh et al. 2022b). In the text-to-
motion task, MDM encodes the text description c = w1:N
using a frozen CLIP-VIT-B/32. During training, classifier-
free guidance (Ho and Salimans 2022) is employed by ran-
domly masking the condition with c = ∅ with a probabil-
ity of 10%. Meanwhile, in the action-to-motion task, the
conditioning c = a is projected to a linear action embed-
ding, and the classifier-free guidance is not applied. Addi-
tionally, three geometric losses are incorporated as training
constraints for this task.
• MotionDiffuse (Zhang et al. 2022) MotionDiffuse em-
ploys a series of transformer decoder layers (Vaswani et al.
2017) and incorporates a frozen CLIP-VIT-B/32 for text de-
scription encoding. However, in contrast to MDM, Motion-
Diffuse focuses on estimating the noise ϵ as its training ob-
jective and does not incorporate the classifier-free guidance
(Ho and Salimans 2022).
• EDGE (Tseng, Castellon, and Liu 2022). EDGE shares
similarities with MDM in terms of its transformer encoder-
only architecture (Vaswani et al. 2017) and the adoption of
geometric losses for the music-to-dance task. In addition, the
authors introduced a novel Contact Consistency Loss to en-
hance foot contact prediction control. In the case of music
conditioning, EDGE utilizes a pre-trained Jukebox model
(Dhariwal et al. 2020) to extract audio features m from mu-
sic, which then serve as conditioning input c = m. During
inference, the approach incorporates classifier-free guidance
(Ho and Salimans 2022) with a masking probability of 25%.
4.2
Text-to-motion
• Datasets. Two leading benchmarks used for text-driven
motion generation are HumanML3D (Guo et al. 2022b) and
KIT-ML (Plappert, Mandery, and Asfour 2016). The KIT-
ML dataset provides 6,353 textual descriptions correspond-
ing to 3,911 motion sequences, while the HumanML3D
dataset combines 14,616 motion sequences from Human-
Act12 (Guo et al. 2020) and AMASS (Mahmood et al.
2019), along with 44,970 sequence-level textual descrip-
tions. As suggested by Guo et al., we adopt a redundant
motion representation that concatenates root velocities, root
height, local joint positions, velocities, rotations, and the
binary labels of foot contact. This representation, denoted
as x ∈ RN×D, is used for both HumanML3D and KIT-
ML, with D being the dimension of the pose vector and is
equal to 263 for HumanML3D or 251 for KIT-ML. This mo-
tion representation is also employed in previous work (Tevet
et al. 2022; Zhang et al. 2022; Chen et al. 2022).
• Implementation Details. On both datasets, we train the
MDM and MotionDiffuse models from scratch for 700K
and 200K steps, respectively. To approximate the noisy mo-
tion data ˜x from x ∈ RN×D, we use noisy ranges [20, 60]
and [20, 40] for HumanML3D and KIT-ML, respectively.
• Evaluation Metrics. As suggested by Guo et al., the met-
rics are based on a text feature extractor and a motion fea-
ture extractor jointly trained under contrastive loss to pro-
duce feature vectors for matched text-motion pairs. R Pre-
cision (top 3) measures the accuracy of the top 3 retrieved
descriptions for each generated motion, while the Frechet
Inception Distance (FID) is calculated using the motion ex-
tractor as the evaluator network. Multimodal Distance mea-
sures the average Euclidean distance between the motion
feature of each generated motion and the text feature of its
corresponding description in the test set. Diversity measures
the variance of the generated motions across all action cate-
gories, while MultiModality measures the diversity of gen-
erated motions within each condition.
• Quantitative Result. Table 1 presents quantitative results
of our weakly-supervised MotionMix using MDM and Mo-
tionDiffuse backbones, in comparison with their original
models that are trained with fully annotated and clean mo-
tion sequences. To our surprise, in most settings, Motion-
Mix even improves the motion quality (i.e., FID) and mul-
timodal consistency (i.e., R Precision) upon the fully super-
vised backbones. For example, on HumanML3D and KIT-
ML dataset, MDM (MotionMix) commonly reduces FID by
over 0.16 compare to MDM; this comes with the enhance-
ment of both R Precision and Multimodal Distance. We may
attribute this to the better generalizability and robustness by
involving noisy data in our MotionMix. On the specifical
setting of MotionDiffuse (MotionMix) on HumanML3D,
though being inferior to the original MotionDiffuse, our
MotionMix maintains competitive performance on par with
other fully supervised baselines, such as Language2Pose
(Ahuja and Morency 2019), Text2Gestures (Bhattacharya
et al. 2021), Guo et al. (Guo et al. 2022b).
4.3
Action-to-motion
• Datasets. We evaluate our MotionMix on two bench-
marks: HumanAct12 (Guo et al. 2020) and UESTC (Ji
et al. 2018). HumanAct12 offers 1,191 motion clips cate-
gorized into 12 action classes, while UESTC provides 24K
sequences of 40 action classes. For this task, we use the
pre-processed sequences provided by Petrovich, Black, and
Varol as the gold clean motion sequences, and further pro-
cess them to approximate noisy samples. A pose sequence of
N frames is represented in the 24-joint SMPL format (Loper
et al. 2015), using the 6D rotation (Zhou et al. 2018) for ev-
ery joint, resulting in p ∈ RN×24×6. A single root trans-
lation r ∈ RN×1×3 is padded and concatenated with p to
obtain the final motion representation x = Concat([p, r]) ∈
RN×25×6.
• Implementation Details. Following the experimental
setup by Tevet et al., we train the MDM (MotionMix) from
scratch on the HumanAct12 and UESTC datasets for 750K
and 2M steps, respectively. In our approximation prepro-
cess, we determine the amount of noise to be injected into
both the pose sequence p and the root translation r by ran-
domly sampling from range [10, 30]. The resulting ˜p and ˜r
are then concatenated to obtain noisy motion ˜x.
• Evaluation Metrics. Four metrics are used to assess the
quality of generated motions. The FID is commonly used to
evaluates the overall quality of generated motions. Accuracy
measures the correlation between the generated motion and
its action class. Diversity and MultiModality are similar to
the text-to-motion metrics.
• Quantitative Result. Table 2 presents the performance
outcomes of MDM (MotionMix) and several baseline mod-
els, including Action2Motion (Guo et al. 2020), ACTOR
(Petrovich, Black, and Varol 2021), INR (Cervantes et al.
2022), MLD (Chen et al. 2022), and MDM (Tevet et al.
2022), on both the HumanAct12 and UESTC datasets. Fol-
lowing the methodology of Tevet et al., we perform 20 eval-
uations, each comprising 1000 samples, and present average
scores with a confidence interval of 95%. The results high-
light that our MotionMix achieves competitive performance
with significantly fewer high-quality annotated data in-
stances. In particular, the improvement seen on the UESTC
dataset underscores its efficacy in training with noisy mo-
tion data from the real-world scenario. On the other hand,
the deterioration in performance on HumanAct12 suggests
that our approach is better suited for larger datasets, given
that the size of HumanAct12 is remarkably smaller than that
of UESTC. Nevertheless, our supplementary videos demon-
strate that the model trained on HumanAct12 remains ca-
pable of generating quality motion sequences based on the
provided action classes.
4.4
Music-to-dance
• Datasets. We utilize the AIST++ dataset (Li et al. 2021),
which comprises 1,408 high-quality dance motions accom-
panied by music from a diverse range of genres. Following
the experimental setup proposed by Tseng, Castellon, and
Liu, we adopt a configuration in which all training sam-
ples are trimmed to 5 seconds and 30 FPS. Similarly to
Real
MDM
MDM(MotionMix)
MotionDiffuse
MotionDiffuse (MotionMix)
“a man mimics a throwing motion with his left hand.”
“person appears to be holding some thing with both hands and then throws it forward with their right hand.”
“the person climbs up something for few steps. ”
Figure 3: Qualitative performance of baseline MDM and MotionDiffuse models, trained exclusively on high-quality annotated
data, with our MotionMix approach, which learns from imperfect data sources. Their visualized motion results are presented
alongside real references for three distinct text prompts. Please refer to supplementary files for more animations.
the action-to-motion data, we concatenate N-frame pose se-
quences denoted as p ∈ RN×24×6=N×144, along with a sin-
gle root translation denoted as r ∈ RN×3, and an additional
binary contact label for the heel and toe of each foot de-
noted as b ∈ {0, 1}N×4. Consequently, EDGE is trained us-
ing the final motion representation x = Concat([b, r, p]) ∈
RN×151.
• Implementation Details. Similar to the action-to-motion
task, we inject noise into both p and r using the same noise
timestep sampled from [20, 80]. Since the contact label b is
obtained from both p and r, it is not necessary to inject noise
into b. Following the setup of Tseng, Castellon, and Liu, we
train both the EDGE model and our EDGE (MotionMix)
from scratch on AIST++ for 2000 epochs.
• Evaluation Metrics. To evaluate the quality of the gener-
ated dance, we adopt the same evaluation settings as sug-
gested in paper EDGE, including Physical Foot Contact
(PFC), Beat Alignment, and Diversity. PFC is a physically-
inspired metric that evaluates physical plausibility by cap-
turing realistic foot-ground contact without explicit physical
modeling or assuming static contact. Following the previous
works (Li et al. 2021; Siyao et al. 2022), Beat Alignment
evaluates the tendency of generated dances to follow the beat
of the music, while Diversity measures the distribution of
generated dances in the “kinetic” (Distk) and “geometric”
(Distg) feature spaces.
• Quantitative Result. In contrary to prior works, which
typically reported only a single evaluation result, we have
observed that the metrics can be inconsistent. Thus, to offer a
more comprehensive evaluation, we present the average and
95% confidence interval, derived from 20 evaluation runs
for our retrained EDGE model and our EDGE (MotionMix)
variant. For Bailando (Siyao et al. 2022) and FACT (Li et al.
2021), we directly fetched results from the paper EDGE
(Tseng, Castellon, and Liu 2022). The results in Table 3
vividly demonstrate that, our EDGE (MotionMix) signif-
icantly outperforms the baseline across all metrics, show-
casing improvements of up to 43.1% in PFC and 95.0% in
Distk. This further reinforces the generalizability prowess of
our MotionMix approach, consistent with the outcomes ob-
served in our text-to-motion experiments.
5
Ablation Studies
MotionMix is introduced as a potential solution that enables
the diffusion model to effectively leverage both noisy mo-
tion sequences and unannotated data. To demonstrate the
efficacy of this approach, we approximate noisy samples
from existing datasets and train the model on them, which
incorporate several essential hyperparameters: (1) the de-
noising pivot T ∗; (2) the ratio of noisy and clean data for
training; (3) the noisy range [T1, T2] to approximate noisy
data. In this section, we thoroughly assess the impact of
each hyperparameters within MotionMix. All ablation ex-
periments are carried out on the HumanML3D dataset us-
Method
R Precision
(top 3)↑
FID↓
Multimodal
Dist.↓
Diversity→
Multimodality↑
HumanML3D
Real Motion
0.797±.002
0.002±.000
2.974±.008
9.503±.065
-
Language2Pose
0.486±.002
11.02±.046
5.296±.008
7.676±.058
-
Text2Gestures
0.345±.002
7.664±.030
6.030±.008
6.409±.071
-
Guo et al.
0.740±.003
1.067±.002
3.340±.008
9.188±.002
2.090±.083
MLD
0.772±.002
0.473±.013
3.196±.010
9.724±.082
2.413±.079
MDM
0.611±.007
0.544±.440
5.566±.027
9.559±.860
2.799±.072
MDM (MotionMix)
0.632±.006 (↑3.4%)
0.381±.042 (↑30.0%)
5.325±.026 (↑4.3%)
9.520±.090 (↑69.6%)
2.718±.019 (↓2.9%)
MotionDiffuse
0.782±.001
0.630±.001
3.113±.001
9.410±.049
1.553±.042
MotionDiffuse (MotionMix)
0.738±.006 (↓5.6%)
1.021±.071 (↓62.1%)
3.310±.020 (↓6.3%)
9.297±.083 (↓121.5%)
1.523±.153 (↓1.9%)
KIT-ML
Real Motion
0.779±.006
0.031±.004
2.788±.012
11.080±.097
-
Language2Pose
0.483±.005
6.545±.072
5.147±.030
9.073±.100
-
Text2Gestures
0.338±.004
12.12±.183
6.964±.029
9.334±.079
-
Guo et al.
0.693±.007
2.770±.109
3.401±.008
10.910±.119
1.482±.065
MLD
0.734±.007
0.404±.027
3.204±.027
10.800±.117
2.192±.071
MDM
0.396±.004
0.497±.021
9.191±.022
10.847±.109
1.907±.214
MDM (MotionMix)
0.404±.005 (↑2.0%)
0.322±.020 (↑35.2%)
9.068±.019 (↑1.3%)
10.781±.098 (↓28.3%)
1.946±.019 (↑2.0%)
MotionDiffuse
0.739±.004
1.954±.062
2.958±.005
11.100±.143
0.730±.013
MotionDiffuse (MotionMix)
0.742±.005 (↑0.4%)
1.192±.073 (↑39.0%)
3.066±.018 (↓3.6%)
10.998±.072 (↓310%)
1.391±.111 (↑90.5%)
Table 1: Quantitative results of text-to-motion on the test set of HumanML3D and KIT-ML. Note all baselines are trained with
gold data. We run all the evaluation 20 times (except Multimodality runs 5 times) and ± indicates the 95% confidence interval. ↑
means higher is better, ↓ means lower is better, → means closer to the real distribution is better. The ↑ x% and ↓ x% indicate the
percentage difference in performance improvement or deterioration when comparing our approach to its correspond baseline.
Method
FID ↓
Accuracy ↑
Diversity →
MultiModality →
HumanAct12
Real Motion
0.053±.003
0.995±.001
6.835±.045
2.604±.040
Action2Motion
0.338±.015
0.917±.001
6.850±.050
2.511±.023
ACTOR
0.120±.000
0.955±.008
6.840±.030
2.530±.020
INR
0.088±.004
0.973±.001
6.881±.048
2.569±.040
MLD
0.077±.004
0.964±.002
6.831±.050
2.824±.038
MDM
0.100±.000
0.990±.000
6.860±.050
2.520±.010
MDM (MotionMix)
0.196±.007 (↓96%)
0.930±.003 (↓6.1%)
6.836±.062 (↑96%)
3.043±.054 (↓422.6%)
UESTC
Real Motion
2.790±.290
0.988±.001
33.349±.320
14.160±.060
ACTOR
23.430±2.200
0.911±.003
31.960±.330
14.520±.090
INR
15.000±.090
0.941±.001
31.590±.190
14.680±.070
MLD
15.790±.079
0.954±.001
33.520±.140
13.570±.060
MDM
12.810±1.460
0.950±.000
33.100±.290
14.260±.120
MDM (MotionMix)
11.400±.393 (↑11%)
0.960±.003 (↑1.1%)
32.806±.176 (↓118%)
14.277±.094 (↓17%)
Table 2: Quantitative results of action-to-motion on the Hu-
manAct12 dataset and UESTC test set. We run the evalua-
tion 20 times, and the metric details are similar to Table 1.
Method
PFC ↓
Beat Align. ↑
Distk →
Distg →
Real Motion
1.380
0.314
9.545
7.766
Bailando
1.754
0.23
10.58
7.72
FACT
2.2543
0.22
10.85
6.14
EDGE†
1.605±.224
0.224±.025
5.549±.783
4.831±.752
EDGE (MotionMix)
1.988±.120 (↑43.1%)
0.256±.013 (↑13.3%)
10.103±2.039 (↑95.0%)
6.595±.173 (↑15.1%)
Table 3: Quantitative results of music-to-dance on the
AIST++ test set. We run the evaluation 20 times, and the
metric details are similar to Table 1. † denotes the EDGE
model that is re-trained by us.1
ing the MDM model with the identical settings described in
Subsection 4.2.
1The results of the baseline EDGE model is different from the
ones submitted to AAAI’24. Nonetheless, our EDGE (MotionMix)
still achieves overall better performance.
5.1
Effect of The Denoising Pivot T ∗
We begin our ablation studies by examining the impact of
the denoising pivot T ∗. To evaluate its impact, we conduct
experiments with a fixed noisy range of [T1, T2] = [20, 60],
a noisy ratio of 50%, and evaluate various T ∗ values, encom-
passing 20, 40, 60, and 80. The results, detailed in Table 4,
reveal a notable observation: a roughly estimated denois-
ing pivot is sufficient for real-world scenarios, as evidenced
by the competitive outcomes across various T ∗ values. This
robustness underlines the versatility of our MotionMix ap-
proach. Additionally, selecting a very small denoising pivot
(e.g., T ∗ = 0 or 20) enables conditions to steer the model
toward diverse rough motion sequences before the refining
phase, as reflected in the MModality score trend. However,
this small value may potentially compromise motion qual-
ity, leading to subpar results in other metrics. In contrast, the
choice of T ∗ = 60, which is well aligned with our prede-
fined noisy range, yields superior results in multiple eval-
uation metrics. This sheds light on the need of tuning the
denoising pivot to optimize the results, as this hyperparam-
eter determines the starting point for the diffusion model to
transform initial noisy motion into high-quality sequences.
5.2
Effect of Noisy/Clean Data Ratio
In this ablation study, we evaluate how the noisy/clean
data ratio affects our approach by keeping T ∗ = 60 and
[T1, T2] = [20, 60] constant. We experiment with various
noisy ratios of 30%, 50%, and 70%. The results, presented
in Table 5, show interesting trends across the evaluation met-
rics. Notably, higher noisy ratios (i.e., 50% and 70%) con-
Method
R Precision
(top 3)↑
FID↓
Multimodal
Dist.↓
Diversity→
Multimodality↑
Real Motion
0.797±.002
0.002±.000
2.974±.008
9.503±.065
-
MDM (Tevet et al. 2022)
0.611±.007
0.544±.440
5.566±.027
9.559±.860
2.799±.072
50% noisy, T1=20, T2=60
MDM (MotionMix) (T ∗=0)
0.598±.006
0.714±.045
5.503±.036
9.750±.123
3.044±.054
MDM (MotionMix) (T ∗=20)
0.601±.005
0.497±.048
5.562±.026
9.414±.092
2.935±.059
MDM (MotionMix) (T ∗=40)
0.604±.008
0.402±.032
5.524±.033
9.396±.094
2.747±.070
MDM (MotionMix) (T ∗=60)
0.632±.006
0.381±.042 5.325±.026
9.520±.090
2.718±.019
MDM (MotionMix) (T ∗=80)
0.594±.005
0.589±.059
5.670±.033
9.242±.086
2.602±.057
Table 4: We evaluate MDM (MotionMix) on the Hu-
manML3D test set using different values of the denoising
pivot T ∗. The metrics are calculated in the same manner as
detailed in Table 1. The best and the second best result are
bold and underlined respectively.
Method
R Precision
(top 3)↑
FID↓
Multimodal
Dist.↓
Diversity→
Multimodality↑
Real Motion
0.797±.002
0.002±.000
2.974±.008
9.503±.065
-
MDM
0.611±.007
0.544±.440
5.566±.027
9.559±.860
2.799±.072
T1=20, T2=60, T ∗=60
MDM (MotionMix) (30% noisy)
0.601±.007
0.898±.045
5.581±.030
9.080±.092
2.856±.074
MDM (MotionMix) (50% noisy)
0.632±.006
0.381±.042
5.325±.026
9.520±.090
2.718±.019
MDM (MotionMix) (70% noisy)
0.615±.006
0.359±.030 5.545±.031
9.457±.098
2.867±.107
Table 5: We evaluate MDM (MotionMix) on the Hu-
manML3D test set using different ratios for noisy and clean
data. The metrics are calculated in the same manner as de-
tailed in Table 1. The best and the second best result are bold
and underlined respectively.
sistently outperform the lower ratio (i.e., 30%). Note that,
a higher noisy ratio allows the model to access a wider
range of annotated text conditions, yielding better R Preci-
sion and Multimodal Distance. On the other hand, the 30%
ratio, despite being trained with a greater amount of clean
data, exhibits suboptimal motion quality (scoring 0.898 in
FID) in comparison to other supervised baselines in Table 1,
such as Language2Pose (FID of 11.02), Text2Gestures (FID
of 7.664), Guo et al. (FID of 1.067). Nevertheless, it still
achieves results on par with the supervised MDM baseline in
terms of multimodal consistency (i.e. Multimodal Distance).
These observations underscore the resilience of our Motion-
Mix approach to variations in the noisy/clean data ratio.
5.3
Effect of The Noisy Range
The purpose of the noisy range in our work is to approxi-
mate the noise schedule found in real-world motion capture
data. Thus, for different datasets in Section 4, we choose
noisy ranges based on the visualization of motion from each
dataset. For example, UESTC (Ji et al. 2018) contains noisy
mocap data, while HumanML3D (Guo et al. 2022b), de-
rived from AMASS (Mahmood et al. 2019), consists of
clean motion sequences. This ablation, therefore, compre-
hensively evaluates the effectiveness of our MotionMix ap-
proach when handling different noisy levels of motion se-
quences. We categorize the evaluations into two groups: nar-
row/wide ranges of noise and low/high schedules of noise.
All experiments are conducted with a noisy ratio of 50%,
and the denoising pivot T ∗ is equal to the chosen T2. The
results are presented in Table 6.
•
Narrow/Wide
Noisy
Range.
Three
noisy
ranges
[T1, T2] ∈ {[20, 40], [20, 60], [20, 80]} are set to analyze the
Method
R Precision
(top 3)↑
FID↓
Multimodal
Dist.↓
Diversity→
Multimodality↑
Real Motion
0.797±.002
0.002±.000
2.974±.008
9.503±.065
-
MDM
0.611±.007
0.544±.440
5.566±.027
9.559±.860
2.799±.072
50% noisy, T ∗ = T2
MDM (MotionMix) (T1=20, T2=40)
0.616±.006
0.451±.033
5.459±.027
9.585±.101
2.585±.076
MDM (MotionMix) (T1=20, T2=60)
0.632±.006
0.381±.042 5.325±.026
9.520±.090
2.718±.019
MDM (MotionMix) (T1=20, T2=80)
0.604±.004
0.614±.060
5.540±.024
9.554±.104
2.768±.095
50% noisy, T ∗ = T2
MDM (MotionMix) (T1=10, T2=30)
0.592±.008
0.713±.048
5.633±.028
9.567±.109
2.783±.139
MDM (MotionMix) (T1=20, T2=40)
0.616±.006
0.451±.033
5.459±.027
9.585±.101
2.585±.076
MDM (MotionMix) (T1=40, T2=60)
0.598±.004
0.554±.076
5.600±.031
9.479±.100
2.815±.094
MDM (MotionMix) (T1=60, T2=80)
0.597±.008
0.437±.039 5.554±.033
9.452±.092
2.895±.079
Table 6: We evaluate MDM (MotionMix) on the Hu-
manML3D test set using different noisy ranges [T1, T2] to
approximate the noisy motion sequences. The table presents
two distinct scenarios: the upper block ablates how much the
range spans, while the lower block examines the impact of
the corruption level of noisy motions. The metrics are cal-
culated in the same manner as detailed in Table 1. For each
setting, the best and the second best result are bold and un-
derlined respectively.
effect of how much the range spans. Counterintuitively, the
smaller noisy range does not equal to the better performance.
For example, noisy ranging from 20 to 60 time steps leads
to overall the best performance, compared to range [20, 40].
Though, large noisy range (i.e., [20, 80]) unevitably deterio-
tate the model capacity.
•
Low/High
Noisy
Schedule.
Four
contrast
ranges
[T1, T2] ∈ {[10, 30], [20, 40], [40, 60], [60, 80]} are experi-
mented to evaluate the robustness of MotionMix regarding
corruption level of noisy motions. Notably, our proposed
MotionMix performs reasonably stable on different levels
of corrupted motions. More visual animations are also pro-
vided in our supplementary videos.
6
Conclusion
In this work, we look into the realm of conditional hu-
man motion generation, devling into the challenge of train-
ing with both noisy annotated and clean unannotated mo-
tion sequences. The proposed approach, MotionMix, pio-
neers the utilization of a weakly-supervised diffusion model
as a potential solution for this challenge. This innovative
method effectively overcomes the constraints arising from
limited high-quality annotated data, achieving competitive
results compared to fully supervised models. The versatility
of MotionMix is showcased across multiple motion genera-
tion benchmarks and fundamental diffusion model designs.
Comprehensive ablation studies further bolster its resilience
in diverse noisy schedules and the strategic selection of the
denoising pivot.
A
Application - Real Case Scenario
We experimented training the EDGE model using both
AIST++ and AMASS together. With AMASS (low PFC),
our model can generate plausible motion with less skating
(PFC: 1.06, Tab. 7), visually supported by videos on our
project page.
Method
PFC ↓
Beat Align. ↑
Distk →
Distg →
Real Motion (AIST++)
1.380
0.314
9.545
7.766
Real Motion (AMASS)
1.032
-
-
-
EDGE†
1.605±.224
0.224±.025
5.549±.783
4.831±.752
Half noisy AIST++ and half clean AIST++ (in our main paper)
EDGE (MotionMix)
1.988±.120
0.256±.013
10.103±2.039
6.595±.173
Combine clean AIST++ and clean AMASS
EDGE (MotionMix) (T ∗=20)
1.310±.078
0.236±.007
3.437±.229
4.308±.134
EDGE (MotionMix) (T ∗=40)
1.062±.080
0.240±.009
3.639±.292
4.371±.111
Table 7: Quantitative results of music-to-dance on the AIST++ test set. We run the evaluation 20 times. The best and the second
best result are bold and underlined respectively. † denotes the EDGE model that is re-trained by us; note that its result is different
from our main paper submitted to AAAI due to a multi-gpu bug we faced,
B
Application - Motion Editing
MDM (Tevet et al. 2022) introduced two motion editing ap-
plications: in-betweening and body part editing. These ap-
plications share the same approach, respectively, in the tem-
poral and spatial domains. For in-betweening, they main-
tained the initial and final 25% of the motion sequence as
fixed, while the model generated the intermediate 50%. In
the context of body part editing, specific joints were held
fixed, leaving the model responsible for generating the re-
maining segments. In particular, their experimentation fo-
cused on editing the upper body joints exclusively. In our
supplementary videos, we demonstrate that, in both scenar-
ios, our MDM (MotionMix) does not compromise this use-
ful feature, exhibiting the ability to produce coherence mo-
tion sequences that align with both the motion’s fixed section
and the given condition (if provided).
References
Ahuja, C.; and Morency, L.-P. 2019. Language2Pose: Nat-
ural Language Grounded Pose Forecasting. 2019 Interna-
tional Conference on 3D Vision (3DV), 719–728.
Aristidou, A.; Yiannakidis, A.; Aberman, K.; Cohen-Or,
D.; Shamir, A.; and Chrysanthou, Y. 2021.
Rhythm is a
Dancer: Music-Driven Motion Synthesis with Global Struc-
ture.
IEEE transactions on visualization and computer
graphics, PP.
Azadi, S.; Shah, A.; Hayes, T.; Parikh, D.; and Gupta, S.
2023.
Make-An-Animation: Large-Scale Text-conditional
3D Human Motion Generation. ArXiv, abs/2305.09662.
Bao, F.; Li, C.; Sun, J.; and Zhu, J. 2022. Why Are Condi-
tional Generative Models Better Than Unconditional Ones?
ArXiv, abs/2212.00362.
Bhattacharya, U.; Rewkowski, N.; Banerjee, A.; Guhan,
P.; Bera, A.; and Manocha, D. 2021.
Text2Gestures: A
Transformer-Based Network for Generating Emotive Body
Gestures for Virtual Agents. 2021 IEEE Virtual Reality and
3D User Interfaces (VR), 1–10.
Cervantes, P.; Sekikawa, Y.; Sato, I.; and Shinoda, K. 2022.
Implicit Neural Representations for Variable Length Human
Motion Generation. ArXiv, abs/2203.13694.
Chang, Z.; Koulieris, G. A.; and Shum, H. P. H. 2023. On
the Design Fundamentals of Diffusion Models: A Survey.
ArXiv, abs/2306.04542.
Chen, X.; Jiang, B.; Liu, W.; Huang, Z.; Fu, B.; Chen, T.; Yu,
J.; and Yu, G. 2022. Executing your Commands via Motion
Diffusion in Latent Space. ArXiv, abs/2212.04048.
Choutas, V.; Pavlakos, G.; Bolkart, T.; Tzionas, D.; and
Black, M. J. 2020. Monocular Expressive Body Regression
through Body-Driven Attention. ArXiv, abs/2008.09062.
Daras, G.; Shah, K.; Dagan, Y.; Gollakota, A.; Dimakis,
A. G.; and Klivans, A. R. 2023.
Ambient Diffusion:
Learning Clean Distributions from Corrupted Data. ArXiv,
abs/2305.19256.
Dhariwal, P.; Jun, H.; Payne, C.; Kim, J. W.; Radford, A.;
and Sutskever, I. 2020. Jukebox: A Generative Model for
Music. ArXiv, abs/2005.00341.
Dhariwal, P.; and Nichol, A. 2021. Diffusion Models Beat
GANs on Image Synthesis. ArXiv, abs/2105.05233.
Fiche, G.; Leglaive, S.; Alameda-Pineda, X.; and S’eguier,
R. 2023. Motion-DVAE: Unsupervised learning for fast hu-
man motion denoising. ArXiv, abs/2306.05846.
Ghosh, A.; Cheema, N.; Oguz, C.; Theobalt, C.; and
Slusallek, P. 2021. Synthesis of Compositional Animations
from Textual Descriptions. 2021 IEEE/CVF International
Conference on Computer Vision (ICCV), 1376–1386.
Gong, K.; Lian, D.; Chang, H.; Guo, C.; Zuo, X.; Jiang, Z.;
and Wang, X. 2023. TM2D: Bimodality Driven 3D Dance
Generation via Music-Text Integration. arXiv:2304.02419.
Guo, C.; Xuo, X.; Wang, S.; and Cheng, L. 2022a. TM2T:
Stochastic and Tokenized Modeling for the Reciprocal
Generation of 3D Human Motions and Texts.
ArXiv,
abs/2207.01696.
Guo, C.; Zou, S.; Zuo, X.; Wang, S.; Ji, W.; Li, X.; and
Cheng, L. 2022b. Generating Diverse and Natural 3D Hu-
man Motions From Text. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition
(CVPR), 5152–5161.
Guo, C.; Zuo, X.; Wang, S.; Zou, S.; Sun, Q.; Deng, A.;
Gong, M.; and Cheng, L. 2020.
Action2Motion: Condi-
tioned Generation of 3D Human Motions. Proceedings of
the 28th ACM International Conference on Multimedia.
Guo, W.; Du, Y.; Shen, X.; Lepetit, V.; Alameda-Pineda, X.;
and Moreno-Noguer, F. 2022c.
Back to MLP: A Simple
Baseline for Human Motion Prediction.
2023 IEEE/CVF
Winter Conference on Applications of Computer Vision
(WACV), 4798–4808.
Ho, J.; Chan, W.; Saharia, C.; Whang, J.; Gao, R.; Grit-
senko, A. A.; Kingma, D. P.; Poole, B.; Norouzi, M.; Fleet,
D. J.; and Salimans, T. 2022.
Imagen Video: High Def-
inition Video Generation with Diffusion Models.
ArXiv,
abs/2210.02303.
Ho, J.; Jain, A.; and Abbeel, P. 2020. Denoising Diffusion
Probabilistic Models. ArXiv, abs/2006.11239.
Ho, J.; and Salimans, T. 2022.
Classifier-Free Diffusion
Guidance. arXiv:2207.12598.
Inc., A. S. 2021. Mixamo. https://www.mixamo.com/. Ac-
cessed: 2021-12-25.
Ji, Y.; Xu, F.; Yang, Y.; Shen, F.; Shen, H. T.; and Zheng, W.
2018. A Large-scale RGB-D Database for Arbitrary-view
Human Action Recognition. Proceedings of the 26th ACM
international conference on Multimedia.
Kanazawa, A.; Black, M. J.; Jacobs, D. W.; and Malik, J.
2017.
End-to-End Recovery of Human Shape and Pose.
2018 IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition, 7122–7131.
Kawar, B.; Elata, N.; Michaeli, T.; and Elad, M. 2023.
GSURE-Based Diffusion Model Training with Corrupted
Data. ArXiv, abs/2305.13128.
Kingma, D. P.; Mohamed, S.; Rezende, D. J.; and Welling,
M. 2014. Semi-supervised Learning with Deep Generative
Models. ArXiv, abs/1406.5298.
Kocabas, M.; Athanasiou, N.; and Black, M. J. 2019. VIBE:
Video Inference for Human Body Pose and Shape Estima-
tion. 2020 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), 5252–5262.
Koppula, H. S.; and Saxena, A. 2013. Anticipating human
activities for reactive robotic response. 2013 IEEE/RSJ In-
ternational Conference on Intelligent Robots and Systems,
2071–2071.
Lee, L.-H.; Braud, T.; Zhou, P.; Wang, L.; Xu, D.; Lin, Z.;
Kumar, A.; Bermejo, C.; and Hui, P. 2021. All One Needs to
Know about Metaverse: A Complete Survey on Technolog-
ical Singularity, Virtual Ecosystem, and Research Agenda.
ArXiv, abs/2110.05352.
Li, C.; Xu, T.; Zhu, J.; and Zhang, B. 2017. Triple Genera-
tive Adversarial Nets. ArXiv, abs/1703.02291.
Li, J.; Yin, Y.; Chu, H.; Zhou, Y.; Wang, T.; Fidler, S.; and
Li, H. 2020. Learning to Generate Diverse Dance Motions
with Transformer. ArXiv, abs/2008.08171.
Li, R.; Yang, S.; Ross, D. A.; and Kanazawa, A. 2021. AI
Choreographer: Music Conditioned 3D Dance Generation
with AIST++.
2021 IEEE/CVF International Conference
on Computer Vision (ICCV), 13381–13392.
Ling, H. Y.; Zinno, F.; Cheng, G.; and van de Panne, M.
2020.
Character controllers using motion VAEs.
ACM
Transactions on Graphics (TOG), 39: 40:1 – 40:12.
Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.; and
Black, M. J. 2015. SMPL: a skinned multi-person linear
model. ACM Trans. Graph., 34: 248:1–248:16.
Lucic, M.; Tschannen, M.; Ritter, M.; Zhai, X.; Bachem, O.;
and Gelly, S. 2019. High-Fidelity Image Generation With
Fewer Labels. ArXiv, abs/1903.02271.
Mahmood, N.; Ghorbani, N.; Troje, N. F.; Pons-Moll, G.;
and Black, M. J. 2019. AMASS: Archive of Motion Capture
As Surface Shapes. 2019 IEEE/CVF International Confer-
ence on Computer Vision (ICCV), 5441–5450.
Miao, Y.-C.; Zhang, L.; Zhang, L.; and Tao, D. 2023.
DDS2M: Self-Supervised Denoising Diffusion Spatio-
Spectral Model for Hyperspectral Image Restoration. ArXiv,
abs/2303.06682.
Nie, W.; Guo, B.; Huang, Y.; Xiao, C.; Vahdat, A.; and
Anandkumar, A. 2022. Diffusion Models for Adversarial
Purification. arXiv:2205.07460.
Petrovich, M.; Black, M. J.; and Varol, G. 2021. Action-
Conditioned 3D Human Motion Synthesis with Transformer
VAE. 2021 IEEE/CVF International Conference on Com-
puter Vision (ICCV), 10965–10975.
Petrovich, M.; Black, M. J.; and Varol, G. 2022. TEMOS:
Generating diverse human motions from textual descrip-
tions. ArXiv, abs/2204.14109.
Plappert, M.; Mandery, C.; and Asfour, T. 2016. The KIT
Motion-Language Dataset. Big Data, 4(4): 236–252.
Raab, S.; Leibovitch, I.; Li, P.; Aberman, K.; Sorkine-
Hornung, O.; and Cohen-Or, D. 2022. MoDi: Unconditional
Motion Synthesis from Diverse Data. arXiv:2206.08010.
Ramesh, A.; Dhariwal, P.; Nichol, A.; Chu, C.; and Chen,
M. 2022a. Hierarchical Text-Conditional Image Generation
with CLIP Latents. ArXiv, abs/2204.06125.
Ramesh, A.; Dhariwal, P.; Nichol, A.; Chu, C.; and Chen,
M. 2022b. Hierarchical Text-Conditional Image Generation
with CLIP Latents. arXiv:2204.06125.
Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; and Om-
mer, B. 2021. High-Resolution Image Synthesis with La-
tent Diffusion Models.
2022 IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), 10674–
10685.
Ruiz, A. H.; Gall, J.; and Moreno-Noguer, F. 2018. Human
Motion Prediction via Spatio-Temporal Inpainting.
2019
IEEE/CVF International Conference on Computer Vision
(ICCV), 7133–7142.
Saharia, C.; Chan, W.; Saxena, S.; Li, L.; Whang, J.; Den-
ton, E. L.; Ghasemipour, S. K. S.; Ayan, B. K.; Mahdavi,
S. S.; Lopes, R. G.; Salimans, T.; Ho, J.; Fleet, D. J.;
and Norouzi, M. 2022. Photorealistic Text-to-Image Dif-
fusion Models with Deep Language Understanding. ArXiv,
abs/2205.11487.
Siyao, L.; Yu, W.; Gu, T.; Lin, C.; Wang, Q.; Qian, C.;
Loy, C. C.; and Liu, Z. 2022. Bailando: 3D Dance Gen-
eration by Actor-Critic GPT with Choreographic Memory.
2022 IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition (CVPR), 11040–11049.
Tevet, G.; Raab, S.; Gordon, B.; Shafir, Y.; Cohen-Or, D.;
and Bermano, A. H. 2022. Human Motion Diffusion Model.
ArXiv, abs/2209.14916.
Tiwari, G.; Antic, D.; Lenssen, J. E.; Sarafianos, N.; Tung,
T.; and Pons-Moll, G. 2022. Pose-NDF: Modeling Human
Pose Manifolds with Neural Distance Fields. In European
Conference on Computer Vision (ECCV).
Tseng,
J.-H.;
Castellon,
R.;
and
Liu,
C.
K.
2022.
EDGE: Editable Dance Generation From Music.
ArXiv,
abs/2211.10658.
Tur, A. O.; Dall’Asen, N.; Beyan, C.; and Ricci, E. 2023. Ex-
ploring Diffusion Models for Unsupervised Video Anomaly
Detection. ArXiv, abs/2304.05841.
Vaswani, A.; Shazeer, N. M.; Parmar, N.; Uszkoreit, J.;
Jones, L.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017.
Attention is All you Need. In NIPS.
You, Z.; Zhong, Y.; Bao, F.; Sun, J.; Li, C.; and Zhu, J. 2023.
Diffusion Models and Semi-Supervised Learners Benefit
Mutually with Few Labels. ArXiv, abs/2302.10586.
Zhang, M.; Cai, Z.; Pan, L.; Hong, F.; Guo, X.; Yang, L.; and
Liu, Z. 2022. MotionDiffuse: Text-Driven Human Motion
Generation with Diffusion Model. ArXiv, abs/2208.15001.
Zhou, Y.; Barnes, C.; Lu, J.; Yang, J.; and Li, H. 2018. On
the Continuity of Rotation Representations in Neural Net-
works.
2019 IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR), 5738–5746.
"
"Dengue fever is a serious disease that has impacted developing nations' public health infrastructure, increasing the severity of dengue infections, and causing life-threatening situations. Dengue outbreak forecasts, which have the potential to prevent these outbreaks, have been primarily based on data that requires significant effort from countries to collect. This work aims to improve the health equity in resource-constrained countries by satellite imagery as a non-traditional and readily accessible data source. A scalable satellite extraction framework based on Sentinel Hub, a cloud-based computing platform, is presented. The study also introduces an innovative architecture named DengueNet, which integrates Vision Transformer, Radiomics, and Long Short-Term Memory to extract and integrate spatiotemporal features from satellite imagery, allowing dengue predictions on an epidemiological-week basis. Conducting experiments on five municipalities in Colombia, using 780 high-resolution Sentinel-2 satellite images for training and evaluation, demonstrated the effectiveness of the proposed method. Across these municipalities, DengueNet achieved an average Mean Absolute Error (MAE) of 43.92±42.19, with Cali, Colombia, recording the highest MAE of 113.65±0.08 and Ibagué's MAE being the lowest at 5.67±0.18. This study strongly supports the efficacy of satellite imagery as a valuable resource for dengue prediction, particularly in guiding public health policies within low- and middle-income countries where high-quality data collection is scarce.nan","Dengue fever, the leading cause of hospitalization and death in many tropical and subtropical regions, is caused by the dengue virus, transmitted by the Aedes mosquito. An estimated 4 billion people are at risk of dengue infection, especially in low- and middle-income countries (LMICs), where dengue fever prevalence is exacerbated by various factors. Rapid response to dengue outbreaks is challenging due to limited information exchange and integration. While timely dengue outbreak forecasts have the potential to prevent such outbreaks, conventional data collection techniques are often costly and difficult to scale. Therefore, alternative resources like publicly available satellite imagery are crucial for LMICs where structured data is scarce and critical indicators are lacking. Remotely sensed satellite imagery can be more cost-effective and efficient than alternative field survey methods and has shown potential correlation with weather variables, a key factor in dengue outbreaks. Moreover, surveillance systems based exclusively on satellite imagery can enhance the response time to national crises in hyperendemic regions in LMICs. This study employs recent advancements in machine learning and proposes an ML-based approach for forecasting dengue incidence in five Colombian municipalities using satellite imagery, selected due to Colombia's consistent high levels of reported dengue outbreaks. The study contributes to scalable data collection and processing, effective preprocessing for satellite imagery, and positive results indicating the feasibility of dengue forecasting using time-series satellite imagery alone for LMICs with limited resources.nan","nanPrior research has demonstrated the potential for dengue forecasting utilizing pre-collected structural information like temperature and precipitation. However, conventional data collection techniques are both costly and difficult to scale. Therefore, seeking alternative resources, such as publicly available satellite imagery, is significant for LMICs where structured data is scarce. Remote sensing satellite imagery can be a more cost-effective and efficient approach than alternative field survey methods and has shown potential correlation with weather variables, which are one of the key factors behind dengue outbreaks. It also enables a higher revisit frequency and diverse resolutions of imagery over time than surveys where repeated measurements at a local level are limited. Furthermore, the development of surveillance systems that rely exclusively on satellite imagery to notify public health authorities of early dengue detection can cost-effectively enhance the response time to national crises in hyperendemic regions in LMICs.nan","The study collects satellite imagery and dengue incidences from 2016 to 2018 in five Colombian municipalities. Sentinel Hub is used to collect and process Sentinel-2 satellite data, and the regions of interest are pre-determined using the municipalities' latitude and longitude square coordinates. Each area is sampled per epidemiological period from Sentinel-2's launch date to the time frame before COVID-19 to create a time-series satellite imagery dataset. Focusing on data before COVID-19, as studies show that COVID-19 has impacted dengue transmission, the data is stored in a TIFF format and contains 12 bands from Sentinel-2. To account for differences in band resolution, the nearest-neighbor interpolation method is used to increase the resolution of all bands to a uniform 10 meters per pixel. Cloud and cloud shadow interferences are avoided using the LeastCC algorithm. Weekly dengue incidences are obtained from the Colombian Public Health System (SIVIGILA) and matched with satellite cases on an epidemiological-week basis.nan","Among the five municipalities assessed, Ibagué exhibits the most favorable performance across all metrics, while Cúcuta reports the least favorable performance, which is anticipated. These results align with the observation that apart from an initial peak, the dengue trend in Ibagué is comparatively more stable than in other municipalities. Although the number of dengue cases in Cali appears stable, the high baseline number of cases results in an increase in the MAE. In the case of Cúcuta, given that the training set has relatively low occurrences of dengue, the model fails to accurately reflect the actual trend of dengue cases for Cúcuta during the testing period. It is notable that while the three metrics have different values within one municipality, they report similar results across municipalities, indicating that DengueNet exhibits relatively stable performance across different metrics. Comparative analysis of DengueNet with actual dengue incidences, an LSTM model relying solely on historical cases, and a combined model incorporating both satellite images and cases, demonstrates the capability of DengueNet to accurately predict most trends, even in cases with greater fluctuations in dengue cases over time. This observation substantiates the effectiveness of DengueNet in forecasting outbreak patterns within a majority of municipalities, relying solely on satellite images as input. Furthermore, DengueNet exhibits robust predictive capabilities not only for short-term trends but also demonstrates adaptability by incorporating historical case data when available, thus enhancing prediction accuracy.nan","The study introduces a robust and efficient approach for extracting satellite data and presents DengueNet, a novel architecture for predicting dengue outbreaks using satellite imagery. Experimentation involves the analysis of satellite images and dengue cases spanning from 2016 to 2018, focusing on five municipalities in Colombia. The proposed model combines ViTs with concatenated multi-layer LSTMs to effectively extract both spatial and temporal information from a series of satellite imagery, resulting in comparable dengue case predictions. To address the challenges posed by the dimensionality of satellite images, the study incorporates band selection based on band-to-band Pearson's correlation, enabling a comprehensive assessment of Sentinel-2 satellite images. The selected bands undergo feature extraction through the use of both the feature-engineering and ViT modules. These extracted features from both modules are subsequently integrated into a concatenated LSTM-based model for predicting dengue cases. Incorporating freely accessible satellite imagery into the DengueNet model holds significant potential for making a substantial impact on public health legislation and fairness in health. DengueNet, which leverages publicly accessible satellite imagery, exhibits comparable performance to that of a straightforward LSTM model that relies exclusively on dengue cases for dengue prediction. This approach advances the democratization of data access and the implementation of machine learning models globally, thereby aiding in the formulation of informed public health policies and strategies for early warning systems.nan",DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for Resource-Limited Countries,"Kuan-Ting Kuo, Dana Moukheiber, Sebastian Cajas Ordonez, David Restrepo, Atika Rahman Paddo, Tsung-Yu Chen, Lama Moukheiber, Mira Moukheiber, Sulaiman Moukheiber, Saptarshi Purkayastha, Po-Chih Kuo, Leo Anthony Celi","DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for
Resource-Limited Countries
Kuan-Ting Kuo1 , Dana Moukheiber2 , Sebastian Cajas Ordonez3,4 , David Restrepo2,5 , Atika
Rahman Paddo6 , Tsung-Yu Chen1 , Lama Moukheiber2 , Mira Moukheiber2 , Sulaiman
Moukheiber7 , Saptarshi Purkayastha6 , Po-Chih Kuo1 and Leo Anthony Celi2,3,8
1 National Tsing Hua Unversity, Taiwan
2 Massachusetts Institute of Technology, USA
3 Harvard University, USA
4 University College Dublin, Ireland
5 University of Cauca, Colombia
6 Indiana University – Purdue University Indianapolis, USA
7 Worcester Polytechnic Institute, USA
8 Beth Israel Deaconess Medical Center, USA
{mimikuo365, lear1007}@gmail.com, {danamouk, davidres, lamam, miram, lceli}@mit.edu,
apaddo@iu.edu, ulsordonez@unicauca.edu.co, swmoukheiber@wpi.edu, saptpurk@iupui.edu,
kuopc@cs.nthu.edu.tw
Abstract
Dengue fever presents a substantial challenge in
developing countries where sanitation infrastruc-
ture is inadequate.
The absence of comprehen-
sive healthcare systems exacerbates the severity
of dengue infections, potentially leading to life-
threatening circumstances.
Rapid response to
dengue outbreaks is also challenging due to lim-
ited information exchange and integration. While
timely dengue outbreak forecasts have the poten-
tial to prevent such outbreaks, the majority of
dengue prediction studies have predominantly re-
lied on data that impose significant burdens on in-
dividual countries for collection.
In this study,
our aim is to improve health equity in resource-
constrained countries by exploring the effective-
ness of high-resolution satellite imagery as a non-
traditional and readily accessible data source. By
leveraging the wealth of publicly available and eas-
ily obtainable satellite imagery, we present a scal-
able satellite extraction framework based on Sen-
tinel Hub, a cloud-based computing platform. Fur-
thermore, we introduce DengueNet1, an innovative
architecture that combines Vision Transformer, Ra-
diomics, and Long Short-term Memory to extract
and integrate spatiotemporal features from satel-
lite images. This enables dengue predictions on an
epidemiological-week basis. To evaluate the effec-
tiveness of our proposed method, we conducted ex-
periments on five municipalities in Colombia. We
utilized a dataset comprising 780 high-resolution
Sentinel-2 satellite images for training and eval-
1https://github.com/mimikuo365/DengueNet-IJCAI
uation.
The performance of DengueNet was as-
sessed using the mean absolute error (MAE) met-
ric.
Across the five municipalities, DengueNet
achieved an average MAE of 43.92±42.19.
No-
tably, the highest MAE was recorded in Cali at
113.65±0.08, whereas the lowest MAE was ob-
served in Ibagu´e, amounting to 5.67±0.18.
Our
findings strongly support the efficacy of satellite
imagery as a valuable resource for dengue predic-
tion, particularly in informing public health poli-
cies within low- and middle-income countries. In
these countries, where manually collected data of
high quality is scarce and dengue virus prevalence
is severe, satellite imagery can play a crucial role
in improving dengue prevention and control strate-
gies.
1
Introduction
Dengue, one of the most ubiquitous mosquito-borne viral in-
fections, is the leading cause of hospitalization and death
in many parts of the world, especially in tropical and sub-
tropical countries [Cattarino et al., 2020].
It is estimated
that 129 countries [WHO, 2022] and 4 billion people [CDC,
2022] are at risk of dengue infection. In low- and middle-
income countries (LMICs) where dengue fever is endemic,
the prevalence of dengue outbreaks is exacerbated by multi-
farious factors such as barriers in the continuum of care, in-
equities in resource allocation, education levels, literacy, and
income[Chaparro et al., 2016]. Because there are no specific
treatments available for the virus, dengue prevention is crit-
ical to reducing its infectious and fatality rate, particularly
in hyperendemic regions in LMICs where dengue poses a
significant public health predicament [Gutierrez-Barbosa et
al., 2020]. Therefore, the strategic utilization of viable early
arXiv:2401.11114v1  [cs.CV]  20 Jan 2024
Figure 1: DengueNet model architecture takes in weekly satellite imagery and dengue cases y as input for predicting ˆy (m/px: meters per
pixel; RGB: red, green and blue bands; SWIR: short wave infrared spectrum band; ViT: Vision Transformer; LSTM: Long Short-Term
memory; MLP: Multilayer Perceptron). The LSTM module consists of three stacked standard LSTM layers.
detection approaches for dengue outbreaks in LMICs is not
only imperative for promoting comprehensive well-being but
also plays a crucial role in the pursuit of reducing health in-
equities. By employing these effective approaches, we can
actively contribute to the realization of equitable healthcare
access and outcomes, thereby fostering a more inclusive and
just society.
Prior research has demonstrated the potential for dengue
forecasting utilizing pre-collected structural information like
temperature and precipitation [Martheswaran et al., 2022;
Jain et al., 2019]. However, conventional data collection tech-
niques are both costly and difficult to scale. Therefore, seek-
ing alternative resources, such as publicly available satellite
imagery, is significant for LMICs where structured data is
scarce and critical indicators remain lacking. Remote sens-
ing satellite imagery can be a more cost-effective and effi-
cient approach than alternative field survey methods and has
shown potential correlation with weather variables [Ren et
al., 2021], which are one of the key factors behind dengue
outbreaks. It also enables a higher revisit frequency and di-
verse resolutions of imagery over time than surveys where
repeated measurements at a local level are limited [Lee et
al., 2017].
Furthermore, the development of surveillance
systems that rely exclusively on satellite imagery to notify
public health authorities of early dengue detection can cost-
effectively enhance the response time to national crises in hy-
perendemic regions in LMICs.
This study employs recent advances in machine learning
(ML) and proposes an ML-based approach for forecasting the
incidence of dengue cases in five municipalities of Colom-
bia using satellite imagery. This selection was made due to
Colombia’s persistent incidence of high levels of reported
dengue outbreaks from 1978 until 2022 [National Institute of
Health of Colombia, 2010]. As one of the top five countries
in the Americas with the highest number of reported dengue
cases, Colombia’s dengue mortality rate is 4.84 times higher
than that of other American countries [PAHO, 2022]. Below
are the three principal contributions to this paper.
• We introduce a scalable data collection and processing
framework to extract time-series data from the Sentinel-
2 satellite.
• We propose a novel preprocessing pipeline that can
effectively eliminate noises and extract spatiotemporal
features from the collected satellite imagery.
• Our model, DengueNet, shows positive results, indicat-
ing dengue forecasting with time-series satellite imagery
alone is a feasible approach for LMICs with limited re-
sources.
2
Related Works
(a) Dengue cases
(b) Geographic regions
Figure 2: Municipality-level dengue case numbers and geographic
locations. (a) Dengue cases from 2016 to 2018 were obtained from
the SIVIGILA database for the top five affected municipalities in
Colombia. (b) Geographic locations from satellite imagery for each
municipality.
The epidemiology of dengue is influenced by multiple
factors, including seasonal fluctuations in temperature and
rainfall, socio-economic determinants such as education and
household income [Morgan et al., 2021; Watts et al., 2020],
and intra-strain genetic variability [Fontaine et al., 2018].
To comprehend the determinants of dengue infection, stud-
ies have been conducted to evaluate the economic, societal,
and other facets of dengue outbreaks worldwide. In terms
of structured data, notable work by researchers has paired a
boosted regression tree framework with longitudinal informa-
tion and population surfaces to develop a risk map to under-
stand the global distribution of dengue and improve disease
Figure 3: Gray-scale satellite band images captured by Sentinel-2 using different wavelengths.
management programs globally [Bhatt et al., 2013]. Similar
work has been established, which investigates the temporal
and spatial distribution of dengue fever in India using Kull-
dorff’s space-time permutation method [Mala and Jat, 2019].
Other work [Mu˜noz et al., 2021] has also looked at the as-
sociation of the local climate with dengue in Colombia us-
ing linear analysis tools and lagged crossed-correlations such
as Pearson’s test. Features highly associated with dengue,
such as environmental, entomological, epidemiological, and
human-related data, have been explored for dengue pre-
diction
[Roster and Rodrigues, 2021; Karim et al., 2012;
Guo et al., 2017; Salim et al., 2021]. Other studies have
used human-related data like mobility [Datoc et al., 2016],
social media data [Livelo and Cheng, 2018], and distance
to public transit [Shragai et al., 2022] to build dengue early
warning systems. In terms of unstructured data, studies com-
pared street view and aerial images with different convolu-
tional neural network architectures to estimate dengue rates
[Andersson et al., 2019].
Satellite imagery is often adopted with other statistical
data to perform spatiotemporal tasks, such as weather fore-
casting, precipitation nowcasting [Moskola¨ı et al., 2021;
Son and Thong, 2017; de Witt et al., 2020] and vector-borne
disease case predictions [Rogers et al., 2002; Li et al., 2022a;
Abdur Rehman et al., 2019]. While LMICs lack access to
reliable information systems for data collection and analy-
sis [Ndabarora et al., 2014; Kruk et al., 2018; Fenech et
al., 2018], free sources of satellite imagery from cloud-based
computing platforms, such as Google Earth Engine and Sen-
tinel Hub, provide an alternative data asset for LMICs for
early detection of dengue. In our work, we build a repro-
ducible Sentinel-2 satellite data extraction framework lever-
aging Sentinel Hub and provide municipality-level predic-
tions of dengue cases in Colombia per epi week. By solely
adopting satellite imagery for dengue outbreak prediction,
our model can focus on learning potential environmental in-
formation through difference in vegetation over time using
time-series images to predict dengue cases [Moskola¨ı et al.,
2021].
3
Dataset
In this study, we collect satellite imagery and dengue inci-
dences from 2016 to 2018 in five Colombian municipalities
including Medell´ın, Ibagu´e, Cali, Villavicencio, and C´ucuta
(Figure 2). These municipalities are chosen as they have re-
ported relatively high dengue cases in Colombia. Sentinel
Hub [Ltd, 2022] is used to collect and process Sentinel-2
satellite data.
The regions of interest are pre-determined
using the different municipalities’ latitude and longitude
square coordinates. Each area is sampled per epi week from
Sentinel-2’s launch date to the time frame before COVID-19,
to create a time-series satellite imagery dataset. We focus on
data before COVID-19, as studies show that COVID-19 has
impacted dengue transmission [Lim et al., 2020]. Our data is
stored in a TIFF format and contains 12 bands from Sentinel-
2 as shown in Figure 3. To account for differences in band
resolution, we use nearest-neighbor interpolation to increase
the resolution of all bands to a uniform 10 meters per pixel.
Cloud inteferences are avoided using the LeastCC algorithm,
which is configured using Sentinel Hub API to request the
images with the least amount of clouds per epi week. We
obtain weekly dengue incidences from the Colombian Pub-
lic Health System (SIVIGILA). Satellite imagery is matched
with dengue cases on an epi-week basis.
4
Methodology
4.1
Overview
To fully examine whether satellite imagery could be used
to predict dengue cases, we introduce multiple modules in
DengueNet (see Figure 1). The model components are de-
signed to capture both the temporal and spatial information
from satellite images for dengue outbreak forcasting. First,
we conduct band correlation analysis to determine which
satellite bands to select and use in our study. We then apply
cloud and cloud shadow (CCS) removal on the selected bands
to reduce noises in the satellite images. The preprocessed
bands are then fed into two spatial feature extraction modules,
the Feature-Engineering and the Vision-Transformer (ViT)
feature extractors, respectively. The features extracted from
Figure 4: Average Pearson’s correlation of the 12 bands for the
Sentinel-2 satellite images across five Colombian municipalities in
the training set from 2016 to 2018. The majority of correlations are
statistically significant (p <0.001).
Original
Band
Images
Image
Slicing
Tile
Classification
Tile
Swapping
Tile
Averaging
Average
Tiles
Preprocessed 
Band Images
Abnormal Tile Indices
Normal Tile 
Indices
CCS
Detection
Sliced Tiles
Masks
Figure 5: Stages involved in the cloud and cloud shadow removal
module. The average tiles are generated using the normal tiles in the
samples (CCS: cloud and cloud shadow).
the two modules are then fed into two multi-layer Long Short-
term Memory (LSTM) networks that can extract temporal
features, and eventually concatenated to a fully connected
neural network for dengue case prediction.
4.2
Band Selection
Satellite imagery often contains multiple bands with different
resolutions, central wavelengths, and channels. An example
is shown in Figure 3. We aim to reduce the dimensionality
of the input satellite images while preserving band variance.
Thus, the band selection module contains two steps. We first
compute the inter-band correlation matrix from the samples in
the training set using Pearson’s correlation coefficient (Fig-
ure 4). We then categorize the bands into different clusters
and select the ones in different clusters.
Figure 4 highlights three clusters in our data, each indicat-
ing the high correlation between the bands (bands 1-5, 6-9,
and 11-12). We aim to select bands from different clusters for
the two feature extraction modules to preserve band variance.
Since bands 11 and 12 correspond to the Short Wave Infrared
(SWIR) spectrum, which is mainly used for measuring soil
and vegetation moisture content as it provides good contrast
between different vegetation types, we intend to select bands
from this cluster for the Feature-Engineering pipeline. Given
that both bands show a high correlation, we select band 12
for its relatively lower correlation coefficient against the other
satellite bands (bands 1-10) to avoid multicollinearity. For the
(a) Original image
(b) Cloud mask
(c) CS mask
Figure 6: Cloud and cloud shadow masks generated in the CCS de-
tection stage in Figure 5. (a) Original image where abnormal tiles
will be swapped with the average of normal tiles. (b) Cloud mask
with detected abnormal cloudy pixels in white and normal pixels in
black. Abnormal tiles detected by the cloud mask are highlighted in
red. (c) Cloud shadow (CS) mask with detected abnormal shadowy
pixels in white and normal pixels in black. Abnormal tiles detected
by the shadow mask are highlighted in green.
ViT feature extraction module, to preserve band diversity and
match channels with the pre-training image set, we use bands
2, 3, and 4, which correspond to the Red, Green, and Blue
channels.
4.3
Cloud and Cloud Shadow Removal
The cloud and cloud shadow removal (CSR) module is used
to remove the cloud and cloud shadow from the selected satel-
lite bands by performing CCS detection, image slicing, tile
classification, tile averaging, and tile swapping (see Figure 5).
As satellite imagery often contains many cloud and cloud
shadow noises, CCS detection [Li et al., 2022b] is an essential
stage for reducing noises. To identify noisy pixels caused by
cloud or cloud shadow coverage, two thresholds are utilized
to determine whether a pixel is considered noisy due to the
often extreme pixel values in the affected areas. To establish
thresholds for detecting cloud and cloud shadow, we evalu-
ate the effectiveness of using pixel value percentiles from the
training set and compare their performance. Through testing
percentiles ranging from the 5th to 95th percentile at 5 per-
centile intervals, we choose two percentiles as the detection
thresholds for cloud and cloud shadow, respectively. These
thresholds are then used to generate the corresponding masks
for cloud and cloud shadow (see Figure 6).
After obtaining the two masks, we slice each satellite band
image into 16×16 tiles. With the sliced tiles and the cloud
and cloud shadow masks, tiles are classified into abnormal
and normal tiles, where an abnormal tile indicates more than
50 percent of pixels in the tile are marked as noise in either
mask.
For each tile in a different position in the images,
we calculate the average tile of that position using the nor-
mal tiles By replacing the abnormal tiles in each sample with
the corresponding average tiles, we generate noise-eliminated
images. These average tiles are obtained by computing the
average of normal tiles for a specific position in the images.
4.4
Spatial Feature Extractors
We adopt two feature extractors to extract different types of
spatial features from the satellite images.
In the Feature-
Engineering feature extractor, we extract statistical pixel-
based features from the SWIR band to obtain the texture in-
formation. Nine features from both first-order and higher-
order features, such as Skewness and Joint Average, are col-
lected using the PyRadiomics library [Van Griethuysen et
al., 2017]. The details can be found in the GitHub reposi-
tory. For the ViT module, we adopt transfer learning to over-
come the limited number of real-world satellite imagery in
our dataset. We utilize a ViT [Wu et al., 2020] pre-trained on
ImageNet [Deng et al., 2009] to collect deep learning-based
features from the RGB bands. The RGB bands are down-
scaled from 736×736 to 224×224 to fit the model.
4.5
Model
The spatial feature extractors are both concatenated to a
multi-layer LSTM module for extracting the temporal char-
acteristics. To mitigate overfitting, a dropout layer is added
after each LSTM layer in the module. The last LSTM lay-
ers are then concatenated to a multilayer perceptron (MLP)
with one dense layer and one neuron as the final layer. We
chose Leaky ReLu [Maas et al., 2013] as the activation func-
tion to add non-linearity to the regression task. All models are
trained for 100 epochs with an adaptive learning rate starting
from 0.0001.
In this work, we train and evaluate the proposed structure
on each municipality individually. This is because, with lim-
ited amount of training data, the model may prioritize learn-
ing the geographic meaning of different tile positions, within
the same municipality. Since historical dengue cases are com-
monly used for dengue prediction, we evaluate the effective-
ness of satellite imagery with dengue cases. To do so, we use
the same multi-layer LSTM structure to create a LSTM model
which takes cases as the model inputs. We also explore model
performance with both satellite images and cases as inputs by
concatenating the two LSTM modules from DengueNet with
the LSTM module from the case model, resulting in a 10 × 1
dimension input to the MLP.
4.6
Evaluation and Performance Metrics
For each municipality, we use the first 80 percent of the data
for training, the next 10 percent of the data for validation,
and the last 10 percent for testing. We evaluate the proposed
model structure using Mean Absolute Error (MAE), Sym-
metric Mean Absolute Percentage Error (sMAPE), and Root-
Mean-Square Error (RMSE) metrics. sMAPE computes the
percentage error between the actual value and the predicted
value. We choose to use sMAPE over MAPE because the
dengue cases in our dataset have relatively low actual values.
RMSE penalizes the cases where the difference between the
actual and the predicted value is the greatest.
MAE = 1
n
n
X
i=1
|ˆyi − yi|,
(1)
sMAPE = 100%
n
n
X
i=1
2 × |ˆyi − yi|
(|ˆyi| + |yi|)
(2)
RMSE =
v
u
u
t 1
n
n
X
i=1
(yi − ˆyi)2,
(3)
Refering to Equations 1,2,3, n is the total number of samples
to evaluate in the test set, and i represents the sample num-
ber. ˆyi represents the predicted value from the model, and yi
represents the actual value from the test set for each sample
starting from (i = 1) to (i = n).
5
Results
Table 1 presents the performance evaluation of DengueNet in
forecasting dengue cases using a time-series of satellite im-
agery with a window size of five weeks. Among the five mu-
nicipalities assessed, Ibagu´e exhibits the most favorable per-
formance across all metrics, while C´ucuta reports the least
favorable performance.
These results are anticipated.
In
Ibagu´e, apart from an initial peak, the dengue trend is com-
paratively more stable than in other municipalities. While the
number of dengue cases in Cali appears stable, the high base-
line number of cases results in an increase in the MAE. In the
case of C´ucuta, given that the training set has relatively low
occurrences of dengue, it is reasonable that the model fails to
accurately reflect the actual trend of dengue cases for C´ucuta
during the testing period. A notable observation is that while
the three metrics have different values within one municipal-
ity, they report similar results acros municipalities, indicating
that DengueNet exhibits relatively stable performance across
different metrics.
Figure 7 depicts the forecasted dengue cases for five mu-
nicipalities utilizing a diverse set of input data, including fea-
tures extracted from satellite imagery and historical dengue
cases.
Comparative analysis is conducted against actual
dengue incidences, an LSTM model relying solely on histor-
ical cases, and a combined model incorporating both satellite
images and cases as input. Upon examination of the figures,
it is evident that DengueNet demonstrates the capability to
accurately predict most trends, even in the case of Villavicen-
cio (refer to Figure 7c), which exhibits greater fluctuations in
dengue cases over time. This observation substantiates the
effectiveness of DengueNet in forecasting outbreak patterns
within the majority of municipalities, relying solely on satel-
lite images as input. Furthermore, our model exhibits robust
predictive capabilities not only for short-term trends, while
performing slightly less worse compared to the LSTM model
that solely relies on historical case data, but also demonstrates
adaptability by easily incorporating historical case data when
available, thus enhancing prediction accuracy.
6
Ablation Studies
For the ablation studies, we evaluate the usage of the two fea-
ture extraction modules as shown in Figure 1, and the CSR
module as presented in Table 2. As we observe a high de-
gree of similarity among the MAE, sMAPE, and RMSE met-
rics in Table 1, our analysis focuses on examining the dif-
ferences between the MAE with and without the inclusion of
these three modules. For the Feature-Engineering module,
four municipalities result in improved MAE, with Medell´ın
having the most significant MAE improvement when paired
with the CSR module. On the other hand, the CSR module
has less impact on the ViT module, with only one municipal-
ity showing improved MAE. However, after combining both
Metrics
Villavicencio
Medell´ın
C´ucuta
Ibagu´e
Cali
Average
MAE
25.54±0.06
50.96±0.34
113.65±0.08
5.67±0.18
23.77±0.95
43.92±42.19
sMAPE
72.90±0.27
92.02±0.33
162.91±0.25
40.06±0.83
56.16±1.15
84.81±47.74
RMSE
30.62±0.03
67.86±0.40
120.57±0.07
7.45±0.22
31.80±1.46
51.66±44.17
Table 1: DengueNet evaluation across five municipalities. All experiments are repeated three times, with the average value reported with the
standard deviation. The scores for the municipalities with the best and worst scores are indicated.
ViT
FEng
CSR
Villavicencio
Medell´ın
C´ucuta
Ibagu´e
Cali
✓
✓
24.67±0.26
45.48±5.56
113.10±0.08
13.46±0.08
58.10±1.27
✓
26.25±0.00
44.77±0.79
109.31±0.00
6.21±0.13
33.42±0.42
✓
✓
24.00±0.05
80.46±0.03
113.46±0.08
3.52±0.06
96.71±0.08
✓
27.21±0.29
111.15±0.19
113.58±0.03
6.96±0.16
48.15±0.31
✓
✓
✓
25.54±0.06
50.96±0.34
113.65±0.08
5.67±0.18
23.77±0.95
✓
✓
24.40±0.06
42.48±0.96
114.19±0.09
7.25±0.09
42.35±0.81
Table 2: MAE scores with or without the cloud shadow removal (CSR) module combined with different feature extractors across five
municipalities. ViT indicates only features extracted from the ViT module are used. FEng indicates only features extracted from the feature-
engineering module are used. All experiments are repeated three times. Average values are reported ± the standard deviation. The best scores
are highlighted.
(a) Medell´ın
(b) Ibagu´e
(c) Villavicencio
(d) Cali
(e) C´ucuta
Figure 7: Dengue case prediction was performed for five municipalities per epidemiological week from 2016 to 2018. Three approaches were
evaluated: using satellite imagery features (ViT+FEng), case data (Case), and a combination of both (ViT+FEng+Case). The Ground Truth
label represents the actual number of dengue cases per week. The grey vertical dashed lines indicate the starting weeks of the validation and
testing sets.
Models
MAE
sMAPE
RMSE
ViT (w/ CSR)
50.96
97.66
60.20
FEng (w/ CSR)
63.63
99.24
74.02
ViT+FEng (w/ CSR)
43.92
84.81
51.66
Table 3: Performance comparison of different feature extractors with
the cloud and shadow removal module (w/ CSR). All experiments
are repeated three times and average values are reported. The best
scores are highlighted.
spatial feature extraction modules as inputs, the CSR module
improves the performance across three municipalities, and the
average MAE across five municipalities also decreases from
54.14 to 51.66.
The effectiveness of having both spatial feature extractors
is also analyzed in Table 3. With a single feature extrac-
tor, the ViT feature extractor performs slightly better than the
Feature-Engineering extractor. However, the lowest average
MAE, sMAPE, and RMSE are observed when both feature
extractors are used. This finding is reasonable as the two
feature extractors retrieve different types of information from
the satellite imagery. This model architecture design enables
DengueNet to maintain high performance even if one of the
feature extraction modules fails to extract crucial features, as
the other feature extractor can compensate for it.
7
Discussion
This study introduces a robust and efficient approach for ex-
tracting satellite data and presents DengueNet, a novel ar-
chitecture for predicting dengue outbreaks using satellite im-
agery. The experimentation phase involves the analysis of
satellite images and dengue cases spanning from 2016 to
2018, focusing specifically on five municipalities in Colom-
bia, a country significantly affected by the prevalence of
dengue fever. The proposed model combines ViTs with con-
catenated multi-layer LSTMs to effectively extract both spa-
tial and temporal information from a series of satellite im-
agery, resulting in comparable dengue case predictions.
To address the challenges posed by the dimensionality of
satellite images, the study incorporates band selection based
on band-to-band Pearson’s correlation, enabling a compre-
hensive assessment of Sentinel-2 satellite images. The se-
lected bands undergo feature extraction through the use of
both the feature-engineering and ViT modules. The feature-
engineering pipeline involves dividing satellite images into
tiles and employing CCS detection to minimize the presence
of environmental noise artifacts, allowing for the extraction
of noise-free pixel features. On the other hand, the ViT mod-
ule utilizes transfer learning from a pre-trained ViT model to
extract features. These extracted features from both modules
are subsequently integrated into a concatenated LSTM-based
model for predicting dengue cases.
Incorporating freely accessible satellite imagery into our
DengueNet model holds significant potential for making a
substantial impact on public health legislation and fairness in
health. Over the past two decades, dengue fever has emerged
as a prevalent epidemic in tropical developing countries, ne-
cessitating the establishment of an effective early warning
system for preventing and monitoring outbreaks. The fea-
sibility of DengueNet for predicting dengue outbreaks has
been successfully demonstrated in five municipalities, show-
casing its potential for transferability to other geographical
regions. Moreover, the computational requirements of the
model are relatively low, and its deployment only requires
minimal resources, making it an accessible alternative for
resource-constrained developing countries.
The proposed approach is further reinforced by the inclu-
sion of a dockerized version of the satellite extraction frame-
work, leveraging Sentinel Hub, which ensures data repro-
ducibility and scalability [Alberto et al., 2023]. This empow-
ers LMICs to leverage higher quality and more frequently up-
dated satellite data, overcoming the limitations of field data
collection characterized by irregular revisit rates and vary-
ing data quality. The utilization of such information can sig-
nificantly contribute to informed policy decisions and strate-
gies at the municipality level, enabling early containment of
the dengue virus.
Ultimately, the proposed method holds
immense potential to enhance the prevention and control of
dengue fever outbreaks in developing countries, thereby ad-
vancing public health outcomes and promoting health equity.
8
Conclusion
The
dockerized
satellite
extraction
framework
and
lightweight DengueNet model presented in this work
present a viable alternative for LMICs, where data collection
and preprocessing pose substantial challenges. The perfor-
mance of DengueNet, which leverages publicly accessible
satellite imagery, exhibits comparable performance to that
of a straightforward LSTM model that relies exclusively on
dengue cases for dengue prediction.
This approach takes
us closer to the democratization of data access and the im-
plementation of machine learning models globally, thereby
aiding in the formulation of informed public health policies
and strategies for early warning systems. To ensure safe and
responsible integration of satellite imagery and DengueNet,
future work should understand and mitigate the sources of
bias inherent in machine learning models[Celi et al., 2022;
Nazer et al., 2023] to promote fairness and reduce disparities
in public health across diverse populations.
Acknowledgments
This work is supported in part by Oracle Cloud credits and
related resources provided by Oracle for Research, as well as
the European Space Agency’s Network of Resources Initia-
tive.
References
[Abdur Rehman et al., 2019] Nabeel Abdur Rehman, Umar
Saif, and Rumi Chunara. Deep landscape features for im-
proving vector-borne disease prediction. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition Workshops, pages 44–51, 2019.
[Alberto et al., 2023] Isabelle Rose I Alberto, Nicole Rose I
Alberto, Arnab K Ghosh, Bhav Jain, Shruti Jayaku-
mar,
Nicole Martinez-Martin,
Ned McCague,
Dana
Moukheiber, Lama Moukheiber, Mira Moukheiber, et al.
The impact of commercial health datasets on medical re-
search and health-care algorithms.
The Lancet Digital
Health, 5(5):e288–e294, 2023.
[Andersson et al., 2019] Virginia Ortiz Andersson, Cristian
Cechinel, and Ricardo Matsumura Araujo.
Combining
street-level and aerial images for dengue incidence rate es-
timation. In 2019 International Joint Conference on Neu-
ral Networks (IJCNN), pages 1–8. IEEE, 2019.
[Bhatt et al., 2013] Samir Bhatt, Peter W Gething, Oliver J
Brady, Jane P Messina, Andrew W Farlow, Catherine L
Moyes, John M Drake, John S Brownstein, Anne G Hoen,
Osman Sankoh, et al. The global distribution and burden
of dengue. Nature, 496(7446):504–507, 2013.
[Cattarino et al., 2020] Lorenzo
Cattarino,
Isabel
Rodriguez-Barraquer, Natsuko Imai, Derek AT Cum-
mings, and Neil M Ferguson. Mapping global variation
in dengue transmission intensity.
Science translational
medicine, 12(528):eaax4144, 2020.
[CDC, 2022] CDC. Dengue. https://www.cdc.gov/dengue/
index.html, 2022. Accessed: 2023-01-15.
[Celi et al., 2022] Leo Anthony Celi, Jacqueline Cellini,
Marie-Laure
Charpignon,
Edward
Christopher
Dee,
Franck Dernoncourt, Rene Eber, William Greig Mitchell,
Lama Moukheiber, Julian Schirmer, Julia Situ, et al.
Sources of bias in artificial intelligence that perpetuate
healthcare disparities—a global review.
PLOS Digital
Health, 1(3):e0000022, 2022.
[Chaparro et al., 2016] P
Chaparro,
W
Le´on,
and
CA Casta˜neda.
Comportamiento de la mortalidad
por dengue en colombia entre 1985 y 2012. Biom´edica,
36(Supl 2):125–34, 2016.
[Datoc et al., 2016] Hillary Ingrid Datoc, Romeo Caparas,
and Jaime Caro.
Forecasting and data visualization of
dengue spread in the philippine visayas island group. In
2016 7th International Conference on Information, Intel-
ligence, Systems & Applications (IISA), pages 1–4. IEEE,
2016.
[de Witt et al., 2020] Christian Schroeder de Witt, Catherine
Tong, Valentina Zantedeschi, Daniele De Martini, Fred-
die Kalaitzis, Matthew Chantry, Duncan Watson-Parris,
and Piotr Bilinski.
Rainbench: towards global precipi-
tation forecasting from satellite imagery. arXiv preprint
arXiv:2012.09670, 2020.
[Deng et al., 2009] J. Deng, W. Dong, R. Socher, L.-J. Li,
K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierar-
chical Image Database. In CVPR09, 2009.
[Fenech et al., 2018] Matthew Fenech, Nika Strukelj, and
Olly Buston. Ethical, social, and political challenges of
artificial intelligence in health. London: Wellcome Trust
Future Advocacy, 12, 2018.
[Fontaine et al., 2018] Albin Fontaine, Sebastian Lequime,
Isabelle Moltini-Conclois, Davy Jiolle, Isabelle Leparc-
Goffart, Robert Charles Reiner Jr, and Louis Lambrechts.
Epidemiological significance of dengue virus genetic vari-
ation in mosquito infection dynamics. PLoS pathogens,
14(7):e1007187, 2018.
[Guo et al., 2017] Pi Guo, Tao Liu, Qin Zhang, Li Wang,
Jianpeng Xiao, Qingying Zhang, Ganfeng Luo, Zhihao Li,
Jianfeng He, Yonghui Zhang, et al. Developing a dengue
forecast model using machine learning: A case study in
china. PLoS neglected tropical diseases, 11(10):e0005973,
2017.
[Gutierrez-Barbosa et al., 2020] Hernando
Gutierrez-
Barbosa, Sandra Medina-Moreno, Juan C Zapata, and
Joel V Chua. Dengue infections in colombia: epidemi-
ological trends of a hyperendemic country.
Tropical
Medicine and Infectious Disease, 5(4):156, 2020.
[Jain et al., 2019] Raghvendra Jain, Sra Sontisirikit, Sopon
Iamsirithaworn, and Helmut Prendinger.
Prediction of
dengue outbreaks based on disease surveillance, meteoro-
logical and socio-economic data. BMC infectious diseases,
19(1):1–16, 2019.
[Karim et al., 2012] Md Nazmul Karim, Saif Ullah Mun-
shi, Nazneen Anwar, and Md Shah Alam. Climatic fac-
tors influencing dengue cases in dhaka city: a model for
dengue prediction. The Indian journal of medical research,
136(1):32, 2012.
[Kruk et al., 2018] Margaret E Kruk, Anna D Gage, Cather-
ine Arsenault, Keely Jordan, Hannah H Leslie, Sanam
Roder-DeWan, Olusoji Adeyi, Pierre Barker, Bernadette
Daelmans, Svetlana V Doubova, et al. High-quality health
systems in the sustainable development goals era: time
for a revolution. The Lancet global health, 6(11):e1196–
e1252, 2018.
[Lee et al., 2017] Jung-Seok Lee, Mabel Carabali, Jacque-
line K Lim, Victor M Herrera, Il-Yeon Park, Luis Vil-
lar, and Andrew Farlow. Early warning signal for dengue
outbreaks and identification of high risk areas for dengue
fever in colombia using climate and non-climate datasets.
BMC Infectious Diseases, 17(1):1–11, 2017.
[Li et al., 2022a] Zhichao Li, Helen Gurgel, Lei Xu, Lin-
sheng Yang, and Jinwei Dong. Improving dengue fore-
casts by using geospatial big data analysis in google earth
engine and the historical dengue information-aided long
short term memory modeling. Biology, 11(2):169, 2022.
[Li et al., 2022b] Zhiwei Li, Huanfeng Shen, Qihao Weng,
Yuzhuo Zhang, Peng Dou, and Liangpei Zhang. Cloud and
cloud shadow detection for optical satellite imagery: Fea-
tures, algorithms, validation, and prospects. ISPRS Jour-
nal of Photogrammetry and Remote Sensing, 188:89–108,
2022.
[Lim et al., 2020] Jue Tao Lim, Borame Sue Lee Dick-
ens, Lawrence Zheng Xiong Chew, Esther Li Wen
Choo, Joel Ruihan Koo, Joel Aik, Lee Ching Ng, and
Alex R Cook.
Impact of sars-cov-2 interventions on
dengue transmission.
PLoS neglected tropical diseases,
14(10):e0008719, 2020.
[Livelo and Cheng, 2018] Evan Dennison Livelo and Chari-
beth Cheng. Intelligent dengue infoveillance using gated
recurrent neural learning and cross-label frequencies. In
2018 IEEE International Conference on Agents (ICA),
pages 2–7. IEEE, 2018.
[Ltd, 2022] Sinergise Ltd. Sentinel-2 L2A about sentinet-2
l2a data. https://www.sentinel-hub.com/, 2022. Accessed:
2022-08-13.
[Maas et al., 2013] Andrew L Maas, Awni Y Hannun, An-
drew Y Ng, et al. Rectifier nonlinearities improve neu-
ral network acoustic models. In Proc. icml, volume 30,
page 3. Atlanta, Georgia, USA, 2013.
[Mala and Jat, 2019] Shuchi Mala and Mahesh Kumar Jat.
Geographic information system based spatio-temporal
dengue fever cluster analysis and mapping. The Egyptian
Journal of Remote Sensing and Space Science, 22(3):297–
304, 2019.
[Martheswaran et al., 2022] Tarun
Kumar
Martheswaran,
Hamida Hamdi, Amal Al-Barty, Abeer Abu Zaid, and
Biswadeep Das.
Prediction of dengue fever outbreaks
using climate variability and markov chain monte carlo
techniques in a stochastic susceptible-infected-removed
model. Scientific Reports, 12(1):5459, 2022.
[Morgan et al., 2021] Jasmine Morgan, Clare Strode, and
J Enrique Salcedo-Sora.
Climatic and socio-economic
factors supporting the co-circulation of dengue, zika and
chikungunya in three different ecosystems in colombia.
PLoS Neglected Tropical Diseases, 15(3):e0009259, 2021.
[Moskola¨ı et al., 2021] Waytehad Rose Moskola¨ı, Wahabou
Abdou, and Albert Dipanda. Application of deep learning
architectures for satellite image time series prediction: A
review. Remote Sensing, 13(23):4822, 2021.
[Mu˜noz et al., 2021] Estefan´ıa Mu˜noz,
Germ´an Poveda,
M Patricia Arbel´aez, and Iv´an D V´elez. Spatiotemporal
dynamics of dengue in colombia in relation to the com-
bined effects of local climate and enso.
Acta Tropica,
224:106136, 2021.
[National Institute of Health of Colombia, 2010] National
Institute of Health of Colombia.
Comportamiento
epidemiol´ogico del dengue en colombia a˜no 2010.
http://www.ins.gov.co/buscador-eventos/Paginas/
Info-Evento.aspx, 2010. Accessed: 2022-08-13.
[Nazer et al., 2023] Lama H Nazer, Razan Zatarah, Shai
Waldrip, Janny Xue Chen Ke, Mira Moukheiber, Ashish K
Khanna, Rachel S Hicklen, Lama Moukheiber, Dana
Moukheiber, Haobo Ma, et al. Bias in artificial intelligence
algorithms and recommendations for mitigation.
PLOS
Digital Health, 2(6):e0000278, 2023.
[Ndabarora et al., 2014] Eleazar
Ndabarora,
Jennifer
A
Chipps, and Leana Uys.
Systematic review of health
data quality management and best practices at commu-
nity and district levels in lmic. Information Development,
30(2):103–120, 2014.
[PAHO, 2022] PAHO.
Dengue.
https://www.paho.org/en/
topics/dengue, 2022. Accessed: 2022-08-13.
[Ren et al., 2021] Xiaoli Ren, Xiaoyong Li, Kaijun Ren,
Junqiang Song, Zichen Xu, Kefeng Deng, and Xiang
Wang. Deep learning-based weather prediction: a survey.
Big Data Research, 23:100178, 2021.
[Rogers et al., 2002] David J Rogers, Sarah E Randolph,
Robert W Snow, and Simon I Hay. Satellite imagery in
the study and forecast of malaria. Nature, 415(6872):710–
715, 2002.
[Roster and Rodrigues, 2021] Kirstin
Roster
and
Fran-
cisco A Rodrigues.
Neural networks for dengue
prediction:
a systematic review.
arXiv preprint
arXiv:2106.12905, 2021.
[Salim et al., 2021] Nurul Azam Mohd Salim, Yap Bee
Wah, Caitlynn Reeves, Madison Smith, Wan Fairos Wan
Yaacob, Rose Nani Mudin, Rahmat Dapari, Nik Nur
Fatin Fatihah Sapri, and Ubydul Haque.
Prediction
of dengue outbreak in selangor malaysia using machine
learning techniques. Scientific reports, 11(1):1–9, 2021.
[Shragai et al., 2022] Talya Shragai, Juliana P´erez-P´erez,
Marcela del Pilar Quimbayo-Forero, Ra´ul Rojo, Laura C.
Harrington, and Guillermo R´ua-Uribe. Distance to pub-
lic transit predicts spatial distribution of dengue virus
incidence in medell´ın, colombia.
Scientific Reports,
12(1):8333, May 2022.
[Son and Thong, 2017] Le Hoang Son and Pham Huy
Thong. Some novel hybrid forecast methods based on pic-
ture fuzzy clustering for weather nowcasting from satellite
image sequences. Applied Intelligence, 46(1):1–15, 2017.
[Van Griethuysen et al., 2017] Joost JM Van Griethuysen,
Andriy Fedorov, Chintan Parmar, Ahmed Hosny, Nicole
Aucoin, Vivek Narayan, Regina GH Beets-Tan, Jean-
Christophe Fillion-Robin, Steve Pieper, and Hugo JWL
Aerts.
Computational radiomics system to decode the
radiographic phenotype. Cancer research, 77(21):e104–
e107, 2017.
[Watts et al., 2020] Matthew J Watts, Panagiota Kotsila,
P Graham Mortyn, Victor Sarto i Monteys, and Cesira
Urzi Brancati. Influence of socio-economic, demographic
and climate factors on the regional distribution of dengue
in the united states and mexico. International journal of
health geographics, 19(1):1–15, 2020.
[WHO, 2022] WHO.
Dengue
and
severe
dengue.
https://www.who.int/news-room/fact-sheets/detail/
dengue-and-severe-dengue, 2022. Accessed: 2022-08-13.
[Wu et al., 2020] Bichen Wu, Chenfeng Xu, Xiaoliang Dai,
Alvin Wan, Peizhao Zhang, Zhicheng Yan, Masayoshi
Tomizuka, Joseph Gonzalez, Kurt Keutzer, and Peter Va-
jda. Visual transformers: Token-based image representa-
tion and processing for computer vision, 2020.
"
"Open information extraction (OpenIE), a task focused on the schema-free extraction of triplets from natural language text, poses various challenges, including complicated triplet structures, overlapping elements, and implicit triplets. In this paper, we introduce DualOIE, a novel generative OpenIE model which incorporates a dual task of converting triplets into sentences to address these complexities and enhance extraction performance. By leveraging the duality, DualOIE effectively recognizes the sentence structure, tackles complicated triplet patterns, and learns diverse relations between arguments, leading to improved extraction results. We establish a new benchmark, MTOIE, for implicit triplet extraction containing a significant number of implicit triplets and various predicate types. Extensive experiments on two benchmarks and our MTOIE demonstrate the superiority of DualOIE over the state-of-the-art baselines and ChatGPT. The conducted online A/B test further verifies DualOIE's utility in improving the performance of a real-world search system.nan","Open information extraction (OpenIE), a task of extracting schema-free triplets in the form of (subject, predicate, object) from unstructured natural language, has gained significant attention for its wide range of downstream applications. Traditional OpenIE methods, such as tagging-based and generative solutions, face challenges in dealing with complicated triplets, including overlapping elements, implicit triplets, and those with intricate structures. To address these limitations, we propose DualOIE, a novel generative OpenIE model that incorporates a dual task of transforming triplets into sentences.nan","Previous approaches to OpenIE have employed tagging-based and generative solutions. Tagging-based models treat OpenIE as a sequence labeling problem, while generative approaches view it as a Seq2Seq task. Notable tagging-based systems include RnnOIE, SpanOIE, and MacroIE. Generative solutions comprise models like NOIE, IMoJIE, Gen2OIE, and ChatGPT. While these methods have shown promise, they often struggle with complicated triplet extraction, particularly when handling implicit triplets and managing the structure of the input sentence.nannan","DualOIE consists of a dual framework with two task directions, namely S → T and T → S, where S denotes the sentence and T represents the triplets. A shared encoder enables the model to learn from both tasks jointly. In the S → T direction, predicate extraction is first performed, followed by triplet generation using the extracted predicates as prompts. This approach helps alleviate repetition and omission issues commonly encountered in generative models for OpenIE. The T → S direction promotes the model's understanding of the sentence structure and aids in resolving complicated triplet structures and implicit triplets.nan","We evaluate DualOIE extensively on two benchmark datasets, CaRB and SAOKE, as well as our constructed MTOIE dataset. The results indicate that DualOIE outperforms all baselines, including ChatGPT, across both explicit and implicit triplet extraction tasks. Analyses reveal that DualOIE effectively tackles complicated triplets, achieves a balance between the two tasks in the dual framework, and exhibits a correlation between the quality of sentence reconstruction and triplet extraction.nan","DualOIE, a generative OpenIE model utilizing a dual task of converting triplets into sentences, demonstrates superior performance on both public benchmarks and our constructed dataset. By incorporating the dual task, DualOIE improves its understanding of sentence structure, handles complicated triplets more effectively, and learns diverse relations between arguments. The positive correlation between the quality of triplet extraction and sentence reconstruction highlights the mutual benefits of the dual task approach. Furthermore, the online A/B test conducted on the Meituan platform showcases the practical utility of DualOIE in enhancing the performance of a real-world search system.nan",Exploiting Duality in Open Information Extraction with Predicate Prompt,"Zhen Chen, Jingping Liu, Deqing Yang, Yanghua Xiao, Huimin Xu, Zongyu Wang, Rui Xie, Yunsen Xian","Exploiting Duality in Open Information Extraction
with Predicate Prompt
Zhen Chen
zhenchen21@m.fudan.edu.cn
Fudan University,
Shanghai Key Laboratory of Data
Science
Shanghai, China
Jingping Liu∗
jingpingliu@ecust.edu.cn
East China University of Science and
Technology
Shanghai, China
Deqing Yang∗
yangdeqing@fudan.edu.cn
Fudan University,
Shanghai Key Laboratory of Data
Science
Shanghai, China
Yanghua Xiao
shawyh@fudan.edu.cn
Fudan University,
Shanghai Key Laboratory of Data
Science
Shanghai, China
Huimin Xu
xuhuimin04@meituan.com
Meituan
Shanghai, China
Zongyu Wang
wangzongyu02@meituan.com
Meituan
Shanghai, China
Rui Xie
rui.xie@meituan.com
Meituan
Shanghai, China
Yunsen Xian
xianyunsen@meituan.com
Meituan
Shanghai, China
ABSTRACT
Open information extraction (OpenIE) aims to extract the schema-
free triplets in the form of (subject, predicate, object) from a given sen-
tence. Compared with general information extraction (IE), OpenIE
poses more challenges for the IE models, especially when multiple
complicated triplets exist in a sentence. To extract these compli-
cated triplets more effectively, in this paper we propose a novel
generative OpenIE model, namely DualOIE, which achieves a dual
task at the same time as extracting some triplets from the sentence,
i.e., converting the triplets into the sentence. Such dual task encour-
ages the model to correctly recognize the structure of the given
sentence and thus is helpful to extract all potential triplets from the
sentence. Specifically, DualOIE extracts the triplets in two steps: 1)
first extracting a sequence of all potential predicates, 2) then using
the predicate sequence as a prompt to induce the generation of
triplets. Our experiments on two benchmarks and our dataset con-
structed from Meituan demonstrate that DualOIE achieves the best
performance among the state-of-the-art baselines. Furthermore, the
online A/B test on Meituan platform shows that 0.93% improvement
of QV-CTR and 0.56% improvement of UV-CTR have been obtained
when the triplets extracted by DualOIE were leveraged in Meituan’s
search system.
∗Corresponding Author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
WSDM ’24, March 4–8, 2024, Merida, Mexico
© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0371-3/24/03...$15.00
https://doi.org/10.1145/3616855.3635799
CCS CONCEPTS
• Computing methodologies → Information extraction.
KEYWORDS
OpenIE, dual task, prompt, generative model.
ACM Reference Format:
Zhen Chen, Jingping Liu, Deqing Yang∗, Yanghua Xiao, Huimin Xu, Zongyu
Wang, Rui Xie, and Yunsen Xian. 2024. Exploiting Duality in Open In-
formation Extraction with Predicate Prompt. In Proceedings of the 17th
ACM International Conference on Web Search and Data Mining (WSDM
’24), March 4–8, 2024, Merida, Mexico. ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3616855.3635799
1
INTRODUCTION
Open information extraction (OpenIE) plays an important role in a
variety of downstream tasks, such as knowledge base construction
[8], question answering [26] and summarization [5]. OpenIE aims
to extract schema-free triplets in the form of (subject, predicate,
object) from unstructured natural language, where subjects and
objects are both called arguments.
In recent years, most OpenIE systems were devised based on
deep neural networks (DNNs), which could be divided into two
main categories: tagging-based and generative methods [29]. The
tagging-based solutions [21] model OpenIE as a sequence labeling
problem, where each token in the input is tagged as a subject, predi-
cate or object. The generative solutions model OpenIE as a Seq2Seq
problem. For example, IMoJIE [14] adopts an iterative generation
mechanism to alleviate redundancy in extractions.Gen2OIE [15]
leverages two mT5 models [25] to extract triplets by reconstructing
multiple inputs. However, the previous models’ inadequate under-
standing of diverse relations between arguments and the sentence’s
intricate structure hinder them to extract the complicated triplets
arXiv:2401.11107v1  [cs.CL]  20 Jan 2024
WSDM ’24, March 4–8, 2024, Merida, Mexico
Zhen Chen et al.
Table 1: A toy example of OpenIE where three triplets can be
extracted from the input sentence.
Sentence: Shea was born on September 5, 1900 in San Francisco, California.
Triplets:
1. (Shea, was born on, [September 5, 1900])
2. (Shea, was born in, [San Francisco, California])
3. (San Francisco, is in, California)
effectively, which include the following three categories [27]. 1)
Overlapping triplets refer to those triplets sharing the same element,
as the first two triplets in Table 1 sharing the same subject “Shea”;
2) Discontinuous triplet has the element composed by two separate
spans, as the second triplet’s predicate in Table 1 that composed of
“was born” and “in” from the input; 3) Two triplets are regarded as
nested triplet , if an element in one triplet contains other element
or shares some words with the other triplet’s element. For example,
the predicates of the first two triplets in Table 1 share the same
word “was born”. In addition, the complicated triplets also include
implicit triplets that are overlooked by current OpenIE research.
The predicate in an implicit triplet is not explicitly mentioned in
the sentence. As shown in Table 1, the predicate “is in” of the third
triplet is absent from the input. Implicit triplets often emerge in
incomplete sentences of oral expression, such as user comments
in real-world scenarios. Thus, the inefficiency in extracting im-
plicit triplets would degrade the downstream task’s performance
severely.
To address the challenges in OpenIE posed by these complicated
triplets, in this paper we propose a novel generative OpenIE model
DualOIE, which achieves enhanced OpenIE mainly through learning
an auxiliary dual task of converting the triplets into a sentence.
Since tagging model could not introduce new words, resulting
in inefficiency in handling implicit triplets, our DualOIE adopts
the paradigm of generation instead of tagging. Trained under the
constraint of the dual task, our model is encouraged to capture
the diverse relations between the arguments and recognize the
overlapping elements in the overlapping triplet by figuring out how
these elements fit into the context of the input sentence. In addition,
the dual task also encourages the model to be more aware of word
order and sentence structure, thus helping the model resolve the
discontinuous triplet and nested triplet in the input sentence. For
implicit triplets, transforming them into sentence enables the model
to comprehend and learn those informal expressions, leading to
more accurate identification of implicit triplets in the extraction
task.
In summary, our DualOIE is built with a dual framework with
two task directions: the S (sentence) to T (triplet) direction corre-
sponds to the primary extraction task, while the T (triplet) to S
(sentence) direction corresponds to the dual task. The two direc-
tions share the same encoder, enabling the model to jointly learn
from the two tasks. Specifically, in the S to T direction, given the
sentence’s complicated structure, directly using a Seq2Seq model to
generate triplets from the input may result in incorrect output, such
as repetition or omission. Therefore, we split the primary extrac-
tion process (S to T) into two steps: 1) first extracting a sequence
of potential predicates from the input; 2) then using the predicate
sequence as a prompt and concatenating it with the input to gener-
ate all triplets. Note that a subject of a triplet might be the object of
another triplet, causing ambiguity in the second step, thus we first
extract predicates as the prompt rather than extracting subjects or
objects as the prompt.
One important reason of previous OpenIE models’ inefficiency in
extracting implicit triplets is that, they are trained with the datasets
only having less implicit triplets. According to our statistics, there
are only 3% and 11% implicit triplets in the OpenIE benchmark
CaRB and SAOKE, respectively. Besides, the two datasets only have
less than 30 types of implicit predicates, which also limits the per-
formance of the models trained with them. The sparsity of implicit
triplets in these two benchmarks is due to that, they were collected
from Wikipedia and Baidu Baike, where the expressions in sen-
tences are more formalized and complete than oral expressions in
various Web platforms such as Meituan, which is a famous Chi-
nese review and search platform for daily life. In order to train
and evaluate OpenIE models towards implicit triplet extraction, we
constructed a dataset MTOIE (MeituanOpenIE) from the real-world
scenario of Meituan. MTOIE was collected from the massive user re-
views on Meituan, annotated following the philosophy of previous
OpenIE benchmarks and crowdsourced by experienced workers. To
sum up, MTOIE has 54,060 sentences and 87,971 triplets, in which
there are about 33% implicit triplets and more than 2,000 types of
implicit predicates.
This paper’s contributions are summarized as follows:
1. We propose a novel OpenIE model based on a joint dual frame-
work with two task directions, which enables the model to learn
under the mutual constraints of both tasks and further use pred-
icate prompt to alleviate the omission and repetition in the S to
T direction. To the best of our knowledge, this is the first work to
introduce duality in OpenIE.
2. To evaluate OpenIE models on complicated triplet extraction,
we also construct a high-quality dataset MTOIE that contains more
than 29,000 implicit triplets and more than 2,000 types of implicit
predicates, which exceeds current benchmarks by a significant
margin in terms of both quantity and variety.
3. We conduct extensive experiments on two benchmark datasets
and our MTOIE, to verify our model’s advantage over all base-
lines, including ChatGPT. Furthermore, the online A/B test on the
Meituan platform shows that the query view click-through rate
(QV-CTR) and unique visitor click-through rate (UV-CTR) have
increased by 0.93% and 0.56% respectively when our model’s ex-
traction results were deployed into the search system.
The source code of DualOIE will be soon available at https://github.com/
ccczhen/DualOIE.
2
OVERVIEW
In this section, we first formalize the problem of OpenIE task ad-
dressed in this paper, and then present the framework of our pro-
posed DualOIE.
2.1
Problem Definition
Given an input sentence 𝑥 = [𝑤1, ...,𝑤𝑛], where 𝑤𝑖 (1≤𝑖≤𝑛) is the
𝑖-th word (token), our task’s goal is to extract a collection of triplets
𝑌={(𝑠𝑖, 𝑝𝑖,𝑜𝑖)}|𝑌 |
𝑖=1 where 𝑠𝑖, 𝑝𝑖,𝑜𝑖 denote the subject term, predicate
Exploiting Duality in Open Information Extraction
with Predicate Prompt
WSDM ’24, March 4–8, 2024, Merida, Mexico
Triplet
Decoder
Predicate
Decoder
Text
Decoder
Sentence
Input 𝒙𝒙𝑷𝑷
Concatenated
Input 𝒙𝒙𝑻𝑻
Predicate
Prompt 𝒚𝒚𝑷𝑷
Triplets
Output 𝒚𝒚𝑻𝑻
Triplets
Input 𝒙𝒙𝑺𝑺
Sentence
Output 𝒚𝒚𝑺𝑺
Concatenation
+
Transformer Block 1
Transformer Block L
. . .
. . .
Shared Encoder
𝜶𝜶𝓛𝓛𝑷𝑷
𝜷𝜷𝓛𝓛𝑻𝑻
𝜸𝜸𝓛𝓛𝑺𝑺
+
𝓛𝓛𝑺𝑺→𝑻𝑻
𝓛𝓛𝑺𝑺→𝑻𝑻
S→T
Step 2
T→S
𝐇𝐇𝑃𝑃
𝐇𝐇𝑇𝑇
𝐇𝐇𝑆𝑆
𝐇𝐇𝑃𝑃
𝑑𝑑
𝐇𝐇𝑆𝑆
𝑑𝑑
𝐇𝐇𝑇𝑇
𝑑𝑑
Step 1
𝒙𝒙𝑺𝑺
𝒙𝒙𝑻𝑻
𝒙𝒙𝑷𝑷
𝒚𝒚𝑷𝑷
𝒚𝒚𝑻𝑻
𝒚𝒚𝑺𝑺
Figure 1: The overall framework of our proposed DualOIE, including the structure of achieving two tasks of opposite directions,
S → T and T → S.
term, object term of the 𝑖-th triplet, respectively. Generally, 𝑠 and
𝑜 might be a single word or a span extracted from 𝑥, and 𝑝 might
even be absent in 𝑥. For example, given “Joe Biden (November 20,
1942- ) is the U.S. president."", a good model needs to output two
triplets, i.e., (Joe Biden, is, the U.S. president.) and (Joe Biden, was
born on, [November 20, 1942]). Note that the predicate of the second
triplet is absent in the input sentence.
2.2
Framework
Given an input sentence 𝑥, the primary objective of our OpenIE
model is to maximize the following probability
𝑝(𝑌 |𝑥),
(1)
where 𝑌 is the collection of fact triplets. It is in fact the task of
S to T direction mentioned before, i.e., extracting triplets from
the input sentence. This direction contains two steps: 1) a prompt
𝑧 = [𝑝1, ..., 𝑝|𝑌 |] is first extracted from 𝑥 as a prompt, where 𝑝𝑖
(1≤𝑖≤|𝑌 |) is the predicate of the 𝑖-th triplet in 𝑌; 2) then 𝑥 is con-
catenated with 𝑧 as [𝑧;𝑥] to generate 𝑌.
As the dual task of S to T, the T to S direction aims to convert
the triplets into a sentence, of which the objective is to maximize
𝑝(𝑥|𝑌).
(2)
In our DualOIE, these two directions have their respective de-
coders but are combined with a shared encoder. During DualOIE’s
training, the overall loss is defined as:
L = L𝑆→𝑇 + L𝑇→𝑆,
(3)
where L𝑆→𝑇 and L𝑇→𝑆 are the loss of S to T and T to S (see
Section 4.1 for details), respectively.
3
METHODOLOGY
In this section, we describe our DualOIE’s details for the two task
directions. The overall structure of DualOIE is depicted in Fig. 1.
3.1
Sentence to Triplets
As mentioned before, this direction is the primary task of our model
which aims to generate triplets 𝑌 based on the input sentence 𝑥.
We introduce the two steps of this direction in turn as follows.
Specifically, the triplet extraction is divided into two steps: 1) extract
the predicate sequence from the input. 2) use the predicate sequence
to induce the generation of triplets.
3.1.1
Predicate Extraction. This first step aims to extract a sequence
of predicates 𝑦𝑃 from the sentence 𝑥. Predicate extraction is de-
signed upon a Transformer encoder of 𝐿 blocks, along with a predi-
cate decoder which is also a Transformer decoder.
Formally, we first concatenate the input sentence 𝑥 with two
special tokens to construct this step’s input as:
𝑥𝑃 = [< sen >,𝑤1, ...,𝑤𝑛, < /sen >].
(4)
Based on the encoder, we calculate the hidden state of 𝑥𝑃 as:
H𝑃 = Encoder(𝑥𝑃).
(5)
Then, we use the predicate decoder to generate the predicate se-
quence 𝑦𝑃 in an auto-regressive way:
𝑦𝑖, h𝑑
𝑖 = Decoder𝑃 ([H𝑃; h𝑑
1, ..., h𝑑
𝑖−1]),
(6)
where 𝑦𝑖 is the 𝑖-th token in 𝑦𝑃 and h𝑑
𝑖 is its decoder state. Please
note that the extracted predicate sequence 𝑦𝑃 might consist of
multiple predicates, each of which is denoted as 𝑝𝑖 and corresponds
to one triplet. Thus, we use <rel> and </rel> to split them as below:
𝑦𝑃 = [<rel>, 𝑝1, </rel>, ..., <rel>, 𝑝|𝑌 |, </rel>].
(7)
Finally, the loss function of predicate extraction is defined as:
L𝑃 =
∑︁
(𝑥𝑃,𝑦𝑃 )∈Ω𝑃
− log𝑝(𝑦𝑃 |𝑥𝑃;𝜃𝑒,𝜃𝑑
𝑃),
(8)
where Ω𝑃 is the training set of all sentence-predicates pairs, 𝜃𝑒 and
𝜃𝑑
𝑃 are the parameters of the encoder and the predicate decoder,
respectively.
3.1.2
Triplet Extraction. This step aims to generate the triplets
sequence 𝑌 based on 𝑥𝑃 and 𝑦𝑃. Similar to the previous step, the
triplet extraction also consists of an encoder and a triplet decoder.
Note that the encoder is shared by the predicate extraction as well.
Formally, given 𝑥𝑃 and 𝑦𝑃 from the former step, we take 𝑦𝑃 as
a prompt and concatenate it with 𝑥𝑃, to construct the input 𝑥𝑇 of
this step as:
𝑥𝑇 = [𝑦𝑃;𝑥𝑃].
(9)
WSDM ’24, March 4–8, 2024, Merida, Mexico
Zhen Chen et al.
Then, we use the shared encoder to get 𝑥𝑇 ’s hidden state H𝑇 , and
decode the target sequence 𝑦𝑇 based on H𝑇 in the same way of Eq.
(6).
To split each extracted triplet, we utilize three pairs of special
tokens to formulate a single triplet 𝑡𝑖 in 𝑦𝑇 as:
𝑡𝑖 = [<sub>,𝑠𝑖, </sub>, <rel>, 𝑝𝑖, </rel>, <obj>,𝑜𝑖, </obj>].
(10)
Similar to L𝑃 defined in 8, the loss function of the triplet extraction
L𝑇 is defined as:
L𝑇 =
∑︁
(𝑥𝑇 ,𝑦𝑇 )∈Ω𝑇
− log𝑝(𝑦𝑇 |𝑥𝑇 ;𝜃𝑒,𝜃𝑑
𝑇 ).
(11)
Note that the predicate prompt 𝑦𝑃 enables DualOIE to avoid
iterative generation and output all triplets in a single decoding
process on the second step. In contrast, the number of decoding
steps in IMoJIE and Gen2OIE depends on the number of triplets
corresponding to the input. In addition, it prompts the model to
generate triplets of the same number as the predicates.
3.2
Triplets to Sentence
This direction aims to reconstruct a sentence 𝑥 from the extracted
triplets 𝑌, which is composed of an encoder and a text decoder.
Note that the encoder is shared by the S to T direction as well.
We formulate the input of this direction as:
𝑥𝑆 = 𝑦𝑇 = [𝑡1, ...,𝑡|𝑌 |].
(12)
Next, we derive the hidden state H𝑆 of 𝑥𝑆 from the shared encoder.
Then, we use the text decoder to decode the target sequence 𝑦𝑆
in the same way of Eq. (6). And the output of this direction 𝑦𝑆 is
defined in the same way as 𝑥𝑃 in Eq. (4).
Finally, the loss function is defined as:
L𝑆 =
∑︁
(𝑥𝑆,𝑦𝑆 )∈Ω𝑆
− log𝑝(𝑦𝑆 |𝑥𝑆;𝜃𝑒,𝜃𝑑
𝑆 ).
(13)
Note that the shared encoder would be optimized toward both
directions, which enables DualOIE to benefit from the dual task
simultaneously. In addition, the order of triplets in 𝑥𝑆 is the same
as 𝑌, i.e., the appearance order of the predicate in the sentence.
4
MODEL TRAINING AND INFERENCE
In this section, we first introduce the training details of loss func-
tions. Then, we describe the inference process of our model.
4.1
Joint Training
We employ a joint training way to S to T direction and T to S. The
loss function of DualOIE is defined as:
L = L𝑆→𝑇 + L𝑇→𝑆,
L𝑆→𝑇 = 𝛼L𝑃 + 𝛽L𝑇,
L𝑇→𝑆 = 𝛾L𝑆,
(14)
where L𝑆→𝑇 and L𝑇→𝑆 are the loss of S to T and T to S. L𝑃, L𝑇
and L𝑆 are the loss of the predicate extraction, triplet extraction
and sentence reconstruction, respectively. In addition, we also use
hyper-parameters 𝛼, 𝛽 and 𝛾 to balance different objectives. As a
result, the overall loss of DualOIE is
L = 𝛼L𝑃 + 𝛽L𝑇 + 𝛾L𝑆.
(15)
4.2
Model Inference
When our model is trained well by the task of S to T and T to S, we
only need to use S to T to solve the triplet extraction task inference
phase. Finally, we split 𝑦𝑇 into the triplets of 𝑌 by special tokens.
5
EXPERIMENTS
In this section, we display the results of our extensive experiments
to verify DualOIE’s advantage, based on which we also provide a
detailed analysis.
5.1
Datasets
CaRB[4] is a crowdsourced English benchmark in OpenIE. How-
ever, it does not contain a training set due to the annotation cost,
so we use the automatically annotated training data produced by
IMoJIE [14]. SAOKE[23] is a large-scale human-annotated Chinese
dataset. Note that 11% triplets in SAOKE are implicit. The statistics
of two datasets are reported in Table 2.
5.2
Baselines
We compared our model against several recent neural OpenIE mod-
els, which could be divided into tagging models and generative
models.
5.2.1
Tagging Models. RnnOIE [21] takes predicate head with the
input together and outputs the tags indicating the token classes.
SpanOIE [28] uses BiLSTM to derive the representation of a span,
and then decoders tags from span representations. IGL-OIE [13]
proposes an iterative grid labelling system to predict tag sequences.
MacroIE [27] builds a fact graph based on token spans, and decodes
the graph into fact triplets during the inference process.
5.2.2
Generative Models. NOIE [6] is built with an encoder-decoder
structure based on stacked LSTM, where both the copy mechanism
and attention mechanism are applied. We provided an advanced
version of NOIE in our comparisons, of which the LSTM encoder
is replaced with BERT. IMoJIE [14] is also composed of a BERT en-
coder and an LSTM decoder, and it leverages an iterative generation
mechanism to alleviate redundant extraction. Gen2OIE [15] is an
OpenIE system based on two mT5 models. Given that ChatGPT is a
powerful large language model (LLM) capable of producing contex-
tually appropriate and logically connected responses, We designed
the prompts of 0-shot, 3-shot and Chain-Of-Thought (COT) [24] to
instruct ChatGPT to achieve extraction task. Note that examples
were randomly selected in the 3-shot setting.
5.3
Evaluation Metrics
F1(1-1) [4], is a token level scorer, which creates a label-prediction
matching table and then computes precision and recall between
Table 2: The statistics of CaRB and SAOKE.
CaRB
SAOKE
# Sentences
# Triplets
# Sentences
# Triplets
Train
92,650
180,689
28,238
73,232
Test
634
2,715
1,569
4,175
Exploiting Duality in Open Information Extraction
with Predicate Prompt
WSDM ’24, March 4–8, 2024, Merida, Mexico
Table 3: Main results on CaRB and SAOKE.
Model
CaRB
SAOKE
F1(1-1)
F1
F1(1-1)
F1
SpanOIE
37.9
48.5
38.6
41.2
RnnOIE
39.5
49.0
39.9
42.7
IGL-OIE
41.1
52.4
42.4
44.5
MacroIE
43.5
54.8
43.7
45.6
NOIE+BERT
38.7
51.6
50.2
51.3
IMoJIE
41.4
53.5
52.4
54.3
Gen2OIE
43.4
54.6
53.6
55.4
ChatGPT (0-shot)
39.5
50.3
51.9
53.7
ChatGPT (3-shot)
40.7
51.1
52.6
54.3
ChatGPT (COT)
42.2
53.4
54.0
55.9
DualOIE w/o D
50.3
54.2
56.4
57.7
DualOIE w/o P
50.9
55.5
56.8
58.0
DualOIE
51.5
56.3
58.1
59.5
Table 4: A toy example of the ablation study of DualOIE.
Sentence
He is idolized , receiving the name of “God”.
DualOIE w/o D
(He , is idolized receiving, the name of “God”)
DualOIE w/o P
(He , receiving, the name of “God”)
DualOIE
(He, is, idolized) ; (He, is receiving, the name of “God”)
Table 5: The results of DualOIE on the two datasets with
different extraction order in the task of S to T.
CaRB
SAOKE
Models
F1(1-1)
F1
F1(1-1)
F1
DualOIE-S
44.8
51.4
54.3
55.6
DualOIE-O
43.6
50.1
51.6
53.2
DualOIE
51.5
56.3
58.1
59.5
each pair. The overall precision and recall are computed through
one-to-one mapping, where a gold triplet and a prediction could
match each other only once. F1 [13] is a variant of F1(1-1), where
the recall is computed through multi-to-one mapping.
5.4
Implementation Detail
During the training, we set the loss coefficient 𝛼=0.4, 𝛽=0.2, 𝛾=0.6.
For CaRB, we used T5 [17] encoder as the shared encoder, and T5
decoder as the predicate decoder, triplet decoder and text decoder,
respectively. For SAOKE, we applied the Chinese T5-pegasus [22].
We trained our model using Pytorch on an NVIDIA Tesla V100
GPU with 32 GB dedicated memory. The network parameters were
optimized by Adam [12] with a learning rate of 2e-5. The batch
size was fixed to 32. The total training time was 5 hours. The final
displayed results were reported as the average of the results of 5
random seeds.
Overlapping
Discontinous
Nested
50
55
60
F1 Score
DuOIE w/o D
DuOIE
DuOIE w/o P
Figure 2: Performance on extraction of complicated triplets
in SAOKE.
5.5
Overall Comparison Results
The comparison results between our DualOIE and the baselines are
shown in Table 3. According to the results, we have the following
conclusions.
1) DualOIE achieves the best extraction performance on the two
datasets under each metric, fully justifying the effectiveness of both
employing the dual task in joint training and the predicate prompt
in extraction process.
2) On CaRB, there is always a gap of about 10% or more between
the two metrics in the baselines, which is mainly caused by the low
quality of automatically-derived training data. DualOIE decreases
this gap to 4.8%, indicating that a triplet well-predicted by it is less
mapped to several different gold triplets. In other words, the output
of DualOIE is much more precise and robust in one-to-one mapping
metric.
3) On SAOKE, DualOIE outperforms the best baseline by a large
margin. In addition, note that generative models perform better
overall than tagging models on SAOKE. This is because the implicit
triplets in SAOKE were missed by the tagging models due to their
inability to introduce new words. In addition, the gap between the
two metrics is much smaller and more stable due to the high quality
of SAOKE.
5.6
In-depth Investigations
5.6.1
Ablation Study. To evaluate the impact of each component
in DualOIE, we compared it with two ablated variants: DualOIE
w/o D whose dual task is removed, and DualOIE w/o P in which the
predicate prompt is removed and the triplets are directly generated
by the decoder.
From the comparison results shown in Table 3, we find: 1) The
two ablated variants still have an advantage over most baselines,
justifying the effectiveness of incorporating either the predicate
prompt or the dual task. 2) The removal of the dual task leads to
an apparent performance drop on both datasets, i.e., (1.2%, 2.1%)
on CaRB and (1.7%, 1.8%) on SAOKE. This proves the importance
of the dual task for enhanced extraction. And the removal of the
predicate prompt also decreases our model’s performance.
Fig. 2 shows the comparison results on complicated cases, which
indicates that the introduction of duality could improve perfor-
mance on these challenges. Since the syntactic knowledge endowed
by the dual task is helpful to solve discontinuous and nested triplets,
which arise from complicated sentence structure. In addition, the
WSDM ’24, March 4–8, 2024, Merida, Mexico
Zhen Chen et al.
You are an OpenIE extractor. Your objective is to extract 
fact triplets in the form of (subject, predicate, object) 
from the given sentence. 
I will give you an <Input sentence>, you should output 
triplets without numbering, i.e. 
<(s1,p1,o1);(s2,p2,o2)...> 
Examples:{examples}   Optional
Input sentence:{input sentence}
Output triplets:
Few-shot Example
Input sentence: Shea was born on September 5, 1900 in 
San Francisco, California.
Output triplets: The explicit predicates of input are < 
was born on> and < was born in>, and the implicit 
predicate is <is>. Based on extracted predicates, the fact 
triplets are <(Shea, was born on, [September 5, 1900]); 
(Shea, was born in, [San Francisco, California]); (San 
Francisco, is in, California)>
COT Example
Figure 3: The prompts we designed to instruct ChatGPT to
perform the OpenIE task.
dual task encourages the model to capture diverse relations be-
tween arguments, which benefits the solving of overlapping. We
also give a case example among ablated versions. As shown in Table
4, DualOIE correctly outputted both triplets. The removal of the
duality prevented the model from effectively learning the structure
of the sentence, resulting in confusion between the two triplets and
outputting an incorrect triplet. Additionally, removing the predicate
prompt caused the model to miss one of the triplets.
5.6.2
Analysis on Extraction Order. We also conducted experiments
to investigate the effect of taking different terms in a triplet as the
prompt. Table 5 details the performance of various prompt settings,
where DualOIE-S(O) is the version where all subjects(objects) are
extracted at first as the prompt, and then concatenated with the
input to generate the triplets. From the table, we observe that the
predicate prompt performs best followed by the subject prompt,
and the object prompt performs worst. It is mainly due to the
fact that a subject or object could appear in multiple triplets, and
sometimes a subject in one triplet might even be an object in another
triplet. Such complicated situations would confuse the model during
triplets generation, while the predicate prompt could reduce this
uncertainty since an extracted predicate corresponds to a certain
triplet.
5.6.3
Impact of Loss Coefficient. As formalized in Eq. 15, the loss
coefficient 𝛼 and 𝛽 indicate importance of the primary extraction
task S to T, while 𝛾 indicates the importance of the dual task T
to S. Thus, to analyze the importance of two task directions, we
compared 𝛼+𝛽 with𝛾 where
𝛾
𝛼+𝛽 was set to 0.5, 1 and 2, respectively.
In addition, to analyze the importance of the two steps in S to T,
we also compared 𝛼 with 𝛽 where the value ratio between them
was set to 2, 3 and 4, respectively.
From Table 6, we have the following conclusions. 1) The case
of 𝛼 + 𝛽 = 𝛾 performs better, indicating that the dual task is as
important as the primary task, but the balance between the two
tasks should be kept. 2) the case of 𝛼 > 𝛽 shows its advantage,
indicating that the predicate extraction is tougher and thus requires
more concentrations. Besides, more concentrations on the predicate
extraction could alleviate the cascading error in DualOIE’s pipeline-
based extraction framework.
5.6.4
Analysis on ChatGPT’s Performance. We have examined the
OpenIE performance of ChatGPT in three prompt settings: 0-shot,
3-shot and COT. Fig. 3 shows the main prompt and the COT ex-
ample. Table 3’s results indicate that ChatGPT is still competitive
with fine-tuned baselines even in the 0-shot scenario. Compared
with 3-shot prompt, COT prompt is more effective since it enables
ChatGPT to learn the knack of extracting the predicate followed
by extracting the subject and object, which is in fact an effective
extraction manner adopted in our DualOIE. However, ChatGPT
still shows less efficacy than DualOIE, since it sometimes fails to
correctly comprehend the relations between arguments and tends
to confuse the boundaries of arguments [11]. For example, given
the input in Table 4, the output of ChatGPT(COT) is (He, idolized,
receiving the name of “God”), because it misjudges the predicate
between arguments.
In addition, we observe that ChatGPT sometimes generates
triples that do not align with the input sentence, also possibly
due to hallucination [2].
5.6.5
Impact of Triplet Number. As illustrated in Fig. 4, it is harder
for the extraction models to obtain satisfactory performance when
the sentence’s structure is getting more complicated, where the
number of potential triplets increases. To further investigate the
models’ capabilities of handling the convoluted sentences with
multiple triplets, we divided the samples (sentences) in SAOKE into
4 groups according to the triplet number in one sentence, and then
evaluated all compared models in each group. Fig. 4 displays the
relevant results where𝑚 is the triplet number. It shows that DualOIE
outperforms baselines on all groups by a large margin. Particularly,
all baselines’ performance degrades sharply when more triplets
exist in a sentence. Comparatively, DualOIE’s performance drop is
slighter, justifying its stability of extracting triplets in complicated
situations.
5.6.6
Correlation of the Two Tasks. We have also observed a phe-
nomenon of mutual promotion between the dual task and the pri-
mary task (triplet extraction). We used BLEU [16] to evaluate the
quality of the restored sentences generated by T to S, and compared
it with the F1 of S to T. The BLEU score varies between 0 and 1,
showing how similar the generated text is to the gold text. The
scatter and the regression line in Fig. 5 show the positive correlation
between BLEU and F1, implying that two tasks could improve the
performance of each other.
Exploiting Duality in Open Information Extraction
with Predicate Prompt
WSDM ’24, March 4–8, 2024, Merida, Mexico
Table 6: Tuning results of loss coefficients on SAOKE.
𝛼 + 𝛽 < 𝛾
𝛼 + 𝛽 = 𝛾
𝛼 + 𝛽 > 𝛾
(𝛼, 𝛽, 𝛾)
F1
(𝛼, 𝛽, 𝛾)
F1
(𝛼, 𝛽, 𝛾)
F1
(0.2,0.4,1.2)
56.4
(0.2,0.4,0.6)
57.1
(0.2,0.4,0.3)
55.9
𝛼 < 𝛽
(0.2,0.6,1.6)
56.3
(0.2,0.6,0.8)
57.5
(0.2,0.6,0.4)
54.9
(0.2,0.8,2.0)
54.0
(0.2,0.8,1.0)
55.6
(0.2,0.8,0.5)
53.3
(0.2,0.2,0.8)
55.7
(0.2,0.2,0.4)
56.5
(0.2,0.2,0.2)
55.3
𝛼 = 𝛽
(0.4,0.4,1.6)
57.0
(0.4,0.4,0.8)
57.3
(0.4,0.4,0.4)
55.8
(0.6,0.6,2.4)
55.7
(0.6,0.6,1.2)
57.0
(0.6,0.6,0.6)
54.9
(0.4,0.2,1.2)
58.1
(0.4,0.2,0.6)
59.5
(0.4,0.2,0.3)
56.2
𝛼 > 𝛽
(0.6,0.2,1.6)
57.2
(0.6,0.2,0.8)
58.4
(0.6,0.2,0.4)
56.0
(0.8,0.2,2.0)
56.7
(0.8,0.2,1.0)
57.3
(0.8,0.2,0.5)
55.4
1
m
3
4
m
6
7
m
9
10
m
12
35
40
45
50
55
60
F1 Score
DualOIE
Gen2OIE
IMoJIE
NOIE+BERT
Figure 4: Performance comparisons on the groups with dif-
ferent triplet numbers (𝑚) of a sentence in SAOKE.
Table 7: Pred-F1 and Trip-F1 are defined identically to those
in Sec.5.3. Gold refers to the situation where golden predicate
prompt is provided.
Model
Dataset
Pred-F1
Trip-F1
DualOIE
CaRB
65.5
56.3
DualOIE
CaRB
Gold
63.2
DualOIE
SAOKE
65.7
59.5
DualOIE
SAOKE
Gold
65.6
5.6.7
Analysis on Cascading Error. Since we used a pipeline-style
extraction structure in the T to S direction, it may cause the cas-
cading error. Therefore, we designed an experiment to analyze the
impact of the cascading error on final triplet extraction. As shown
in Table 7, the F1 of the predicate extraction on two datasets are
65.5% and 65.7%. Given the prompt with golden predicates, there is
6.9% and 6.1% improvement in extraction results.
6
CONSTRUCTION OF MTOIE
MTOIE is a large-scale Chinese dataset and mainly focuses on
noun-based attributes of POIs, which refer to the predicates in user
comments, since the noun-based attributes often reflect customer
attitudes to the POIs. We randomly collected sentences from user
comments of POIs on the Meituan platform, covering domains
like food, entertainment and accommodation. Then we sent these
sentences to the annotators and asked them to annotate triples in
the form of (entity, attribute, attribute-value). The annotation for
0.2
0.4
0.6
0.8
BLEU
0.2
0.4
0.6
0.8
F1 Score
Figure 5: Correlation analysis between the BLEU of T to S
(X-axis) and the F1 of S to T (Y-axis).
MTOIE is not easy for those inexperienced workers, especially for
triples with implicit attributes. Thus, we employed 12 professional
annotators served in Meituan. To obtain a high-quality dataset, we
first trained them to annotate the triples with explicit attributes, and
then evaluated their performance. Only the annotators achieving
high evaluation scores were allowed to annotate the triplets with
implicit attributes.
6.1
Explicit Triplet Annotation
The triplets with explicit attributes require the annotators to tag
out the entity, attribute, and attribute-value in the sentence in
order. To make the annotators quickly understand the definition
of attributes, we leveraged a predefined attribute vocabulary1 to
match the attributes in the sentence and marked them to indicate
possible attributes. Following the philosophy of previous OpenIE
benchmarks [4, 23], we identified the following three guidelines for
MTOIE annotation.
Completeness We aim to extract all triplets with marked attributes
from the sentence. Firstly, the annotators must carefully examine
all marked attributes, and annotate the entities and attribute-values
corresponding to the attributes that were judged as correct. Then,
the annotators checked again whether some attributes are missing
from the marked attributes.
Assertedness The annotation for the triplets with explicit attributes
follows the principle of “literally honest”, i.e., entity, attribute and
1About 2,000 attributes accumulated by the Meituan company.
WSDM ’24, March 4–8, 2024, Merida, Mexico
Zhen Chen et al.
Algorithm 1 Iterative Annotation Framework.
Require: 𝐷𝑒𝑥: annotated explicit samples; 𝐷𝑢𝑛: unannotated sen-
tences.
Ensure: 𝐷𝑖𝑚: annotated implicit samples;
1: Mask the attribute in the sentence of 𝐷𝑒𝑥 to get the pseudo
implicit samples 𝐷𝑝𝑠;
2: for 𝑘 = 1 → 𝐾 do
3:
Train OAE model 𝑀𝑘 with 𝐷𝑝𝑠;
4:
Use model 𝑀𝑘 to predict 𝐷𝑢𝑛 and obtain semi-supervised
samples;
5:
Deliver semi-supervised samples to the annotators, get an-
notated implicit samples 𝐷𝑖𝑚;
6:
Update 𝐷𝑝𝑠 with 𝐷𝑖𝑚;
7: end for
attribute-value must be asserted by the original sentence.
Atomicity Each triplet is required to be an indivisible unit. The
annotators must extract multiple atomic triplets from the sentence
that has conjunctions. For example, given a sentence “面包有两种
口味，菠萝味和芒果味。/Bread has two flavors, pineapple and
mango.”, the annotators should annotate (面包/Bread, 口味/flavors,
菠萝味/pineapple) and (面包/Bread, 口味/flavors, 芒果味/mango)
instead of (面包/Bread, 口味/flavors, 菠萝味和芒果味/pineapple
and mango).
6.2
Implicit Triplet Annotation
Implicit attributes are the most challenging part of the annotation.
Manually annotating implicit attributes from the unstructured text
tends to cause missing and incorrect annotations. Therefore, we pro-
posed an iterative annotation framework to reduce the annotation
difficulty, simplifying the “manual inference” to “model prediction
along with by manual discrimination” (as shown in Algorithm 1).
At first, we masked the attributes in the explicit samples 𝐷𝑒𝑥
to obtain the pseudo implicit samples 𝐷𝑝𝑠. For example, given “这
家游泳池水深2米。/The swimming pool is 2 meters deep”, the
original explicit triplet is (游泳池/The swimming pool, 水深/deep,
2米/2 meters), then we removed the attribute “水深/deep” from the
sentence, and thus the triplet becomes a pseudo implicit one.
Second, we trained the model 𝑀 based on 𝐷𝑝𝑠 and then used
𝑀 to predict the unannotated sentences 𝐷𝑢𝑛 and obtain the semi-
supervised samples. Then, the samples whose attributes do not
appear in the sentences were delivered to the annotators. This
method greatly reduces the annotation difficulty, and the annotators
only need to judge whether the implicit triplets could be inferred
from the sentence.
Third, the annotated implicit samples were used to train the
model 𝑀 continuously. After 𝐾 rounds of iteration, we obtained
the final annotated implicit dataset. Following [7], we calculated
the Cohen’s Kappa to measure the agreements between annotators,
and the Kappa score is 88.36%.
6.3
Dataset Statistics
In MTOIE, we have collected 54,060 Chinese sentences and 87,971
triplets in total. Among them, 15,137(28%) sentences contain implicit
triplets, 29,290(33%) triplets are implicit, and there are 2109 types
of implicit predicates. To estimate the overall quality of the dataset,
two volunteers randomly picked 200 sentences from the dataset
and evaluated them carefully. The result shows that the triple-level
precision and recall are 94.6% and 85.5%, respectively.
7
APPLICATION ON MEITUAN
We have also evaluated our proposed DualOIE on our built MTOIE
and verified its effectiveness for the real scenario, i.e., the search
service on the Meituan Platform.
Metric. Our concentration on POI attributes makes the triplets
in MTOIE much shorter. Thus using the token-level metrics might
overestimate model performance. Therefore, we adopted a more
strict matching strategy, where each subject and object are evalu-
ated by a full match. Besides, we used a semantic similarity model2
to determine whether the predicted attribute and the gold have the
same meaning. The threshold is set to 0.7.
Comparison Results. We compared DualOIE’s extraction perfor-
mance on MTOIE with NOIE+BERT, IMoJIE and Gen2OIE. ChatGPT
was not included as MTOIE has not been released yet. Using Chat-
GPT could lead to data leaks. The relevant results will be updated
on GitHub once it is released in future. The results in Table 8 justify
our DualOIE’s advantage on both implicit triplets and all triplets
under strict matching metrics. It shows that the relative perfor-
mance improvement of DualOIE over the baselines on implicit
triplets is more significant than that on all triplets, demonstrating
DualOIE’s stronger capability of extracting implicit information.
We also compared all the models’ efficiency through analyzing the
number of sentences that the models can process per second, as
shown in the last column of Table 8. As mentioned before, DualOIE
shows an advantage over IMoJIE and Gen2OIE due to its decoding
steps independent of the triplets number, while the two competitors
spend more time on sentences with multiple triplets. Note that the
single-turn decoding model NOIE+BERT is much faster than the
other three generative methods, because it adopts beam search to
output multiple triplets instead of a sequence of all triplets. Since
the number of beams should be pre-decided, it fails to naturally
adapt the extraction number to the input sentence.
Furthermore, we display the extraction results of our DualOIE
and two state-of-the-art baselines, i.e., IMoJIE and Gen2OIE, on
some difficult cases. As shown in Table 9, for the first case, IMoJIE
and Gen2OIE both miss a gold triplet. For the second case, IMoJIE
predicts a wrong triplet and misses an implicit triplet, and Gen2OIE
predicts the wrong subject of the implicit triplet. The two baselines’
inferior results are due to their insufficient recognition of the input
sentence’s structure. By contrast, DualOIE generates more correct
triplets with the help of the dual task.
A/B Test. We also conducted an online A/B test to show how our
model helps the Meituan platform improve search performance.
Specifically, given a POI, we first used DualOIE to extract a collec-
tion of triplets from every user comment of it. Then, we used the
semantic similarity model to normalize the collection as follows.
1) The similarity scores of the subject, attribute (predicate) and
object were computed between two triplets, and they would be
2https://github.com/shibing624/text2vec
Exploiting Duality in Open Information Extraction
with Predicate Prompt
WSDM ’24, March 4–8, 2024, Merida, Mexico
Table 8: Triplet extraction comparisons of different models on MTOIE.
Implicit Triplets
All Triplets
Speed
Model
Precision
Recall
F1
Precision
Recall
F1
sen.#/sec
NOIE+BERT
60.5
↑36%
51.5
↑37%
55.6
↑36%
64.8
↑32%
54.7
↑32%
59.3
↑32%
11.5
IMoJIE
61.7
↑33%
54.8
↑29%
58.0
↑31%
67.2
↑27%
61.0
↑19%
64.0
↑22%
2.6
Gen2OIE
69.1
↑19%
59.7
↑18%
64.1
↑18%
73.4
↑16%
63.7
↑14%
68.2
↑15%
2.8
DualOIE
82.1
70.5
75.9
85.3
72.3
78.3
3.7
Table 9: Extraction results for two cases where the incorrect terms are marked red.
Sentence
现在许多博物馆，纪念馆票价都免费了。/Nowadays many museums, monuments tickets are free.
IMoJIE
(纪念馆/monuments，票价/tickets，免费/free)
Gen2OIE
(纪念馆/monuments，票价/tickets，免费/free)
DualOIE
(博物馆/museums，票价/tickets，免费/free), (纪念馆/monuments，票价/tickets，免费/free)
Sentence
帮我做美睫的小姐姐很专业，效果非常满意。
The lady helping me with beautiful eyelashes is professional, the effect is very satisfactory.
IMoJIE
(小姐姐/The lady，效果/effect，满意/satisfactory)
Gen2OIE
(美睫/beautiful eyelashes，效果/effect，满意/satisfactory), (美睫/beautiful eyelashes，手法/skill，专业/professional)
DualOIE
(美睫/beautiful eyelashes，效果/effect，满意/satisfactory), (小姐姐/The lady，手法/skill，专业/professional)
considered expressing the same fact if their scores are over (0.7,
0.7, 0.7). 2) The triplets with the same meaning were replaced by
the most frequent one in the collection, and the reserved triplets
were ranked by their frequencies. Finally, given a triplet such as
(海底捞/Haidilao，食材/food，新鲜/fresh) in the normalized col-
lection, we concatenated the attribute “食材/food” with the object
“新鲜/fresh” as the given POI’s label “食材新鲜/food fresh”.
For the online A/B test, we used two buckets where each bucket
containing 25% randomly selected users. For one bucket, the system
returned the search results using the labels to filter out POIs. For
another bucket, the system directly returned the POIs by its default
principle. We ran our A/B test on Meituan’s searching system and
compared daily average performance on query view click-through
rate (QV-CTR) and unique visitor click-through rate (UV-CTR),
which refer to the ratio of clicked queries to all queries and the
ratio of clicked queries to all unique user-query pairs, respectively.
After the running of 15 days, we noticed that QV-CTR and UV-CTR
increased by 0.93% and 0.56%, respectively. These results indicate
that the POI labels obtained through DualOIE indeed improve the
performance of Meituan’s search service.
8
RELATED WORK
Traditional OpenIE systems such as TextRunner [3], ReVerb [9], OL-
LIE [20], Stanford-IE [1], OpenIE-5 [19] and MinIE [10] are mainly
based on rules and statistics, which are combined with some mod-
ules like POS taggers, SRL parsers and chunkers.
In recent years, researchers mainly focus on neural solutions,
which could be divided into two categories: tagging-based systems
and generative systems. Tagging-based systems model OpenIE as a
sequence labelling problem. For example, RnnOIE [21] introduces
a custom BIO tagging scheme and takes the predicate head with
the input together. SenseOIE [18] introduces the dependency tree,
where the feature of a token is influenced by its parent and children.
Besides, it also uses lexical and syntactic features such as POS em-
bedding and syntactic role embedding. OpenIE6 [13] is built as an
iterative grid labelling (IGL) system and achieves predictions in a
2D grid labelling way. SpanOIE [28] uses BiLSTM to derive the rep-
resentation of a span, from which the tag of each token is predicted.
In MacroIE [27], a fact graph is built based on the token spans, and
decoded into fact triplets during the inference process. On the other
hand, generative systems model OpenIE as a Seq2Seq problem, and
thus are capable of introducing new words to deal with implicit
triplets. NOIE [6] uses LSTM as both encoder and decoder, and in-
troduces copy attention to address the out-of-vocabulary problem.
In Logician [23], BiGRU is used as both encoder and decoder. As
well, the coverage mechanism and gated dependency mechanism
are both introduced. IMoJIE [14] uses BERT as encoder and LSTM as
decoder. It leverages an iterative generation mechanism to alleviate
the redundancy in triplets generation. Gen2OIE [15] is composed of
two mT5 [25] models, which reconstructs multiple inputs based on
the first model, and then uses the second model to generate triplets.
9
CONCLUSION
We propose a novel generative OpenIE model DualOIE based on
an auxiliary dual task with predicate prompt. By exploiting duality,
DualOIE performs better than the previous OpenIE models, since it
can better understand the sentence structure and capture diverse
relations between arguments. We also provide a high-quality Ope-
nIE dataset MTOIE, which is constructed from the user comments
on Meituan’s platform. The experiments on public benchmarks and
MTOIE justify DualOIE’s superiority over the baselines. The online
A/B test on Meituan platform also suggests the extracted triplets
can promote the real-world search service.
10
ACKNOWLEDGEMENT
This paper was supported by Chinese NSF Major Research Plan
No.92270121, NSF funding No.62306112, Shanghai Sailing Program
No.23YF1409400, Shanghai Science and Technology Innovation
Action Plan No.21511100401.
WSDM ’24, March 4–8, 2024, Merida, Mexico
Zhen Chen et al.
REFERENCES
[1] Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D Manning.
2015. Leveraging linguistic structure for open domain information extraction. In
Proceedings of the 53rd Annual Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference on Natural Language Processing
(Volume 1: Long Papers). 344–354.
[2] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan
Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023. A multitask,
multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and
interactivity. arXiv preprint arXiv:2302.04023 (2023).
[3] M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. 2007. Open
information extraction from the web. Communications of the Acm (2007).
[4] Sangnie Bhardwaj, Samarth Aggarwal, and Mausam Mausam. 2019. CaRB: A
Crowdsourced Benchmark for Open IE. In Proceedings of the 2019 Conference
on Empirical Methods in Natural Language Processing and the 9th International
Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association
for Computational Linguistics, Hong Kong, China, 6262–6267. https://doi.org/
10.18653/v1/D19-1651
[5] Ziqiang Cao, Furu Wei, Wenjie Li, and Sujian Li. 2018. Faithful to the original:
Fact aware neural abstractive summarization. In thirty-second AAAI conference
on artificial intelligence.
[6] Lei Cui, Furu Wei, and Ming Zhou. 2018. Neural Open Information Extraction.
In Proceedings of the 56th Annual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers). Association for Computational Linguistics,
Melbourne, Australia, 407–413. https://doi.org/10.18653/v1/P18-2065
[7] Ning Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang, Xu Han, Pengjun Xie,
Hai-Tao Zheng, and Zhiyuan Liu. 2021. Few-nerd: A few-shot named entity
recognition dataset. arXiv preprint arXiv:2105.07464 (2021).
[8] Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Mur-
phy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault:
A web-scale approach to probabilistic knowledge fusion. In Proceedings of the 20th
ACM SIGKDD international conference on Knowledge discovery and data mining.
601–610.
[9] Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations
for open information extraction. In Proceedings of the 2011 conference on empirical
methods in natural language processing. 1535–1545.
[10] Kiril Gashteovski, Rainer Gemulla, and Luciano del Corro. 2017. Minie: min-
imizing facts in open information extraction. Association for Computational
Linguistics.
[11] Ridong Han, Tao Peng, Chaohao Yang, Benyou Wang, Lu Liu, and Xiang Wan.
2023. Is Information Extraction Solved by ChatGPT? An Analysis of Performance,
Evaluation Criteria, Robustness and Errors. arXiv preprint arXiv:2305.14450
(2023).
[12] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[13] Keshav Kolluru, Vaibhav Adlakha, Samarth Aggarwal, Mausam, and Soumen
Chakrabarti. 2020. OpenIE6: Iterative Grid Labeling and Coordination Analysis
for Open Information Extraction. In Proceedings of the 2020 Conference on Empir-
ical Methods in Natural Language Processing (EMNLP). Association for Computa-
tional Linguistics, Online, 3748–3761. https://doi.org/10.18653/v1/2020.emnlp-
main.306
[14] Keshav Kolluru, Samarth Aggarwal, Vipul Rathore, Mausam, and Soumen
Chakrabarti. 2020. IMoJIE: Iterative Memory-Based Joint Open Information
Extraction. In Proceedings of the 58th Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational Linguistics, Online, 5871–5886.
https://doi.org/10.18653/v1/2020.acl-main.521
[15] Keshav Kolluru, Muqeeth Mohammed, Shubham Mittal, Soumen Chakrabarti,
et al. 2022. Alignment-Augmented Consistent Translation for Multilingual Open
Information Extraction. In Proceedings of the 60th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long Papers). 2502–2517.
[16] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a
method for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics. 311–318.
[17] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the
limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn.
Res. 21, 140 (2020), 1–67.
[18] Arpita Roy, Youngja Park, Taesung Lee, and Shimei Pan. 2019. Supervising
unsupervised open information extraction models. In Proceedings of the 2019
Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).
728–737.
[19] Swarnadeep Saha, Harinder Pal, et al. 2017. Bootstrapping for numerical open ie.
In Proceedings of the 55th Annual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers). 317–323.
[20] Michael Schmitz, Stephen Soderland, Robert Bart, Oren Etzioni, et al. 2012. Open
language learning for information extraction. In Proceedings of the 2012 joint
conference on empirical methods in natural language processing and computational
natural language learning. 523–534.
[21] Gabriel Stanovsky, Julian Michael, Luke Zettlemoyer, and Ido Dagan. 2018. Super-
vised Open Information Extraction. In Proceedings of the 2018 Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, Volume 1 (Long Papers). Association for Computational
Linguistics, New Orleans, Louisiana, 885–895. https://doi.org/10.18653/v1/N18-
1081
[22] Jianlin Su. 2021. T5 PEGASUS - ZhuiyiAI. Technical Report. https://github.com/
ZhuiyiTechnology/t5-pegasus
[23] Mingming Sun, Xu Li, Xin Wang, Miao Fan, Yue Feng, and Ping Li. 2018. Logician:
a unified end-to-end neural approach for open-domain information extraction.
In Proceedings of the Eleventh ACM International Conference on Web Search and
Data Mining. 556–564.
[24] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning
in large language models. Advances in Neural Information Processing Systems 35
(2022), 24824–24837.
[25] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya
Siddhant, Aditya Barua, and Colin Raffel. 2020. mT5: A massively multilingual
pre-trained text-to-text transformer. arXiv preprint arXiv:2010.11934 (2020).
[26] Zhao Yan, Duyu Tang, Nan Duan, Shujie Liu, Wendi Wang, Daxin Jiang, Ming
Zhou, and Zhoujun Li. 2018. Assertion-based QA with question-aware open infor-
mation extraction. In Proceedings of the AAAI Conference on Artificial Intelligence,
Vol. 32.
[27] Bowen Yu, Yucheng Wang, Tingwen Liu, Hongsong Zhu, Limin Sun, and Bin
Wang. 2021. Maximal clique based non-autoregressive open information ex-
traction. In Proceedings of the 2021 Conference on Empirical Methods in Natural
Language Processing. 9696–9706.
[28] Junlang Zhan and Hai Zhao. 2020. Span model for open information extraction
on accurate corpus. In Proceedings of the AAAI Conference on Artificial Intelligence,
Vol. 34. 9523–9530.
[29] Shaowen Zhou, Bowen Yu, Aixin Sun, Cheng Long, Jingyang Li, and Jian Sun.
2022. A Survey on Neural Open Information Extraction: Current Status and
Future Directions. In Proceedings of the Thirty-First International Joint Con-
ference on Artificial Intelligence, IJCAI-22, Lud De Raedt (Ed.). International
Joint Conferences on Artificial Intelligence Organization, 5694–5701.
https:
//doi.org/10.24963/ijcai.2022/793 Survey Track.
"
"In recent years, Transformer structures have demonstrated their excellence in diverse domains across deep learning. It sparks discussions on whether such sophisticated structures are necessary and whether simple structures like Mixer can achieve comparable performance while maintaining reduced inference cost. To explore the Mixer's effectiveness, this research applies a more compact version of the Mixer to audio classification tasks, conducting comparative experiments with the Transformer-based Audio Spectrogram Transformer (AST) on three datasets. Additionally, this study examines the application of various activation functions in Mixer and compares their impact on model performance.nan","In recent years, Transformer structures have significantly impacted various artificial intelligence domains, such as visual classification, temporal prediction, and audio classification. Their exceptional results in data processing have come at the cost of extensive parameters and intricate designs. Additionally, the surge in computing power and vast dataset collection has resulted in numerous models with complex architectures.nan","nanYuan Gong, Yu-An Chung, and James Glass introduced a model known as AST: Audio Spectrogram Transformer at the Interspeech2021 conference. This model originated from the aforementioned situation. In the AST paradigm, voice segments are converted into 128-dimensional Mel spectral features, and then a windowing operation is used to produce the associated spectrogram. The spectrogram is then divided into several segments by the AST model using Transformer’s approach, which are then supplied into the encoder structure following Linear Projection and feature extraction. The categorization outcomes are then output by the AST model using a linear layer. The model will be utilized as a comparison target in this research since it exhibits good performance on the three datasets.nan","In this research, an audio classification task is utilized to evaluate the efficacy of a more compact version of the Mixer. Comparative experiments are conducted with the Transformer-based Audio Spectrogram Transformer (AST) model on three datasets: Speech Commands, UrbanSound8k, and CASIA Chinese Sentiment Corpus. Additionally, this study explores the impact of various activation functions on Mixer's performance.nan","The experimental results demonstrate the effectiveness of the Mixer in audio classification tasks. The Mixer outperforms the AST model in terms of accuracy and area under the curve (AUC) on both the validation and test sets across all three datasets. This suggests that Mixer can achieve comparable performance to Transformer-based models while maintaining a simpler structure and lower inference cost. Furthermore, the study finds that the RGB-to-grayscale map formula outperforms the simple weighted fusion approach in Linear Projection, leading to improved model performance.nan","In conclusion, this study highlights the potential of Mixer in audio classification tasks, demonstrating its ability to achieve competitive performance with a simpler structure and reduced inference cost. The study also emphasizes the importance of adhering to objective laws and knowledge from other fields when making model optimizations, as this approach can provide more targeted directions for improvement. Future research directions include examining the application of Mixer pre-trained networks, removing the CLS flag in AST, optimizing the Mixer unit structure, and exploring self-supervised training approaches to further enhance the model's performance.nan",ASM: Audio Spectrogram Mixer,"Qingfeng Ji, Jicun Zhang, Yuxin Wang","ASM: Audio Spectrogram Mixer
Qingfeng Ji1, Jicun Zhang2 and Yuxin Wang3
Abstract— Transformer structures have demonstrated out-
standing skills in the deep learning space recently, signif-
icantly increasing the accuracy of models across a variety
of domains. Researchers have started to question whether
such a sophisticated network structure is actually necessary
and whether equally outstanding results can be reached with
reduced inference cost due to its complicated network topology
and high inference cost. In order to prove the Mixer’s efficacy
on three datasets—Speech Commands, UrbanSound8k, and
CASIA Chinese Sentiment Corpus—this paper applies a more
condensed version of the Mixer to an audio classification task
and conducts comparative experiments with the Transformer-
based Audio Spectrogram Transformer (AST) model. In ad-
dition, this paper conducts comparative experiments on the
application of several activation functions in Mixer, namely
GeLU, Mish, Swish and Acon-C. Furthermore, the use of
various activation functions in Mixer, including GeLU, Mish,
Swish, and Acon-C, is compared in this research through
comparison experiments. Additionally, some AST model flaws
are highlighted, and the model suggested in this study is
improved as a result. In conclusion, a model called the Audio
Spectrogram Mixer is suggested in this study, and the model’s
future directions for improvement are examined.
I. INTRODUCTION
Encoder-Decoder structures and attention mechanisms
havebeen extremely important in a number of artificial in-
telligence domains, including visual classification, temporal
prediction, audio classification, etc., due to the popularity of
Transformer structures in recent years. Due to their extensive
parameters and intricate designs, transformer architectures
have demonstrated excellent outcomes in data processing.
Meanwhile, numerous models with intricate architectures
have surfaced as a result of the huge rise in computing power
and vast dataset collecting.
Researchers including Yuan Gong, Yu-An Chung, and
James Glass presented a model known as AST: Audio
Spectrogram Transformer at the Interspeech2021 confer-
ence(Gong, Chung, and Glass 2021). This model was born
out of the aforementioned situation. In the AST paradigm,
voice segments are converted into 128 The AST model
converts speech snippets into 128-dimensional Mel spectral
characteristics, and then uses a windowing operation to
produce the associated spectrograms. The spectrogram is
then divided into several segments by the AST model using
Transformer’s approach, which are then supplied into the
*This work was not supported by any organization
1Qingfeng
Ji
is
with
School
of
Computer
Science
and
Technology,
Dalian
University
of
Technology,
Dalian,
PRC
15640414255@mail.dlut.edu.cn
2Jicun Zhang is with Neusoft Reach Automotive Technology(Dalian)
Co.,Ltd., Dalian, PRC zhangjicun89@163.com
3Yuxin Wang is with School of Computer Science and Technology,
Dalian University of Technology, Dalian, PRC wyx@dlut.edu.cn
encoder structure following Linear Projection and feature
extraction. The categorization outcomes are then output by
the AST model using a linear layer. The model will be
utilized as a comparison target in this research since it
exhibits good performance on the three datasets.
In fact, the development of the Transformer structure has
greatly advanced deep learning. But given the high cost
of model inference, we begin to doubt the necessity of a
framework as intricate as Transformer. Google provided the
answer to this question in the paper titled ”MLP-Mixer:
An all-MLP Architecture for Vision” that was published in
NeurIPS(Tolstikhin et al. 2021). MLP-Mixer is the name of
the model architecture that they suggested. By combining
data in different positions (token-mixing) and in the same
data in different positions of the channel (channel-mixing),
the mixer is able to extract features easily. In short, feature
slices are extracted first in the column direction and then in
the row direction.
The Google team tested the effectiveness of MLP-Mixer
using various vision datasets and discovered that its rel-
atively straightforward structure performs nearly as well
as various variations of Vision Transformer (ViT) while
requiring less processing power. This shows that perfor-
mance comparable to that of complex structures can be
obtained even with simpler structures. The study ”MTS-
Mixers: Multivariate Time Series Forecasting via Factorized
Temporal and Channel Mixing” released by the Huawei
team in 2023 confirms the efficiency of the Mixer in the
field of time series forecasting(Li et al. 2023). The Huawei
team emphasizes that capturing temporal correlation does not
always need attention. Their test findings on various real
datasets demonstrate that MTS-Mixer outperforms existing
Transformerbased algorithms in terms of efficiency.
We propose the question of whether the Mixer has the
potential to implement SOTA in the audio domain after
validating the Mixer’s performance in the fields of vision
and timing prediction. We change the technical aspects of
the AST model that do not follow the objective laws and
suggest a structure called Audio Spectrogram Mixer (ASM)
by using the Mixer
II. ASM
A. Motivation
According
to
validation
on
three
datasets,
AudioSet(Gemmeke et al. 2017), ESC50 (Piczak 2015),and
Speech CommandsV2 (35 categories)(Warden 2018),the
Transformer structure used by the AST model is capable of
outperforming SOTA in the audio classification domain. This
suggests that the AST model handles audio categorization
arXiv:2401.11102v1  [cs.SD]  20 Jan 2024
tasks with greater performance. The authors of the research
have developed an upgraded version of the AST model called
”SSAST: Self-Supervised Audio Spectrogram Transformer,”
which enhances the performance of downstream audio tasks
by utilizing masks and self-supervised pre-training(Gong et
al. 2022).
Based on the success of the AST model, we choose the
AST structure as a blueprint for our ASM model with the
structure shown in Figure 1 and compare the two on three
publicly available datasets. We aim to verify that the Mixer
has the potential to achieve SOTA in the audio classification
domain. By comparing with the AST model, we will further
explore the advantages and potential of the Mixer in the
audio domain with the aim of bringing better performance
to audio classification tasks.
In addition to the above, we found one more aspect of
the AST model that needs improvement. The Transformer
structure of the AST model is migrated from the ViT
model(Dosovitskiy et al. 2020) in the vision domain, which
deals with three-channel images, while the audio spectro-
gram has only single-channel features. To solve the problem
of channel number mismatch, the AST model directly sums
the weights of the three channels in the Linear Projection
layer to obtain the single channel weights. However, ac-
cording to objective laws, we think this approach is not
appropriate. Therefore, in this paper, we choose to use the
formula of RGB to grayscale map instead of this operation
to deal with the problem of channel number mismatch more
accurately. With this alternative, we hope to further improve
the performance of the model and ensure consistency with
the objective law.
B. Model Architecture
Figure 1 shows a detailed illustration of the ASM architec-
ture. First, the input audio is converted into 128-dimensional
Mel-spectral features and windowed to obtain the corre-
sponding spectrogram as the input to the ASM. Then, we
divide the spectrogram into multiple patch sequences of size
16x16. These patch sequences are converted into 1D patch
embeddings of size 768 by linear projection layer. next, the
embedded sequences are input into MLP-Mixer. In MLP-
Mixer, we keep some settings similar to AST, such as keep-
ing the embedding dimension at 768 and keeping 12 MLP-
Mixer layers. In the MLP unit, we use GeLU(Hendrycks
and Gimpel 2016), Mish(Misra 2019), Swish(Ramachandran,
Zoph, and Le 2017), and Acon-C(Ma et al. 2021) activation
functions, which have non-zero gradients in the negative
region and avoid the problem of dead neurons. In addition
these functions are smoother at 0 than activation functions
such as ReLU, and thus converge more easily during training.
Unlike the AST model, we modify the Mixer architec-
ture instead of choosing the original, unmodified Mixer
architecture. Such modifications include adjustments to the
shape of the Mixer Blocks. We make this choice because
there are no pre-trained Mixer-like models available that are
comparable to the number of DeiT(Touvron et al. 2021)
parameters used by the AST model. Making comparisons
Fig. 1.
Audio Spectrogram Mixer
in the absence of substantial prior knowledge is as unfair
as comparing the ability of high-potential newborns and
junior high school students to acquire knowledge in the same
situation. However, we retain a clear separation from the
projection layer at the input of the Mixer so that it can be
replaced in the future with a possible pre-trained Mixer-like
model with a large amount of prior knowledge.
III. EXPERIMENTS
In AST, the authors provide an option to decide whether to
use a visual pre-training model (e.g., ImageNet equals True
or False), and the AST model uses a DeiT with a parametric
number of 87M and an image input size of 384x384 as its
visual pre-training model. Therefore, the RGB to grayscale
map formula is used in the Linear Projection layer only when
ImageNet=True.
To compare the capabilities of the Mixer and Transformer
structures, we choose to conduct comparison experiments in
the two cases where ImageNet is True and False. Among
them, when ImageNet is True, in order to avoid unfairness
due to DeiT’s Encoder structure with prior knowledge, we
reinitialize an Encoder unit with the same structure as
DeiT, but keep the weight parameter of DeiT before the
Encoder layer and use it as the baseline. the purpose of
this is to ensure fairness and eliminate the influence of prior
knowledge on the experimental results.
TABLE I
IMAGENET=FALSE, SCV2, AST AND MIXER
AST
Mixer
v-acc
0.8062±0.0088
0.9292±0.0084
v-auc
0.9888±0.0007
0.9977±0.0006
t-acc
0.7924±0.0093
0.9189±0.0106
t-auc
0.9873±0.0009
0.9973±0.0005
It is also worth noting that the focus of the comparison
experiments is only on verifying the capabilities of the Mixer
and the validity of the RGB to grayscale map formula, so
we don’t spend as much time fine-tuning and adapting the
ASM on AudioSet as AST does.
In our experiments, we use an ASM structure with a
maximum number of parameters of 71M, which can save
more than 15% of adjustable parameters and exhibit higher
parameter efficiency compared to the AST model.
A. Speech Commands Experiments
1) Dataset Introduction and training details:
Speech
Commands V2(Warden 2018) is an audio dataset containing
35 classifications, consisting of 84843 training samples, 9981
validation samples and 11005 test samples. The duration of
each sample is 1 second.
According to the settings in ”AST: Audio Spectrogram
Transformer”, we set the initial learning rate to 2.5e-4 and
reduce the learning rate of each epoch to 0.85 of the learning
rate of the previous epoch after the 5th epoch. for the two
cases of ImageNet being True and False, we respectively We
conducted experiments with 10 epochs and 30 epochs for the
two cases of ImageNet being True and False, respectively.
We select the best model by evaluating the metrics on the
validation dataset and report the evaluation metrics on the
test set. For the validation process of each model, we used
three different random seeds.
We choose the accuracy rate (ACC) and area under the
curve (AUC) as evaluation metrics.
2) Speech Commands Results : First, we conducted ex-
perimental validation for the case of not using the pre-trained
model, specifically, setting ImageNet to False and evaluating
the effectiveness of replacing the Encoder with the MLP-
Mixer. The experimental results are detailed in Table 1,
which lists the data for the validation set accuracy (v-acc),
the area under the validation set curve (v-auc), the test set
accuracy (t-acc), and the area under the test set curve (t-auc).
Throughout the experiments in the paper, the metric names
and random seed labels are consistent to ensure comparable
experimental results.
Notably, after 30 epochs of training, we observe that
the ASM model performs significantly better than the AST
model (Baseline) in terms of ACC and AUC on the validation
and test sets. This indicates that the replacement of Encoder
using the MLP-Mixer with the removal of the pretrained
model can effectively improve the performance of the model
on this dataset.
Next, we verify the effectiveness of using the RGB to
grayscale map formula in Linear Projection under the con-
TABLE II
IMAGENET=TRUE, SCV2, AST ,AST-RGB
AST
AST-RGB
v-acc
0.8006±0.0215
0.8146±0.0101
v-auc
0.9883±0.0020
0.9907±0.0011
t-acc
0.7834±0.0301
0.7951±0.0167
t-auc
0.9873±0.0019
0.9889±0.0015
TABLE III
IMAGENET=TRUE, SCV2, AST AND MIXER
AST
Mixer
v-acc
0.8006±0.0215
0.9470±0.0022
v-auc
0.9883±0.0020
0.9987±0.0003
t-acc
0.7834±0.0301
0.9401±0.0041
t-auc
0.9873±0.0019
0.9983±0.0002
dition of using a pre-trained model, i.e., ImageNet=True.
The experimental results are detailed in Table 2, where the
column and row names are the same as in the previous paper.
We observe that after 10 epochs of training, the model using
the RGB-to-grayscale map formula performs consistently
better than the AST model (Baseline) in terms of accuracy
(ACC) and area under the curve (AUC) on both the validation
and test sets.
At the end of this subsection, we further validate the
effectiveness of using the MLP-Mixer to replace Encoder
under the condition of using a pre-trained model (i.e.,
ImageNet=True). The experimental results are detailed in
Table 3, where the column and row names have the same
meaning as before. We observe that after 10 epochs of
training, the ASM model with the MLP-Mixer replacing
Encoder performs significantly better than the AST model
(Baseline) in terms of accuracy (ACC) and area under the
curve (AUC) on the validation and test sets.
B. UrbanSound8K Experiments
1) Dataset Introduction and training details:
Urban-
Sound8K(Jaiswal and Patel 2018) is a commonly used audio
classification dataset for research and experiments in sound
classification and ambient sound recognition. It consists of
a series of audio samples from urban environments and
contains 8,732 short audio clips.
The following are some important information and fea-
tures of the UrbanSound8K dataset:
Data source: Audio samples for the UrbanSound8K dataset
are collected from 10 different urban environments, including
streets, highways, parks, shopping malls, and more. These
audio clips are collected by deploying sensors in the city
and recording environmental sounds.
Audio classification: Each audio clip in the dataset is
classified into one of 10 categories, which include: air
conditioner, car horn, children playing, dog bark, drilling,
engine idling, gunshot, jackhammer, siren, and street music.
Data format: Each audio clip is stored in WAV format
(lossless audio) and has the same sample rate (44.1 kHz).
The duration of the audio clips is between 1 and 4 seconds.
Dataset division: The UrbanSound8K dataset is divided
according to a training set and a test set. The training
TABLE IV
IMAGENET=FALSE, US8K, AST AND MIXER
AST
Mixer
v-acc
0.7628±0.0089
0.8852±0.0029
v-auc
0.9676±0.0015
0.9906±0.0012
t-acc
0.7510±0.0113
0.8951±0.0069
t-auc
0.9662±0.0018
0.9903±0.0019
set contains the majority of the 8,732 audio clips (with at
least 400 samples per category), while the test set contains
additional audio clips for evaluating model performance.
Metadata information: In addition to the audio samples
themselves, the dataset also contains metadata information
for each audio clip, such as file ID, audio category, sample
rate, duration, etc. This metadata information can be used to
train the model and perform evaluation.
The UrbanSound8K dataset provides a rich and diverse
sample of urban environmental sounds that can be used to
conduct research related to sound classification, environmen-
tal sound recognition, machine learning and deep learning. It
has become one of the benchmark datasets for many audio
classification algorithms and models.
In this part of the experiments, we set the initial learning
rate to 1e-4 and after the 5th epoch, the learning rate of
each epoch decreases to 0.85 of the learning rate of the
previous epoch. we conducted two cases of experiments
with ImageNet as True and False, and 10 epochs of training
were performed in each case. We selected the best model by
validating the evaluation metrics of the dataset and reported
these evaluation metrics on the test set. To increase the
reliability of the experimental results, we performed three
different random seed validations for each model, as in the
previous section. We chose accuracy (ACC) as the primary
evaluation metric and area under the curve (AUC) as a
secondary evaluation metric to assess the performance of the
models.
2) UrbanSound8K Results: First, we verified the effec-
tiveness of using MLP-Mixer to replace Encoder without
using the pre-trained model (i.e., ImageNet = False). The
results of our experiments are shown in Table 4, where the
column and row names have the same meaning as before.
By comparing the experimental results, we can observe
that after 10 epochs of training, the ASM model using MLP-
Mixer to replace Encoder performs significantly better than
the AST model (Baseline) on the validation set.
Next, we verify the effectiveness of using the RGB-to-
grayscale map formula in Linear Projection and the effec-
tiveness of using the MLP-Mixer to replace Encoder in the
case of using a pre-trained model (i.e., ImageNet = True).
The experimental results are shown in Table 5, where the
meanings of column and row names are the same as before.
After 10 epochs of training, we observe that the model
using the RGB-to-grayscale map formula performs stably
better than the AST model (Baseline) on the validation and
test sets.
In addition, we can also find that the ASM model using
MLP-Mixer to replace Encoder performs significantly better
TABLE V
IMAGENET=TRUE, US8K, AST ,AST-RGB
AST
AST-RGB
v-acc
0.8806±0.0053
0.8932±0.0043
v-auc
0.9892±0.0015
0.9908±0.0010
t-acc
0.8898±0.0024
0.8951±0.0074
t-auc
0.9896±0.0014
0.9905±0.0013
TABLE VI
IMAGENET=TRUE, US8K, AST AND MIXER
AST
Mixer
v-acc
0.8806±0.0053
0.9230±0.0142
v-auc
0.9892±0.0015
0.9944±0.0020
t-acc
0.8898±0.0024
0.9176±0.0127
t-auc
0.9896±0.0014
0.9944±0.0009
than the AST model (Baseline) on the validation and test
sets.
C. CASIA Chinese Sentiment Corpus Experiments
1) Dataset Introduction and training details: The CASIA
Chinese Sentiment Corpus(Ke et al. 2018) is recorded by the
Institute of Automation, Chinese Academy of Sciences. The
corpus covers speech material recorded by four professional
pronouncers, including six emotions: angry, happy, fear, sad,
surprised and neutral. A total of 9600 speech samples with
different pronunciations are included.
Of these, 300 speech samples are recorded based on the
same text, i.e., the same text is given different emotional
states for reading aloud. These samples can be used to com-
pare and analyze the acoustic characteristics and rhythmic
performance in different emotional states.
In addition, there are 100 speech samples are recorded
based on different texts. These texts are literally clear in their
emotional attribution, enabling the pronouncer to express the
corresponding emotional state more accurately.
The CASIA Chinese Sentiment Corpus is designed to
provide researchers with rich phonetic data to explore dif-
ferences in the acoustic and rhythmic aspects of emotional
expression. The data in this corpus are recorded from pro-
fessional speakers and possess high quality and accuracy,
which can provide strong support for research in the fields
of emotion recognition and speech emotion processing.
In this section, we refer to the setup of the Speech
Commands V2 dataset experiments. The initial learning rate
is set to 2.5e-4, and after the 5th epoch, the learning rate
of each epoch decreases to 0.85 of the learning rate of the
previous epoch. we conduct experiments with 25 epochs
in both the True and False cases of ImageNet. The best
model is selected by validating the evaluation metrics of the
dataset, and we report these evaluation metrics on the test
set. To increase the reliability of the experimental results,
we perform three different random seed validations for each
model. We choose the accuracy rate (ACC) of the model.
2) CASIA Chinese Sentiment Corpus Results: First, we
verify the effectiveness of using the MLP-Mixer to replace
the Encoder without using the pre-trained model (i.e., Im-
ageNet = False). The results of our experiments are shown
TABLE VII
IMAGENET=FALSE, CASIA, AST AND MIXER
AST
Mixer
v-acc
0.7833±0.0194
0.9025±0.0089
v-auc
0.9783±0.0033
0.9948±0.0012
t-acc
0.7760±0.0112
0.8997±0.0107
t-auc
0.9780±0.0024
0.9943±0.0008
TABLE VIII
IMAGENET=TRUE, CASIA, AST ,AST-RGB
AST
AST-RGB
v-acc
0.7932±0.0121
0.7984±0.0044
v-auc
0.9821±0.0021
0.9834±0.0016
t-acc
0.7997±0.0099
0.8102±0.0064
t-auc
0.9826±0.0012
0.9839±0.0007
in Table 7, where the column and row names have the same
meaning as before.
By comparing the experimental results, we can observe
that after 25 epochs of training, the ASM model using MLP-
Mixer to replace Encoder performs significantly better than
the AST model (Baseline) in terms of accuracy (ACC) and
area under the curve (AUC) on the validation and test sets.
Next, we verify the validity of using the RGB to grayscale
map formula in Linear Projection in the case of using a
pretrained model (i.e., ImageNet = True). The experimental
results are shown in Table 8, where the column and row
names have the same meaning as before.
After 25 epochs of training, we observe that the model
using the RGB-to-grayscale map formula performs relatively
consistently better than the AST model (Baseline) in terms
of accuracy (ACC) and area under the curve (AUC) on both
the validation and test sets.
At the end of this subsection, we validate the effectiveness
of using the MLP-Mixer to replace the Encoder for the case
where a pre-trained model is used (i.e., ImageNet = True).
The experimental results are detailed in Table 9, where the
meaning of the column and row names in the table is the
same as in the previous section.
After 25 epochs of training, we observe that the ASM
model using MLP-Mixer to replace Encoder performs sig-
nificantly better than the AST model (Baseline) in terms of
accuracy (ACC) and area under the curve (AUC) on both the
validation and test sets.
D. Comparison of Activation Functions in Mixer
1) Dataset and Experimental setup: We use the CASIA
Chinese Sentiment Corpus as the experimental dataset for
this part, and use the Gelu activation function used in ”MLP-
Mixer” as the baseline, and use the Mish, Swish and Acon-C
TABLE IX
IMAGENET=TRUE, CASIA, AST AND MIXER
AST
Mixer
v-acc
0.7932±0.0121
0.9247±0.0056
v-auc
0.9821±0.0021
0.9962±0.0010
t-acc
0.7997±0.0099
0.9176±0.0088
t-auc
0.9826±0.0012
0.9945±0.0012
Fig. 2.
Seed-1, ACC
activation functions for comparison. In addition, we make
appropriate adjustments to the function characteristics of
Acon-C to ensure that the p1 parameter is initialized near
1 and the p2 parameter is initialized near 0 as much as
possible. Since the implementation of Acon-C requires the
use of batch size as a parameter, considering the number of
data samples in the CASIA Chinese sentiment corpus, we
made appropriate adjustments to ensure that the impact of
batch size on the experiment is eliminated in order to make
the experiment more complete. We still use 3 random seeds
in our experiments, which is the same as described in the
previous section.
The initial learning rate is set to 2.5e-4 and after the
5th epoch, the learning rate of each epoch decreases to
0.85 of the learning rate of the previous epoch. we conduct
experiments with ImageNet = False for 25 epochs. The
best model was selected using evaluation metrics from the
validation set, and we report these evaluation metrics on the
test set. We choose accuracy (ACC) as the main evaluation
metric and area under the curve (AUC) as a secondary
evaluation metric.
2) Experimental Results: After 25 epochs of training, the
results of our experiments on random seed No. 1 are shown
in Table 10, Figure 2 and Figure 3. From them, it can be
observed that the model with the use of the adjusted Acon-
C activation function performs best in all four evaluation-
metrics. However, the Swish activation function performs the
worst in all four evaluation-metrics.
Fig. 3.
Seed-1, AUC
TABLE X
IMAGENET=TRUE, CASIA, SEED-1
Seed-1
GeLU
Mish
Swish
Acon-C
Acon-C(adapted)
v-acc
0.8954
0.8907
0.8870
0.8944
0.9028
v-auc
0.9922
0.9927
0.9922
0.9926
0.9952
t-acc
0.8824
0.8759
0.8704
0.8963
0.9046
t-auc
0.9915
0.9914
0.9911
0.9916
0.9934
Fig. 4.
Seed-2, ACC
Fig. 5.
Seed-2, AUC
Similarly, the results of our experiments with random seed
No. 2 are shown in Table 11, Figure 4, and Figure 5, and it
is found that the model using the adjusted Acon-C activation
function still performs best on the four metrics.
In the experiments with random seed No. 3, the results
of the evaluation metrics for the validation and test sets are
shown in Table 12, Figure 6, and Figure 7, and we again find
that the model using the adapted Acon-C activation function
performs best on all four metrics.
IV. CONCLUSION AND FOLLOW-UP
A. Conclusion
In recent years, the Transformer has become an indispens-
able and critical component in various fields. However, in
our study, we find that it is not necessary to adopt such
a complex network structure. In the field of vision and
temporal prediction, there are already successful cases that
demonstrate the superiority of the Mixer, which reduces the
inference cost (according to our experiments, saving more
Fig. 6.
Seed-3, ACC
Fig. 7.
Seed-3, AUC
than 20% of the training time compared to AST) while
having an accuracy that is as good as or even better than that
of the Transformer. The Mixer does not yet have a pre-trained
model comparable to the volume of DeiT, so we cannot
verify whether Mixer can maintain its excellent performance
with a large amount of prior knowledge. However, based
on the work in this paper, we have good reasons to believe
that Mixer has the potential to challenge Transformer in the
field of audio classification, and researchers should pay more
attention and devote more resources to the research of MLP
and Mixer.
Also in this study, we validate the use of the RGB-
to-grayscale map formulation instead of simple weighted
fusion. The experimental data show that the optimized model
performs stably better than the original model, although
the improvement in accuracy is only between 1% and 3%.
We should recognize that the accuracy of the model is
mainly influenced by factors such as model structure and
data volume. However, this optimization work still reminds
us that changes and optimizations should be made with more
TABLE XI
IMAGENET=TRUE, CASIA, SEED-2
Seed-1
GeLU
Mish
Swish
Acon-C
Acon-C(adapted)
v-acc
0.8852
0.8889
0.9065
0.8972
0.9120
v-auc
0.9915
0.9928
0.9931
0.9933
0.9949
t-acc
0.8778
0.8796
0.8769
0.8806
0.9102
t-auc
0.9910
0.9908
0.9904
0.9919
0.9939
TABLE XII
IMAGENET=TRUE, CASIA, SEED-3
Seed-1
GeLU
Mish
Swish
Acon-C
Acon-C(adapted)
v-acc
0.8815
0.8963
0.9009
0.8833
0.9139
v-auc
0.9926
0.9930
0.9935
0.9915
0.9948
t-acc
0.8759
0.8843
0.8824
0.8787
0.9019
t-auc
0.9900
0.9906
0.9909
0.9904
0.9947
reference to objective laws and knowledge that has been
practically validated in other fields. Such an approach can
provide us with more targeted directions for improvement,
which can lead to better model performance.
B. Follow-up
We plan to apply the existing Mixer pre-trained network
to ASM to explore its effectiveness in audio classification
tasks. Compared with Transformer, Mixer does not seem
to require trainable location information, so we consider
verifying whether removing the CLS flag in AST will have
an impact on the accuracy. In addition, we plan to further
optimize the structure of the Mixer unit to find a more
suitable Mixer for audio classification tasks.
Besides, we are also inspired by the SSAST method and
plan to try to train the ASM model using a self-supervised
training approach to solve the problem of mismatch between
the migrated visual model and the audio spectrogram. This
will help improve the generalization performance of the
model and further enhance the accuracy of audio classifi-
cation.
REFERENCES
[1] Dosovitskiy, Alexey , et al. ""An Image is Worth 16x16 Words: Trans-
formers for Image Recognition at Scale."" International Conference on
Learning Representations 2021.
[2] Gemmeke, Jort F. , et al. ""Audio Set: An ontology and human-labeled
dataset for audio events."" IEEE International Conference on Acoustics
IEEE, 2017.
[3] Gong, Yuan , Y. A. Chung , and J. Glass . ""AST: Audio Spectrogram
Transformer."" (2021).
[4] [1] Hendrycks, Dan , and K. Gimpel . ""Gaussian Error Linear Units
(GELUs)."" (2016).
[5] Jaiswal, Kaustumbh, and Dhairya Kalpeshbhai Patel. ""Sound classifi-
cation using convolutional neural networks."" 2018 IEEE International
Conference on Cloud Computing in Emerging Markets (CCEM).
IEEE, 2018.
[6] Ke, Xianxin, et al. ""Speech emotion recognition based on SVM and
ANN."" International Journal of Machine Learning and Computing 8.3
(2018): 198-202.
[7] Li, Zhe, et al. ""Mts-mixers: Multivariate time series forecast-
ing via factorized temporal and channel mixing."" arXiv preprint
arXiv:2302.04501 (2023).
[8] Ma, Ningning, et al. ""Activate or not: Learning customized activation.""
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition. 2021.
[9] Misra, Diganta. ""Mish: A self regularized non-monotonic activation
function."" arXiv preprint arXiv:1908.08681 (2019).
[10] Piczak, Karol J. ""ESC: Dataset for environmental sound classification.""
Proceedings of the 23rd ACM international conference on Multimedia.
2015.
[11] Ramachandran, Prajit , B. Zoph , and Q. V. Le . ""Swish: a Self-Gated
Activation Function."" (2017).
[12] Tolstikhin, Ilya O., et al. ""Mlp-mixer: An all-mlp architecture for
vision."" Advances in neural information processing systems 34 (2021):
24261-24272.
[13] Touvron, Hugo, et al. ""Training data-efficient image transformers &
distillation through attention."" International conference on machine
learning. PMLR, 2021.
[14] Warden, Pete. ""Speech commands: A dataset for limited-vocabulary
speech recognition."" arXiv preprint arXiv:1804.03209 (2018).
"
"In this research, we introduce Boidae, a suite of customizable, user-controlled Boa installations. Utilizing automation tools such as Ansible and Docker, Boidae enables deployment of tailored Boa setups. Notably, it allows the creation of custom datasets from any collection of Git repositories. These customized datasets can be generated from any set of Git repositories and are facilitated by helper scripts that aid in finding and cloning repositories from GitHub and SourceForge. The utility of Boidae lies in its versatile architecture, enabling researchers to generate custom datasets and make modifications to the Boa language and runtime.nan","Mining software repositories (MSR) is a powerful technique for unearthing developer habits and feature usage within the Software Engineering (SE) community. However, conducting MSR studies presents challenges, such as time-consuming dataset generation and complex data processing. Boa, a domain-specific query language and runtime infrastructure, simplifies MSR research. It facilitates the analysis of ultra-large-scale repositories, such as those found on GitHub and SourceForge, by leveraging Hadoop's infrastructure for storage and computation. While Boa streamlines MSR studies, it has limitations. Researchers often require customized datasets for their research, or they may wish to modify the Boa runtime or query language, which can be difficult with the current Boa setup.nan","nanThe mining software repositories (MSR) research process can be broken down into three main stages: dataset generation, dataset mining, and dataset analysis. Though these stages can be challenging for new researchers, the first two stages pose unique difficulties. Dataset generation can be time-consuming and requires knowledge of tasks like using the GitHub API, parsing source files with libraries like Eclipse JDT, and storing large amounts of data using distributed filesystems or formats like Protocol Buffers. Mining the data also demands substantial expertise, including knowledge of distributed data analysis frameworks like Hadoop or Spark. While there are solutions that help alleviate some of these difficulties, none of them offer a comprehensive solution that allows for both easy dataset generation and customization of the mining framework. This is the primary motivation behind the development of Boidae.nan","Boidae's architecture has two primary components, each corresponding to a different runtime environment. The first component is a Docker image designed for local operation on a single machine, primarily intended for testing and analyzing small datasets. This image includes helper scripts for generating customized datasets from GitHub or SourceForge projects, and it enables modifications to the Boa compiler, runtime infrastructure, and language. For larger datasets, the second component provisions a distributed environment. Users can set up a cluster of compute nodes using their organization's computing services, cloud platforms like AWS, or research infrastructure such as CloudLab or ACCESS. Once the servers are provisioned, Ansible scripts can be used to install and configure a distributed Boidae instance, supporting dataset and runtime customization.nan","The Boidae infrastructure was evaluated in four ways. Initially, to evaluate its ability to run on multiple systems, the Docker version was tested on various machines, and the cloud version was verified using Ansible scripts deployed on small clusters at Bowling Green State University and the CloudLab experimental testbed. To assess dataset generation capabilities, a custom dataset was built using repositories from the boalang user on GitHub. Furthermore, the infrastructure was tested for language and runtime customization by modifying the Boa language to add custom functions and then verifying their availability and functionality in queries. Additionally, the scalability of the infrastructure was evaluated by running tasks with varying numbers of map tasks, demonstrating good performance and the capability to handle larger datasets.nan","Boidae is a significant contribution to the field of MSR as it offers a user-friendly platform for creating customized Boa instances. This enables researchers to generate custom datasets and modify the Boa language and runtime as needed. The availability of Boidae as a Docker container and the provision of Ansible scripts ensures that researchers can easily set up and manage their own Boa instances. Moreover, the operational Boa instance, available at https://boa.cs.iastate.edu/boa/, provides a readily accessible platform for users who prefer not to set up their own instances. With Boidae, researchers can focus more on their research questions and gain deeper insights into software repositories, alleviating the complexities of dataset generation and runtime modifications.nan",Boidae: Your Personal Mining Platform,"Brian Sigurdson, Samuel W. Flint, Robert Dyer","Boidae: Your Personal Mining Platform
Brian Sigurdson
Bowling Green State University
Bowling Green, Ohio, USA
bsigurd@bgsu.edu
Samuel W. Flint
University of Nebraska-Lincoln
Lincoln, Nebraska, USA
swflint@huskers.unl.edu
Robert Dyer
University of Nebraska-Lincoln
Lincoln, Nebraska, USA
rdyer@unl.edu
ABSTRACT
Mining software repositories is a useful technique for researchers
and practitioners to see what software developers actually do when
developing software. Tools like Boa provide users with the ability
to easily mine these open-source software repositories at a very
large scale, with datasets containing hundreds of thousands of
projects. The trade-off is that users must use the provided infras-
tructure, query language, runtime, and datasets and this might not
fit all analysis needs. In this work, we present Boidae: a family
of Boa installations controlled and customized by users. Boidae
uses automation tools such as Ansible and Docker to facilitate the
deployment of a customized Boa installation. In particular, Boidae
allows the creation of custom datasets generated from any set of
Git repositories, with helper scripts to aid in finding and cloning
repositories from GitHub and SourceForge. In this paper, we briefly
describe the architecture of Boidae and how researchers can uti-
lize the infrastructure to generate custom datasets. Boidae’s scripts
and all infrastructure it builds upon are open-sourced. A video
demonstration of Boidae’s installation and extension is available at
https://go.unl.edu/boidae.
CCS CONCEPTS
• Software and its engineering;
KEYWORDS
Boa, mining software repositories, scalable, open source
ACM Reference Format:
Brian Sigurdson, Samuel W. Flint, and Robert Dyer. 2024. Boidae: Your
Personal Mining Platform. In 2024 IEEE/ACM 46th International Conference
on Software Engineering: Companion Proceedings (ICSE-Companion ’24), April
14–20, 2024, Lisbon, Portugal. ACM, New York, NY, USA, 4 pages. https:
//doi.org/10.1145/3639478.3640026
1
INTRODUCTION
Mining software repositories (MSR) is a powerful methodology for
discovering developer habits, feature usage, etc. within the Software
Engineering (SE) community. However, performing mining studies
comes with great difficulty: generating a dataset takes time, and
processing that dataset is difficult. Libraries like PyDiller [13] help
ease writing mining code but do not provide easy access to the
source code’s abstract syntax tree (AST) which can either limit
your analysis or require additional, complex libraries. Boa [4, 5,
11] is a domain-specific query language and runtime infrastructure
This is the author’s version of the work. It is posted here for your personal use. Not
for redistribution. The definitive version was published in ICSE-Companion’24.
ICSE-Companion ’24, April 14–20, 2024, Lisbon, Portugal
© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00
https://doi.org/10.1145/3639478.3640026
designed to ease MSR research. Boa has been shown to reduce
the effort necessary to complete MSR studies on ultra-large-scale
repositories such as GitHub and SourceForge. Boa is able to do so
by leveraging the Hadoop framework for storage and computation,
allowing it to scale to accommodate large datasets. It provides users
with a web-based interface and allows users to easily replicate
Boa-based experiments provided by other researchers.
Boa has a few limitations, however. First, users often want to
build customized datasets for their research tasks. This may be
necessary if they want to analyze proprietary datasets or when
replicating prior research that requires building a dataset with the
same (or comparable) repositories in it, such as was the case for
Keshk et al. [8] that built a custom Boa dataset to replicate the
prior work of Nakamaru et al. [10]. Since most researchers do not
have access to the Boa infrastructure itself, building a custom Boa
dataset is not even an option and they can only query the existing
datasets, which currently support languages such as Java, Kotlin,
and Python.
The second limitation is in the runtime and query language.
Biswas et al. [2] extended Boa to add support for the Python lan-
guage and produced a dataset of repositories related to data science.
Once again, since most users have no administrative access to the
Boa infrastructure, even if they wanted to modify the open-sourced
compiler for Boa’s query language to add additional features or
provide support for other programming languages they want to
mine, they currently are unable to do so.
To solve these problems, in this work, we present Boidae.
Whereas Boa is a specific instance of a mining framework, Boidae
is a family of (possibly customized) mining frameworks. While Boa
aims to provide an easy-to-use, single place for users wishing to
mine open-source repositories, Boidae’s intended users are more
advanced software miners who need customization not currently
feasible with Boa.
Users are able to instantiate their own Boa instance either locally
on their computer using Docker1 or remotely on a set of cloud
servers using Ansible2. Thus, if users want to analyze a smaller,
but custom, dataset or to test their queries locally on a sample of
the larger datasets they can run a Docker instance. Once they want
to scale to a larger dataset, they have the ability to easily spin up
a cluster, on any cloud platform they have access to, with their
custom Boa dataset.
The remainder of the paper is organized as follows. First, we
discuss some background on the MSR process and closely related
works in Section 2. Next, we discuss Boidae, its use case, workflow,
and general use in Section 3. We evaluate the approach in Section 4.
Finally, we conclude in Section 5.
1https://www.docker.com/
2https://www.ansible.com/
arXiv:2401.11092v1  [cs.SE]  20 Jan 2024
ICSE-Companion ’24, April 14–20, 2024, Lisbon, Portugal
Brian Sigurdson, Samuel W. Flint, and Robert Dyer
1. Dataset Generation
2. Dataset Mining
3. Dataset Analysis
Figure 1: Overview of the general mining software repositories workflow
All source code for the Boa language and runtime and Boidae’s
Ansible and Docker scripts are available on GitHub at https://github.
com/unl-pal/Boidae.
2
BACKGROUND AND RELATED WORKS
The mining software repositories (MSR) research process can be
thought of as having three main stages: dataset generation, dataset
mining, and dataset analysis. The overall workflow is shown in
Fig. 1. While all stages can be difficult for new researchers, the first
two stages pose several challenges beyond other types of SE re-
search. First, generating datasets can be time intensive and requires
knowledge of things like the GitHub API, how to parse source files
with libraries such as Eclipse JDT, and methods for storing large
amounts of data such as utilizing distributed filesystems or complex
formats such as Protocol Buffers.
Second, even once such a dataset is generated, mining that data
also requires substantial expertise. For example, if the dataset is
sufficiently large it might require knowledge of distributed data
analysis frameworks such as Hadoop or Spark. Mining the code
structure itself requires a lot of domain expertise and knowledge of
things like abstract syntax trees.
Finally, users can analyze the mined data. Here they may need
to leverage things like Pandas for the analysis and Matplotlib for
visualizing the results.
All three stages are difficult and time-intensive, however, the
first and the second can be abstracted. Researchers can build and
share datasets or tools that enable other researchers to implement
their studies more easily. An example is the Boa infrastructure [4,
5, 11], which provides support for the first two steps. As we will
discuss late, Boidae builds on top of Boa.
With Boa, many repositories are collected in advance and trans-
lated into a format that is suitable for mining using a paralleliz-
able, domain-specific language. Boa provides several pre-generated
datasets, with support for analyzing several programming lan-
guages such as Java, Python, and Kotlin. The datasets typically
have 10’s to 100’s of thousands of projects each. Once generated,
the datasets are immutable and will never change over time. This
aids the replication of prior results.
Boa also provides a query language designed to abstract away
as much of the parallelization as possible. Users write queries that
look sequential, essentially focusing on what data they want to
extract from a single project. Boa then automatically parallelizes the
query, running it as a distributed Hadoop program. This provides
scalability, so queries on hundreds of thousands of projects can
return in as little as 30 seconds.
There are other prior works that provide some similar func-
tionality. For example, GHTorrent [6, 7] is a website and dataset
containing the event stream from GitHub. Similar to Boa, users can
use a shared infrastructure if they wish to query the dataset, and
dataset generation is controlled by the GHTorrent admins.
PyDriller [13] provides a library to more easily mine Git repos-
itories. While PyDriller makes it easier to analyze repositories, it
does not currently provide support to make the generation of a
dataset easier.
Sourcerer [9] provides a large dataset of Java projects in the form
of a SQL database. Again, the generation of that data is up to the
maintainers, and the dataset is provided in a fixed format. Users
must query that data with SQL queries but are free to write any
custom mining functions they wish as the infrastructure does not
provide a custom query language.
All of these approaches help ease either step 1 or step 2 of the
MSR workflow. But none of them ease both steps while also pro-
viding the ability to easily customize the dataset being generated
or customize the query language used to mine that data. This is the
main goal of Boidae.
3
BOIDAE
Here, we describe Boidae’s architecture and an example use case.
3.1
Use Case
While Boa presents a large dataset and pre-built infrastructure,
Boidae allows researchers to build custom datasets and make mod-
ifications to the Boa language. Consider, for example, a researcher
who wishes to perform a more one-to-one analysis on a dataset
from a prior work. While they may be able to find and clone all of
the same Git datasets as the prior work, writing analyses on it or
scaling those analyses could be difficult.
The researcher could write custom code using several different
libraries in their programming language of choice, however, this
would require keeping track of many small details leading to more
complicated code: additionally, it likely would not run quickly as
it may not be easily parallelizable. Using Boidae, our researcher
can build a dataset from these projects and run it on any server the
research has access to. Additionally, with some effort, they could
extend Boa to include additional information they may be interested
in (e.g., output from runs of external tools, or issue tracker data).
3.2
Architecture
The architecture of Boidae is split, based on two different runtime
environments, as shown in Fig. 2. First, we provide a Docker im-
age for running Boidae locally on a single machine. This image
is designed to support two use cases: testing and analyzing small
datasets. Users utilize Docker’s compose functionality to run the
container and then connect to a web service running on localhost.
This provides a web interface similar to the one Boa provides, al-
lowing the user to select a dataset and run a query.
The container also contains helper scripts for generating cus-
tomized datasets. The scripts provide support for both GitHub and
SourceForge, or the user can simply manually clone any Git reposi-
tories and generate a dataset from that set of repositories. If gener-
ating from GitHub-based projects, the user has the option of simply
specifying a list of repositories they want to generate a dataset from
Boidae: Your Personal Mining Platform
ICSE-Companion ’24, April 14–20, 2024, Lisbon, Portugal
Boidae
Docker
(local/testing)
Ansible
(distributed)
Run Docker
docker-compose up
Provision Servers
Install Ansible
Install Boidae
Figure 2: Overview of the Boidae architecture
or they can use more generic tools that will use GitHub’s API to
search for projects matching the user’s requirements.
The container also provides support for modifying the runtime.
The language’s compiler and runtime infrastructure are installed
in source format, with a full build environment available. There
are also support scripts to help update/install new versions of the
compiler, once users have modified it.
The second supported runtime environment is a distributed en-
vironment. This helps support any use case where the user has a
larger dataset they might need to query frequently. For this, the
user needs to first provision a set of compute nodes. This can be
done with their employer’s/university’s computing services, with a
cloud such as Amazon Web Services (AWS) [12], or using research
infrastructure such as CloudLab [3] or ACCESS [1]. Once they have
servers provisioned, they can install Ansible and use our provided
Ansible scripts to get a Boidae distributed instance installed and
configured. They still have the ability to customize the dataset or
runtime when utilizing the Ansible scripts.
3.3
Workflow
With Boidae, the overall workflow remains the same as shown in
Fig. 1, but there are changes in some details, and steps 2 and 3 are
more easily repeated. Continuing on with our prior use case, our
researcher would complete the following steps.
First, a basic Boa cluster would be configured using either the
Ansible scripts or the Docker file. The Ansible scripts will allow for
the installation of a Boidae cluster on a number of nodes, though it
is specifically designed for CloudLab [3]. The Docker file is instead
useful for the generation of datasets, testing of modifications to the
compiler on small datasets, or general work on small datasets. At
this point, any modifications to the dataset generation code (to store
results of external tools), the compiler (for further integration of
external tools), or the run time (addition of language-level functions)
should be completed.
Then, they would collect metadata files for each repository. These
are JSON files that are collected using the GitHub API, which de-
scribe a number of properties of the project, including star gazer
count. These JSON files are then used to generate the dataset
through the use of one of several scripts. This script will clone
the repositories automatically. To ensure that private repositories
can be cloned appropriately, GitHub’s HTTPS authentication must
be correctly configured. Generation of a dataset will take time when
many repositories are ingested. Once the generation is complete,
the dataset can be installed into the configured Boidae cluster. From
this point forward, steps 2 and 3 may commence: the dataset is now
ready to be used for studies.
Now the dataset may be mined using the Boa language, running
queries like that shown in Fig. 3, which counts the number of
annotations per project. Writing Boa queries is a topic in itself,
but generally, the visitor pattern is used to visit each commit, and
within each commit, each changed file. A query can drill down to
whatever level of the file is necessary, and tabular data is generated.
The example query shows data indexed by project, but indexing by
other elements is possible.
1
o: output sum[project: string] of int;
2
3
visit(input , visitor {
4
before node: CodeRepository -> {
5
snapshot := getsnapshot(node);
6
foreach (i: int; def(snapshot[i]))
7
visit(snapshot[i]);
8
stop;
9
}
10
before mod: Modifier -> {
11
if (mod.kind == ModifierKind.ANNOTATION)
12
o[input.id] << 1;
13
}
14
});
Figure 3: Count number of annotations per project.
These tabular data files can be easily converted to CSV and
analyzed using any preferred tools. Support for building multiple-
file analyses is partially provided by the Boa Study Template.3
4
EVALUATION
We evaluated the Boidae infrastructure in four ways. First, we
wanted to ensure that the infrastructure can run on multiple sys-
tems. To evaluate this, we first verified we can run the Docker
version of the infrastructure on several different machines. Next,
we wanted to verify if the cloud version of Boidae works. To verify
this, we used the Ansible scripts to install Boidae onto a small
cluster of five nodes at Bowling Green State University. We also uti-
lized the CloudLab [3] infrastructure, an experimental testbed that
allows researchers to experiment with cloud infrastructures. Once
we configured the server infrastructure, we were able to once again
utilize the Ansible scripts to get an instance of Boidae running on
CloudLab’s servers.
Our second evaluation was to see if it is possible to build custom
datasets. We used Boidae’s feature for building GitHub datasets to
build a custom dataset containing the repositories in the boalang
user, which represents the open-source infrastructure for Boa. We
were able to successfully generate the dataset and run sample
queries on it.
3https://github.com/boalang/study-template
ICSE-Companion ’24, April 14–20, 2024, Lisbon, Portugal
Brian Sigurdson, Samuel W. Flint, and Robert Dyer
The third evaluation is to see if Boidae supports customizing
the language and runtime. For this evaluation, we modified the
Boa language to add additional support for custom domain-specific
mining functions. We then verified that those custom functions
were available in queries and manually inspected the results to
verify they worked as intended.
Finally, we previously evaluated the scalability of the infrastruc-
ture. Since the infrastructure runs on top of Hadoop, we ran several
tasks in a prior work [4]. We then varied the number of map tasks
from 1 to 32. See Figure 4 for the results.
Figure 4: Task execution times as the number of maps in-
creases [4].
As can be seen from the figure, the time needed to execute the
queries decreases as the number of parallel map tasks increases.
It then levels out at around 16 map tasks. This shows that the
infrastructure can scale, providing good performance.
5
CONCLUSION
Mining software repositories is an important field of research in
SE. Tools like Boa provide ways to more easily mine repositories
but, despite being open-sourced, do not allow users the ability to
customize the dataset or the runtime. Boidae provides a solution to
allow researchers to run their own customized instances of Boa, en-
abling them to easily generate and mine their own custom datasets.
Boidae provides the ability to run locally on Docker, or scale to
cloud-scale using Ansible scripts.
An operational Boa instance is available at https://boa.cs.iastate.
edu/boa/ and available to the public. For anyone wishing to cus-
tomize either the dataset or Boa’s infrastructure, Boidae pro-
vides installation in the form of either Ansible scripts at https:
//github.com/boalang/ansible or a Docker container at https://
github.com/boalang/boa-docker. The Boa infrastructure, which
Boidae utilizes, is available at https://github.com/boalang/compiler
and https://github.com/boalang/drupal.
All artifacts for this demo are available in GitHub at https:
//github.com/unl-pal/Boidae. A video demonstration of Boidae’s
installation and extension is available at https://go.unl.edu/boidae.
ACKNOWLEDGMENTS
This work was supported in part by the U.S. National Science Foun-
dation (NSF) under grants 1512947 and 1518776.
REFERENCES
[1]
ACCESS. Advanced cyberinfrastructure coordination ecosys-
tem: services and support, 2023. url: https://access-ci.org/.
[2]
S. Biswas, M. J. Islam, Y. Huang, and H. Rajan. Boa meets
Python: a Boa dataset of data science software in Python
language. In Proceedings of the 16th International Conference
on Mining Software Repositories, MSR ’19, Montreal, Canada,
2019.
[3]
CloudLab. The CloudLab website, 2023. url: http://www.
cloudlab.us/.
[4]
R. Dyer, H. A. Nguyen, H. Rajan, and T. N. Nguyen. Boa: a
language and infrastructure for analyzing ultra-large-scale
software repositories. In Proceedings of the 35th International
Conference on Software Engineering, ICSE ’13, pages 422–431,
2013. doi: 10.1109/ICSE.2013.6606588.
[5]
R. Dyer, H. A. Nguyen, H. Rajan, and T. N. Nguyen. Boa:
ultra-large-scale software repository and source-code min-
ing. ACM Transactions on Software Engineering and Method-
ology, 25(1):7:1–7:34, 2015.
[6]
G. Gousios. The GHTorrent dataset and tool suite. In Pro-
ceedings of the 10th Working Conference on Mining Software
Repositories, MSR ’13, pages 233–236, San Francisco, CA,
USA. IEEE Press, 2013.
[7]
G. Gousios and D. Spinellis. GHTorrent: GitHub’s data from
a firehose. In Proceedings of the 9th Working Conference on
Mining Software Repositories, MSR, pages 12–21. IEEE, 2012.
[8]
A. M. Keshk and R. Dyer. Method chaining redux: an empir-
ical study of method chaining in Java, Kotlin, and Python.
In Proceedings of the 20th International Conference on Mining
Software Repositories, MSR ’23’, pages 546–557, Melbourne,
Australia, 2023.
[9]
E. Linstead, S. Bajracharya, T. Ngo, P. Rigor, C. Lopes, and
P. Baldi. Sourcerer: mining and searching internet-scale soft-
ware repositories. Data Mining and Knowledge Discovery,
18(2):300–336, Apr. 2009. issn: 1573-756X. doi: 10 . 1007/
s10618-008-0118-x.
[10]
T. Nakamaru, T. Matsunaga, T. Yamazaki, S. Akiyama, and
S. Chiba. An empirical study of method chaining in Java. In
Proceedings of the 17th International Conference on Mining
Software Repositories, MSR ’20, pages 93–102, Seoul, Republic
of Korea. Association for Computing Machinery, 2020. isbn:
9781450375177. doi: 10.1145/3379597.3387441.
[11]
H. Rajan, T. N. Nguyen, R. Dyer, and H. A. Nguyen. Boa
website, 2024. url: http://boa.cs.iastate.edu/boa/.
[12]
A. W. Services. AWS global infrastructure, 2023. url: https:
//aws.amazon.com/about-aws/global-infrastructure.
[13]
D. Spadini, M. Aniche, and A. Bacchelli. PyDriller: Python
framework for mining software repositories. In Proceedings
of the 26th ACM Joint Meeting on European Software Engineer-
ing Conference and Symposium on the Foundations of Software
Engineering, ESEC/FSE ’18, pages 908–911, New York, NY,
USA. ACM, 2018. doi: 10.1145/3236024.3264598.
"
"This research paper introduces FEDRKG, a novel federated recommendation framework that employs Graph Neural Networks (GNN) and incorporates a knowledge graph (KG) to enhance recommendation algorithms. The key insight is to construct higher-order user-item interactions through the relationships in the KG, while preserving user privacy. FEDRKG enables effective recommendation without the need for private user data exchange or costly homomorphic encryption.nan","Federated Learning (FL) has emerged as a promising approach to address the privacy concerns associated with centralized recommendation systems. However, existing FL-based recommendation methods often suffer from limited modeling capabilities and privacy issues. This paper proposes FEDRKG, a novel GNN-based federated learning framework that leverages public item information to enhance recommendation accuracy while protecting user privacy.nan","nanRelevant research works are reviewed in three categories: knowledge graph-based recommendation, federated learning for recommendation systems, and privacy-preserving techniques in federated learning.nan","FEDRKG constructs a global knowledge graph using publicly available item information and distributes KG subgraphs to clients to improve local training. It utilizes a relation-aware GNN model with local differential privacy (LDP) for interaction items and gradients, ensuring privacy preservation during communication with the server.nan","Extensive experiments on three real-world datasets demonstrate the effectiveness of FEDRKG in terms of recommendation accuracy and privacy protection. It outperforms centralized algorithms and existing federated learning baselines, achieving competitive results while preserving user privacy.nan",FEDRKG offers a promising approach for privacy-preserving federated recommendation tasks. It effectively utilizes public item information to enhance recommendation quality and employs various privacy-preserving techniques to protect user data. The proposed framework has the potential to improve the accuracy and privacy of federated recommendation systems.nan,FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement,"Dezhong Yao, Tongtong Liu, Qi Cao, Hai Jin","FEDRKG: A Privacy-preserving Federated
Recommendation Framework via Knowledge Graph
Enhancement
Dezhong Yao1
Tongtong Liu1
Qi Cao2
Hai Jin1
1Huazhong University of Science and Technology
2University of Glasgow
{dyao,tliu,hjin}@hust.edu.cn
qi.cao@glasgow.ac.uk
Abstract
Federated Learning (FL) has emerged as a promising approach for preserving
data privacy in recommendation systems by training models locally. Recently,
Graph Neural Networks (GNN) have gained popularity in recommendation tasks
due to their ability to capture high-order interactions between users and items.
However, privacy concerns prevent the global sharing of the entire user-item graph.
To address this limitation, some methods create pseudo-interacted items or users in
the graph to compensate for missing information for each client. Unfortunately,
these methods introduce random noise and raise privacy concerns. In this paper,
we propose FEDRKG, a novel federated recommendation system, where a global
knowledge graph (KG) is constructed and maintained on the server using publicly
available item information, enabling higher-order user-item interactions. On the
client side, a relation-aware GNN model leverages diverse KG relationships. To
protect local interaction items and obscure gradients, we employ pseudo-labeling
and Local Differential Privacy (LDP). Extensive experiments conducted on three
real-world datasets demonstrate the competitive performance of our approach
compared to centralized algorithms while ensuring privacy preservation. Moreover,
FEDRKG achieves an average accuracy improvement of 4% compared to existing
federated learning baselines.
1
Introduction
Recommendation systems are widely used in various domains, such as e-commerce and social
recommendation, by alleviating users from the burden of sifting through vast amounts of data to
discover suitable options [1]. These systems utilize user preferences and relevant information to
provide personalized recommendations, making the process of finding relevant items more efficient
and convenient [2]. However, the effectiveness of most recommendation methods heavily relies on
centralized storage of user data [3]. User data generated from software usage has the potential to
enhance user experiences, deliver personalized services, and provide insights into user behavior [4].
Nevertheless, user data inherently includes user preferences and involves personal privacy. With the
increasing awareness of privacy and the implementation of relevant regulations such as the General
Data Protection Regulation (GDPR) [5], service providers may face growing challenges in centrally
storing and processing user data, as shown in Fig. 1(a).
The exclusive client access to local data leads to two challenges. Firstly, limited access to first-
order interaction data hampers the effectiveness of the recommendation model. Secondly, privacy-
preserving mechanisms are required to ensure secure communication between the client and server.
To address these challenges, FL is introduced into the recommendation system. Existing works focus
on the case of Fig. 1(b), where recommendations are achieved by directly finding correlations between
Preprint. Under review.
arXiv:2401.11089v1  [cs.CR]  20 Jan 2024
(a) Centralized Learning
server
user
client
item
attribute
user-item interaction
user-user interaction
knowledge graph
server
user
client
item
attribute
user-item interaction
user-user interaction
knowledge graph
(b)  Federated learning through user relevancy 
(c)   Federated learning through item relevancy
Figure 1: Comparison of centralized learning, federated learning with enhanced user connections,
and federated learning with enhanced project connections.
users. For example, FedMF [6] and FedGNN [7] use only the local user-item interaction graph to
find links between different users by collaborative filtering (CF). However, incorporating various
types of information in the conventional graph recommendation task can significantly improve the
recommendation accuracy while changing the graph structure [4]. Additionally, FeSoG [8] utilizes
social networks as side information, adding direct connections between different users. Nevertheless,
this method requires the server to possess the complete social network, which is a type of private data
that is difficult to obtain for most recommendation systems. Furthermore, methods like FedGNN
employ homomorphic encryption, which incurs substantial computational overhead and is not suitable
as the primary encryption algorithm on edge devices with performance constraints.
To maximize the utilization of diverse data types while ensuring privacy protection on edge devices,
we propose FEDRKG1, a GNN-based federated learning recommendation framework. Unlike CF
or direct construction of connections between users using privacy-sensitive information, FEDRKG
leverages publicly available item information (e.g., appearance, attributes) to establish higher-order
connections between different items, as shown in Fig. 1(c).
The server firstly constructs and maintains knowledge graphs (KGs) by utilizing publicly available
item information. Then, we employ on-demand sampling of KGs and distribute them to the client.
Subsequently, we design a novel method to expand the local graph by merging KG subgraphs with
the local user-item interaction graph, enabling the construction of high-order user-item interactions
through KGs. Additionally, our framework introduces a request-based distribution mechanism. By
obfuscating interaction items into request items, the server can efficiently distribute only the necessary
request embeddings, significantly reducing communication overhead compared to previous methods
while effectively protecting the privacy of raw interaction items. Simultaneously, we employ local
differential privacy (LDP) to protect all uploaded gradients, further enhancing the privacy of the
federated learning process. Our approach has been extensively evaluated on three real-world datasets,
demonstrating its competitive performance compared to centralized algorithms while ensuring privacy
preservation. Moreover, FEDRKG outperforms existing federated learning baselines, achieving an
average accuracy improvement of approximately 4%. The major contributions of this work are
summarized as follows:
• To the best of our knowledge, we are the first to introduce a knowledge graph to enhance the
performance of the federated recommendation system while protecting privacy.
• We introduce an algorithm for user-item graph expansion using KG subgraphs to improve
local training.
• We propose innovative privacy-preserving techniques for interaction items, while simultane-
ously reducing communication overhead through strategic distribution of embeddings.
1The source code is available at: https://github.com/ttliu98/FedRKG
2
2
Related Work
2.1
Knowledge Graph Based Recommendation
In recent years, significant research has focused on recommendation systems that utilize Graph Neural
Networks (GNNs). GNNs have gained attention and popularity in recommendation systems due to
their ability to learn representations of graph-structured data, which is well-suited for the inherent
graph structures in recommendation systems. Knowledge graphs, as a typical graph structure, are
often leveraged as side information in recommendation systems. By incorporating knowledge graphs,
high-order connections can be established through the relationships between items and their attributes.
This integration enhances the accuracy of item representations and provides interpretability to the
recommendation results. One type of method is integrating user-item interactions into KG. Methods
like KGAT [1], CKAN [9], and MKGAT [10] treat users as entities within KG, and relationships
between users and items are incorporated as part of KG’s relationships, too. This integration enables
the merged graph to be processed using a generic GNN model designed for knowledge graphs.
Another idea is employed by KGCN [11] and KGNN-LS [12], directly connecting KG to the user-
item graph without any transformation. These methods utilize relation-aware aggregation and consider
the user’s preference for relationships when generating recommendations.
2.2
Federated Learning for Recommendation System
Federated learning is extensively utilized in privacy-preserving scenarios, as it ensures that the
original data remains on local devices while allowing multiple clients to train a model together [13].
Considering the information required for recommendations, which includes users’ preferences for
items, the introduction of federated learning can help us prevent privacy breaches. FedSage [14]
and FKGE [15] focus on cross-silo federation learning, they are not suitable for protecting the
privacy of individual users on client devices. FCF [16] and FedMF [6] decompose the scoring matrix,
retain user embeddings locally, and aggregate item embeddings on the server. FedGNN [7] utilizes
homomorphic encryption for CF and protects the original gradients using pseudo-labeling and LDP.
However, the computational requirements for homomorphic encryption pose challenges, particularly
on performance-constrained devices. In contrast to methods that do not leverage any side information,
FeSoG [8] introduces social networks to establish connections between users. Unfortunately, in many
recommendation scenarios such as e-commerce, service providers do not offer social services, and
social network information is considered private. Therefore, the lack of user connection on the server
in Fig. 1(b), like a social network, restricts the method’s ability to generalize [17]. Currently, there is
a scarcity of federated learning algorithms that effectively utilize side information for cross-device
scenarios.
3
Federated Recommendation with Knowledge Graph Enhancement
3.1
Problem Definition
User-item interactions can be represented by a typical bipartite graph G = (U, T , E), where U =
{u1, u2, . . . , uN} and T = {t1, t2, . . . , tM} represent a set of users and items of size N and M,
respectively. To describe the set of edges E, an interaction matrix Y ∈ RM×N is employed. In
particular, yut takes on the value 1 if an interaction exists in the user’s history, and 0 otherwise.
For federated recommendation, each client ci owned by corresponding user ui can only access the
interaction graph Gi stored locally, containing a set of items Ti that have been interacted with. Each
Gi is a subgraph of the global interaction graph G.
In addition to the client-side data, the server maintains a knowledge graph K, which is represented
as a series of triples {(h, r, t) | h, t ∈ E, r ∈ R}. The entities h and t each refer to the head and
tail, respectively, within the specific combination denoted by each triple, both belonging to the set of
entities E. The relationship r represents the connection between two distinct entities, belonging to a
set of relations R.
Our goal is to train a generalized GNN model using the local bipartite graphs Gi and the knowledge
graph K while preserving user privacy. The model predicts the probability ˆyut that a user u will be
interested in an unexplored item t.
3
GNN
Predictor
Loss
Embedding
Gradients
Model
Gradients
LDP
LDP
Aggregtor
Model
Gradients
Embedding
Gradients
Update
Distribute
Distribute
Request 
Request 
𝑡𝑖,1 
𝑡𝑖,2 
𝑡𝑖,𝑛 
𝑢𝑖 
GNN
Knowledge
Graph
𝒆𝑖
𝑢 
Client i
 
 
𝒆𝑖,1
𝑝
 
𝑡𝑖,2 
𝑝𝑖,1 
𝑡𝑖,𝑛 
𝒆𝑖,2
𝑡
 
𝒆𝑖,𝑛
𝑡
 
𝒆𝑖,1
𝑒
 
𝒆𝑖,1
𝑟
 
𝒉𝑖,1
𝑝
 
𝒉𝑖,2
𝑡
 
𝒉𝑖,𝑛
𝑡
 
GNN
Predictor
Loss
Embedding
Gradients
Model
Gradients
LDP
LDP
𝑡𝑗,1 
𝑡𝑗,2 
𝑡𝑗,𝑛 
𝑢𝑗 
𝒆𝑗
𝑢 
 
 
𝒆𝑗,1
𝑝
 
𝑡𝑗,2 
𝑝𝑗,1 
𝑡𝑗,𝑛 
𝒆𝑗,2
𝑡
 
𝒆𝑗,𝑛
𝑡
 
𝒆𝑗,1
𝑒
 
𝒆𝑗,1
𝑟
 
𝒉𝑗,1
𝑝
 
𝒉𝑗,2
𝑡
 
𝒉𝑗,𝑛
𝑡
 
Client j
Figure 2: The framework of FEDRKG.
3.2
Framework Overview
To enable privacy-preserving recommendation tasks across diverse private devices, we introduce a
federated learning framework, in Fig. 2, based on the knowledge graph named FEDRKG. In the
proposed framework, the client-server architecture is adopted. The client, which is the user’s private
device, is responsible for training a local graph neural network model. The server, on the other hand,
is responsible for aggregating the models and embeddings, maintaining the knowledge graph, and
constructing higher-order connections between clients.
The entire workflow is summarized in Algorithm 1, which concisely represents the complete workflow.
3.3
Client Design
In our framework, the client plays a crucial role in two tasks. First, it is responsible for ensuring the
confidentiality of the user’s private information during the communication process with the server,
which is achieved through privacy-preserving algorithms. Second, the client utilizes the embeddings
and models provided by the server to expand the local user-item graph and train the local model.
Based on the knowledge graph shared by the server, we design a novel method to expand the
local subgraph. During the request phase, the client applies a privacy protection mechanism to
the interaction items Tn, generating obfuscated request items T ′
n. These request items are then
transmitted to the server. The client receives a GNN model and a knowledge subgraph that includes
the request items and some of their neighboring entities in the complete KG. By merging this
knowledge subgraph with local user-item interaction, the client generates a graph for local training.
This approach guarantees the privacy of the user’s interaction records by never disclosing them to
the server, while also allowing the client to obtain more item-related information for training, thus
indirectly enabling the construction of higher-order connections through knowledge subgraph.
Once the aggregated global model is received, the client proceeds to update its local model and
initiates a training process. We use a relation-aware GNN as a recommendation model [18] that
conforms to the message-passing paradigm [13], as shown in Fig. 3. For a given user u, entity ei, ej,
and ri,j as the relation between two entities, we follow node-wise computation at step t+1:
x(t+1)
i
= ϕ

x(t)
i , ρ
n
m(t+1)
ri,j
: (u, ej, ru,v) ∈ E
o
(1)
where xt
i ∈ Rd is embedding of entity ei in step t. We utilize a simple summation operation as the
reduce function ρ and directly replace the original embeddings with the aggregated results as the
4
Algorithm 1: FEDRKG
Input: Neighbor sampling size K; embedding size d; depth of receptive field H; learning rate η;
client number N; item number M; pseudo items p; (0, 1) flipping q;LDP parameter δ, λ;
knowledge graph K; clients local graph
n
Gn|N
n=1
o
Output: GNN parameters and KG embeddings θ,user embeddings
n
e∗
u|N
n=1
o
1 Initialize θ, K,
n
e∗
u|N
n=1
o
;
2 while FEDRKG not converged do
3
Randomly select a subset N from N randomly;
4
// client
5
for each client n ∈ N do
6
T ′
n ← GenerateRequestItems(Gn, p, q);
7
θ, Gn ← Request(T ′
n)
8
gn ← LocalTrain(θ, Gn)
9
˜gn ←LDP(gn)
10
Upload(˜gn)
11
end
12
// server
13
for each client n ∈ N do
14
T ′
n ←ReceiveRequest()
15
Gn ← GetSubKG(T ′
n)
16
Distribute(θ, Gn)
17
˜gn ←ReceiveGrad()
18
end
19
g ←Eq.(5)
20
θ ←Eq.(6)
21 end
reduce function, denoted as ϕ. ej sends a relationship-aware message mri,j to its neighbor:
mri,j = αu
ri,jxj
(2)
where the attention score αu
ri,j between user u and relation ri,j is derived from the following formula:
su
rt,i = score(eu, ert,i)
(3)
Att(eu, ei) = αu
rt,i =
exp

su
rt,i

P
i′∈N (t) exp

surt,i′

(4)
We calculate an attention score using a score function (e.g. inner product) and then normalize it.
After obtaining the final embedding xt of item t, we calculate the prediction ˆy by a readout function
and then train this GNN model using BCE as the loss function. Finally, client uploads encrypted
gradient to server.
3.4
Server Design
Similar to clients, the server performs distinct tasks that are mainly distributed across two phases.
Firstly, the server’s primary responsibility is to respond to the client’s requests. Based on the
requested items, the server utilizes the knowledge graph to sample a subgraph that corresponds to
a specific client. The subgraph comprises two key components, namely the structural information
in the form of triples, and the feature information, represented by the embedding of entities and
relations. Subsequently, the server shares the subgraph, together with the global model, with the
client. Secondly, the server needs to receive all gradients of local models and embeddings uploaded
by clients. These gradients are then aggregated and used to update the global model and knowledge
graph.
5


𝑦  
Subgraph from sever
user-item 
interaction


item embedding
relation embedding
entity embedding
dot product
sum
𝐞𝑢  
𝐞𝑡  
𝑨𝒕𝒕 𝐞𝑢, 𝐞𝑖 →  𝜶𝑟𝑡,𝑖 ⊗   
𝐞𝑢  
𝐞𝑘  

𝑨𝒕𝒕 𝐞𝑢, 𝐞𝑘 →  𝜶𝑟𝑡,𝑘 ⊗   

user embedding
relation
Figure 3: Relation-aware aggregation in client.
In each communication round, the server activates N clients. After receiving request items from
those clients, server randomly samples a set of neighbors, denoted as S(t) ≜ {e|e ∼ N(t)}, for
the request item t. Here, |S(v)| = K represents the fixed size when sampling, and N(t) represents
immediate neighbors for item t. In our framework, S(v) is also referred to as the (single-layer)
receptive field of item t. Repeat the above sampling several times to obtain Gi containing n iterations
and then distribute it to the client along with the parameters θ, consisting of the model parameters
θm and all embeddings of entities and relations in Gi denoted by θe. Finally, it receives the local
gradients ˜gi of these clients and aggregates them as follow:
g =
P
n∈N |T ′
n| · ˜gn
P
n∈N |T ′n|
(5)
After aggregation, the server updates all parameters θ with gradient descent as:
θ∗ = θ − η · ¯g
(6)
where η is the learning rate.
3.5
Privacy-Preserving Communication
3.5.1
User privacy
Within our proposed framework, user-related privacy pertains primarily to user embedding. Tra-
ditional embedding-based recommendation algorithms can derive both user and item embeddings
and generate user-specific recommendations through a straightforward readout operation. However,
user embeddings comprise the user’s preference characteristics, which can lead to a compromise of
their privacy. In the federated learning scenario where the server does not have access to the raw
data, to avoid exposing user preferences directly to the server, it is obvious that we need to keep
the user embeddings on the client side and isolate them from the server. Clients can simply protect
user-related privacy by refraining from uploading user embeddings after the training phase.
3.5.2
Interaction privacy
The interaction between users and items is considered highly sensitive information, susceptible to
potential leaks during two stages. Firstly, due to the large size of the knowledge graph for items and
limited transmission bandwidth, it is not practical to distribute all embeddings to client similar to
FedGNN and FedSoG. Instead, we aim to complete the entire training process through the limited
distribution of embeddings. However, this presents a challenge in determining which embeddings
should be distributed by the server. Server can not explicitly obtain the required embeddings, as this
would mean that it has access to the client’s real interaction item. Therefore, we need to obfuscate
6
the original interaction items to obtain encrypted request items, which can then be sent to the server
to sample the corresponding subgraph required for training.
We have designed a local differential privacy(LDP) mechanism to generate request items from
the interaction items. Specifically, user-item interaction for user u can be represented as a set
{(ti, yui) | yui ∈ {0, 1}, i = 1, 2, . . . , n}. This collection contains |T | elements, each of which is
a binary, the first of which is an item and the second is either 0 or 1, indicating whether the user
interacted with the item. Let the query for the ti be yui, then the interaction can be privacy-preserving
using an ϵ-LDP algorithm. The privacy budget ϵ indicates the maximum acceptable loss of privacy.
Let the interaction for each item satisfy ϵ-LDP, and we have: for any item, keep the original interaction
value with probability
eϵ
eϵ+1 and invert it to another value with
1
eϵ+1 (0,1 flipping).
A potential privacy concern with the widely used pseudo-labeling method in previous work is that
the interacted item will always generate gradients, even if pseudo-labeling is used. Additionally, the
pseudo-labeling method applied during the training phase does not effectively reduce the commu-
nication overhead associated with distributing embeddings. To address this issue, we first sample
several non-interactive samples, mix them with real interaction items, and further obfuscate them by
the above LDP method to achieve privacy protection.
3.5.3
Gradients privacy
Ensuring the privacy of users’ sensitive information is a critical concern when maintaining a knowl-
edge graph and updating the global model in a federated recommendation system. In each communi-
cation round, the server needs to aggregate gradients of entity embeddings, relational embeddings,
and GNN models from different clients. However, it has been demonstrated, as exemplified by
FedMF, that uploading users’ gradients in consecutive steps can lead to the inadvertent exposure
of sensitive data, such as users’ ratings. Therefore, we need to obfuscate gradients to protect user
privacy. However clients of recommendation systems, such as mobile devices, often have limited
computational capabilities [19], and computationally intensive methods like homomorphic encryption
may not be practical to implement on such devices. To tackle this, we employ LDP by injecting
random noise into the local gradients before uploading them to the server. This approach effectively
protects row gradients without compromising the accuracy of the model. Moreover, it helps ensure
that the computational overhead remains manageable and within acceptable limits.
To be more specific, gives all gradients as gn = {ge
n, gm
n } = ∂Ln
∂θ , where Ln denotes loss of client n,
the LDP is formulated as:
˜gn = clip (gn, δ) + Laplacian (0, λ)
(7)
where ˜gn is the encrypted gradient, clip(x, δ) denotes the gradient clipping operation with a threshold
δ to limit x and prevent the gradient from being too large, after which we add to the gradient a mean
value of 0 and an intensity of λ of Laplacian noise, denoted by Laplacian (0, λ). This results in a
ϵ-LDP, where the privacy budget ϵ is 2δ
λ .
4
Experiment
4.1
Datasets
In order to ensure the robustness of the algorithm, we aim to test the overall performance of the
framework on a variety of datasets with different sizes, sparsity, and domains. Therefore, we have
selected the following real-world datasets:
• MovieLens-20M [20] contains five-star ratings from MovieLens, a movie recommendation
service, as of 2019. Each user in the dataset has provided a minimum of 20 ratings (ranging
from 1 to 5) on the MovieLens website.
• Book-Crossing [21] contains user ratings (ranging from 0 to 10) of books extracted from
the Book-Crossing community in 2004. In this dataset, a rating of 0 indicates an implicit
interaction between the user and the book.
7
Table 1: Dataset basic information and hyperparameters, notation is consistent with Algorithm 1.
MovieLens-20M
Book-Crossing
Last.FM
users
138,159
19,676
1,872
items
16,954
20,003
3,846
interactions
13,501,622
172,576
42,346
entities
102,569
25,787
9,366
relations
32
18
60
KG triples
499,474
60,787
15,518
K
4
8
8
d
32
64
16
H
2
1
1
λ
10−7
2 × 10−5
10−4
η
2 × 10−2
2 × 10−4
5 × 10−4
N
32768
64
32
• Last.FM [22] contains musician listening recodes from the Last.FM music streaming service.
We consider artists as items and the number of listens as ratings. In particular, we utilize the
HetRec 2011 version in our study.
To adapt the dataset for the recommendation task in a federated learning environment, several steps
are taken. Firstly, only the user-item interactions are retained from the original dataset, while other
data are discarded. Then, the publicly available Microsoft Satori is utilized to create a knowledge
graph by selecting triples with a confidence level greater than 0.9, where the tail corresponds to items
in the dataset. Interactions, where the item is not present in the knowledge graph, are subsequently
removed. Next, these three datasets are transformed into implicit feedback. We consider all artists
listened to in Last.FM, all books with ratings present in book-cross, and all movies with ratings
greater than or equal to 4 stars in MovieLens, as positive feedback. Conversely, items not meeting
these criteria are treated as negative feedback. Lastly, since the original recommendation dataset
already contains user information, each user’s data is assigned to the corresponding client to generate
a federated learning dataset. Details of the dataset are shown in Table 1
4.2
Baselines
We compare the proposed FEDRKG with the following baselines, in which the first two baselines
are KG-free while the rest are all KG-aware methods. Hyper-parameter settings for baselines are
introduced in the next subsection.
• SVD [23] is a classical CF recommendation algorithm based on matrix decomposition. Here
we use an unbiased version.
• LibFM [24] is a method based on Factorization Machines that captures the similarity
between features
• PER [25] is an algorithm based on a personalized attention mechanism and constructs a
Meta-path between users and items through a heterogeneous graph (KG).
• CKE [26] is a knowledge graph-based collaborative embedding recommendation algorithm
that combines data from CF and other modalities.
• RippleNet [27] is a memory-network-like approach that simulates and exploits the ripple
effect between users and items to propagate information on the knowledge graph
• KGCN [11] is a KG-based method, that achieves efficient recommendations by merging
KG and CF data.
• FedMF [6] is a recommendation algorithm based on matrix decomposition while protecting
privacy through an encryption mechanism.
• FedGNN [7] is a GNN-based recommendation algorithm that uses homomorphic encryption
for aggregation and protects the original gradient by differential privacy and pseudo-labeling.
8
Table 2: Results for CRT prediction. KGCN achieves the best AUC among the first five centralized
learning methods. Our method performs best in the next three federal learning methods, while the
gap with KGCN is acceptable.
Model
MovieLens-20M
Book-Crossing
Last.FM
AUC
F1
AUC
F1
AUC
F1
SVD
0.952(±0.013)
0.909(±0.014)
0.665(±0.058)
0.628(±0.051)
0.760(±0.026)
0.688(±0.022)
LibFM
0.960(±0.018)
0.907(±0.024)
0.692(±0.046)
0.619(±0.063)
0.779(±0.019)
0.711(±0.011)
PER
0.824(±0.119)
0.780(±0.121)
0.611(±0.101)
0.557(±0.100)
0.627(±0.125)
0.593(±0.107)
CKE
0.918(±0.050)
0.866(±0.056)
0.673(±0.057)
0.607(±0.055)
0.739(±0.044)
0.669(±0.046)
RippleNet
0.964(±0.010)
0.909(±0.020)
0.712(±0.023)
0.648(±0.032)
0.777(±0.016)
0.699(±0.015)
KGCN
0.978(±0.002)
0.932(±0.001)
0.738(±0.003)
0.688(±0.006)
0.794(±0.002)
0.719(±0.003)
FedMF
0.865(±0.012)
0.852(±0.015)
0.657(±0.039)
0.605(±0.060)
0.720(±0.018)
0.660(±0.013)
FedGNN
0.939(±0.011)
0.891(±0.021)
0.671(±0.024)
0.620(±0.037)
0.753(±0.014)
0.681(±0.028)
FEDRKG
0.970(±0.002)
0.919(±0.002)
0.724(±0.004)
0.667(±0.006)
0.785(±0.004)
0.708(±0.002)
4.3
Experimental Settings
Table 2 shows the hyperparameter for the experiments. We split the datasets into training, validation,
and testing sets in a 6:2:2 ratio. AUC and F1 scores are used as evaluation metrics for click-through
rate (CTR) prediction.
For the Last.FM, Book-Crossing, and MovieLens-20M datasets, the SVD method is applied with
imensions (8, 8, 8) and learning rates (0.1, 0.5, 0.5). For LibFM, the dimensions are (8, 1, 1). PER
utilizes the user-item-attribute-item meta-path, with dimensions (64, 128, 64) and learning rates
(0.1, 0.5, 0.5). The learning rates for KG in CKE are (0.1, 0.1, 0.1), while the dimensions are
(16, 4, 8) and the H values are (3, 3, 2). RippleNet’s dimensions are (16, 4, 8), H values are (3, 3, 2),
learning rates are (0.005, 0.001, 0.01), regularization parameters λ1 are (10−5, 10−5, 10−6), and λ2
are (0.02, 0.01, 0.01). Other hyperparameters remain the same as in the original papers, and the
federated learning settings are consistent with this paper.
4.4
Overall Comparison
We conduct a comprehensive comparison of multiple models under various settings. Given the
dataset’s specific characteristics, only including knowledge graphs and user-item graphs, many
federated learning algorithms simplify to FedGNN in this dataset. Therefore, we select FedGNN
and FedMF as the baseline methods, representing GNN and matrix decomposition approaches in
federated learning. The experimental results for CTR prediction are presented in Table 2, while Fig. 4
illustrates the outcomes of top-k recommendation. Based on those results, we draw the following
conclusions:
• On the one hand, GNN-based algorithms, such as KGCN and FEDRKG, outperform
matrix decomposition-based algorithms like SVD and FedMF. This is due to the superior
performance of GNNs in automatically capturing user preferences and enabling the spreading
of user or item embeddings to neighboring nodes. On the other hand, algorithms that require
manual design such as meta-paths for PER and knowledge graph embedding (KGE) method
for CKE, often underperform due to the complexity of graph data.
• The experimental results consistently demonstrate that the appropriate utilization of addi-
tional side information can significantly improve the accuracy of recommendation systems.
For example, KGCN and RippleNet outperform other centralized algorithms regarding both
AUC and F1 metrics, while FEDRKG, as a knowledge graph-based algorithm, performs
best in federated learning. However, it should be noted that not all methods that leverage
side information deliver satisfactory outcomes. This holds true for methods like PER and
CKE, which encounter difficulties in effectively harnessing side information.
• Knowledge graphs are well-suited for integration into recommendation systems as side
information, especially using GNNs, given their inherent graph structure and the ability to
combine multi-domain knowledge. Algorithms incorporating relation-aware aggregation,
such as KGCN and FEDRKG, achieve the best performance in their respective settings,
confirming the effectiveness of introducing relational attention mechanisms.
9
Overall, our framework outperforms existing federated learning algorithms and achieves competitive
performance compared to centralized algorithms.
(a) MovieLens-20M
(b) Book-Crossing
(c) Last.FM
Figure 4: Results for top-K recommendation. The dashed line represents centralized learning,
while the solid line represents federated learning. Our method surpasses all federated baselines and,
furthermore, achieves competitive results compared to centralized learning.
4.5
Sensitivity Analysis
4.5.1
Activated client number
In general, a smaller number of activated clients in each training round will speed up the model
convergence and conversely better capture the global user data distribution. We test the algorithm
on three datasets with three different numbers of activation clients, and the results are shown in the
figure above. Probably due to the sparse data and a large number of clients, a small adjustment has a
limited impact on the final results and the Last.FM and Book-Crossing datasets both show a small
decrease in AUC when 64 clients are activated.
4.5.2
Receptive field depth
By testing different receptive field depths, we note that an excessive receptive field reduces model
prediction accuracy. As data sparsity decreases, better performance needs a larger receptive field,
while a one-layer perceptual region is sufficient to achieve better performance on those sparse data
sets.
Figure 5: Sensitivity analysis of activated clients and receptive field depth.
4.5.3
Interaction item protection
We introduce new interaction record protection and assess diverse flipping rates, with corresponding
results depicted in Fig. 6. Generally, integrating privacy-preserving mechanisms often diminishes
recommendation accuracy. However given limited client-side graph data, our scenario tends to induce
model overfitting. Hence, proper regularization effectively enhances recommendation accuracy
10
Figure 6: Effect of flipping rate on AUC.
and privacy protection. Notably, excessive flip rates can compromise system performance despite
heightened privacy. Our experiments indicate a balance between accuracy and privacy at a flipping
rate of 0.1.
5
Conclusion
This paper introduces a novel federated learning framework, FEDRKG, which employs GNN for
recommendation tasks. Our approach integrates KG information while upholding user privacy. The
limitation here is the absence of user connections, and our forthcoming focus is on improving the
efficiency and interpretability of utilizing existing user connections without introducing new private
data. Specifically, a server-side KG is created from public item data, maintaining relevant embeddings.
The client conceals local interaction items and requests server training data. The server samples
a KG subgraph and distributes it with the GNN model to the client. The client then expands its
user-item graph with the KG subgraph for training, uploading the gradient for server aggregation.
Our framework creates higher-order interactions without extra privacy data, relying solely on public
information for KG. Sampled KG subgraphs enhance local training by capturing interactions between
users and items without direct links. We employ LDP and pseudo-labeling to protect privacy and
reduce overhead by requesting partial data. Gradients are encrypted using LDP for user preference
protection and local user embedding storage. Experimental results on three datasets demonstrate our
framework’s superiority over SOTA federated learning recommendation methods. It also performs
competitively against centralized algorithms while preserving privacy.
5.0.1
Acknowledgements
This work is supported by the National Key Research and Development Program of China under
Grant No.2021YFB1714600 and the National Natural Science Foundation of China under Grant
No.62072204 and No.62032008. The computation is completed in the HPC Platform of Huazhong
University of Science and Technology and supported by the National Supercomputing Center in
Zhengzhou.
References
[1] Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. Kgat: Knowledge graph
attention network for recommendation. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, KDD, pages 950–958, 2019.
[2] Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, and Qing He. A
survey on knowledge graph-based recommender systems. IEEE Transactions on Knowledge
and Data Engineering, 34(8):3549–3568, 2020.
[3] Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng
Wang, Changcheng Li, and Maosong Sun. Graph neural networks: A review of methods and
applications. AI Open, 1:57–81, 2020.
[4] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. Graph neural networks in recom-
mender systems: a survey. ACM Computing Surveys, 55(5):1–37, 2022.
11
[5] Paul Voigt and Axel Von dem Bussche. The EU general data protection regulation (GDPR).
A Practical Guide, 1st Ed., Cham: Springer International Publishing, 10(3152676):10–5555,
2017.
[6] Di Chai, Leye Wang, Kai Chen, and Qiang Yang. Secure federated matrix factorization. IEEE
Intelligent Systems, 36(5):11–20, 2020.
[7] Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, and Xing Xie. FedGNN: Federated
graph neural network for privacy-preserving recommendation. arXiv preprint arXiv:2102.04925,
2021.
[8] Zhiwei Liu, Liangwei Yang, Ziwei Fan, Hao Peng, and Philip S Yu. Federated social recommen-
dation with graph neural network. ACM Transactions on Intelligent Systems and Technology,
13(4):1–24, 2022.
[9] Ze Wang, Guangyan Lin, Huobin Tan, Qinghong Chen, and Xiyang Liu. Ckan: collaborative
knowledge-aware attentive network for recommender systems. In Proceedings of the 43rd
International ACM SIGIR Conference on Research and Development in Information Retrieval,
SIGIR, pages 219–228, 2020.
[10] Rui Sun, Xuezhi Cao, Yan Zhao, Junchen Wan, Kun Zhou, Fuzheng Zhang, Zhongyuan Wang,
and Kai Zheng. Multi-modal knowledge graphs for recommender systems. In Proceedings
of the 29th ACM International Conference on Information & Knowledge Managemen, CIKM,
pages 1405–1414, 2020.
[11] Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, and Minyi Guo. Knowledge graph convolu-
tional networks for recommender systems. In Proceedings of the World Wide Web Conference,
WWW, pages 3307–3313, 2019.
[12] Hongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec, Miao Zhao, Wenjie Li, and
Zhongyuan Wang. Knowledge-aware graph neural networks with label smoothness regular-
ization for recommender systems. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, KDD, pages 968–977, 2019.
[13] Hai Jin, Dongshan Bai, Dezhong Yao, Yutong Dai, Lin Gu, Chen Yu, and Lichao Sun. Personal-
ized edge intelligence via federated self-knowledge distillation. IEEE Transactions on Parallel
and Distributed Systems, 34(2):567–580, 2023.
[14] Ke Zhang, Carl Yang, Xiaoxiao Li, Lichao Sun, and Siu Ming Yiu. Subgraph federated
learning with missing neighbor generation. In Proceedings of the Annual Conference on Neural
Information Processing Systems, NeurIPS, volume 34, pages 6671–6682, 2021.
[15] Hao Peng, Haoran Li, Yangqiu Song, Vincent Zheng, and Jianxin Li. Differentially private fed-
erated knowledge graphs embedding. In Proceedings of the 30th ACM International Conference
on Information & Knowledge Management, CIKM, pages 1416–1425, 2021.
[16] Muhammad Ammad-Ud-Din, Elena Ivannikova, Suleiman A Khan, Were Oyomno, Qiang Fu,
Kuan Eeik Tan, and Adrian Flanagan. Federated collaborative filtering for privacy-preserving
personalized recommendation system. arXiv preprint arXiv:1901.09888, 2019.
[17] Guoren Wang, Yue Zeng, Rong-Hua Li, Hongchao Qin, Xuanhua Shi, Yubin Xia, Xuequn
Shang, and Liang Hong. Temporal graph cube. IEEE Transactions on Knowledge and Data
Engineering, pages 1–15, 2023.
[18] Wenming Cao, Canta Zheng, Zhiyue Yan, and Weixin Xie. Geometric deep learning: progress,
applications and challenges. Science China Information Sciences, 65(2):126101, 2022.
[19] Yuanyishu Tian, Yao Wan, Lingjuan Lyu, Dezhong Yao, Hai Jin, and Lichao Sun. FedBERT:
When federated learning meets pre-training. ACM Transactions on Intelligent Systems and
Technology, 13(4):1–26, 2022.
[20] F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. ACM
Transactions on Interactive Intelligent Systems, 5(4):19:1–19:19, 2016.
[21] Cai-Nicolas Ziegler, Sean M McNee, Joseph A Konstan, and Georg Lausen. Improving
recommendation lists through topic diversification. In Proceedings of the World Wide Web
Conference, WWW, pages 22–32, 2005.
[22] Iván Cantador, Peter Brusilovsky, and Tsvi Kuflik. Second workshop on information hetero-
geneity and fusion in recommender systems (HetRec2011). In Proceedings of the 2011 ACM
Conference on Recommender Systems, RecSys, pages 387–388, 2011.
12
[23] Yehuda Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering
model. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD, pages 426–434, 2008.
[24] Steffen Rendle. Factorization machines with libfm. ACM Transactions on Intelligent Systems
and Technology, 3(3):1–22, 2012.
[25] Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandelwal, Brandon
Norick, and Jiawei Han. Personalized entity recommendation: A heterogeneous information
network approach. In Proceedings of the 7th ACM International Conference on Web Search
and Data Mining, WSDM, pages 283–292, 2014.
[26] Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, and Wei-Ying Ma. Collaborative
knowledge base embedding for recommender systems. In Proceedings of the 22nd ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD, pages
353–362, 2016.
[27] Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo.
Ripplenet: Propagating user preferences on the knowledge graph for recommender systems.
In Proceedings of the 27th ACM International Conference on Information and Knowledge
Management, CIKM, pages 417–426, 2018.
13
"
"Cross-Domain Facial Expression Recognition (CD-FER) faces challenges in feature representation and transferability due to the domain shift. This paper introduces a framework called Adaptive Global-Local Representation Learning and Selection (AGLRLS) to overcome these challenges. The framework consists of separate global-local adversarial learning and semantic-aware pseudo label generation. Specifically, it includes global and local adversarial learning modules that independently learn domain-invariant global and local features. There's also a pseudo label generation mechanism that assigns pseudo class labels to unlabeled data features, preventing mutual interference among classifiers. In the training process, separate classifier learning is performed by optimizing the model with the adversarial learning process using these labels, aiding in the learning of more discriminative features for the target dataset. During inference, a global-local prediction consistency strategy is used to infer the optimal class label by combining the prediction scores from the global and local classifiers. Comprehensive experiments demonstrate the superiority of AGLRLS in CD-FER.nan","CD-FER aims to automatically determine a person's emotional state from a facial image, regardless of the domain. It's challenging due to variations in different datasets and large discrepancy among FER datasets, resulting in domain shift. In recent years, significant efforts have been devoted to domain adaptation models for CD-FER. However, these models primarily focused on holistic features for domain adaptation, overlooking the potential benefits of local features, like greater transferability and fine-grained representation of variations. Previous research combined graph representation propagation with adversarial learning to reduce domain shift, while others incorporated semantic information into the multi-view features learning to bridge the semantic gap. Despite these advances, the significant problem of imbalanced class distribution was largely overlooked, leading to suboptimal performance.nan","nanA series of CD-FER methods has been proposed to address data bias among different FER datasets. These methods utilize subspace learning, metric learning, dictionary learning, contrastive learning, and other techniques to facilitate unsupervised CD-FER. Recent years have seen the emergence of domain adaptation models that employ adversarial learning mechanisms to mitigate domain shift. Inspired by generative adversarial networks, these methods use a feature extractor and a domain discriminator to learn transferable domain-invariant features through a two-player game. The feature extractor learns the features, while the domain discriminator struggles to distinguish samples from the target dataset. Several methods have achieved state-of-the-art performance on FER benchmark datasets. However, they tend to focus on holistic features for adaptation, neglecting the potential advantages of local features in addressing the domain shift and improving discriminability.nan","The proposed AGLRLS framework comprises separate global-local adversarial learning and semantic-aware pseudo label generation. It integrates global and local adversarial learning modules that independently learn domain-invariant global and local features. Furthermore, a feature-level pseudo label generation mechanism is designed to assign reliable pseudo labels to each global and local feature of unlabeled data. These labels are utilized for model optimization through the adversarial learning process, enhancing the learned features' generalization and representation capacities. During inference, a global-local prediction consistency strategy is devised to refine recognition results by combining the prediction scores from the global and local classifiers. The framework effectively mitigates domain shift and amplifies the discriminative power in the target domain.nan","Extensive experiments are conducted to evaluate the effectiveness of AGLRLS against state-of-the-art CD-FER methods. The results demonstrate that AGLRLS consistently outperforms competing algorithms across various configurations and datasets. The analysis highlights the robustness of AGLRLS with different backbones and source domains. Statistical tests further confirm the significance of AGLRLS's performance. Ablation studies reveal the contributions of individual components, underscoring the effectiveness of the proposed global-local representation learning and selection strategy.nan","The proposed AGLRLS framework showcases superior performance in CD-FER tasks, effectively addressing the issues of data inconsistency and less discriminative ability prevalent in existing methods. It seamlessly integrates global-local adversarial learning and semantic-aware pseudo label generation to learn domain-invariant and discriminative features that generalize well across source and target datasets. In addition, the global-local prediction consistency strategy enhances the reliability of recognition results during inference. AGLRLS demonstrates state-of-the-art performance on various benchmark datasets, setting a new standard for CD-FER. The findings contribute to the development of more effective and robust facial expression recognition systems capable of handling cross-domain scenarios.nan",Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition,"Yuefang Gao, Yuhao Xie, Zeke Zexi Hu, Tianshui Chen, Liang Lin","IEEE TRANSACTIONS ON MULTIMEDIA
1
Adaptive Global-Local Representation Learning and
Selection for Cross-Domain Facial Expression
Recognition
Yuefang Gao, Yuhao Xie, Zeke Zexi Hu, Tianshui Chen, Liang Lin
Abstract—Domain shift poses a significant challenge in Cross-
Domain Facial Expression Recognition (CD-FER) due to the
distribution variation between the source and target domains.
Current algorithms mainly focus on learning domain-invariant
features through global feature adaptation, while neglecting
the transferability of local features across different domains.
Additionally, these algorithms lack discriminative supervision
during training on target datasets, resulting in deteriorated
feature representation in the target domain. To address these
limitations, we propose an Adaptive Global-Local Representation
Learning and Selection (AGLRLS) framework. The framework
incorporates global-local adversarial adaptation and semantic-
aware pseudo label generation to enhance the learning of domain-
invariant and discriminative feature representation during train-
ing. Meanwhile, a global-local prediction consistency learning
is introduced to improve classification results during inference.
Specifically, the framework consists of separate global-local
adversarial learning modules that learn domain-invariant global
and local features independently. We also design a semantic-
aware pseudo label generation module, which computes semantic
labels based on global and local features. Moreover, a novel
dynamic threshold strategy is employed to learn the optimal
thresholds by leveraging independent prediction of global and
local features, ensuring filtering out the unreliable pseudo labels
while retaining reliable ones. These labels are utilized for model
optimization through the adversarial learning process in an
end-to-end manner. During inference, a global-local prediction
consistency module is developed to automatically learn an optimal
result from multiple predictions. To validate the effectiveness
of our framework, we conduct comprehensive experiments and
analysis based on a fair evaluation benchmark. The results
demonstrate that the proposed framework outperforms the
current competing methods by a substantial margin.
Index
Terms—Domain
adaptation,
Adverserial
learning,
Pseudo label generation, Facial expression recognition
I. INTRODUCTION
Cross-Domain Facial Expression Recognition (CD-FER)
aims at automatically determining a person’s emotional state
from a face image, regardless of the domain, by transferring
the learned knowledge from labeled source data to unlabeled
This work was supported in part by National Key R&D Program of
China (Grant No. 2021ZD0111601), in part by the National Natural Science
Foundation of China (Grant No. 62206060) and Guangzhou Basic and Applied
Basic Research Foundation (Grant No. SL2022A04J01626). (Corresponding
author: Tianshui Chen)
Yuefang Gao is with South China Agricultural University, Guangzhou,
China. Yuhao Xie is with Guangzhou Institute of Technology, Xidian Uni-
versity, Guangzhou, China. Zeke Zexi Hu is with the School of Computer
Science, University of Sydney, Darlington, New South Wales, Australia.
Tianshui Chen is with Guangdong University of Technology, Guangzhou,
China. Liang Lin is with Sun Yat-Sen University, Guangzhou, China.
target data. It plays a significant role in human-computer
interaction [1], affective computing [2], intelligent driving [3],
and so forth. While conventional facial expression recognition
methods focus on a single dataset [4]–[7], CD-FER is more
challenging due to the subtle interclass variations in different
facial expression classes and the large discrepancy among FER
datasets. These variations result in evident domain shift, which
undermines models to generalize to more datasets.
In the past decade, various CD-FER methods have been
proposed and evaluated on popular FER datasets such as RAF-
DB [8], FER2013 [9], CK+ [10], JAFFE [11], SFEW2.0 [12],
and ExpW [13]. These methods aimed to address the issue of
data inconsistency between different datasets. Earlier studies
have tackled this problem through transfer learning [14] and
supervised kernel matching [15]. However, these methods re-
quire a number of annotated samples from the target domain to
ensure the discriminative information among categories, which
is not suitable for unsupervised CD-FER settings. More recent
strategies attempted to incorporate other learning techniques,
including dictionary learning [16], metric learning [17], and
contrastive learning [18], to facilitate unsupervised CD-FER.
Besides, some methods focused on generating more additional
samples to bridge the gap in feature distribution between the
source and target datasets [19], [20].
In recent years, significant efforts have been devoted to do-
main adaptation models for the CD-FER. These models aimed
to learn transferable domain-invariant features by employing
adversarial learning mechanisms [21]–[23]. By aligning the
feature distribution of the source and target domains, these
methods achieved high recognition accuracy. However, de-
spite their outstanding performance, these models primarily
focused on extracting holistic features for domain adaptation,
while overlooking the potential benefits of local features,
e.g. greater transferability across domains and a more fine-
grained representation of variations, which led to domain shift
in inappropriate adversarial learning. To address the limita-
tion, some studies [24], [25] combined graph representation
propagation with adversarial learning to reduce the domain
shift by modeling the correlation of holistic-local features
within each domain and across different domains. There were
also some works incorporating semantic information into
the multi-view features learning to bridge the semantic gap
during domain adaptation [26], [27]. These studies utilized
the category prior knowledge or imposed the global and
local semantic consistency constraints to learn semantically
discriminative features. Nevertheless, the significant problem
arXiv:2401.11085v1  [cs.CV]  20 Jan 2024
IEEE TRANSACTIONS ON MULTIMEDIA
2
of imbalanced class distribution was largely overlooked among
these methods, leading to suboptimal performance.
In this paper, we introduce an adaptive global-local repre-
sentation learning and selection model to address the issue
of data inconsistency, which adversely affects the recognition
performance in cross-domain scenarios. The proposed method
learns domain-invariant and discriminative feature represen-
tation in training by incorporating global-local adversarial
adaptation and semantic-aware pseudo label generation, fol-
lowed by a global-local prediction consistency strategy to
refine recognition results in inference. Specifically, the model
utilizes global and local adversarial learning independently
to obtain compact and discriminative domain-invariant global
and local features. Subsequently, a feature-level pseudo label
generation mechanism is introduced to assign pseudo class
labels to the features of unlabeled data, preventing mutual
interference among classifiers. The separate classifier learn-
ing is further performed by optimizing the model with the
adversarial learning process using these labels, facilitating
the learning of more discriminative features for the target
dataset. During inference, a global-local prediction consistency
strategy is designed to learn the optimal class label by joint
inference of the global and local prediction results. In this
way, our approach significantly enhances the learned features,
bolstering their generalization and representation capacities
across the source and target datasets and meanwhile amplify-
ing their discriminative power in the target domain, effectively
mitigating domain shift to facilitate the CD-FER performance.
Building upon our previous conference work [27], this
paper presents several improvements. Firstly, instead of using
a strict global-local semantic consistency constraint in the
pseudo target label generation process, we adopt an adjustable
threshold learning process to generate richer and more fine-
grained pseudo labels for all the categories of the unlabeled
faces, effectively alleviating the problem of class imbalance
caused by source domain. Secondly, a global-local prediction
consistency strategy is developed to infer the final labels of
target data by combining the prediction scores from the global
and local classifiers. This strategy mitigates the problem of
domain shift across domains and achieves competitive perfor-
mance. Finally, we conduct extensive experiments and ablation
studies using more datasets and backbones to demonstrate
the effectiveness of our method and the contribution of each
component.
The contributions of this work can be summarized as
follows: i) An Adaptive Global-Local Representation Learning
and Selection (AGLRLS) model is proposed, which incorpo-
rates separate global-local adversarial learning and semantic-
aware pseudo label generation to learn more domain-invariant
and discriminative feature representation and thus address the
domain shift and less discriminative ability issues in current
CD-FER methods. ii) A semantic-aware pseudo label genera-
tion method is designed to produce reliable pseudo labels for
each global and local feature of unlabeled data by utilizing
learned adaptive thresholds. iii) A global-local prediction con-
sistency learning is introduced that integrates global and local
prediction results to infer the optimal class label, effectively
bridging the semantic gap between source and target domains.
iv) Comprehensive experiments are conducted to compare our
proposed method with current CD-FER algorithms, demon-
strating its superior performance. Codes and trained models are
available at https://github.com/yao-papercodes/AGLRLS.
II. RELATED WORKS
Quite a lot of research works have addressed the challenging
task of cross-domain facial expression recognition. In this
section, we mainly present a few methods that are closely re-
lated to this work, namely, cross-domain FER and adversarial
domain adaptation.
A. Cross-Domain FER
To deal with the data bias among different FER datasets,
a series of CD-FER methods have been proposed [14], [17],
[19], [20], [26], [28]–[33]. Yan et al. [14] utilized subspace
learning to transfer the learned knowledge from the source data
to the unlabeled target data. However, annotating some sam-
ples from the target data is necessary for this method. To han-
dle CD-FER in unsupervised scenarios, work [29] presented
a domain adaptive dictionary learning model that unified the
unlabeled data to adaptively adjust the misaligned distribution
in an embedded space. Later on, a transductive transfer regu-
larized least-squares regression model was proposed [32] that
learned a discriminative subspace by combining the labeled
source data and unlabeled auxiliary target data to reduce the
dissimilarity of the marginal probability distribution between
domains. In [17], a discriminative metric space was learned in
a dictionary learning procedure to alleviate the influence of the
distribution inconsistency. Different from these works, Wang
et al. [19] used samples generated by Generative Adversarial
Network (GAN) on the target dataset to facilitate the CD-
FER. Another domain regenerator was designed in [20] that
regenerated source and target domain samples with the same
or similar feature distribution to guide the label prediction of
the unlabeled data.
In the recently proposed methods, Ji et al. [34] attempted
to learn a common representation of expression in different
domains through the fusion of intra-category common features
and inter-category distinction features. [35] developed a deep
emotion conditional adaptation network to learn the domain-
invariant and class discriminative feature representation. This
method aligned the marginal distribution globally and matched
the fine-grained class-conditional distribution using the under-
lying label information on target datasets that can effectively
mitigate the data bias between domains. In addition, Li et
al. [26] proposed the deep margin-sensitive representation
learning model that extracted semantically multi-level discrim-
inative and transferable features by leveraging the category
prior knowledge during domain adaptation to alleviate the
domain shift. A recent study [31] introduced an emotion-
guided similarity network that learned a transferable model
for compound expression recognition from the unseen domain
in the cross-domain few-shot learning scenario. In contrast
to the current methods, we propose an adaptive global-local
representation learning and selection method to address the
problem of data inconsistency in CD-FER.
IEEE TRANSACTIONS ON MULTIMEDIA
3
B. Adversarial Domain Adaptation
Adversarial domain adaptation methods have recently be-
come increasingly popular for cross-domain recognition due
to the advantage of the disentangled and transferable repre-
sentation learning [21], [24], [25], [27], [36]–[41]. Inspired
by the adversarial learning in generative adversarial networks,
these methods utilize a feature extractor and a domain dis-
criminator to mitigate domain shift through a two-player game
in which the feature extractor learns the transferable domain-
invariant features while the domain discriminator struggles to
distinguish samples from the target dataset. As a pioneering
effort, Tzeng et al. [36] presented an adversarial discriminative
domain adaptation method that combined discriminative mod-
eling, united weight sharing, and adversarial loss to achieve
better performance in challenging cross-modality classification
task. Subsequent research [39] applied the condition adver-
sarial mechanism to the domain discriminator on the class
information and proposed a conditional domain adversarial
network with multilinear conditioning and entropy condition-
ing strategies to further improve the discriminability and trans-
ferability of the classifier. In [22], an unsupervised adversarial
domain adaptation model was designed that integrated three
learning strategies to adapt the pose and expression distribution
between the source and target domain and learned the pose-
and-identity features with robustness. Rather than focusing
on holistic features for adaptation, some works [24], [25]
integrated graph representation propagation [42], [43] with
adversarial learning to learn more representative and domain-
invariant global-local features. Despite achieving superior per-
formance on several publicly available face expression bench-
mark datasets, the learned features are less discriminative due
to the lack of direct supervision for the samples of the target
domain.
Recent works show a tendency to incorporate the semantic-
aware strategy while learning the feature representation [21],
[26], [27], [44], [45]. To reduce the semantic gap during do-
main distribution alignment, Bozorgtabar et al. [21] employed
adversarial domain adaptation to transform the visual appear-
ance of the images from different domains while preserving
the semantic information. In [27], a consistent global-local
and semantic learning method was proposed that integrated
the domain-invariant global-local features and consistent se-
mantic learning to further mitigate the problem of semantic
inconsistency during domain adaptation. However, the method
employed fixed criteria in the pseudo label generation process,
which could lead to only a limited number of expression
classes having the capability to generate pseudo labels. In
contrast to the previously mentioned methods, our proposed
approach focuses on the domain-invariant multi-scale features
through separate global and local adversarial learning and
preserves the underlying semantic consistency by the global-
local unified prediction selection strategy.
III. PROPOSED METHOD
A. Overview
Our objective is to tackle the Cross-Domain Facial Ex-
pression Recognition (CD-FER) task where we are given a
source dataset Ds = {(xs
i, ys
i )}ns
i=1 and a target dataset Dt =
IEEE TRANSACTIONS ON MULTIMEDIA
4
𝑥𝑗
𝑡
Samples from target domain:
𝑥𝑖
𝑠
Samples from source domain:
Crop
-Net
F
F
𝑫𝟎
𝑫𝟏
𝑫𝟐
𝑫𝟑
𝑫𝟒
𝑫𝟓
𝑫𝟔
𝐟𝟎
𝐟𝟏
𝐟𝟐
𝐟𝟑
𝐟𝟒
𝐟𝟓
𝐟𝟔
SAL
𝑮𝟎
𝑮𝟏
𝑮𝟐
𝑮𝟑
𝑮𝟒
𝑮𝟓
𝑮𝟔
𝐟𝟎
𝐟𝟏
𝐟𝟐
𝐟𝟑
𝐟𝟒
𝐟𝟓
𝐟𝟔
𝑦0/ො𝑦0
SCL
𝐟𝟎
𝒊
𝐟𝟏
𝒊
𝐟𝟐
𝒊
𝐟𝟑
𝒊
𝐟𝟒
𝒊
𝐟𝟓
𝒊
𝐟𝟔
𝒊
F(𝑥𝑖
𝑠)
𝐟𝟏
𝒋
𝐟𝟐
𝒋
𝐟𝟑
𝒋
𝐟𝟒
𝒋
𝐟𝟓
𝒋
𝐟𝟔
𝒋
F(𝑥𝑗
𝑡)
𝐟𝟎
𝒋
𝑫
𝑮
Classify separately
𝑫
𝑮
Classify separately
ො𝑦0
𝑗, ො𝑦1
𝑗, ො𝑦2
𝑗, ො𝑦3
𝑗, ො𝑦4
𝑗, ො𝑦5
𝑗, ො𝑦6
𝑗
FPLG
predict
filter
convert
ො𝑦0
𝑗
ො𝑦1
𝑗
ො𝑦2
𝑗
ො𝑦3
𝑗
ො𝑦4
𝑗
ො𝑦5
𝑗
ො𝑦6
𝑗
෡𝐟𝟎
𝐣
෡𝐟𝟏
𝐣
෡𝐟𝟐
𝐣
෡𝐟𝟑
𝐣
෡𝐟𝟒
𝐣
෡𝐟𝟓
𝐣
෡𝐟𝟔
𝐣
Training
Crop-
Net & F
Inference
𝐟𝟎
𝐟𝟏
𝐟𝟐
𝐟𝟑
𝐟𝟒
𝐟𝟓
𝐟𝟔
𝑮𝟎
𝑮𝟏
𝑮𝟐
𝑮𝟑
𝑮𝟒
𝑮𝟓
𝑮𝟔
C0
C1
C2
C3
C4
C5
C6
prediction probility
threshold
C0
C1
C2
C3
C4
C5
C6
C0
C1
C2
C3
C4
C5
C6
…
…
…
…
C0
C1
C2
C3
C4
C5
C6
prediction probility
C0
C1
C2
C3
C4
C5
C6
C0
C1
C2
C3
C4
C5
C6
filter
filter
filter
⊕
< C1-“Fear” >
GLPC
…
…
…
…
C0
C1
C2
C3
C4
C5
C6
prediction probility
𝑦0𝑖, 𝑦1𝑖, 𝑦2𝑖, 𝑦3𝑖, 𝑦4𝑖, 𝑦5𝑖 , 𝑦6𝑖
𝑦1/ො𝑦1
𝑦2/ො𝑦2
𝑦3/ො𝑦3
𝑦4/ො𝑦4
𝑦5/ො𝑦5
𝑦6/ො𝑦6
Fig. 1. Illustration of the training and inference stages of our proposed AGLRLS model.
B. Domain-Invariant Representation Learning
1) Separate Adversarial Learning: In this subsection, we
will present a detailed explanation of the separate adversarial
learning process, denoted as SAL in Fig. 1. As the previous
work [25] has suggested, local regions surrounding specific
facial landmarks play a crucial role in expression recognition.
Building upon this insight, we adopt a strategy to extract not
only the full-face image as the global image but also the
key facial landmarks as the local images. These landmarks
include the left eye (le), right eye (re), nose (ne), left mouth
corner (lm), and right mouth corner (rm). Following the
aforementioned procedure, we obtain a global feature vector,
denoted as fg, as well as five local feature vectors, namely fle,
fre, fne, flm, and frm. Additionally, we concatenate these six
vectors into a seventh vector, denoted as fgl. Consequently, a
feature set f is formed, comprising seven vectors. The strategy
can be mathematically expressed as follows,
fgl = fg ⊕ fle ⊕ fre ⊕ fne ⊕ flm ⊕ frm,
f = {fg, fle, fre, fne, flm, frm, fgl}
(5)
where ⊕ is the concatenation operation. To perform separate
adversarial learning, we utilize indices ranging from 0 to 6 to
access the vector f. Thus, Equation (3) can be formulated as
below,
L (F, D) =
6
X
i=0
− βi·Ef s
i ∼Ds log [Di (f s
i )]
− βi·Ef t
i ∼Dt log

1 − Di
IEEE TRANSACTIONS ON MULTIMEDIA
5
target domain. To achieve this, we introduce the Feature-level
Pseudo Label Generation (FPLG) module in Fig. 1, which
independently generates a corresponding pseudo label for each
learned domain-invariant feature. Specifically, in Equation (5),
seven features are obtained from a target data xt, each of
which is subsequently fed into the corresponding classifier Gi
to make a prediction,
si = Gi(f t
i ) =

si
j
	
, s.t.j = 0, .., c − 1.
(7)
where si represents the total prediction score of Gi based on
f t
i and si
j is the score that Gi predicts xt as class j based
on the f t
i . c indicates the number of categories. The predicted
class p is obtained from si with the maximum probability,
p = argmax(si)
(8)
Then, with the prediction result of each classifier, we need to
determine whether the generated pseudo label is valid. Inspired
by FlexMatch [46], a dynamic threshold set ti is applied to
each classifier,
ti =

ti
j
	
, s.t.j = 0, .., c − 1.
(9)
where ti
j represents the threshold that Gi needs to reach to
generate pseudo label for class j. ti
j is calculated by the
following equation,
ti
j = M(λi
j) × θ
(10)
where θ is a fixed threshold, M is a nonlinear mapping
function with respect to λi
j, and λi
j represents the proportion
of data that the classifier Gi has successfully generated pseudo
label for class j, which can be calculated as follows,
λi
j =
σi
j
max σi
(11)
where σi represents the cumulative pseudo label quantities
generated by Gi for all categories until current training pro-
cess, while σi
j signifies the accumulation for class j. To ensure
the sensitivity of M to λi
j, we improve the M function so that
the mapped value is always greater than λi
j,
M(λi
j) = (λi
j + 1)2
4
(12)
Finally, we can obtain the final value of ˆyi by comparing si
p
and ti
p through the following formula,
ˆyi =
 p,
si
p > ti
p
−1,
otherwise
(13)
where -1 indicates that the generation of a pseudo label has
failed. We repeat the above process seven times and obtain
seven pseudo labels ˆy based on the extracted seven features.
ˆy = { ˆy0, ˆy1, ˆy2, ˆy3, ˆy4, ˆy5, ˆy6}
(14)
Upon the reliable pseudo labels flexibly taking the class
imbalance issue into consideration and containing abundant
semantic information, we leverage these target data to re-
train the network with the SCL module. This joint training
process not only boosts the discriminability of features but
also enhances the generalization of the model across domains.
Specifically, Equation (4) captures the essence of this training
process, which can be further refined as shown below,
L(F, G) =
6
X
i=0
− ηi · E(f s
i ,ys
i)∼Dsℓ (Gi (f s
i ) , ys
i )
− ηi · E
f t
i , ˆ
yt
i

∼Dtℓ

Gi
IEEE TRANSACTIONS ON MULTIMEDIA
6
Specifically, we calculate a mask matrix m using the following
formula,
m = s > t =





1
0
· · ·
1
1
0
· · ·
1
...
...
...
...
0
1
· · ·
0





(18)
The matrix m, which is also a 7×7 matrix, consists of
elements mij. mij takes a value of 1 if si
j is greater than
ti
j, otherwise, it is set to 0. Next, the masked score matrix ˆs
is obtained by the dot product of s and m.
ˆs = s · m =






ˆs0
0
0
· · ·
ˆs0
6
ˆs1
0
0
· · ·
ˆs1
6
...
...
...
...
0
ˆs6
1
· · ·
0






(19)
The prediction score for each class is produced by summing
up the masked scores from all the classifiers as follows,
˜s =
( 6
X
i=0
ˆsi
j
)
, j = 0...6.
(20)
Finally, our predicted label p is the class with the highest
prediction score in ˜s as
p = argmax(˜s)
(21)
IV. EXPERIMENTS
A. Experimental Settings
1) Dataset: There are six datasets used in the experiments,
namely RAF-DB [8], FER2013 [9], CK+ [10], JAFFE [11],
SFEW2.0 [12], and ExpW [13]. RAF-DB includes 29,672
diverse, gender-balanced facial images across various ages
and poses. FER2013, compiled via the Google image search
engine, contains 35,887 images of different facial expressions.
CK+ offers 593 annotated video samples from 123 subjects,
used for lab-based facial expression recognition. JAFFE fea-
tures 213 images from 10 Japanese women, each of which is
labeled as one of six basic expressions or as neutral. SFEW2.0
is an ’in-the-wild’ dataset with unconstrained facial expres-
sions, varying in age, pose, and resolution. ExpW has 91,793
’in-the-wild’ face images, collected via Google’s search API.
The class quantity distribution of the aforementioned datasets
is illustrated in Fig. 2.
2) Evaluation Metrics: To conduct fair comparison exper-
iments, multiple evaluation metrics are used in this paper as
follows:
Accuracy represents the percentage of samples that are
correctly predicted. It is also known as overall accuracy and
is the most commonly used metric in the classification task.
Recall is the proportion of true positive prediction among
all actual positive instances. Although it was originally used
for binary classification task, it can be also applied to multi-
classification task and effectively measure a model’s perfor-
mance, even in a class-imbalanced dataset. In our case, we
utilize Macro-Average Recall to obtain the average recall of
IEEE TRANSACTIONS ON MULTIMEDIA
7
TABLE I
ACCURACIES OF OUR PROPOSED AGLRLS AND EXISTING LEADING METHODS ON VARIOUS DATASETS USING DIFFERENT
SOURCE DATASETS AND BACKBONE NETWORKS. THE BEST RESULTS ARE IN BOLD.
Method
i) Source=RAF-DB, Backbone=ResNet50
ii) Source=RAF-DB, Backbone=MobileNet-v2
CK+
JAFFE
SFEW2.0
FER2013
ExpW
Mean
CK+
JAFFE
SFEW2.0
FER2013
ExpW
Mean
DT [25]
71.32
50.23
50.46
54.49
67.45
58.79
66.67
38.97
41.74
49.99
63.08
52.09
PLFT [25]
77.52
53.99
48.62
56.46
69.81
61.28
72.09
38.97
41.97
51.11
64.12
53.65
ICID [34]
74.42
50.70
48.85
53.70
69.54
59.44
57.36
37.56
38.30
44.47
60.64
47.67
DFA [47]
64.26
44.44
43.07
45.79
56.86
50.88
41.86
35.21
29.36
42.36
43.66
38.49
FTDNN [48]
79.07
52.11
47.48
55.98
67.72
60.47
71.32
46.01
45.41
49.96
62.87
55.11
JUMBOT [49]
79.46
54.13
51.97
53.56
63.69
60.56
73.64
51.35
44.41
49.05
60.84
55.86
ETD [50]
75.16
51.19
52.77
50.41
67.82
59.47
69.27
48.57
41.34
49.43
57.05
53.13
CADA [39]
72.09
52.11
53.44
57.61
63.15
59.68
62.79
53.05
43.12
49.34
59.40
53.54
SAFN [51]
75.97
61.03
52.98
55.64
64.91
62.11
66.67
45.07
40.14
49.90
61.40
52.64
SWD [52]
75.19
54.93
52.06
55.84
68.35
61.27
68.22
55.40
43.58
50.30
60.04
55.51
LPL [53]
74.42
53.05
48.85
55.89
66.90
59.82
59.69
40.38
40.14
50.13
62.26
50.52
DETN [54]
78.22
55.89
49.40
52.29
47.58
56.68
53.49
40.38
35.09
45.88
45.26
44.02
ECAN [35]
79.77
57.28
52.29
56.46
47.37
58.63
53.49
43.08
35.09
45.77
45.09
44.50
AGRA [25]
85.27
61.50
56.43
58.95
68.50
66.13
72.87
55.40
45.64
51.05
63.94
57.78
CGLRL [27]
82.95
59.62
56.88
59.30
70.02
65.75
69.77
52.58
49.77
52.46
64.87
57.89
AGLRLS
87.60
61.97
58.26
60.68
73.00
68.30
82.95
56.81
50.23
54.51
69.10
62.72
Method
iii) Source=FER2013, Backbone=ResNet50
iv) Source=FER2013, Backbone=MobileNet-v2
CK+
JAFFE
SFEW2.0
RAF-DB
ExpW
Mean
CK+
JAFFE
SFEW2.0
RAF-DB
ExpW
Mean
DT [25]
68.99
44.13
42.43
63.84
54.17
54.71
62.02
39.44
30.96
40.95
47.05
44.08
PLFT [25]
79.07
46.48
42.20
67.92
54.96
58.13
61.24
44.60
28.67
40.30
53.63
45.69
ICID [34]
63.57
44.60
43.58
62.08
54.01
53.57
55.81
39.44
31.42
41.21
41.50
41.88
DFA [47]
55.81
42.25
34.86
48.84
44.55
45.26
55.81
36.15
27.78
34.18
43.83
39.55
FTDNN [48]
72.09
53.99
45.64
64.40
54.67
58.16
59.69
45.54
39.68
52.43
49.87
49.44
JUMBOT [49]
75.76
49.69
44.33
63.08
52.37
57.05
51.16
41.54
36.06
44.93
49.30
44.60
ETD [50]
77.42
44.17
39.58
61.18
49.97
54.46
54.55
40.32
30.77
50.54
45.91
44.42
CADA [39]
81.40
45.07
46.33
65.96
54.84
58.72
66.67
50.23
41.28
53.15
51.84
52.63
SAFN [51]
68.99
45.07
38.07
62.80
53.91
53.77
66.67
37.56
35.78
38.73
45.56
44.86
SWD [52]
65.89
49.30
45.64
65.28
56.05
56.43
53.49
48.36
35.78
47.44
50.02
47.02
LPL [53]
68.22
42.72
44.27
64.23
52.45
54.38
60.47
37.56
31.88
43.92
49.83
44.73
DETN [54]
65.89
37.89
37.39
50.51
52.15
48.77
48.09
42.31
27.54
40.53
39.14
39.52
ECAN [35]
60.47
41.76
46.01
53.41
48.88
50.11
55.65
44.12
28.46
42.31
41.53
42.41
AGRA [25]
85.69
52.74
49.31
67.62
60.23
63.12
67.44
47.89
41.74
52.27
59.41
53.75
CGLRL [27]
79.84
53.52
52.29
71.84
61.94
63.87
59.69
50.23
44.72
61.95
55.33
54.38
AGLRLS
89.92
54.93
52.52
72.02
62.63
66.40
69.77
50.70
47.02
64.85
57.14
57.90
To combine the global and local features, we concatenate
the global feature vector with the five local feature vectors,
resulting in a feature vector of 384 dimensions. The set of
feature vectors, denoted as f, consists of seven elements.
Corresponding to the seven features in f, seven classifiers G
and domain discriminators D are constructed, the former of
which uses a series of fully connected layers and the latter
uses the approach in [39].
b) Training Details: In the proposed AGLRLS frame-
work, the feature extractors F, classifiers G and domain
discriminators D are trained and optimized in Equations (1)
and (2). We initialize the backbone network using models
pretrained on the MS-Celeb-1M dataset [58]. The parameters
of the newly added layers are initialized using the Xavier
algorithm [59]. Stochastic Gradient Descent (SGD) is used
as the optimizer in the experiment. Inspired by the previous
works [24], [60], we adopt a two-stage training process.
In the first stage, we solely utilize labeled source domain
samples to train the feature extractor and classifier using cross-
entropy loss, as described in the first part of Equation (15).
The learning rate, weight decay, and momentum are set to
0.0001, 0.0005, and 0.9, respectively. We train the network
for approximately 15 epochs. In the second stage, the domain
discriminator is trained utilizing the objective loss specified in
Equation (6), while the feature extractor and classifier undergo
fine-tuning using the objective loss described in Equation
(15). The momentum and weight decay parameters remain
unchanged from the first stage. Specifically, the initial learning
rate for the feature extractor and the source classifier is set to
0.00001 and subsequently divided by 10 after 20 epochs. As
for the domain discriminator, it is trained from scratch with
an initial learning rate of 0.0001, and this learning rate is
reduced by a factor of 10 once the error reaches a saturation
point. The balance coefficient set β and η are both set to
{7, 1, 1, 1, 1, 1, 7}.
In addition, in the pseudo label generation module, three
points should be noted. First, although the pseudo label gen-
eration and cross-entropy calculation share the same target do-
main images, data augmentation is performed differently as the
former uses weak augmentation and the latter applies stronger
enhancement such as diffraction. Second, after using the
classifier to predict the initial label scores, we apply a softmax
process to compare with the threshold. Thirdly, pseudo label
generation is seamlessly integrated into the model’s forward
propagation, constituting a minor portion of the total runtime.
In our experiments, the average forward propagation time for
a single batch is 0.78 seconds, while the generation of seven
sets of pseudo labels and the associated calculations require
IEEE TRANSACTIONS ON MULTIMEDIA
8
only 0.05 seconds, accounting for approximately 6.41%.
B. Comparisons With The Existing Methods
In the context of cross-domain facial expression recognition,
comparing the performance of different methods can be chal-
lenging due to variations in the source domain and backbones.
To ensure a fair comparison, we refer to the benchmark pro-
posed by Chen et al. [25] and compare our proposed AGLRLS
method with a number of leading methods. The comparative
results are presented in Table I. It is evident from the table
that our method consistently outperforms the other algorithms
across various configurations and datasets. For more insights,
we will delve into a comprehensive analysis of our proposed
method’s performance under different conditions.
1) Using Different Backbones: The utilization of different
backbones results in variations in the capabilities of our
feature extractor. To assess the robustness of our method with
different backbones, we employed two widely used backbones,
namely ResNet50 and MobileNet-v2. The comparative results
presented in Table I demonstrate that when we keep the source
domain constant and replace ResNet50 with MobileNet-v2,
the performances of almost all the approaches show a vary-
ing degree of degradation across all datasets. For a more
detailed analysis, we focus on subtables i and ii in Table
I, where RAF-DB is the source domain and MobileNet-v2
replaces ResNet50. The AGRA algorithm, previously regarded
as the best, experiences a reduction of 12.4%, 6.1%, 10.79%,
7.9%, and 4.56% in accuracy on the CK+, JAFFE, SFEW2.0,
FER2013, and ExpW datasets, respectively. Similarly, our
preliminary work, CGLRL, also shows decreases of 13.18%,
7.04%, 7.11%, 6.84%, and 5.15% on these five datasets,
respectively. This reduction in performance can be attributed
to the fact that MobileNet-v2 utilizes depthwise separable
convolution in its architecture, resulting in relatively weaker
feature extraction capability compared to ResNet50. While the
performance of our proposed AGLRLS method also declines,
the reduction is comparatively smaller than that of AGRA and
CGLRL. Specifically, we observe decreases of 4.65%, 5.16%,
8.03%, 6.17%, and 3.90% on the aforementioned datasets,
respectively. Notably, even when using MobileNet-v2 with
relatively inferior feature extraction capability, our method still
outperforms the best algorithm on the five datasets by 9.31%,
1.41%, 0.46%, 2.05%, and 4.23%, respectively. To facilitate a
fair comparison, we calculate the average accuracy across each
target domain, referred to as the Mean. This demonstrates the
consistent robustness of AGLRLS across the target datasets.
2) Using Different Source Domain: Another important fac-
tor that affects the accuracy of the target domain is the
similarity between the source and target domain. As shown
in Table I, when we maintain the same backbone network
and switch the source domain from RAF-DB to FER2013,
almost all of the algorithms experience varying degrees of
performance degradation across all datasets. For example, in
subtables i) and iii) of Table I, we use the same backbone,
ResNet50, and change the source domain from RAF-DB to
FER2013. The accuracy of AGRA increases by 0.42% on
CK+ dataset but decreases by 8.76%, 7.12%, and 8.27% on
0.0
2.5
5.0
7.5
10.0
PLFT
JUMBOT
ETD
SAFN
SWD
LPL
DETN
ECAN
AGRA
AGLRLS
α = 0.05
0.0
2.5
5.0
7.5
10.0
PLFT
JUMBOT
ETD
SAFN
SWD
LPL
DETN
ECAN
AGRA
AGLRLS
α = 0.10
Fig. 3. The Friedman Test Chart. The left half is the case
of α=0.05, and the right half is the case of α=0.10. The
horizontal coordinate corresponding to the intermediate point
of each algorithm is the average order value. The lower the
value, the better the performance. The range of horizontal lines
on both sides of each intermediate point represents the CD
value. If the horizontal lines between the two algorithms do not
overlap, it means that the performance of these two methods
is significantly different.
JAFFE, SFEW2.0, and ExpW datasets, respectively. Similarly,
CGLRL experiences reductions of 3.11%, 6.1%, 4.59%, and
8.08%. The reasons can be summarized as follows:
Firstly, although RAF-DB and FER2013 have similar data
sizes and are both collected from the Web, FER2013 data
are in grayscale while RAF-DB data are in color. The tar-
get datasets, SFEW2.0 and ExpW, consist of color images.
From this perspective, the similarity between FER2013 and
SFEW2.0/ExpW is smaller compared to the similarity be-
tween RAF-DB and SFEW2.0/ExpW. Similarly, CK+ is also
a grayscale image dataset, and its similarity with FER2013
is higher than the similarity between CK+ and RAF-DB.
Consequently, some methods may show a slight improvement
in performance on FER2013. The second difference between
RAF-DB and FER2013 is the different coverage of ethnic
groups. The RAF-DB dataset includes a considerable number
of samples of Asian people, while FER2013 does not. As a
result, the similarity between FER2013 and the JAFFE dataset,
which consists of Asian women, is much lower compared to
the similarity between RAF-DB and JAFFE. This explains the
significant performance drop of most methods on the JAFFE
dataset.
Despite experiencing some degree of degradation, our pro-
posed model still outperforms other state-of-the-art approaches
on CK+, JAFFE, SFEW2.0, and ExpW by 4.23%, 1.41%,
0.23%, and 0.69%, respectively. To ensure a fair comparison,
we utilize the Mean metric for evaluation. As shown in Table
I (iii), our AGLRLS method consistently achieves the best
performance compared to the other approaches.
3) Using Statistical Test: Statistical tests offer a more
rigorous and scientific approach for comparing algorithm per-
IEEE TRANSACTIONS ON MULTIMEDIA
9
IEEE TRANSACTIONS ON MULTIMEDIA
10
IEEE TRANSACTIONS ON MULTIMEDIA
11
IEEE TRANSACTIONS ON MULTIMEDIA
12
[10] P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and I. Matthews,
“The extended cohn-kanade dataset (ck+): A complete dataset for action
unit and emotion-specified expression,” in IEEE Computer Society
Conference on Computer Vision and Pattern Recogniton-Workshops,
2010, pp. 94–101.
[11] M. Lyons, S. Akamatsu, M. Kamachi, and J. Gyoba, “Coding facial
expressions with gabor wavelets,” in IEEE International Conference on
Automatic Face and Gesture Recognition, 1998, pp. 200–205.
[12] A. Dhall, R. Goecke, S. Lucey, and T. Gedeon, “Static facial expression
analysis in tough conditions: Data, evaluation protocol and benchmark,”
in IEEE International Conference on Computer Vision Workshops (ICCV
Workshops), 2011, pp. 2106–2112.
[13] Z. Zhang, P. Luo, C. C. Loy, and X. Tang, “From facial expression
recognition to interpersonal relation prediction,” International Journal
of Computer Vision, vol. 126, pp. 550–569, 2018.
[14] H. Yan, “Transfer subspace learning for cross-dataset facial expression
recognition,” Neurocomputing, vol. 208, pp. 165–173, 2016.
[15] Y.-Q. Miao, R. Araujo, and M. S. Kamel, “Cross-domain facial ex-
pression recognition using supervised kernel mean matching,” in 11th
International Conference on Machine Learning and Applications, 2012,
pp. 326–332.
[16] Z. Sun, R. Chiong, Z.-p. Hu, and S. Dhakal, “A dynamic constraint
representation approach based on cross-domain dictionary learning for
expression recognition,” Journal of Visual Communication and Image
Representation, vol. 85, p. 103458, 2022.
[17] T. Ni, C. Zhang, and X. Gu, “Transfer model collaborating metric
learning and dictionary learning for cross-domain facial expression
recognition,” IEEE Transactions on Computational Social Systems,
vol. 8, no. 5, pp. 1213–1222, 2021.
[18] C. Wang, J. Ding, H. Yan, and S. Shen, “A prototype-oriented contrastive
adaption network for cross-domain facial expression recognition,” in
Asian Conference on Computer Vision (ACCV), 2022, pp. 324–340.
[19] X. Wang, X. Wang, and Y. Ni, “Unsupervised domain adaptation for
facial expression recognition using generative adversarial networks,”
Computational Intelligence and Neuroscience, p. 7208794, 2018.
[20] Y. Zong, W. Zheng, X. Huang, J. Shi, Z. Cui, and G. Zhao, “Domain
regeneration for cross-database micro-expression recognition,” IEEE
Transactions on Image Processing, vol. 27, no. 5, pp. 2484–2498, 2018.
[21] B. Bozorgtabar, D. Mahapatra, and J.-P. Thiran, “Exprada: Adversarial
domain adaptation for facial expression analysis,” Pattern Recognition,
vol. 100, p. 107111, 2020.
[22] G. Liang, S. Wang, and C. Wang, “Pose-aware adversarial domain
adaptation for personalized facial expression recognition,” arXiv preprint
arXiv:2007.05932, 2020.
[23] H. Yang, Z. Zhang, and L. Yin, “Identity-adaptive facial expression
recognition through expression regeneration using conditional genera-
tive adversarial networks,” in 13th IEEE International Conference on
Automatic Face & Gesture Recognition, 2018, pp. 294–301.
[24] Y. Xie, T. Chen, T. Pu, H. Wu, and L. Lin, “Adversarial graph represen-
tation adaptation for cross-domain facial expression recognition,” in 28th
ACM International Conference on Multimedia, 2020, pp. 1255–1264.
[25] T. Chen, T. Pu, H. Wu, Y. Xie, L. Liu, and L. Lin, “Cross-domain facial
expression recognition: A unified evaluation benchmark and adversarial
graph learning,” IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 44, no. 12, pp. 9887–9903, 2022.
[26] Y. Li, Y. Gao, B. Chen, Z. Zhang, L. Zhu, and G. Lu, “Jdman:
Joint discriminative and mutual adaptation networks for cross-domain
facial expression recognition,” in 29th ACM International Conference
on Multimedia, 2021, pp. 3312–3320.
[27] Y. Xie, Y. Gao, J. Lin, and T. Chen, “Learning consistent global-
local representation for cross-domain facial expression recognition,” in
26th International Conference on Pattern Recognition (ICPR), 2022, pp.
2489–2495.
[28] X. Zou, Y. Yan, J. Xue, S. Chen, and H. Wang, “Learn-to-decompose:
Cascaded decomposition network for cross-domain few-shot facial ex-
pression recognition,” in European Conference on Computer Vision,
2022, pp. 683–700.
[29] K. Yan, W. Zheng, Z. Cui, and Y. Zong, “Cross-database facial expres-
sion recognition via unsupervised domain adaptive dictionary learning,”
in International Conference on Neural Information Processing, 2016,
pp. 427–434.
[30] M. Meng, M. Lan, J. Yu, J. Wu, and L. Liu, “Dual-level adaptive and
discriminative knowledge transfer for cross-domain recognition,” IEEE
Transactions on Multimedia, vol. 25, pp. 2266–2279, 2023.
[31] X. Zou, Y. Yan, J.-H. Xue, S. Chen, and H. Wang, “When facial
expression recognition meets few-shot learning: a joint and alternate
learning framework,” in the AAAI Conference on Artificial Intelligence,
2022, pp. 5367–5375.
[32] W. Zheng, Y. Zong, X. Zhou, and M. Xin, “Cross-domain color facial
expression recognition using transductive transfer subspace learning,”
IEEE Transactions on Affective Computing, vol. 9, no. 1, pp. 21–37,
2018.
[33] Y. Li, Z. Zhang, B. Chen, G. Lu, and D. Zhang, “Deep margin-sensitive
representation learning for cross-domain facial expression recognition,”
IEEE Transactions on Multimedia, vol. 25, pp. 1359–1373, 2023.
[34] Y. Ji, Y. Hu, Y. Yang, F. Shen, and H. T. Shen, “Cross-domain facial
expression recognition via an intra-category common feature and inter-
category distinction feature fusion network,” Neurocomputing, vol. 333,
pp. 231–239, 2019.
[35] S. Li and W. Deng, “A deeper look at facial expression dataset bias,”
IEEE Transactions on Affective Computing, vol. 13, no. 2, pp. 881–893,
2022.
[36] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, “Adversarial discrimi-
native domain adaptation,” in IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), 2017, pp. 2962–2971.
[37] A. Conti, P. Rota, Y. Wang, and E. Ricci, “Cluster-level pseudo-labelling
for source-free cross-domain facial expression recognition,” in the 3rd
British Machine Vision Conference (BMVC), 2022, pp. 1–13.
[38] M. de Carvalho, M. Pratama, J. Zhang, and E. Y. K. Yee, “Acdc: Online
unsupervised cross-domain adaptation,” Knowledge-Based Systems, vol.
253, p. 109486, 2022.
[39] M. Long, Z. Cao, J. Wang, and M. I. Jordan, “Conditional adversarial
domain adaptation,” in Advances in Neural Information Processing
Systems, 2018, pp. 1647–1657.
[40] Y. Ji, Y. Hu, Y. Yang, and H. T. Shen, “Region attention enhanced unsu-
pervised cross-domain facial emotion recognition,” IEEE Transactions
on Knowledge and Data Engineering, vol. 35, no. 4, pp. 4190–4201,
2023.
[41] J. Wang and J. Jiang, “Learning across tasks for zero-shot domain
adaptation from a single source domain,” IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 44, no. 10, pp. 6264–6279, 2022.
[42] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, “Gated graph
sequence neural networks,” arXiv:1511.05493, 2015.
[43] T. Chen, L. Lin, R. Chen, X. Hui, and H. Wu, “Knowledge-guided
multi-label few-shot learning for general image recognition,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 44,
no. 3, pp. 1371–1384, 2020.
[44] Z. Wang, J. Zhang, T. Chen, W. Wang, and P. Luo, “Restoreformer++:
Towards real-world blind face restoration from undegraded key-value
pairs,” IEEE Transactions on Pattern Analysis and Machine Intelligence,
vol. 45, no. 12, pp. 15 462–15 476, 2023.
[45] T. Pu, T. Chen, H. Wu, Y. Lu, and L. Lin, “Spatial-temporal knowledge-
embedded transformer for video scene graph generation,” IEEE Trans-
actions on Image Processing, vol. 33, pp. 556–568, 2023.
[46] B. Zhang, Y. Wang, W. Hou, H. Wu, J. Wang, M. Okumura, and
T. Shinozaki, “Flexmatch: Boosting semi-supervised learning with cur-
riculum pseudo labeling,” in Advances in Neural Information Processing
Systems, 2021, pp. 18 408–18 419.
[47] R. Zhu, G. Sang, and Q. Zhao, “Discriminative feature adaptation for
cross-domain facial expression recognition,” in International Conference
on Biometrics (ICB), 2016, pp. 1–7.
[48] M. V. Zavarez, R. F. Berriel, and T. Oliveira-Santos, “Cross-database
facial expression recognition based on fine-tuned deep convolutional
network,” in 30th Conference on Graphics, Patterns and Images (SIB-
GRAPI), 2017, pp. 405–412.
[49] K. Fatras, T. Sejourne, R. Flamary, and N. Courty, “Unbalanced mini-
batch optimal transport; applications to domain adaptation,” in 38th
International Conference on Machine Learning, 2021, pp. 3186–3197.
[50] M. Li, Y.-M. Zhai, Y.-W. Luo, P. Ge, and C.-X. Ren, “Enhanced transport
distance for unsupervised domain adaptation,” in IEEE/CVF Conference
on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 13 933–
13 941.
[51] R. Xu, G. Li, J. Yang, and L. Lin, “Larger norm more transferable: An
adaptive feature norm approach for unsupervised domain adaptation,” in
IEEE/CVF International Conference on Computer Vision (ICCV), 2019,
pp. 1426–1435.
[52] C.-Y. Lee, T. Batra, M. H. Baig, and D. Ulbricht, “Sliced wasserstein
discrepancy for unsupervised domain adaptation,” in IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition (CVPR), 2019, pp.
10 277–10 287.
[53] S. Li, W. Deng, and J. Du, “Reliable crowdsourcing and deep locality-
preserving learning for expression recognition in the wild,” in IEEE/CVF
IEEE TRANSACTIONS ON MULTIMEDIA
13
Conference on Computer Vision and Pattern Recognition (CVPR), 2017,
pp. 2584–2593.
[54] S. Li and W. Deng, “Deep emotion transfer network for cross-database
facial expression recognition,” in 24th International Conference on
Pattern Recognition (ICPR), 2018, pp. 3092–3099.
[55] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR), 2016, pp. 770–778.
[56] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen,
“Mobilenetv2: Inverted residuals and linear bottlenecks,” in IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR), 2018,
pp. 4510–4520.
[57] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao, “Joint face detection and
alignment using multitask cascaded convolutional networks,” IEEE
Signal Processing Letters, vol. 23, no. 10, pp. 1499–1503, 2016.
[58] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao, “Ms-celeb-1m: A
dataset and benchmark for large-scale face recognition,” in European
Conference on Computer Vision (ECCV), 2016, pp. 87–102.
[59] X. Glorot and Y. Bengio, “Understanding the difficulty of training
deep feedforward neural networks,” in The Thirteenth International
Conference on Artificial Intelligence and Statistics, 2010, pp. 249–256.
[60] J. Wen, R. Liu, N. Zheng, Q. Zheng, Z. Gong, and J. Yuan, “Exploiting
local feature patterns for unsupervised domain adaptation,” in the AAAI
Conference on Artificial Intelligence, 2019, pp. 5401–5408.
[61] M. Friedman, “The use of ranks to avoid the assumption of normality
implicit in the analysis of variance,” Journal of The American Statistical
Association, vol. 32, no. 200, pp. 675–701, 1937.
[62] R. TAMURA, “Some distribution-free multiple comparison procedures,”
Memoirs of the Faculty of Literature and Science, Shimane University,
Natural Sciences, vol. 1, pp. 1–7, 1968.
[63] J. Demˇsar, “Statistical comparisons of classifiers over multiple data sets,”
The Journal of Machine learning research, vol. 7, pp. 1–30, 2006.
Yuefang Gao received the Ph.D. degree in computer
science from South China University of Technology
in 2009. She is an associate professor in College
of Mathematics and Informatics, South China Agri-
cultural University, China. Her research interests
include computer vision, machine learning and data
mining. She has authored and co-authored more
than 20 papers in top-tier academic journals and
conferences, including T-CSVT, PR, TKDE, ACM
MM, etc. She has served as a reviewer for some
academic journals and conferences.
Yuhao Xie received his bachelor’s degree from
South China Agricultural University, China in 2023.
He is currently pursuing a master’s degree at the
Guangzhou Institute of Technology, Xidian Univer-
sity. His research interests include computer vision
and deep learning.
Zeke Zexi Hu is currently a Ph.D. candidate at
the School of Computer Science, University of Syd-
ney, Australia. He received his bachelor’s degree
from South China Agricultural University, China in
2014 and his M.Phil. degree from the University of
Sydney in 2020. His research focuses on computer
vision and deep learning.
Tianshui Chen received a Ph.D. degree in computer
science at the School of Data and Computer Science
Sun Yat-sen University, Guangzhou, China, in 2018.
Prior to earning his Ph.D., he received a B.E. degree
from the School of Information and Science Tech-
nology in 2013. He is currently an associated profes-
sor in the Guangdong University of Technology. His
current research interests include computer vision
and machine learning. He has authored and coau-
thored approximately 40 papers published in top-
tier academic journals and conferences, including T-
PAMI, T-NNLS, T-IP, T-MM, CVPR, ICCV, AAAI, IJCAI, ACM MM, etc.
He has served as a reviewer for numerous academic journals and conferences.
He was the recipient of the Best Paper Diamond Award at IEEE ICME 2017.
Liang Lin (Fellow, IEEE) is a full professor at
Sun Yat-sen University. From 2008 to 2010, he
was a postdoctoral fellow at the University of Cal-
ifornia, Los Angeles. From 2016–2018, he led the
SenseTime R&D teams to develop cutting-edge and
deliverable solutions for computer vision, data anal-
ysis and mining, and intelligent robotic systems. He
has authored and coauthored more than 100 papers
in top-tier academic journals and conferences (e.g.,
15 papers in TPAMI and IJCV and 60+ papers in
CVPR, ICCV, NIPS, and IJCAI). He has served as
an associate editor of IEEE Trans. Human-Machine Systems, The Visual
Computer, and Neurocomputing and as an area/session chair for numerous
conferences, such as CVPR, ICME, ACCV, and ICMR. He was the recipient
of the Annual Best Paper Award by Pattern Recognition (Elsevier) in 2018, the
Best Paper Diamond Award at IEEE ICME 2017, the Best Paper Runner-Up
Award at ACM NPAR 2010, Google Faculty Award in 2012, the Best Student
Paper Award at IEEE ICME 2014, and the Hong Kong Scholars Award in
2014. He is a Fellow of IEEE, IAPR, and IET.
"
"In this paper, we investigate transmission control for unmanned aerial vehicles (UAVs) operating in unlicensed spectrum bands. A rigorous interference-aware queuing analysis framework is developed to optimize expected throughput by balancing packet drops from queues and transmission errors caused by low SINR. Two packet loss probabilities are explored, buffer overflow model and time threshold model. Two algorithms, Interference-Aware Transmission Control (IA-TC) and Interference-Aware Distributed Transmission Control (IA-DTC), adjust transmission policies to optimize throughput. Numerical results demonstrate that both algorithms find the optimal transmission policy. Focus is on LoS and NLoS interference links between UAVs and ground nodes.nan","UAV networks have great potential, but reliable and robust communication in unlicensed spectrum bands is challenging. This paper explores distributed transmission policies that consider queue and channel impairments. Previous works have not investigated this issue in-depth.nan",nanExisting literature on UAV network transmission policies does not comprehensively consider the effects of queue and in-band interference on packet losses. Some studies assume LoS or NLoS links without interference models or only model system performance in terms of UAV trajectory and not channel parameters.nan,"A comprehensive analytical framework is proposed to characterize two factors that impact packet losses: queue-related analysis with a time threshold model and buffer overflow model, and channel-related analysis that focuses on outage probability and the impact of interference. Two transmission policy algorithms, IA-TC and IA-DTC, are introduced to find the optimal channel fading threshold in the presence of queue and channel impairments.nan",The performance of the proposed algorithms is evaluated under various scenarios. Results show that IA-TC constantly tries to increase the channel fading threshold for interferer nodes and decrease it for the main source node. IA-DTC balances the trade-offs between optimizing the throughput of the main link and minimizing interference to other nodes. Both algorithms achieve higher throughput compared to baseline policies.nan,"An in-depth investigation of distributed transmission policy that considers both packet queues and interference levels is presented. Two transmission algorithms, IA-TC and IA-DTC, are proposed and their effectiveness is demonstrated. The optimal transmission policy under various scenarios is found. Future work will extend analysis to model-free analysis and optimization solutions.nan",Interference-Aware Queuing Analysis for Distributed Transmission Control in UAV Networks,"Masoud Ghazikor, Keenan Roach, Kenny Cheung, Morteza Hashemi","Interference-Aware Queuing Analysis for
Distributed Transmission Control in UAV Networks
Masoud Ghazikor∗, Keenan Roach†, Kenny Cheung†, Morteza Hashemi∗
∗Department of Electrical Engineering and Computer Science, University of Kansas
†Universities Space Research Association (USRA)
Abstract—In this paper, we investigate the problem of dis-
tributed transmission control for unmanned aerial vehicles
(UAVs) operating in unlicensed spectrum bands. We develop
a rigorous interference-aware queuing analysis framework that
jointly considers two inter-dependent factors: (i) limited-size
queues with delay-constrained packet arrival, and (ii) in-band
interference introduced by other ground/aerial users. We aim to
optimize the expected throughput by jointly analyzing these fac-
tors. In the queuing analysis, we explore two packet loss probabil-
ities including, buffer overflow model and time threshold model.
For interference analysis, we investigate the outage probability
and packet losses due to low signal-to-interference-plus-noise
ratio (SINR). We introduce two algorithms namely, Interference-
Aware Transmission Control (IA-TC), and Interference-Aware
Distributed Transmission Control (IA-DTC). These algorithms
maximize the expected throughput by adjusting transmission
policies to balance the trade-offs between packet drop from
queues vs. transmission errors due to low SINRs. We implement
the proposed algorithms and demonstrate that the optimal
transmission policy under various scenarios is found.
Index Terms—Unmanned aerial vehicles, distributed transmis-
sion policy, channel fading threshold, expected throughput
I. INTRODUCTION
Unmanned Aerial Vehicles (UAVs) have emerged as a
transformative technology for a wide range of applications
such as environmental conservation, emergency services, de-
livery, and more. These instances are crucial to determining
how to support the expected increase in UAV usage [1]. For
UAV communications, both licensed and unlicensed spectrum
can be used. Licensed spectrum grants exclusive access to
the channel and includes regulatory requirements to fulfill.
In contrast, unlicensed spectrum is shared among different
communication nodes, and thus it includes light regulations
that make nodes more prone to interference from other users.
As a result, reliable and robust UAV communication in unli-
censed spectrum bands is challenging. To address this issue,
developing a distributed transmission policy is essential to
ensure a high quality of service, particularly for UAV networks
that require delay-sensitive command-and-control (C2) data.
Over the past few years, there has been extensive amounts
of research on different aspects of UAV networking (see, for
example, [2]–[4]). However, there are still research gaps in
developing distributed transmission policies that jointly take
into account (i) the level of interference in the unlicensed
spectrum bands, and (ii) the transmission queue state in terms
of buffer size and queuing delay. For instance, in [5], Line-of-
Sight (LoS) and Non-Line-of-Sight (NLoS) wireless links are
modeled for UAVs and a transmission policy is defined without
considering interference. In [6], distributed transmission policy
is developed for ground level terrestrial networks, and not
NLoS Interference Link
LoS Interference Link
G2A
G2A
A2A
Main Link
βn
λn
Enqueuing Packets 
βm1
λm1
βm2
λm2
βm3
λm3
Fig. 1: System model that consists of ground and aerial nodes.
specifically for UAV networks. A new LoS channel model
is proposed in [7] for UAVs, but the interference model is not
included in the outage probability calculation. In [8], ground-
to-air (G2A) and air-to-ground (A2G) channels are modeled,
and system performance is characterized in terms of UAV
trajectory, and not the channel parameters.
Although there have been research on UAV network trans-
mission policies [5], [7], [8], an in-depth investigation of
distributed transmission policy that takes into account both
packet queues and interference levels in unlicensed frequency
bands is still lacking. This paper aims to address this gap
by exploring how UAVs and ground-level nodes achieve an
optimal policy by adjusting the channel fading threshold in a
distributed manner. To this end, we propose a comprehensive
analytical framework to characterize two factors that impact
packet losses: (i) queue-related analysis wherein we consider
a time threshold model to capture the delay sensitivity of data
packets, and buffer overflow model to capture the limited size
of data queues, and (ii) channel-related analysis by which we
focus on the outage probability and analyze the impact of in-
band interference on packet transmission errors.
Given these factors, we introduce two transmission algo-
rithms, namely, Interference-Aware Transmission Control (IA-
TC), and Interference-Aware Distributed Transmission Control
(IA-DTC). In the IA-TC algorithm, we assume there is a
single source node and devise a solution to find its optimal
channel fading threshold βn and the best expected throughput
(Rbest
n
), while adjusting the βm of other aerial or ground
interferer nodes. On the other hand, in the IA-DTC algorithm,
we find the optimal channel fading threshold for all nodes, i.e.,
β ≜ {βm, βn}, by assuming that each node can be considered
as a source node. In this algorithm, each node discovers its
optimal β through a consensus-based optimization approach.
Through numerical results, we compare the performance of our
proposed algorithms with several baselines to demonstrate the
arXiv:2401.11084v1  [cs.IT]  20 Jan 2024
efficacy of the our method. In summary, the main contributions
of this paper are as follows:
• We propose a comprehensive analytical framework for
developing throughput-optimal transmission policies for
UAV networks. Our system takes into account the effects
of queue and in-band interference on packet losses.
• We introduce two transmission policy algorithms for find-
ing the optimal channel fading threshold in the presence
of queue and channel impairments. We implement coor-
dinate descent optimization to find the optimal channel
fading threshold for the source node and consensus-based
distributed optimization to determine the optimal channel
fading threshold for each node.
• We implement the proposed algorithms and assess their
effectiveness under various scenarios in comparison to
several alternative baseline policies.
The rest of this paper is organized as follows. In Section II, the
system model is introduced. Section III offers an analysis of
the time threshold and buffer overflow models, as well as the
outage probability by considering the impact of interference.
In Section IV, the IA-TC and IA-DTC transmission policy
algorithms are introduced. Section V provides the numerical
results, followed by the conclusion in Section VI.
II. SYSTEM MODEL
We consider a network that consists of ground and aerial
nodes, all operating in unlicensed spectrum bands for G2A,
A2G, G2G, and A2A links. The spectrum band is divided
into a set of F frequency channels. We further assume that
the source node communicates with the main UAV (right UAV
in Fig. 1), while several interferer ground nodes communicate
with the interferer UAV (left UAV in Fig. 1). In general, N
denotes the set of communication sessions that share the same
spectrum band, and n ∈ N represents the individual session
between the source node and the UAV.
Furthermore, we assume that each node has a limited-size
queue, where the packet arrival process (λi) follows a Poisson
distribution. Each node either transmits the packet to its
destination or keeps the packet in its queue. This transmission
decision is determined based on channel conditions and queue
states. For instance, if two or more nodes choose the same
channel to transmit packets simultaneously, there would be
in-band interference and degraded SINR values.
Channel Modeling. Given the described system model, first
we calculate the LoS probability (PLoS(di)) that captures
different types of channels [9]:
PLoS(di) =






1 − e(−
z2
i
2ζ2 )di√vµ
zi = zu

1 −
√
2πζ
dV
i
Q( zi
ζ ) − Q( zu
ζ )

dH
i
√vµ
zi ̸= zu,
where ζ, v, and µ are environmental parameters and Q(x) is
the Q-function. Also, dH
i
=
p
(xi − xu)2 + (yi − yu)2 and
dV
i
=
p
(zi − zu)2 are, respectively, horizontal and vertical
distances between the transmitter (i) and receiver (u). Thus,
the total distance between node i and a specific receiver node
is obtained as:
di =
q
dH
i
2 + dV
i
2
∀i = {n, m} ,
(1)
where the indices n and m denote the source node and the
set of interferer nodes in a given area, respectively.
Given the transmit power Pt, we have Pr = Pt|hf
n|2 in
which Pr is the received power and hf
n is the channel gain of
channel f ∈ F. Furthermore, hf
n can be expressed as hf
n =
˜hf
nˆhf
n, in which ˜hf
n denotes the channel fading coefficient, and
ˆhf
n is the square root of the path loss. By using a single-slope
path loss model [10], we have:
ˆhf
n =
r
c(d0
di
)α(di)
if di ≥ d0,
(2)
where c =
λ2
16π2d2
0 is a constant factor. Furthermore, d0 and di
are the reference distance and the distance between the nodes
and their intended receiver, respectively. Also, the path loss
exponent α(di) is defined as [11], [12]:
α(di) = αLoSPLoS(di) + αNLoS(1 − PLoS(di)),
(3)
in which αLoS and αNLoS are the path loss exponents for LoS
and NLoS links, respectively.
In the framework of a block fading channel model, the
variable ˜hf
n follows either the Rician (Rice) or Rayleigh
(Ray) distributions depending on whether it corresponds to
LoS or NLoS channels, respectively. Let us initially focus on
the Rician channel, in which the probability density function
(PDF) is given by:
Pb(˜hf
n = x) = xe− x2+b2
2
I0(xb),
(4)
where b =
p
2K(di) is defined according to the Rician factor
K(di) = KNLoSeln(
KLoS
KNLoS )PLoS(di)2
in which KLoS and
KNLoS are determined when PLoS(di) is equal to one and
zero, respectively [9]. Also, I0 represents the modified Bessel
function of the first kind with order zero.
Principle of the Transmission Policy.
The source node
transmits its packet to the UAV over the best frequency channel
f ∗ = arg maxf∈F
˜hf
nˆhf
n if the channel fading coefficient is
larger than a channel fading threshold βn, i.e., ˜hf ∗
n
≥ βn;
otherwise, the source node would enqueue the packet [6].
Let βn > 0 be the channel fading threshold. Based on
βn, the cumulative distribution function (CDF) of the Rician
distribution is given by:
Pb(˜hf
n < βRice
n
) =
Z βRice
n
0
xe− x2+b2
2
I0(xb) dx
= 1 − Q1(b, βRice
n
),
(5)
where Q1 represents the first-order Marcum Q-function.
Therefore, assuming that |F| represents the cardinality of the
set F, the transmission probability of the source node during
a time slot over the Rician channel can be expressed as:
µn(βRice
n
) = 1 − Pb(˜hf ∗
n < βRice
n
)
= 1 − (1 − Q1(b, βRice
n
))|F |.
(6)
The same approach can be applied to the Rayleigh channel,
where the PDF of the Rayleigh distribution is given by:
Pb(˜hf
n = x) = 2x
Ω e− x2
Ω ,
(7)
where Ω is the Rayleigh fading factor. Then, the CDF of the
Rayleigh distribution is formulated as follows:
Pb(˜hf
n < βRay
n
) =
Z βRay
n
0
2x
Ω e− x2
Ω dx = 1 − e− (βRay
n
)2
Ω
.
Finally, the transmission probability of a packet from source
node in a time slot over the Rayleigh channel is defined as:
µn(βRay
n
) = 1 − (1 − e− (βRay
n
)2
Ω
)|F |.
(8)
Given the presented system model, our goal is to find the
optimal values for the channel fading threshold βn such that
the network throughput is maximized.
III. PROBLEM FORMULATION
In this section, we characterize throughput performance in
terms of its constituent queuing and interference components.
A. Queuing Characterization
We focus on two queue management mechanisms designed
to regulate the number of packets in the queue.
Time Threshold Model. UAVs may communicate delay-
sensitive data such as command-and-control messages. In this
case, it is critical to ensure that data packets are delivered to
their intended destination in a specified timeout value. Assume
that Tn denotes the waiting time in the queue for node n.
When the source node is unable to transmit packets due to poor
channel conditions (e.g., low SINR), any packet with a waiting
time Tn greater than the time threshold T th
n
is discarded.
By using µn(βn) derived from Eq. (6) and Eq. (8) for
Rician and Rayleigh channels in a M/M/1 queue scenario, the
probability of packet loss due to exceeding the time threshold
can be expressed as [6]:
P dly
n (βn) ≜ Pb(Tn > T th
n ) = e−( µn(βn)
Tslt
−λn)T th
n ,
(9)
where Tslt and λn denote the time slot duration and average
incoming packet rate, respectively. In order to determine the
upper bound for βn, an important parameter in our IA-TC
and IA-DTC algorithms, it is known that P dly
n (βn) ≤ 1.
Consequently, the upper bounds for βn in the case of Rician
and Rayleigh channels can be obtained as:
(
Q1(b, βRice
n
) ≥ 1 − (1 − λnTslt)
1
|F | ,
Rician;
βRay
n
≤
q
−Ωln[1 − (1 − Tsltλn)
1
|F | ]
Rayleigh.
(10)
The authors in [6] have provided the derivations under
Rayleigh channel conditions.
Buffer Overflow Model. In addition to time-threshold model
that captures time-sensitivity of data traffics, assume that
queues have limited buffer sizes as well. Therefore, there
are chances that new packet arrivals are inadmissible due to
buffer overflow, and thus they are dropped. By applying the
principles of queuing theory, the probability of exceeding the
buffer capacity in a certain state i can be defined [13], [14]:
Pi,i+1 = P[X1 + ... + Xi+1 > Bn|X1 + ... + Xi ≤ Bn]
=
R Bn
0
P[Xi+1 > Bn − x]fX1+...+Xi(x)dx
P[X1 + ... + Xi ≤ Bn]
,
in which Bn and X denote the buffer capacity and the packet
length, respectively. For the sake of analysis, we assume that
the packet length follows an exponential random variable with
a parameter ηn. Also, fX1+...+Xi(x) represents the PDF of an
i-Erlang distribution, respectively. Hence, the complement of
Pi,i+1 without occurring buffer overflow is defined as:
Pi,i+1 = 1 − Pi,i+1 =
1 − Pi
j=0
(Bnηn)j
j!
e−Bnηn
1 − Pi−1
j=0
(Bnηn)j
j!
e−Bnηn .
(11)
According to the Markov chain, the local balance equation
is πi+1 = ρn(βn)Pi,i+1πi, where ρn(βn) =
λnTslt
µn(βn) is the
offered load. Then, πi can be derived as:
πi = ρi
n(βn)
 i−1
Y
j=0
Pj,j+1

π0 =
ρi
n(βn)

1 −
i−1
X
j=0
(Bnηn)j
j!
e−Bnηn

π0.
(12)
The probability of buffer overflow can be approximated by:
P ov
n (βn) ≈
∞
X
i=0
Pi,i+1πi = (1 − ρn(βn))e−Bnηn(1−ρn(βn))
1 − ρn(βn)e−Bnηn(1−ρn(βn)) .
(13)
Next, we characterize the impacts of interference as a function
of the transmission policy parameter βn.
B. Interference Characterization
In this part, we investigate the impact of interference on the
UAV using the signal-to-interference-plus-noise ratio (SINR).
If the SINR falls below the SINR threshold γth, a transmission
error occurs. Let If
n(β−n) be the impact of the interferer nodes
on the UAV [6]:
If
n(β−n) =
X
m∈N\n
Pm(ˆhf
mn˜hf
mn)2αf
m(βm),
(14)
where the channel fading threshold of the interferer nodes
is defined as β−n ≜ (βm)m∈N\n. Also, αf
m(βm) equals
one if interferer node m transmits using channel f, and zero
otherwise. Thus, the outage probability is defined as:
P out
n
(β) ≜ Pb(γn < γth) = Pb
 
Pn(ˆhf
n)2(˜hf
n)2
σ2 + If
n(β−n)
< γth
!
.
Here, Pn is the transmission power, σ2 = kTW denotes the
thermal noise power where k, T, and W are the Boltzmann’s
constant, temperature, and bandwidth, respectively.
By adopting a classical stochastic geometry approach to
model If
n(β−n) using Gamma distribution, the final expres-
sion for the outage probability is given by [6]:
P out
n
(β) =
Z ∞
βn
Pb(˜hf
n = x)vn(Pn(ˆhf
n)2
γth
x2 − σ2, β−n)dx,
(15)
where Pb(˜hf
n = x) is determined according to the channel’s
type (Rician or Rayleigh) and vn(x, β−n) is the complemen-
tary cumulative distribution function (CCDF) of If
n(β−n).
From [6], we have:
vn(x, β−n) = Pb(If
n(β−n) > x) = 1 −
φ(kn(β−n),
x
θn(β−n))
Γ(kn(β−n))
,
where φ(kn(β−n),
x
θn(β−n)) =
R
x
θn(β−n)
0
skn(β−n)−1e−sds is
the lower incomplete gamma function and Γ(kn(β−n)) =
R ∞
0
xkn(β−n)−1e−xdx is the Gamma function.
C. Throughput Characterization
Given the presented queuing and interference analysis, now
we consider all three packet loss probabilities, namely: (i)
packet loss due to time threshold P dly
n (βn), (ii) packet loss
due to buffer overflow P ov
n (βn), and (iii) packet loss due to
outage and low SINR P out
n
(β). Thus, the probability of overall
loss P loss
n
(β) is determined as:
P loss
n
(β) = P ov
n (βn) + [1 − P ov
n (βn)]P dly
n (βn)+
[1 − P ov
n (βn)][1 − P dly
n (βn)]P out
n
(β).
(16)
Since the products of P dly
n (βn), P ov
n (βn), and P out
n
(β) are
negligible, we consider only the “first order” terms, and thus
the expected throughput can be approximated as [6]:
Rn(β) = λn[1 − P loss
n
(β)] ≈
λn[1 − P dly
n (βn) − P ov
n (βn) − P out
n
(β)].
(17)
Next, we present two transmission policies to maximize the
expected throughput performance by finding the optimal chan-
nel fading threshold β.
IV. PROPOSED TRANSMISSION POLICY ALGORITHMS
Interference-Aware Transmission Control. As mentioned,
our goal is to develop a transmission policy that achieves the
maximum expected throughput for the source node. To this
end, we consider aim to maxβ Rn(β), subject to the upper
bound constraints on βRice
m
and βRay
m
, which should be smaller
than βRice
max and βRay
max, respectively. To solve this problem, we
use a coordinate descent algorithm to maximize a function
(Rn(β)) by adjusting different variables (i.e., components of
the vector β) across each coordinate separately.
At each step, the algorithm focuses on one variable and
updates it, while keeping the other variables constant. In par-
ticular, Algorithm 1 optimizes the expected throughput (Rn)
by adjusting the channel fading thresholds β ≜ {βm, βn} for
the interferer (βm ≜

βRice
m
, βRay
m
	
) and source (βn) nodes.
Consider the same βRice
m
, βRay
m
for all interferers and βn as
three coordinate axes. Initially (lines 5-7), we set βn and βRay
m
as fixed parameters and change βRice
m
by the step of stpm to
determine the best expected throughput (Rbest
n
) in the specified
coordinate. Then (lines 8-11), we repeat the same procedure
while interchanging βRice
m
, βRay
m
, and βn.
To control βm, we set its maximum value as the smallest
upper bound for two types of channels among all interferer
nodes, denoted as βRice
max and βRay
max. However, there is no need
to set a maximum value for βn as it dynamically adjusts itself
through iteration. Also, stopping criteria are based on the max-
imum number of iterations (maxiter) and the condition that
the difference between Rbest
n
and the previous one (Rprev
n
) is
Algorithm 1 Interference-Aware Transmission Control (IA-TC)
1: function IA-TC(βini, βRice
max, βRay
max, stpi, maxiter)
2:
β ← βini, Rbest
n
← Rn(β)
3:
for iter in range maxiter do
4:
Rprev
n
← Rbest
n
5:
if ∃ Rice ∈ m and βRice
m
+ stpm < βRice
max then
6:
β, Rbest
n
= CS(βm, stpm, Rbest
n
, βn)
7:
end if
8:
if ∃ Ray ∈ m and βRay
m
+ stpm < βRay
max then
9:
β, Rbest
n
= CS(βm, stpm, Rbest
n
, βn)
10:
end if
11:
β, Rbest
n
= CS(βn, stpn, Rbest
n
, βm)
12:
if |Rprev
n
− Rbest
n
| < ϵ then
13:
break
14:
end if
15:
end for
16:
return β, Rbest
n
17: end function
lower than ϵ. In the Coordinate Search (CS) function (lines 6,
9, and 11), we explore the coordinate by stpi ≜ {stpm, stpn}
to determine Rbest
n
and β in each coordinate axis.
Remarks. IA-TC algorithm constantly tries to increase βRice
m
and βRay
m
until it reaches the maximum value since the inter-
ferer nodes send fewer packets and the level of interference
on the main link decreases. Furthermore, as βn increases,
the source node enqueues more packets. Thus, while packet
loss in the queue rises, packet loss due to transmission error
decreases. Therefore, as the number of iterations of the IA-TC
algorithm increases, the values of βRice
m
and βRay
m
increases,
and the value of βn decreases. Therefore, the main source
node would have more transmission opportunities, while the
transmission attempts by the interferer nodes decreases. Our
numerical results in Section V confirm this result.
Interference-Aware Distributed Transmission Control.
Here, our goal is to develop a distributed transmission policy
that achieves the maximum expected throughput across all
links, while assuming that each link can be a main link. When
compared to IA-TC, increasing the channel fading threshold
for interferer nodes is no longer optimal because they could
also serve as the main link. In this case, distributed nodes
should coordinate with each other to converge to the optimal
transmission policy that is desirable for all nodes, rather than
just one, as in IA-TC.
We use consensus-based distributed optimization to solve
this problem in which multiple nodes collaborate to reach a
consensus on β. Each node has its own local information and
objective function (Rn(β)), and it communicates iteratively
with its neighbors to find optimal β and maximize Rn(β) [15].
In Algorithm 2, our goal is to determine the optimal set of
channel fading thresholds (β⋆) for nodes. Initially, we start
by setting the channel fading threshold of interferer nodes to
the maximum value, allowing each node to selfishly identify
its best channel fading threshold (βbest
n
) based on the results
obtained from the IA-TC algorithm. During each iteration, if
the difference between the updated channel fading threshold
Algorithm 2 Interference-Aware Distributed Transmission Control
(IA-DTC)
1: function IA-DTC(βmax, ˆm, stp, maxiter)
2:
mprev ← ˆm, β ← βmax
3:
for n in range ˆm do
4:
βn ← β[n], m ← ˆm − {n}
5:
βbest
n
= LCS(maxiter, stp, βn, βm)
6:
βcan[n] ← βbest
n
, ˆm ← mprev
7:
end for
8:
for iter in range maxiter do
9:
β ← βcan
10:
for n in range ˆm do
11:
βn ← β[n], m ← ˆm − {n}
12:
R[iter][n] ← Rn(βn, βm)
13:
βbest
n
= LCS(maxiter, stp, βn, βm)
14:
βcan[n] ← βbest
n
, ˆm ← mprev
15:
end for
16:
if |β − βcan| < ϵ then
17:
β⋆ ← βcan
18:
break
19:
end if
20:
end for
21:
return β⋆, R
22: end function
set and the previous one is greater than ϵ, nodes exchange
information regarding their channel fading thresholds with
each other to determine the optimal channel fading threshold.
In this algorithm, the set
ˆm includes all nodes (source
or interferer), also, n and set m specifies the source node
and interferer nodes, respectively. We introduce the βcan list
to collect the updated channel fading thresholds as different
nodes are selected as the source node. In lines 2-7, the primary
β ≜ (βm, βn)m,n∈N is set to the maximum value of the
channel fading threshold (βmax) according to the upper bound
of it. Then, selfish values of the channel fading threshold are
stored in βcan. In lines 8-20, nodes find their best channel
fading thresholds by β and then update βcan. In each iteration,
Rn(β) for all nodes is stored in R. The Local Coordinate
Search (LCS) function (lines 5 and 13) determines βbest
n
for
each node while having access to βm. This function explores
a coordinate by stp until it finds βbest
n
associated with Rbest
n
.
V. NUMERICAL RESULTS
In our setup, 10 nodes (1 main UAV, 1 interferer UAV, 8
ground nodes) are placed according to the Poisson distribution
in the area, and the main link is established between the source
node (node 8) and the main UAV at 40 m height (node 10),
while other ground nodes (nodes 1 to 7) serve as interferer
nodes communicating with the interferer UAV (node 9). In
our simulations, we assume that the ground nodes experience
the same type of channel conditions (Rician or Rayleigh) to
the main and interferer UAVs. Key simulation parameters are
summarized in Table I.
IA-TC Algorithm Performance. The efficacy of the IA-
TC algorithm is shown in Figures 2 and 3 for three different
interferer UAV heights. From Fig. 2, we observe how the
TABLE I: Key Simulation Parameters
Parameter
Value
Communication Area
100 × 100 m2
PLoS Model
ζ = 20, v = 3 × 10−4, µ = 0.5
Path Loss Model
αLoS = 2, αNLoS = 3.5, d0 = 10 m
Channel Model
|F| = 14, Ω = 2
Rician Factor Model
KLoS = 15, KNLoS = 1
Queuing Model (1)
T th
n = 80 ms, Tslt = 5 ms
Queuing Model (2)
λn = 80, Bnηn = 100
Interference Model
Pi = 0.5 W, γth = 10
Noise Model
f = 2.4 GHz, T = 290 K
IA-TC Algorithm (1)
βini = [3, 2, 4], stpi = [0.05, 0.02]
IA-TC Algorithm (2)
βRice
max = 4.08, βRay
max = 2.57
IA-DTC Algorithm
stp = 0.05, maxiter = 100
source node finds the optimal βn as the IA-TC algorithm
iterates. At the higher altitudes of the interferer UAV (60 m),
the interference impact of the A2A link is larger compared
with lower altitudes. Thus, as the altitude of the inteferer UAV
increases, the source node chooses larger βn values, thereby
enqueuing more packets instead of transmitting to the main
UAV. In Fig. 2, initially the source node increases βn since
βm are small, but, as the IA-TC algorithm increases βm, the
source node gradually decreases βn, which means that the
source node would try transmitting more often due to lower
interference. In Fig. 3, we report the throughput performance
of the source node as the IA-TC algorithm iterates, which
results in a higher Rn. Furthermore, Rn increases as the
altitude of the interferer UAV decreases, as expected. In the
lower altitudes of the interferer UAV (10 m), we achieve the
largest Rn, since the interferer UAV is located near ground
level, its impact is not as significant as the higher altitudes.
IA-DTC Algorithm Performance. Fig. 4 shows that how
the optimal channel fading threshold of the source node (β⋆
n)
changes as a function of the number of nodes and for different
γth values. From the results, we observe that as the number
of nodes increases, the source node increases the level of β⋆
n
due to the stronger impact of the interferer nodes. As a result,
by increasing the number of nodes and γth, the source node
acts more conservatively (i.e., fewer transmission attempts)
and increases its β⋆
n.
In Fig. 5, we present a comparative analysis of the IA-DTC
algorithm output, denoted as β⋆, compared to four baseline
transmission policies: (i) Random policy: Different nodes
select their transmission threshold randomly between zero and
the upper bound. (ii) Aggressive policy: Different nodes select
their transmission threshold such that the probability of packet
drop from the queue (due to overflow or time-threshold) is
minimized. In this case, nodes attempt to transmit despite
poor channel conditions. (iii) Selfish policy: Different nodes
do not cooperate with each other, and treat other nodes as
interference. (iv) Conservative policy: Different nodes select
their transmission threshold to be close to the upper bound
values, and thus they aim to minimize outage probability, while
increasing the likelihood of packet loss from queues. From
the results in Fig. 6, we observe that the IA-DTC algorithm
0
3
6
9
12
15
18
21
Number of Iterations
3.85
3.90
3.95
4.00
4.05
4.10
Channel Fading Threshold (
n)
Interferer UAV Height = 60 m
Interferer UAV Height = 30 m
Interferer UAV Height = 10 m
Fig. 2: βn vs. # of Iterations by IA-TC
0
3
6
9
12
15
18
21
Number of Iterations
73
74
75
76
77
78
79
80
Expected Throughput (Pkts/Sec)
Interferer UAV Height = 60 m
Interferer UAV Height = 30 m
Interferer UAV Height = 10 m
Fig. 3: Rn vs. # of Iterations by IA-TC
5
8
10
12
15
SINR Threshold (
th)
4.4
4.5
4.6
4.7
4.8
4.9
5.0
Optimal Channel Fading Threshold (
n)
Number of Nodes = 5
Number of Nodes = 7
Number of Nodes = 10
Fig. 4: β⋆
n vs. γth by IA-DTC
1
2
3
4
5
6
7
8
9
Node ID
0.5
1.5
2.5
3.5
4.5
5.5
6.5
Channel Fading Threshold (
i)
Random Policy
Aggressive Policy
Selfish Policy
IA-DTC Algorithm
Conservative Policy
Fig. 5: βi vs. Node ID by IA-DTC
1
2
3
4
5
6
7
8
9
Node ID
0
10
20
30
40
50
60
70
80
Expected Throughput (Pkts/Sec)
Random Policy
Aggressive Policy
Selfish Policy
IA-DTC Algorithm
Conservative Policy
Fig. 6: Rn vs. Node ID by IA-DTC
1
2
3
4
5
6
7
8
9
Node ID
2.0
2.5
3.0
3.5
4.0
4.5
5.0
5.5
6.0
6.5
Optimal Channel Fading Threshold (
i )
SINR Threshold (
th) = 5
SINR Threshold (
th) = 8
SINR Threshold (
th) = 10
SINR Threshold (
th) = 12
SINR Threshold (
th) = 15
Fig. 7: β⋆
i vs. Node ID by IA-DTC
achieves the highest Rn compared with all other baselines.
Furthermore, Fig. 7 demonstrates the behavior of the IA-DTC
algorithm as γth changes. Clearly, as γth increases, nodes
increase their optimal channel fading thresholds (β⋆
i ) since
they require a better channel condition to send their packets,
which means that they prefer to enqueue their packets rather
than sending them to the UAVs.
VI. CONCLUSION
In this paper, we investigated the problem of distributed
transmission control for UAVs operating in unlicensed spec-
trum bands. We developed an analytical interference-aware
queuing analysis framework that jointly considers three types
of packet losses including packet drop due to exceeding the
time threshold (P dly
n (βn)), buffer overflow (P ov
n (βn)), and
low SINR (P out
n
(β)). Using this analysis, we were able to
calculate the throughput performance Rn according to the
probability of overall loss. In the transmission policy section,
we proposed two algorithms IA-TC and IA-DTC to control β
for each node to improve Rn. We numerically investigated the
performance of our algorithms, and confirmed that it achieves
the optimal solution. As a future direction, we aim to extend
our analysis to model-free analysis and optimization solutions.
ACKNOWLEDGMENT
The material is based upon work supported by NASA under
award No(s) 80NSSC20M0261, and NSF grants 1948511,
1955561, and 2212565. Any opinions, findings, and conclu-
sions or recommendations expressed in this material are those
of the author(s) and do not necessarily reflect the views of
NASA and NSF.
REFERENCES
[1] B. Badnava, T. Kim, K. Cheung, Z. Ali, and M. Hashemi, “Spectrum-
aware mobile edge computing for UAVs using reinforcement learning,”
2021 IEEE/ACM Symposium on Edge Computing (SEC), 2021.
[2] K. Meng, Q. Wu, S. Ma, W. Chen, and T. Q. S. Quek, “UAV trajectory
and beamforming optimization for integrated periodic sensing and
communication,” IEEE Wireless Communications Letters, 2022.
[3] B. Badnava, K. Roach, K. Cheung, M. Hashemi, and N. B. Shroff,
“Energy-efficient deadline-aware edge computing: Bandit learning with
partial observations in multi-channel systems,” arXiv:2308.06647, 2023.
[4] S. Reddy Chintareddy, K. Roach, K. Cheung, and M. Hashemi, “Collab-
orative wideband spectrum sensing and scheduling for networked UAVs
in UTM systems,” arXiv:2308.05036, 2023.
[5] P. S. Bithas and A. L. Moustakas, “Generalized UAV selection with
distributed transmission policies,” IEEE Transactions on Comm., 2023.
[6] Z. Guan, T. Melodia, and G. Scutari, “To transmit or not to transmit?
distributed queueing games in infrastructureless wireless networks,”
IEEE/ACM Transactions on Networking, 2016.
[7] P. S. Bithas, V. Nikolaidis, A. G. Kanatas, and G. K. Karagiannidis,
“UAV-to-ground communication: Channel modeling and UAV selec-
tion,” IEEE Transactions on Communications, 2020.
[8] J. Cui, Z. Ding, Y. Deng, and A. Nallanathan, “Model-free based
automated trajectory optimization for UAVs toward data transmission,”
2019 IEEE Global Communications Conference (GLOBECOM), 2019.
[9] M. Kim and J. Lee, “Impact of an interfering node on unmanned aerial
vehicle communications,” IEEE Trans. on Vehicular Technology, 2019.
[10] Z. Ren, G. Wang, Q. Chen, and H. Li, “Modelling and simulation of
rayleigh fading, path loss, and shadowing fading for wireless mobile
networks,” Simulation Modelling Practice and Theory, 2011.
[11] M. M. Azari, F. Rosas, K.-C. Chen, and S. Pollin, “Ultra reliable UAV
comm. using altitude and coop. diversity,” IEEE Trans. on Comm., 2018.
[12] M. Kim and J. Lee, “Outage probability of UAV communications in the
presence of interference,” 2018 IEEE Global Comm. Conf., 2018.
[13] D. Gross, J. F. Shortle, J. M. Thompson, and C. M. Harris, Fundamentals
of Queueing Theory.
Wiley-Interscience, 2008.
[14] M. Ghazikor, K. Roach, K. Cheung, and M. Hashemi, “Exploring the
interplay of interference and queues in unlicensed spectrum bands for
UAV networks,” arXiv:2308.05187, 2023.
[15] A. S. Berahas, R. Bollapragada, N. S. Keskar, and E. Wei, “Balancing
comm. and comp. in dist. opt.” IEEE Trans. on Auto. Control, 2019.
"
"Homomorphic encryption (HE) enables privacy-preserving cloud computing by allowing direct computations on ciphertexts. The computations involve modular reduction, and the overall complexity of ciphertext multiplication can be reduced by utilizing the quotient. Previous work considers the cases that the dividend is an integer multiple of the modulus and the modulus is in the format of 2w − 2u ± 1, where u < w/2. This paper generalizes the division for larger u and dividend not an integer multiple of the modulus. An algorithm is proposed to compute the quotient, and efficient hardware architecture is developed for implementing the algorithm.nan","Homomorphic encryption (HE) allows computations to be carried out on ciphertexts without decryption. Popular HE schemes involve computations over very long polynomials, whose coefficients are large integers, and coefficient multiplication and addition are followed by modular reduction. To reduce the computation complexity, the large coefficients are represented by residue number system, and moduli with a small number of nonzero bits are chosen. It was found in [5] that the overall complexity of ciphertext multiplication can be reduced by combining and reformulating the coefficients multiplication and relinearization, which is enabled by using the quotient of dividing coefficients product by q.nan","The division can be implemented by using a look-up table [6]. However, the size of the look-up table increases exponentially with the number of bits to divide in each clock cycle. Approximate division by very short integers, such as 8-bit, has been investigated for image processing in [7], [8]. The approximations in these schemes lead to a big difference in the quotient for large q. In [9], the quotient is derived by multiplying an approximation of q⁻1. To improve the precision, 2w bits are used to represent the approximation when q has w bits. The dividend is a product of two w-bit coefficients and also has 2w bits. Hence, a 2w × 2w wide multiplier is needed, and it leads to not only a long data path but also a large area. To address these issues, the quotient is calculated as a × λ + b, and then the least significant bits are deleted in [10]. Here a and b are precomputed constants with at most w bits. Although the width of the multiplicand is reduced, a wide multiplier is still needed for this design.nannan","The design in [5] assumes that q = 2w − 2u ± 1. Utilizing the property that q has a small number of nonzero bits, the quotient is calculated by addition and shift operations that have much shorter data path and smaller area requirements compared to those multiplying approximation of q⁻1 as in [9], [10]. However, the design in [5] is limited to the case of u < w/2, and the dividend is an integer multiple of q. Given the product of two coefficients, its remainder of division by q needs to be calculated and subtracted first before the division can be carried out.nan","For w = 32, there are 31 different possible u. For 50%, 16%, and 9% of these possible values of u, the proposed design achieves 55%, 32%, and 9% shorter latency, respectively, and at least 79% silicon area reduction compared to the divider in [10].nan","This paper proposed a low-complexity integer divider for calculating the quotient when the divisor has a small number of nonzero bits. It generalized the previous design to handle more possible divisors and the case that the dividend is not an integer multiple of the divisor. In addition, by analyzing the possible values of the intermediate results, simplifications on the hardware implementation architectures are developed. Compared to prior designs that are based on multiplying the inverse of the divisor, the proposed design reduces the area requirement to a fraction and also has much shorter latency.nan",Low-Complexity Integer Divider Architecture for Homomorphic Encryption,"Sajjad Akherati, Jiaxuan Cai, Xinmiao Zhang","arXiv:2401.11064v1  [cs.CR]  19 Jan 2024
Low-Complexity Integer Divider Architecture for
Homomorphic Encryption
Sajjad Akherati, Jiaxuan Cai, and Xinmiao Zhang
The Ohio State University, OH 43210, U.S.
Abstract—Homomorphic encryption (HE) allows computations
to be directly carried out on ciphertexts and enables privacy-
preserving cloud computing. The computations on the coefﬁcients
of the polynomials involved in HE are always followed by
modular reduction, and the overall complexity of ciphertext
multiplication can be reduced by utilizing the quotient. Our
previous design considers the cases that the dividend is an integer
multiple of the modulus and the modulus is in the format of
2w − 2u ± 1, where u < w/2. In this paper, the division is
generalized for larger u and dividend not an integer multiple of
the modulus. An algorithm is proposed to compute the quotient
and vigorous mathematical proofs are provided. Moreover, efﬁ-
cient hardware architecture is developed for implementing the
proposed algorithm. Compared to alternative division approaches
that utilize the inverse of the divisor, for w = 32, the proposed
design achieves at least 9% shorter latency and 79% area
reduction for 75% possible values of u.
I. INTRODUCTION
Homomorphic encryption (HE) allows computations to be
carried out on ciphertexts without decryption. It is the key to
preserving privacy in cloud computing. Popular HE schemes
[1]–[3] involve computations over very long polynomials,
whose coefﬁcients are large integers, and coefﬁcients mul-
tiplication and addition are followed by modular reduction.
To reduce the computation complexity, the large coefﬁcients
are represented by residue number system [4], and moduli
with a small number of nonzero bits, such as in the format
of q = 2w − 2u ± 1, are chosen. It was found in [5] that the
overall complexity of ciphertext multiplication can be reduced
by combining and reformulating the coefﬁcients multiplication
and relinearization, which is enabled by using the quotient of
dividing coefﬁcients product by q.
The division can be implemented by using a look-up table
[6]. However, the size of the look-up table increases expo-
nentially with the number of bits to divide in each clock
cycle. Approximate division by very short integers, such as
8-bit, has been investigated for image processing in [7], [8].
The approximations in these schemes lead to a big difference
in the quotient for large q. In [9], the quotient is derived
by multiplying an approximation of q−1. To improve the
precision, 2w bits are used to represent the approximation
when q has w bits. The dividend is a product of two w-bit
coefﬁcients and also has 2w bits. Hence, a 2w × 2w wide
multiplier is needed, and it leads to not only a long data path
but also a large area. To address these issues, the quotient
is calculated as a × λ + b, and then the least signiﬁcant bits
This work is supported in part by Cisco Systems.
are deleted in [10]. Here a and b are precomputed constants
with at most w bits. Although the width of the multiplicand
is reduced, a wide multiplier is still needed for this design.
The design in [5] assumes that q = 2w − 2u ± 1. Utilizing
the property that q has a small number of nonzero bits, the
quotient is calculated by addition and shift operations that
have much shorter data path and smaller area requirements
compared to those multiplying approximation of q−1 as in
[9], [10]. However, the design in [5] is limited to the case of
u < w/2, and the dividend is an integer multiple of q. Given
the product of two coefﬁcients, its remainder of division by q
needs to be calculated and subtracted ﬁrst before the division
can be carried out.
This paper proposes a generalized low-complexity integer
division algorithm and implementation architecture. An itera-
tive process is developed to compute the quotient in the case
of u ≥ w/2, where each iteration consists of simple addition
and shift operations. The number of iterations needed is a
small value depending on the ratio of u/w. Mathematical
formulas and corresponding proofs are given for the number
of iterations. Unlike the algorithm in [5], the proposed design
does not require the dividend to be an integer multiple of q and
hence does not need a separate remainder calculation. Instead,
the quotient computed from the iterative process is adjusted
to take into account the remainder. Efﬁcient hardware imple-
mentation architectures are also developed for the proposed
algorithm and synthesis has been carried out. For w = 32,
there are 31 different possible u. For 50%, 16%, and 9% of
these possible values of u, the proposed design achieves 55%,
32%, and 9% shorter latency, respectively, and at least 79%
silicon area reduction compared to the divider in [10].
II. EXISTING INTEGER DIVIDERS
Consider λ/q where λ and q have 2w and w bits, respec-
tively. In [9], the quotient of λ/q is calculated by multiplying
λ with a pre-computed constant J = ⌊23w−1/q⌋ + 1. The
higher w bits of this product is the quotient of λ/q. J has
2w bits in order to ensure the correctness of the quotient. The
design in [10] calculates the quotient as ⌊(aλ+b)/2k⌋, where
a, b and k are constants pre-computed according to q. a is
an (k − w)-bit number, where w < k ≤ 2w. Consequently,
the width of the multiplier needed is reduced. However, the
quotient computed from this algorithm can be different from
the actual quotient by ±1.
The design in [5] assumes q = 2w−2u±1, u < w/2, and λ
is an integer multiple of q. Let c = ⌊λ/2w⌋. It ﬁrst calculates
b∗ = c − ⌊ −c(2u∓1)
2w
⌋. It was shown that λ/q equals b∗ when
b∗ and λ are both even or odd. Otherwise, λ/q = b∗ + 1. As
a result, the division was implemented by two adders and two
shifters.
III. GENERALIZED LOW-COMPLEXITY INTEGER DIVISION
This section ﬁrst generalizes the previous division algorithm
in [5] to the case of q = 2w − 2u ± 1 with u ≥ w/2. Then the
design is further extended to the case that λ is not an integer
multiple of q.
A. Extension for u ≥ w/2 with λ as an integer multiple of q
Denote the quotient of λ/q by b (b ∈ Z+). Replace q by
2w − 2u ± 1 in λ = bq. Then c = ⌊λ/2w⌋ can be rewritten as
c = ⌊ bq
2w ⌋ = b + ⌊(−1) b(2u∓1)
2w
⌋. Deﬁne
f(x) ≜ x + v(x),
(1)
where
v(x) ≜ ⌊(−1)x(2u ∓ 1)
2w
⌋.
(2)
b is the solution of f(x) = c. This solution can be found
iteratively using Algorithm 1. In this algorithm, the least
signiﬁcant bit (LSB) of a number y is denoted by LSB(y).
Algorithm 1 Algorithm for calculating b = λ/q (λ is an
integer multiple of q)
Input: λ, q = 2w − 2u ± 1, w, u
1: c ← ⌊ λ
2w ⌋; i ← 0; b0 ← c;
2: while f(bi) ̸= c do
3:
bi+1 ← bi + (c − f(bi)); i ← i + 1; b∗ ← bi;
4: b ← b∗ + (LSB(λ) XOR LSB(b∗));
5: return b;
In the following, Theorem 1 proves that the loop in Al-
gorithm 1 will terminate with a ﬁnite number of iterations.
Theorem 2 connects the b∗ computed from the loop with the
actual b value. The number of iterations needed in Algorithm
1 is given through Theorem 3 and 4.
Theorem 1. Algorithm 1 will terminate with a ﬁnite number
of iterations.
Proof. By induction, it is shown in the following that
f(bi−1) < f(bi) ≤ c. Using the properties of the ﬂoor
function, it can be derived that f(x) + f(y) ≤ f(x + y) ≤
f(x) + f(y) + 1. Besides, from (2), it can be easily seen that
0 < f(x) < x for x > 0. Hence, for i = 1:
f(b1)=f(b0+c−f(b0))≥f(b0)+f(c−f(b0))
=f(b0)+f(c−f(c))>f(b0)
Similarly,
f(b1)≤f(b0)+f(c−f(b0))+1<f(b0)+(c−f(b0))+1=c+1.
Since f(b1) is integer, f(b1) ≤ c. Assume that f(bi−2) <
f(bi−1) ≤ c, similar derivations as in the above two formulas
show that f(bi−1) < f(bi) ≤ c. Since f(bi) strictly increases
with iteration i and it is always an integer not exceeding c,
f(bi) will equal to c in an iteration and the loop in Lines 2
and 3 of Algorithm 1 terminates.
Theorem 2. The bi in every iteration of Algorithm 1 is at
most b.
Proof. This is proved by induction. Since c = b + v(b) and
v(b) ≤ 0, it is clear that b0 = c ≤ b. Now suppose that bi ≤ b.
From Algorithm 1, if bi = b, then the loop terminates and there
will be no other b′
i with i′ > i. If bi < b, then v(b) ≤ v(bi)
from (2). Accordingly,
bi+1 = bi + c − f(bi) = bi + c − (bi + v(bi))
= c − v(bi) = b + v(b) − v(bi) ≤ b.
Theorem 2 shows that the b∗ calculated by the loop in
Algorithm 1 does not exceed b. Next, it will be shown that
b∗ equals either b − 1 or b. From (1), f(b) = b + v(b) and
f(b−1) = b−1+v(b−1). Since v(b−1) = v(b) or v(b)+1,
f(b − 1) = f(b) or f(b) − 1. If f(b − 1) = f(b) = c then
the b∗ from the loop in Algorithm 1 may be either b − 1 or b.
Similarly, it can be shown that f(b−2) = f(b)−1 or f(b)−2.
Hence, f(b−2) ̸= c and b∗ can not be b−2 or a smaller value.
Since q is an odd number, b is even or odd when λ is even or
odd, respectively. Hence, whether b equals b∗ or b∗ + 1 can
be decided by using the LSB of λ and b∗ as listed in Line 4
of Algorithm 1.
The initial value of b0 should be less than b, which is
unknown at the beginning of Algorithm 1. On the other hand,
initializing b0 to the smallest positive integer, 1, leads to more
iterations in Algorithm 1. Since c ≤ b, c is chosen as the initial
value in our algorithm. With this initial value, c − f(bi) is the
largest value that can be used to update f(bi) as proposed in
Algorithm 1. Consider the case that b = 2 and u < w − 2.
Then c = 1 and f(b0) = f(c) = f(1) = 0. If c − f(b0) + j
(j ≥ 1) is used to update bi. Then b1 = b0+(c−f(b0)+j) ≥ 3
and f(3) = 2 > c. Hence, Algorithm 1 will not terminate and
c − f(bi) + j with j ≥ 1 can not be used to update f(bi).
Theorem 3. Suppose that the number of iterations to calculate
b = λ
q (λ < 22w − 1) and bMAX ≜ ⌊ 22w−1
q
⌋ from Algorithm 1
are N and NMAX, respectively. Then N ≤ NMAX.
Proof. Let cMAX = ⌊(22w −1)/2w⌋ and bMAXi be the interme-
diate value at iteration i of Algorithm 1 for calculating bMAX.
It is shown below that b − bi ≤ bMAX − bMAXi by induction.
It can be derived that
b − b0 = b − ⌊ bq
2w ⌋ < b − bq
2w + 1 = b(1 − q
2w ) + 1
≤ bMAX(1 − q
2w ) + 1 = bMAX − bMAXq
2w
+ 1
< bMAX − ⌊bMAXq
2w
⌋ + 1 = bMAX − bMAX0 + 1.
b and b0 are integers, and hence b − b0 ≤ bMAX − bMAX0.
Suppose that for iteration i < N, b − bi ≤ bMAX − bMAXi.
For i + 1 < N
b − bi+1 = b − (bi + c − f(bi)) = b − c + v(bi)
< b − c − bi(2u ∓ 1)
2w
< b − bq
2w − bi(2u ∓ 1)
2w
+ 1
= (b − bi)2u ∓ 1
2w
+ 1 ≤ (bMAX − bMAXi)2u ∓ 1
2w
+ 1
= bMAX − bMAXq
2w
− bMAXi(2u ∓ 1)
2w
+ 1
= bMAX − ⌊bMAXq
2w
⌋ + ⌊(−1)bMAXi(2u ∓ 1)
2w
⌋
+ 1 + −[bMAXq]2w + [−bMAXi(2u ∓ 1)]2w
2w
,
where [·]2w denotes the remainder of dividing by 2w. It can
be shown that 0 < 1+
−[bMAXq]2w +[−bMAXi(2u∓1)]2w
2w
< 1. Since
b − bi+1 is an integer,
b − bi+1 ≤ bMAX − cMAX + v(bMAXi) = bMAX − bMAXi+1.
Algorithm 1 terminates at iteration N when λ is the input.
From previous analysis, bN equals either b or b − 1. From the
above proof, bMAX−bMAXN ≥ b−bN. Hence bMAX−bMAXN ≥
0. On the other hand, bMAX − bMAXN−1 ̸= 0. Otherwise, the
algorithm with λ as the input already terminates at iteration
N −1 and this contradicts the assumption. Accordingly, when
the input of Algorithm 1 is 22w−1, it may need more than N
iterations to compute bMAX and hence NMAX ≥ N.
Theorem 4. For q = 2w − 2u ± 1, let t be the integer such
that tu > (t − 1)w and (t + 1)u ≤ tw. Then NMAX = t.
Proof. Clearly cMAX = 2w − 1. From Algorithm 1
bMAX1 = bMAX0 + cMAX − f(bMAX0) = cMAX − v(cMAX)
= 2w − 1 − ⌊(−1)(2w − 1)(2u − 1)
2w
⌋ = 2w + 2u − 2.
By substituting the above formula into Line 3 of Algorithm
1 for i iterations, it can be derived that bMAXi = 2w + 2u +
22u−w + 23u−2w + · · · + 2iu−(i−1)w − {1 or 2}. It can be
derived that f(bMAXi) ̸= cMAX for i < t, where t is the integer
such that tu > (t − 1)w and (t + 1)u ≤ tw. On the other
hand, f(bMAXt) = cMAX. This means that Algorithm 1 needs
t iterations to terminate when its input is 22w − 1.
From Theorem 3 and 4, Algorithm 1 needs at most t
iterations, where t is the integer such that tu > (t − 1)w
and (t + 1)u ≤ tw. For u ≤ 3/4w, Algorithm 1 terminates in
at most 3 iterations. Algorithm 1 still applies when u < w/2,
in which case t = 1 and Algorithm 1 reduces to the same
algorithm as in [5].
B. Extension for λ not an integer multiple of q
Assume that λ = bq + r, where 0 ≤ r < q. If r = 0, it
reduces to the case covered in Subsection A, and the loop in
Algorithm 1 returns a b∗ that equals b or b−1 from the previous
analysis. Consider the case of 0 < r < q, λ < λ′ = (b + 1)q.
Feeding λ′ as the input of Algorithm 1, the loop would return
a b∗ that is either b + 1 or b. Therefore, b may have three
possible values: b∗, b∗ + 1 or b∗ − 1.
Since λ = bq + r, λ − b∗q should equal r + q, r, and
r − q when b∗ is b − 1, b, and b + 1, respectively. After b∗ is
calculated, λ − b∗q can be computed. Since r − q < 0 < r <
q < r + q, b is set to b∗ − 1, b∗, and b∗ + 1 when λ − b∗q is
less than 0, between 0 and q, and larger than q, respectively.
As a result, the quotient of dividing a λ that is not necessarily
an integer multiple of q can be calculated using Algorithm 2.
Algorithm 2 Algorithm for calculating ⌊b = λ/q⌋
Input: λ, q = 2w − 2u ± 1, w, u
1: c ← ⌊ λ
2w ⌋; i ← 0; b0 ← c;
2: while f(bi) ̸= c do
3:
bi+1 ← bi + (c − f(bi)); i ← i + 1; b∗ ← bi;
4: r∗ ← λ − b∗q; b ← b∗;
5: if r∗ < 0 then b ← b − 1;
6: else if r∗ ≥ q then b ← b + 1;
7: return b;
IV. DIVIDER HARDWARE IMPLEMENTATION
ARCHITECTURES AND COMPARISONS
This section ﬁrst proposes efﬁcient hardware architectures
to implement the proposed divider. Then comparisons with
other dividers are provided.
When u < w/2, Algorithm 2 has one iteration in the
loop and it reduces to the algorithm proposed in [5]. The
hardware architecture for implementing one iteration of Line
3 of Algorithm 2 is available in [5]. bi+1 = bi + c− f(bi) can
be simpliﬁed as c + ⌊ bi(2u∓1)
2w
⌋ + D. From [5], D = 0 when
bi(2u ∓ 1)/2w is an integer and D = 1 otherwise. However,
since bi is a w-bit number, it does not have w factors of 2.
2u∓1 does not have any factor of 2. Therefore, bi(2u∓1)/2w
can not be an integer, and the architecture from [5] can be
simpliﬁed to the units in the dashed block in Fig. 1. t copies
of these units are needed to implement t iterations of the
loop in Algorithm 2 in a pipelined manner. The shifters align
the bits in the inputs to take care of the 2u multiplication
and 2w division. The control signal s is ‘1’ and ‘0’ when
q = 2w − 2u + 1 and q = 2w − 2u − 1, respectively. cini is
set to ‘1’ when the lower u bits of bi are all ‘0’ and s = 1
in order to eliminate the addition on unnecessary bits. More
explanations on these signals can be found in [5].
From previous analysis, λ − b∗q ∈ {r, r ± q}. Hence, the
exact value of λ − b∗q does not need to be calculated. It is
sufﬁcient to know if λ−b∗q is negative, positive and less than
q, or positive and larger than or equal to q. For q = 2w−2u±1,
the numbers that need to be added to calculate λ − b∗q are
shown in Fig. 2(a). Since r < r + q < 2w+1, if λ − b∗q is
positive, all its bits with weight at least 2w+1 are ‘0’. On the
other hand, |r − q| < 2w. Hence, all the bits with weight at
least 2w+1 are ‘1’ in the 2’s complement representation of
r − q. Therefore, it is sufﬁcient to tell that λ − b∗q is negative
if the (w+2)-th bit in λ−b∗q is ‘1’. If this bit is ‘0’, whether
λ − b∗q = r or r + q can be decided by comparing the lower
w + 1 bits of λ − b∗q with q. As a result, only the w + 2 least
signiﬁcant bits of the numbers in Fig. 2 need to be added.
Shifter
Shifter
b0
u
cin1
wͲu
1
b1
0
1
D
Shifter
Shifter
btͲ1
u
cint
wͲu
bt=b*
0
1
Shifter
Shifter
b1
u
cin2
wͲu
b2
0
1
D
...
D
s
c
...
......
...
...
Figure 1: Architecture for calculating b∗ in Algorithm 2.
Ͳb*
b*
Ͳ/+b*
u
wͲu
u
ʄ
Shifter
b*
u
ʄ[w+1:0]
Comparator
q
(a)
(b)
b
b*+1 b*Ͳ1 b*
‘00’
w
w+2
1
‘0...0’
w
w+2
w+2
w+2
w
w+1
s
MSB
w
w+2
2
Figure 2: (a) The numbers need to be added for calculating
λ − b∗q; (b) The hardware architecture to derive b from b∗
using partial calculation of λ − b∗q.
The architecture in Fig. 2(b) computes b from b∗. First ‘00’
is padded to the left of the most signiﬁcant bit (MSB) of b∗
to extend it to (w + 2)-bit. The multiplexer on the top passes
either 2’s complement of b∗ or b∗ depending on whether the
last number to add in Fig. 2(a) is −b∗ or +b∗. The shifter in
Fig. 2(b) shifts the lower w − u + 2 bits of the input to the
left and pads u ‘0’s to the right. It aligns the bits from the b∗
number in the middle of Fig. 2(a) for addition. Only the two
LSBs of the −b∗ number in Fig. 2(a) need to be added. They
are padded with w ‘0’s to the right for the addition. The four
numbers from Fig. 2(a) are added up by the carry-save adder
in the middle of Fig. 2(b). The lowest w + 1 bits of the adder
output is compared with q. The value for b is chosen based
on the MSB of the adder output and the comparison result.
To further evaluate the complexity of our proposed design,
it is synthesized using the Global Foundries 22FDX process
for an example case of w = 32 and 2w/3 ≤ u < 3w/4.
In this case, t = 3 copies of the units in Fig. 1 are needed.
Different timing constraints were tried in the synthesis, and
the tightest timing constraint that does not lead to a substantial
area increase is reported in Table I in order to compare the
minimum achievable clock period of different designs. In the
proposed design, t = 3 copies of units compute b∗ in three
pipelining stages. After that, another clock cycle is needed to
calculate b.
Table I: Synthesis results of dividers with w = 32 using Global
Foundries 22FDX process
Timing
Area
Latency
constraint (ps)
(µm2)
(# of clks)
Design in [9]
2600
11168
1
Design in [10]
1460
6140
1
Proposed design (t = 3)
330
1320
4
For comparison, the designs in [9] and [10] are synthesized
and the results are also listed in Table I. They have 2w × 2w
and 2w×w multipliers, respectively, in their critical paths. On
the other hand, the critical path of our proposed design only
consists of a shifter, a w-bit carry-save adder, a comparator,
and a few multiplexers as shown in Fig. 2. As a result, our
design achieves a much shorter clock period. The achievable
improvement further increases for larger w. Although our
design requires t+1 clock cycles to compute the quotient, the
latency is still lower than that of the previous design due to
the shorter clock period. For w = 32, t = 1 for 1 ≤ u < 16,
t = 2 for 16 ≤ u < 22, and t = 3 for 22 ≤ u < 24.
Hence 75% of possible u leads to t ≤ 3. Our proposed design
achieves 1 − 330 × 4/1460 = 9%, 1 − 330 × 3/1460 = 32%
and 1 − 330 × 2/1460 = 55% latency reductions for t = 3, 2,
and 1, respectively, compared to the divider in [10].
Since the designs in [9] and [10] consist of wide multipliers,
their area requirement is much larger than that of the proposed
design as shown in Table I. The proposed architecture achieves
1-1320/6140=79% area reduction compared to the design in
[10]. For a u corresponding to smaller t, fewer copies of the
units in Fig. 1 are utilized, and the achievable area reduction
would be more signiﬁcant.
V. CONCLUSIONS
This paper proposed a low-complexity integer divider for
calculating the quotient when the divisor has a small number
of nonzero bits. It generalized the previous design to handle
more possible divisors and the case that the dividend is not
an integer multiple of the divisor. In addition, by analyzing
the possible values of the intermediate results, simpliﬁcations
on the hardware implementation architectures are developed.
Compared to prior designs that are based on multiplying the
inverse of the divisor, the proposed design reduces the area
requirement to a fraction and also has much shorter latency.
Future research will extend the proposed algorithm to the case
that the divisor has more than three nonzero bits.
REFERENCES
[1] Z. Brakerski, C. Gentry, and V. Vaikuntanathan, “(Leveled) fully homo-
morphic encryption without bootstrapping,”
Proc. of ACM Innovation
in Theoretical Computer Science, pp. 309-325, 2012.
[2] Z. Brakerski, “Fully homomorphic encryption without modulus switch-
ing from classical GapSVP,” Lecture Notes in Computer Science, vol.
7417, pp. 868-886, Springer, 2012.
[3] J. H. Cheon, A. Kim, M. Kim, and Y. Song, “Homomorphic encryption
for arithmetic of approximate numbers,” Advances for Cryptology-
ASIACRYPT, pp. 409-437, 2017.
[4] J. H. Cheon, K. Han, A. Kim, M. Kim, and Y. Song, “A full RNS
variant of the approximate homomorphic encryption,” Selected Areas in
Cryptography, pp. 347–368, 2018.
[5] S. Akherati, X. Zhang, “Low-complexity ciphertext multiplication for
CKKS homomorphic encryption,” IEEE Trans. on Circuits and Syst.-II,
2023.
[6] F. Dinechin, L. Didier, “Table-based division by small integer constants,
reconﬁgurable computing: architectures, tools and applications,” Lecture
Notes in Computer Science, vol. 7199, pp. 53-63, 2012.
[7] D. Kromichev, “FPGA based Canny: advanced integer division algo-
rithm,” 2021 12th National Conf. with Int. Participation, pp. 1-4, 2021.
[8] D. Kromichev, “FPGA based edge detection: integer division algorithm
with a constant divisor,” 13th National Conf. with Int. Participation, pp.
1-4, 2022.
[9] D. Cavagnino and A. E. Werbrouck, “Efﬁcient algorithms for integer
division by constants using multiplication,” The Computer Journal, vol.
51, no. 4, pp. 470-480, 2008.
[10] T. Drane, W. -C. Cheung and G. Constantinides, “Correctly rounded
constant integer division via multiply-add,” IEEE Intl. Symp. on Circuits
and Sys., pp. 1243-1246, 2012.
Shifter
Shifter
b*
m
 1
n-m
b*
-b*
 2
-/+b*
r*
Comparator/
b calculation
q
"
"nanIn scenarios where data is limited or incomplete, machine learning classification models face challenges. The Small and Incomplete Dataset Analyser (SaNDA) emerged as a suitable technique to improve performance in these situations by leveraging data abstractions. This paper evaluates how modifying the abstraction methods affects the SaNDA classification process's explainability and accuracy. We investigate alternative abstraction techniques, constant binning and quantiles, in contrast to the conventional ROC curve-based method. Our experiments on 13 small and two medium datasets, including synthetic DIGEN datasets, provide empirical evidence. The findings suggest that quantile-based abstractions (quantiles 20) offer better classification performance compared to constant binning or the original ROC curve method. The number of categories produced by the abstraction method is of greater significance than the type of abstraction used, influencing accuracy. Increasing the abstraction levels consistently enhances performance but introduces limitations related to statistical representation, explainability, and computational efficiency. Our modified SaNDA with quantiles 20 abstraction method exhibits promising potential as an alternative to Random Forest for complete datasets and demonstrates its advantage with missing data. Future work may involve developing a dynamic approach to selecting methods and abstraction levels, allowing for customization to specific problem requirements.","nan{'Relevance_of_Data_Abstraction_Methods': 'The applicability of widely adopted machine learning (ML) methods to classification for Critical Decision-Making (CDM) processes is circumscribed by the imperatives of explicability and uncertainty management.', 'Background_of_SaNDA': 'Recently, Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the ability to perform classification in such domains, by develop-ing a data abstraction protocol using a ROC curve-based method.'}","nannan{'Challenges_with_Deep_Learning': 'Classification for CDM processes encompasses two fundamental attributes: explainability [24] and uncertainty [34], characteristics notably absent in outcomes generated by deep learning [6, 30].', 'Limitations_of_Random_Forest': 'Random Forest was originally presented as an approach for improving the accuracy of single decision tree which sometimes has problem with over-fitting and therefore with generalization [3].'}","nan{'Verification_Metrics': 'Several metrics are used as a valuable tool for comparing the performance of ML classification models. They provide a comprehensive assessment of a model’s performance across different aspects.', 'SaNDA_Classification_Method': 'SaNDA consists of two main parts, which interacts with each other to provide compre-hensive method of data analysis: classification, and KG [15].', 'Abstraction_Methods': 'Abstraction as a procedure for reducing the number of values that a variable can take is defined in Sec. 2.2.'}","nan{'Comparison_of_Abstraction_Methods': 'For each dataset detailed in Section 3, it contrasts the BA acquired from SaNDA across various abstraction types: ROC, deciles (quantiles 10), quantiles 20, 10 bins, and 20 bins.', 'Quantile-Based_Abstractions_Offer_Better_Classification_Performance': 'Based on this experiment, it can be observed that overall quantiles 20 offers better classification performance compared to 20 bins abstraction method.', 'Number_of_Categories_Produced_by_Abstraction_Method_Impacts_Accuracy': 'One might naively believe that increasing the number of abstractions will enhance classification accuracy. However, this approach harbours potential pitfalls that warrant careful consideration.'}","nan{'SaNDA_with_Quantiles_20_Abstraction_Method_as_Alternative_to_Random_Forest': 'The proposed new data abstraction methods significantly outperform abstractions using ROC.', 'Future_Work': 'A future direction of research may involve the choice of an appropriate method and level of abstraction.'}",The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making,"Karol Capała, Paulina Tworek, Jose Sousa","Highlights
The Significance of Data Abstraction Methods in Machine Learning Classifi-
cation Processes for Critical Decision-Making
Karol Capa la, Paulina Tworek, Jose Sousa
• Classification is characterised by the attributes of explicability and uncertainty
management
• Medical, behavioural and financial datasets, among others, are often small and full
of missing data
• SaNDA was proposed as an explainable method tweaked for such datasets
• This paper analyses how different abstraction methods influence SaNDA’s perfor-
mance
• Modified SaNDA with new abstraction methods is compared against first version
of SaNDA and Random Forest
arXiv:2401.11044v1  [cs.LG]  19 Jan 2024
The Significance of Data Abstraction Methods in Machine
Learning Classification Processes for Critical Decision-Making
Karol Capa laa,b,∗, Paulina Tworeka, Jose Sousaa
aPersonal Health Data Science group, Sano – Centre for Computational Medicine, Czarnowiejska 36
building C5, 30-054 Krak´ow, Poland
bInstitute of Computer Science, AGH University of Krakow, Kawiory 21, 30-059 Krak´ow, Poland
Abstract
The applicability of widely adopted machine learning (ML) methods to classification
is circumscribed by the imperatives of explicability and uncertainty, particularly evident
in domains such as healthcare, behavioural sciences, and finances, wherein accountability
assumes priority. Recently, Small and Incomplete Dataset Analyser (SaNDA) has been
proposed to enhance the ability to perform classification in such domains, by develop-
ing a data abstraction protocol using a ROC curve-based method. This paper focuses
on column-wise data transformations called abstractions, which are crucial for SaNDA’s
classification process and explores alternative abstractions protocols, such as constant
binning and quantiles. The best-performing methods have been compared against Ran-
dom Forest as a baseline for explainable methods. The results suggests that SaNDA can
be a viable substitute for Random Forest when data is incomplete, even with minimal
missing values. It consistently maintains high accuracy even when half of the dataset is
missing, unlike Random Forest which experiences a significant decline in accuracy under
similar conditions.
Keywords:
Missing Data, Small Datasets, Explainable Models, Machine Learning,
Data Science, Uncertainty
1. Introduction
The recent upswing in the adoption and advancement of Artificial Intelligence (AI)
applied to classification for Critical Decision-Making (CDM) has been propelled by the
implementation of deep learning, grounded in the unique amalgamation of substantial
datasets (big data) and the availability of computational power [20]. This adoption of
deep learning is centred on the comparative analysis of outcomes between human decision-
making and machine-driven processes. However, this prompts question on the degree of
comparability between these outcomes [24].
Classification for CDM processes encompasses two fundamental attributes: explain-
ability [24] and uncertainty [34], characteristics notably absent in outcomes generated by
deep learning [6, 30]. The integration of deep learning into CDM processes has encoun-
tered obstacles due to its opaque nature [19, 12], leading to the emergence of research
∗Corresponding author
Email addresses: k.capala@sanoscience.org (Karol Capa la), p.komorek@sanoscience.org
(Paulina Tworek), j.sousa@sanoscience.org (Jose Sousa)
Preprint submitted to Information Sciences Journal
January 23, 2024
trends such as eXplainable Artificial Intelligence (XAI) [18, 27] and one-shot learning
[17].
Explainability holds particular and pivotal significance in the technological assimi-
lation within CDM, primarily due to accountability concerns [6].
When ML informs
CDM, a comprehensive explanation is imperative to elucidate the classification rationale,
facilitating a deeper understanding of the decision-making process.
Nowadays, among various ML methods, deep learning is commonly used, as it has a
huge advantage in finding patterns in the data. However, the application of deep learning
requires the collection of substantial datasets, which is not achievable in many areas.
Presence of small and missing data, characteristic for many fields, causes uncertainty [30]
to be an inherent property of CDM scenarios [28].
Despite the advancements on data access [25], federated learning [37] and encrypted
learning techniques [33], these challenges persist among others across diverse domains,
including healthcare, behavioural sciences, and finances [5, 8, 21]. Moreover, challenges
such as privacy concerns, limited accessibility, ethical considerations, and inherent data
nature impend the acquisition of significant datasets [26, 14, 35, 31]. Therefore, it is
necessary to focus on creating solutions for small and incomplete data.
Random Forest was originally presented as an approach for improving the accuracy
of single decision tree which sometimes has problem with over-fitting and therefore with
generalisation [3]. Random Forest [4] is based on an ensemble of individual decision tree
trained on random samples of the training data, thereby achieving different characteristics
of the data distribution. Once the decision trees have been constructed, the random forest
algorithm makes a prediction by averaging the predictions of all of the trees reducing the
variance of the model.
This produces more accurate predictions than any individual
tree could make, while remaining explainable. Moreover, in case of medium size, tabular
datasets, Random Forest may outperform deep learning on classification task [10, 11].
These two properties make them suitable for use in many sensitive areas.
However, similarly to the majority of the widely used ML algorithms, they are unable
to properly proceed with missing values. Therefore, they require removal of incomplete
entries, or, when it is not possible or undesired, filling them with the help of imputation.
An alternative explainable ML method, SaNDA, built on the use of incomplete data
and with the classification explainability provided by knowledge graphs (KG), has been
recently proposed by us [15]. The solution eliminates the need for imputers, which can
introduce erroneous information into the model, especially when the number of missing
values is high or there is a bias in their occurrence. In addition to KG, another impor-
tant element of SaNDA are abstractions, which is the transformation of data values into
a smaller categorical distribution. More specifically, for each column of data, SaNDA
assigns the values it contains to one of two states (categories) called UP or DOWN.
However, this binary abstraction choice is not the only possible one.
This paper in-
vestigates the impact of other abstraction methods on the classification performance of
SaNDA. The aim of the experiments is to improve SaNDA’s performance in classifica-
tion processes for CDM, while maintaining functionality, even with very large amounts
of missing data.
Sec. 2 provides a more detailed description of the classification process of SaNDA, as
well as the alternative abstraction methods proposed in this paper and the metrics used
to evaluate model performance. Research questions and descriptions of the experiments
undertaken to answer them are described in Sec. 3. Results of the numerical experiments
2
are given in Sec. 4. Finally, the paper is closed with a summary and conclusions (Sec. 5).
2. Model
2.1. Verification metrics
Several metrics are used as a valuable tool for comparing the performance of ML
classification models. They provide a comprehensive assessment of a model’s performance
across different aspects. To define chosen metrics the following basic concepts as results
of the classification task should be introduced:
• True positives (TP) - number of correctly classified instances of the positive class,
• False positives (FP) - number of incorrectly classified instances of the negative class,
• True negatives (TN) - number of correctly classified instances of the negative class,
• False negatives (FN) - number of incorrectly classified instances of the positive class.
Based on the concepts several metrics of classification tasks are defined. Among these,
balanced accuracy (BA) provides a comprehensive assessment of model performance.
BA is the primary metrics chosen for evaluation the performance of selected abstraction
methods and comparing them with Random Forest. It is one of the simplest metrics
for evaluating a classification model’s ability to accurately predict classes in the context
of imbalanced datasets, which are common, among others, for medical and financial
problems. BA is a extension of standard accuracy metrics, it is an average accuracy from
both the minority and majority classes, i.e.,
BA =
TP
TP+FN +
TN
TN+FP
2
.
(1)
Beyond a simple BA, there are other metrics which offer different insights into how
well a classification model is performing [13]. Recall, defined as
recall =
TP
TP + FN,
(2)
measures the ability for the correct identification of instances of the positive class from
all the actual positive samples in the dataset. This metrics is widely employed in various
domains, particularly in application classification algorithms used, e.g. in medical and
financial scenarios. For instance, in healthcare it is crucial especially in medical screening
and diagnostic testing as high value of recall suggests that the test performs well in
detecting TP cases, thereby reducing the chances of missing instances (FN) [13].
In
financial area, recall is frequently measured in the context of risk management and fraud
detection to ensure that potential risks or fraudulent activities are detected effectively
[22].
However, there are also scenarios, where the accuracy of positive predictions made by
a classification model is critical, e.g. consequences of carrying out medical or financial
interventions or procedures that are not actually required, stemming from false positive
results, can have a substantial impact.
In such case precision should be monitored.
Precision provides information about the quality of positive predictions made by the
3
model. It is defined as the number of positive instances divided by the total number of
positive predictions, both correctly and incorrectly classified as positive class:
precision =
TP
TP + FP
(3)
Achieving a careful equilibrium between recall and precision holds paramount impor-
tance in many applications. However, the optimal metrics for evaluation ML models
should be chosen based on the specific scope and nature of the problem at hand.
2.2. SaNDA classification method
SaNDA consists of two main parts, which interacts with each other to provide compre-
hensive method of data analysis: classification, and KG [15]. While classification module
can separate data into classes and provide information how well model captures properties
of the data, KG enhance explainability of the results and provide deeper insight into inter-
dependence between features. Since the primary objective of this paper is to investigate
the potential for enhancing SaNDA’s data representation capability, which is primar-
ily evaluated through the classification aspect, this section focuses on the explanation
of classification method using SaNDA. The most important concepts for a classification
problem using SaNDA are abstractions and the classification algorithm itself.
Data abstraction involves simplifying a specific set of data by condensing it into a
more streamlined representation of the entire dataset. It allows for eliminating specific
traits from an object or concept to distill it down to a collection of fundamental elements.
To this end, data abstraction creates a simplified representation of the underlying data,
while hiding its complexities and associated operations. In addition, abstraction method
used in SaNDA ensures the anonymisation of the data. There are various approaches to
creating abstractions.
The abstraction is formally defined as [15]:
Definition 1. Given A and B two sets of numerical values, with |A| ≥ |B|, an abstraction
is defined as a function F : A → B that maps the values of A to values of B.
In other world, process of abstraction maps original values from the data into smaller
set of values. It is important to mention that abstraction process is performed on column-
by-column basis. In the founding paper, original data was transformed into two classes,
using ROC curve method. However, other methods resulting in the different number
of abstractions (categories), i.e., cardinality of set |B| ̸= 2, may also be an appropriate
solution. All of the methods using ROC curves and the new proposed alternative methods
are presented in the subsection 2.3. For the need of SaNDA, elements of the new set
are represent as B = B1, ..., B|B| and can be treated as a set of categorical variables.
Therefore, if every of n features in the dataset is abstracted to the same amount of
abstractions, each input is now described by a set of categorical values X = {x1, · · · , xn}.
The input constructed in this way can be combined with the natively categorical data,
enabling easy integration of different types of data [9].
Then based on obtained data abstractions, we generate an explainable KG represen-
tation, which is created as it was previously described [16, 15]. Through building the
graphs, a representation for each class based on available features is prepared. The sig-
nificance of each vertex of the KG is represented by the probability of each feature being
in given category of the given class.
4
Following paper focuses on binary classification, however SaNDA algorithm can be
described and performed also for arbitrary number of classes [9, 15]. Let Cj be the jth
class. Then for given Cj the following probability can be computed as:
P(X|Cj) =
n
Y
i=1
P(xi|Cj)
(4)
The class with the highest P(X|Cj) is chosen, i.e.
argmaxC {P(X|Cj)} .
(5)
Therefore, SaNDA assigns a given set of values to the class for which its occurrence is
most likely. If the given feature xi is empty (missing value) or is represented by null
values, it is skipped in the calculation of the probability P(X|Cj).
Contrary to the majority of commonly used methods, SaNDA does not divide feature
space base on optimisation of some classification function. Instead values of every feature
are individually divided based on abstraction methods, which does not need (but can)
take into account class distribution. From the perspective of the entire feature space, it
creates division into grind, which every “cell” is label as one of the classes based on the
conditions given by Eqs. (4) and (5). These conditions do not consider every individual
“cell” but rather try to approximate it base on every dimension separately. On the one
hand, this approach may diminish the classification accuracy of the method by failing to
incorporate more intricate, nonlinear relationships, particularly in the context of a sparse
grid (where the number of abstractions is low). On the other hand it allows to complete
classification test even in the present of missing values by considering lower-dimensional
space.
2.3. Abstraction methods
Abstraction as a procedure for reducing the number of values that a variable can take
is defined in Sec. 2.2. This section presents methods of abstracting data used in this
paper.
2.3.1. ROC Curves
ROC curve abstractions split the values of a feature into two categories in a way that
maximizes the separation between the classes in the feature. To be more precise, the
values of the feature in the abstracted column are split into smaller and larger than the
value that maximizes BA, as given by Eq (1).
2.3.2. constant binning
Abstractions though constant binning divide the values of a feature into categories of
equal range. Let A be a set of the values taken by the feature. Then L = maxA − minA
is a range of values. constant binning divide range of the data L, into n equal intervals
of length L/n, assigning the feature a number corresponding to the bin number in which
its original value falls.
5
2.3.3. Quantiles
While constant binning divides data to keep the range of every bin equal, abstractions
based on quantiles divide data into categories of the equal size. Cut-off values are chosen
based on the values of quantiles. Quantile of the order n is defined based on the probability
distribution of the random variable ranging over the set X is such a way that the locations
yq of the quantile q (q = k/n, where k ≤ n) given by
q =
Z yq
−∞
p(x)dx.
(6)
In other words, quantile yq is such value that cumulative distribution function takes at
this point value q or alternatively qth part of the data takes values smaller or equal yq.
Quantile-based abstractions therefore assign the feature the largest k for which x < yq,
i.e., corresponding to the highest quantile larger than initial value.
The most commonly used quantiles are ones of the order n = 2 (median), n = 4
(quartiles) and n = 10 (deciles).
3. Experiments
The main goal of this research is to improve the efficacy of the SaNDA algorithm by
examining the abstraction phase. To achieve this, it is necessary to first explore how
different abstraction methods influence the metrics that describe SaNDA performance.
Based on the results, determine whether there are criteria for choosing an abstraction
method that can be applied in model design, and if so, how to choose the best abstraction
method for a given use of the SaNDA algorithm. Finally, verify how the best-performing
abstraction methods influences SaNDA performance in the presence of missing values in
the dataset. For the sake of comparison with the original research, we used the 5 datasets
from the paper proposing SaNDA [15] in the following experiments, supplemented by 10
synthetic DIGEN datasets (8 4426, 10 8322, 17 6949, 22 2433, 23 5191, 24 2433, 32 5191,
35 4426, 36 466, 39 5578). A selection of datasets is briefly described below.
The Ionosphere dataset [7, 32], a collection of 351 radar measures of the ionosphere in
Goose Bay, Labrador, is used to classify its structure. The dataset includes 34 numeric
features that measure the number of free electrons and other electromagnetic signals in
the ionosphere.
The Sonar dataset [7, 1] consists of 60 numerical features that measure the shape and
characteristics of the sonar signal. The classification task is to distinguish underwater
surfaces as rock or metal. It is the smallest number of records equal to 208.
The Wisconsin Breast Cancer dataset [7, 36] uses 30 numerical features that measure
the shape and composition of a breast mass to describe 569 fine needle aspirates. The
task is to distinguish between cancerous and non-cancerous samples. It consists of 569
entries.
The Accelerometer dataset [7, 29] was generated for prediction of motor failure time
with application of an artificial neural network. It uses 4 numerical features; 3 of them
represents the values of x, y and z axes, while the fourth is cooler maximum speed per-
centage ranging from 20% to 100% with 5% intervals. The fifth attribute was used as
target class, where normal configuration was admitted as negative class, while perpen-
dicular and opposite configuration as positive class. It has the largest number of records
equal to 102000.
6
The HIGGS dataset [7, 2] is produced from Monte Carlo simulations of particle decays
and contains 1.1 × 107 entrances. Each process is described by 28 features, of which 21
are kinematic properties measured by the particle detectors in the accelerator and the
remaining 7 are quantities derived from them. The classification task is to distinguish
between measurements of background noise and those connected to the observation of the
Higgs particle. 105 randomly selected records were taken for the experiments presented
in this work.
DIGEN [23] datasets were designed to differentiate the performance of some of the
leading classification methods. It is the collection of 40 synthetic datasets created from
each of the generative mathematical functions for testing binary classification task. Every
dataset from DIGEN contains 10 features of 1000 normally distributed values.
In summary, the experimental setup consists of 13 small and 2 medium datasets. This
disproportion is caused by the target domain for SaNDA, which is related to the nature
of data occurring in personal health care or finances.
To achieve the goals of this research, we conducted two numerical experiments using
the datasets described above. The first experiment focuses on exploring the different
abstraction methods presented in the Sec 2.3 and their impact on SaNDA performance
with an indication of classifciation accuracy. For this purpose, each of the studied datasets
was transformed using one of the following abstraction methods:
• constant binning into 10 and 20 bins
• quantiles of order 10 (deciles) and 20
• using ROC curve method as a control group
Then, using the method used in SaNDA, models were created for classification purposes.
It is important to note that in this experiment we do not create any missing data in the
datasets.
Following the initial experiment, the abstraction methods yielding the highest BA
was selected for each dataset with the selected percentage of missing data. Subsequently,
the SaNDA classification algorithm was modified to incorporate this chosen abstraction
methods and applied to datasets containing 1%, 5%, 10%, and 50% of missing data.
Datasets with n% missing data were created from the original datasets by randomly
removing n% of data from each column (feature). The results were compared to those
obtained from the original, ROC curve-based SaNDA and Random Forest algorithms.
For Random Forest, missing data were replaced with zeros to be able to process the
datasets. Subsequently, for all of the methods the BA, recall and precision values were
compared.
4. Results
Figure 1 and Table 1 show the BA for experiment 1. For each dataset detailed in
Section 3, it contrasts the BA acquired from SaNDA across various abstraction types:
ROC, deciles (quantiles 10), quantiles 20, 10 bins, and 20 bins. For the accelerometer,
Higgs, WDBC, and DIGEN datasets, with the exception of DIGENs: 22 2433, 24 2433,
and 17 6949, the use of quantiles 20 results in superior BA for classification. On the other
hand, for the remaining DIGENs, Sonar and Ionosphere datasets, the application of 20
bins abstraction yields higher BA compared to other abstraction methods.
7
Based on this experiment, it can be observed that overall quantiles 20 offers better
classification performance compared to 20 bins abstraction method. In the case of the
opposite being true, the discrepancy is significantly narrower. Similar but weaker trend
can be also observed between deciles and 10 bins.
In light of the results, quantile-
based abstractions can be regarded as a preferable choice of abstraction for SaNDA
classification.
However, the number of categories into which data is transformed as a result of ab-
straction process is of far greater significance than the type of abstraction employed. This
can be explained by the fact that a higher number of abstractions (categories) enhances
the resolution of the grid created in the feature space. As a result, a denser grid enables
a more homogeneous distribution of data across its constituent parts, leading to more
accurate classification performance.
One might naively believe that increasing the number of abstractions will enhance
classification accuracy. However, this approach harbours potential pitfalls that warrant
careful consideration. First, increasing the number of abstractions can result in a de-
crease in the average number of data points per category, potentially compromising the
accurate representation of statistical properties. Furthermore, an increase in the number
of abstractions can lead to an expansion in the number of nodes within the KG gener-
ated by SaNDA, potentially diminishing its explainability. Finally, an extensive number
of abstractions can exert a detrimental impact on the computational time required for
generating classification and KG, a factor that may become particularly crucial when
computational resources are constrained or the analysed problem demands expediency.
Given these considerations, the maximum number of abstractions employed in this re-
search was limited to 20.
Based on the results of Experiment 1, Experiment 2 employed SaNDA classification
using 20 bins and quantiles 20 for comparison with the original ROC curves abstractions
and Random Forest was performed. The results of this comparison for increasing per-
centage of missing data are presented in Figs 2–4 and in Tables 1–15. Fig. 2 shows BA
as a function of missing data for each dataset separately. In all of the cases, 20 categories
abstractions, bin- or quantile-based, outperform both ROC-based abstractions. Random
Forest achieves higher BA in only 4 of 15 datasets with non-zero amount of missing
data: Accelerometer, HIGGS and DIGENs: 39 5578, 23 5191. However, for HIGGS and
DIGEN23 5191 the difference between 20 quantiles abstractions SaNDA and Random
Forest in the BA is slight. When the proportion of missing data increases the advan-
tage of SaNDA with 20 categories abstraction methods increases, as it achieves higher
BA for majority of tested datasets. A notable exception is observed in the Accelerom-
eter dataset, where Random Forest surpasses both proposed new abstraction methods
regardless of amount of missing values. This behaviour can be attributed to the limited
number of features, specifically 4, characterising this dataset. Additionally, the size of
the dataset, which can be considered average with approximately 105 inputs, favors the
efficiency of Random Forest.
BA is not the only important metrics from the point of view of classification models.
The proposed system, due to its ability to anonymize data and dealing with missing
values may be particularly relevant, among others, in areas of medicine, social sciences
and finance where the high level of recall and precision is also very important. Therefore,
we decided to check whether increasing the number of abstractions (categories) would
affect mentioned metrics and compare them with the values obtained for Random Forest.
8
The results presented in Figure 3 showed that the recall was higher for quantiles 20
than for ROC for all of the chosen datasets. Comparison of quantiles 20 and Random
Forest shows that Random Forest wins in the case of 6 datasets (Accelerometer, HIGGS,
Wisconsin Breast Cancer and DIGENs: 8 4426, 39 5578, 23 5191, when there aren’t any
missing values. Quantiles 20 or 20 bins achieves better results for 9 datasets (Ionosphere,
Sonar and DIGENs: 32 5191, 36 466, 35 4426, 10 8322, 22 2433, 24 2433, 17 6949) with
an advantage for quantiles. The only dataset where Random Forest performance is much
better is Accelerometer, but the same observation was noticed for BA and it may be
related to low number of features.
Similar conclusions were reached for precision, see Fig. 4. For all datasets, the pro-
posed new abstraction methods performed significantly better than ROC. In the ab-
sence of missing data Random Forest achieves highest precision values for 6 (HIGGS,
Ionosphere, Wisconsin Breast Cancer and DIGENs: 39 5578, 23 5191, 22 2433) of 15
datasets, in the case of 2 of these datasets the difference was marginal (DIGENs: 23 5191
and 22 2433). For the rest of the datasets, classification using either quantiles 20 or 20
bins yields higher precision (Accelerometer, Sonar and DIGENs: 8 442, 32 5191, 36 466,
35 4426, 10 8322, 24 2433, 17 6949). With 10% of the missing data quantiles 20 or 20 bins
outperform Random Forest in 12 out of 15 cases for recall (HIGGS, Ionosphere, Sonar and
DIGENs: 8 442, 32 5191, 39 5578, 36 466, 35 4426, 10 8322, 23 5191, 24 2433, 17 6949)
and in 12 cases for precision (Accelerometer, HIGGS, Sonar and DIGENs: 32 5191,
39 5578, 36 466, 35 4426, 10 8322, 23 5191, 24 2433, 17 6949). A greater proportion of
missing data works against Random Forest, which is particularly noticeable when 50%
of data is removed - in such conditions Random Forest prevails by a minimal margin for
only 1 dataset (for recall - Accelerometer, while for precision - DIGEN39 5578).
The results clearly demonstrate that the proposed new data abstraction methods
significantly outperform abstractions using ROC. Moreover, the values obtained from se-
lected metrics indicate that classification using SaNDA with a quantiles 20 abstraction
method can compete with Random Forest for complete datasets. Additionally, classifica-
tion with missing data clearly shows the advantage of the new data abstraction methods
over classical approach.
5. Summary and Conclusions
The increasing research on data anonymisation, federated learning and encrypted
computing aims at increasing the data size and availability for deep learning, the driving
force behind the recent developments and impact of ML. However, there are areas such
as healthcare, behavioural sciences and finances, where data, to support CDM remains
very limited. Recently, the Small and Incomplete Dataset Analyser (SaNDA) [15] has
emerged as a promising solution to facilitate the adoption of ML in such areas due to its
capability to use small and noisy datasets, while explaining the outcomes.
SaNDA can effectively tackle classification tasks even with substantial amounts of
missing data, eliminating the need for data imputation or modelling, which can be chal-
lenging, costly and time-consuming in extremely low-quality datasets. One of its funda-
mental aspects is the use of abstractions, which involve column-wise transformations of
numerical data into categorical representations.
In this paper we describe experiments to compare constant width constant binning
and quantiles-based abstraction protocols as alternatives to the previously employed ROC
9
curve-based method. Their influence on classification performance has been extensively
examined and measured.
As a general result, increasing the number of data abstractions consistently enhances
the performance of the SaNDA algorithm, however, this results into some potential lim-
itations. Firstly, it was identified that splitting the data into many categories, results
in a poor statistical representation of the real population. Secondly, it reduces the ex-
plainability of the model due to the increase of the complexity of the KG representation,
becoming useless for Critical Decision-Making. Lastly, a substantial increase on the time
required to create the classification model makes its usefulness questionable for the pro-
posed classification environments.
Due to these limitations, we decided to cap the number of abstractions to 20, regard-
less of the chosen abstraction method. This limit proved to be effective in significantly
improving the balanced accuracy of SaNDA.
In conclusion, the SaNDA classification process, built through the meticulous ex-
periments of a chosen abstraction methodology, holds as a prospective alternative to
conventional explainable ML paradigms such as Random Forest. This assertion gains
particular relevance in situations necessitating CDM within constraints of small datasets
and missing data. The proposed SaNDA enhanced classification processes demonstrates
its potential to yield robust and explainable outcomes, thereby presenting a viable option
in contexts where deep learning methodologies may encounter limitations.
A future direction of research may involve the choice of an appropriate method and
level of abstraction. The abstraction method can be chosen to maximise accuracy while
maintaining computation time efficiency for a specific dataset.
The abstraction level
dictates how accurately it mirrors the intricacies of the problem domain and the extent to
which it simplifies and generalizes domain concepts. It can range from being very detailed
and specific to more generalized and fundamental, depending on the intended scope and
purpose of the domain problems. Adopting a dynamic approach to selecting methods
and determining abstraction levels can enhance the model’s versatility. This adaptability
would allow for easy customization to meet specific problem and user requirements.
Acknowledgements
This research has been supported by the European Union’s Horizon 2020 research
and innovation programme under grant agreement Sano No 857533. This publication
is supported by Sano project carried out within the International Research Agendas
programme of the Foundation for Polish Science MAB PLUS/2019/13, co-financed by
the European Union under the European Regional Development Fund. This research
was supported in part by PLGrid Infrastructure.
References
[1] Connectionist Bench (Sonar, Mines vs. Rocks). UCI Machine Learning Repository.
[2] Pierre Baldi, Peter Sadowski, and Daniel Whiteson. Searching for exotic particles in high-energy
physics with deep learning. Nature communications, 5(1):1–9, 2014.
[3] Vaishak Bella and Ioannis Papantonis. Principles and practice of explainable machine learning.
Frontiers in Big Data, 4:688969, 2021.
[4] Leo Breiman. Random forests. Mach. Learn., 45(1):5–32, 2001.
[5] Varsha Chiruvella and Achuta Kumar Guddati. Ethical issues in patient data ownership. Interact
J Med Res., 10(2):e22269, 2021.
10
[6] Derek Doran, Sarah Schulz, and Tarek R Besold. What Does Explainable AI Really Mean? A New
Conceptualization of Perspectives. arXiv, 2017.
[7] Dheeru Dua and Casey Graff. UCI machine learning repository, 2017.
[8] Ajith Abraham Aswani Kumar Cherukuri Patricia Melin Niketa Gandhi. Intelligent Systems Design
and Applications, 18th International Conference on Intelligent Systems Design and Applications
(ISDA 2018) held in Vellore, India, December 6-8, 2018, Volume 1. 2020.
[9] Luca Gherardini, Varun Ravi Varma, Karol Capa la, Roger Woods, and Jose Sousa.
Cactus:
a comprehensive abstraction and classification tool for uncovering structures.
arXiv preprint
arXiv:2308.12031, 2023.
[10] Mitchell Gill, Robyn Anderson, and Haifei et al. Hu. Machine learning models outperform deep
learning models, provide interpretation and facilitate feature selection for soybean trait prediction.
BMC Plant Biol, 22:180, 2022.
[11] L´eo Grinsztajn, Edouard Oyallon, and Ga¨el Varoquaux. Why do tree-based models still outperform
deep learning on typical tabular data? Advances in Neural Information Processing Systems, 35:507–
520, 2022.
[12] Vikas Hassija, Vinay Chamola, Atmesh Mahapatra, Abhinandan Singal, Divyansh Goel, Kaizhu
Huang, Simone Scardapane, Indro Spinelli, Mufti Mahmud, and Amir Hussain. Interpreting Black-
Box Models: A Review on Explainable Artificial Intelligence. Cognitive Computation, pages 1–30,
2023.
[13] Steven Hicks, Inga Str¨umke, and Vajira et al. Thambawita. On evaluation metrics for medical
applications of artificial intelligence. Sci Rep, 12:5979, 2022.
[14] Mohammad Hosseini, Micha l Wieczorek, and Bert Gordijn. Ethical issues in social science research
employing big data. Sci Eng Ethics, 28:29, 2022.
[15] Alfredo Ibias, Varun Ravi Varma, Karol Capa la, Luca Gherardini, and Jose Sousa. Sanda: A small
and incomplete dataset analyser. Information Sciences, 640:119078, 2023.
[16] Wei Jin, Tyler Derr, Haochen Liu, Yigi Wang, Suhang Wang, Zitao Liu, and Jiliang Tang. Self-
supervised learning on graphs: deep insights and new direction. arXiv:2006.10141, 2020.
[17] Suvarna Kadam and Vinay Vaidya. Review and analysis of zero, one and few shot learning ap-
proaches. In Ajith Abraham, Aswani Kumar Cherukuri, Patricia Melin, and Niketa Gandhi, editors,
Intelligent Systems Design and Applications, pages 100–112, Cham, 2020. Springer International
Publishing.
[18] Andrej Karpathy, Justin Johnson, and Li Fei-Fei. Visualizing and understanding recurrent networks.
arXiv preprint arXiv:1506.02078, 2015.
[19] Alex John London. Artificial Intelligence and Black-Box Medical Decisions: Accuracy versus Ex-
plainability. Hastings Center Report, 49(1):15–21, 2019.
[20] Alexandra L’Heureux, Katarina Grolinger, Hany F Elyamany, and Miriam AM Capretz. Machine
learning with big data: Challenges and approaches. IEEE Access, 5:7776–7797, 2017.
[21] Blake Murdoch. Privacy and artificial intelligence: challenges for protecting health information in
a new era. BMC Medical Ethics, 11:122, 2021.
[22] Rtayli Naoufal and Enneya Nourddine. Enhanced credit card fraud detection based on svm-recursive
feature elimination and hyper-parameters optimization. Journal of Information Security and Ap-
plications, 55:102596, 2020.
[23] Patryk Orzechowski and Jason H Moore. Generative and reproducible benchmarks for comprehen-
sive evaluation of machine learning classifiers. Science Advances, 8(47):eabl4747, 2022.
[24] Uwe Peters. Explainable AI lacks regulative reasons: why AI and human decision-making are not
equally opaque. AI and Ethics, 3(3):963–974, 2023.
[25] Shukor Abd Razak, Nur Hafizah Mohd Nazari, and Arafat Al-Dhaqm. Data Anonymization Using
Pseudonym System to Preserve Data Privacy. IEEE Access, 8:43256–43264, 2020.
[26] Muhammad Imran Razzak, Muhammad Imran, and Guandong Xu. Big data analytics for preventive
medicine. Neural Comput & Applic, 32:4417–4451, 2020.
[27] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should i trust you?” Explaining
the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference
on knowledge discovery and data mining, pages 1135–1144, 2016.
[28] Bukhoree Sahoh and Anant Choksuriwong. The role of explainable Artificial Intelligence in high-
stakes decision-making systems: a systematic review. Journal of Ambient Intelligence and Human-
ized Computing, 14(6):7827–7843, 2023.
[29] Scalabrini Sampaio, Vallim Filho, Santos da Silva, and Augusto da Silva. Prediction of motor failure
11
time using an artificial neural network. Sensors, 19(19):4342, October 2019.
[30] Silvia Seoni, Vicnesh Jahmunah, Massimo Salvi, Prabal Datta Barua, Filippo Molinari, and U. Ra-
jendra Acharya. Application of uncertainty quantification to artificial intelligence in healthcare: A
review of last decade (2013–2023). Comput. Biol. Med., 165(C), jan 2024.
[31] Fadi Shehab Shiyyab, Abdallah Bader Alzoubi, Mr. Qais Obidat, and Hashem Alshurafat. The
impact of artificial intelligence disclosure on financial performance. Int. J. Financial Stud., 11:115,
2023.
[32] Vincent Sigillito, Simon Wing, Larrie Hutton, and Kile Baker. Ionosphere. UCI Machine Learning
Repository, 1989.
[33] Xiaoqiang Sun, Peng Zhang, Joseph K. Liu, Jianping Yu, and Weixin Xie. Private Machine Learning
Classification Based on Fully Homomorphic Encryption. IEEE Transactions on Emerging Topics
in Computing, 8(2):352–364, 2017.
[34] Gaia Tavoni, Takahiro Doi, Chris Pizzica, Vijay Balasubramanian, and Joshua I. Gold. Human
inference reflects a normative balance of complexity and accuracy.
Nature Human Behaviour,
6(8):1153–1168, 2022.
[35] Patrick Weber, K.Valerie Carl, and Oliver Hinz. Applications of explainable artificial intelligence
in finance—a systematic review of finance, information systems, and computer science literature.
Manag Rev Q, 2023.
[36] William Wolberg, Olvi Mangasarian, W. Street, and Nick Street. Breast Cancer Wisconsin (Diag-
nostic). UCI Machine Learning Repository, 1995.
[37] Chen Zhang, Yu Xie, Hang Bai, Bin Yu, Weihong Li, and Yuan Gao. A survey on federated learning.
Knowledge-Based Systems, 216:106775, 2021.
12
dataset
quantiles 20
deciles
ROC
10 bins
20 bins
Random Forest
DIGEN23 5191
0.681
0.633
0.564
0.601
0.657
0.686
DIGEN24 2433
0.682
0.597
0.597
0.635
0.690
0.594
DIGEN39 5578
0.674
0.622
0.601
0.603
0.661
0.757
DIGEN17 6949
0.623
0.602
0.593
0.615
0.633
0.483
DIGEN32 5191
0.665
0.602
0.568
0.605
0.658
0.447
DIGEN10 8322
0.682
0.611
0.577
0.620
0.657
0.627
DIGEN22 2433
0.668
0.603
0.563
0.611
0.672
0.645
DIGEN8 4426
0.675
0.623
0.589
0.648
0.687
0.656
DIGEN35 4426
0.664
0.627
0.560
0.611
0.663
0.640
DIGEN36 466
0.687
0.629
0.584
0.630
0.660
0.628
Accelerometer
0.718
0.713
0.676
0.638
0.678
0.889
Ionosphere
0.940
0.924
0.911
0.950
0.957
0.936
Wisconsin Breast Cancer
0.969
0.952
0.948
0.948
0.953
0.958
Sonar
0.981
0.906
0.847
0.923
0.986
0.832
HIGGS
0.663
0.658
0.624
0.609
0.640
0.666
Table 1: Balanced accuracy (BA) for selected SaNDA classification methods and Random Forest for all
chosen datasets with 0% missing values
13
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.678
0.58
0.664
0.647
DIGEN24 2433
0.692
0.593
0.686
0.611
DIGEN39 5578
0.679
0.601
0.651
0.657
DIGEN17 6949
0.648
0.584
0.632
0.553
DIGEN32 5191
0.669
0.564
0.658
0.555
DIGEN10 8322
0.685
0.574
0.663
0.654
DIGEN22 2433
0.658
0.581
0.673
0.625
DIGEN8 4426
0.683
0.592
0.683
0.663
DIGEN35 4426
0.667
0.57
0.664
0.596
DIGEN36 466
0.685
0.574
0.667
0.571
Accelerometer
0.718
0.676
0.678
0.885
Ionosphere
0.940
0.911
0.959
0.941
Wisconsin Breast Cancer
0.970
0.946
0.953
0.958
Sonar
0.981
0.866
0.896
0.793
HIGGS
0.663
0.624
0.639
0.661
Table 2: Balanced accuracy (BA) for selected SaNDA classification methods and Random Forest for all
chosen datasets with 1% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.682
0.566
0.670
0.541
DIGEN24 2433
0.678
0.580
0.666
0.687
DIGEN39 5578
0.690
0.589
0.680
0.610
DIGEN17 6949
0.661
0.588
0.677
0.618
DIGEN32 5191
0.680
0.593
0.667
0.689
DIGEN10 8322
0.669
0.588
0.658
0.572
DIGEN22 2433
0.646
0.578
0.655
0.572
DIGEN8 4426
0.682
0.588
0.657
0.693
DIGEN35 4426
0.672
0.575
0.653
0.594
DIGEN36 466
0.684
0.580
0.679
0.626
Accelerometer
0.716
0.673
0.693
0.869
Ionosphere
0.936
0.901
0.967
0.941
Wisconsin Breast Cancer
0.969
0.952
0.953
0.942
Sonar
0.981
0.853
0.981
0.818
HIGGS
0.661
0.620
0.637
0.614
Table 3: Balanced accuracy (BA) for selected SaNDA classification methods and Random Forest for all
chosen datasets with 5% missing values
14
dataset
20 deciles
roc
static 20
Random Forest
DIGEN23 5191
0.678
0.593
0.652
0.633
DIGEN24 2433
0.694
0.587
0.677
0.562
DIGEN39 5578
0.665
0.591
0.679
0.637
DIGEN17 6949
0.654
0.591
0.657
0.657
DIGEN32 5191
0.659
0.563
0.655
0.508
DIGEN10 8322
0.675
0.583
0.669
0.594
DIGEN22 2433
0.674
0.577
0.667
0.594
DIGEN8 4426
0.667
0.575
0.682
0.694
DIGEN35 4426
0.678
0.563
0.665
0.660
DIGEN36 466
0.678
0.565
0.657
0.556
Accelerometer
0.715
0.668
0.671
0.848
Ionosphere
0.942
0.892
0.947
0.936
Wisconsin Breast Cancer
0.964
0.954
0.958
0.962
Sonar
0.975
0.871
0.991
0.700
HIGGS
0.657
0.618
0.635
0.622
Table 4: Balanced accuracy (BA) for selected SaNDA classification methods and Random Forest for all
chosen datasets with 10% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.656
0.555
0.646
0.490
DIGEN24 2433
0.671
0.618
0.656
0.541
DIGEN39 5578
0.648
0.569
0.665
0.493
DIGEN17 6949
0.680
0.617
0.689
0.600
DIGEN32 5191
0.687
0.607
0.679
0.526
DIGEN10 8322
0.648
0.589
0.669
0.491
DIGEN22 2433
0.679
0.575
0.640
0.513
DIGEN8 4426
0.662
0.579
0.679
0.524
DIGEN35 4426
0.684
0.569
0.669
0.496
DIGEN36 466
0.679
0.622
0.640
0.520
Accelerometer
0.678
0.615
0.607
0.711
Ionosphere
0.944
0.900
0.947
0.796
Wisconsin Breast Cancer
0.959
0.943
0.952
0.909
Sonar
0.990
0.911
0.995
0.718
HIGGS
0.627
0.593
0.606
0.517
Table 5: Balanced accuracy (BA) for selected SaNDA classification methods and Random Forest for all
chosen datasets with 50% missing values
15
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.681
0.567
0.659
0.684
DIGEN24 2433
0.683
0.600
0.689
0.569
DIGEN39 5578
0.673
0.599
0.656
0.760
DIGEN17 6949
0.621
0.600
0.639
0.530
DIGEN32 5191
0.662
0.570
0.657
0.473
DIGEN10 8322
0.680
0.575
0.661
0.639
DIGEN22 2433
0.671
0.566
0.663
0.679
DIGEN8 4426
0.672
0.590
0.691
0.654
DIGEN35 4426
0.663
0.561
0.664
0.658
DIGEN36 466
0.683
0.588
0.659
0.652
Accelerometer
0.820
0.749
0.940
0.890
Ionosphere
0.944
0.938
0.969
1.000
Wisconsin Breast Cancer
0.958
0.922
0.961
0.972
Sonar
0.970
0.901
0.980
0.821
HIGGS
0.636
0.615
0.630
0.683
Table 6: Precision for selected SaNDA classification methods and Random Forest for all chosen datasets
with 0% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.679
0.586
0.671
0.664
DIGEN24 2433
0.690
0.594
0.683
0.584
DIGEN39 5578
0.677
0.602
0.645
0.652
DIGEN17 6949
0.649
0.585
0.640
0.601
DIGEN32 5191
0.665
0.560
0.654
0.595
DIGEN10 8322
0.687
0.571
0.668
0.671
DIGEN22 2433
0.659
0.581
0.669
0.652
DIGEN8 4426
0.680
0.593
0.686
0.660
DIGEN35 4426
0.662
0.568
0.657
0.602
DIGEN36 466
0.681
0.577
0.666
0.593
Accelerometer
0.819
0.750
0.940
0.885
Ionosphere
0.944
0.938
0.969
0.972
Wisconsin Breast Cancer
0.962
0.917
0.961
0.972
Sonar
0.970
0.907
0.980
0.824
HIGGS
0.637
0.615
0.630
0.673
Table 7: Precision for selected SaNDA classification methods and Random Forest for all chosen datasets
with 1% missing values
16
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.665
0.570
0.650
0.609
DIGEN24 2433
0.676
0.580
0.677
0.610
DIGEN39 5578
0.687
0.587
0.658
0.686
DIGEN17 6949
0.643
0.579
0.659
0.532
DIGEN32 5191
0.665
0.562
0.661
0.564
DIGEN10 8322
0.697
0.593
0.683
0.625
DIGEN22 2433
0.663
0.596
0.681
0.647
DIGEN8 4426
0.618
0.589
0.665
0.688
DIGEN35 4426
0.684
0.585
0.674
0.700
DIGEN36 466
0.665
0.588
0.656
0.600
Accelerometer
0.816
0.754
0.833
0.870
Ionosphere
0.937
0.925
0.978
0.972
Wisconsin Breast Cancer
0.958
0.926
0.952
0.954
Sonar
0.970
0.876
0.970
0.897
HIGGS
0.635
0.607
0.627
0.642
Table 8: Precision for selected SaNDA classification methods and Random Forest for all chosen datasets
with 5% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.651
0.549
0.643
0.497
DIGEN24 2433
0.656
0.605
0.648
0.516
DIGEN39 5578
0.632
0.553
0.642
0.645
DIGEN17 6949
0.667
0.606
0.674
0.469
DIGEN32 5191
0.690
0.625
0.694
0.546
DIGEN10 8322
0.651
0.599
0.671
0.529
DIGEN22 2433
0.704
0.604
0.661
0.513
DIGEN8 4426
0.646
0.565
0.656
0.517
DIGEN35 4426
0.692
0.583
0.680
0.539
DIGEN36 466
0.657
0.595
0.616
0.555
Accelerometer
0.740
0.689
0.698
0.678
Ionosphere
0.945
0.932
0.956
0.839
Wisconsin Breast Cancer
0.927
0.901
0.935
0.927
Sonar
0.990
0.934
0.990
0.725
HIGGS
0.602
0.575
0.589
0.310
Table 9: Precision for selected SaNDA classification methods and Random Forest for all chosen datasets
with 10% missing values
17
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.651
0.549
0.643
0.497
DIGEN24 2433
0.656
0.605
0.648
0.516
DIGEN39 5578
0.632
0.553
0.642
0.645
DIGEN17 6949
0.667
0.606
0.674
0.469
DIGEN32 5191
0.690
0.625
0.694
0.546
DIGEN10 8322
0.651
0.599
0.671
0.529
DIGEN22 2433
0.704
0.604
0.661
0.513
DIGEN8 4426
0.646
0.565
0.656
0.517
DIGEN35 4426
0.692
0.583
0.680
0.539
DIGEN36 466
0.657
0.595
0.616
0.555
Accelerometer
0.740
0.689
0.698
0.678
Ionosphere
0.945
0.932
0.956
0.839
Wisconsin Breast Cancer
0.927
0.901
0.935
0.927
Sonar
0.990
0.934
0.990
0.725
HIGGS
0.602
0.575
0.589
0.310
Table 10: Precision for selected SaNDA classification methods and Random Forest for all chosen datasets
with 50% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.680
0.544
0.652
0.711
DIGEN24 2433
0.678
0.584
0.692
0.608
DIGEN39 5578
0.676
0.612
0.678
0.755
DIGEN17 6949
0.630
0.560
0.612
0.488
DIGEN32 5191
0.674
0.556
0.662
0.449
DIGEN10 8322
0.688
0.590
0.644
0.614
DIGEN22 2433
0.658
0.538
0.698
0.587
DIGEN8 4426
0.684
0.582
0.676
0.693
DIGEN35 4426
0.666
0.554
0.660
0.623
DIGEN36 466
0.698
0.560
0.662
0.594
Accelerometer
0.558
0.530
0.380
0.888
Ionosphere
0.982
0.933
0.969
0.872
Wisconsin Breast Cancer
0.962
0.943
0.929
0.963
Sonar
0.990
0.784
0.990
0.914
HIGGS
0.664
0.564
0.586
0.697
Table 11: Recall for selected SaNDA classification methods and Random Forest for all chosen datasets
with 0% missing values
18
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.674
0.546
0.644
0.612
DIGEN24 2433
0.696
0.586
0.694
0.629
DIGEN39 5578
0.684
0.594
0.670
0.682
DIGEN17 6949
0.644
0.576
0.602
0.524
DIGEN32 5191
0.682
0.594
0.670
0.456
DIGEN10 8322
0.680
0.598
0.648
0.627
DIGEN22 2433
0.654
0.578
0.686
0.581
DIGEN8 4426
0.690
0.586
0.674
0.699
DIGEN35 4426
0.684
0.582
0.686
0.630
DIGEN36 466
0.696
0.554
0.670
0.535
Accelerometer
0.558
0.527
0.379
0.884
Ionosphere
0.982
0.933
0.973
0.897
Wisconsin Breast Cancer
0.962
0.943
0.929
0.963
Sonar
0.990
0.804
0.990
0.800
HIGGS
0.663
0.564
0.586
0.693
Table 12: Recall for selected SaNDA classification methods and Random Forest for all chosen datasets
with 1% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.692
0.608
0.664
0.553
DIGEN24 2433
0.706
0.580
0.686
0.601
DIGEN39 5578
0.668
0.596
0.654
0.722
DIGEN17 6949
0.658
0.570
0.642
0.451
DIGEN32 5191
0.690
0.596
0.698
0.582
DIGEN10 8322
0.672
0.568
0.672
0.588
DIGEN22 2433
0.656
0.544
0.666
0.568
DIGEN8 4426
0.704
0.618
0.674
0.719
DIGEN35 4426
0.662
0.548
0.644
0.682
DIGEN36 466
0.682
0.586
0.666
0.503
Accelerometer
0.558
0.513
0.484
0.868
Ionosphere
0.991
0.938
0.973
0.897
Wisconsin Breast Cancer
0.962
0.948
0.934
0.963
Sonar
0.981
0.804
0.990
0.743
HIGGS
0.663
0.568
0.586
0.650
Table 13: Recall for selected SaNDA classification methods and Random Forest for all chosen datasets
with 5% missing values
19
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.688
0.598
0.654
0.645
DIGEN24 2433
0.706
0.600
0.696
0.524
DIGEN39 5578
0.660
0.578
0.696
0.636
DIGEN17 6949
0.622
0.510
0.600
0.457
DIGEN32 5191
0.668
0.538
0.632
0.500
DIGEN10 8322
0.704
0.572
0.664
0.575
DIGEN22 2433
0.664
0.548
0.642
0.677
DIGEN8 4426
0.668
0.608
0.718
0.634
DIGEN35 4426
0.660
0.542
0.646
0.656
DIGEN36 466
0.666
0.572
0.668
0.581
Accelerometer
0.559
0.498
0.367
0.845
Ionosphere
0.996
0.902
0.964
0.872
Wisconsin Breast Cancer
0.953
0.957
0.939
0.972
Sonar
0.959
0.825
1.000
0.686
HIGGS
0.659
0.569
0.586
0.597
Table 14: Recall for selected SaNDA classification methods and Random Forest for all chosen datasets
with 10% missing values
dataset
quantiles 20
ROC
20 bins
Random Forest
DIGEN23 5191
0.674
0.612
0.658
0.480
DIGEN24 2433
0.720
0.682
0.682
0.552
DIGEN39 5578
0.710
0.720
0.744
0.562
DIGEN17 6949
0.718
0.668
0.732
0.573
DIGEN32 5191
0.678
0.536
0.640
0.409
DIGEN10 8322
0.638
0.540
0.664
0.536
DIGEN22 2433
0.618
0.434
0.574
0.510
DIGEN8 4426
0.718
0.686
0.754
0.497
DIGEN35 4426
0.662
0.484
0.638
0.494
DIGEN36 466
0.748
0.766
0.742
0.541
Accelerometer
0.548
0.418
0.377
0.804
Ionosphere
0.991
0.920
0.973
0.667
Wisconsin Breast Cancer
0.962
0.948
0.943
0.944
Sonar
0.990
0.876
0.990
0.829
HIGGS
0.600
0.547
0.559
0.161
Table 15: Recall for selected SaNDA classification methods and Random Forest for all chosen datasets
with 50% missing values
20
Figure 1: Balanced accuracy (BA) of SaNDA classification method as a function the different abstraction
methods.
21
Figure 2: Balanced accuracy (BA) as a function of percentage of missing data for SaDNA with two best
performing abstraction methods (order quantiles 20 and 20 bins), SaNDA with ROC curve and Random
Forest.
22
Figure 3: Recall as a function of percentage of missing data for SaDNA with two best performing
abstraction methods (order quantiles 20 and 20 bins), SaNDA with ROC curve and Random Forest.
23
Figure 4: Precision as a function of percentage of missing data for SaDNA with two best performing
abstraction methods (order quantiles 20 and 20 bins), SaNDA with ROC curve and Random Forest.
24
"
This paper presents a study investigating human cognitive augmentation due to using ChatGPT in two experiments and concludes that using ChatGPT does not always enhance cognitive ability or replace human judgment and discernment.nan,"The use of tools enhances human cognitive performance, with calculators and spreadsheets improving mathematical calculations and software aiding in processing words, images, video, and numbers. However, unsupervised, deep, machine learning techniques have led to cognitive systems (cogs) outperforming humans in certain domains. These cogs can be utilized in a human/cog ensemble, leading to human cognitive augmentation. Specifically, the effect of ChatGPT on human cognitive augmentation is explored in this paper.nan","nanCognitive systems (cogs) have been designed using artificial intelligence (AI) and cognitive systems (cogs), allowing humans and cogs to collaborate in human/cog ensembles, enhancing human cognitive performance. Cogs outperform humans in various domains, such as detecting lung cancers better than human doctors and diagnosing childhood depression better than humans. Cognitive augmentation depends on the cog's sophistication, the amount of cognitive work it performs, and the human's level of collaboration. ChatGPT, a large language model that mimics human-created text, is used by millions of people for various tasks.nan","The authors conducted two experiments to compare human cognitive performance with and without using ChatGPT. In the first experiment, one group of students was assisted by ChatGPT, while the other was not, to synthesize innovative solutions to a problem statement. The second experiment involved retirement planning, with one group receiving ChatGPT assistance and the other prohibited from using ChatGPT. The responses were evaluated for expert-level quality.nan","For the innovation challenge, both groups predominantly suggested changing the field rather than the skeet, showing that ChatGPT did not alter the type of solutions generated. Interestingly, students using ChatGPT suggested ideas unrelated to the problem statement, potentially due to ChatGPT's response being driven by word association. For the retirement decision challenge, while more students using ChatGPT provided expert-level answers than those not using ChatGPT, the difference was not definitive. Furthermore, if non-ChatGPT students were disallowed from using a retirement calculator, ChatGPT students might have performed better.nan","Although ChatGPT is capable of producing expert-level responses, it does not guarantee it. Cognitive processes requiring high-level analysis, understanding, evaluation, and judgment are more difficult for ChatGPT to handle. ChatGPT may relieve humans of lower-level cognitive tasks, leading to significant cognitive augmentation in the future.nan",Does Using ChatGPT Result in Human Cognitive Augmentation?,"Ron Fulbright, Miranda Morrison","Does Using ChatGPT Result in Human Cognitive Augmentation? 
 
Ron Fulbright1, Miranda Morrison2 
University of South Carolina Upstate 
800 University Way, Spartanburg, SC USA 29303 
1fulbrigh@uscupstate.edu 
2morrisme@email.uscupstate.edu  
 
 
Abstract. Human cognitive performance is enhanced by the use of tools. For example, 
a human can produce a much greater, and more accurate, volume of mathematical 
calculation in a unit of time using a calculator or a spreadsheet application on a 
computer. Such tools have taken over the burden of lower-level cognitive “grunt 
work” but the human still serves the role of the expert performing higher-level 
thinking and reasoning. Recently, however, unsupervised, deep, machine learning has 
produced cognitive systems able to outperform humans in several domains. When 
humans use these tools in a human/cog ensemble, the human’s cognitive ability is 
augmented. In some cases, even non-experts can achieve, and even exceed, the 
performance of experts in a particular domain—synthetic expertise. A new cognitive 
system, ChatGPT, has burst onto the scene during the past year. This paper 
investigates human cognitive augmentation due to using ChatGPT by presenting the 
results of two experiments comparing responses created using ChatGPT with results 
created not using ChatGPT. We find using ChatGPT does not always result in 
cognitive augmentation and does not yet replace human judgement, discernment, and 
evaluation in certain types of tasks. In fact, ChatGPT was observed to result in 
misleading users resulting in negative cognitive augmentation. 
 
Keywords:  human cognitive augmentation, cognitive systems, human/cog 
ensembles 
 
 
 
1 
Introduction  
Human performance of any kind is augmented by the use of tools. Physical performance is 
enhanced by using simple tools like hammers, shovels, and axes. Likewise, human 
cognitive performance is augmented by the use of tools able to process and transform 
information. For example, unaided, a human might take several minutes to add a column 
of numbers, and then the sum would need to be checked because of the possibility of error 
in the calculations. However, using a calculator or a computer spreadsheet, a human could 
produce a reliable sum in a fraction of a second. In fact, entry of the numbers becomes the 
limiting factor in terms of speed. Today, we commonly use software able to process words, 
images, video, and numbers to perform our volume of daily work. Such tools have taken 
over the burden of lower-level cognitive “grunt work.” So far, though, the human still 
serves the role of the expert and performs the high-level thinking.  
Recently, however, cognitive systems technology (“AIs”) built using unsupervised, 
deep, machine learning techniques, has produced tools able to outperform humans in 
several domains formerly thought to be possible only as the result of high-level human 
cognitive processing. We call such systems “cogs.” When humans use tools like these in a 
collaborative manner (a human/cog ensemble) human cognitive performance is 
enhanced—augmented. If a human’s cognitive ability is augmented enough, even a non-
expert can achieve, and even exceed, the performance of an expert in a particular domain, 
something called synthetic expertise. So far, though, such cognitive systems are narrow in 
their applicability. Even though they outperform humans, they are limited to just that 
domain. 
Things are changing. Systems like the new Chat Generative Pre-Trained Transformer 
(ChatGPT), have gained much attention recently. ChatGPT is a large language model 
trained to predict the most probable next word in a sequence of words and is fine-tuned for 
conversational usage. ChatGPT mimics human-created text. Instead of being limited to a 
narrow domain, users can conduct extended textual dialogs with ChatGPT on practically 
any topic and most of the time, text generated by ChatGPT is indistinguishable from text 
produced by another human. Every day, millions of people use ChatGPT for assistance in 
learning, researching, getting advice, writing music, poetry, and prose, generating 
computer program code, and much more. A person using ChatGPT certainly fits our 
definition of a human/cog ensemble. Accordingly, the hypothesis explored in this paper is:  
 
H1: In a human/cog ensemble consisting of a person using ChatGPT we should 
be able to observe, measure, and characterize human cognitive augmentation in 
the form of enhanced performance when performing a task.  
 
To investigate the hypothesis, we designed two experiments to compare human 
cognitive performance with and without using ChatGPT. In one experiment we found a 
person using ChatGPT as a assistive tool was marginally better than a person not using 
ChatGPT but not enough for the result to be compelling. In the other experiment we found 
using ChatGPT had no effect on a person’s ability to perform the task and even misled 
users resulting in negative cognitive augmentation. 
 
 
2 Previous Work 
 
2.1 Cognitive Systems 
With recent advances in artificial intelligence (AI) and cognitive systems (cogs), we are at 
the beginning of a new era in human history in which humans will work in partnership with 
artificial entities capable of performing high-level cognition rivaling or surpassing human 
ability (Kelly & Hamm, 2013; Wladawsky-Berger, 2015; Gil, 2019; Fulbright, 2016a; 
2016b; 2020). Already, there are artificial systems and algorithms outperforming humans 
and achieving expert-level results.  
For example, a deep-learning algorithm has learned to detect lung cancers better than 
human doctors (Sandoiu, 2019). The algorithm outperforms humans in recognizing 
problem areas reducing false positives by 11% and false negatives by 5%.  
Google’s convolutional neural network, Inception v4, outperformed a group of 58 
human dermatologists using dermoscopic images and corresponding diagnoses of 
melanoma (Haenssle et al., 2018).  
In the field of diabetic retinopathy, a study evaluated the diagnostic performance of a 
cognitive system for the automated detection of diabetic retinopathy (DR) and Diabetic 
Macular Edema (DME) (Abràmoff, et al., 2018). The cog exceeded all pre-specified 
superiority goals.  
At the University of California San Francisco and the University of California 
Berkeley, an algorithm running on a convolutional neural network was better than experts 
at finding tiny brain hemorrhages in scans of patients’ heads (Kurtzman, 2019). The cog 
was able to complete a diagnosis in only one second, something a human would take many 
minutes to do.  
Cognitive systems are already better than humans at diagnosing childhood depression 
(Lavars, 2019), predicting mortality (Wehner, 2019), detecting valvular heart disease 
(Stevens, 2023), and assessing cancerous tumors (Towers-Clark, 2019).  
Not only are cognitive systems able to outperform humans in some domains, they are 
able to do things humans cannot. For example, the FIND FH machine learning model 
analyzed the clinical data of over 170 million people and discovered 1.3 million of them 
were previously undiagnosed as being likely to have familial hypercholesterolemia (Myers 
et al., 2019). Follow-on studies of the individual cases flagged by the cog have shown over 
80% of the cases do in fact have a high enough clinical suspicion to warrant evaluation and 
treatment. This means on the order of 800,000 people could receive life-extending 
treatment who otherwise would not. 
An algorithm named Word2Vec sifted through some 3.3 million abstracts and 
discovered associations previously unknown by human readers and predicted a new 
thermoelectric material four years before it was discovered (Tshitoyan, 2019; Gregory, 
2019).  
 
 
2.2 Cognitive Augmentation 
We can view data, information, knowledge, and wisdom (DIKW) as a hierarchy based on 
relative value (Ackoff, 1989). Each level is of a higher value than the level below it partly 
because of the processing involved to produce the information stock at that level and partly 
due to the utility of the information stock at that level. Information is processed data, 
knowledge is processed information, etc. Processing at each level can be modeled as a 
cognitive process.  Data, information, or knowledge, generically referred to as information 
stock, is input to the cognitive process. The cognitive process transforms the input and 
produces the higher-valued output. This transformation is accomplished by the expenditure 
of a certain amount of cognitive work (W) (Fulbright, 2020). 
In a human/cog ensemble, a collaborative team consisting of one or more humans and 
one or more cognitive systems), cognitive processing of the entire ensemble is a mixture 
of human cognitive processing (WH) and artificial cognitive processing (WC) (W* = WH + 
WC)  as depicted in Fig. 1 (Fulbright, 2020; 2020a; Fulbright & Walters, 2020). 
 
 
Fig. 3. A Human/Cog ensemble performing a cognitive process. 
A human working alone is able to achieve a certain amount of cognitive work. A 
human aided by a cognitive system is able to achieve a greater amount of cognitive work. 
We call this increase in cognitive performance, cognitive augmentation (Fulbright, 2017; 
2020). 
The amount of cognitive augmentation depends on how sophisticated the cognitive 
system, how much of the total cognitive work it performs, and how well the human 
collaborates with the cognitive system. Throughout history, humans have created ever-
evolving technology to assist in cognitive processing. As these systems get more capable, 
especially now in the era of artificial intelligence and unsupervised deep machine learning, 
cognitive augmentation will increase rapidly.   
Different Levels of Cognitive Augmentation have been defined ranging from no 
augmentation at all (all human thinking) to fully artificial intelligence (no human thinking) 
as shown in Fig. 2 (Fulbright, 2020; 2020a; Fulbright & Walters, 2020).  
 
 
 
 
 
 
 
Level 0:  No Augmentation 
 
the human performs all cognitive processing 
 
Level 1:  Assistive Tools 
 
e.g., abacus, calculators, software, etc. 
 
Level 2:  Low-Level Cognition 
 
pattern recognition, classification, speech 
 
human makes all high-level decisions 
 
Level 3:  High-Level Cognition 
 
concept understanding, critique 
 
conversational natural language 
 
Level 4:  Creative Autonomy 
 
human-inspired/unsupervised synthesis 
 
Level 5:  Artificial Intelligence 
 
no human cognitive processing 
 
 
Fig. 2. Levels of Cognitive Augmentation. 
 
In previous work, we have conducted various experiments designed to measure and 
characterize cognitive augmentation. Fulbright (2017; 2018) discusses several kinds of 
metrics and proposes several metrics to employ when measuring cognitive augmentation. 
Fulbright (2019) calculates cognitive augmentation for a given task finding cognitive 
augmentation as high as 74% when people are provided different numbers of hints by a 
simulated cognitive system. Fulbright & McGaha (2023) shows how information of 
different types affects the level of cognitive augmentation when tasked with solving several 
different kinds of puzzles. In both of these studies, enhanced cognitive accuracy and 
cognitive precision were measured.  
In all three of these studies assistive information supplied to the human was simulated 
and did not come from an actual cognitive system. However, ChatGPT represents a 
cognitive system, already used by millions, with which to conduct experiments in cognitive 
augmentation. There have been some notable studies comparing human performance to 
ChatGPT. 
 
 
2.3 ChatGPT and Cognitive Augmentation 
Li et al. (2023) compared the results of ChatGPT versus human performance on the 
Objective Structured Clinical Examination (OSCE) in obstetrics and gynecology. ChatGPT 
was asked to answer discussion questions in seven key disciplines within obstetrics and 
gynecology. ChatGPT outscored human test-takers in questions regarding postpartum 
management, urogynecology and pelvic floor problems, labor management, and post-
operative care. ChatGPT did not outperform humans in early pregnancy care, core surgical 
skills, or gynecologic oncology. Li et al. (2023) theorized those question require multiple 
answers and higher-level reasoning.  
Kung et al. (2023) found comparable results when administering the United States 
Medical Licensing Examination (USMLE) to ChatGPT. ChatGPT beat the passing score 
of 60% on most areas but narrowly failed to pass the multiple choice-question section 
(59.1%) and the multiple-choice with forced justification section (52.4%) on Step 2CK of 
the exam. Step 2CK is typically administered to students who have successfully completed 
their fourth year of medical school (Kung et al., 2023). 
In taking the American Board of Neurological Surgery Self-Assessment Examination 
1, Ali et al. (2023) found ChatGPT 3.5 achieved a score of 73.4% and GPT-4 achieved a 
score of 83.4% relative to the human average of 72.8%. Both versions of ChatGPT 
exceeded last year's passing threshold of 69%.  
Liéven et al. (2023) determined GPT-3.5 performed higher than the needed passing 
score on questions taken from the USMLE and MedMCQA examinations, however, GPT-
3.5 still underperformed on both examinations in comparison to humans.  
Brin et al. (2023), determined GPT-4 to have performed 10.77% better than human 
test-takers on multiple-choice questions from the USMLE involving soft skills, such as 
empathy, leadership, emotional intelligence, and communication.  
Similarly, Eloyseph et al. (2023) found ChatGPT to score 74.35% higher than males 
and 66.27% higher than females on the Levels of Emotional Awareness Scale (LEAS), a 
test measuring emotional intelligence in the form of open-ended questions that are 
evaluated by licensed psychologists. It is also worth noting ChatGPT took the LEAS 
evaluation twice: once in January and once in February. ChatGPT improved its LEAS score 
by 13% between the two exams.  
Duong & Solomon (2023) compared the ability of ChatGPT to humans in answering 
multiple-choice questions about genetics. Humans answered questions with 1.61% greater 
accuracy overall, but ChatGPT performed 8.51% better than humans on questions that 
relied on memorization instead of critical thinking.  
Jarou et al. (2023) administered multiple-choice questions from the American College 
of Emergency Physicians (ACEP) study guide. Human respondents scored 36.32% higher 
than GPT-3.5 and 19.5% higher than GPT-4; yet GPT-4 scored 33.71% higher than GPT-
3.5.  
Additionally, Katz et al. (2023) compared the performance of GPT-3.5 and GPT-4 
with human respondents on the Uniform Bar Exam. GPT-4 performed 11.3% better than 
human test-takers, but GPT-3.5 could not exceed human performance in any of the subject 
areas tested on the exam. 
Instead of situations in which ChatGPT replaces humans, this paper is interested in 
exploring how using ChatGPT enhances a user’s cognitive ability as stated in the 
hypothesis, H1. Unfortunately, there have not yet been a lot of studies like this. Noy and 
Zhang (2023) assigned 444 professionals with tasks related to their respective profession, 
such as sensitive e-mails, press releases, and reports. After completing the initial task, the 
group was split in two. The control group was asked to repeat the task using LaTeX, a 
document preparation program, while the test group used ChatGPT to assist them with their 
second task. Those using ChatGPT reduced the time spent on the task by 35.16% and 
improved their score on the second task by 15.45%. 
 
3 The Experiments 
 
This paper presents the results of two experiments in which we asked students to perform 
a task and comparing their performance with that of an expert. Students were tasked with 
two different challenges, an innovation problem and an expert advice question. Students 
used ChatGPT 3.5 (circa November 2023, January 2024) in these experiments.  
  
3.1 Innovation Challenge 
For the innovation challenge, students were given the following problem statement: 
When shooting skeet, fragments from the skeet fall on and cause harm to the 
grass field by preventing sunlight and water from reaching the grass. What 
changes can I make to protect the grass?   
This is the same problem statement used in a previous cognitive augmentation 
experiment described in Fulbright (2019). In that experiment, students were given hints in 
the form of innovative suggestions (called operators) and the results showed it was possible 
to affect the innovative solutions arrived at by the participants toward a desired goal—the 
preferred solution. In fact, results showed as much of a 74% increase in cognitive accuracy 
was achieved demonstrating significant cognitive augmentation.  
Participants were asked to synthesize three innovative solutions to the problem. Any 
solution could not interfere with the sheet shooting activity, must be relatively easy and 
inexpensive to implement, and involve as little change to the current situation as possible. 
One-half of the participants were instructed to not use any Internet-based resource at all. 
The other half were instructed to use only ChatGPT. 
This innovation problem was chosen because it is a problem used in teaching 
innovation at the university undergraduate level for over many years. As such, there is a 
long history of solutions, and patterns of solutions, to compare new results with. Because 
of this history, we know what type of solutions people give when not aided by any cognitive 
system or assistive information and we know what type of solutions are given by 
professional/expert innovators. 
With respect to H1, our goal was to see if using ChatGPT altered the type of solutions. 
If H1 was verified in this experiment, we would expect to see the solutions trend toward 
the professional/expert type of solutions.  
 
3.2 Retirement Decision 
For the second experiment, participants were given detailed information about an 
imaginary college professor approaching retirement. Information provided included: age, 
profession (and pros and cons of the profession), salary, debt, medical situation, retirement 
savings, with the goals of being able to remain in the current home, travel at least twice per 
year after retirement, and not outliving their money. 
Participants were asked if the person should retire early at 67 or wait until the age of 
70. A person can go to a retirement planning expert and ask this question and receive a 
detailed response including an explanation of why it is better to retire at 67 or wait until 
70. None of the participants, being university students, were experts in retirement planning. 
However, we asked each participant to provide a specific answer (either 67 or 70) and then 
also provide a justification to support the answer. In our judgement of the results, it did not 
matter which age was given as the answer. We focused on the level of detail in the 
justification. A detailed and specific justification, in our view, constituted an expert-level 
answer to the challenge. 
One-half of the participants were instructed to use ChatGPT only, an no other Internet-
based resource, and the other half was instructed to use any Internet-based resource except 
ChatGPT. With respect to H1, we expected to see an increase in the ability of participants 
to provide an expert-level answer due to using ChatGPT. 
 
4 
The Results  
4.1 Innovation Challenge Results 
For the innovation challenge, 13 students used ChatGPT and 13 students did not use 
ChatGPT to synthesize a total of N=96 ideas to solve the skeet shooting innovation 
challenge. As we have seen in earlier studies using this problem statement, ideas fell into 
three broad categories: changing the field (F), changing the skeet (T), or ideas not solving 
the problem at all (X). Ideas involving the field fell into three different subcategories and 
ideas involving the skeet fell into two categories:  
 
 
FT  
protecting the field with a tarp, net, or some other kind of covering 
 
FC 
ways of cleaning the field or making picking up fragments easier 
 
FG 
changing or replacing the grass on the field 
 
TB 
replacing clay skeet with biodegradable material 
 
TC 
changing the clay skeet to make cleanup more easier 
 
X 
ideas addressing ideas other than the stated problem 
 
 
 
Fig. 4 shows the results for students not using ChatGPT. Overwhelmingly, most ideas 
(79.5%) involved changing the field in some way such as covering it with a tarp or net to 
prevent fragments from reaching the grass or various ways to clean the field after fragments 
have fallen onto the grass. The remainder (20.5%) of the ideas involved changing the clay 
skeet such as making the skeet out of biodegradable material or out of some material other 
than clay to facilitate easier cleanup. Field-related ideas out numbered skeet-related ideas 
3.8:1. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3. Solutions Using ChatGPT for Assistance (47 ideas). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4. Solutions Not Using ChatGPT for Assistance (39 ideas). 
 
Fig. 3 shows the results for students using ChatGPT. As in Fig 4, ideas involving 
changing the field vastly outnumber ideas involving changing the skeet by almost exactly 
the same ratio 3.75:1. Therefore, we see no difference in the type of ideas generated as a 
result of using ChatGPT. Therefore, the hypothesis, H1, is refuted. 
FT (11) 
23.4% 
FC (14) 
29.8% 
FG (5) 
 
10.6% 
63.8% (30) 
Change Field 
TB (5) 
10.6% 
TC (3) 
 
6.4% 
17.0% (8) 
Change Skeet 
XB 
No Solution 
19.1% (9) 
FC (12) 
30.7% 
FT (17) 
43.6% 
FG (2) 
 
5.1% 
79.5% (31) 
Change Field 
TB (6) 
15.4% 
TC (2) 
 
5.1% 
20.5% (8) 
Change Skeet 
N = 47 ideas 
N = 39 ideas 
Interestingly, students using ChatGPT synthesized a number of ideas having no effect 
at all on the primary problem—littering of the grass by the fragments. Examining these 
ideas in detail shows these ideas were related to “educating shooters about the 
environmental impact” and “educating shooters about gun safety.” These ideas can be 
explained when one analyzes the response from ChatGPT when given the problem 
statement as the prompt. ChatGPT is trained from articles and other content available on 
the Internet. Because the problem statement involves guns and shooting, ChatGPT 
responded with suggestions to educate shooters about gun safety because on the Internet, 
when one sees a document about guns and shooting, it is very likely to also include 
comments about safety. Even though the concepts of guns and safety are understandably 
related, the safety issue has nothing to do with solving the problem given in the problem 
statement—littering the grass field. ChatGPT however does not perform such in-depth 
analysis to realize this. ChatGPT’s responses are driven by word association. Likewise, 
because the problem statement mentions littering and damaging grass, ChatGPT finds 
associations with environmental issues important and therefore responded to students 
suggesting education about the environment since this is found in millions of pages on the 
Internet when litter and harming grass is mentioned. While one could argue you might be 
able to talk a shooter out of shooting after they understand the harm to the grass, this is not 
likely to change the mind of the vast majority of shooters, so is not a practical solution. 
Interestingly, in this case, using of ChatGPT actually distracted students by misleading 
them to consider things having nothing to do with the problem. Therefore, one could argue 
using ChatGPT actually decreased cognitive ability—resulting in negative cognitive 
augmentation.      
 
4.2 Retirement Decision Results 
For the retirement decision challenge, 15 students used ChatGPT and 10 students did not 
use ChatGPT. The challenge asked students to provide a specific answer, whether or not 
the subject should retire at 67 or 70 and also provide an expert-level justification of that 
answer. We explained to the students how people could visit a retirement planning 
professional and receive guidance and we asked students to provide a similar-quality 
answer here.  
Responses were judged to be either “expert quality” or “non-expert quality” as seen in 
Fig. 5. The difference between an expert and a non-expert response is in the details 
provided in the justification. To answer the question properly, one must calculate the 
monthly inflow and outflow of money. To do that, one has to find out how much per month 
social security payments would be and add to that withdrawals from savings to augment 
the monthly inflow. Once this is established, one has to calculate how long the subject’s 
money would last. Very different answers are obtained if one retires at age 67 versus 70. 
In judging the responses, we did not consider which answer the student provided. It did not 
matter at what age the student decided the subject should retire. What we did look for, 
though, is did the student conduct and include the analysis needed to justify their response. 
Reponses including the analysis were deemed “expert” and the responses not including the 
analysis were deemed “non-expert.” 
Another characteristic of non-expert responses was “generic” information like “the 
person must consider how long their savings will last.” While this is certainly is something 
a person needs to consider when planning retirement, one would not have to visit an expert 
to get this advice. Any friend, family member, or easy search on the Internet will produce 
a list of such things for one to consider. In fact, the first response from ChatGPT gives a 
list of  8-10 such generic issues to consider. So, a response simply containing generic 
information like this was considered “non-expert.”  
Fig. 5 shows students not using ChatGPT provided expert-quality answers 40% of the 
time. Students using ChatGPT provided expert-quality answers 53% of the time. While 
this is an increase, it is not a definitive increase in our opinion. Of further note, is of the 
students using ChatGPT, there was only one more expert response than non-expert 
response. If ChatGPT provided demonstrable cognitive augmentation for this task, one 
would expect many more expert answers than non-expert answers from the group of 
students using ChatGPT.  
Students not using ChatGPT were allowed to use any other Internet-based resource 
and reported the tool or information source they used. We observed all expert-quality 
answers from the non-ChatGPT group were provided by students who used a retirement 
calculator available on the Internet. We believe the students using a retirement calculator 
were cognitively augmented just like students using ChatGPT. In fact, the retirement 
calculator is an assistive tool designed specifically to help answer retirement planning 
questions whereas ChatGPT is not. Although we are not able to definitively conclude it in 
this study, we believe if non-ChatGPT students were not allowed to use a retirement 
calculator, the number of expert-quality answers would be much lower and students using 
ChatGPT would have performed much better.    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 5. Responses to the Retirement Decision Challenge (25 responses). 
 
 
5 Conclusion  
Our hypotheses, H1 was refuted in the innovation experiment and only moderately 
confirmed in the retirement decision experiment. In fact, in the innovation experiment, 
ChatGPT actually misled students to thinking about issues irrelevant to the problem 
statement, resulting in negative cognitive augmentation. Both experiments involved tasks 
requiring detailed analysis, high-level reasoning, and human judgment and were questions 
without a definite right and wrong answer. To this extent, we confirm the findings of Li et 
al. (2023), Liéven et al. (2023), Jarou et al. (2023), and  Katz et al. (2023) who found 
ChatGPT outperformed humans on some types of questions but not those involving higher-
level analysis.   
Our results show using ChatGPT does not guarantee expert-level performance. None 
of the students participating in this study were experts at using ChatGPT. For some, this 
task was the first time they ever used ChatGPT. If students had more experience with 
ChatGPT, more expert-level results might be expected. Also, students who participated 
were not given detailed instructions on how to answer retirement questions nor how to 
think innovatively. If they had knew more about the subject, it stands to reason more would 
have been able to provide expert-quality answers. This can be explored in future studies. 
It is necessary to note, when designing these experiments, we found it quite difficult 
to determine  tasks to give to students. We tested and discarded several tasks before 
deciding on the innovation and retirement challenges because we found ChatGPT was able 
to simply spit out a perfectly correct answer on the first prompt. Over time, we realized we 
could not ask students to perform any task involving just simple knowledge retrieval 
Expert (4) 
40% 
Not Using ChatGPT 
Non-Expert (6) 
60% 
Expert (8) 
53% 
Using ChatGPT 
Non-Expert (7) 
47% 
because ChatGPT does this quite well. To create a challenge tough enough, we realized the 
tasks needed to require cognitive processes involving understanding, evaluation, 
appraisal, critique, and judgment in order to exercise the students and ChatGPT more 
vigorously.  
We recognize these types of cognitive processes represent the upper levels of Bloom’s 
Taxonomy, a framework for categorizing educational goals and therefore classifying levels 
of cognitive processes (Bloom et. al., 1956; Anderson & Kratwohl, 2001). We expect 
future studies to show ChatGPT already able to take the cognitive “grunt work” of lower-
level cognitive processes like recall, defining, listing, classifying, describing, discussing, 
explaining, translating, and recognizing away from the human in a human/cog ensemble. 
Any task involving these levels of cognitive processing will be done quicker and better by 
ChatGPT leaving the human to do the higher-level cognitive processing. Relieving the 
human of the cognitive “grunt work” will result in significant cognitive augmentation in 
the form of higher-quality, higher-value results in less time with less effort. 
 
 
References  
  
1. 
Abràmoff, M. D., Lavin, P. T., Birch, M., Shah, N. and Folk, J. C. (2018). Pivotal trial of an 
autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care 
offices. Digital Med., 1: 39. Available online at: https://www.nature.com/articles/s41746-018-
0040-6, last accessed January 2024. 
2. 
Ackoff, R. (1989). From Data to Wisdom, Journal of Applied Systems Analysis, 16. Available 
online: https://faculty.ung.edu/kmelton/Documents/DataWisdom.pdf last accessed February 
2023. 
3. 
Ali, R., Tang, O. Y., Connolly, I. D., Zadnik Sullivan, P. L., Shin, J. H., Fridley, J. S., Asaad, 
W. F., Cielo, D., Oyelese, A. A., Doberstein, C. E., Gokaslan, Z. L., & Telfeian, A. E. (2023). 
Performance of CHATGPT and GPT-4 on Neurosurgery Written Board Examinations. 
Neurosurgery. https://doi.org/10.1227/neu.0000000000002632. 
4. 
Anderson, L. W., Krathwohl, D. R., Airasian, P. W., Cruik-shank, K. A., Mayer, R. E., (2001). 
A taxonomy for learning, teaching, and assessing: A revision of Bloom's taxonomy of 
educational objectives, Pearson. 
5. 
Bloom, B. S.,  Engelhart, M. D., Furst, E. J., Hill, W. H., Krath-wohl, D. R., (1956). 
Taxonomy of educational objectives: The classification of educational goals. Handbook I: 
Cognitive domain. New York: David McKay Company. 
6. 
Brin, D., Sorin, V., Vaid, A., Soroush, A., Glicksberg, B. S., Charney, A. W., Nadkarni, G., & 
Klang, E. (2023). Comparing ChatGPT and GPT-4 Performance in USMLE Soft Skill 
Assessments. Scientific Reports, 13(1). https://doi.org/10.1038/s41598-023-43436-9. 
7. 
Elyoseph, Z., Hadar-Shoval, D., Asraf, K., & Lvovsky, M. (2023). ChatGPT Outperforms 
Humans in Emotional Awareness Evaluations. Frontiers in Psychology, 14. 
https://doi.org/10.3389/fpsyg.2023.1199058.   
8. 
Fulbright, R. (2016a). The Cogs Are Coming: The Cognitive Augmentation Revolution, 
Proceedings of the Association Supporting Computer Users in Education 2015 (49th, Myrtle 
Beach, SC). Available online at: https://eric.ed.gov/?q=cognitive+development+ 
in+early+childhood&ff1=dtysince_2014&pg=1340&id=ED570900, last accessed January 
2024. 
9. 
Fulbright, R. (2016b). How Personal Cognitive Augmentation Will Lead To The 
Democratization Of Expertise, Advances in Cognitive Systems, 4. Available online at: 
http://www.cogsys.org/posters/2016/poster-2016-3.pdf, last viewed January 2024. 
10. Fulbright, R. (2017). Cognitive Augmentation Metrics Using Representational Information 
Theory, In: Schmorrow D., Fidopiastis C. (eds) Augmented Cognition. Enhancing Cognition 
and Behavior in Complex Human Environments,  AC 2017, Lecture Notes in Computer 
Science, vol 10285. Springer, Cham. Available online: 
https://link.springer.com/chapter/10.1007/978-3-319-58625-0_3 last accessed 2023. 
11. Fulbright, R. (2018). On Measuring Cognition and Cognitive Augmentation, In: Yamamoto, 
S., Mori, H. (eds) Human Interface and the Management of Information, HIMI 2018, Lecture 
Notes in Computer Science, vol 10905. Springer, Cham. Available online: 
https://link.springer.com/chapter/10.1007/978-3-319-92046-7_41 last accessed February 2023. 
12. Fulbright, R. (2019). Calculating Cognitive Augmentation -A Case Study, In: Schmorrow, D. 
and Fidopiastis, C. (eds) Augmented Cognition,  AC 2019, Lecture Notes in Computer Science, 
vol 11580. Springer, Cham. Available online: https://link.springer.com/chapter/10.1007/978-
3-030-22419-6_38 last accessed February 2023. 
13. Fulbright, R. (2020). Democratization of Expertise: How Cognitive Systems Will Revolutionize 
Your Life, CRC Press, Boca Raton, Fl.  
14. Fulbright, R. (2020a). The Expertise Level, In: Schmorrow D., Fidopiastis C. (eds) Augmented 
Cognition. Human Cognition and Behavior. HCII 2020. Lecture Notes in Computer Science, 
vol 12197. Springer, Cham. Available online: https://link.springer.com/chapter/10.1007/978-
3-030-50439-7_4 last accessed February 2023. 
15. Fulbright R. and Walters, G. (2020). Synthetic Expertise, In: Schmorrow D., Fidopiastis C. 
(eds) Augmented Cognition. Human Cognition and Behavior. HCII 2020. Lecture Notes in 
Computer Science, vol 12197. Springer, Cham. Available online: 
https://link.springer.com/chapter/10.1007/978-3-030-50439-7_3 last accessed February 2023. 
16. Fulbright R. and McGaha, S. (2023). The Effect of Information Type on Human Cognitive 
Augmentation, In: Schmorrow, D. and Fidopiastis, C. (eds), Augmented Cognition: 17th 
International Conference, AC 2023, held as Part of the 25th HCI International Conference, 
HCII 2023, Copenhagen, Denmark, July 23–28, 2023, pages 206- 220. Available online at: 
https://dl.acm.org/doi/abs/10.1007/978-3-031-35017-7_14, last viewed January 2024. 
17. Gil, D. (2019). Cognitive systems and the future of expertise, YouTube video located at 
https://www.youtube.com/watch?v=0heqP8d6vtQ and last accessed February 2023. 
18. Gregory, M., (2019). AI Trained on Old Scientific Papers Makes Discoveries Humans Missed, 
Vice Internet page located at: https://www.vice.com/en_in/article/neagpb/ai-trained-on-old- 
last accessed January 2024. 
19. Haenssle, H. A., Fink, C., Schneiderbauer, R., Toberer, F., Buhl, T., Blum, A., Kalloo, A., 
Hassen, A. B. H., Thomas, L., Enk, A. and Uhlmann, L. (2018). Man against machine: 
diagnostic performance of a deep learning convolutional neural network for dermoscopic 
melanoma recognition in comparison to 58 dermatologists. Annals of Oncology, 29(8): 1836–
1842. August. Available online: https://academic.oup.com/annonc/article/29/8/1836/5004443, 
last accessed November 2019. 
20. Jarou, Z. J., Dakka, A., McGuire, D., & Bunting, L. (2023). ChatGPT Versus Human 
Performance on Emergency Medicine Board Preparation Questions. Annals of Emergency 
Medicine. https://doi.org/10.1016/j.annemergmed.2023.08.010. 
21. Katz, D. M., Bommarito, M. J., Gao, S., & Arredondo, P. (2023). GPT-4 Passes the Bar Exam. 
SSRN Electronic Journal. https://doi.org/10.2139/ssrn.4389233.   
22. Kelly, J.E. and Hamm, S. (2013). Smart Machines: IBMs Watson and the Era of Cognitive 
Computing, Columbia Business School Publishing, Columbia University Press, New York, 
NY. 
23. Kung, T. H., Cheatham, M., Medenilla, A., Sillos, C., De Leon, L., Elepaño, C., Madriaga, M., 
Aggabao, R., Diaz-Candido, G., Maningo, J., & Tseng, V. (2023). Performance of ChatGPT 
on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models. 
PLOS Digital Health, 2(2). https://doi.org/10.1371/journal.pdig.0000198   
24. Kurtzman, L. (2019). AI Rivals Expert Radiologists at Detecting Brain Hemorrhages: Richly 
Annotated Training Data Vastly Improves Deep Learning Algorithm’s Accuracy, UCSF News, 
University of California San Francisco. Available online at: https://www.ucsf.edu/news/ 
2019/10/415681/ai-rivals-expert-radiologists-detecting-brain-hemorrhages, last viewed 
January 2024. 
25. Lavars, N. (2019). Machine learning algorithm detects signals of child depression through 
speech, New Atlas, published May 7. Available online at https://newatlas.com/machine-
learning-algorithm-depression/59573/ last accessed February 2023. 
26. Li, S. W., Kemp, M. W., Logan, S. J. S., Dimri, P. S., Singh, N., Mattar, C. N. Z., Dashraath, 
P., Ramlal, H., Mahyuddin, A. P., Kanayan, S., Carter, S. W. D., Thain, S. P. T., Fee, E. L., 
Illanes, S. E., Choolani, M. A., Rauff, M., Biswas, A., Low, J. J. H., Ng, J. S., … Lim, M. Y. 
(2023). ChatGPT Outscored Human Candidates in a Virtual Objective Structured Clinical 
Examination in Obstetrics and Gynecology. American Journal of Obstetrics and Gynecology, 
229(2). Available online at: https://pubmed.ncbi.nlm.nih.gov/37088277/, last viewed January 
2024. 
27. Liévin, V., Hother, C. E., & Winther, O. (2023). Can Large Language Models Reason About 
Medical Questions? arXiv. https://doi.org/https://doi.org/10.48550/arXiv.2207.08143. 
28. Myers, K. D., Knowles, J. W., Staszak, D., Shapiro, M. D., Howard, W., Yadava, M., Zuzick, 
D., Williamson, L., Shah, N. H., Banda, J. M., Leader, J., Cromwell, W. C., Trautman, E., 
Murray, M. F., Baum, S. J., Myers, S., Gidding, S. S., Wilemon, K. and Rader, D. J. (2019). 
Precision screening for familial hypercholesterolaemia: a machine learning study applied to 
electronic health encounter data, Lancet Digital Health, Available online at: 
https://www.thelancet.com/journals/ landig/article/PIIS2589-7500(19)30150-5/fulltext, last 
accessed January 2024. 
29. Noy, S., and Zhang, W. (2023). Experimental Evidence on the Productivity Effects of Generative Artificial 
Intelligence, Science, Vol 381, Issue 6654, pp. 187-192. Available online at: https://www.science.org/ 
doi/10.1126/science.adh2586, last viewed January 2024. 
 
30. [Stevens] (2023). Listen to your heart: AI tool detect heart diseases that doctors often miss, Stevens Institute 
of Technology media release. Available online at: https://www.stevens.edu/ news/listen-to-your-heart-ai-tool-
detects-cardiac-diseases-that-doctors-often#, last viewed January 2024. 
31. Sandoiu, A. (2019). Artificial intelligence better than humans at spotting lung cancer. Medical 
News Today Newsletter, May 20. Available online: https://www. 
medicalnewstoday.com/articles/325223.php#1, last accessed November 2019.  
32. Tshitoyan, V., Dagdelen, J., Weston, L., Dunn, A., Rong, Z., Kononova, K., Persson, A., 
Ceder, G., and Jain, A. (2019). Unsupervised word embeddings capture latent knowledge from 
materials science literature, Nature, 571. Available online at: https://www.nature.com/ 
articles/s41586-019-1335-8, last viewed January 2024. 
33. Towers-Clark, C. (2019). The Cutting-Edge of AI Cancer Detection, Forbes, published April 
30. Available online at  https://www.forbes.com/sites/charlestowersclark/ 
2019/04/30/the-cutting-edge-of-ai-cancer-detection/#45235ee77336 last accessed February 
2023. 
34. Wehner, M. (2019). AI is now better at predicting mortality than human doctors, New York 
Post, published May 14. Available online at https://nypost.com/2019/05/14/ai-is now-better-
at-predicting-mortality-than-human doctors/?utm_campaign=partnerfeed&utm_medium= 
syndicated&utm_source=flipboard last accessed February, 2023.  
35. Wladawsky-Berger, I. (2015). The Era of Augmented Cognition, The Wall Street Journal: 
CIO Report Internet page located at http://blogs.wsj.com/cio/2013/06/28/the-era-of-
augmented-cognition/ last accessed February 2023. 
 
 
"
"The concept of Spatial XR-IoT (XRI) Zone Agents is presented, merging Extended Reality (XR), the Internet of Things (IoT), and spatial computing for smart environments. These zone agents serve as applications and companions in shared spaces, reducing the gap between the physical environment and traditional user interfaces. By incorporating Mixed Reality Agents (MiRAs), agent and scene design strategies are outlined for spatial zone agents. A prototype and user interaction scenario demonstrate human-to-space agent relationships in an immersive smart-space application.nan","The metaverse integrates computing technologies to combine virtual and physical spaces, connecting the digital and real worlds. However, a gap exists between users' physical and virtual environments, referred to as the metaverse disconnect. To address this, the method of XRI (XR-IoT) is introduced, supporting hyper-connected metaverse environments. XRI combines IoT components and hybrid physical-virtual interactions to create smart spaces that are social, smart, engaging, and immersive. These concepts lay the groundwork for enriching user information architecture across applications and smart space configurations.nan","Researchers have explored methods to enhance the connection between users and smart spaces, aiming to reduce the metaverse disconnect. The XRI concept, combining XR and IoT, is presented along with early frameworks and proof-of-concept prototypes. These prototypes demonstrated the integration of virtual plants in mixed reality connected to physical environments via IoT, as well as enhanced head-mounted display prototypes. Metaverse has various definitions, reflecting its evolving state, ranging from immersive 3D digital environments to a combination of internet, web technologies, and extended reality. The metaverse is envisioned as the next generation of the internet, increasing connectivity with physical spaces.nannan","The research integrates insights from Mixed Reality Agents (MiRAs), spatial computing and interface, and agent system design. These theories are combined and adapted into a three-dimensional design space for XRI Zone Agents. The dimensions include the mixed reality dimension, the level of agency, and the physical-remote (PR) spatial interaction capacity. This framework is used to design spatial zone agents with different interactions, capabilities, and objectives.nan","A prototype of the XRI Zone Agent is presented, demonstrating scenario-based user interaction within a laboratory environment. When users navigate the lab wearing an XR HMD, they encounter virtual agents, such as a plant avatar, that provide guidance and enable user-selected tasks. These tasks include study mode, relaxation mode, and meeting mode, each represented by a spatial zone agent. The agents respond to user actions, such as thumbs-up gestures, and control virtual objects and physical IoT devices (e.g., lights, projectors) based on user context and spatial location.nan","This work offers a theoretical framework for considering smart-space zones as agents and explores mixed reality and IoT (XRI) zone agents using design-theoretic methods. It envisions that zone agents would adapt to user spatial contexts and needs through changes in physical or virtual reality. The presented high-level user interaction design, based on three zone agents for work, leisure, and meetings, illustrates potential applications of these concepts. The research aims to pave the way for further exploration of space-to-human and human-to-space interactions driven by mixed-reality agents and user and environmental context within zones.nan",Design Frameworks for Spatial Zone Agents in XRI Metaverse Smart Environments,"Jie Guan, Jiamin Liu, Alexis Morris","©2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any
current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new
collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other
works.
arXiv:2401.11040v1  [cs.HC]  19 Jan 2024
Design Frameworks for Spatial Zone Agents
in XRI Metaverse Smart Environments
Jie Guan
Adaptive Context Environments Lab
OCAD University
Toronto, Canada
jie.guan@ocadu.ca
Jiamin Liu
Adaptive Context Environments Lab
OCAD University
Toronto, Canada
jiaminliu@ocadu.ca
Alexis Morris
Adaptive Context Environments Lab
OCAD University
Toronto, Canada
amorris@ocadu.ca
Abstract—The spatial XR-IoT (XRI) Zone Agents concept
combines Extended Reality (XR), the Internet of Things (IoT),
and spatial computing concepts to create hyper-connected spaces
for metaverse applications; envisioning space as zones that are
social, smart, scalable, expressive, and agent-based. These zone
agents serve as applications and agents (partners, assistants, or
guides) for users co-living and co-operating together in a shared
spatial context. The zone agent concept is toward reducing the
gap between the physical environment (space) and the classical
two-dimensional user interface, through space-based interactions
for future metaverse applications. This integration aims to enrich
user engagement with their environments through intuitive and
immersive experiences and pave the way for innovative human-
machine interaction in smart spaces. Contributions include: i) a
theoretical framework for creating XRI zone/space-agents using
Mixed-Reality Agents (MiRAs) and XRI theory, ii) agent and
scene design for spatial zone agents, and iii) prototype and user
interaction design scenario concepts for human-to-space agent
relationships in an early immersive smart-space application.
Index Terms—Virtual Reality, Mixed Reality, Augmented Real-
ity, Internet of Things, Human-Computer Interaction, Metaverse
I. INTRODUCTION
The Metaverse refers to the merger of computing technolo-
gies that blend virtual and physical spaces; applying technolo-
gies such as Artificial intelligence and Extended Reality and
the internet-of-things [1]. These technologies aim to provide
digital twins of the real world as well as completely virtual
shared environments; however, in both cases there is a clear
gap between the user’s physical environment and their virtual
environment. This is referred to as the metaverse disconnect
problem and researchers have explored methods to increase
the connection between users and their relationships to smart
spaces [2]–[5]. To enhance the communication and connection
between the metaverse and physical environments and objects,
the method of XRI (XR-IoT) [6], [7] is introduced for support-
ing the hyper-connected metaverse environment. These XRI
components allow for the creation of hybrid physical-virtual
objects as well as the hybrid physical-virtual interactions that
can take place. As more “hybrid objects” are combined into a
user’s space, this results in a “hyper-connected” environment
that can be social, smart, engaging, and immersive, as in [8].
Such environments are poised to enrich the user’s information
Tri-council of Canada, Canada Research Chairs program.
architecture, as in [9] in terms of placemaking (presence),
consistency(mental models), resilience (adaptation), reduction
(context adaptation), and correlation (exploration), across ap-
plications and smart space configurations (small home spaces,
work spaces, larger scale city environments, etc).
Fig. 1.
XRI smart-spaces [6] can be transformed into zone-aware spatial
agents that have potential to interact with users based on their spatial contexts.
This work focuses on design components and strategies for these agents [10].
However, these designs still have interaction challenges
between humans, agents, and spaces of the metaverse context.
This vision of the metaverse requires user, multi-agent, XRI,
and Spatial Computing Interfaces in order to make the hybrid
environment fit the user application context. Figure 1 presents
a high-level XRI smart space (objects, IoT components,
cameras, as well as virtual agents, etc), and highlights that
multiple design components and strategies for mixed reality
interactions, from [10], can be considered toward not just
mixed reality or IoT objects, but also spatial zone agents
(or zone as agent designs). This work presents the design of
example zone-based agents and agent interactions using an
early framework. It addresses the question of how to design a
spatial zone agent for metaverse interactions, and an approach
for creating zone agent prototypes. Contributions include: i)
a theoretical framework for creating XRI zone/space-agents
using Mixed Reality Agents (MiRAs) theory [11] and XRI,
ii) agent and scene design for spatial zone agents, and iii)
prototype and user interaction design scenario and concepts
for human-to-space agent relationships in an early immersive
smart-space application.
Fig. 2. Zone-aware spatial agents can have a range of Physical and Remote
interaction abilities and properties, as well as Mixed Reality Agency (MiRAs),
as seen in examples 1-5, based on [11] [10].
II. BACKGROUND
XRI and Metaverse: The early frameworks and proof-of-
concept prototypes of XR and IoT for specific scenarios had
been presented in [12] [13] to connect the physical information
and the virtual GUI and objects. Based on this foundation,
previous works also explored a virtual plant embodied in
Mixed Reality and connected to the physical environment via
IoT in mobile device [14], and an enhanced head-mounted
display prototype, in [15] [16]. The XRI concept also appears
in [7] with a taxonomy and workstation prototype in [6].
Metaverse has diverse definitions as it is a developing term
in the state of the art. As in [17], the metaverse is considered
to be constructed by the immersive and three-dimensional
digital online environments, while in [1] [18], it is considered
metaverse is constructed by internet, web technologies and
extended reality with hybridization of physical and virtual
space. Metaverse has been considered as the next generation
of the internet in both industry and academia [19]. Together,
the metaverse as a virtual online environment is envisioned
to increase the connectedness with the physical space. Hence,
the concept of extending the metaverse with XRI has been
presented in previous works such as in [2]–[5], [8].
Spatial Computing and interface: Spatial computing in-
corporates the concept and technologies to create a new
understanding of locations, improving the relationship between
humans and space [20]. Spatial Computing is the human-
in-the-loop interaction that engages with real objects and
space; together with the recent trend of mixed reality that
merges real and virtual worlds, the need for mapping virtual
environments in the real-world is becoming more important
[21]. Spatial computing allows users to interact freely with
the 2D interface and three-dimensional information that spatial
augmented reality provides [22].
Agent System Design (Agency): Agent System Design is
an interdisciplinary field, within Artificial Intelligence, as in
[23], which has been instrumental in laying the groundwork
for creating intelligent and scalable agent-based systems. This
foundation has opened avenues for innovation in various
realms, including Mixed Reality. The Mixed Reality Agents
(MiRAs) [11] framework considers agents that are designed
to operate within mixed reality environments, with dimensions
in embodiment, interaction and agency level. Moreover, the
robot as an agent has been explored within the domain of
Human-Robot Interaction (HRI) and Extended Reality (XR)
[10], where they can act to bridge the chasm between the
human environment and the digital world [24].
Agent systems integrate AI, software design, and HCI
[25], cognitive architectures, like Prometheus [26], and other
beliefs-desires-intentions (BDI) frameworks, and machine
learning models, like those used in robotics and games [27],
[28], and deploy approaches like Behavior Trees for decision-
making [29], [30]. Similarly, in entertainment, Emotional AR
Agents can enhance immersion and interactivity [31]–[33],
and in HRI, agent embodiment can influence user perception,
particularly with recent advancements in generative AI (like
DALL-E and VQGAN) revolutionizing agent visual represen-
tation and understanding capabilities [34]–[37].
Together, these indicate new directions for future metaverse
spaces that are agent-based, zone-oriented, and immersive.
III. THEORY - DESIGNING A SPATIAL ZONE AGENT FOR
XRI SMART SPACES
Design Dimensions for Spatial Zone Agents: MiRAs and
XRI and HRI Taxonomy [10] Figure 2 presents the XRI
Zone Agent design theory, which has been merged and adapted
from XRI theory, virtuality continuum [38], MiRAs [11] and
human-robot interaction [10] into three dimensions, including
the mixed reality dimension, the level of agency, and physical-
remote (PR) spatial interaction capacity. The X axis is the
mixed reality dimension adapted from the virtuality continuum
[38] that represents the real-environment on the left and fully
virtual reality environment on the right. The Y axis is the
level of agency, which means how capable the agent is in
terms of its autonomous, reactive, proactiveness, and social
abilities [23]. The Z axis of physical-to-remote (PR) spatial
interaction capacity represents the level of physical or remote
control users have when interacting with objects, and ranges
from physical interaction to non-physical interaction, such as
through IoT communication.
On the left side, the number 1 represents physical interaction
and interface design, with the 3D physical interfaces (the phys-
Fig. 3.
Zone agents are here designed for spatial context, based on agent
design methodology like [26] [23], (including monitoring and responding to
user-zone events such as time context, virtual context, IoT context, zone object
context, etc.). These agents express embodiment through zone-driven actions
that may be virtual or physical. The level of agency can vary according to
agent implementation (from simple reflex agents to high-functioning agents).
ical toggle, slider, etc.), empowering users to interact with and
dynamically adjust elements within the physical environment,
and a 2D digital user interface (screen icons are widely used
for human-machine interaction). The number 2 indicates the
IoT-enabled physical objects and integrated controllers, and
this setup facilitates the communication of information across
a network of devices. In addition, autonomous agents, such as
robots, have the capacity to function within and adapt to this
environment while establishing interaction with users.
On the right side, the number 3 is from mixed reality to fully
virtual environments, where users manipulate 2D digital UI
and 3D objects. Current mixed-reality interactions commonly
employ 3D virtual objects with hand-tracking capabilities to
simulate interaction with real-world objects. The number 4
presents that the virtual objects could be used to control or be
manipulated by physical objects through IoT communication,
as in [2] [3] [8]. Finally, the number 5 shows XRI 3D Spatial
Zone Interaction. These agents and their design capabilities
and objectives are shown in Figure 3.
The scenario considers the designed spatial position of
different agents (with virtual embodiment) and the potential
IoT-Enabled devices that could be controlled (such as a light,
projector, and robot). In terms of spatial zone agents these
can include a relaxation agent, meeting agent, and workstation
agent, each operating as applications within the space, driven
by specific objectives and responding to user contexts.
IV. DESIGN FRAMEWORK AND PROTOTYPE OF SPATIAL
ZONE AGENTS
XRI Zone Agent Framework: Figure 4 shows the frame-
work of the prototype, indicating how the user navigates the
use case environment (lab environment) between zones and
the interaction with both virtual and physical objects through
IoT communication. The virtual agents such as lab assistant
agent are rendering in XR headset, powered by Unity1, and
the physical objects, such as Phillips Hue smart lights2 and
Webcam are communicating to the virtual agents through an
MQTT Broker3.
Prototype of XRI Zone Agent Interactions: Figure 5
presents the prototype of the XRI Zone Agent, for the scenario
and user behaviour interaction within the lab environment with
the XRI zone agents. When users wear the XR HMD device
and enter the lab environment, they can see the virtual lab
assistant agent represented as a plant avatar, with butterflies
moving in the environment. The avatar is a guide that shows
welcome messages to the user and displays an initial introduc-
tion to the user. There is also an indicator to tell the user how
to interact and enable the next state of the plant avatar with a
thumbs-up gesture (hand tracking). When the user shows the
thumbs-up gesture (see Figure 5), the plant avatar will wave
and move toward the user and show three menu icons of tasks
(start learning, start relaxing, and start meeting) for selection
that could be performed in the lab. When the user presses the
start learning button, for example, the plant avatar will move
toward the learning zone with the workstation agent and show
an indicator on that zone to guide the user to the location (this
is an example of a spatial agent that can move between zones).
The user will enter the “learning zone”, and the workstation
agent for that zone will show the time of how long the user
has been studying (this is an example of tracking user context
in the zone). Once the time reaches the desired length, the
plant avatar will stand in front of the user to ask if the user
would like to start relaxing. If the user presses the start relaxing
button, the plant avatar will guide the user toward the relax
zone, and the wall around the user, driven by the relax agent,
will transform into a relaxed scene with particle effects (an
example of a simple-reflex zone agent based on user entry).
Also, when the user wants to start a meeting, they can perform
the thumbs-up gesture, to summon the plant avatar and select
the meeting state. The plant avatar will move to the physical
light switch to ask/guide the user to turn it off. Once the
meeting zone agent detects the environment light has turned
off (through computer vision light detection), the meeting
projector will turn on and enter the meeting mode (another
example of zone agent responsiveness). While these agent
interactions are simple-reflex agents, they can be enhanced
by integration of stronger agent paradigms, such as the use of
ML model-driven controllers, large language models, or more
capable cognitive architectures.
V. SUMMARY
This work has provided a theoretical framework for consid-
ering smart-space zones as agents, and has proposed an early
design-theoretic exploration of mixed reality and IoT (XRI)
1https://unity.com/
2https://www.philips-hue.com/en-ca/p/hue-white-and-color-ambiance-
a19—e26-smart-bulb—75-w–2-pack-/046677563370
3https://mqtt.org/
Fig. 4. The prototype framework for the multi-agent Zone scenario includes the highlighted actors (user, learning agent, relax agent, meeting agent); these
agents interact with the user; which may be both physical, IoT, or virtual interactions, across a communication channel (e.g., MQTT).
Fig. 5. Using the HRI Framework [10], the design of Zone agents can be considered; showing user interface and widgets, spatial references and visualizations,
embedded visual effects, and interaction modalities for an early prototype, as shown. A deeper evaluation of zone agents is left for future work.
zone agents as well as an architecture and initial prototype
implementation. This has considered that user interactions with
zone/space agents will involve sensors, actuators, embodiment,
decision-making, and a mixture of communication paradigms.
The work considers exploring space-to-human and human-
to-space interactions driven-by mixed-reality agents and user
and environmental context within zones. It envisions that zone
agents would be designed to adapt to user spatial contexts and
needs through changes in either physical or virtual reality. A
high-level user interaction design has been presented, based
on three zone agents for work, leisure, and meetings. The
hope is that such framing of space-as-agent will help further
new forms of metaverse exploration where digital twins of
everyday environments work together with humans-in-the-
loop, streamlining their shared contexts. This early exploration
sets the stage for further research in this direction, and future
research will refine further in terms of agency level, physical-
virtual responsiveness, and new forms of spatial interaction.
ACKNOWLEDGMENT
This work gratefully acknowledges funding from the Tri-
council of Canada under the Canada Research Chairs program.
REFERENCES
[1] L.-H. Lee, T. Braud, P. Zhou, L. Wang, D. Xu, Z. Lin, A. Kumar,
C. Bermejo, and P. Hui, “All one needs to know about metaverse: A
complete survey on technological singularity, virtual ecosystem, and
research agenda,” arXiv preprint arXiv:2110.05352, 2021.
[2] J. Guan, J. Irizawa, and A. Morris, “Extended reality and internet of
things for hyper-connected metaverse environments,” in 2022 IEEE
Conference on Virtual Reality and 3D User Interfaces Abstracts and
Workshops (VRW), 2022, pp. 163–168.
[3] J. Guan, A. Morris, and J. Irizawa, “Cross-reality for extending the
metaverse: Designing hyper-connected immersive environments with
xri,” in 2023 IEEE Conference on Virtual Reality and 3D User Interfaces
Abstracts and Workshops (VRW), 2023, pp. 305–311.
[4] ——, “Extending the metaverse: Hyper-connected smart environments
with mixed reality and the internet of things,” in 2023 IEEE Conference
on Virtual Reality and 3D User Interfaces Abstracts and Workshops
(VRW), 2023, pp. 817–818.
[5] J. Guan, “Extending the metaverse: Exploring generative objects with
extended reality environments and adaptive context awareness,” 2022.
[6] A. Morris, J. Guan, and A. Azhar, “An xri mixed-reality internet-of-
things architectural framework toward immersive and adaptive smart
environments,” in 2021 IEEE International Symposium on Mixed and
Augmented Reality Adjunct (ISMAR-Adjunct), 2021, pp. 68–74.
[7] T. Tsang and A. Morris, “A hybrid quality-of-experience taxonomy for
mixed reality iot (xri) systems,” in 2021 IEEE International Conference
on Systems, Man, and Cybernetics (SMC), 2021, pp. 1809–1816.
[8] J. Guan and A. Morris, “Design frameworks for hyper-connected
social
xri
immersive
metaverse
environments,”
arXiv
preprint
arXiv:2306.06230, 2023.
[9] A. Resmini, B. Lindenfalk, and J. Jauhiainen, “Being elsewhere: An
information architecture approach to the design of a sense of presence
in xr environments,” in International Conference on Human-Computer
Interaction.
Springer, 2023, pp. 502–521.
[10] R. Suzuki, A. Karim, T. Xia, H. Hedayati, and N. Marquardt, “Aug-
mented reality and robotics: A survey and taxonomy for ar-enhanced
human-robot interaction and robotic interfaces,” in Proceedings of the
2022 CHI Conference on Human Factors in Computing Systems, 2022,
pp. 1–33.
[11] T. Holz, A. G. Campbell, G. M. O’Hare, J. W. Stafford, A. Martin,
and M. Dragone, “Mira—mixed reality agents,” International journal of
human-computer studies, vol. 69, no. 4, pp. 251–268, 2011.
[12] D. Jo and G. J. Kim, “Ariot: scalable augmented reality framework
for interacting with internet of things appliances everywhere,” IEEE
Transactions on Consumer Electronics, vol. 62, no. 3, pp. 334–340,
2016.
[13] ——, “Ar enabled iot for a smart and interactive environment: A survey
and future directions,” Sensors, vol. 19, no. 19, p. 4330, 2019.
[14] Y. Shao, N. Lessio, and A. Morris, “Iot avatars: Mixed reality
hybrid objects for core ambient intelligent environments,” Procedia
Computer Science, vol. 155, pp. 433–440, 2019, the 16th International
Conference on Mobile Systems and Pervasive Computing (MobiSPC
2019),The 14th International Conference on Future Networks and
Communications (FNC-2019),The 9th International Conference on
Sustainable
Energy
Information
Technology.
[Online].
Available:
https://www.sciencedirect.com/science/article/pii/S1877050919309743
[15] J. Guan, N. Lessio, Y. Shao, and A. Morris, “Exploring a mixed
reality framework for the internet-of-things: Toward visualization and
interaction with hybrid objects and avatars,” in 2020 IEEE Conference
on Virtual Reality and 3D User Interfaces Abstracts and Workshops
(VRW), 2020, pp. 857–857.
[16] A. Morris, J. Guan, N. Lessio, and Y. Shao, “Toward mixed reality
hybrid objects with iot avatar agents,” in 2020 IEEE International
Conference on Systems, Man, and Cybernetics (SMC), 2020, pp. 766–
773.
[17] J. D. N. Dionisio, W. G. B. III, and R. Gilbert, “3d virtual worlds and
the metaverse: Current status and future possibilities,” ACM Computing
Surveys (CSUR), vol. 45, no. 3, pp. 1–38, 2013.
[18] H. Ning, H. Wang, Y. Lin, W. Wang, S. Dhelim, F. Farha, J. Ding, and
M. Daneshmand, “A survey on metaverse: the state-of-the-art, technolo-
gies, applications, and challenges,” arXiv preprint arXiv:2111.09673,
2021.
[19] R. Cheng, N. Wu, S. Chen, and B. Han, “Will metaverse be nextg
internet? vision, hype, and reality,” arXiv preprint arXiv:2201.12894,
2022.
[20] S. Shekhar, S. K. Feiner, and W. G. Aref, “Spatial computing,”
Commun. ACM, vol. 59, no. 1, p. 72–81, dec 2015. [Online]. Available:
https://doi.org/10.1145/2756547
[21] S. Greenwold, “Spatial computing,” Massachusetts Institute of Technol-
ogy, Master, 2003.
[22] M. R. Marner, R. T. Smith, J. A. Walsh, and B. H. Thomas, “Spatial
user interfaces for large-scale projector-based augmented reality,” IEEE
computer graphics and applications, vol. 34, no. 6, pp. 74–82, 2014.
[23] M. Wooldridge and N. R. Jennings, “Intelligent agents: Theory and
practice,” The knowledge engineering review, vol. 10, no. 2, pp. 115–
152, 1995.
[24] D. Szafir, “Mediating human-robot interactions with virtual, augmented,
and mixed reality,” in International Conference on Human-Computer
Interaction.
Springer, 2019, pp. 124–149.
[25] N. R. Jennings, K. Sycara, and M. Wooldridge, “A roadmap of agent
research and development,” Autonomous agents and multi-agent systems,
vol. 1, no. 1, pp. 7–38, 1998.
[26] L. Padgham and M. Winikoff, “Prometheus: A methodology for devel-
oping intelligent agents,” in International Workshop on Agent-Oriented
Software Engineering.
Springer, 2002, pp. 174–185.
[27] P. Caillou, B. Gaudou, A. Grignard, C. Q. Truong, and P. Taillandier, “A
simple-to-use bdi architecture for agent-based modeling and simulation,”
in Advances in Social Simulation 2015.
Springer, 2017, pp. 15–28.
[28] R. H. Bordini, A. El Fallah Seghrouchni, K. Hindriks, B. Logan, and
A. Ricci, “Agent programming in the cognitive era,” Autonomous Agents
and Multi-Agent Systems, vol. 34, no. 2, pp. 1–31, 2020.
[29] A. S. Kyaw, C. Peters, and T. N. Swe, Unity 4. x Game AI Programming.
Packt Publishing, 2013.
[30] M. Iovino, E. Scukins, J. Styrud, P. ¨Ogren, and C. Smith, “A survey of
behavior trees in robotics and ai,” Robotics and Autonomous Systems,
vol. 154, p. 104096, 2022.
[31] H. Ushida, Y. Hirayama, and H. Nakajima, “Emotion model for life-like
agent and its evaluation,” in AAAI/IAAI, 1998, pp. 62–69.
[32] K. Gushima, H. Akasaki, and T. Nakajima, “Ambient bot: delivering
daily casual information through eye contact with an intimate virtual
creature,” in Proceedings of the 21st International Academic Mindtrek
Conference, 2017, pp. 231–234.
[33] D. Bylieva, N. Almazova, V. Lobatyuk, and A. Rubtsova, “Virtual pet:
trends of development,” in The 2018 International Conference on Digital
Science.
Springer, 2019, pp. 545–554.
[34] B. Wang and P.-L. P. Rau, “Influence of embodiment and substrate
of social robots on users’ decision-making and attitude,” International
Journal of Social Robotics, vol. 11, no. 3, pp. 411–421, 2019.
[35] V. Groom, C. Nass, T. Chen, A. Nielsen, J. K. Scarborough, and
E. Robles, “Evaluating the effects of behavioral realism in embodied
agents,” International Journal of Human-Computer Studies, vol. 67,
no. 10, pp. 842–849, 2009.
[36] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen,
and I. Sutskever, “Zero-shot text-to-image generation,” in International
Conference on Machine Learning.
PMLR, 2021, pp. 8821–8831.
[37] K. Crowson, S. Biderman, D. Kornis, D. Stander, E. Hallahan, L. Cas-
tricato, and E. Raff, “Vqgan-clip: Open domain image generation and
editing with natural language guidance,” in European Conference on
Computer Vision.
Springer, 2022, pp. 88–105.
[38] P. Milgram and F. Kishino, “A taxonomy of mixed reality visual
displays,” IEICE TRANSACTIONS on Information and Systems, vol. 77,
no. 12, pp. 1321–1329, 1994.
"
"Insecure content such as cyberbullying, self-harm, and sexually explicit images are increasingly being shared on social media platforms. These platforms use AI and human moderation to safeguard users from such images and provide an explanation of why they are flagged. However, two critical problems arise from this process - identifying a rationale for obfuscating the images and deciding how much to obfuscate. This work addresses these issues by proposing a visual reasoning model (VLM) called ConditionalVLM, conditioned on pre-trained unsafe image classifiers, to provide an accurate rationale grounded in unsafe image attributes. Additionally, the paper introduces a counterfactual explanation algorithm that minimally obfuscates unsafe regions for safe viewing. Our experiments on real-world data demonstrate the efficacy of the proposed method.nan","Social media platforms are increasingly being misused for sharing unsafe content such as sexually explicit images, cyberbullying, and self-harm. To safeguard users from such content, major platforms employ AI and human-based content moderation techniques to flag and obfuscate (i.e., make the image safer by blurring sensitive regions) such images. This process involves obfuscating unsafe image regions in the image (Li et al. 2017) along with generating a rationale that backs up the decision to obfuscate the flagged images (Meta 2022). The image obfuscation process faces two critical problems regarding how much of the unsafe image is obfuscated and why it is obfuscated: First, the decision to deem an image unsafe and obfuscate it demands providing a rationale for the decision. For example, Instagram moderators are required to provide a legal rationale (Bronstein 2021; Are 2020) to back up their decision (Tenbarge 2023). Existing visual reasoning methods (Li et al. 2022, 2023; Dai et al. 2023) are severely limited for unsafe images such as sexually explicit, cyberbullying, and self-harm since they cannot provide a rationale grounded in attributes that are specific to such images, such as rude hand gestures in cyberbullying images (Vishwamitra et al. 2021), or sensitive body parts in sexually-explicit images (Binder 2019). Second, the unsafe image needs minimal obfuscation while still depicting the safe regions for evidence collection and investigation (Billy Perrigo 2019). For instance, human moderators need to determine the age of the person in the image (e.g., in child sex-ual abuse material (CSAM) investigations), look for identi-fiers (e.g., tattoos, scars, and unique birthmarks), and deter-mine their location information (e.g., landmarks, geograph-ical features, and recognizable surroundings). Current seg-mentation techniques (Chandrasekaran et al. 2021; Vermeire et al. 2022; Bethany et al. 2023) cannot minimally identify the regions and consequently impede investigations that per-tinently need full details of the remaining safe regions.nan","nanSocial media platforms are constantly misused to share un-safe content. For example, sexually-explicit images (Ashurst and McAlinden 2015; Sanchez et al. 2019), non-consensual in-timate images (NCII) (Lenhart, Ybarra, and Price-Feeney 2016) and child sexual abuse material (CSAM) are being in-creasingly shared on major social media platforms (Sanchez et al. 2019). Cyberbullying, a critical issue affecting ado-lescents and adults is spread unabated via images (Vish-wamitra et al. 2021). Furthermore, self-harm images are widely spread on these platforms that further alienate vulner-able users (John et al. 2018). To defend against this threat, social media platforms alter the unsafe image by blurring the sensitive regions. This obfuscation of such unsafe im-ages has substantial implications. For instance, social media platforms employ over a million moderators globally (bbc 2021), who manually view unsafe images which is known to have an adverse effect on their mental health, includ-ing PTSD (reu 2021). Vulnerable users, such as minors also need image safeguarding methods that can shield them from unsafe content. Furthermore, law enforcement agents who investigate images from a crime scene need image safe-guarding since such images contain extremely disturbing images, such as CSAM. These applications have a critical need, the unsafe regions must be minimally obfuscated. For instance, a moderator needs to view the safe regions to con-duct investigations, such as determining the age of the per-son to report CSAM content to law enforcement.nan","Figure 1 illustrates the architecture of our proposed ap-proach, which consists of two modules. The initial module utilizes ConditionalVLM for classifying images as safe or unsafe, while the subsequent module proposes counterfactual visual explanations to identify and obfuscate the unsafe regions within the image.nan","We evaluated our Conditional VLM and Counterfactual Subobject Explanation methods on three datasets of real-world harmful images to study the practical application of counterfactual subobject explanations.

Sexually Explicit: First, we sampled a subset of images from an NSFW images dataset (Kim 2021) consisting of 334,327 images by selecting the “porn”, “neutral”, and “sexy” classes. We combine the “neutral”, and “sexy” classes into a single class of “safe” images.

Cyberbullying: Second, we used a cyberbullying im-ages (Vishwamitra et al. 2021) dataset consisting of nearly 20,000 images belonging to the classes “cyberbullying” and “non-cyberbullying”.

Self-Harm: Third, we used a self-harm images dataset (Bethany et al. 2023), consisting of 5000 images with classes “self-harm” and “non self-harm”.nan","In this work, we have presented ConditionalVLM, a vi-sual reasoning framework that generates accurate rationales for unsafe image descriptions by leveraging state-of-the-art VLMs conditioned on pre-trained unsafe image classi-fiers, and CSE, a counterfactual visual explanation tech-nique to obfuscate the unsafe regions in unsafe images for safer sharing. We evaluated these two methods on three cat-egories of unsafe images. An implementation of Condition-alVLM, which we called ConditionalBLIP showed supe-rior performance compared to other state-of-the-art image-to-text models on describing unsafe images. We also com-pare CSE against another recent unsafe image obfuscation method and show how our approach is effective in generat-ing causal explanations for obfuscating unsafe images.nan",Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually,"Mazal Bethany, Brandon Wherry, Nishant Vishwamitra, Peyman Najafirad","Image Safeguarding: Reasoning with Conditional Vision Language Model
and Obfuscating Unsafe Content Counterfactually
Mazal Bethany*1 2, Brandon Wherry*1 2, Nishant Vishwamitra1, Peyman Najafirad1 2 †
1University of Texas at San Antonio 2Secure AI and Autonomy Lab
{mazal.bethany, brandon.wherry, nishant.vishwamitra, peyman.najafirad}@utsa.edu
Abstract
Social media platforms are being increasingly used by ma-
licious actors to share unsafe content, such as images de-
picting sexual activity, cyberbullying, and self-harm. Con-
sequently, major platforms use artificial intelligence (AI)
and human moderation to obfuscate such images to make
them safer. Two critical needs for obfuscating unsafe im-
ages is that an accurate rationale for obfuscating image re-
gions must be provided, and the sensitive regions should be
obfuscated (e.g. blurring) for users’ safety. This process in-
volves addressing two key problems: (1) the reason for ob-
fuscating unsafe images demands the platform to provide an
accurate rationale that must be grounded in unsafe image-
specific attributes, and (2) the unsafe regions in the image
must be minimally obfuscated while still depicting the safe
regions. In this work, we address these key issues by first
performing visual reasoning by designing a visual reason-
ing model (VLM) conditioned on pre-trained unsafe image
classifiers to provide an accurate rationale grounded in un-
safe image attributes, and then proposing a counterfactual
explanation algorithm that minimally identifies and obfus-
cates unsafe regions for safe viewing, by first utilizing an
unsafe image classifier attribution matrix to guide segmen-
tation for a more optimal subregion segmentation followed
by an informed greedy search to determine the minimum
number of subregions required to modify the classifier’s out-
put based on attribution score. Extensive experiments on un-
curated data from social networks emphasize the efficacy
of our proposed method. We make our code available at:
https://github.com/SecureAIAutonomyLab/ConditionalVLM
Introduction
Social media is being increasingly misused by bad actors
to share sexually explicit, cyberbullying, and self-harm
content (Hendricks 2021; Chelmis and Yao 2019; Adler and
Chenoa Cooper 2022). However, social media platforms
are required by law to safeguard their users against such
images (Exon 1996), as well as provide a rationale for
why such images are flagged (Gesley 2021; Cabral et al.
2021) for the purpose of transparency. In response, major
platforms have deployed AI and human-based content mod-
eration techniques to flag and obfuscate (i.e, make the image
safer by blurring sensitive regions) such images (Bethany
*These authors contributed equally.
†Corresponding author
et al. 2023). This process involves obfuscating (e.g. by
blurring or blocking) unsafe image regions in the image (Li
et al. 2017) along with generating a rationale that backs up
the decision to obfuscate the flagged images (Meta 2022).
The image obfuscation process faces two critical prob-
lems regarding how much of the unsafe image is obfuscated
and why it is obfuscated: First, the decision to deem an
image unsafe and obfuscate it demands providing a ratio-
nale for the decision. For example, Instagram moderators are
required to provide a legal rationale (Bronstein 2021; Are
2020) to back up their decision (Tenbarge 2023). Existing
visual reasoning methods (Li et al. 2022, 2023; Dai et al.
2023) are severely limited for unsafe images such as sexu-
ally explicit, cyberbullying, and self-harm since they cannot
provide a rationale grounded in attributes that are specific
to such images, such as rude hand gestures in cyberbullying
images (Vishwamitra et al. 2021), or sensitive body parts in
sexually-explicit images (Binder 2019). Second, the unsafe
image needs minimal obfuscation while still depicting the
safe regions for evidence collection and investigation (Billy
Perrigo 2019). For instance, human moderators need to de-
termine the age of the person in the image (e.g., in child sex-
ual abuse material (CSAM) investigations), look for identi-
fiers (e.g., tattoos, scars, and unique birthmarks), and deter-
mine their location information (e.g., landmarks, geograph-
ical features, and recognizable surroundings). Current seg-
mentation techniques (Chandrasekaran et al. 2021; Vermeire
et al. 2022; Bethany et al. 2023) cannot minimally identify
the regions and consequently impede investigations that per-
tinently need full details of the remaining safe regions.
In this work, we take the first step towards addressing
a pertinent, but overlooked problem of the image moder-
ation process in social media platforms. Our major objec-
tive is to first identify and minimally obfuscate the sensitive
regions in an unsafe image such that the safe regions are
unaltered to aid an investigation, and then provide an accu-
rate rationale for doing so, that is grounded in unsafe im-
age attributes (e.g., private body parts, rude gestures or hate-
ful symbols). To this end, we address this problem in two
steps: (1) we develop a novel unsafe image rationale genera-
tion method called ConditionalVLM (i.e., conditional vision
language model) that leverages the state-of-the-art large lan-
guage models (LLM)-based vision language models (Fang
et al. 2023) to perform an in-depth conditional inspection to
arXiv:2401.11035v1  [cs.CV]  19 Jan 2024
generate an accurate rationale that is grounded in unsafe im-
age attributes; and (2) minimally obfuscating the sensitive
regions only by calculating the classifier attribution matrix
using a FullGrad-based model (Srinivas and Fleuret 2019)
and then utilize this information to guide Bayesian super-
pixel segmentation (Uziel, Ronen, and Freifeld 2019) for a
more informed and optimal dynamic subregion segmenta-
tion, via calculating the attribution score of each subregion.
Finally, we utilize a discrete optimization technique such as
informed greedy search to determine the minimum number
of subregions required to modify the classifier’s output, us-
ing the score attribution.
Our work has profound implications for the safety of so-
cial media content moderators, by greatly reducing their
need to view unsafe content (Steiger et al. 2021), social me-
dia users who are minors or sensitive to such content (Har-
grave and Livingstone 2009), and law enforcement agents
who need to investigate such images as part of their investi-
gation (Krause 2009). We make the following contributions:
• We develop ConditionalVLM, a visual reasoning model
that generates accurate rationales for unsafe images by
leveraging state-of-the-art VLMs conditioned on pre-
trained unsafe image classifiers.
• We develop a novel unsafe image content obfuscation
algorithm that minimally obfuscates only the unsafe re-
gions while keeping the rest of the image unaltered for
investigations.
• Evaluations of our work show that it can categorize the
three social media unsafe categories of images with an
accuracy of 93.9%, and minimally segment only the un-
safe regions with an accuracy of 81.8%.
Related Works
Safeguarding Images
Social media platforms are constantly misused to share un-
safe content. For example, sexually-explicit images (Ashurst
and McAlinden 2015; Sanchez et al. 2019), non-consensual
intimate images (NCII) (Lenhart, Ybarra, and Price-Feeney
2016) and child sexual abuse material (CSAM) are being in-
creasingly shared on major social media platforms (Sanchez
et al. 2019). Cyberbullying, a critical issue affecting ado-
lescents and adults is spread unabated via images (Vish-
wamitra et al. 2021). Furthermore, self-harm images are
widely spread on these platforms that further alienate vulner-
able users (John et al. 2018). To defend against this threat,
social media platforms alter the unsafe image by blurring
the sensitive regions. This obfuscation of such unsafe im-
ages has substantial implications. For instance, social media
platforms employ over a million moderators globally (bbc
2021), who manually view unsafe images which is known
to have an adverse effect on their mental health, includ-
ing PTSD (reu 2021). Vulnerable users, such as minors also
need image safeguarding methods that can shield them from
unsafe content. Furthermore, law enforcement agents who
investigate images from a crime scene need image safe-
guarding since such images contain extremely disturbing
images, such as CSAM. These applications have a critical
need, the unsafe regions must be minimally obfuscated. For
instance, a moderator needs to view the safe regions to con-
duct investigations, such as determining the age of the per-
son to report CSAM content to law enforcement.
Vision-Language Models
Given the achievements of pre-trained models in computer
vision (CV) and natural language processing (NLP), numer-
ous studies have attempted to pre-train large-scale models
that incorporate both vision and language modalities. These
models are commonly referred to as Vision-Language
Models (VLM). One group of methods propose end-to-end
approaches for learning vision-language models. Works
such as CLIP (Radford et al. 2021) use a contrastive pre-
training process to jointly train an image and a text encoder
on image-text pairs. Other works such as BEIT-3 (Wang
et al. 2023) use multiway transformers for general-purpose
modeling and carry out masked modeling on images, text,
and image-text pairs. Some methods use modular tech-
niques to utilize pre-existing models to interpret image data
and take advantage of established LLMs. One major hurdle
in these works is coordinating visual features within the
realm of text. To accomplish this, works such as Flamingo
(Alayrac et al. 2022) add cross attention layers and train
these layers on image-text pairs. Works such as BLIP-2 use
a frozen image encoder and LLM and propose a querying
transformer to bridge modalities (Li et al. 2023). Other
methods such as LENS (Berrios et al. 2023) require no
additional training, and develop visual vocabularies of
an image by collecting tags, attributes and captions from
various models. LENS then uses this visual vocabulary to
generate text prompts by which questions can be asked
about an image on a frozen LLM. A major limitation
of these methods is that they do not have conditioning
capability (Ramesh et al. 2022), a crucial requirement to
ground the output in domain-specific attributes.
Image Segmentation and Counterfactual
Explanation for Obfuscation
Another type of explanation that is growing in popularity
due to its ability to address several of these issues is coun-
terfactual explanations (Wachter, Mittelstadt, and Russell
2017). A counterfactual explanation can be defined as tak-
ing the form: a decision y was produced because variable X
had values (v1, v2, . . . ) associated with it. If X instead had
values (v1′, v2′, . . . ), and all other variables had remained
constant, score y′ would have been produced. Some works
such as BEN (Chandrasekaran et al. 2021), SEDC (Vermeire
et al. 2022), and CSRA (Bethany et al. 2023) have explored
region-based counterfactual visual explanations. However,
existing approaches face two key challenges: 1. suboptimal
subregion boundaries, leading to excessive parts of the im-
age being identified as causing a decision, and 2. high time
complexity 2K in searching for a counterfactual in an im-
age of K regions. BEN and SEDC segment an input image
into K static subregions without any prior knowledge of the
classifier, resulting in an uninformed search strategy for find-
ing the counterfactual examples. While CSRA does use prior
Counterfactual 
Generation 
Algorithm
Using Informed 
Search 
Subobject
Region 
Partitioning 
using 
Adaptive 
Segmentation
Bayesian 
Adaptive 
Superpixel
Segmentation
FullGrad
Conditional Image 
Instruction-guided 
Transformer
(CIIT)
Pre-trained
Large Language Model
(LLM) 
Instruction (I)
(Z)
Pre-trained Image 
Encoder
Select Highest 
Region
Attribution
Description: In the image, a woman is
making
an
offensive
gesture,
such
as
flipping someone off, with her middle finger.
Does the image 
contain potentially 
offensive gestures 
or symbols?
Image (X)
0.4
0.2
0.07
0.10
0.15
Masked Image (X’)
X
Unsafe 
Classifier
(c) 
X
Conditional 
Figure 1: Overview of the proposed architecture. The initial module utilizes ConditionalVLM for classifying images as safe or
unsafe, while the subsequent module proposes counterfactual visual explanations to identify and obfuscate the unsafe regions
within the image.
knowledge of the classifier to inform the search of the coun-
terfactual example, BEN, SEDC and CSRA do not jointly
optimize the subregions boundaries and minimize the num-
ber of subregions, which is particularly important for ob-
fuscation applications where preserving as much context as
possible is preferred.
Method
Figure 1 illustrates the architecture of our proposed ap-
proach, which consists of two modules. The initial module
proposes a conditional visual language model designed for
image reasoning. The model classifies images as safe or un-
safe by understanding the interactions or activities of enti-
ties within the image, using its comprehension of visual fea-
tures and linguistic annotations. In the subsequent module,
counterfactual visual explanations are proposed to precisely
identify sub-object regions of the image contributing to its
unsafe classification for obfuscation.
Conditional Vision-Language Model
We introduce a framework that synergistically combines the
strengths of large language models (LLMs) with the spe-
cific requirements of large image encoders. Additionally,
it provides more explicit control over visual features being
reasoned. The ConditianalVLM architecture is anchored by
three pivotal components, as depicted in Figure 1:
A Large Pre-trained Image Encoder takes an image X as
input and outputs a visual embedding representation of the
image, Z = g(X). We explore a state-of-the-art pre-trained
vision transformer ViT-g/14 from EVA (Fang et al. 2023).
A Conditional Image Instruction-guided Transformer
(CIIT) employs contrastive language-image pre-training to
encode visual data in congruence with a specific language
prompt. Additionally, we condition this language prompt
using pre-trained unsafe image classifiers. This allows the
model to match and parse the unsafe visual embedding
effectively, while also providing more explicit control over
unsafe visual features (Ramesh et al. 2022). CIIT utilizes
a pre-trained Q-Former model (Li et al. 2023), which is
conditioned on image classifiers as control code c on unsafe
image content such as sexually explicit, cyberbullying, and
self-harm.
• A prior p(I|c) that produces CIIT instruct prompt I con-
ditioned on control code c.
• A transformer decoder p(L|I, c) that produces con-
trastive embedding L conditioned on Instruct prompt I
and control code c.
The transformer decoder allows us to invert images given
their CIIT Instruct prompt, while the prior allows us to learn
a generative model of the image embeddings themselves.
Taking the product of these two components yields a gen-
erative model P(L|c) of embedding L given control c:
p(L|c) = p(L, I|c) = p(L|I, c)p(I|c)
(1)
The control code c provides a point of control over the
CIIT generation process. The distribution can be decom-
posed using the chain rule of probability and trained with
a loss that takes the control code into account.
p(L|c) =
n
Y
i=1
p(Li|L<i, c)
(2)
We train the model with parameters θ to minimize the
negative log-likelihood over a dataset D = X1, ..., Xn:
L(D) = −
|D|
X
k=1
log pθ(Lk
i |L<i, ck)
(3)
A Pre-trained Large Language Model Decoder takes a
text embedding L as input and outputs linguistic sentences
derived from the embedding, Text = LLM(L). We choose
Vicuna (Vic 2023) as our LLM decoder which is constructed
upon LLaMA (Touvron et al. 2023) and can perform a wide
range of complex linguistic tasks.
Counterfactual Subobject Explanations for
Obfuscation
In order to connect region attribution to provide counterfac-
tual subobject region explanation of an image, relative to a
given machine learning predictive model, we propose a two-
phase approach. The pipeline of the proposed approach is
illustrated in Figure 1. We first partition the image into non-
intersecting subobject regions and measuring region attribu-
tion value to each region using gradient attribution maps in
Section 3.1 and Section 3.2. The counterfactual analysis of
alternate versions of the image using a greedy search algo-
rithm using regions with highest attribution values for coun-
terfactual analysis is followed in Section 3.3.
Subobject Region Partitioning using Adaptive Segmen-
tation. We represent a given image,Xas a non-intersecting
set of K regions given by {z1, z2, · · · , zK}. The boundaries
of these regions are defined by clustering algorithms that use
color and spatial information and are called superpixels. Let
Z represent the K region segmentation, zi represent the la-
bel assigned to Xi and j represent the label of some arbitrary
cluster. An image must be segmented into meaningful sub-
object regions in order to allow for a counterfactual analysis
of the image by the binary predictive model f(X) → 0, 1.
These regions serve as the features that are analyzed in
the counterfactual analysis. To maximize the efficiency of
a counterfactual analysis, we require an adaptive segmen-
tation method. Many segmentation methods are wasteful
in their assignment of many segments to uninformative re-
gions, while not segmenting detailed regions enough. Such
a method should be able to respect pixel connectivity and
spatial coherence and requires an adaptive number of re-
gions. K-means based clustering methods are a fast and sim-
ple basis for leading segmentation, however Gaussian Mix-
ture Models (GMM) may be better suited for an adaptive
segmentation method since we need to capture the hetero-
geneity in the pixel distribution of various types of images.
Let N = h ∗ w be the number of pixels in an image, X
with c color channels. The values attributed to the pixels in
X can be denoted as Xi = (li, ci) ∈ R5, where li ∈ R2 rep-
resent the x, y coordinate location and ci ∈ R3 represent the
RGB color information. Superpixel clustering methods with
spatial coherence aim to partition (Xi)N
i=1 into K disjoint
groups. Let Z represent the K region segmentation, zi rep-
resent the label assigned to Xi and j represent the label of
some arbitrary cluster. Where N(X; µj, Σj) is a Gaussian
PDF with mean µj and a covariance matrix Σj of size n ∗ n,
the PDF of a GMM with K components is
p(X; (µj, Σj, λj)K
j=1) =
K
X
j=1
λjN(X|µj, Σj)
The mixing coefficients λj in the PDF of a GMM form a
convex combination where:
K
X
j=1
λj = 1, λj ≥ 0
∀j
and this allows for a globally optimal clustering. Given a
Gaussian distribution j where θj = (µj, Σj), a Bayesian
GMM with random variables (θj)K
j=1 and (λj)K
j=1 are drawn
from p((θj, λj)K
j=1), a prior distribution. Assuming inde-
pendence, the prior distribution can be factorized as follows
p((θj, λj)K
j=1) = p((λj)K
j=1)
K
Y
j=1
p(θj)
Using a Normal-Inverse Wishart (NIW) for p(θj) and a
Dirichlet distribution for p((λj)K
j=1) gives us posterior dis-
tributions in the same form as the priors. Furthermore, the
updates from the priors are given in closed form.
The Bayesian GMM inference to calculate Z can be done
by performing Gibbs sampling, alternating between the fol-
lowing equations:
p((λj)K
j=1|Z, (Xi)N
i=1)
K
Y
j=1
p((θj, λj)|Z, (Xi)N
i=1)
p(Z|(θj, λj)K
j=1, (Xi)N
i=1)
Subobject Region Attribution Value. We start by creating
the FullGrad (Srinivas and Fleuret 2019) attribution map for
image feature attribution. Given an image X and the fea-
ture maps generated by the FullGrad L[u, v] of width u and
height v for the model prediction, the goal of the visual at-
tention model is to identify the discriminative regions of the
image that significantly influence the class prediction score
of the predictive model using L[u, v] pixel attribution values.
The attribution map of the FullGrad method is generated
by propagating an image through a CNN, obtaining the out-
put score before the softmax layer, and then computing the
gradients with respect to the input (input-gradients) and the
biases at each layer (bias-gradients). These gradients are
then combined, with each bias-gradient reshaped to match
the input dimensionality and all gradients summed to form
the FullGrad attribution map.
FullGrad Definition: Consider a CNN model f, with x de-
noting the input and b denoting the biases at each layer, c
representing the channels of layer k. Furthermore, given an
output of interest f(x), and a postprocessing operator ψ(·)
the FullGrad attribution map LF ullGrad is defined as:
LF ullGrad = ψ(∇xf(x) ⊙ x) +
X
k∈K
X
c∈ck
ψ(f b(x)c)
To facilitate an efficient sampling of regions in the coun-
terfactual analysis, we utilize the FullGrad attribution map.
Definition 1: (Subobject Region Attribution Score) Us-
ing the attribution map of model f(X) and the subobject
regions {z1, z2, · · · , zK} created by adaptive segmentation
for the input image X, we define the subobject region attri-
bution score, {s1, s2, · · · , sK} as follows:
sk =
1
n.m
X
n
X
m
LF ullGrad(F,X)[i, j], X[i, j] ∈ zk
Although feature attributions highlight features that are
significant in terms of how they affect the model’s ability to
predict, they do not indicate that altering significant features
would result in a different desired outcome.
Definition 2: (Subobject Region Confidence Reduc-
tion) Given a model Y = f(X) that takes an image X
with subobject regions X = [z0, z1, ..., zn]T and outputs a
probability distribution Y. The confidence reduction crk of
subobject region zk, (k ∈ [1, n]) towards Y is the change of
the output by masking the k-th subobject region of X, while
being classified as the same class, as follows:
crk = f(X) − f(X ◦ Mask(zk))
In Sec 3.3, we present our greedy region search algorithm
which utilizes subobject region attribution score as heuris-
tics and employs confidence level for causal obfuscation us-
ing counterfactual subobject region explanations.
Counterfactual Generation Using Informed Subobject
Region Search. The previous sections lead us to the mini-
mum region masking problem. This can be computationally
expensive to solve, as it requires the masking and analysis of
2K different combination of regions, Z of X based on Sec-
tion 3.1 . Rather than solving the problem directly, we find
an approximate solution using a greedy region search.
Given a predictive model f : X → 0, 1, we can define the
set of counterfactual explanations for an input x ∈ X as x′
while argmin x′d(x, x′) and x′ = {x ∈ X|f(x) ̸= f(x′)}.
In other words x′ = {x ∈ X|f(x) ̸= f(x′)} , contains
all the inputs x for which the model f returns a prediction
different from f(x) while minimizing the distance between
x and x′.
Our greedy region search, starts with us first sorting the
K regions in descending order by the average attribution
for each region which were calculated in subsection . The
greedy region search considers a subset of regions k ∈ K. k
begins with the top region by average attribution and itera-
tively expands to the top two regions by average attribution
and so on until an x′ is found such that f(x′) ̸= f(x).
Experimental Evaluation
Datasets
We evaluated our Conditional VLM and Counterfactual
Subobject Explanation methods on three datasets of real-
world harmful images to study the practical application of
counterfactual subobject explanations.
Sexually Explicit: First, we sampled a subset of images
from an NSFW images dataset (Kim 2021) consisting of
334,327 images by selecting the “porn”, “neutral”, and
“sexy” classes. We combine the “neutral”, and “sexy”
classes into a single class of “safe” images.
Cyberbullying: Second, we used a cyberbullying im-
ages (Vishwamitra et al. 2021) dataset consisting of nearly
20,000 images belonging to the classes “cyberbullying” and
“non-cyberbullying”.
Self-Harm: Third, we used a self-harm images dataset
(Bethany et al. 2023), consisting of 5000 images with classes
“self-harm” and “non self-harm”.
Evaluation Settings
ConditionalVLM. We compare our proposed method
against other state-of-the-art image-to-text models such as
InstructBLIP (Dai et al. 2023), OFA-Large (Wang et al.
2022), and mPLUG (Li et al. 2022). We use the implementa-
tions of these methods from HuggingFace. For InstructBLIP,
we
use
InstructBLIP-Vicuna-13b
with
num beams=5,
max length=512,
min length=1,
top p=0.9,
repeti-
tion penalty=1.5, length penalty=1.0, and temperature=1.
The image encoder for this implementation of InstructBLIP
was Vit-g/14 (Fang et al. 2023). For mPLUG, we use the
parameters do sample=True, top k=5, and max length=512.
For
OFA
we
use
the
parameters
of
num beams=5,
no repeat ngram size=3.
To
demonstrate
our
Condi-
tionalVLM
framework,
we
modify
the
InstructBLIP-
Vicuna-13b architecture to include a CIIT, which we call
ConditionalBLIP. All experiments were carried out on a
DGX 8x A100 GPU, with 80GB of VRAM each.
We fine-tuned a ResNet-50 classifier available in Pytorch
(Paszke et al. 2019) using pre-trained model weights trained
from the ImageNet dataset (Deng et al. 2009). The NSFW,
cyberbullying and self-harm datasets were each divided into
train, validation, and test sets, with 80% being allocated to
the train set, and 10% each allocated to validation and test
sets. We trained the models for 50 epochs and selected the
models that have the highest classification accuracies on the
validation sets. These models achieved accuracies of 98.9%,
91.9% and 97.6% respectively on the test set in our exper-
iments. We use these classifiers as the control code for the
CIIT in ConditionalBLIP.
Counterfactual Subobject Explanations for Obfuscation.
To test different segmentation methods, we experimented
with SLIC (Achanta et al. 2010), Felzenszwalb (Felzen-
szwalb and Huttenlocher 2004), and Compact Watershed
(Neubert and Protzel 2014) segmentation methods imple-
mented in the scikit-image library (van der Walt et al. 2014),
Segment Anything Model (SAM) (Kirillov et al. 2023), and
Bayesian Adaptive Superpixel Segmentation (Uziel, Ronen,
and Freifeld 2019). For our experiments, we selected the fol-
lowing parameters for each segmentation method: for SLIC,
we chose the number of segments to be 25 and compactness
equal to 1; for Felzenszwalb we selected the scale to be 500,
sigma to be 0.5, and a minimum component size of 200; for
Compact Watershed, we chose the number of markers to be
25 and the compactness parameter to be 0.001.
Figure 2: Examples of segmentation methods on a cyberbul-
lying image. From top to bottom: (1) BASS, (2) SLIC, (3)
SAM.
We used the following attribution map methods in our
experiments: (Grad-CAM (Selvaraju et al. 2017), XGrad-
CAM (Fu et al. 2020), Grad-CAM ++ (Chattopadhay et al.
2018), FullGrad (Srinivas and Fleuret 2019), and Ablation-
CAM (Ramaswamy et al. 2020)). For the implementation of
the attribution map methods, we use the Pytorch Grad-CAM
library (Gildenblat and contributors 2021).
Evaluation Metrics
ConditionalVLM. We evaluate VLM’s ability to investi-
gate three different unsafe image categories in two phases.
In the first phase, we conduct a coarse-grained evaluation
by having human evaluators determine based off of the im-
age descriptions produced by the VLM whether a moderator
should be able to understand which dataset of unsafe im-
age the image belongs to. In this evaluation, a team of three
human evaluators who were involved in this research were
asked to evaluate whether these descriptions produced by
the VLM on the questions of ”What is happening in the im-
age?”, and ”What are the people doing?” were sufficient to
accurately categorize them into the correct dataset that the
unsafe image the image belongs to. The final labels were
assigned by majority voting.
In the second phase, we conduct a fine-grained evaluation
by having human evaluators evaluate the responses of the
VLM to curated moderator questions with respect to an un-
safe image image. These fine-grained questions ask about
specific attributes of images relating to the unsafe image
categories. In this evaluation, the same team of evaluators
were asked to determine whether the answers produced by
the VLM correctly answered these curated questions.
Counterfactual Subobject Explanations for Obfuscation.
We investigate the ability of CSE to generate a successful
counterfactual explanation on an unsafe image X to satisfy
two requirements: (1) the generated counterfactual example
X′ must be a convincing representation of another class such
that it has a softmax score greater than a threshold T on an-
other class, and (2) the search space that the counterfactual
example X′ exists in must be found by searching N or fewer
different regions. Since, there are 2K different combinations
of regions to be analyzed in X with K number of regions, we
limit the search space to a certain number of regions in our
evaluation. In our experiments on unsafe images, we select
the threshold for softmax score T to be 0.5 and the threshold
Dataset
Model
Human Evaluation
ConditionalBLIP
94.5
Sexually Explicit
InstructBLIP
80.0
mPLUG
73.5
OFA-Large
13.5
ConditionalBLIP
99.5
Cyberbullying
InstructBLIP
23.0
mPLUG
16.0
OFA-Large
10.0
ConditionalBLIP
99.0
Self-Harm
InstructBLIP
47.0
mPLUG
51.5
OFA-Large
17.0
Table 1: Quantitative results of VLM on coarse-grained im-
age descriptions.
Dataset
Questions
InstructBLIP
ConditionalBLIP
Does the image contain any
sexual content or nudity?
61.1
99.2
Sexually Explicit
Does the image contain ex-
plicit sexual content?
37.9
99.9
Does the image contain po-
tentially offensive gestures
or symbols?
59.1
80.0
Does the image contain any
weapons?
99.2
94.0
Cyberbullying
Is there any aggressive be-
havior shown in the image?
56.4
98.3
Is there any text in the im-
age that might be considered
hate speech?
57.2
95.2
Are there any depictions of
self-harm in the image?
27.4
98.9
Self-Harm
Are there visible signs of
self-bruising
or
self-harm
through physical trauma?
74.2
99.2
Does
the
image
contain
symbols
associated
with
self-destructive behavior?
30.2
81.4
Table 2: Quantitative results of VLM on fine-grained mod-
erator questions.
for regions to be 10.
Results and Discussion
ConditionalVLM. The results for the coarse-grained eval-
uations of the VLM are shown in Table 1. In this table, we
present the accuracy of four models, including our model,
ConditionalBLIP, that convert images to text, specifically
focusing on their ability to identify unsafe attributes in im-
ages based on generic questions. In this experiment, a total
of 2000 unsafe image samples from each category of unsafe
image datasets were tested. The results show that Condi-
tionalBLIP is able to significantly outperform other state-
of-the-art models in identifying the unsafe image attributes
of unsafe images, simply from asking generic questions on
the image, with an average correct identification accuracy
of 98% of unsafe image attributes across the three datasets.
Compared to the 50% accuracy by InstructBLIP, 47% by
mPLUG, and 13.5% by OFA-Large, we observe that exist-
ing models are insufficient for describing unsafe images.
We present the questions and quantitative results of the
fine-grained evaluation of ConditionalBLIP in Table 2.
We compare ConditionalBLIP against InstructBLIP, which
showed the best coarse-grained results compared to other
methods that were evaluated in Table 1. Furthermore, the
InstructBLIP model is the most similar in implementation to
the ConditionalBLIP model, where the primary difference
is the usage of the CIIT in ConditionalBLIP. In Table 2, we
present the question posed to the VLM, alongside the de-
tection accuracy of InstructBLIP and ConditionalBLIP on
these questions. The fine-grained evaluation shows that im-
age conditioning significantly enhances VLMs ability to un-
derstand unsafe images, with an average improvement in ac-
curacy of 38.2% across the questions. The comparison be-
tween the performances of InstructBLIP and Conditional-
BLIP reveals significant differences in their respective abil-
ities to identify and describe unsafe content in visual data.
For example, given a question on a randomly selected cy-
berbullying image, specifically asking “What are the people
doing?”, the responses from the two models were notice-
ably distinct. InstructBLIP stated, “The people in the image
are posing for a photograph,” a general and incorrect analy-
sis that fails to capture the offensive nature of the image. In
contrast, ConditionalBLIP accurately identified the behav-
ior, stating “In the image, a woman is making an offensive
gesture, such as flipping someone off, with her middle fin-
ger.” This response was consistent with the actual content of
the image. By employing contrastive language-image pre-
training and conditioning the language prompt using pre-
trained unsafe image classifiers, ConditionalBLIP is able to
parse the unsafe visual embedding effectively.
Counterfactual Subobject Explanations for Obfuscation.
For the counterfactual image obfuscation experiments, we
test on 585 sexually explicit, cyberbullying and self-harm
images. We compare our method against the CSRA method,
setting numROI = 10 to match time complexity. Previous
work showed gradient-based attribution maps were unsuit-
able for obfuscating unsafe images (Bethany et al. 2023).
Our trained models show improvements of 13.9% on sex-
ually explicit, 22.0% on cyberbullying, and 39.5% on self-
harm images when comparing CSRA vs CSE.
We tested various attribution map methods with BASS
(Uziel, Ronen, and Freifeld 2019) as the constant segmenta-
tion method on unsafe image samples, with results in Table
3. The average search space required to find a counterfactual
example was presented, showing that different attribution
map methods do not significantly impact CSE, with most
generating similar highest average attribution scores in sim-
ilar areas. The exception was the FullGrad method, which
provided slightly more successful counterfactual examples,
better average search space, and fewer obfuscated regions.
This can be attributed to FullGrad’s more dispersed attri-
butions across the image, which does not restrict the search
space as much, and its unique method of satisfying local
and global importance by aggregating information from
both input-gradient and intermediate bias-gradients, thus
aiding CSE in finding suitable counterfactual explanations
more readily.
We tested different segmentation methods with FullGrad
as the constant attribution map method on unsafe image
samples, and the results are in Table 4. The choice of seg-
mentation method significantly impacted the number of suc-
cessful counterfactual explanations, average search space,
and average number of regions obfuscated. BASS was the
Dataset
Attribution Map
Counterfactual
Avg Depth
Avg Obfuscation
FullGrad
90.6
5.8
35.0
Ablation-CAM
90.6
5.8
35.2
Sexually Explicit
Grad-CAM
90.6
5.8
35.2
Grad-CAM++
90.6
5.8
35.2
XGrad-CAM
90.6
5.8
35.2
FullGrad
82.0
5.2
35.2
Ablation-CAM
79.5
5.1
34.2
Cyberbullying
Grad-CAM
79.5
5.1
34.2
Grad-CAM++
79.5
5.1
34.2
XGrad-CAM
79.5
5.1
34.2
FullGrad
72.8
5.6
50.1
Ablation-CAM
72.8
5.6
50.1
Self-Harm
Grad-CAM
72.8
5.6
50.1
Grad-CAM++
72.8
5.6
50.1
XGrad-CAM
72.8
5.6
50.1
Table 3: Quantitative results of CSE using different attribu-
tion map methods.
Dataset
Attribution Map
Counterfactual
Avg Depth
Avg Obfuscation
BASS
90.6
5.8
35.0
SLIC
76.6
7.6
33.0
Sexually Explicit
Felzenswalb
19.9
7.5
12.2
Watershed
51.2
7.9
31.9
SAM
29.5
7.4
33.2
BASS
82.0
5.2
35.2
SLIC
60.0
6.3
25.9
Cyberbullying
Felzenswalb
20.5
6.3
17.6
Watershed
50.0
6.6
23.9
SAM
50.0
6.6
40.2
BASS
72.8
5.6
50.1
SLIC
33.4
6.6
26.3
Self-Harm
Felzenswalb
38.4
6.5
47.5
Watershed
33.1
6.8
24.6
SAM
39.5
6.2
70.6
Table 4: Quantitative results of CSE on different segmenta-
tion methods.
most effective, with a combination of BASS and FullGrad
yielding 81.8% successful counterfactual examples, a search
depth of 5.5, and an average of 40.1% of the image obfus-
cated. The segmentation’s effect on counterfactual examples
can be seen in Figure 2, and as Table 4 showed, methods like
BASS are key for successful counterfactual explanations, as
they break the image into non-intersecting, color and spa-
tially coherent subobjects.
Ablation Study. To evaluate our vision-language model’s
conditioning, we conducted an ablation study by changing
unsafe classifier guidance on the Image Instruction-guided
Transformer or CIIT model’s instruct prompt embedding
from 1 to 0. This conditioning on zero-shot instruct em-
beddings yielded acceptable results for unsafe images by
allowing CIIT to match and parse the unsafe visual embed-
ding effectively, while also providing more explicit control
over unsafe visual feature correlation with conditioned
instruct prompt. For instance, the LLM decoder’s output for
an unsafe image changed to suggest “women are performing
potential erotic dance in a bar” vs. “women dancing in a
bar”. These results suggest that conditioning is a promising
approach for vision language models. Further details are in
Appendix [ConditioningVLM]. Future research could ex-
plore alternative safeguard mechanisms for vision language
models.
Conclusion
In this work, we have presented ConditionalVLM, a vi-
sual reasoning framework that generates accurate rationales
for unsafe image descriptions by leveraging state-of-the-
art VLMs conditioned on pre-trained unsafe image clas-
sifiers, and CSE, a counterfactual visual explanation tech-
nique to obfuscate the unsafe regions in unsafe images for
safer sharing. We evaluated these two methods on three cat-
egories of unsafe images. An implementation of Condition-
alVLM, which we called ConditionalBLIP showed supe-
rior performance compared to other state-of-the-art image-
to-text models on describing unsafe images. We also com-
pare CSE against another recent unsafe image obfuscation
method and show how our approach is effective in generat-
ing causal explanations for obfuscating unsafe images.
Acknowledgments
This research project and the preparation of this publi-
cation were funded in part by the Department of Home-
land Security (DHS), United States Secret Service, National
Computer Forensics Institute (NCFI) via contract number
70US0920D70090004 and by NSF Grant No. 2245983.
References
2021. Facebook moderator: ‘Every day was a nightmare’.
https://www.bbc.com/news/technology-57088382.
2021.
Judge OKs $85 mln settlement of Facebook mod-
erators’ PTSD claims.
https://www.reuters.com/legal/
transactional/judge-oks-85-mln-settlement-facebook-
moderators-ptsd-claims-2021-07-23/.
2023. Vicuna. https://github.com/lm-sys/FastChat.
Achanta, R.; Shaji, A.; Smith, K.; Lucchi, A.; Fua, P.; and
S¨usstrunk, S. 2010. Slic superpixels. Technical report.
Adler, R. A.; and Chenoa Cooper, S. 2022. “When a Tornado
Hits Your Life:” Exploring Cyber Sexual Abuse Survivors’
Perspectives on Recovery. Journal of Counseling Sexology
& Sexual Wellness: Research, Practice, and Education, 4(1):
1–8.
Alayrac, J.-B.; Donahue, J.; Luc, P.; Miech, A.; Barr, I.; Has-
son, Y.; Lenc, K.; Mensch, A.; Millican, K.; Reynolds, M.;
et al. 2022. Flamingo: a visual language model for few-shot
learning. Advances in Neural Information Processing Sys-
tems, 35: 23716–23736.
Are, C. 2020.
How Instagram’s algorithm is censoring
women and vulnerable users but helping online abusers.
Feminist media studies, 20(5): 741–744.
Ashurst, L.; and McAlinden, A.-M. 2015. Young people,
peer-to-peer grooming and sexual offending: Understanding
and responding to harmful sexual behaviour within a social
media society. Probation Journal, 62(4): 374–388.
Berrios, W.; Mittal, G.; Thrush, T.; Kiela, D.; and Singh,
A. 2023. Towards Language Models That Can See: Com-
puter Vision Through the LENS of Natural Language. arXiv
preprint arXiv:2306.16410.
Bethany, M.; Seong, A.; Silva, S. H.; Beebe, N.; Vishwami-
tra, N.; and Najafirad, P. 2023. Towards targeted obfuscation
of adversarial unsafe images using reconstruction and coun-
terfactual super region attribution explainability.
In 32nd
USENIX Security Symposium (USENIX Security 23), 643–
660.
Billy Perrigo. 2019.
Facebook Says It’s Removing More
Hate Speech Than Ever Before. But There’s a Catch.
Binder, M. 2019. Facebook claims its new AI technology
can automatically detect revenge porn.
https://mashable.
com/article/facebook-ai-tool-revenge-porn.
Bronstein, C. 2021. Deplatforming sexual speech in the age
of FOSTA/SESTA. Porn Studies, 8(4): 367–380.
Cabral, L.; Haucap, J.; Parker, G.; Petropoulos, G.; Valletti,
T. M.; and Van Alstyne, M. W. 2021. The EU digital mar-
kets act: a report from a panel of economic experts. Cabral,
L., Haucap, J., Parker, G., Petropoulos, G., Valletti, T., and
Van Alstyne, M., The EU Digital Markets Act, Publications
Office of the European Union, Luxembourg.
Chandrasekaran, J.; Lei, Y.; Kacker, R.; and Kuhn, D. R.
2021. A combinatorial approach to explaining image classi-
fiers. In 2021 IEEE International Conference on Software
Testing, Verification and Validation Workshops (ICSTW),
35–43. IEEE.
Chattopadhay, A.; Sarkar, A.; Howlader, P.; and Balasub-
ramanian, V. N. 2018. Grad-cam++: Generalized gradient-
based visual explanations for deep convolutional networks.
In 2018 IEEE winter conference on applications of computer
vision (WACV), 839–847. IEEE.
Chelmis, C.; and Yao, M. 2019. Minority report: Cyberbul-
lying prediction on Instagram. In Proceedings of the 10th
ACM conference on web science, 37–45.
Dai, W.; Li, J.; Li, D.; Tiong, A. M. H.; Zhao, J.; Wang, W.;
Li, B.; Fung, P.; and Hoi, S. 2023. InstructBLIP: Towards
General-purpose Vision-Language Models with Instruction
Tuning. arXiv:2305.06500.
Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and Fei-
Fei, L. 2009. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE conference on computer vision and
pattern recognition, 248–255. Ieee.
Exon, J. 1996. The Communications Decency Act. Federal
Communications Law Journal, 49(1): 4.
Fang, Y.; Wang, W.; Xie, B.; Sun, Q.; Wu, L.; Wang, X.;
Huang, T.; Wang, X.; and Cao, Y. 2023.
Eva: Exploring
the limits of masked visual representation learning at scale.
In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 19358–19369.
Felzenszwalb, P. F.; and Huttenlocher, D. P. 2004. Efficient
graph-based image segmentation. International journal of
computer vision, 59(2): 167–181.
Fu, R.; Hu, Q.; Dong, X.; Guo, Y.; Gao, Y.; and Li, B. 2020.
Axiom-based Grad-CAM: Towards Accurate Visualization
and Explanation of CNNs. In BMVC.
Gesley, J. 2021.
Germany: Network Enforcement Act
Amended to Better Fight Online Hate Speech.
In Li-
brary of Congress, at: https://www. loc. gov/item/global-
legal-monito r/2021-07-06/germany-network-enforcement-
act-amended-to-better-fight-online-hat e-speech/#:˜: text=
Article%
20Germany%
3A%
20Network%
20Enforce-
ment% 20Act, fake% 20news% 20in% 20social% 20net-
works.
Gildenblat, J.; and contributors. 2021. PyTorch library for
CAM methods.
https://github.com/jacobgil/pytorch-grad-
cam.
Hargrave, A. M.; and Livingstone, S. M. 2009. Harm and
offence in media content: A review of the evidence.
Hendricks, T. 2021. Cyberbullying increased 70% during
the pandemic; Arizona schools are taking action.
https:
//www.12news.com/article/news/crime/cyberbullying-
increased-70-during-the-pandemic-arizona-schools-are-
taking-action/75-fadf8d2c-cf11-43f0-b074-5de485a3247d.
John, A.; Glendenning, A. C.; Marchant, A.; Montgomery,
P.; Stewart, A.; Wood, S.; Lloyd, K.; Hawton, K.; et al. 2018.
Self-harm, suicidal behaviours, and cyberbullying in chil-
dren and young people: Systematic review. Journal of Med-
ical Internet Research, 20(4).
Kim, A. 2021.
NSFW Data Scraper.
https://github.com/
alex000kim/nsfw data scraper.
Kirillov, A.; Mintun, E.; Ravi, N.; Mao, H.; Rolland, C.;
Gustafson, L.; Xiao, T.; Whitehead, S.; Berg, A. C.; Lo,
W.-Y.; et al. 2023.
Segment anything.
arXiv preprint
arXiv:2304.02643.
Krause, M. 2009. Identifying and managing stress in child
pornography and child exploitation investigators. Journal of
Police and Criminal Psychology, 24(1): 22–29.
Lenhart, A.; Ybarra, M.; and Price-Feeney, M. 2016. Non-
consensual image sharing: one in 25 Americans has been a
victim of” revenge porn”.
Li, C.; Xu, H.; Tian, J.; Wang, W.; Yan, M.; Bi, B.; Ye,
J.; Chen, H.; Xu, G.; Cao, Z.; et al. 2022.
mPLUG: Ef-
fective and Efficient Vision-Language Learning by Cross-
modal Skip-connections. In Proceedings of the 2022 Con-
ference on Empirical Methods in Natural Language Pro-
cessing, 7241–7259.
Li, J.; Li, D.; Savarese, S.; and Hoi, S. 2023.
Blip-2:
Bootstrapping language-image pre-training with frozen im-
age encoders and large language models.
arXiv preprint
arXiv:2301.12597.
Li, Y.; Vishwamitra, N.; Knijnenburg, B. P.; Hu, H.; and
Caine, K. 2017.
Effectiveness and users’ experience of
obfuscation as a privacy-enhancing technology for sharing
photos. Proceedings of the ACM on Human-Computer In-
teraction, 1(CSCW): 1–24.
Meta.
2022.
Appealed
Content.
https://transparency.fb.com/policies/improving/appealed-
content-metric/.
Neubert, P.; and Protzel, P. 2014. Compact watershed and
preemptive slic: On improving trade-offs of superpixel seg-
mentation algorithms. In 2014 22nd international confer-
ence on pattern recognition, 996–1001. IEEE.
Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.;
Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga,
L.; Desmaison, A.; Kopf, A.; Yang, E.; DeVito, Z.; Raison,
M.; Tejani, A.; Chilamkurthy, S.; Steiner, B.; Fang, L.; Bai,
J.; and Chintala, S. 2019. PyTorch: An Imperative Style,
High-Performance Deep Learning Library. In Wallach, H.;
Larochelle, H.; Beygelzimer, A.; d'Alch´e-Buc, F.; Fox, E.;
and Garnett, R., eds., Advances in Neural Information Pro-
cessing Systems 32, 8024–8035. Curran Associates, Inc.
Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;
Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;
et al. 2021. Learning transferable visual models from nat-
ural language supervision. In International conference on
machine learning, 8748–8763. PMLR.
Ramaswamy, H. G.; et al. 2020. Ablation-cam: Visual ex-
planations for deep convolutional network via gradient-free
localization. In Proceedings of the IEEE/CVF Winter Con-
ference on Applications of Computer Vision, 983–991.
Ramesh, A.; Dhariwal, P.; Nichol, A.; Chu, C.; and Chen, M.
2022. Hierarchical text-conditional image generation with
clip latents. arXiv preprint arXiv:2204.06125.
Sanchez, L.; Grajeda, C.; Baggili, I.; and Hall, C. 2019. A
practitioner survey exploring the value of forensic tools, AI,
filtering, & safer presentation for investigating child sexual
abuse material (CSAM). Digital Investigation, 29.
Selvaraju, R. R.; Cogswell, M.; Das, A.; Vedantam, R.;
Parikh, D.; and Batra, D. 2017. Grad-cam: Visual explana-
tions from deep networks via gradient-based localization. In
Proceedings of the IEEE international conference on com-
puter vision, 618–626.
Srinivas, S.; and Fleuret, F. 2019. Full-gradient representa-
tion for neural network visualization. Advances in neural
information processing systems, 32.
Steiger, M.; Bharucha, T. J.; Venkatagiri, S.; Riedl, M. J.;
and Lease, M. 2021. The psychological well-being of con-
tent moderators: the emotional labor of commercial moder-
ation and avenues for improving support. In Proceedings
of the 2021 CHI conference on human factors in computing
systems, 1–14.
Tenbarge, K. 2023. Instagram’s sex censorship sweeps up
educators, adult stars and sex workers.
Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
M.-A.; Lacroix, T.; Rozi`ere, B.; Goyal, N.; Hambro, E.;
Azhar, F.; et al. 2023. Llama: Open and efficient founda-
tion language models. arXiv preprint arXiv:2302.13971.
Uziel, R.; Ronen, M.; and Freifeld, O. 2019.
Bayesian
adaptive superpixel segmentation.
In Proceedings of the
IEEE/CVF International Conference on Computer Vision,
8470–8479.
van der Walt, S.; Sch¨onberger, J. L.; Nunez-Iglesias, J.;
Boulogne, F.; Warner, J. D.; Yager, N.; Gouillart, E.; Yu,
T.; and the scikit-image contributors. 2014. scikit-image:
image processing in Python. PeerJ, 2: e453.
Vermeire, T.; Brughmans, D.; Goethals, S.; de Oliveira, R.
M. B.; and Martens, D. 2022. Explainable image classifi-
cation with evidence counterfactual. Pattern Analysis and
Applications, 25(2): 315–335.
Vishwamitra, N.; Hu, H.; Luo, F.; and Cheng, L. 2021. To-
wards Understanding and Detecting Cyberbullying in Real-
world Images. In 2020 19th IEEE International Conference
on Machine Learning and Applications (ICMLA).
Wachter, S.; Mittelstadt, B.; and Russell, C. 2017. Counter-
factual explanations without opening the black box: Auto-
mated decisions and the GDPR. Harv. JL & Tech., 31: 841.
Wang, P.; Yang, A.; Men, R.; Lin, J.; Bai, S.; Li, Z.; Ma, J.;
Zhou, C.; Zhou, J.; and Yang, H. 2022. Ofa: Unifying archi-
tectures, tasks, and modalities through a simple sequence-to-
sequence learning framework. In International Conference
on Machine Learning, 23318–23340. PMLR.
Wang, W.; Bao, H.; Dong, L.; Bjorck, J.; Peng, Z.; Liu,
Q.; Aggarwal, K.; Mohammed, O. K.; Singhal, S.; Som, S.;
et al. 2023. Image as a Foreign Language: BEiT Pretraining
for Vision and Vision-Language Tasks. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 19175–19186.
"
"Modern vehicles employ intelligent systems like interconnected autonomous driving and advanced driving assistance systems for improved driving experiences, which are enabled by increased connectivity to infrastructure and the fusion of information from multiple sensing modes. However, the increased connectivity combined with the inherent security flaws in legacy network architecture renders vehicles vulnerable to active and passive attacks, directly affecting passenger safety. Researchers have proposed machine learning models for detecting attacks, whose deployments are enabled through quantised neural networks targeting low-power platforms. Our research presents a custom quantised MLP (CQMLP) model as a multi-class classifier capable of detecting multiple attacks from a benign flow of controller area network (CAN) messages. The specific quantisation and neural architecture were determined through a joint design space exploration, resulting in our choice of the 2-bit precision and the n-layer MLP. Our 2-bit version was trained using Brevitas and optimised as a dataflow hardware model through the FINN toolflow from AMD/Xilinx, targeting an XCZU7EV device. Our findings indicate that the 2-bit CQMLP model, when integrated as an IDS, can detect malicious attack messages (DoS, fuzzing, and spoofing attacks) with very high accuracy of 99.9%, on par with the state-of-the-art methods in the literature. Furthermore, the dataflow model can perform line rate detection at a latency of 0.11 ms from message reception while consuming 0.23 mJ/inference.nan","Automotive networks are undergoing rapid evolution to cater to the data-intensive needs of novel intelligent capabilities that enhance safety, infotainment, and comfort for passengers. These interconnected networks, via multiple network protocols, facilitate high-speed communication and information exchange between numerous electronic computing units (ECUs), sensors, and actuators present in modern cars. Among the network protocols, Controller Area Network (CAN) is widely used for critical communication between ECUs and continues to be the predominant network protocol for in-vehicle networks due to its cost-effectiveness and ease of use in control applications. Earlier ECUs and software functions deployed on the CAN were automatically siloed due to the limited connectivity of vehicles to the external world. However, modern vehicles rely on connectivity to infrastructure and other vehicles, enabling real-time sensing of the external environment and unique features like remote monitoring and control of specific capabilities for diagnostics and over-the-air upgrades. Researchers have demonstrated that such interfaces open new avenues for injecting malicious code or messages into these previously siloed networks. As a result, intrusion detection approaches have been proposed in the literature, allowing critical systems to enter a ‘safe working’ mode when such threats are detected. Machine learning (ML) approaches have shown significant improvement in detecting these threats and can adapt to newer attack vectors without the overheads of rule-based approaches. Additionally, quantised versions of floating-point models, termed quantised neural networks (QNNs), have demonstrated viability as alternatives, reducing computational complexity, resource, and energy consumption at the expense of a slight reduction in inference accuracy. QNNs are then deployed on constrained devices such as low-end FPGAs or embedded platforms. Frameworks such as Vitis-AI and FINN can convert Pytorch/TensorFlow representations at native precisions to quantised models and dataflow-style hardware accelerators for deployment on the FPGA.nan","nanRule-based approaches, commonly employed for intrusion detection systems (IDS), can be further classified into flow-based and payload-based approaches. While flow-based approaches identify traits like message frequency and/or interval for the network to detect abnormalities, payload-based approaches utilise the data segment in CAN frames to detect abnormal sequences of instructions or data. Researchers also explored hybrid schemes using both message timing/frequency and payload information. Machine learning-based techniques further generalise these techniques when trained with large datasets through classification, sequential, and deep learning-based approaches.nan","Our proposed methodology involves the formulation of a feed-forward custom quantised multi-layer-perceptron-based IDS for automotive CAN, the design of a dataflow-style custom quantised hardware implementation of the model, and the integration of the dataflow accelerator as an Advanced eXtensible Interface (AXI) slave peripheral to the ARM cores, offering complete isolation from the software tasks on them.nan","Our experimental results demonstrate that the proposed custom quantised (2-bit) MLP-based IDS (CQMLP-IDS) achieves an average accuracy of 99.91% across Denial of Service (DoS), Fuzzing, and RPM-spoofing attacks among the benign flow of messages, identical to or exceeding the detection accuracy achieved by state-of-the-art GPU- and CPU-based implementations. The tightly integrated ECU architecture reduces the per-message execution latency by 2.2× and the energy consumed by 3.9× compared to state-of-the-art IDSs proposed in the research literature. Furthermore, our (fp32) MLP model on a Jetson Nano, mimicking a dedicated IDS ECU, incurs 12× higher energy consumption per inference, compared to the integrated IDS-ECU.nan","Our research presents a dataflow-style hardware accelerator that implements a custom quantised MLP (CQMLP) model for detecting and classifying multiple attack vectors on an automotive CAN network. By tightly integrating the accelerator to the ARM core on a Zynq Ultrascale+ platform, we demonstrate a 2.2× speed-up in per-message processing latency and almost 3.9× reduction in energy consumption with 0.23mJ per inference when compared to the state-of-the-art IDSs. The quantised model also maintains high detection and classification accuracy across various attacks, making it suitable for distributing IDS capabilities across ECUs in a vehicle network.nan",Exploring Highly Quantised Neural Networks for Intrusion Detection in Automotive CAN,"Shashwat Khandelwal, Shreejith Shanker","Exploring Highly Quantised Neural Networks for
Intrusion Detection in Automotive CAN
Shashwat Khandelwal & Shanker Shreejith
Reconfigurable Computing Systems Lab, Electronic & Electrical Engineering
Trinity College Dublin, Ireland
Email: {khandels, shankers}@tcd.ie
Abstract—Vehicles today comprise intelligent systems like
connected autonomous driving and advanced driving assistance
systems (ADAS) to enhance the driving experience, which is
enabled through increased connectivity to infrastructure and
fusion of information from different sensing modes. However, the
rising connectivity coupled with the legacy network architecture
within vehicles can be exploited for launching active and passive
attacks on critical vehicle systems and directly affecting the
safety of passengers. Machine learning-based intrusion detection
models have been shown to successfully detect multiple targeted
attack vectors in recent literature, whose deployments are en-
abled through quantised neural networks targeting low-power
platforms. Multiple models are often required to simultaneously
detect multiple attack vectors, increasing the area, (resource)
cost, and energy consumption. In this paper, we present a case
for utilising custom-quantised MLP’s (CQMLP) as a multi-class
classification model, capable of detecting multiple attacks from
the benign flow of controller area network (CAN) messages.
The specific quantisation and neural architecture are determined
through a joint design space exploration, resulting in our choice
of the 2-bit precision and the n-layer MLP. Our 2-bit version
is trained using Brevitas and optimised as a dataflow hardware
model through the FINN toolflow from AMD/Xilinx, targeting
an XCZU7EV device. We show that the 2-bit CQMLP model,
when integrated as the IDS, can detect malicious attack messages
(DoS, fuzzing, and spoofing attack) with a very high accuracy of
99.9%, on par with the state-of-the-art methods in the literature.
Furthermore, the dataflow model can perform line rate detection
at a latency of 0.11 ms from message reception while consuming
0.23 mJ/inference, making it ideally suited for integration with
an ECU in critical CAN networks.
Index Terms—Controller Area Network, Intrusion Detection
System, Quantised Neural Nets, Machine Learning, FPGAs
I. INTRODUCTION & RELATED WORKS
Automotive networks are evolving rapidly to cater to the
high-data needs for novel/intelligent capabilities that have en-
abled safety, infotainment, and comfort for passengers. These
interconnected networks (via multiple network protocols) fa-
cilitate high-speed communication/information exchange be-
tween over a hundred electronic computing units (ECUs),
sensors, and actuators present in modern cars. Among the
network protocols, Controller Area Network (CAN) is used
for critical communication between ECUs and it continues
to be the most widely used network protocol for in-vehicle
networks owing to its cost-effective nature and ease of use in
control applications [1]. Early ECUs and software functions
deployed on the CAN were automatically siloed due to the
limited connectivity of the vehicles then, to the external world.
Novel capabilities in vehicles today rely on connectivity to
infrastructure and other vehicles to enable real-time sensing
Body 
Control
Module
Engine
Control
Module 
(Transmitter) 
 Brake
Control
Module 
(Receiver)
0x043f
0x043f
CAN Bus
(a)
]
Body 
Control
Module 
Engine
Control
Module 
(Transmitter) 
 Brake
Control
Module 
(Receiver)
0x043f
0x0000
0x0000
Comprimised
ECU
CAN Bus
Fig. 1: An illustration of a simple DoS attack launched through
a compromised ECU. Part (a) shows the normal communica-
tion between the ECUs, while in (b), the ECU is unable to
transmit messages on the CAN bus as the compromised ECU
floods the bus with high priority messages.
of the outside environment and also to enable unique features
like remote monitoring and control of specific capabilities for
diagnostics, and over-the-air upgrades. Researchers however
have shown that such interfaces open up new avenues for
injecting malicious code/messages into these previously siloed
networks [2]–[4]. Figure 1 shows an example of a simple DoS
attack on a standard CAN bus. Such attacks are largely enabled
by the lack of inherent security and authentication mechanisms
in CAN and similar automotive network protocols [5], [6].
To detect the onset of such intrusions on CAN, multiple
intrusion detection approaches have been proposed in the lit-
erature allowing critical systems to enter into a ‘safe working’
mode when such threats are detected. Early intrusion detection
systems (IDS) proposed were rule/specification based, which
utilised a set of rules to compare known attack signatures to
patterns captured from current network parameters/messages
to detect unusual activity [7]–[9]. Recently, machine learning
(ML) approaches have shown significant improvement in the
detection accuracy of such threats and the ability to adapt to
newer attack vectors [10]–[14] without incurring overheads
of rule-based approaches. In addition to native precision ML
models, quantised variants of the floating-point models have
shown to be viable alternatives, reducing the computational
complexity, resource, and energy consumption at the expense
of a slight reduction in inference accuracy. Quantised models
are then deployed on constrained devices such as low-end FP-
GAs or dedicated embedded platforms [15]. Frameworks such
as Vitis-AI and FINN can convert the Pytorch/TensorFlow
representations at native precisions to quantised models and
dataflow-style hardware accelerators for deployment on the
arXiv:2401.11030v1  [cs.CR]  19 Jan 2024
FPGA [16], [17]. ECU architectures based on hybrid FPGAs
are a promising platform for the deployment of such QNNs
as IDS, while also enabling consolidation with standard ECU
function(s), with clear isolation between them on the same
die [18]. However, most methods so far relied on the integra-
tion of multiple accelerators, each fine-tuned to detect a subset
of attacks, increasing the energy cost and area overhead.
In this paper, we explore the case for a custom quantised
feed-forward network that can classify multiple attack vectors
simultaneously and a dataflow-style custom quantised hard-
ware implementation of the model. The dedicated hardware
implements IDS capability as an Advanced eXtensible In-
terface (AXI) slave peripheral to the ARM cores, offering
complete isolation from the software tasks on them, mimicking
the model ECU architecture for deploying distributed IDS in
CAN networks. Starting from a standard multi-layer percep-
tron (MLP) model, we analyse and evaluate different model
configurations and quantisations for weights/biases/activations
to arrive at our custom model with 2-, 3- & 4-bit precisions
through a constrained design space exploration. Subsequently,
the dataflow accelerator is generated and deployed using
AMD/Xilinx’s FINN framework [17]. This integration allows
the software tasks on the ECU to invoke and fully control
the operation of the IDS accelerator through APIs, similar
to offloads enabled by AUTOSAR abstractions. The key
contributions of this paper are as follows:
• A feed-forward custom quantised multi-layer-perceptron
based-IDS for automotive CAN achieving state-of-the-
art classification accuracy across multiple attack vectors
using only a single model.
• Exploits the tightly-coupled ECU architecture with the
dataflow implementation of IDS accelerating IDS opera-
tion in full isolation.
• Quantify the performance and energy savings of the pro-
posed ML model and its integration using the open CAN
dataset. Our results show that the proposed IDS achieves
significant improvements in terms of per-message pro-
cessing latency and power consumption against the state-
of-the-art IDSs in the literature.
We evaluate our approach using the openly available CAR
Hacking dataset [13] for training and validation across multiple
attack vectors captured from an actual vehicle with the entire
CAN data frame used as an input feature to improve the
detection performance. We analyse the 2-, 3- & 4-bit preci-
sion models and utilise the inference accuracy and resource
utilisation parameters to arrive at the most optimal model.
Our experiments show that the proposed custom quantised (2-
bit) MLP-based IDS (referred to as CQMLP-IDS) achieves an
average accuracy of 99.91% across Denial of Service (DoS),
Fuzzing, and RPM-spoofing attacks among the benign flow
of messages, identical to or exceeding the detection accuracy
achieved by state-of-the-art GPU- and CPU-based implemen-
tations. The tightly integrated ECU architecture reduces the per
message execution latency by 2.2× and the energy consumed
by 3.9× compared to state-of-the-art IDSs proposed in the re-
search literature. We also show that our (fp32) MLP model on
a Jetson Nano [19], mimicking a dedicated IDS ECU, incurs
12× higher energy consumption per inference, compared to
the integrated IDS-ECU.
The remainder of the paper is organised as follows: Sec-
tion II captures background information and state-of-the-art
research in this area; section III describes the proposed MLP
model and design choices for the implementation; section IV
outlines the experiment setup and results; and we conclude the
paper in section V.
II. BACKGROUND AND RELATED WORKS
A. Controller Area Network
In-vehicle networks enable distributed ECUs to exchange
control and data messages to achieve the global functions of
the vehicle. Multiple protocols are used in vehicular systems
to cater to different functions based on their criticality and
to optimise the cost of E/E systems. CAN [1] and CAN-
FD [20] continue to be the most widely used protocol to-
day due to their lower cost, flexibility, and robustness. The
broadcast CAN bus uses carrier sense multiple access with
the collision avoidance and arbitration priority (CSMA/CA-
AP) access/arbitration mechanism to control access to the bus
using the CAN ID allocated to each message. This enables
higher priority messages to be processed first hence efficiently
handling messages from safety-critical applications. CAN also
supports multiple data rates (125 Kbps to 1 Mbps) and multiple
modes of operation (1-wire, 2-wire) to cater to a range of
critical and non-critical functions in vehicles. Despite this
robustness, CAN is inherently insecure: there is no built-
in mechanism (like message encryption) in the network to
authenticate the transmitter, receiver, or the message content
itself [21]. This makes CAN vulnerable to simple yet efficient
active message injection attacks like fuzzing, spoofing, replay
attacks, and Denial of Service (DoS) attacks [6], [22]–[24].
Researchers have explored different flavours of IDSs from
rule-based approaches to machine learning-based methods to
address CAN’s existing vulnerabilities. Rule-based approaches
are further classified into flow-based and payload-based. While
flow-based approaches identify traits like message frequency
and/or interval for the network to detect abnormalities [25],
payload-based approaches use the data segment in CAN
frames to detect abnormal sequences of instructions and or
data [26]. Purely payload-based methods, however, fail to
capture the timing/sequence of messages in an attack, lead-
ing to parts of attack messages being flagged as benign.
Hybrid schemes use both the message timing/frequency and
the payload information to capture a more holistic view
of the network, allowing them to extract specific signatures
of transmitting ECUs, receiving ECUs, and messages [27].
Machine learning-based techniques further generalises such
techniques when trained with large datasets through classi-
fication approaches, sequential techniques, and deep learning-
based schemes.
B. Machine Learning based IDSs
ML-based IDSs discussed in the literature mostly use a
combination of input features, as shown in table I. In [13],
the authors propose a reduced inception net architecture as an
TABLE I: Input features used by the IDSs & IPSs proposed
in the research literature.
Models
Input Features Used
GIDS [30]
CAN ID
DCNN [13]
CAN ID
Rec-CNN [38]
CAN ID
G-IDCS [28]
CAN ID
TAN-IDS [29]
CAN ID
iForest [35]
Data Field
MLIDS [36]
CAN ID + Data Field
NovelADS [32]
CAN ID + Data Field
TCAN-IDS [31]
CAN ID + Data Field
MTH-IDS [37]
CAN ID + Data Field
HyDL-IDS [33]
CAN ID + Data Field + DLC
GRU [34]
CAN ID + Data Field + DLC
CQMLP-IDS (proposed)
CAN ID + Data Field
IDS using deep convolutional neural networks. They achieve
over 99% accuracy for DoS, fuzzing & spoofing attacks.
In [28], authors present a graph based intrusion detection
protocol and propose improvements over existing graph based
IDS techniques. In [29], a transformer network-based IDS is
proposed which demonstrates very high classification accuracy
at the cost of higher detection latency. In [30], the authors
propose a GAN-based IDS and achieve an average accuracy
of 97.5% for the same attacks. More complex ML architec-
tures like temporal convolution with global attention [31],
a combination of convolutional neural networks (CNN) and
long short-term memory (LSTM) cells using both supervised
and unsupervised approaches [32], [33], gated recurrent units
(GRU) networks [34] have been shown to improve detection
accuracy. In [35], the authors use an iForest anomaly detection
algorithm as an intrusion prevention system (IPS) to detect
fuzzing and spoofing (RPM & Gear) attacks and mark the
message as an error preventing its propagation to other ECUs;
however, this can cause multiple messages to be dropped from
the bus in case of false positives or DoS attacks. The key
challenge of ML-based approaches is their deployment as an
in-vehicle ECU. Most approaches rely on high-performance
GPUs to meet the inference deadlines [13], [30]–[32], [34],
[36], while others rely on dedicating full ECUs for IDS [35],
[37]; both approaches incur additional overheads in energy
budget and weight, making them less suited for distributing
IDS among different network segments. Similarly, almost all
methods presented in the literature require multiple uniquely
trained models to detect all possible threat vectors, which incur
much higher resources and energy than a singular model which
can classify multiple threat vectors.
III. SYSTEM ARCHITECTURE
A. MLP model for IDS
To determine the best ML model for IDS, we profiled differ-
ent ML architectures to find a model with high classification
accuracy which also offers low computational complexity. We
observed that while CNNs were effective for classification
when using only CAN IDs, MLPs provided more accurate
detection (accuracy, false positives, and false negatives) when
using the entire message contents at much lower computational
complexity; since message data can contain malicious content,
Hidden FC Layers
{256,128,64,32}
(BN+ReLU)
Input Layer-
{40}
Ouptut Linear Layer-{4}
Activation : Softmax
Benign
DoS
Fuzzing
RPM
Spoof
Output
Probabilities
Fig. 2: The proposed MLP model as a multi-attack detection
IDS.
we chose MLPs as our choice of architecture and entire
message as the input feature [39], [40]. A concatenation of
n = 4 successive messages (CAN IDs + payload) is chosen
as the input feature based on this testing. Note that during
training/testing, if the block has even one attack message, the
entire block is treated as an attack block. In a real system, this
means that a window of 4 messages containing a single attack
message will be detected as a malicious window, allowing a
sequence of events leading to and after the attack message as
potential threats. Though conservative, this approach enables
the model to better capture normal operating sequences during
training and provides a better balance to the dataset. We
observed that using a block with a higher number of messages
( > 4 ) improves the classification accuracy as the model has
more input data to make a decision; however, grouping more
messages also affects the detection latency from the arrival of
the ‘infected’ message, leading to our choice of n = 4.
Our final MLP model consists of 5 Linear layers imple-
mented with the 256, 128, 64, 32 & 4 units at each layer
as shown in Figure 2. The time-series data from the input
feature buffer is fed as input to the input layer with 40 units.
Subsequent layer(s) operate on the output of the previous
layer, with increasing complexity to perform classification.
Batch Normalisation was used between the linear layers to
prevent over-fitting and to improve the learning efficiency
during the training phase. The output linear layer uses a
softmax activation at the output to estimate the probability
of the message being benign, DoS, fuzzing, or RPM-spoofed.
The model is defined in Pytorch using standard functions and
nodes with the quantised versions of linear and relu activation
layers imported from the brevitas training library.
B. Design space exploration
To arrive at the optimum bit-precision for the quantised
model, we trained our final MLP model at 2-bit, 3-bit, and
4-bit uniform quantisation on all the attacks to determine the
trade-offs in detection accuracy and resource consumption (in-
directly leading to power consumption and latency). Figures 3
& 4 show the training and validation losses when the model
was trained for 1000 epochs at each quantisation. The 2-bit
model converges to an optimum detection and is very close
to the 3-bit & 4-bit variants (between epoch 810 and 820) in
TABLE II: Inference cost of the custom quantised models
(CQMLP) inferred through the FINN library and normalised
to the 4-bit model.
CQMLP Models
2-bit
3-bit
4-bit
Normalised inference cost
0.27
0.67
1
terms of validation loss. We observed 147 misclassifications
out of the total 180,000 messages in the test set for the 2-bit
variant. For the same test set, we found misclassifications to
be 74 & 31 for the 3-bit & 4-bit variants respectively.
To capture the inference costs of the models further, we
use the FINN utility function (inference cost) to estimate
the memory footprint and operational complexity of each
model. This function captures the memory footprint and binary
operations cost for each version of the model; the costs are
then normalised (against a baseline) and linearly combined to
arrive at the normalised inference cost for each of the three
quantisation levels. Table II shows these costs with the 4-bit
version as the baseline. We find the cost of the 2-bit version is
40% & 27% of the 3-bit & 4-bit version respectively, without
a significant drop in detection accuracy and was hence chosen
as the optimal bitwidth for deploying the CQMLP.
C. Dataset and Training
We use the open Car Hacking dataset for training our model
and to test its performance [41]. The dataset provides a labelled
set of benign and attack messages which were captured via
the Onboard Diagnostic (OBD) port in an actual vehicle, with
attack messages injected in real-time. The dataset includes
DoS, Fuzzing, and RPM-Spoofing message injections allowing
us to validate the detection accuracy across these different
attacks. We split the dataset as 85:10:5 for training, validation,
and testing respectively, allocating the large section to training
and optimisation of the quantised network. The performance
of the model on the validation set during training ensures that
it is not over-fitting on any of the attacks. We pre-process
the dataset before training to mimic the dataflow the model
will obtain as its input when integrated into the ECU. Each
message (ID and payload) is encoded into INT8 type vector,
and an adjacent sequence of n = 4 of these encoded messages
form the input feature buffer content for the IDS (block shape
of {1,10*n} INT8 data).
The different bit models were trained using Brevitas, a
quantisation-aware training (QAT) library from AMD/Xilinx
[42]. We used the adam optimizer with binary cross-entropy as
the loss function. The learning rate was set to 0.0001 to allow
for slower learning which aids in efficient model training [43].
Each model has 54,824 learning parameters and was trained
for 1000 epochs with a batch size of 128 for the DoS, Fuzzing,
and RPM-Spoof attacks. The best model in terms of validation
loss was saved and exported as an ’onnx’ graph. This graph
was then fed into the FINN hardware generation flow for the
CQMLP-IDS IP generation.
0
200
400
600
800
1000
Epochs
0.00
0.01
0.02
0.03
0.04
0.05
Average Epoch loss
4-bit
3-bit
2-bit
Fig. 3: Training loss of the model for different precision of
weights and activations for all the attacks.
0
200
400
600
800
1000
Epochs
0.000
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
Average Validation loss
4-bit
3-bit
2-bit
Fig. 4: Validation loss of the model for different precision of
weights and activations for all the attacks.
D. Dataflow hardware generation and integration to ECU
ECU-IDS
We utilise the FINN compiler to synthesize and generate
the RTL description of the hardware implementation of the
model. Starting at the ’onnx’ graph, FINN applies a series
of streamlining and dataflow transformations to convert the
ML model into a synthesizable graph. We further specify
the parallelism to achieve our target latency (set to 100000
messages per second), matrix-vector activation unit widths (set
to 80), and folding levels to generate the dataflow hardware
with AXI interfaces for input and output. Subsequently, FINN
invokes Vivado tools to stitch the accelerator as an AXI slave
to a Zynq subsystem for our target device (XCZU7EU) and
generates the final bitstream along with the software drivers
for our hardware ML engine. This integration allows us to
model the Zynq-based hybrid ECU architecture, where our
custom hardware is accessible from the ECU and performs
IDS in complete isolation from the tasks on the ARM cores
as shown in Figure 5. We build on the proposed architecture
from our previous works which contain detailed information
of the same [18], [44]. For our experiments, we use the PYNQ
runtime on top of a Linux kernel on the ARM cores to interact
DRAM
AXI Interconnect
Switch
CAN Interface
ARM Cortex-A53 CPU
APU
PS
PL
Incoming CAN
messages
Streaming
FIFO_0
MatrixVector
Activation_0
Custom Quantised IDS accelerator
MatrixVector
Activation_4
Fig. 5: The proposed IDS-ECU architecture. The ML model
is accelerated on the PL part of the FPGA.
with our hardware model on the PL.
IV. EXPERIMENTAL RESULTS
To quantify the performance and energy benefits of a
dedicated dataflow accelerator implementing our CQMLP-IDS
integrated with ECU function(s), we use a Zynq Ultrascale+
ZCU104 development board as the test ECU platform. The
ZCU104 board features an XCZU7EV Ultrascale+ device with
quad-core ARM A53 cores and dual-core ARM R5 cores on
the PS as our target platform. The A53 cores on the PS are
configured to run at 1.2 GHz peak, and the dataflow hardware
was synthesized for a clock frequency of 200 MHz by FINN.
The ARM cores run Linux OS with petalinux tools and PYNQ
runtime to provide APIs to interface to the CQMLP-IDS IP
in the PL. When testing, the hardware CQMLP model is fed
with inputs message from the ECU mimicking the standard
message flow within ECUs, and use our test split from the
Car Hacking dataset to perform inference. We quantify the
inference accuracy by evaluating the precision, recall, and F1
rates of our CQMLP models when inference is performed
on the Zynq-IDS-ECU. We also quantify the per-message
processing latency and power consumption for each incoming
CAN message on the Zynq-IDS-ECU. The results, in terms
of inference accuracy and message processing latency, are
compared against the state-of-the-art IDSs/IPSs presented in
the research literature. We also compare the per-block process-
ing latency and the per-inference energy consumption when
the FP32 version of the proposed model is executed on an
NVIDIA Jetson Nano 4GB GPU. In the case of schemes where
inference is performed on a block of CAN messages, we use
these metrics along with the block size for the comparison.
We also compare our active power consumption against ML-
based IDS approaches in literature where power consumption
has been reported.
A. Inference accuracy
We evaluate the classification performance of the model in
identifying DoS, Fuzzy and RPM-Spoofing attacks from the
Car Hacking dataset and compare them against state-of-the-art
techniques in the literature. Table III captures the classification
TABLE III: Confusion matrix capturing the classification
results of the CQMLP.
Predicted Values
CQMLP
Benign
DoS
Fuzzing
RPM-Spoof
Benign
103142
17
17
0
DoS
27
23666
0
0
Fuzzing
78
0
28003
8
RPM-Spoof
0
0
0
25042
performance of our model in isolation across our test set as a
confusion matrix. The misclassifications in our test set can be
attributed to scenarios where nearly identical attack and benign
message patterns are observed in a block at a given time which
leads to an overall false positive rate (FPR) of 0.03% (34
messages falsely classified as attacks out of the total 103176
benign messages). We compare the inference performance of
our 2-bit CQMLP model integrated within the ECU against
the state-of-the-art IDSs and IPSs proposed in the literature:
GIDS [30], DCNN [13], MLIDS [36], HyDL-IDS [33] Nov-
elADS [32], TCAN-IDS [31], IForest [35], MTH-IDS [37],
GRU [34], G-IDCS [28], TAN-IDS [29] and Rec-CNN [38]
which are captured in table IV, comparing them in terms
of inference precision, recall, F1 score and false negative
rate. For the DoS attack the 2-bit CQMLP performs equally
among the proposed IDSs in terms of F1 score. In the case of
fuzzing attack, the 2-bit CQMLP model performs identically
to DCNN [13] while performing better than iForest [35],
TCAN-IDS [31], and GRU [34] by 2.3%, 0.6% and 0.6%
respectively in terms of F1 score. The 2-bit CQMLP also
achieves almost perfect classification for the RPM-spoofing
attack and performs better than or equal to the other methods
proposed in the literature. Our prior work using two 8-bit
variants of the feed-forward model achieved 99.96%, 99.76%
& 100% F1 scores for the DoS, Fuzzing, and RPM spoofing
attacks, when deployed as two concurrent accelerators for
detecting them simultaneously [18]. In contrast, our 2-bit
CQMLP variant achieves almost identical F1 scores (99.90%,
99.81% & 99.98% respectively) for the same attacks (from
the same dataset) while performing multi-class classification
using a single inference model. By adopting QAT training and
conservative block-based labelling, our low precision model is
able to match the inference performance of the MLP variant
at 8-bit quantisation discussed in [18].
B. Inference latency
We quantify the per-message processing latency of the
model, starting from the arrival of the CAN message at the
interface to determine the detection delay incurred by the ap-
proach. Table V compares our result against other approaches
in the literature, which utilise different platforms (GPUs,
Jetson edge accelerators, Raspberry Pi) and approaches (block
of CAN messages v/s individual messages). It should be noted
that the latency metric in the case of block-based IDS does not
consider the delay in acquiring the number of CAN messages
required, and hence could result in potentially larger delays
in detection of the onset of an attack. The tightly integrated
CQMLP-IDS achieves 0.11 ms per CAN frame, which is a
TABLE IV: Accuracy metric comparison (%) of our CQMLP
accelerators against the reported literature on the DoS, Fuzzing
and RPM-Spoof attacks.
Attack
Model
Precision
Recall
F1
FNR
DoS
GIDS [30]
-
99.9
-
-
DCNN [13]
100
99.89
99.95
0.13
MLIDS [36]
99.9
100
99.9
-
G-IDCS [28]
99.81
98.86
99.33
-
TAN-IDS [29]
100
100
100
-
HyDL-IDS [33]
100
100
100
0
NovelADS [32]
99.97
99.91
99.94
-
TCAN-IDS [31]
100
99.97
99.98
-
iForest [35]
-
-
-
-
GRU [34]
99.93
99.91
99.92
-
CQMLP-IDS
99.92
99.88
99.90
0.11
Fuzzing
GIDS [30]
-
98.7
-
-
DCNN [13]
99.95
99.65
99.80
0.5
MLIDS [36]
99.9
99.9
99.9
-
G-IDCS [28]
99.71
99
99.35
-
TAN-IDS [29]
99.99
99.99
99.99
-
HyDL-IDS [33]
99.98
99.88
99.93
NovelADS [32]
99.99
100
100
-
TCAN-IDS [31]
99.96
99.89
99.22
-
iForest [35]
95.07
99.93
97.44
-
GRU [34]
99.32
99.13
99.22
-
CQMLP-IDS
99.93
99.69
99.81
0.27
RPM-Spoof
GIDS [30]
-
99.6
-
-
DCNN [13]
99.99
99.94
99.96
0.05
MLIDS [36]
100
100
100
-
G-IDCS [28]
99.85
98.69
99.27
-
TAN-IDS [29]
99.99
99.93
99.96
-
HyDL-IDS [33]
100
100
100
0
NovelADS [32]
99.9
99.9
99.9
-
TCAN-IDS [31]
99.9
99.9
99.9
-
iForest [35]
98.9
100
99.4
-
CQMLP-IDS
99.96
100
99.98
0
TABLE V: Per-message latency comparison against other
state-of-the-art IDSs reported in literature.
Models
Latency
Frames
Platform
GRU [34]
890 ms
5000 CAN frames
Jetson Xavier NX
MLIDS [36]
275 ms
per CAN frame
GTX Titan X
Rec-CNN [38]
117 ms
128 CAN frames
Jetson TX2
NovelADS [32]
128.7 ms
100 CAN frames
Jetson Nano
GIDS [30]
5.89 ms
64 CAN frames
GTX 1080
TAN-IDS [29]
11.6 ms
128 CAN frames
-
DCNN [13]
5 ms
29 CAN frames
Tesla K80
TCAN-IDS [31]
3.4 ms
64 CAN frames
Jetson AGX
MTH-IDS [37]
0.574 ms
per CAN frame
Raspberry Pi 3
QMLP-IDS [18]
0.24 ms
per CAN frame
Zynq Ultrascale+
CQMLP-IDS
0.11 ms
per CAN frame
Zynq Ultrascale+
2.18× improvement over the dedicated line-rate QMLP-IDS
ECU proposed in [18]. We also observe the inference latency
of the (fp32) model on the Jetson Nano (modeling a dedicated
IDS ECU) to be 1.2 ms when averaged over 10000 runs.
This is 10.9× slower than the proposed CQMLP-IDS on the
integrated IDS-ECU on the Zynq Ultrascale platform. In terms
of raw throughput, our dataflow implementation of CQMLP
coupled to the ECU can process over 9090 messages per
second at the highest payload capacity, achieving near-line-
rate detection on high-speed critical CAN networks.
TABLE VI: Resource utilisation breakdown of our proposed
CQMLP (XCZU7EV).
Node
LUT
FF
BRAM/URAM
DSP
2-bit-CQMLP-IDS
3999
4524
4/0
0
% Usage
1.74%
0.98%
1.28%/ 0%
0%
C. Power consumption, Resource Utilisation (PS/PL)
We further quantify the active power consumption of our
dataflow accelerator to determine the average energy consump-
tion per inference and the hardware resources incurred by the
dataflow design on the XCZU7EV device. We observe that
our model consumed 2.15 W when measured directly from the
device’s power rails (using the PYNQ-PMBus package) while
performing inference and other tasks on the ECU (with Linux
OS), thus consuming 0.23 mJ of energy per inference. This is
a 3.9× improvement compared to QMLP-IDS which report a
per-inference energy consumption of 0.9 mJ. In comparison,
we also observed the per-inference energy consumption of
our (fp32) CAE model on the Jetson Nano to be 2.76 mJ
when averaged over 10000 inference runs which is 12× more
than the proposed CQMLP-IDS on the tightly integrated IDS-
ECU on a hybrid FPGA device. Among other reported results
in the literature, our approach improves the active power
consumption by 4.6× when compared to the GRU [34] model
on an Nvidia Jetson Xavier as a dedicated IDS node. In
terms of resources, the dataflow CQMLP model consumes
less than 2% of resources on the device, leaving behind
enough resources to integrate dedicated accelerators for the
ECU function.
We also quantify the utilisation of the ARM cores for
managing the dataflow CQMLP accelerator to estimate the
overhead in consolidating the IDS capability on the ECU. It
was observed that a single core utilisation peaked at 40% when
processing the completion interrupt from the IDS core (at
the highest message rate modelling the worst case scenario),
while other cores remained at IDLE (≤ 2% utilisation). We
believe that this could be further refined by processing the
classification results using hardware logic, interrupting the
ECU only when a threat is detected, while also improving
the detection latency.
V. CONCLUSION
In this paper, we present a dataflow-style hardware accelera-
tor that implements a custom quantised MLP (CQMLP) model
for detecting and classifying multiple attack vectors on an
automotive CAN network. The accelerator generated through
the FINN flow is quantised to 2-bit precision for weights and
activations and is tightly integrated to the ARM core on a
Zynq Ultrascale+ platform, mimicking a standard ECU. We
show that the dataflow integration achieves a 2.2× speed-up
in per-message processing latency and almost 3.9× reduction
in energy consumption with 0.23mJ per inference when com-
pared to the state-of-the-art IDSs. The quantised model also
maintains high detection and classification accuracy across a
range of attacks including DoS, fuzzing, and RPM-Spoofing
attacks, making it an ideal approach for distributing IDS
capabilities across ECUs in a vehicle network.
REFERENCES
[1] R. B. GmbH, “CAN Specification, Version 2.0,” 1991.
[2] S. Nie, L. Liu, and Y. Du, “Free-fall: Hacking Tesla from wireless to
CAN bus,” Briefing, Black Hat USA, vol. 25, pp. 1–16, 2017.
[3] K. Iehira, H. Inoue, and K. Ishida, “Spoofing attack using bus-off attacks
against a specific ECU of the CAN bus,” in Proc. IEEE Communications
& Networking Conference (CCNC), pp. 1–4, IEEE, 2018.
[4] Z. Cai, A. Wang, W. Zhang, M. Gruffke, and H. Schweppe, “0-days
& mitigations: Roadways to exploit and secure connected BMW cars,”
Black Hat USA, vol. 2019, p. 39, 2019.
[5] C. Miller and C. Valasek, “Remote exploitation of an unaltered passenger
vehicle,” Black Hat USA, vol. 2015, no. S 91, 2015.
[6] M. Enev, A. Takakuwa, K. Koscher, and T. Kohno, “Automobile Driver
Fingerprinting.,” Proc. Priv. Enhancing Technol., vol. 2016, no. 1,
pp. 34–50, 2016.
[7] U. E. Larson, D. K. Nilsson, and E. Jonsson, “An approach to
specification-based attack detection for in-vehicle networks,” in Proc.
IEEE Intelligent Vehicles Symposium, pp. 220–225, 2008.
[8] C. Miller and C. Valasek, “Adventures in automotive networks and
control units,” Def Con, vol. 21, no. 260-264, pp. 15–31, 2013.
[9] I. Studnia, E. Alata, V. Nicomette, M. Kaˆaniche, and Y. Laarouchi, “A
language-based intrusion detection approach for automotive embedded
networks,” International Journal of Embedded Systems, vol. 10, 2018.
[10] S. N. Narayanan, S. Mittal, and A. Joshi, “Using data analytics to detect
anomalous states in vehicles,” arXiv preprint arXiv:1512.08048, 2015.
[11] A. Alshammari, M. A. Zohdy, D. Debnath, and G. Corser, “Classifi-
cation approach for intrusion detection in vehicle systems,” Wireless
Engineering and Technology, vol. 9, no. 4, pp. 79–94, 2018.
[12] L. Yang, A. Moubayed, I. Hamieh, and A. Shami, “Tree-based intelligent
intrusion detection system in internet of vehicles,” in 2019 IEEE global
communications conference (GLOBECOM), pp. 1–6, IEEE, 2019.
[13] H. M. Song, J. Woo, and H. K. Kim, “In-vehicle network intrusion
detection using deep convolutional neural network,” Vehicular Commu-
nications, vol. 21, p. 100198, 2020.
[14] S. Tariq, S. Lee, and S. S. Woo, “CANTransfer: transfer learning based
intrusion detection on a controller area network using convolutional
LSTM network,” in Proceedings of the 35th Annual ACM Symposium
on Applied Computing, pp. 1048–1055, 2020.
[15] P. Jokic, S. Emery, and L. Benini, “Binaryeye: A 20 kfps streaming cam-
era system on FPGA with real-time on-device image recognition using
binary neural networks,” in 2018 IEEE 13th International Symposium
on Industrial Embedded Systems (SIES), pp. 1–7, IEEE, 2018.
[16] Xilinx, “Vitis AI User Guide,” 2021.
[17] Y. Umuroglu, N. J. Fraser, G. Gambardella, M. Blott, P. Leong, M. Jahre,
and K. Vissers, “Finn: A framework for fast, scalable binarized neural
network inference,” in Proc. Intl. Symposium on Field-Programmable
Gate Arrays (FPGA), pp. 65–74, 2017.
[18] S. Khandelwal and S. Shreejith, “A Lightweight FPGA-based IDS-ECU
Architecture for Automotive CAN,” in 2022 International Conference
on Field-Programmable Technology (ICFPT), pp. 1–9, IEEE, 2022.
[19] NVIDIA, “https://developer.nvidia.com/embedded/jetson-nano.”
[20] F. Hartwich et al., “CAN with flexible data-rate,” in Proc. iCC, pp. 1–9,
Citeseer, 2012.
[21] M. Bozdal, M. Samie, and I. Jennions, “A Survey on CAN Bus Protocol:
Attacks, Challenges, and Potential Solutions,” in Proc. Intl. Conf.
on Computing, Electronics Communications Engineering (iCCECE),
pp. 201–205, 2018.
[22] S. Mukherjee, H. Shirazi, I. Ray, J. Daily, and R. Gamble, “Practical
DoS attacks on embedded networks in commercial vehicles,” in Proc.
Intl Conference on Information Systems Security, Springer, 2016.
[23] K. Koscher, S. Savage, F. Roesner, S. Patel, T. Kohno, A. Czeskis,
D. McCoy, B. Kantor, D. Anderson, H. Shacham, et al., “Experimental
security analysis of a modern automobile,” in Proc. IEEE Sym. on
Security and Privacy, pp. 447–462, IEEE Computer Society, 2010.
[24] A. Palanca, E. Evenchick, F. Maggi, and S. Zanero, “A stealth, selective,
link-layer denial-of-service attack against automotive networks,” in Proc.
Intl. Conf. on Detection of Intrusions and Malware, and Vulnerability
Assessment, pp. 185–206, Springer, 2017.
[25] T. P. Vuong, G. Loukas, and D. Gan, “Performance evaluation of
cyber-physical intrusion detection on a robotic vehicle,” in Proc. Intl.
Conf. on Computer and Information Technology; Ubiquitous Computing
and Communications; Dependable, Autonomic and Secure Computing;
Pervasive Intelligence and Computing, pp. 2106–2113, IEEE, 2015.
[26] D. Stabili, M. Marchetti, and M. Colajanni, “Detecting attacks to internal
vehicle networks through hamming distance,” in AEIT Intl. Annual
Conference, pp. 1–6, IEEE, 2017.
[27] M. Weber, S. Klug, E. Sax, and B. Zimmer, “Embedded hybrid anomaly
detection for automotive CAN communication,” in Proc. European
Congress on Embedded Real Time Software and Systems (ERTS), 2018.
[28] S. B. Park, H. J. Jo, and D. H. Lee, “G-IDCS: Graph-Based Intrusion
Detection and Classification System for CAN Protocol,” IEEE Access,
vol. 11, pp. 39213–39227, 2023.
[29] T. P. Nguyen, H. Nam, and D. Kim, “Transformer-Based Attention
Network for In-Vehicle Intrusion Detection,” IEEE Access, vol. 11,
pp. 55389–55403, 2023.
[30] E. Seo, H. M. Song, and H. K. Kim, “GIDS: GAN based intrusion
detection system for in-vehicle network,” in Proc. Conf. on Privacy,
Security and Trust (PST), pp. 1–6, IEEE, 2018.
[31] P. Cheng, K. Xu, S. Li, and M. Han, “TCAN-IDS: Intrusion Detection
System for Internet of Vehicle Using Temporal Convolutional Attention
Network,” Symmetry, vol. 14, no. 2, p. 310, 2022.
[32] K. Agrawal, T. Alladi, A. Agrawal, V. Chamola, and A. Benslimane,
“NovelADS: A Novel Anomaly Detection System for Intra-Vehicular
Networks,” IEEE Transactions on Intelligent Transportation Systems,
2022.
[33] W. Lo, H. Alqahtani, K. Thakur, A. Almadhor, S. Chander, and G. Ku-
mar, “A hybrid deep learning based intrusion detection system using
spatial-temporal representation of in-vehicle network traffic,” Vehicular
Communications, vol. 35, p. 100471, 2022.
[34] H. Ma, J. Cao, B. Mi, D. Huang, Y. Liu, and S. Li, “A GRU-
Based Lightweight System for CAN Intrusion Detection in Real Time,”
Security and Communication Networks, vol. 2022, 2022.
[35] P. F. De Araujo-Filho, A. J. Pinheiro, G. Kaddoum, D. R. Campelo,
and F. L. Soares, “An Efficient Intrusion Prevention System for CAN:
Hindering Cyber-Attacks with a Low-Cost Platform,” IEEE Access,
vol. 9, pp. 166855–166869, 2021.
[36] A. K. Desta, S. Ohira, I. Arai, and K. Fujikawa, “MLIDS: Handling
Raw High-Dimensional CAN Bus Data Using Long Short-Term Memory
Networks for Intrusion Detection in In-Vehicle Networks,” in Proc. Intl.
Telecommunication Networks and Applications Conference (ITNAC),
pp. 1–7, IEEE, 2020.
[37] L. Yang, A. Moubayed, and A. Shami, “MTH-IDS: A Multitiered Hybrid
Intrusion Detection System for Internet of Vehicles,” IEEE Internet of
Things Journal, vol. 9, no. 1, pp. 616–632, 2021.
[38] A. K. Desta, S. Ohira, I. Arai, and K. Fujikawa, “Rec-CNN: In-vehicle
networks intrusion detection using convolutional neural networks trained
on recurrence plots,” Vehicular Communications, vol. 35, p. 100470,
2022.
[39] S. Khandelwal, E. Wadhwa, and S. Shreejith, “Deep Learning-based
Embedded Intrusion Detection System for Automotive CAN,” in 2022
IEEE 33rd International Conference on Application-specific Systems,
Architectures and Processors (ASAP), pp. 88–92, 2022.
[40] S. Khandelwal and S. Shreejith, “A Lightweight Multi-Attack CAN
Intrusion Detection System on Hybrid FPGAs,” in 2022 32nd Inter-
national Conference on Field-Programmable Logic and Applications
(FPL), pp. 425–429, 2022.
[41] CAR
Hacking
Dataset,
“https://ocslab.hksecurity.net/datasets/can-
intrusion-dataset,” 2020.
[42] A. Pappalardo, “Xilinx/brevitas,” 2021.
[43] S. Wu, G. Li, F. Chen, and L. Shi, “Training and inference with integers
in deep neural networks,” arXiv preprint arXiv:1802.04680, 2018.
[44] S. Khandelwal, A. Walsh, and S. Shreejith, “Quantised Neural Network
Accelerators for Low-Power IDS in Automotive Networks,” in 2023
Design, Automation & Test in Europe Conference & Exhibition (DATE),
pp. 1–2, IEEE, 2023.
"
"We present five optimizations for a matrix-based CFL-r algorithm that utilize the specific properties of both the underlying semiring and the widely-used linear algebra library SuiteSparse:GraphBlas. Our experimental results show that these optimizations result in orders of magnitude speedup, with the optimized matrix-based CFL-r algorithm consistently outperforming state-of-the-art CFL-r solvers across four considered static analyses.nan","Context-Free Language Reachability (CFL-r) is a core building block for a wide range of static analyses. The problem asks to find pairs of vertices in an edge-labeled graph that are connected by a path labeled with a word from a Context-Free Language (CFL). While CFL-r is often solved by standard graph reachability algorithms, one promising line of research is to instead formulate CFL-r as a matrix-based operation on sparse matrices, as these operations can be efficiently executed on modern hardware.nan","nanAzimov et al. [2] proposed a context-free path querying algorithm by matrix multiplication that oftentimes surpasses analogous in terms of performance. However, it takes a considerable amount of time to deal with paths with deep derivation trees and large CFGs of field- and context-sensitive analyses. Extensive research has been conducted to develop general-purpose CFL-r algorithms. POCR [6], Gigascale [4], and Graspan [16] represent three such tools.nan",We propose a set of optimizations for the matrix-based CFL-r algorithm that significantly improve its performance on large-scale CFL-r instances:nan,"Our experiments show that the proposed optimizations result in orders of magnitude speedup, with the optimized matrix-based CFL-r algorithm consistently outperforming state-of-the-art CFL-r solvers across four considered static analyses: Field-Sensitive Java Points-To (FSJPT), Field-Insensitive C/C++ Alias (FICA), Field-Sensitive C/C++ Alias (FSCA), and Context-Sensitive C/C++ Value-Flow (CSCVF).nan","We have presented a set of optimizations that significantly improve the performance of the matrix-based CFL-r algorithm, making it a competitive choice for solving large-scale CFL-r instances. Our future work includes complexity analysis as well as generalization of proposed optimizations for other algorithms.nan",Optimization of the Context-Free Language Reachability Matrix-Based Algorithm,Ilia Muravev,"Optimization of the Context-Free Language Reachability
Matrix-Based Algorithm
ILIA MURAVEV, Saint Petersburg State University, Russia
Various static analysis problems are reformulated as instances of the Context-Free Language Reachability
(CFL-r) problem. One promising way to make solving CFL-r more practical for large-scale interprocedural
graphs is to reduce CFL-r to linear algebra operations on sparse matrices, as they are efficiently executed
on modern hardware. In this work, we present five optimizations for a matrix-based CFL-r algorithm that
utilize the specific properties of both the underlying semiring and the widely-used linear algebra library
SuiteSparse:GraphBlas. Our experimental results show that these optimizations result in orders of magnitude
speedup, with the optimized matrix-based CFL-r algorithm consistently outperforming state-of-the-art CFL-r
solvers across four considered static analyses.
CCS Concepts: • Theory of computation → Grammars and context-free languages; • Information
systems → Query languages for non-relational engines; • Computing methodologies → Massively
parallel algorithms; • Software and its engineering → Automated static analysis.
Additional Key Words and Phrases: Context-free language reachability, GraphBLAS
1
INTRODUCTION
Context-Free Language Reachability (CFL-r) is the problem of finding pairs of vertices in an edge-
labeled graph that are connected by a path, with the condition that the labels along this path spell
a word from a Context-Free Language (CFL) defined by a given Context-Free Grammar (CFG). A
wide range of problems is reduced to CFL-r, including, among others, alias analysis [18], points-to
analysis [4], value-flow analysis [13], and fixing compilation errors [17]. Furthermore, CFL-r is also
used to approximate solutions for some undecidable problems, for example, points-to analysis that
is simultaneously context-, field-, and flow-sensitive [9, 12].
Since Thomas Reps et al. [10] proposed using CFL-r for precise interprocedural dataflow analysis,
numerous CFL-r algorithms have been developed [2, 6–8]. One of the promising general-purpose
CFL-r algorithms is a matrix-based algorithm by Rustam Azimov et al. [2]. This algorithm naturally
utilizes parallel hardware and oftentimes surpasses analogous in terms of performance [1]. However,
it still takes a considerable amount of time to deal with paths with deep derivation trees and large
CFGs of field- and context-sensitive analyses. In this work, we propose a set of optimizations that
improve performance of the matrix-based algorithm in such cases. Our evaluation demonstrates
that the optimized version outperforms such tools as POCR [6], Gigascale [4], and Graspan [16].
2
PRELIMINARIES
Definition 2.1 (Weak Chomsky Normal Form (WCNF)). Let 𝐺𝑟 = (𝑁, Σ, 𝑃,𝑆) be a CFG, where 𝑁
is a set of non-terminals, Σ is a set of terminals, 𝑃 is a set of productions, and 𝑆 is the starting
non-terminal.𝐺𝑟 is said to be in WCNF if 𝑃 ⊆ {𝑎 → 𝑏 | 𝑎 ∈ 𝑁,𝑏 ∈ Σ∪{𝜀}}∪{𝑐 → 𝑎 𝑏 | 𝑎,𝑏,𝑐 ∈ 𝑁 }.
Definition 2.2 (Reachability Semiring of CFG). Let 𝐺𝑟 = (𝑁, Σ, 𝑃,𝑆) be a CFG in WCNF. In this
paper, 𝑅𝐺𝑟 = (2𝑁, ∪, ⊗𝐺𝑟, ∅) is called a reachability semiring1 of 𝐺𝑟, where 2𝑁 is the domain, ∪ acts
as addition, ⊗𝐺𝑟 acts as multiplication, and 𝐴 ⊗𝐺𝑟 𝐵 = {𝑐 ∈ 𝑁 | ∃(𝑎,𝑏) ∈ 𝐴 × 𝐵 ((𝑐 → 𝑎 𝑏) ∈ 𝑃)}.
1𝑅𝐺𝑟 is a semiring according to GraphBlas [3], but not according to the common algebraic definition of a semiring.
Research advisor: Semyon Grigorev, s.v.grigoriev@spbu.ru.
Author’s address: Ilia Muravev, muravjovilya@gmail.com, Saint Petersburg State University, 7/9 University Embankment,
St. Petersburg, Russia, 199034.
arXiv:2401.11029v1  [cs.PL]  19 Jan 2024
2
Ilia Muravev
Algorithm 1: Original Matrix-Based CFL-r Algorithm as Introduced in [2]
Data: CFG 𝐺𝑟 = (𝑁, Σ, 𝑃,𝑆), graph 𝐺 = (𝑉, 𝐸), where 𝑉 = 1..𝑛 are vertices and 𝐸 are edges
Result: Matrix 𝑀 ∈ 𝑅|𝑉 |×|𝑉 |
𝐺𝑟
, where 𝑀𝑖𝑗 = {𝑥 ∈ 𝑁 | ∃ path from 𝑖 to 𝑗 derivable from 𝑥}
1 𝐺𝑟 ← CFG in WCNF equivalent to CFG 𝐺𝑟;
2 𝑀 ← zero |𝑉 | × |𝑉 | matrix over 𝑅𝐺𝑟;
// Stored as |𝑁 | Boolean matrices
3 foreach (𝑖,𝑥, 𝑗) ∈ 𝐸 do
4
𝑀𝑖𝑗 ← 𝑀𝑖𝑗 ∪ {𝐴 | (𝐴 → 𝑥) ∈ 𝑃};
5 end
6 while 𝑀 is changing do
7
𝑀 ← 𝑀 ∪ (𝑀 ·𝑅𝐺𝑟 𝑀);
// ·𝑅𝐺𝑟 is a matrix multiplication in semiring 𝑅𝐺𝑟
8 end
3
OPTIMIZATIONS
Following optimizations have been proposed, implemented, and evaluated.
(1) The bottleneck in Algorithm 1 is at ·𝑅𝐺𝑟 on line 7. To address this, 𝑀 ·𝑅𝐺𝑟 𝑀 is replaced with
(𝑀𝑜𝑙𝑑 ·𝑅𝐺𝑟 Δ𝑀) ∪ (Δ𝑀 ·𝑅𝐺𝑟 𝑀), where Δ𝑀 = 𝑀 \ 𝑀𝑜𝑙𝑑 (element-wise set difference) and
𝑀𝑜𝑙𝑑 is the value of the variable 𝑀 during the previous iteration of the while loop. Initially,
𝑀𝑜𝑙𝑑 = ∅|𝑉 |×|𝑉 |. The rationale here is that (𝑀𝑜𝑙𝑑 ·𝑅𝐺𝑟 Δ𝑀)∪(Δ𝑀 ·𝑅𝐺𝑟 𝑀)∪(𝑀𝑜𝑙𝑑 ·𝑅𝐺𝑟 𝑀𝑜𝑙𝑑) =
𝑀 ·𝑅𝐺𝑟 𝑀 and 𝑀𝑜𝑙𝑑 ·𝑅𝐺𝑟 𝑀𝑜𝑙𝑑 has already been added to 𝑀 on the previous iteration.
(2) Now, during most iterations, Δ𝑀 is highly sparse, while 𝑀𝑜𝑙𝑑 and 𝑀 are less sparse. The
multiplication of a highly sparse matrix with a less sparse one is considerably faster in
row-major format when the sparser matrix is on the left and in column-major format when
the sparser matrix is on the right [3]. Therefore, the next optimization involves maintaining
two copies of 𝑀 in both row- and column-major formats and computing 𝑀𝑜𝑙𝑑 ·𝑅𝐺𝑟 Δ𝑀 and
Δ𝑀 ·𝑅𝐺𝑟 𝑀 using column-by-column and row-by-row (hyper)sparse matrix multiplication
techniques, respectively [5]. In practice, non-terminals that don’t occur in place of 𝑎 in
productions like 𝑐 → 𝑎 𝑏 don’t need to be stored in the column-major copy of 𝑀, and those
that don’t occur in place of 𝑏 don’t need to be stored in the row-major copy of 𝑀.
(3) The next bottleneck is the element-wise union on line 7, which becomes problematic as
adding a highly sparse matrix to 𝑀 causes a complete reconstruction of 𝑀. To cope with this,
𝑀 is no longer stored as a matrix. Instead, we now use a set of matrices e
𝑀 = {𝑀1, 𝑀2, . . . , 𝑀𝑝}
such that 𝑀 = Ð e
𝑀, ∀𝐴, 𝐵 ∈ e
𝑀 (𝑛𝑛𝑧(𝐴) < 𝑛𝑛𝑧(𝐵) =⇒ 𝑏 𝑛𝑛𝑧(𝐴) < 𝑛𝑛𝑧(𝐵)), where 𝑏 > 1
is a hyperparameter and 𝑛𝑛𝑧(𝑋) is the number of non-zero elements in matrix 𝑋. The
element-wise union on line 7 is computed by adding Δ𝑀 to e
𝑀 as a set element and replacing
e
𝑀 with e
𝑀 \ {𝐴, 𝐵} ∪ {𝐴 ∪ 𝐵} as long as there are 𝐴, 𝐵 ∈ e
𝑀 that violate e
𝑀’s invariants.
(4) For CFGs with a large number of productions (|𝑃|), the bottleneck is once again ·𝑅𝐺𝑟 ,
requiring |𝑃| Boolean matrix multiplications [15]. Fortunately, such CFGs often use “indexed”
non-terminals (see examples in appendix B). We exploit this by storing only two Boolean
block-matrices (horizontal and vertical) per entire “indexed” non-terminal, reducing the
number of Boolean matrix multiplications needed for ·𝑅𝐺𝑟 to the number of productions
differing not only in indices. For example, ∀𝑖 (𝐴𝑅𝑖 → 𝐴 𝑟𝑒𝑡𝑖) now counts as one production.
(5) Finally, profiling has revealed equivalent transformations of CFGs for field-sensitive Java
points-to [4] and field-insensitive C/C++ memory-alias2 [18] analyses that improve perfor-
mance (see appendix B).
2Transformed CFG for C/C++ memory-alias analysis is no longer usable for C/C++ value-alias analysis.
Optimization of the Context-Free Language Reachability Matrix-Based Algorithm
3
Table 1. All-Pairs CFL-r Run Time in Seconds
Problem
Graph
𝑚𝑎
𝑚𝑎1
𝑚𝑎14
𝑚𝑎1234
𝑚𝑎12345
POCR
Graspan
Gigascale
FSJPT
tradebeans
OOT
5075
51
20
1.3
395
-
5.1
tradesoap
OOT
5284
52
20
1.5
400
-
4.5
FICA
apache
999
139
139
88
19
OOM
2619
-
postgre
1365
186
186
109
30
OOM
1712
-
FSCA
imagick
2279
372
214
137
137
1538
-
-
perlbench
4544
1721
1321
1675
1675
OOT
-
-
CSCVF
povray
OOT
1057
21.7
10
10
28
-
-
perlbench
OOT
OOT
195
41
41
OOM
-
-
4
EVALUATION
All experiments were run on a PC with an Intel Core i7-6700 CPU (3.4 GHz, 4 threads, hyper-
threading is turned off), and DDR4 64GB RAM, running Ubuntu 20.04 with SuiteSparse:GraphBLAS
7.4.4 and Java HotSpot(TM) 64-Bit Server VM (build 15.0.2+7-27, mixed mode, sharing) installed.
Proposed variants of Algorithm 1 were implemented3 and compared with state-of-the-art CFL-r
implementations: POCR4 [6] and Graspan5 [16], as well as with the field-sensitive Java points-to
analyzer Gigascale6 [4] on graphs from the CFPQ Data7 and CPU178 data sets and their corre-
sponding canonical CFGs (see appendix B). Algorithm 1 with optimizations 𝑎,𝑏, . . . ,𝑐 is denoted by
𝑚𝑎𝑎𝑏...𝑐. For example, 𝑚𝑎12345 means algorithm 1 with all proposed optimizations.
The following analyses are considered: Field-Sensitive Java Points-To (FSJPT) [4], Field-Insensitive
C/C++ Alias (FICA) [18], Field-Sensitive C/C++ Alias (FSCA) [18], and Context-Sensitive C/C++
Value-Flow (CSCVF) [13]. To show the worst-case performance of proposed optimizations, for each
analysis, two graphs that took𝑚𝑎12345 the longest time to analyze were selected. For selected graphs,
the mean run time over five runs is displayed in Table 1. In all cases, the unbiased standard deviation
estimate is less than 10% of the mean. OOT (Out of Time) means exceeding the 10,000-second
timeout, OOM (Out of Memory) refers to running out of available memory, and a dash “-” indicates
that a particular implementation is not applicable to a problem9. For selected graphs, proposed
optimizations preserved the correctness of the answers and increased RAM consumption by at
most 70% compared to the baseline (see appendix A).
5
CONCLUSION AND FUTURE WORK
The optimized version of the matrix-based CFL-r algorithm was shown to outperform analogous
across a range of considered problems. Building on this success, future work is expected to include
complexity analysis as well as generalization of proposed optimizations for other algorithms10.
3Implementations of matrix-based algorithm variants — https://github.com/FormalLanguageConstrainedPathQuerying/
CFPQ_PyAlgo/tree/murav/optimize-matrix (date of access: 06.11.2023), for optimization (3) hyperparameter 𝑏 = 10 is used.
4POCR — https://github.com/kisslune/POCR (date of access: 06.11.2023).
5Graspan — https://github.com/Graspan/Graspan-C (date of access: 06.11.2023).
6Gigascale — https://bitbucket.org/jensdietrich/gigascale-pointsto-oopsla2015/src/master/ (date of access: 06.11.2023).
7CFPQ Data — https://formallanguageconstrainedpathquerying.github.io/CFPQ_Data (date of access: 06.11.2023).
8CPU17 (graphs for SPEC 2017 C/C++ programs) — https://github.com/kisslune/CPU17-graphs (date of access: 06.11.2023).
Graphs from the “simplified-interdyck” folders are used, as done in POCR [6]. Our evaluation excludes the time taken to
construct SVFG and PEG graphs, eliminate cycles [14], and substitute variables [11], since it remains the same regardless of
the CFL-r implementation.
9Gigascale is not a general CFL-r solver and only solves FSJPT, while Graspan encodes each non-terminal using a single
byte and hence can’t handle arbitrarily large CFGs for field- and context-sensitive analyses.
10All proposed optimizations can already be transferred to single-path semantics of CFL-r by merely changing the semiring.
4
Ilia Muravev
REFERENCES
[1] Rustam Azimov. 2022. Context-Free Path Querying Using Linear Algebra. Ph. D. Dissertation. St. Petersburg State
University. https://disser.spbu.ru/files/2022/disser_azimov.pdf
[2] Rustam Azimov and Semyon Grigorev. 2018. Context-Free Path Querying by Matrix Multiplication. In Proceedings
of the 1st ACM SIGMOD Joint International Workshop on Graph Data Management Experiences & Systems (GRADES)
and Network Data Analytics (NDA) (Houston, Texas) (GRADES-NDA ’18). Association for Computing Machinery, New
York, NY, USA, Article 5, 10 pages. https://doi.org/10.1145/3210259.3210264
[3] Timothy A. Davis. 2023. Algorithm 1037: SuiteSparse:GraphBLAS: Parallel Graph Algorithms in the Language of
Sparse Linear Algebra. ACM Trans. Math. Softw. 49, 3, Article 28 (sep 2023), 30 pages. https://doi.org/10.1145/3577195
[4] Jens Dietrich, Nicholas Hollingum, and Bernhard Scholz. 2015. Giga-Scale Exhaustive Points-to Analysis for Java in
under a Minute. In Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming,
Systems, Languages, and Applications (Pittsburgh, PA, USA) (OOPSLA 2015). Association for Computing Machinery,
New York, NY, USA, 535–551. https://doi.org/10.1145/2814270.2814307
[5] Jianhua Gao, Weixing Ji, Fangli Chang, Shiyu Han, Bingxin Wei, Zeming Liu, and Yizhuo Wang. 2023. A Systematic
Survey of General Sparse Matrix-Matrix Multiplication. ACM Comput. Surv. 55, 12, Article 244 (mar 2023), 36 pages.
https://doi.org/10.1145/3571157
[6] Yuxiang Lei, Yulei Sui, Shuo Ding, and Qirun Zhang. 2022. Taming Transitive Redundancy for Context-Free Language
Reachability. Proc. ACM Program. Lang. 6, OOPSLA2, Article 180 (oct 2022), 27 pages. https://doi.org/10.1145/3563343
[7] Ciro M. Medeiros, Martin A. Musicante, and Umberto S. Costa. 2018. Efficient Evaluation of Context-Free Path Queries
for Graph Databases. In Proceedings of the 33rd Annual ACM Symposium on Applied Computing (Pau, France) (SAC ’18).
Association for Computing Machinery, New York, NY, USA, 1230–1237. https://doi.org/10.1145/3167132.3167265
[8] Egor Orachev, Ilya Epelbaum, Rustam Azimov, and Semyon Grigorev. 2020. Context-Free Path Querying by Kronecker
Product. Springer-Verlag, Berlin, Heidelberg, 49–59. https://doi.org/10.1007/978-3-030-54832-2_6
[9] Thomas Reps. 2000. Undecidability of Context-Sensitive Data-Dependence Analysis. ACM Trans. Program. Lang. Syst.
22, 1 (jan 2000), 162–186. https://doi.org/10.1145/345099.345137
[10] Thomas Reps, Susan Horwitz, and Mooly Sagiv. 1995. Precise Interprocedural Dataflow Analysis via Graph Reachability.
In Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (San Francisco,
California, USA) (POPL ’95). Association for Computing Machinery, New York, NY, USA, 49–61. https://doi.org/10.
1145/199448.199462
[11] Atanas Rountev and Satish Chandra. 2000. Off-Line Variable Substitution for Scaling Points-to Analysis. In Proceedings
of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation (Vancouver, British
Columbia, Canada) (PLDI ’00). Association for Computing Machinery, New York, NY, USA, 47–56. https://doi.org/10.
1145/349299.349310
[12] Johannes Späth, Karim Ali, and Eric Bodden. 2019. Context-, Flow-, and Field-Sensitive Data-Flow Analysis Using
Synchronized Pushdown Systems. Proc. ACM Program. Lang. 3, POPL, Article 48 (jan 2019), 29 pages.
https:
//doi.org/10.1145/3290361
[13] Yulei Sui, Ding Ye, and Jingling Xue. 2014. Detecting Memory Leaks Statically with Full-Sparse Value-Flow Analysis.
IEEE Transactions on Software Engineering 40, 2 (2014), 107–122. https://doi.org/10.1109/TSE.2014.2302311
[14] Robert Tarjan. 1971. Depth-First Search and Linear Graph Algorithms. In Proceedings of the 12th Annual Symposium
on Switching and Automata Theory (Swat 1971) (SWAT ’71). IEEE Computer Society, USA, 114–121. https://doi.org/10.
1109/SWAT.1971.10
[15] Leslie G. Valiant. 1975. General context-free recognition in less than cubic time. J. Comput. System Sci. 10, 2 (1975),
308–315. https://doi.org/10.1016/S0022-0000(75)80046-8
[16] Kai Wang, Aftab Hussain, Zhiqiang Zuo, Guoqing Xu, and Ardalan Amiri Sani. 2017. Graspan: A Single-Machine
Disk-Based Graph System for Interprocedural Static Analyses of Large-Scale Systems Code. SIGPLAN Not. 52, 4 (apr
2017), 389–404. https://doi.org/10.1145/3093336.3037744
[17] Wenjie Zhang, Guancheng Wang, Junjie Chen, Yingfei Xiong, Yong Liu, and Lu Zhang. 2023. OrdinalFix: Fixing
Compilation Errors via Shortest-Path CFL Reachability. arXiv:2309.06771 [cs.SE]
[18] Xin Zheng and Radu Rugina. 2008. Demand-Driven Alias Analysis for C. SIGPLAN Not. 43, 1 (jan 2008), 197–208.
https://doi.org/10.1145/1328897.1328464
A
RAM CONSUMPTION
Table 2 displays the maximum RAM usage for all conducted experiments, using the same notations
as in Table 1.
Optimization of the Context-Free Language Reachability Matrix-Based Algorithm
5
Table 2. All-Pairs CFL-r RAM Consumption in GB
Problem
Graph
𝑚𝑎
𝑚𝑎1
𝑚𝑎14
𝑚𝑎1234
𝑚𝑎12345
POCR
Graspan
Gigascale
FSJPT
tradebeans
OOT
2.2
1.9
1.8
0.35
3.2
-
1.0
tradesoap
OOT
2.2
1.9
1.8
0.35
3.2
-
1.0
FICA
apache
12
11
11
12
2.9
OOM
11
-
postgre
11
11
11
11
3.3
OOM
12
-
FSCA
imagick
13
11
11
14
14
7.3
-
-
perlbench
16
21
21
27
27
OOT
-
-
CSCVF
povray
OOT
1.3
1.1
1.2
1.2
9.9
-
-
perlbench
OOT
OOT
5.8
6.0
6.0
OOM
-
-
Table 3. Characteristics Of Analyzed Graphs
Problem
Graph
Vertices
Edges
Distinct Edge Labels
FSJPT
tradebeans
439,693
933,938
31,886
tradesoap
440,680
936,526
31,980
FICA
apache
1,721,418
3,020,822
4 (𝑎,𝑑,𝑎,𝑑)
postgre
5,203,419
9,357,086
4 (𝑎,𝑑,𝑎,𝑑)
FSCA
imagick
41,652
111,550
288
perlbench
38,091
110,874
110
CSCVF
povray
346,034
581,210
11,311
perlbench
605,864
1,114,892
28,881
Table 4. Used CFGs
Problem
𝑚𝑎, 𝑚𝑎1 𝑚𝑎14, 𝑚𝑎1234
𝑚𝑎12345
POCR
Graspan
Gigascale
FSJPT
Figure 1a*
Figure 1b
Figure 1a*
-
Embedded
FICA
Figure 2a*
Figure 2b
Figure 2a*
Figure 2a*
-
FSCA
Figure 3b
Figure 3b
Embedded
-
-
CSCVF
Figure 4b
Figure 4b
Embedded
-
-
B
GRAPHS AND GRAMMARS
Table 3 displays the characteristics of analyzed graphs: number of vertices, edges, and distinct
labels.
In this work, as optimization (5) states, CFGs for field-sensitive Java points-to [4] and field-
insensitive C/C++ memory-alias [18] analyses were manually transformed to WCNF (see Figures 1b
and 2b) in such a way that results in better performance compared to automatically generated
WCNF (compare 𝑚𝑎1234 and 𝑚𝑎12345 in Table 1).
Table 4 shows, for each pair of CFL-r implementation and a problem, which CFG was used.
“Embedded” means that the representation of CFL for a specific problem is embedded into the CFL-r
implementation itself, and an asterisk “*” indicates that the CFG is automatically11 normalized,
because a particular CFL-r implementation only works with CFGs in WCNF.
11CFG normalization implementation — https://formallanguageconstrainedpathquerying.github.io/CFPQ_Data/reference/
grammars/generated/cfpq_data.grammars.converters.cnf.html#cfpq_data.grammars.converters.cnf.cnf_from_cfg (date of
access: 06.11.2023).
6
Ilia Muravev
𝑃𝑇
→ 𝑃𝑇𝐻 𝑎𝑙𝑙𝑜𝑐
𝑃𝑇𝐻 → 𝜀 | 𝑎𝑠𝑠𝑖𝑔𝑛 𝑃𝑇𝐻
𝑃𝑇𝐻 → 𝑙𝑜𝑎𝑑𝑖 𝐴𝑙 𝑠𝑡𝑜𝑟𝑒𝑖 𝑃𝑇𝐻
𝐹𝑇
→ 𝑎𝑙𝑙𝑜𝑐 𝐹𝑇𝐻
𝐹𝑇𝐻 → 𝜀 | 𝑎𝑠𝑠𝑖𝑔𝑛 𝐹𝑇𝐻
𝐹𝑇𝐻 → 𝑠𝑡𝑜𝑟𝑒𝑖 𝐴𝑙 𝑙𝑜𝑎𝑑𝑖 𝐹𝑇𝐻
𝐴𝑙
→ 𝑃𝑇 𝐹𝑇
(a) CFG taken from CFPQ Data
𝑃𝑇
→ 𝑎𝑙𝑙𝑜𝑐 | 𝑎𝑠𝑠𝑖𝑔𝑛 𝑃𝑇 | 𝐿𝑃𝐹𝑆𝑖 𝑃𝑇
𝐹𝑇
→ 𝑎𝑙𝑙𝑜𝑐 | 𝐹𝑇 𝑎𝑠𝑠𝑖𝑔𝑛 | 𝐹𝑇 𝑆𝑃𝐹𝐿𝑖
𝐿𝑃𝐹𝑆𝑖 → 𝐿𝑃𝑖 𝐹𝑆𝑖
𝐿𝑃𝑖
→ 𝑙𝑜𝑎𝑑𝑖 𝑃𝑇
𝐹𝑆𝑖
→ 𝐹𝑇 𝑠𝑡𝑜𝑟𝑒𝑖
𝑆𝑃𝐹𝐿𝑖 → 𝑆𝑃𝑖 𝐹𝐿𝑖
𝑆𝑃𝑖
→ 𝑠𝑡𝑜𝑟𝑒𝑖 𝑃𝑇
𝐹𝐿𝑖
→ 𝐹𝑇 𝑙𝑜𝑎𝑑𝑖
(b) CFG in WCNF, introduced as optimization (5)
Fig. 1. CFG for field-sensitive Java points-to analysis
𝑀 → 𝑑 𝑉 𝑑
𝑉 → 𝜀 | 𝑉1 𝑉2 𝑉3
𝑉1 → 𝜀 | 𝑉2 𝑎 𝑉1
𝑉2 → 𝜀 | 𝑀
𝑉3 → 𝜀 | 𝑎 𝑉2 𝑉3
(a) CFG taken from CFPQ Data
𝑀
→ 𝑁1 𝑁3 | 𝑁2 𝑁3
𝑁1 → 𝑑 | 𝑁1 𝑎 | 𝑁2 𝑎
𝑁2 → 𝑁1 𝑀
𝑁3 → 𝑑 | 𝑎 𝑁3 | 𝐴𝑀 𝑁3
𝐴𝑀 → 𝑎 𝑀
(b) CFG in WCNF, introduced as optimization (5)
Fig. 2. CFG for field-insensitive C/C++ alias analysis
𝑀 → 𝑑 𝑉 𝑑
𝑉 → 𝐴 𝑉 𝐴 | 𝑓𝑖 𝑉 𝑓𝑖 | 𝑀 | 𝜀
𝐴 → 𝑎 𝑀? | 𝜀
𝐴 → 𝑀? 𝑎 | 𝜀
(a) CFG
𝑀
→ 𝐷𝑉 𝑑
𝐷𝑉 → 𝑑 𝑉
𝑉
→ 𝐴 𝑉 | 𝑉 𝐴 | 𝐹𝑉𝑖 𝑓𝑖 | 𝑀 | 𝜀
𝐹𝑉𝑖 → 𝑓 𝑖𝑉
𝐴
→ 𝑎 𝑀 | 𝑎 | 𝜀
𝐴
→ 𝑀 𝑎 | 𝑎 | 𝜀
(b) CFG in WCNF
Fig. 3. CFG for field-sensitive C/C++ alias analysis, taken from [6]
𝐴 → 𝐴 𝐴 | 𝑎 | 𝜀
𝐴 → 𝑐𝑎𝑙𝑙𝑖 𝐴 𝑟𝑒𝑡𝑖
(a) CFG
𝐴
→ 𝐴 𝑎 | 𝐴 𝐴𝐻 | 𝜀
𝐴𝐻 → 𝑐𝑎𝑙𝑙𝑖 𝐴𝑅𝑖
𝐴𝑅𝑖 → 𝐴 𝑟𝑒𝑡𝑖
(b) CFG in WCNF
Fig. 4. CFG for context-sensitive C/C++ value-flow analysis, taken from [6]
"
This paper aims to explore the direct relationship between emotion and state-of-the-art speaker embeddings in the form of intra-speaker clusters and provide a contrastive pretraining approach for speech emotion recognition. We conduct a thorough clustering analysis to demonstrate the extractability of emotion information from speaker embeddings. The proposed method leverages extensive emotion-unlabeled data and significantly improves speech emotion recognition performance.nan,"Speech emotion recognition remains challenging due to its complexity and the subjective nature of emotional expression. Recent works explore the potential of speaker embeddings in enhancing speech emotion recognition, but they assume that emotion information is indirectly encoded within speaker embeddings. We aim to investigate the direct accessibility of emotion-related information within speaker embeddings and find effective ways to leverage this information in SER tasks.nan","nanPrevious studies have revealed increased equal error rates in speaker verification for non-matching emotional conditions, highlighting the sensitivity of speaker features to emotional states. Research has also demonstrated emotion-related information in speaker embeddings via autoencoder-based reconstruction analysis and emotion classification. Recent works have employed deep speaker embedding networks to transfer knowledge from speaker verification to speech emotion recognition. However, the potential of deep speaker embeddings in encoding emotional information remains an area that requires comprehensive exploration.nan","We evaluate the relationship between emotion and speaker embedding clusters using clustering analysis. We utilize d-vector and ECAPA-TDNN speaker embeddings and compute intra-speaker clusters corresponding to emotion categories. The evaluation metrics used include Normalized Mutual Information (NMI), Adjusted Rand Index (ARI), Purity Score, and Silhouette Score. To leverage the clustered embeddings, we then introduce a novel contrastive learning approach for SER. We employ positive and negative example pairs based on the speaker embedding clusters and formulate a contrastive loss function. The contrastive learning is applied as the primary objective of pretraining and as an additional task for existing pretraining methods in a multi-task setting.nan","Our analysis reveals distinct intra-speaker clusters that reflect emotional states, suggesting a strong link between speaker and emotion recognition. Pretraining with the proposed contrastive strategy demonstrates significant improvement in speech emotion recognition compared to no pretraining and supervised speaker classification. The multi-task learning approach, which simultaneously considers intra-speaker variations and speaker-emotion connection, achieves the best performance. Fine-tuning a pre-trained wav2vec2.0 model with our contrastive learning and multi-task strategies further enhances speech emotion recognition performance.nan","Our research establishes a direct link between emotions and state-of-the-art speaker embeddings, highlighting the potential of speaker embeddings for SER. The novel contrastive pretraining approach significantly improves SER performance, providing a practical solution for data scarcity in SER. Future work will extend the analysis of emotion information in speaker embeddings and explore factors affecting its appearance.nan",Revealing Emotional Clusters in Speaker Embeddings: A Contrastive Learning Strategy for Speech Emotion Recognition,"Ismail Rasim Ulgen, Zongyang Du, Carlos Busso, Berrak Sisman","REVEALING EMOTIONAL CLUSTERS IN SPEAKER EMBEDDINGS:
A CONTRASTIVE LEARNING STRATEGY FOR SPEECH EMOTION RECOGNITION
Ismail Rasim Ulgen1, Zongyang Du1, Carlos Busso2, Berrak Sisman1
1Speech & Machine Learning (SML) Lab, The University of Texas at Dallas, USA
2Multimodal Signal Processing (MSP) Lab, The University of Texas at Dallas, USA
ABSTRACT
Speaker embeddings carry valuable emotion-related informa-
tion, which makes them a promising resource for enhancing
speech emotion recognition (SER), especially with limited la-
beled data. Traditionally, it has been assumed that emotion in-
formation is indirectly embedded within speaker embeddings,
leading to their under-utilization. Our study reveals a direct
and useful link between emotion and state-of-the-art speaker
embeddings in the form of intra-speaker clusters. By conduct-
ing a thorough clustering analysis, we demonstrate that emo-
tion information can be readily extracted from speaker em-
beddings. In order to leverage this information, we introduce
a novel contrastive pretraining approach applied to emotion-
unlabeled data for speech emotion recognition. The proposed
approach involves the sampling of positive and the negative
examples based on the intra-speaker clusters of speaker em-
beddings. The proposed strategy, which leverages extensive
emotion-unlabeled data, leads to a significant improvement
in SER performance, whether employed as a standalone pre-
training task or integrated into a multi-task pretraining setting.
Index Terms— Speech emotion recognition, speaker em-
beddings, clustering, contrastive learning, multi-task learning
1. INTRODUCTION
Speech emotion recognition remains a challenging task due
to its complexity and the subjective nature of emotional ex-
pression, compounded by the scarcity of labeled emotional
data [1]. These factors significantly hinder the development
of effective SER methods, and encourage researchers to lever-
age auxiliary knowledge from closely related speech tasks,
such as speaker verification (SV) [2–5].
In contrast to SER, SV benefits from the availability of
sufficient labeled data [6, 7]. Although the tasks of recog-
nizing emotions from speech and verifying speakers differ in
their primary objectives, they both revolve around the identifi-
cation of fundamental voice attributes, including pitch, tone,
and phonation patterns. Consequently, speaker verification
techniques with robust performance are now being explored
as promising tools for enhancing the performance of speech
emotion recognition systems [2,3,8]
Emotion information within speaker features has been
explored in various emotional speech tasks. Studies [9–11]
revealed increased equal error rates in speaker verification
for non-matching emotional conditions, highlighting the sen-
sitivity of speaker features to emotional states [12].
Re-
search by [13] demonstrated emotion-related information
in speaker embeddings via autoencoder-based reconstruc-
tion analysis and emotion classification.
This finding was
confirmed by [8], which also performed reconstruction anal-
ysis and used speaker embeddings as SER input features.
Recent works [2, 3] employed deep speaker embedding net-
works to transfer knowledge from speaker verification to
speech emotion recognition. However, the potential of recent
deep speaker embeddings like d-vector [14] and ECAPA-
TDNN [15] in encoding emotional information remains an
area that requires comprehensive exploration. Previous stud-
ies are limited by the assumption that emotion information
is indirectly encoded within speaker embeddings and can
be utilized under supervision. In this paper, we aim to ex-
plore whether emotion-related information directly resides
within the speaker embedding space and find effective ways
to leverage this information in SER tasks.
Self-supervised speech models such as wav2vec2.0 [16]
can leverage large unlabeled speech datasets to enhance su-
pervised SER frameworks [5,17,18]. However, it’s important
to note that these pre-training objectives were not originally
designed for SER, except for [19] which incorporated audio-
visual features. Additionally, existing pretraining tasks uti-
lized in SER are frame-level tasks while speech emotion is
usually formulated as an uttterance-level task. Consequently,
a significant gap exists in the field, particularly in the develop-
ment of an utterance-level, unsupervised pre-training strategy
explicitly tailored to SER, exclusively using speech-related
features, which is one of the contributions of this paper.
This paper marks the first attempt to investigate the
direct accessibility of emotion-related information within
state-of-the-art deep speaker embeddings. Our analysis re-
veals distinct intra-speaker clusters that reflect emotional
states, suggesting a strong link between speaker and emotion
recognition. To utilize this information, we propose a novel
pretraining strategy using large-scale, emotion-unlabeled
data. This approach employs contrastive learning, forming
positive-negative pairs based on speaker embedding clusters,
without the need for emotion labels. We apply this strategy
both as the primary objective of pretraining and as an addi-
tional task for the existing pretraining methods in a multi-task
©2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing
this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this
work in other works.
arXiv:2401.11017v1  [eess.AS]  19 Jan 2024
Table 1: Intra-speaker clustering evaluation for emotion classification.
d-vector
ECAPA-TDNN
Dataset
NMI [0,1] ↑
ARI [0,1] ↑
Purity [0,1] ↑
Silhoutte [-1,1] ↑
NMI [0,1] ↑
ARI [0,1] ↑
Purity [0,1] ↑
Silhoutte [-1,1] ↑
ESD
0.76
0.72
0.89
0.14
0.89
0.91
0.97
0.13
IEMOCAP
0.29
0.21
0.66
0.01
0.31
0.25
0.67
0.01
CREMA-D
0.43
0.39
0.63
0.07
0.36
0.27
0.57
0.04
RAVDESS
0.59
0.38
0.67
0.14
0.51
0.28
0.62
0.05
setting.
Our contributions can be summarized as follows:
1) We reveal readily available emotion information within
speaker embeddings; 2) We introduce a unique, utterance-
level contrastive learning approach for SER, without relying
on emotion labels; 3) We demonstrate that combination of
pretraining tasks in a multi-task setting can further improve
SER performance; and 4) Through our proposed training
strategy, we enhance a very strong framework, wav2vec2.0,
in terms of emotion recognition performance.
2. REVEALING EMOTION CLUSTERS IN SPEAKER
EMBEDDINGS
In this section, we conduct clustering analysis on speaker
embeddings to explore emotion discrimination within the
speaker embedding space, aiming to establish a direct link
between intra-speaker clusters of embeddings and emotional
categories.
This connection holds significant potential for
various SER applications, particularly in harnessing exten-
sive, emotion-unlabeled data. Our analysis is driven by the
hypothesis that speaker embeddings, designed to capture
voice characteristics, are sensitive to variations in a speaker’s
voice across different emotional states [8–10, 13], drawing
inspiration from studies indicating distinct speaker patterns
in different emotional contexts [9–11].
2.1. Dataset, speaker embeddings and evaluation metrics
We applied k-means clustering to length-normalized speaker
embeddings of using a maximum of 320 different utterances
for each speaker within a dataset, using a fixed number of
clusters to align with the four categorical emotions: neu-
tral, happiness, sadness, and anger. We selected four widely
used labeled emotion datasets: IEMOCAP [20], ESD [21],
CREMA-D [22], and RAVDESS [23]. Our choice of deep
speaker embedding networks includes d-vector [14] and
ECAPA-TDNN [15], both trained with metric-based ob-
jectives like generalized end-to-end loss and angular margin
softmax loss on the voxceleb2 dataset [7]. We evaluated the
alignment between intra-speaker cluster labels and emotion
categories using metrics such as Normalized Mutual Infor-
mation (NMI) [24], Adjusted Rand Index (ARI) [24], Purity
Score [25], and Silhouette Score [26], averaged over speakers
and larger values indicate a stronger alignment.
2.2. Clustering and Evaluations
The clustering results are reported in Table 1. Notably, the
ESD dataset consistently demonstrates exceptionally high
metrics, indicating a direct alignment between intra-speaker
clusters and emotion categories in specific conditions where
the utterances are very clean, linguistic content is normalized
over emotion categories and emotion intensity tends to be
(a) T-SNE of speaker embeddings in ESD dataset
(b) T-SNE of speaker embeddings in IEMOCAP dataset
Fig. 1: Visualization of intra-speaker clusters in two datasets,
the colors represent {speaker id} {emotion}.
high. While the metrics for other datasets are not as high as
in ESD, a meaningful correlation exists across all datasets.
The IEMOCAP dataset, with challenges like reverberation
and overlapping speech, exhibits the lowest metrics, possibly
due to variance introduced into speaker embeddings.
The distribution of embeddings can be observed in the t-
SNE plots in Figure 1, showing clear separation in the ESD
dataset and some distinction in the IEMOCAP dataset. We’ve
plotted t-SNE plots only for ESD and IEMOCAP due to sim-
ilar trends in other databases. NMI values tend to be higher
than ARI values, indicating uneven clustering errors. Higher
purity values, compared to lower ARI values, suggest over-
laps between specific emotion pairs, hinting at unique rela-
tionships between emotion categories. Low silhouette scores
are expected due to closely spaced embeddings, aligning with
their original goal of grouping speaker utterances together.
In general, the clustering results validate that speaker em-
beddings tend to group together for different emotional states
in the embedding space due to distinct vocal characteristics
for each emotion. The correspondence between emotion cate-
gories and intra-speaker clusters is limited in non-ideal condi-
tions possibly due to other factors affecting the speech signal.
The results show that even clusters with limited accuracy can
serve as effective learning tasks [27–29]. Inspired by these
findings, we propose a contrastive learning strategy based on
the trend of intra-speaker clustering of emotion categories.
2
Pooling
Dense
(ReLu)
Dense
(tanh)
Contrastive
Loss
Pooling
Emotion Classification
Loss
Stage 1:
Pre-training
Stage 2:
Supervised SER
Spk Classification
Loss
Dense
(ReLu)
Dense
(softmax)
Pooling
Dense
(ReLu)
Dense
(softmax)
Dense
(ReLu)
Dense
(tanh)
Contrastive
Loss
 Proposed
Multi-Task Learning
Encoder
Encoder
Encoder
(Shared)
a)
b)
Fig. 2: a) Proposed contrastive pre-training and SER training,
b) Proposed multi-task learning framework.
3. CONTRASTIVE LEARNING FOR SER
In this study, we introduce a novel contrastive pretrain-
ing strategy without emotion labels, which capitalizes on
emotion-related information present in the form of intra-
speaker clusters within speaker embeddings. Our approach is
based on contrastive learning, a technique well-known for its
efficacy across various tasks [30, 31]. The learning objective
tries to maximize the similarity between positive pairs while
minimize it for negative pairs. In our approach, positive pairs
consist of utterances sampled from the same intra-speaker
cluster, likely sharing the same emotion category. In contrast,
negative examples are created from different intra-speaker
clusters of the same speaker, likely to have different emo-
tion categories given our analysis in Section 2. This setup
inherently fosters an utterance-level emotion classification.
3.1. Contrastive Pretraining
In the pretraining stage, we obtain intra-speaker clusters of
speaker embeddings in a separate process similar to the ex-
periments in Section 2.1, where the only difference is in the
number of clusters N since we don’t have a prior about cat-
egories on emotion-unlabeled data.
A variant NT-Xent [30]
loss is used as an objective in the training:
l = −log
exp(sim(zi, zj)/τ)
PN/2
k=1 exp(sim(zi, zk)/τ)[k̸=i]
(1)
where zi, zj is the positive pair and zi, zk are the nega-
tive pairs for a given utterance.
The similarity function
sim(x, y) = xT y/||x||.||y|| calculates the cosine similarity
and τ denotes the temperature parameter.
Soft-sampling: For each utterance, we select one positive
and N/2 negative utterances based on intra-speaker cluster
labels. Due to rough clustering, when sampling the negative
examples, we employ a soft-sampling strategy, selecting one
negative sample from each of the N/2 intra-speaker clusters
Encoder
CNN 
Encoder
Transformer
Encoder
Input
Waveform
Frame-level
Outputs
Fig. 3: The encoder architecture utilized in the networks.
that are farthest from the positive cluster center. The model
architecture consists of an encoder followed by a contrastive
learning head, as shown in Fig.2(a) and Fig. 3.
3.2. Contrastive Pretraining for Multi-Task Design
Given the success of the transfer learning from speaker
recognition to SER due to their connection, we also pro-
pose a multi-task learning (MTL) strategy to utilize available
speaker labels. The proposed multi-task framework includes
shared encoder layers along with two separate heads: con-
trastive learning and speaker classification head which can
be seen in Figure 2(b).
The contrastive learning head is
trained with the proposed objective in Section 3.1; while the
speaker classification head is trained with the cross-entropy
loss with speaker labels. Along with the multi-task frame-
work, speaker adversarial setting is also experimented, by
including a Gradient Reversal Layer (GRL) just before the
speaker classification head.
3.3. Speech Emotion Recognition
After pretraining on a large-scale, emotion-unlabeled dataset,
the model is trained in a supervised manner on a smaller
dataset with categorical emotion labels. During supervised
training, we introduce a freshly initialized classification head
on top of pre-trained encoder layers. This classification head
comprises an average pooling layer, a dense projection layer
with rectified linear unit (ReLU) activation, and a dense out-
put layer with softmax activation. In this stage, we fine-tune
the pre-trained layers in conjunction with the classification
head, utilizing cross-entropy loss and emotion labels. The
diagram can be seen in the Figure 2(a).
4. EXPERIMENTS
In this section, we report the effect of our proposed pretrain-
ing strategies with only contrastive loss and multi-task learn-
ing on SER performance when dealing with a limited amount
of labeled data. We have evaluated our strategies indepen-
dently and in conjunction with wav2vec2.0 to clearly discern
their effect on emotion recognition performance.
4.1. Experimental setup
Datasets: During pretraining, we utilize voxceleb2 [7] as an
emotion-unlabeled dataset, known for its diverse emotional
contexts [13], aligning with our intra-speaker clustering ap-
proach. In supervised SER training, we separately employ
two labeled emotion datasets, IEMOCAP and CREMA-D.
We focus exclusively on Anger, Happiness, Neutral, Sadness,
establishing a speaker-independent emotion recognition sce-
nario. For the IEMOCAP corpus, we only use improvised ut-
terances and create 5-fold training and test splits following the
3
leave-one-session-out rule described in [17] and [2], exclud-
ing a small subset from one of the test speakers for validation.
For CREMA-D, we use training data from 64 speakers, with
8 for validation and 19 for testing.
Baselines: In our basic SER experiments, we establish
three baselines: No-pretraining, which involves initializing
the model randomly before supervised SER training, with-
out any pretraining; No-pretraining (small), which has a
smaller architecture with only 2 transformer layers to assess
the impact of overfitting; and Pretraining w/ spk classifi-
cation which employs pretraining the model with encoder
followed by only speaker classification head and loss, sim-
ilar to the methodology in [2]. For SER experiments based
on wav2vec2.0, we utilize a smaller version of the original
wav2vec2.0 as the baseline pretraining method.
Model Architecture & Training: In our pretraining and
basic SER experiments, our proposed methods and base-
line models, have the same encoder architecture, which is
based on wav2vec2.0 [16].
This encoder architecture in-
cludes a feature extractor and a transformer encoder, similar
to wav2vec2.0, but with a more compact design featuring
only 6 transformer layers.
The contrastive learning head
includes an average pooling layer for frame-level outputs,
followed by two dense layers featuring ReLU and tanh acti-
vation functions shown in Figure 2, respectively. The speaker
and emotion classification heads have a similar structure as
the contrastive head but use softmax activation at the output
layer, shown in Figure 2. In the speaker adversarial setting,
we introduce an additional GRL layer after pooling and be-
fore the speaker classification head. All the proposed models
take the raw waveform of an utterance as input.
During pretraining, we segment the input utterances into
4-second intervals and perform offline intra-speaker cluster-
ing with N = 20. The models are pretrained for 250k steps
using the AdamW optimizer with a batch size of 8. In the su-
pervised SER training that follows, the model undergoes 30
epochs of training with a learning rate of 1e-5, stopping based
on the validation accuracy. We repeat each supervised SER
training 5 times with different initialization seeds and mea-
sure unweighted average recall (UAR) during the evaluation.
For the SER experiments based on wav2vec2.0 reported in
Table 3, the baseline wav2vec2.01 with 6 transformer layers,
is pretrained for 400k steps on voxceleb2. We then fine-tune
this model with our strategies on voxceleb2 for an extra 50k
steps. The feature extractor and transformer layers of fine-
tuned wav2vec2.0 are utilized in the supervised SER training.
4.2. Results and Discussion
According to the results in Table 2, our proposed contrastive
strategy, denoted as Pretraining w/ proposed contrastive,
demonstrate a significant improvement in SER compared to
cases with no pretraining in both datasets. We note that pre-
training with supervised speaker classification also leads to
1 https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec
Table 2: SER results, in terms of mean UAR.
Pre-Training
IEMOCAP
(UAR)
CREMA- D
(UAR)
No pretraining (small)
58.37
65.12
No pretraining
58.54
64.15
Pretraining w/ spk classification
67.57
75.23
Pretraining w/ proposed contrastive
65.50
70.44
Pretraining w/ proposed spk ADV
64.48
66.58
Pretraining w/ proposed MTL
69.16
73.80
Table 3: SER results with wav2vec2.0, mean UAR.
Pre-Training
IEMOCAP
(UAR)
CREMA- D
(UAR)
wav2vec2.0 [16]
72.14
80.78
FT wav2vec2.0 w/ proposed contrastive
72.78
81.72
FT wav2vec2.0 w/ proposed MTL
73.80
83.01
substantial improvements in both datasets, consistent with
findings in [2]. The proposed multi-task learning approach,
denoted as Pretraining w/ proposed MTL, leverages the in-
herent connection between speaker and emotion recognition,
while simultaneously considering intra-speaker variations
and obtains the best performance in the IEMOCAP corpus.
We observe that speaker adversarial network degrades perfor-
mance, indicating that trying to remove speaker information
has a negative impact and supports the connection between
speaker and emotion recognition. In CREMA-D, the speaker
classification baseline performs exceptionally well, possibly
due to the presence of normalized linguistic content, cre-
ating ideal conditions for discriminating emotions through
speaker embeddings, as discussed in Section 2. Overall, these
results underscore the effectiveness of our multi-task learn-
ing method and highlight the strong relationship between
emotion and speaker recognition.
In Table 3, baseline wav2vec2.0 model, pretrained with
voxceleb2, performs impressively well as a pretraining
method for SER, underscoring its effectiveness. Fine-tuning
this baseline with our contrastive learning strategy, FT
wav2vec2.0 w/ proposed contrastive, seems leading to mi-
nor improvements in both datasets. Fine-tuning wav2vec2.0
with our proposed multi-task setting, FT wav2vec2.0 w/ pro-
posed MTL, yields substantial enhancement, highlighting the
effectiveness of our approach.
5. CONCLUSION
Our research reveals the potential of speaker embeddings for
enhancing SER task, even with limited labeled data.
Our
study establishes a direct link between emotions and state-
of-the-art speaker embeddings through intra-speaker clus-
ters. Our novel contrastive pretraining approach on emotion-
unlabeled datasets, based on these clusters, significantly im-
proves SER performance, whether used alone or in multi-task
settings. Our findings not only advance our understanding of
speaker embeddings and emotions but also provide practical
solutions for data scarcity in SER. As a future work, we in-
tend to extend the analysis of emotion information in speaker
embeddings, analyzing other factors which potentially affect
the appearance of that information.
4
6. REFERENCES
[1] Vidhyasaharan Sethu, Emily Mower Provost, Julien Epps, Carlos
Busso, Nicholas Cummins, and Shrikanth S. Narayanan,
“The am-
biguous world of emotion representation,” ArXiv, vol. abs/1909.00360,
2019.
[2] R. Pappagari, Tianzi Wang, Jes´us Villalba, Nanxin Chen, and Najim
Dehak, “X-vectors meet emotions: A study on dependencies between
emotion and speaker recognition,”
ICASSP 2020 - 2020 IEEE In-
ternational Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 7169–7173, 2020.
[3] Sarala Padi, Seyed Omid Sadjadi, Dinesh Manocha, and Ram D. Sri-
ram,
“Improved speech emotion recognition using transfer learning
and spectrogram augmentation,” Proceedings of the 2021 International
Conference on Multimodal Interaction, 2021.
[4] Sitong Zhou and Homayoon S. M. Beigi, “A transfer learning method
for speech emotion recognition from automatic speech recognition,”
ArXiv, vol. abs/2008.02863, 2020.
[5] Leonardo Pepino, Pablo Riera, and Luciana Ferrer, “Emotion Recog-
nition from Speech Using wav2vec 2.0 Embeddings,” in Proc. Inter-
speech 2021, 2021, pp. 3400–3404.
[6] Arsha Nagrani, Joon Son Chung, and Andrew Zisserman, “Voxceleb:
A large-scale speaker identification dataset,” in Interspeech, 2017.
[7] Joon Son Chung, Arsha Nagrani, and Andrew Zisserman, “Voxceleb2:
Deep speaker recognition,” in Interspeech, 2018.
[8] Zakaria Aldeneh and Emily Mower Provost, “You’re not you when
you’re angry: Robust emotion features emerge by recognizing speak-
ers,” IEEE Transactions on Affective Computing, vol. 14, pp. 1351–
1362, 2023.
[9] Srinivas Parthasarathy, Chunlei Zhang, John H. L. Hansen, and Carlos
Busso, “A study of speaker verification performance with expressive
speech,” 2017 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP), pp. 5540–5544, 2017.
[10] Srinivas Parthasarathy and Carlos Busso, “Predicting speaker recogni-
tion reliability by considering emotional content,” 2017 Seventh Inter-
national Conference on Affective Computing and Intelligent Interaction
(ACII), pp. 434–439, 2017.
[11] Michelle I Bancroft, Reza Lotfian, John H. L. Hansen, and Carlos
Busso, “Exploring the intersection between speaker verification and
emotion recognition,” 2019 8th International Conference on Affective
Computing and Intelligent Interaction Workshops and Demos (ACIIW),
pp. 337–342, 2019.
[12] Najim Dehak, Patrick Kenny, R´eda Dehak, Pierre Dumouchel, and
Pierre Ouellet,
“Front-end factor analysis for speaker verification,”
IEEE Transactions on Audio, Speech, and Language Processing, vol.
19, pp. 788–798, 2011.
[13] Jennifer Williams and Simon King, “Disentangling style factors from
speaker representations,” in Interspeech, 2019.
[14] Li Wan, Quan Wang, Alan Papir, and Ignacio Lopez-Moreno, “Gen-
eralized end-to-end loss for speaker verification,”
2018 IEEE In-
ternational Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 4879–4883, 2017.
[15] Brecht Desplanques,
Jenthe Thienpondt,
and Kris Demuynck,
“ECAPA-TDNN: Emphasized Channel Attention, Propagation and Ag-
gregation in TDNN Based Speaker Verification,” in Proc. Interspeech
2020, 2020, pp. 3830–3834.
[16] Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael
Auli,
“Wav2vec 2.0: A framework for self-supervised learning of
speech representations,” in Proceedings of the 34th International Con-
ference on Neural Information Processing Systems, Red Hook, NY,
USA, 2020, NIPS’20, Curran Associates Inc.
[17] Edmilson da Silva Morais, Ron Hoory, Weizhong Zhu, Itai Gat,
Matheus Damasceno, and Hagai Aronowitz, “Speech emotion recogni-
tion using self-supervised features,”
ICASSP 2022 - 2022 IEEE In-
ternational Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 6922–6926, 2022.
[18] Mao Li, Bo Yang, Joshua Levy, Andreas Stolcke, Viktor Rozgic, Spy-
ros Matsoukas, Constantinos Papayiannis, Daniel Bone, and Chao
Wang, “Contrastive unsupervised learning for speech emotion recogni-
tion,” ICASSP 2021 - 2021 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), pp. 6329–6333, 2021.
[19] Lucas Goncalves and Carlos Busso,
“Improving Speech Emotion
Recognition Using Self-Supervised Learning with Domain-Specific
Audiovisual Tasks,” in Proc. Interspeech 2022, 2022, pp. 1168–1172.
[20] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh,
Emily Mower, Samuel Kim, Jeannette N Chang, Sungbok Lee, and
Shrikanth S Narayanan, “Iemocap: Interactive emotional dyadic mo-
tion capture database,” Language resources and evaluation, vol. 42, pp.
335–359, 2008.
[21] Kun Zhou, Berrak Sisman, Rui Liu, and Haizhou Li, “Emotional voice
conversion: Theory, databases and esd,” Speech Communication, vol.
137, pp. 1–18, 2022.
[22] Houwei Cao, David G. Cooper, Michael K. Keutmann, Ruben C. Gur,
Ani Nenkova, and Ragini Verma, “Crema-d: Crowd-sourced emotional
multimodal actors dataset,” IEEE Transactions on Affective Computing,
vol. 5, no. 4, pp. 377–390, 2014.
[23] Steven R Livingstone and Frank A Russo, “The ryerson audio-visual
database of emotional speech and song (ravdess): A dynamic, multi-
modal set of facial and vocal expressions in north american english,”
PloS one, vol. 13, no. 5, pp. e0196391, 2018.
[24] Xuan Vinh Nguyen, Julien Epps, and James Bailey, “Information the-
oretic measures for clusterings comparison: Variants, properties, nor-
malization and correction for chance,” J. Mach. Learn. Res., vol. 11,
pp. 2837–2854, 2010.
[25] Er´endira Rend´on, Itzel M. Abundez, Citlalih Gutierrez, Sergio D´ıaz
Zagal, Alejandra Arizmendi, Elvia M. Quiroz, and H. Elsa Arzate,
“A comparison of internal and external cluster validation indexes,” in
Proceedings of the 2011 American Conference on Applied Mathemat-
ics and the 5th WSEAS International Conference on Computer En-
gineering and Applications, Stevens Point, Wisconsin, USA, 2011,
AMERICAN-MATH’11/CEA’11, p. 158–163, World Scientific and
Engineering Academy and Society (WSEAS).
[26] Peter J. Rousseeuw, “Silhouettes: a graphical aid to the interpretation
and validation of cluster analysis,” Journal of Computational and Ap-
plied Mathematics, vol. 20, pp. 53–65, 1987.
[27] Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakho-
tia, Ruslan Salakhutdinov, and Abdelrahman Mohamed, “Hubert: Self-
supervised speech representation learning by masked prediction of hid-
den units,” IEEE/ACM Transactions on Audio, Speech, and Language
Processing, vol. 29, pp. 3451–3460, 2021.
[28] Bing Han, Zhengyang Chen, and Yanmin Qian, “Self-supervised learn-
ing with cluster-aware-dino for high-performance robust speaker veri-
fication,” ArXiv, vol. abs/2304.05754, 2023.
[29] Ruijie Tao, Kong-Aik Lee, Rohan Kumar Das, Ville Hautamaki, and
Haizhou Li,
“Self-supervised speaker recognition with loss-gated
learning,”
ICASSP 2022 - 2022 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pp. 6142–6146,
2021.
[30] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hin-
ton, “A simple framework for contrastive learning of visual representa-
tions,” in Proceedings of the 37th International Conference on Machine
Learning. 2020, ICML’20, JMLR.org.
[31] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross B. Girshick,
“Momentum contrast for unsupervised visual representation learning,”
2020 IEEE/CVF Conference on Computer Vision and Pattern Recogni-
tion (CVPR), pp. 9726–9735, 2019.
5
"
"We propose creating a custom Generative Pre-Trained Transformer (GPT) for developers to discuss and solve ethical issues in AI engineering, ensuring legal compliance and ethical perspectives.nan","Current AI software can raise ethical concerns, and legal requirements are often general and open to subversion. We aim to develop a tool to aid developers in addressing these issues.nan",Previous approaches like privacy chatbots and legal compliance APIs address limited aspects of AI ethics. We address a broad range of AI-related software ethical issues with a focus on underrepresented perspectives.nannan,We will create a high-quality dataset and analyze biases in existing LLM. We will develop deterministic responses to critical questions and validate our custom tool with AI engineers.nan,"Our tool will generate diverse ethical perspectives, assisting developers in creating AI solutions that comply with legal requirements and consider diverse ethical perspectives. A demonstration addresses the ethical concern of cyberbullying through AI-based solutions.nan","Our custom conversational agent will aid developers in creating ethical AI solutions, improving legal compliance, and fostering ethical considerations in software development.nan",Custom Developer GPT for Ethical AI Solutions,Lauren Olson,"Custom Developer GPT for Ethical AI Solutions
Lauren Olson
l.a.olson@vu.nl
Vrije Universiteit Amsterdam
Amsterdam, Netherlands
ABSTRACT
The main goal of this project is to create a new software artefact: a
custom Generative Pre-trained Transformer (GPT) for developers
to discuss and solve ethical issues through AI engineering. This
conversational agent will provide developers with practical appli-
cation on (1) how to comply with legal frameworks which regard
AI systems (like the EU AI Act [8] and GDPR [11]) and (2) present
alternate ethical perspectives to allow developers to understand
and incorporate alternate moral positions. In this paper, we provide
motivation for the need of such an agent, detail our idea and demon-
strate a use case. The use of such a tool can allow practitioners to
engineer AI solutions which meet legal requirements and satisfy
diverse ethical perspectives.
ACM Reference Format:
Lauren Olson. 2024. Custom Developer GPT for Ethical AI Solutions. In
Proceedings of 3rd International Conference on AI Engineering — Software
Engineering for AI (CAIN 2024). ACM, New York, NY, USA, 3 pages. https:
//doi.org/10.1145/nnnnnnn.nnnnnnn
1
INTRODUCTION
Current development strategies contain roles, artefacts, ceremonies,
and cultures that focus on business rather than human ethical val-
ues [6]. The business focus of these standard practices facilitates
the creation of unethical AI software, creating myriad ethical con-
cerns. Ethical concerns, issues regarding the subversion of ethical
values, plague software technologies. These concerns include cy-
berbullying, privacy, and censorship, and have been at the forefront
of modern societal struggles. AI plays a predominant role in the
propagation of these ethical concerns due to its ubiquity and effec-
tiveness in modern software solutions; therefore, any solution to
ameliorate these issues will likely also require AI solutions. Fur-
thermore, when incorporating ethical standards (like GDPR) into
AI software, some developers find legal requirements general and
difficult to apply consistently [6]. This legal ambiguity also makes it
easier for software companies to subvert ethical values while techni-
cally following legal requirements [5], leading to continued ethical
concerns. As potential solutions, few software tools have been pro-
posed to aid developers in complying with AI legal frameworks: a
privacy chatbot [1] and legal compliance API [4]. In our approach,
we aim to improve the previously proposed privacy chatbot [1] by
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CAIN 2024, April 2024, Lisbon, Portugal
© 2024 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn
expanding the ethical concerns addressed by the conversational
agent to encompass a wide range of AI-related software ethical
issues.
In addition, the restricted demography of software practitioners,
especially in decision-making roles, narrows the available ethical
perspectives and concerns discussed in development processes.
Eighty-five percent of software developers are men, and most
are white, English-speaking, middle to upper-class men from the
USA [2]. The background of these developers drive their perspec-
tives and priorities regarding software development, with studies
showing that political affiliations affect design decisions [2]. There-
fore, the human values reflected in many software products may
reflect only a small portion of the population.
Unfortunately, current artefacts for integrating minoritized per-
spectives into the design practice, like user personas and user jour-
ney stories, have received criticism for creating biased, stereotyped
views of identities [9]. This lack of proper artefacts, combined with
a dearth of user feedback tools for analysis and triangulation in
general [7], demonstrate a gap for new, improved artefacts which
capture and integrate user perspectives on software, especially mi-
noritized populations’ ethical concerns. As a result, our proposed
conversational agent will be trained on real user feedback data
collected from minoritized participants.
In this paper, we propose a custom Generative Pre-trained Trans-
former (GPT). GPTs have already become widely popular tools
amongst developers, with many companies considering it best prac-
tice for practitioners to use when developing software. However,
these systems are non-determininstic 1 and contain unknown safe-
guards and biases. Therefore, will we develop a custom GPT with
two critical features: (1) a sizeable knowledge base of data from
minoritized groups on their ethical concerns regarding software
and (2) deterministic responses to feature-elicitation prompts with
AI features which follow legal frameworks and address diverse ethical
perspectives.
This tool will function within software development processes
as both an interactive, data-driven user story and a values transla-
tor [6]. As such, it will be used to define value streams and epics,
create and prioritize features, and guide sprint planning, design and
testing. As a values translator, it will ‘communicate values concepts
in a terminology understandable for the development teams [6].’
2
IMPLEMENTATION
To implement our new SE artefact, we will (1) create a high-quality
dataset of diverse users’ ethical concerns, (2) discover the inherent
LLM biases and trained safeguards of GPT surrounding these ethical
conversations, (3) create a GPT customized with the most recent
legal and ethical frameworks, our data, and deterministic responses
based on our data to users’ top concerns.
1given the same input, output is not constant
arXiv:2401.11013v1  [cs.SE]  19 Jan 2024
CAIN 2024, April 2024, Lisbon, Portugal
Lauren Olson
We will first collect data on minoritized communities’ ethical
concerns to provide the LLM with high-quality training data to
summarize the ethical needs of these communities. This data will
allow for the creation of a new software artefact: an interactive, data-
driven user journey story. We have already completed this first step
by collecting, annotating, and analyzing over 2000 Reddit posts
from seven minoritized communities for software-based ethical
concerns [10]. The Reddit posts detail user experiences of ethical
concerns with seven different software platforms.
The next step to properly building this software tool is, through
custom prompts, to determine the existing conversational space
surrounding AI-based ethical concerns. When dealing with ethical
concerns and minoritized populations specifically, it is critical to
proactively determine potential biases and pre-trained safeguards
which restrict and color the GPT’s responses. From these results,
we will develop deterministic responses to critical questions to
prevent responses which conflict with users’ ethical requirements
or existing legal requirements.
The final step is to create the custom GPT. It is essential to
develop this tool with the developers who will use it: AI engineers.
We plan to perform user studies with AI engineers to ensure the
tool is usable and integrates well into their existing development
pipelines. Through these user studies, we will also test whether
more ethical AI solutions are successfully developed by using our
tool.
3
USE CASE
Consider a specific cyberbullying concern: online, non-consensual
pornography, where sexually explicit material of a person is shared
without their consent. In several countries, non-consensual pornog-
raphy is a crime and if platforms do not take reasonable measures
to remove it, they can be held legally accountable; therefore, plat-
forms need to take measures to prevent its occurrence. In our initial
work, we find that women of color highly report non-consensual
pornography as an ethical concern [10]. To combat non-consensual
pornography, women typically have to manually monitor online
channels to curb the spread of this unwanted content. In a recent
study, researchers found that nearly 40 percent of platforms did not
have any reporting interfaces and only 16% allowed users to indicate
the occurrence of non-consensual pornography with a proper legal
vocabulary [3]. However, these reporting systems place the burden
of solving the issue on the victim and it is incredibly difficult to
manually monitor the spread of content across the internet. Instead,
software practitioners could engineer an AI solution to automat-
ically identify and remove non-consensual pornography, so that
women don’t have to manually track and report non-consensual
images.
Instead of having software which worsens this issue by having
insufficient software design, our conversational agent could pro-
vide developers with (1) real women’s ethical complaints, which
detail struggles with non-consensual pornography, (2) legal require-
ments regarding non-consensual pornography, and (3) examples
of features which could be implemented which satisfy (1) and (2).
To tackle this challenge, the developer will first prompt our GPT
for women’s ethical concerns and elicit a response informed by its
already high-quality knowledge base and our data (see Figure 1).
Figure 1: Sample prompt showing developer eliciting
women’s
cyberbullying
requirements,
non-consensual
pornography underlined, full GPT response not shown due
to size constraints
Figure 2: Sample prompt showing developer finding solu-
tion to non-consensual pornography, full GPT response not
shown due to size constraints
Next, the developer will identify non-consensual pornography as
an ethical concern which can be solved through AI, and prompt
the GPT for a proper solution (see Figure 2). Figures 1 and 2 show
initial prompts and responses; further prompting is necessary to
obtain a full solution.
Custom Developer GPT for Ethical AI Solutions
CAIN 2024, April 2024, Lisbon, Portugal
REFERENCES
[1] Lamya Alkhariji, Suparna De, Omer Rana, and Charity Perera. 2022. Poster:
Ontology Enabled Chatbot for Applying Privacy by Design in IoT Systems. In
Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications
Security. 3323–3325.
[2] Sasha Costanza-Chock. 2020. Design justice: Community-led practices to build the
worlds we need. The MIT Press.
[3] Antonella De Angeli, Mattia Falduti, Maria Menendez-Blanco, and Sergio Tessaris.
2023. Reporting non-consensual pornography: clarity, efficiency and distress.
Multimedia Tools and Applications 82, 9 (2023), 12829–12858.
[4] Catalina Goanta, Thales Bertaglia, and Adriana Iamnitchi. 2022. The case for
a legal compliance API for the enforcement of the EU’s digital services act on
social media platforms. In Proceedings of the 2022 ACM Conference on Fairness,
Accountability, and Transparency. 1341–1349.
[5] Colin M Gray, Cristiana Santos, Nataliia Bielova, Michael Toth, and Damian
Clifford. 2021. Dark patterns and the legal requirements of consent banners: An
interaction criticism perspective. In Proceedings of the 2021 CHI Conference on
Human Factors in Computing Systems. 1–18.
[6] Waqar Hussain, Mojtaba Shahin, Rashina Hoda, Jon Whittle, Harsha Perera, Arif
Nurwidyantoro, Rifat Ara Shams, and Gillian Oliver. 2022. How can human
values be addressed in agile methods? A case study on SAFe. IEEE Transactions
on Software Engineering 48, 12 (2022), 5158–5175.
[7] Ze Shi Li, Nowshin Nawar Arony, Kezia Devathasan, Manish Sihag, Neil Ernst,
and Daniela Damian. 2023. Unveiling the Life Cycle of User Feedback: Best
Practices from Software Practitioners. arXiv:2309.07345 [cs.SE]
[8] Tambiama Madiega. 2023.
Artificial Intelligence Act.
https:
//www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-
ai-act-first-regulation-on-artificial-intelligence
[9] Nicola Marsden and Maren Haag. 2016. Stereotypes and politics: reflections on
personas. In Proceedings of the 2016 CHI conference on human factors in computing
systems. ACM, San Jose, CA, USA, 4017–4031.
[10] L. Olson, E. Guzman, and F. Kunneman. 2023. Along the Margins: Marginalized
Communities’ Ethical Concerns about Social Platforms. In 2023 IEEE/ACM 45th
International Conference on Software Engineering: Software Engineering in Society
(ICSE-SEIS). IEEE Computer Society, Los Alamitos, CA, USA, 71–82.
https:
//doi.org/10.1109/ICSE-SEIS58686.2023.00013
[11] European Union. 2016. General Data Protection Regulation. https://gdpr-info.eu
"
"This workshop report provides insights into the context of the creation and the underlying methodological considerations behind the authors' published game database. The database was collaboratively developed and lists digital games developed in Germany, Austria, and Switzerland up to the year 2000. In this report, in addition to our initial considerations and the various work steps involved in the realization, we also outline the data basis on which the database was built and tested, the goals of the data model, and the difficulties we faced during the process of creation. Subsequently, we classify the current status of the game database and provide an outlook on the further plans for the project.nan","With the growing interest from research and journalism in digital games, there is also an increasing awareness of their history. It quickly becomes apparent that the ""new"" medium - depending on the starting point - is not even 50 years old. However, something else also became apparent: A kind of US-American-Japanese master narrative quickly emerged, which is often uncritically repeated to this day. It tells the story of mostly male, white geniuses and innovators who, often against the spirit of the times, implemented their visions: from the young MIT students who repurposed a PDP-10 computer for the night to develop the game Spacewar! to the self-made millionaire and enfant terrible Nolan Bushnell, who triggered the first video game boom in the USA with the foundation of Atari.nan","In recent times, a shift in focus towards regional and national digital game history has become apparent - here, too, a similar trend can be observed in research and journalism. Graeme Kirkpatrick has dedicated himself to video game culture in the United Kingdom (Kirkpatrick 2015), Alexis Blanchet and Guillaume Montagnon researched the origins of the ""French Touch"" (Blanchet and Montagnon 2020), and Melanie Swalwell has dealt extensively with the origins of the so-called homebrew culture in Australia and New Zealand (Swalwell 2021). These first studies on a local history of digital games have impressively shown that these were not marginal notes of a primarily US-American-Japanese dynamic. Jaroslav Švelch was able to demonstrate in his study on the early history of digital games in Czechoslovakia that even behind the Iron Curtain and against all odds, an independent culture of digital games emerged in the 1980s (Švelch 2018).nannan","These preliminary studies made us increasingly aware of the urgent need for this research. To give one example, if one wants to better understand the success of the Anno series today, a look at the Ultimate History of Video Games is of no help. In the US-American video game chronicles, the phenomenon ""economic simulation and construction game"" is rarely or never mentioned. Fortunately, we are currently witnessing many simultaneously emerging and interconnected initiatives to research the respective history of digital games throughout Europe as well as in South America, Asia, Africa and Oceania. In Germany and Austria, several projects are currently in the making, and in Switzerland, a large SNF-Sinergia project on the research of local video game history is being funded from 2023 to 2027, in which four universities and colleges as well as 20 researchers are involved, including three of the four authors of this workshop report.nan","All these projects face a similar problem at the beginning: One basically knows, often from own experience, about games from the investigated geographical area, but there are only a few, incomplete lists or databases of these games - and sometimes none at all. However, such datasets - even if they are only rudimentary - are a basic prerequisite for most historical research questions, even if they are not primarily quantitative studies: How many games were developed in total in which period of time and how has this number changed? Which systems were particularly popular where and when? Which genres were popular when and where? How many developers were normally involved at which times? When and where did transnational cooperations take place?nan","This critical point does not apply to the collection work itself. After all, these are private initiatives that live from the unpaid collection and research work of individuals. They are a valuable resource and were very helpful for our work, but are not suitable as databases for research, also because they do not claim to be complete - but above all because they have not been scientifically critically reviewed.nan","Warum wir es für eine gute Idee gehalten haben, eine DACH-Spieledatenbank aufzubauen","Eugen Pfister, Aurelia Brandenburg, Adrian Demleitner, Lukas Daniel Klausner","Warum wir es für eine gute Idee 
gehalten haben, eine DACH-
Spieledatenbank aufzubauen
Eugen Pfister, Aurelia Brandenburg, Adrian Demleitner und Lukas Daniel Klausner
Zusammenfassung
Unser  Werkstattbericht  gibt  Einblick  in  den  Entstehungskontext  sowie  die  zugrundeliegenden
methodischen Überlegungen hinter der von den Autor*innen publizierten Spieledatenbank. Diese
wurde kollaborativ erarbeitet und führt digitale Spiele, die in Deutschland, Österreich und der
Schweiz bis zum Jahr 2000 entwickelt wurden. In diesem Bericht skizzieren wir neben unseren
Ausgangsüberlegungen und  den  verschiedenen  Arbeitsschritten  bei  der  Realisierung  außerdem
auch, auf welcher Datenbasis die Datenbank aufgebaut und geprüft wurde, was die Ziele des
Datenmodells sind und mit welchen Schwierigkeiten wir im Prozess der Erstellung konfrontiert
waren. Hiernach ordnen wir den aktuellen Stand der Spieledatenbank ein und geben einen Ausblick
auf die weiteren Pläne des Projekts. 
Schlüsselwörter
Game Studies, Spielgeschichte, local history, Datenbank, Datenmodellierung, Digitalisierung, 
Werkstattbericht
1. Einleitung und Motivation
Mit dem wachsenden Interesse von Forschung und Journalismus an digitalen Spielen geht auch ein
wachsendes Bewusstsein für ihre Geschichte einher. Hier zeigt sich rasch, dass das „neue“ Medium
mit – je nach gesetztem Anfangspunkt – mindestens fünfzig Jahren Geschichte gar nicht mehr so
jung ist. Es zeigte sich aber auch etwas Anderes: Rasch hat sich eine Art US-amerikanisch-japanische
Meistererzählung herauskristallisiert, die bis heute häufig unkritisch wiederholt wird. Sie erzählt eine
Geschichte von meist männlichen, weißen Genies und Innovatoren, die oft gegen den Zeitgeist ihre
Visionen umgesetzt haben: Von den jungen Studenten des MIT, die nächtens einen PDP-10-Rechner
zweckentfremdet haben, um darauf das Spiel  Spacewar! zu entwickeln, bis hin zum Self-made-
Millionär und Enfant terrible Nolan Bushnell, der mit der Gründung von Atari den ersten Videospiel-
Boom in den USA ausgelöst hat.
Später liest man vom großen Video Game Crash in den USA, von hunderttausenden Spielecartridges,
die  verschämt  in  der  Wüste  vergraben  wurden,  vom  Aufstieg  der  japanischen  Unternehmen
Nintendo und Sega und deren „Console Wars“. Diese Geschichte, wie wir sie zum Beispiel in Steven
Kents Ultimate History of Video Games lesen können (Kent 2001), ist nicht grundsätzlich falsch – sie
blendet aber quasi alle Länder abseits der USA, Japans und vielleicht noch Großbritanniens aus.
Dabei spürte man in Europa beispielsweise  nur  wenig  vom  Crash, weil  hier  Konsolen  nie  so
verbreitet waren wie in den USA. Und trotzdem wurde fast überall gespielt: auf Jahrmärkten, in
Spielhallen und zu Hause. In Europa hatten sich etwa dynamische Entwickler*innen-Netzwerke um
die hier populären Mikrocomputer gebildet: um den ZX Spectrum und den Amstrad CPC, vor allem
aber um den C64, den Commodore Amiga und MS-DOS-kompatible Computer. Um diese Plattformen
herum  entstanden  in  Europa,  aber  auch  in  Australien  und  Neuseeland  extrem  produktive
eigenständige Spielekulturen.
Erst in jüngster Zeit hat sich – auch hier zeigt sich ein ähnlicher Trend in Forschung und Journalismus
– der Fokus verstärkt auf die regionale und nationale digitale Spielegeschichte verlagert. Graeme
Kirkpatrick hat sich der Videospielkultur im Vereinigten Königreich gewidmet (Kirkpatrick 2015),
Alexis Blanchet und Guillaume Montagnon forschten den Ursprüngen des „French Touch“ nach
(Blanchet und Montagnon 2020) und Melanie Swalwell hat sich ausführlich mit den Ursprüngen der
sogenannten  Homebrew Culture in Australien und Neuseeland beschäftigt (Swalwell 2021). Diese
ersten Studien zu einer local history digitaler Spiele haben eindrücklich gezeigt, dass es sich hierbei
nicht um Randnotizen einer primär US-amerikanisch-japanischen Dynamik gehandelt hat. Jaroslav
Švelch konnte in seiner Studie zur frühen Geschichte digitaler Spiele in der Tschechoslowakei
nachweisen, dass es in den 1980er-Jahren sogar hinter dem Eisernen Vorhang und gegen alle
Widrigkeiten zur Entwicklung einer eigenständigen Kultur digitaler Spiele kam (Švelch 2018).
Durch diese Vorarbeiten wurde uns immer deutlicher bewusst, wie dringend notwendig diese
Forschung ist. Um ein Beispiel zu nennen: Will man heute etwa den Erfolg der Anno-Reihe besser
verstehen, hilft kein  Blick in die  Ultimate History of Video Games. In den US-amerikanischen
Videospielchroniken findet das Phänomen „Wirtschaftssimulation und Aufbauspiel“ selten bis nie
Erwähnung.  Zum  Glück  werden  wir  gerade  Zeug*innen  vieler  gleichzeitig  entstehender  und
miteinander vernetzter Initiativen zur Erforschung der jeweiligen Geschichte digitaler Spiele in ganz
Europa sowie auch in Südamerika, Asien, Afrika und Ozeanien. In Deutschland und Österreich sind
gerade mehrere Projekte im Entstehen begriffen, und in der Schweiz wird von 2023 bis 2027 ein
großes SNF-Sinergia-Projekt zur Erforschung der lokalen Videospielgeschichte finanziert, an dem vier
Universitäten und Hochschulen sowie 20 Forscher*innen beteiligt sind, unter anderem auch drei der
vier Autor*innen dieses Werkstattberichts.1
Alle diese Projekte stehen zu Beginn vor einem ähnlichen Problem: Man weiß grundsätzlich, oft aus
eigener Erfahrung, von Spielen aus dem untersuchten geografischen Raum, es gibt aber nur wenige,
unvollständige Listen oder Datenbanken dieser Spiele – und manchmal auch gar keine. Solche – und
seien  es  nur  rudimentäre  –  Datensätze  sind  aber  Grundvoraussetzung  für  die  meisten
1 Siehe auch das Blog zum Projekt unter https://chludens.hypotheses.org/.
geschichtlichen Forschungsfragen, auch wenn es keine primär quantitativen Studien sind: Wie viele
Spiele wurden insgesamt ungefähr in welchem Zeitraum entwickelt und wie hat sich diese Zahl
verändert? Welche Systeme waren wann wo besonders verbreitet? Welche Genres waren wann wo
populär? Wie viele Entwickler*innen waren zu welchen Zeitpunkten normalerweise beteiligt? Wann
und wo kam es zu transnationalen Kooperationen?
Egal, ob man sich für frühe Homebrew-Spiele interessiert, für Spiele, die für den Schulunterricht
eingesetzt wurden, oder für das Entstehen der ersten kommerziellen Entwicklungsstudios – um ein
Phänomen historisch erfassen zu können, ist es notwendig, zumindest einen rudimentären Überblick
über die Datenlage zu haben. Das zeigt sich auch daran, wie erschreckend schnell vergessen wird:
Auch in unserem Team hat sich herausgestellt, dass wir alle die Anzahl der Spiele, die bis zum Jahr
2000 entwickelt wurden, dramatisch unterschätzt hatten.
Aus den genannten Gründen war es für uns wichtig, eine Datenbank von Spielen für Deutschland,
Österreich und die Schweiz zu erstellen. Im Frühjahr 2023 haben wir, nach etwas über einem Jahr
Arbeit, eine erste (noch sehr unvollständige) Version unserer Arbeit in Open Access veröffentlicht
(Pfister et al. 2023), gerade um es anderen Forscher*innen, Journalist*innen oder auch einfach nur
Interessierten in Zukunft leichter zu machen. Wie es dazu kam, von den Herausforderungen und
Rückschlägen, aber auch von ersten Entdeckungen wollen wir im Folgenden berichten – beginnend
mit der Ausgangslage.
2. Quellenbasis
Es wäre vermessen, behaupten zu wollen, dass es bisher gar keine Spieledatenbanken für den
deutschsprachigen Raum gegeben hätte. Vielmehr ist es so, dass wir ohne die Vorarbeit von
tausenden Beitragenden gar nicht in der Lage gewesen wären, unsere Datenbank aufzubauen.
Allerdings  war  die  Ausgangslage  gerade  für  unsere  Bedürfnisse  unzufriedenstellend:  Die
englischsprachigen Listen auf Wikipedia2 geben wirklich nur einen allerersten, sehr begrenzten
Einblick in die Entwicklungsgeschichte der drei Länder, insbesondere im Hinblick auf die frühe
Geschichte digitaler Spiele.
Weitaus ergiebiger sind da schon einschlägige Spiele-Datenbanken. Eine erste Kategorie von diesen
sind  große,  webbasierte  Angebote, namentlich  MobyGames (http://mobygames.com/)  und  die
Universal  Videogame  List (https://www.uvlist.net/).  Beides  sind  umfassende,  crowdgesourcte
Datenbanken, die für unser Projekt sehr hilfreich beim Nachschlagen von Daten und Fakten zu
2 Konkret also „Category:Video games developed in Germany“ (https://en.wikipedia.org/w/index.php?
title=Category:Video_games_developed_in_Germany), „Category:Video games developed in 
Switzerland“ (https://en.wikipedia.org/wiki/Category:Video_games_developed_in_Switzerland) und 
„List of video games developed in Austria“ 
(https://en.wikipedia.org/wiki/List_of_video_games_developed_in_Austria).
bereits identifizierten Spielen waren. Was sie jedoch nicht einfach erlauben, ist die Suche nach
Ländermerkmalen  der  beteiligten  Personen  oder  Firmen.  MobyGames,  die  wahrscheinlich
vollständigste internationale Datenbank digitaler Spiele, erlaubt es etwa gar nicht, nach den Ländern
der Entwickler*innen zu filtern oder zu durchsuchen, und auch hier hat sich im Zuge unserer
Recherchen gezeigt, dass insbesondere frühe im DACH-Raum entwickelte Spiele oft fehlen. Die
deutschsprachige Online-Games-Datenbank (OGDB, https://ogdb.eu/) wiederum lässt sich zwar nach
Herkunftsland filtern, aber auch hier fehlen viele Spiele aus den 1980er- und 1990er-Jahren. Vor
allem aber eignet sich die OGDB nur bedingt für wissenschaftliche und journalistische Recherchen,
da sie sich zum einen nicht nach Jahren ordnen lässt und zum anderen alle weiterführenden
Angaben zu den Entwicklerstudios, Publishern und allen beteiligten Entwickler*innen fehlen. Die
dänische Datenbank Play:Right (https://
 
 www.playrigh
 
 t.dk/
 
 ) schließlich lässt sich nach Herkunftsland
filtern und dann nach Erscheinungsjahr sortieren, ist aber ebenfalls sehr unvollständig.3
Dieser Kritikpunkt trifft auch auf eine weitere essenzielle Art von Informationsquellen zu, nämlich
jene Datenbanken, welche sich auf einzelne Plattformen bzw. Systeme fokussieren. Beispielhaft
aufzuführen  wären  unter  anderem  Hall  of  Light (https://hol.abime.net/)  und  Lemon  Amiga
(https://www.lemonamiga.com/),
 C64-Wiki 
(https://www.c64-wiki.de/)  und
 Gamebase  64
(http://www.gamebase64.com/) oder Atari Mania (http://www.atarimania.com/). Diese Plattformen
sind  in  ihrer  Organisation  oftmals  an  Wikis  angelehnt.  Das  heißt,  sie  funktionieren  dank  der
freiwilligen Teilnahme ungezählter interessierter Personen und Enthusiast*innen. Diese investieren
ihre Freizeit, um die Plattformen mit Wissen zu füttern. Teilweise schlägt sich das in umfassenden
(für die Forschung extrem wertvollen) Datensammlungen nieder: Im C64-Wiki etwa finden sich zu
vielen kleinen Spielen neben Beschreibungen auch Anleitungen und Lösungen, Karten, Screenshots,
Scans der Cover usw. Aus der Sicht der Wissenschaft leiden diese Plattformen aber unter den
gleichen Problemen wie auch die zuvor genannten crowdgesourcten Quellen: Die Provenienz der
Daten der einzelnen Einträge sind nicht oder nur schwer nachzuvollziehen.
Es  ist  uns  an  dieser  Stelle  wichtig  darauf  hinzuweisen,  dass  es  sich  bei  diesen  kritischen
Anmerkungen nicht um eine Kritik an der Sammlungsarbeit an sich handelt. Schließlich handelt es
sich hierbei um Privatinitiativen, die von der unbezahlten Sammel- und Recherchearbeit Einzelner
leben. Sie sind eine wertvolle Ressource und waren sehr hilfreich für unsere Arbeit, eignen sich aber
nicht  als  Datenbanken  für  die  Forschung,  auch  deshalb,  weil  sie  gar  keinen  Anspruch  auf
Vollständigkeit stellen können – vor allem aber, weil sie nicht wissenschaftlich kritisch überprüft
wurden. 
3 Bis inklusive 1999 werden etwa nur 12 österreichische, 168 deutsche und 3 Schweizer Spiele 
aufgelistet.
Unser Ansatz für die Erstellung unserer eigenen Liste beinhaltete deshalb neben der zweifachen
Kontrolle auch die Triangulation von Quellen. Wir nehmen an, dass diese Quellen ihr Wissen auch
untereinander teilen und so unter Umständen Falschinformationen wiederholen. Daher haben wir in
Ansätzen  versucht,  die  Informationen  mit  Quellen  abzugleichen,  welche  nicht  auf  diesen
spezialisierten Plattformen verzeichnet waren. Eine interessante Differenz in diesen spezialisierten
Plattformen lässt sich an den erweiterten Suchmasken ausmachen. Einige Plattformen, wie zum
Beispiel Hall of Light und Atari Mania, hatten tatsächlich Optionen für die Suche nach Land oder
Sprache. Andere, etwa Gamebase 64, ließen sich stattdessen danach durchsuchen, wer ein Spiel
gecrackt hatte.4
Zuletzt haben wir außerdem versucht, die Metadaten zu einzelnen Spielen auch darüber hinaus mit
entsprechenden Einträgen in größeren Datenbanken abzugleichen, die nicht oder nur schlecht für
unsere Zwecke durchsuchbar waren, aber die Überprüfung von Informationen erlauben – Seiten wie
etwa die Interactive Fiction Database (IFDB, https://ifdb.org/), bei der es sich ebenfalls um ein Wiki-
ähnliches Projekt handelt, die aber nicht auf ein System, sondern auf ein Genre fokussiert ist. Diese
Seiten katalogisieren so z. B. allgemein Spiele, sind aber mehr auf eine Veröffentlichung und
Archivierung von kleinen Projekten und/oder ihren Metadaten ausgelegt und nicht darauf, Spiele
unter speziellen Kriterien zu recherchieren. Die komplexeste Zugriffsmöglichkeit stellte hier noch die
Sammlung des  Internet Archives (https://archive.org/details/classicpcgames) dar, das inzwischen
auch im großen Stil ältere Software zum Download oder sogar direkt im Browser zugänglich macht
und so teilweise durch Filtermöglichkeiten der Suche oder untereinander verlinkte Einträge die
Recherche zu einzelnen Spielen erleichtern kann. Außerdem hostet das Internet Archive schön
länger  eine  umfassende  Sammlung  an  Schriftquellen  zu  digitaler  Spielgeschichte,  wie  etwa
Spielemagazine  und  Werbeanzeigen,  mit  denen  sich  ebenfalls  z.  B.  Informationen  aus
crowdgesourcten Angeboten gegenprüfen lassen.
Während diese Seiten allerdings teils ausführliche Metadaten aufweisen, sind sie alle primär dafür
gedacht, das digitale Objekt eines Spiels oder eines Digitalisats zugänglich zu machen, und nicht
dafür, eine nach bestimmten Kriterien geordnete Spielliste aufzustellen. Alle Datenbanken und
Seiten,  welche  wir  für  unsere  Recherchen  beigezogen  hatten,  operieren  auf  der  Ebene  des
Einzelobjektes. Die Metadaten einzelner Spiel-Einträge waren oft genügend bis ausführlich, wir
konnten jedoch mit keiner der Seiten eine für die Forschung brauchbare geordnete Spielliste
erstellen. Die Organisation von Wissen und das zugehörige Datenmodell erfolgt also primär über
einige wenige normierte Felder wie etwa die*den Ersteller*in eines Eintrags in Kombination mit
einem Schlagwort- und/oder Kategorie-Sammlungssystem, das allerdings abhängig von der*dem
4 Das ist für uns zwar nicht unmittelbar relevant, zeigt jedoch auf, wie eine Suchmaske etwas über 
das epistemologische Modell einer Plattform aussagen kann.
Bearbeiter*in eines Eintrags variieren kann, wenn verschiedene User*innen zwar inhaltlich dasselbe
meinen, es aber unterschiedlich verschlagworten. Bleibt schließlich eine Ausnahme zu erwähnen:
der  Swiss  Games  Garden (https://swissgames.garden/).  Die  Sammlung  entstand  aus  einer
Kooperation des Schweizer Entwicklers David Stark und der zwei Forscher David Javet und Yannick
Rochat, wobei Letzterer auch Kollege in unserem SNF-Sinergia-Projekt Confederatio Ludens ist. Die
Datenbank ist gerade erst im Aufbau begriffen und wir haben bereits dazu beigetragen, sie mit
unseren Funden weiter auszubauen. Wir möchten dabei betonen, dass es nie unser Ziel war, eine
„wissenschaftliche“  Konkurrenz  zu  bestehenden  Datenbanken  aufzubauen,  sondern  unsere
Datensammlung so offen zu gestalten, dass sie potenziell allen zur Verfügung steht. Im Swiss Games
Garden und in Wikidata (siehe unten) haben wir selbst unsere Daten wiederum eingepflegt.
3. Zum Aufbau einer Alpha-Version
Ausgehend von unserer Forschungsfrage und der Quellenbasis gab es nun in unserer Wahrnehmung
zwei Möglichkeiten: Der wissenschaftlich saubere Weg wäre es gewesen, in Form eines finanzierten
Projekts eine neue Infrastruktur aufzubauen, mit mehreren bezahlten Mitarbeiter*innen im Vorfeld
den Aufbau der Datenbank zu strukturieren, ein kontrolliertes Vokabular zu erstellen und dann
gezielt mit der Suche und Befüllung der Datenbank anzufangen. Erfahrungsgemäß bräuchte ein
solches Projekt eine Vorlaufzeit von mindestens einem Jahr für Recherchen im Vorfeld und das
Schreiben des Antrags. Dann bestünde je nach Förderinstrument eine 10- bis 20-prozentige Chance,
dass das Projekt auch finanziert würde, woraufhin wir drei bis vier Jahre Zeit hätten, es umzusetzen.
Vorteil wäre, dass viele schwierige Fragen im Vorfeld geklärt werden könnten und das Team sehr
gezielt und aufeinander abgestimmt bei der Suche vorgehen könnte. Nachteil wäre die lange
Vorbereitungszeit des Projekts und dass die Daten dann erst nach vier Jahren zur Verfügung
stünden, vor allem aber, dass die Aussichten auf Finanzierung insgesamt gering wären. Was also tun,
wenn  das  Projekt  nicht  finanziert  würde?  Wir  könnten  natürlich  das  Projekt  umschreiben,
nachbessern und auf eine Finanzierung im nächsten Jahr hoffen – im besten Fall.
Aus diesen Gründen hat sich Eugen Pfister im Frühjahr 2022 für einen anderen Zugang entschieden.
Zu diesem Zeitpunkt hatte er schon Listen an Schweizer und österreichischen Spielen angelegt, ihm
fehlten aber wichtige Informationen zu einem der größten Spielmärkte Europas, mit dem die
Schweiz und Österreich eng verwoben waren: Deutschland. Deshalb nutzte er die Gelegenheit eines
Lehrauftrags an der Heinrich-Heine-Universität Düsseldorf, um sich gemeinsam mit seinen dortigen
Geschichtsstudent*innen  in  einem  Kurs  auf  die  „Spurensuche  [nach  den]  frühen  Spiele-
Entwickler*innen im deutschsprachigen Raum“ zu begeben. Gemeinsam mit den Student*innen
Constantin Bintz, Marlon Duncan Bonsch, Lars Brandes, Lisa Bresgott, Rika Bunse, Noah Dix, Victoria
Hou, Daniel Kaspereit, Petros Kiorpes-Betchawas, Simon Körner, Rabea Kuschel, Christian Mischke,
Sebastian Müller, Tanja Pabst, Ann-Kristin Potthast, Deniz Sargin, Clarissa Schiffer, Jan Stockschläger
und Ebru Yaylali sammelte er im Rahmen der Lehrveranstaltungen Titel für eine gemeinsame
Datenbank in Form einer Google-Sheets-Tabelle. Zuerst wurden in Kleingruppen jene Plattformen
durchsucht, die sich (zumindest über Umwege) nach Herkunftsländern filtern ließen: So wurde zum
Beispiel  auf  den  Plattformen  Lemon  Amiga  und  Interactive  Fiction  Database  nach  Spielen  in
deutscher Sprache gesucht.5 In einem nächsten Schritt wurde dann auch auf anderen Plattformen
nach Studios und einzelnen Entwickler*innen gesucht, die eindeutig dem DACH-Raum zugeordnet
werden konnten. In der Folge wurden alle Listings des  Computronic-Magazins aufgenommen, die
über  das  Internet  Archive  verfügbar  waren.  Die  Kleingruppen  kontrollierten  dabei  jeweils  die
Eingaben anderer Kleingruppen. So entstand zuerst eine Alpha-Version und nach gemeinsamer
Überarbeitung eine gesäuberte Beta-Version mit bereits ca. 600 Titeln, darunter aber nach wie vor
einige Dubletten und Falschzuordnungen. Basierend auf dieser Liste haben die Student*innen dann
historische Fallstudien einzelner Titel erstellt (z. B. Bonsch und Bunse 2023; Bresgott et al. 2022;
Müller und Sargin 2023). Nach Abschluss des Semesters hat Ann-Kristin Potthast unter Mitarbeit von
Marlon Duncan Bonsch, Lisa Bresgott, Rika Bunse, Clarissa Schiffer und Jan Stockschläger geholfen,
die Datenbank gemeinsam mit Eugen Pfister und Lukas Daniel Klausner noch einmal gründlich zu
kontrollieren. Zu jedem Titel wurden zusätzliche Quellen gesucht und angegeben. Doppelnennungen
– zum Beispiel bedingt durch die Existenz mehrerer Namen für ein und dasselbe Spiel – wurden
aufgelöst. Außerdem hat Eugen Pfister immer wieder freie Minuten genutzt, um nach weiteren
Quellen, Studios und Entwickler*innen zu suchen.
4. Von der Beta- zur Gamma-Version
Mit Beginn des SNF-Sinergia-Projekts kamen dann die Projektmitglieder Adrian Demleitner, Addrich
Mauch und Aurelia Brandenburg hinzu, welche die mittlerweile knapp 1200 Titel noch einmal zu
kontrollieren halfen. Aufbauend auf der Beta-Version haben wir anschließend die Gamma-Version so
entwickelt, wie sie inzwischen auch online frei abrufbar ist (Pfister et al. 2023). Dabei wurden wir mit
denselben Problemen konfrontiert, wie sie häufig auftreten, wenn man sich darum bemüht, wenig
aufgearbeitete und komplexe historische Daten unter einem bestimmten Aspekt zu strukturieren
und zu säubern. So waren zum Beispiel die Genres der Spiele eine relevante Information und damit
ein wichtiges Feld, auch um einen einzelnen Datensatz später einordnen zu können – aber gerade
Genreeinteilungen sind meist fließend und schlecht zu standardisieren. Genauso waren wir mit einer
großen  Bandbreite an Qualität  der  recherchierbaren  Informationen  pro Titel konfrontiert: Für
5 https://ifdb.org/search?sortby=old&searchfor=language%3Agerman (Suche nach Sprache, „earliest 
publications first“) und https://www.lemonamiga.com/games/advanced_search.php (Advanced 
Search, suchen nach „Language: German“).
manche Spiele ließen sich verhältnismäßig leicht z. B. über MobyGames umfangreiche Listen der
beteiligten Entwickler*innen recherchieren, die dann fast zu umfangreich für ein einzelnes Feld in
der Datenbank waren, in anderen Fällen war auch mit genauerer Prüfung fürs Erste nur ein Studio
oder ein Publisher, aber keine individuellen Entwickler*innen zu eruieren.
Gerade Entwickler*innen (aber auch Publisher) boten auch über die bloße Informationsdichte hinaus
einige Probleme in diesem Arbeitsschritt, weil beides immer wieder die Frage aufwarf, wann ein
Spiel nun denn tatsächlich ein Spiel aus dem DACH-Raum war und wann nicht. In manchen Fällen
lassen sich etwa einzelne Team-Mitglieder  unter den Entwickler*innen (z.  B. bei  Rayman  der
Schweizer Yann Le Tensorer) ausmachen, die aus dem DACH-Raum stammen und so ein gutes
Beispiel für eine internationale Vernetzung unter Entwickler*innen darstellen, während aber die
Studios dieser Spiele ihren Sitz außerhalb Deutschlands, Österreichs oder der Schweiz hatten. Solche
Nuancen verdeutlichen natürlich ganz automatisch, dass gerade in Hinblick auf digitale Spiele
nationale Grenzen fließend sind und auch diese Art Sonderfälle sind (mit entsprechendem Vermerk)
in der Gamma-Version aufgeführt – nur führen sie konkret vor Augen, wie schwer sich historische
Daten Datenbankstrukturen unterwerfen lassen.
Dazu kam auch, dass wir uns durch unseren möglichst inklusiven Zugang der Erfassung (möglichst)
aller  Spiele  zwar  bewusst  gängigen  Kanonisierungsprozessen  dessen,  was  heute  meist  als
„Gamingkultur“ gilt, widersetzt haben, dieser Zuschnitt aber auch dazu führt, dass auch die fertige
Gamma-Version  einige  Titel  enthält,  über  die  wir  über  ihre  bloße  Existenz  hinaus  wenig
Informationen erfassen konnten. In manchen Fällen lag das auch schon an der Publikationsform:
Spiele wie Time-Rally (1987) wurden z. B. als Listings in Computerspielmagazinen – in diesem Fall der
Computronic – veröffentlicht und entsprachen damit grundsätzlich unseren Kriterien, sind aber
natürlich nicht ohne Weiteres im selben Maße verarbeitbar wie viele kommerziell vertriebene
Spiele.
5. Ausblick
Wir sind uns dessen bewusst, dass unsere Datenbank – zum derzeitigen Zeitpunkt wie auch in
absehbarer Zukunft – unvollkommen ist. So haben wir bisher nur die Listings aus einem Magazin
aufgenommen. Wir müssen sogar davon ausgehen, dass selbst viele der kommerziell vertriebenen
Spiele nach wie vor fehlen. Des Weiteren ist die Zuordnung zu Genres nach wie vor problematisch.
Das liegt bis zu einem gewissen Grad in der Natur der Sache, weil es hierzu in der Forschung nach
wie vor keinen Konsens gibt. Zugleich ist eine Zuordnung zu Genres gerade für unsere Forschung
hoch  relevant  –  denken  wir  nur  an  die  eingangs  gestellte  Frage  zur  deutschsprachigen
Sonderstellung  des  Genres  Wirtschaftssimulation.  Außerdem  verschwinden  in  der  derzeitigen
Tabellenstruktur  die  beteiligten  Entwickler*innen,  seien  sie  nun  Programmierer*innen,
Grafiker*innen, Autor*innen usw., in einer Kolonne der Tabelle.
Diese oft frustrierende Ungenauigkeit haben wir aber bewusst in Kauf genommen, eben weil wir uns
entschieden haben, nicht auf eine Finanzierung zu warten, sondern über eine lange Zeit hinweg in
unserer Freizeit voranzutreiben. Es war uns wichtig, möglichst bald erste Daten zur Verfügung zu
stellen – nicht nur für unsere eigene Forschung, sondern für alle, die daran interessiert sind.
Manchmal ist es auch in  der  Wissenschaft notwendig, „quick and dirty“ vorzugehen, um die
Forschung weiter anzustoßen. Es erscheint doch erstaunlich, dass es bis 2022 keine einschlägige, gut
zugängliche Online-Datenbank für Game Studies unter dem Blickwinkel der local history gab. Und wir
selbst haben schon jetzt enorm von der Arbeit profitiert – so ist das Sample von Schweizer Spielen
für das SNF-Sinergia-Projekt von knapp über 50 auf 122 angestiegen, übrigens auch dank der
Recherchen unserer Kolleg*innen aus dem Projekt. Auch zeigen sich schon in dem vorhandenen
Sample an Spielen erste interessante Muster, die es weiter zu erforschen gälte. So fällt zum Beispiel
auf,  dass  gerade  in  den  1980er-  und  1990er-Jahren  nur  wenige  Spiele  in  den  größten
deutschsprachigen Städten entwickelt wurden und kleine bzw. mittelgroße Städte hier überwiegen.
Im selben Zeitraum finden sich in vielen Entwickler*innenteams öfter der gleiche Nachname, was auf
Geschwister- oder Ehepaare schließen ließe. Außerdem kann man bereits sehr schön Konjunkturen
einzelner Spielmechaniken nachzeichnen.
Der nächste Schritt wäre es, die Daten weiter zu säubern, sich der ungeliebten Genre-Frage zu
stellen und allgemein saubere Metadatenstandards zu diskutieren. Dabei stehen wir aber erst am
Anfang unserer Arbeit. Es ist unser Ziel, an der Datenbank beständig weiterzuarbeiten. Zugleich
wünschen wir uns aber auch, dass möglichst viele von dieser Vorarbeit – denn mehr ist es bislang
nicht  –  profitieren,  weswegen  wir  schon  die  Gamma-Version  trotz  all  ihrer  Leerstellen  und
potenziellen Fehler im Rahmen einer CC-BY-SA-Lizenz online gestellt haben. Die Daten gehören nicht
uns, sondern allen, die etwas damit anfangen können und wollen.
Parallel sind wir auch aktiv bemüht, die Ergebnisse in andere Datenbanken einzuarbeiten, zuallererst
den bereits genannten Swiss Games Garden, aber auch – und hier für ein potenziell weitaus
größeres  Publikum  –  in  das  Wikimedia-Projekt  Wikidata.  Während  der  Integration  unserer
bisherigen  Daten  in  Wikidata  begegnen  wir  erneut  ähnlichen  Herausforderungen  wie  beim
Aufbereiten der Liste selbst. Das WikiProject  Video Games,6 eine Arbeitsgruppe, die sich mit der
Eintragung von digitalen Spielen in Wikidata befasst, hat ein eigenes Datenmodell entwickelt und im
Zuge dessen Vorschläge für Genres und andere Attribute erstellt. Diese decken sich nicht immer mit
unserer  Liste, weshalb zusätzlicher  Aufwand erforderlich ist  und Konsense oder Kompromisse
gefunden werden müssen. Wir nehmen während dieses Prozesses aktiv an der Arbeitsgruppe teil
6 https://www.wikidata.org/wiki/Wikidata:WikiProject_Video_games
und haben uns auch bei Jean-Frédéric Berthelot, welcher seit Langem an dieser Arbeitsgruppe
mitwirkt, um Unterstützung bemüht. Laut Berthelot hat Wikidata nicht den Anspruch, alle anderen
Plattformen und Datenbanken zu ersetzen, sondern soll wie das Pilzmyzel im Wald7 verschiedene
Spieledatenbankprojekte miteinander verbinden. Daher ist die Verknüpfung zu den Einträgen eines
Spiels auf anderen Seiten von hoher Bedeutung.
Das endgültige Ziel unseres Projekts ist es, verschiedenen Nutzer*innengruppen eine umfassende,
möglichst vollständige und wissenschaftlich validierte Datenquelle zur Verfügung zu stellen. Nicht
zuletzt wäre dies natürlich auch für journalistische Recherche dienlich, wenn sich Journalist*innen
nicht auf unsichere Informationen von privaten Websites verlassen möchten.  Es ist eine große
Freude zu beobachten, wie viele Menschen bereits in den ersten Wochen nach Veröffentlichung auf
unsere Datenbank reagierten. Teilweise kamen einzelne Ergänzungen herein, teilweise ganze Listen
mit mehreren hundert Titeln, die es nun einzuarbeiten gilt. Vor allem aber freut uns, wie viele
Kolleg*innen sich von unserer Arbeit inspiriert zeigen – und die Datenlage in Zukunft hoffentlich
noch besser machen.
Literatur
Blanchet, A. & Montagnon, G. (2020). Une histoire du jeu vidéo en France, vol. 1: 1960–1991: Des
labos aux chambres d'ados. Houdan: Pix’n Love.
Bonsch, M. D. & Bunse, R. (2023). „Eine Klinge die alle Orks fürchten!“: eine Fallstudie zu „Das
Schwarze
 
Auge:
 
Die
 
Schicksalsklinge“
 
(1992).
 Spiel-Kultur-Wissenschaft.
http://spielkult.hypotheses.org/4040
Bresgott, L., Dix, N. & Potthast, A.-K. (2022). Fallstudie: Indiana Jones’ Greatest Adventures. Spiel-
Kultur-Wissenschaft. http://spielkult.hypotheses.org/3574
Kent, S. L. (2001). The Ultimate History of Video Games: From Pong to Pokémon and Beyond – The
Story Behind the Craze That Touched Our Lives and Changed the World. Shreveport, LA: Prima
Publishing.
Kirkpatrick, G.  (2015).  The Formation  of  Gaming  Culture: UK  Gaming  Magazines, 1981–1995.
London: Palgrave Macmillan.
Müller, S. C. H. & Sargin, D. (2023). Kampf der (Unterwasser-)Kulturen. Fallstudie Schleichfahrt. Spiel-
Kultur-Wissenschaft. http://spielkult.hypotheses.org/3941
Pfister, E., Brandenburg, A., Demleitner, A., Klausner, L. D., Mauch, A. & Potthast, A.-K. (2023).
Historische
 
DACH-Spieledatenbank
 
(Gamma-Version).
 Spiel-Kultur-Wissenschaft.
http://spielkult.hypotheses.org/3999
7 https://commonists.wordpress.com/2019/10/10/wikidata-the-underground-fungus-in-the-vast-forest-
that-is-the-internet/
Švelch,  J.  (2018).  Gaming  the  Iron  Curtain:  How  Teenagers  and  Amateurs  in  Communist
Czechoslovakia Claimed the Medium of Computer Games. Cambridge, MA: MIT Press.
Swalwell, M. (2021). Homebrew Gaming and the Beginnings of Vernacular Digitality. Cambridge, MA:
MIT Press.
"
"During deep sleep and under anesthesia spontaneous patterns of cortical activation frequently take the form of slow travelling waves. Here we show how data recorded from transgenic mice under anesthesia can be processed to analyze sources, sinks and patterns of flow. To make the best possible use of the data novel means of data processing are necessary. Therefore, we (1) give a an brief account on processes that play a role in generating slow waves and demonstrate (2) a novel approach to characterize its patterns in GCaMP recordings.nan","Slow waves represent an important yet highly variable neural phenomenon. Thus methods are required which allow for a systematic measurement of slow wave properties. Previous work that described different types of slow waves relied on manually crafted shape parameters such as the slope of the rising and falling edge of the slow waves in EEG or the spatial extent (local/widespread) of cortical coverage [4]. Some invasive neuroimaging studies have focused on patterns of the spread of activity. For example, the wavefront is measured using delay maps which indicate the temporal offset of an event for every pixel relative to its global onset [3].nan",Townsend and Gong [5] suggest an approach to characterize more diverse temporo-spatial properties of slow waves in GCaMP recordings by the kernel-based detection of specific patterns in the vector fields of Dense Optical Flow such as spirals or saddles.nannan,"We considered related methods for structural MRI [6], extend on the idea of an event related slow wave analysis [3] as well as the one of using Optical Flow [5] and suggest a technique that enables a novel perspective on slow waves as events with source- and sink-regions and specific patterns of directional flow: The combination of Helmholtz-Decomposition and Optical Flow for fluorescence microscopy. It allows to measure properties of events that can incorporate several oscillations even if they have a poor signal-to-noise ratio, occur simultaneously and overlap.nan",The approach can help in improving our understanding of neural processing in the brain during sleep and under anaesthesia. This paper is structured as follows. In section 2 we briefly explain the mechanisms that generate slow waves during sleep and anaesthesia. Section 3 introduces the approach of using Helmholtz-Decomposition and Optical flow with GCaMP data and the results achieved with it are presented in section 4. The last section summarizes and gives a critical discussion on the limitations of the results and the presented approach.nan,We demonstrate a new method to characterize neocortical slow waves using fluorescence microscopy. It relies on the Helmholtz-Decomposition of Dense Optical Flow and captures the global dynamics of spread. It shows that different types of slow waves form clusters with respect to different features.nan,Helmholtz-Decomposition and Optical Flow: A new method to characterize GCamP recordings,"Michael Gerstenberger, Dominic Juestel, Silviu Bodea","1
Helmholtz-Decomposition and Optical Flow:
A new method to characterize GCamP recordings
Michael Gerstenberger, Dominik Juestel and Silviu Bodea
Abstract—During deep sleep and under anaesthesia sponta-
neous patterns of cortical activation frequently take the form of
slow travelling waves. Slow wave sleep is an important cognitive
state especially because of its relevance for memory consolidation.
However, despite extensive research the exact mechanisms are
still ill-understood. Novel methods such as high speed widefield
imaging of GCamP activity offer new potentials. Here we show
how data recorded from transgenic mice under anesthesia can
be processed to analyze sources, sinks and patterns of flow. To
make the best possible use of the data novel means of data
processing are necessary. Therefore, we (1) give a an brief account
on processes that play a role in generating slow waves and
demonstrate (2) a novel approach to characterize its patterns
in GCamP recordings. While slow waves are highly variable, it
shows that some are surprisingly similar. To enable quantitative
means of analysis and examine the structure of such prototypical
events we propose a novel approach for the characterization
of slow waves: The Helmholtz-Decomposition of gradient-based
Dense Optical Flow of the pixeldense GCamP contrast (df/f). It
allows to detect the sources and sinks of activation and discern
them from global patterns of neural flow. Aggregated features can
be analyzed with variational autoencoders. The results unravel
regularities between slow waves and shows how they relate to
the experimental conditions. The approach reveals a complex
topology of different features in latent slow wave space and
identifies prototypical examples for each stage.
Index Terms—Helmholtz-Decomposition, Optical Flow; Slow
Waves; Optical Imaging; GCamp Imaging
I. INTRODUCTION
While stimulus dependent activity can be observed during
wakefulness, spontaneous patterns of activation dominate in
stages of deep sleep [1]. Similarly, fast neuronal firing is
replaced by slow, traveling waves of activation during anaes-
thesia [2], [3]. Neocortical slow waves can be captured by
fluorescence microscopy of GCaMP activity in transgenic mice
with a sampling rate of up to 100Hz.
Slow waves represent an important yet highly variable neu-
ral phenomenon. Thus methods are required which allow for
a systematic measurement of slow wave properties. Previous
work that described different types of slow waves relied on
manually crafted shape parameters such as the slope of the
rising and falling edge of the slow waves in EEG or the
spatial extent (local/widespread) of cortical coverage [4]. Some
invasive neuroimaging studies have focused on patterns of the
spread of activity. For example, the wavefront is measured
using delay maps which indicate the temporal offset of an
event for every pixel relative to its global onset [3]. Townsend
D. Juestel leads the Optoacoustic Lab at the Helmholtz-Center Munich,
Germany. S. Bodea is Member of the Westmeyer Lab at TU Munich and M.
Gerstenberger was Research Associate at Fraunhofer HHI Berlin, Germany.
E-Mail the corresponding author at michael.werner.gerstenberger@gmail.com.
Manuscript submitted 12/2023.
and Gong [5] suggest an approach to characterize more
diverse temporo-spatial properties of slow waves in GCamP
recordings by the kernel-based detection of specific patterns
in the vector fields of Dense Optical Flow such as spirals or
saddles.
We considered related methods for structural MRI [6], extend
on the idea of an event related slow wave analysis [3] as well
as the one of using Optical Flow [5] and suggest a technique
that enables a novel perspective on slow waves as events
with source- and sink-regions and specific patterns of di-
rectional flow: The combination of Helmholtz-Decomposition
and Optical Flow for fluorescence microscopy. It allows to
measure properties of events that can incorporate several
oscillations even if they have a poor signal-to-noise ratio, occur
simultaneously and overlap. The procedure aims to describe
slow waves by a dense yet interpretable set of features that
includes the shape of the spatially averaged df/f, the location
of sources and sinks and the direction of flow. To visualize
the polymorphism of slow waves and identify prototypical
slow waves that are most characteristic for each experimental
condition embedding vectors are computed for each event
using autoencoders. We test our novel method using a GCamP
dataset of mice including six levels of isoflurane. The approach
can help in improving our understanding of neural processing
in the brain during sleep and under anaesthesia.
This paper is structured as follows. In section 2 we briefly
explain the mechanisms that generate slow waves during sleep
and anaesthesia. Section 3 introduces the approach of using
Helmholtz-Decomposition and Optical flow with GCamP data
and the results achieved with it are presented in section 4. The
last section summarizes and gives a critical discussion on the
limitations of the results and the presented approach.
II. SLOW-WAVES AND DELTA OSCILLATIONS
A large body of literature addresses slow oscillations in
the brain. Slow waves in the delta range (0.5-4 Hz) can be
identified in electroencephalograms (EEG) during deep sleep
and under anaesthesia. Neurons that switch between up and
down states in the respective frequency exist in thalamus and
arguably trigger slow waves. Hence, this kind of slow waves is
referred to as thalamocortical slow wave [1], [7]. A different
type of slow waves that occurs with a frequency below 1Hz
has been studied as well[2]: Neocortical slow oscillations. As
they do not necessarily occur in regular time intervals they are
also referred to as neocortical slow waves here. Note also that
the exact frequency depends on the measuring technique. The
peak frequency in ECoG tends to be higher as compared to
GCamp imaging due to implicit temporal smoothing as a result
arXiv:2401.11008v1  [cs.CV]  19 Jan 2024
2
(a) Oscillatory centers in the brain
(b) GCamP and ECoG signatures of slow waves
(c) Segmentation of Slow Waves
Fig. 1. Neural oscillators, delta oscillations and slow waves
of the lower sampling rate. This can be shown using publicly
available data from [8] by computation of the frequency power
of ECoG and the aligned GCamP signal. Fig. 1b shows the
spatially averaged df/f and ECoG signals on the left and their
Fourier spectrogram on the right. While the peak amplitute is
0.9 Hz in the earlier signal domain it is only 0.2 Hz in the
latter.
Both electrophysiological recordings as well as fluorescence
microscopy have been used to investigate neocortical slow
waves [3], [9]. Neocortical neurons can oscillate in isolation
even in vitro [10]. However it was found that slow waves and
subcortical signals often occur in an orchestrated way. This
holds not only for thalamus. Slow waves arguably also bind
together spindles and delta waves [1]. While named signals
are of different origin, one could hence consider them to be
the signature of a single, yet distributed process.
The question how bistable states arise from the interaction of
cells in neural networks has been addressed using spiking net-
work models. They provide an explanation for the occurrence
of neocortical slow waves during deep sleep and under anaes-
thesia. The circumstance that several models explain slow
oscillations highlights not only that more then one explanation
is possible, but also that different kinds of processes might
play a role [11]. While certain characteristics of slow waves
differ, bistable states occur both during sleep and anaesthesia
in vivo[11] and even spontaneously in vitro [10].
In contrast to anaesthesia, sleep is a vegetative state. While
slow wave sleep is promoted by several mechanisms including
the circadian cycle and the release of melatonin that alters neu-
ral excitability, sleep spindles of thalamic origin are assumed
to be the trigger for a transition to deep sleep [12]. During slow
wave sleep cortex resides in a bistable state with decreased
excitability. This decrease in excitation is achieved by a
suppression of excitatory input from the ascending reticular
activation system (ARAS). As outlined above slow waves may
occur spontaneously but can also be triggered by other signals
in such states [1]. The interaction of various neural generators
of rhythmic activity is shown by Fig. 1. Slow wave sleep alter-
nates with REM stages during normal sleep and occurs even
in cerveau isol´e preparations when excitation from the ARAS
is fully absent. A putative function of neocortical slow waves
is memory consolidation. The assumed modes of action have
been described in the hippocampo-neocortical-dialog model.
Empirical results support its core hypothesis that memory
replay occurs during sleep and includes both hippocampus
and neocortex. Arguably sleep slow waves represent a neural
signature of this process[13].
The emergence of slow waves under anaesthesia has been
studied on a cellular level. Isoflurane has inhibitory effects
as it increases K+ channel leakage currents and hence de-
creases the number of positively charged ions in the cells,
making them more negative. Isoflurane anaesthesia manifests
in the form of higher outward currents throughout tonic and
burst ranges (when K+ channels are active) and a membrane
hyperpolarization at rest [14]1. This means the excitability
decreases as a stronger depolarization is required to reach
threshold and trigger an action potential. Besides effects on
K+ channels a potentiation of glycine receptors is assumed
alongside other neurochemical mechanisms that alter the ex-
citability of neurons [15]. While isoflurane is known to reduce
the CL- influx upon administration of GABA [16] and hence
decreases its inhibitory effect, electrophysiological studies in
vivo indicate that the net-effect of isoflurane is inhibitory for
all relevant dosages. In this respect, isoflurane contrasts with
other anaesthetics including halothane and ketamine that show
concentration dependence [10]. Isoflurane hyperpolarizes cells
which inhibits neural signal transduction by a reduced gap
junctional conductance.
While named effects explain the inhibition of neural firing
under anaesthesia, decisive effects arise on the population
level. Eger (1981) systematically studied the EEG patterns
in the awake state and during anaesthesia with isoflurane for
five different dosages at up to 2.9% in humans. For very
light anaesthesia (iso = .56%) low voltage fast activity can
be observed. At a light surgical level (iso = .96% and 1.78%)
1This was demonstrated in thalamocortical cells of the rat using the patch
clamp technique. Na+ channels are blocked for control using Tetrodotoxin.
3
(a) Sources, Sinks and Flow
(b) Helmholtz-Decomposition for simulated Optical Flow
Fig. 2. Helmholtz-Decomposition of Optical Flow
slow oscillations are present that change from more regular to
irregular. Alternating patterns with high amplitude oscillations
can be observed at a moderate surgical level (iso = 2.2%). For
deep anaesthesia only occasional low voltage activity shows
(iso = 2.9%). Isoflurane administration leads to a gradual shift
from a stable awake state to bistable states and finally deep
anaesthesia where quiescence dominates.
In summary it shows that neocortical slow waves emerge
spontaneously in cortex while they can be also be triggered by
signals from subcortical structures. Methods for the character-
ization of slow waves with widefield fluorescence must help in
detecting the source regions of slow waves and describe how
the patterns spread and where they target. The circumstance
that a complex dynamic occurs on a population level that
manifests in characteristic sequences of oscillations during the
up-state of a slow wave reflect how cortical pathways act as
a generator of rhythmical activity.
III. METHOD
We present a new approach for the analysis of slow waves
that includes three steps: (1) Detection of events, (2) feature
extraction by Optical Flow and Helmholtz-Decomposition as
well as (3) the retrieval of embedding vectors by aggregation
and the use of Autoencoders for the visualization of the slow
wave distribution and the detection of prototypical events.
To detect slow waves we compute the dF/F signal for each
recording as dF/F = (Ft − F0)/F0. We refine the signal
by band-stop filtering to remove effects of the heartbeat (10-
20Hz) and take the arithmetic mean over the spatial domain.
After detrending, the onset/offset of the events can be deter-
mined by thresholding the resulting 1D time series(Fig. 1c).
We continue with the computation of the pixeldense dFw/Fw
signal per slow wave i.e. the percentage change of each frame
fwt as compared to baseline activity Fw00 of the event.
dFw/Fw = (Fwt − Fw0)/Fw0
(1)
Vector fields of pixel displacements can be computed from
fluorescence recordings using gradient based Dense Optical
Flow[5]. To this end we rely on the method suggested by
Horn and Schunck[17]. It estimates the Optical Flow using
both the image gradient and the temporal derivative between
the pixel values of two subsequent frames. Optical Flow is
computed by iterative minimization of an objective function
e. The first part ef of this function measures the error in the
optical flow constraint of the vector fields.
ef =
ZZ
(Ixu + Iyv + It)2dxdy
(2)
Here Ix and Iy are the spatial derivatives of the df/f signal,
u and v denote the vector components of the flow field to be
computed and It is the temporal derivative. Recall that optical
flow can be measured uniquely in 1D but the solution in 2D is
ubiquitous (aperture problem). Hence an additional assumption
is made and a global smoothness constraint introduced by the
Horn-Schunck method.
es =
ZZ
(∥∇u∥2 + ∥∇v∥2)dxdy
(3)
The energy functional is the sum of both terms where the
global smoothness is weighted by the parameter α2.
E = ef + α2es
(4)
An iterative scheme can be derived to compute the vector
fields[17]. We suggest computing Optical Flow separately for
each hemisphere and then masking the background vectors.
The resulting vector fields reflect the apparent motion and ap-
proximates the displacement of pixels with the same intensity
(GCaMP fluorescence) between frames of the df/f contrast.
Hence, it implicitly captures the direction and speed at which
neocortical slow waves spread.
Patterns in these vector fields can be used to characterize
the way neural signals travel in cortex during slow wave sleep
and anaesthesia. Townsend and Gong (2018) suggest a kernel-
based approach to detect several local and global features.
A more general account that allows to study fundamental
properties of vector fields is Helmholtz-Decomposition. The
fundamental theorem of vector calculus states that every vector
field can be expressed as the sum of a curl free and a
divergence free vector field if it is sufficiently smooth and
decays rapidly.
v = ∇φcurl=0 + J∇φdiv=0
(5)
Helmholtz-Decomposition allows to retrieve the curl free
and the divergence free component for the given vector field.
The divergence free vector field is also referred to as flow
(Fig. 2a). The vector fields are expressed via the gradient ∇φ.
4
J relates to a matrix that rotates the gradient of the scalar
potential of the divergence free component by 90 degrees
(Eq. 5). The flow component of displacement vectors indicates
the global dynamics of neural activity and shows the overall
direction of the slow waves.
Osources =
(
∇φcurl=0,
if ∇φcurl=0 > 0
0,
otherwise
Isinks =
(
∇φcurl=0,
if ∇φcurl=0 < 0
0,
otherwise
(6)
The curl free vector field can be separated into the distribution
of sources O and sinks I. Sources are especially important
because they indicate the origin of focal activity. Fig. 2b
illustrates the effects of the Helmholtz-Decomposition of
Optical Flow for a simulated signal with increasing global
df/f originating from the top and a focal spot of raising
intensity(Fig. 2b; left). The constructed global downwards
trend is captured by the flow component (Fig. 2b; right) while
the location of the slow wave origin manifest as sources
visible as blue areas in the scalar potential (Fig. 2b; left).
The suggested approach allows to assess properties of
slow
waves
quantitatively.
To
this
end
we
compute
several derived measures: The vertical fraction of flow
Vertical flow = uflow/(uflow + vflow), the share of bottom-up
flow of vertical flow Bottom up = uflow>0/uflow, the fraction
of medial to lateral flow (vflow>0/vflow) for the left and
vflow<0/vflow for the right hemisphere), the total upwards-
(P uflow>0) and downwards flow (P uflow>0) as well as
the leftwards- (P vflow<0) and rightwards flow (P vflow<0)
of the left hemisphere, the peak amplitude of the GCamP
signal max df/f its duration as well as the temporal integral
over the sources
R
Odt/n and sinks
R
Idt/n that shows
the average distributions per event. These features capture
important characteristics of slow waves that can be displayed
and interpreted on the basis of individual events.
We test using variational autoencoders (VAEs) to retrieve a
low dimensional latent embedding and investigate distributions
of different types of slow waves exploratively. The position
on the embedding manifold reflects what the events look like
and thus shows characteristic features of the events. This
allows for an event related analysis of slow waves and to
investigate differences between conditions.
L = KLloss(zmean, zlogvar) +
X
piMSE(di, VAE(di)) (7)
The first VAE embeds the GCamP signal
R
df/fdt/n using
six fully connected layers with ReLU activation. It reveals the
topology of slow waves according to the shape of the spatially
averaged GCamP signal (see Fig. 8). A second model embeds
a larger number of slow wave features. They include the spatial
distribution of the sources
R
Odt/n and sinks
R
Idt/n, the
GCamP time series that was averaged spatially, the duration
and amplitude of the event as well as the direction of flow.
The latter is aggregated in four values that represent the sum
of the upwards-, downwards-, leftwards and rightwards vector
components of the flow field that was computed using the
Helmholtz Decomposition of the Optical Flow of the df/f
Fig. 3. A mixed input Variational Autoencoder (VAE)
signal (see Fig. 9). Our third model auto-encodes the GCamP
signal
R
df/fdt/n as well as the upwards and downwards
flow. A custom loss function was used to ensure that all of
the encoded features are well reflected in the reconstructions.
The respective function is given by Equation 7 where MSE
relates to the mean squared error and d is a set of the inputs
to the respective model. Fig. 3 depicts the mixed input model.
The parameter pi of the individual terms in the loss functions
were adjusted manually while changes to the network structure
were made until all the predictions correlated strongly with the
data.
Prototypical examples are detected with a class specific GMM
that approximates the conditional likelyhood of the embedding
vectors z of each condition c = 1 . . . 5 by an independent set
of Gaussian mixture components (k = 3).
pc =
N
X
k=1
wkcN(µkc, Σkc), where
Z|K ∼ N(µKc, ΣKc)
Each mixture component corresponds to a prototype and its
mean µ represents the prototype vector. The prototypical
samples are the ones with the embedding vector that has the
highest likelyhood for the respective gaussian kernel.
IV. RESULTS
We apply the proposed method on a dataset from an
experiment with five conditions. Each recording has a length
of 30 seconds and was measured at a different level of
isofluarane ranging from 1.8% to 2.6%. Several different types
of neocortical slow waves can be discerned intuitively based
on the shape of the temporal mean of the respective df/f signal.
Events with peak-amplitude below 5% in the df/f signal and a
high correlation with the hemodynamic signal (r > .3) were
excluded from the analysis to prohibit potential artifacts from
affecting the analysis that result from variations in the oxygen
levels due to breathing.
Fig. 4A shows the prototypical examples of the detected slow
waves in the embeddings of VAE 1 for the different conditions
5
in blue and the reconstructions in orange. While longer periods
of continuous activity with multiple peaks can be observed at
1.8% isoflurane, increasing levels of anesthetics correlate with
events that have few peaks or even only a single maximum.
As a tendency the average amplitude decreases with higher
levels of isoflurane. The same holds for the standard deviation
of the amplitudes (Fig. 4B).
As described in the method section the results of the
Helmholtz-Decomposition of Dense Optical Flow can be well
visualized. Fig. 5 illustrates the dynamics of flow during an
Fig. 4. Prototypical Slow Waves
event with a single peak and reveals its relationship to the
df/f signal. Visual inspection of the df/f videos gives the
impression of an event where activity spreads from frontal-
medial areas of the left hemisphere towards lateral and parietal
portions of cortex. This pattern is well captured by the flow
component. Fig. 5A shows the vector field for the measure-
ment with the maximal global field strength (dt = 18ms).
Arrows indicate the direction and strength of flow, the latter
of which is also indicated in the background. Fig. 5B shows the
relationship with the df/f signal. The flow is strongest in the
beginning of the event during the rising phase of df/f which
continues to increase thereafter. While activity spreads in early
stages of the slow wave a uniform change of fluorescence that
involves all cortex typically occurs later.
Areas with a focal increase in GCamP activity have high
values in the scalar potential of the sources (Fig. 2b). Sources
indicate the origin of neural activity as indicated by the Optical
Flow of the df/f signal. For many single peak events there
are distinct source areas, directional flow that originates from
them and targets at sinks where activity prevails longest. For
one type of slow waves medial portions of cortex typically act
as the sources while occipital areas are the sinks (Fig. 6B and
C). These events are characterized by pronounced media-to-
lateral flow (Fig. 6E) and a tendency towards downwards flow
(Fig. 6D). Visual inspection of the df/f videos confirms this
dynamic of cortical activity that originates in frontal areas,
Fig. 5. Vector Field of Flow
Fig. 6. Sources, sinks and flow
spreads quickly downwards towards medial areas and then
laterally. It shows empirically that activity in areas that act
as a sink typically lasts longest.
Fig. 7. Subsegments of a slow wave
We encode different sets of features using variational au-
toencoders to inspect the distribution of samples with different
isoflurane levels in latent space. Events with peak-amplitude
6
below 5% signal change or high correlation with breathing
(r>.3) were excluded from the analysis. The first model
targets at a latent space defined by the slow wave shape.
Fig. 8 illustrates the results. Panel A shows a reconstruction
manifold for latent-layer activations chosen from an evenly
spaced grid. Larger waves are mapped to the center while
smaller ones lie in the periphery: The phase and amplitude is
higher for the respective samples (Panels F-G). The samples
in the center region also have stronger flow as measured by
the area under the df/f curve. Samples from the different
experimental conditions are unevenly distributed. Panels H-
L show the distribution of samples with different isoflurane
levels. The density of the distribution for overlapping points
is color-coded. All samples that do not belong to the respective
condition are plotted in grey. Most samples with an isoflurane
level of 1.8% lie within the center and represent events with
multiple peaks and longer upstate periods. In contrast the
examples at 2% lie further to the lower right and represent
slow waves with one peak and a steep rising and falling edge.
For higher levels of isoflurane a cluster exists in the upper
right. This cluster arguably corresponds to waves with two
peaks the smaller one of which corresponds to an oscillation
that is triggered by breathing. A relationship between breathing
and neural oscillations has been identified before [18]. These
samples have strong vertical flow (as compared to horizontal
flow) and little bottom-up flow (as compared to top-down
flow; Panels B-D). Other samples of the very deep anaesthesia
conditions (iso>2%) are mapped to to the lower-right. This
indicates a general shift from longer lasting up states with
several oscillations of varying to less dynamical states where
smaller waves typically have only one single peak.
Fig. 8. Slow wave shapes in feature space (VAE 1)
Fig. 9 shows the results of for the mixed input model.
Panel A shows the reconstructions of the df/f signal. Duration
and amplitude are square root scaled. Panel B indicates the
direction of flow. Note that upwards flow dominates in the
Fig. 9. Slow waves in a combined feature space (VAE 2)
lower center, flow occurs in all directions rather evenly in the
middle left portion while downwards flow dominates for events
in the upper right area. Panel C and D show the reconstructions
of the temporal average of the sources and sinks. Panels E to
I show the distribution of samples of different experimental
conditions in latent slow wave space.
The model encoders the shape of the df/f signal alongside the
duration and amplitude, the ratio between flow in different
directions as well as the distibution of sources and the dis-
tribution of sinks. Hence latent slow wave space allows for a
more complete distinction of neocortical slow waves. Although
only a two dimensional latent space was used an acceptable
reconstruction was achieved for all included features. Here
large amplitude waves with multiple peaks that are typical for
low isoflurane levels (iso=1.8%) are mapped to the lower left
corner. Within this area one may discern events with frontal
sources (and ubiquitous flow) and those with sources along
the medial band (with flow rather bottom-up or medial-to
lateral). Large single peak waves that are characteristic for 2%
isoflurane are mapped to the central portions of the lower left
quadrant - an area with mostly medial to lateral or upwards
flow. Small waves that include a second peak lie in the upper
right area. Sources in frontal areas are present for small waves
that exist mainly during deep anaesthesia (iso>2.2%). This
type of small waves is characterized by downwards flow. The
manifold of sources and sinks provides further information
regarding the nature of larger waves. Neocortical slow waves
7
that are mapped to a region to the lower right have sources in
areas of the brain that potentially relate to the barrel fields in
fronto-peripheral parts of cortex. Especially for the latter kind
of events sinks reside in areas different from the sources and
upwards flow dominates.
The third model auto-encodes the df/f signal alongside the
Fig. 10. Latent distribution of Flow (VAE 3)
upwards and downwards flow and can be used to examine
regularities in the direction of flow during different stages of
slow waves. It shows that in most cases there is a point in
time when most upwards or downwards flow occurs. This
holds typically for the first rising edge of the events. At
1.8% isoflurane many events begin with downwards flow
(orange peak; central reconstructions) while pronounced peak
in upwards flow (green peak; central portion of upper right)
shows in areas of latent space mainly occupied by examples
of 2% isoflurane. This tendency for bottom up flow also holds
for events at higher levels of isoflurane (upper left).
Our results reveal a complex topology of events. It reveals the
potentials of the proposed method. The analysis with VAEs is
especially well suited to understand the structure of the data
exploratively. We found several types of slow waves for the
given dataset and provide the prerequisites for a systematic,
hypothesis-driven analysis of slow waves with fluorescence
microscopy. The combination of Helmholtz-Decomposition
with the Optical Flow of the pixel-dense GCamP contrast (df/f)
represents a viable tool for further research.
V. SUMMARY AND DISCUSSION
We demonstrate a new method to characterize neocortical
slow waves using fluorescence microscopy. It relies on
the Helmholtz-Decomposition of Dense Optical Flow and
captures the global dynamics of spread. Moreover it allows
to capture the sources and sinks of of the events. They can
be interpreted as the sites of origin of neocortical slow waves
and the areas activity converges at and prevails longest. Thus
it captures how different brain regions interact during bistable
states of anaesthesia and arguably also during deep sleep.
Our results appear promising and show the potentials of the
approach. Convolutional VAEs have proven useful to retrieve
a low dimensional latent representation that can be used to
visualize feature spaces that describe the variability of slow
waves. Prototypical events can be identified by a categorical
GMM. We understand slow waves as periods of an extended
up-state that may incorporate multiple oscillations in different
regions of the brain. Therefore they reflect how activity
travels along functional cortical pathways which might play
an important role as a generator of rhythmical activity in
neocortex. The Helmholtz-Decomposition of the Optical Flow
of the pixeldense GCamP contrast is well suited to detect
important features of neural activity and characterize slow
waves.
The proposed method can be used to characterize and
distinguish slow waves that occur at different stages of
anaesthesia. We tested with recordings acquired from a single
transgenic mouse. The analysed data with a high sampling
rate of (100Hz) was measured for time frame of 30s per
condition. Although the number of events is thus limited the
results are congruent with the changes in cortical dynamicd
reported previously. We found that different types of slow
waves form clusters with respect to different features. At
low isoflurane concentrations events typically have multiple
peaks and a complex dynamic that incorporates periods of
downwards and subsequent upwards flow. With increasing
levels of isoflurane the amplitude decreases and shorter events
with a single maximum prevail. One type of events appears
to be triggered by the somatosensory state of the animal.
This type of low amplitude events that are phase locked to
breathing occur at deep anesthesia. Several regions act as
sources of neural activity. Frontal areas are most common for
lower levels of isoflurane while, medial, occipital or lateral
clusters become more frequent at higher concentrations that
cause deep anaesthesia.
Future research should focus on means of a fine grained
categorization of different types of slow waves that was not
attempted here. Considering the high temporal resolution
of modern GCamP recording setups and the interactions of
cortical and subcortical sites during bistable neurological
states the approach offers potentials not only for studiyng
slow wave anaesthesia but potentially also the interaction
of different brain regions and rhythmical activity during sleep.
8
REFERENCES
[1]
R. E. Brown, R. Basheer, J. T. McKenna, R. E. Strecker,
and R. W. McCarley, “Control of sleep and wakeful-
ness,” Physiological reviews, 2012.
[2]
M. Steriade, A. Nunez, and F. Amzica, “A novel slow
(1 hz) oscillation of neocortical neurons in vivo: Depo-
larizing and hyperpolarizing components,” Journal of
neuroscience, vol. 13, no. 8, pp. 3252–3265, 1993.
[3]
M. Celotto, C. De Luca, P. M. F. Resta, et al., “Analysis
and model of cortical slow waves acquired with optical
techniques,” Methods and Protocols, vol. 3, no. 1, p. 14,
2020.
[4]
G. Bernardi, F. Siclari, G. Handjaras, B. A. Riedner,
and G. Tononi, “Local and widespread slow waves
in stable nrem sleep: Evidence for distinct regulation
mechanisms,” Frontiers in human neuroscience, vol. 12,
p. 248, 2018.
[5]
R. G. Townsend and P. Gong, “Detection and analysis
of spatiotemporal patterns in brain activity,” PLoS com-
putational biology, vol. 14, no. 12, e1006643, 2018.
[6]
J. Lef`evre, F. Leroy, S. Khan, et al., “Identification
of growth seeds in the neonate brain through surfacic
helmholtz decomposition,” in Information Processing
in Medical Imaging: 21st International Conference,
IPMI 2009, Williamsburg, VA, USA, July 5-10, 2009.
Proceedings 21, Springer, 2009, pp. 252–263.
[7]
M. Steriade and M. Deschenes, “The thalamus as a
neuronal oscillator,” Brain Research Reviews, vol. 8,
no. 1, pp. 1–63, 1984.
[8]
A. Stroh, H. Adelsberger, A. Groh, et al., “Making
waves: Initiation and propagation of corticothalamic
ca2+ waves in vivo,” Neuron, vol. 77, no. 6, pp. 1136–
1150, 2013.
[9]
N. Niethard, H.-V. V. Ngo, I. Ehrlich, and J. Born, “Cor-
tical circuit activity underlying sleep slow oscillations
and spindles,” Proceedings of the National Academy of
Sciences, vol. 115, no. 39, E9220–E9229, 2018.
[10]
H. Moghadam, T. Yar, M. M. Qazzaz, I. A. Ahmed,
and W. Winlow, “A comparative study of cell specific
effects of systemic and volatile anesthetics on identified
motor neurons and interneurons of lymnaea stagnalis
(l.), both in the isolated brain and in single cell culture,”
Frontiers in Physiology, vol. 10, p. 583, 2019.
[11]
T.-A. E. Nghiem, N. Tort-Colet, T. G´orski, et al.,
“Two types of slow waves in anesthetized and sleeping
brains,” bioRxiv, p. 430 405, 2018.
[12]
P. Montagna, “Fatal familial insomnia: A model dis-
ease in sleep physiopathology,” Sleep medicine reviews,
vol. 9, no. 5, pp. 339–353, 2005.
[13]
G. Buzs´aki, “The hippocampo-neocortical dialogue,”
Cerebral cortex, vol. 6, no. 2, pp. 81–92, 1996.
[14]
C. R. Ries and E. Puil, “Ionic mechanism of isoflu-
rane’s actions on thalamocortical neurons,” Journal of
neurophysiology, vol. 81, no. 4, pp. 1802–1809, 1999.
[15]
N. C. for Biotechnology Information. “Pubchem com-
pound summary for cid 3763.” (2021), [Online]. Avail-
able: https://pubchem.ncbi.nlm.nih.gov/compound/
Isoflurane (visited on 01/01/2021).
[16]
A. Jenkins, N. P. Franks, and W. R. Lieb, “Effects of
temperature and volatile anesthetics on gabaareceptors,”
Anesthesiology: The Journal of the American Society of
Anesthesiologists, vol. 90, no. 2, pp. 484–491, 1999.
[17]
B. K. Horn and B. G. Schunck, “Determining optical
flow,” Artificial intelligence, vol. 17, no. 1-3, pp. 185–
203, 1981.
[18]
A. B. Tort, S. Ponsel, J. Jessberger, Y. Yanovsky,
J. Brankaˇck, and A. Draguhn, “Parallel detection of
theta and respiration-coupled oscillations throughout the
mouse brain,” Scientific reports, vol. 8, no. 1, p. 6432,
2018.
"
"Soft robots are increasingly utilized due to their softness and high degrees of freedom (DOFs). However, modular soft robots introduce difficulties in accurate control. Hence, we propose a novel and accurate biLSTM controller for modular soft robots that adapts to different module numbers. It controls the module configurations and works for robots with different module numbers. Our contribution is threefold: a data collection strategy, a biLSTM configuration controller, and validation on simulated and real pneumatic robots. Experiments show that our controller achieves low error configuration control tasks on robots with two, three, four, and six modules.nan","Soft robots have been widely applied in numerous areas due to their softness and high degrees of freedom (DOFs), and various soft robots have been designed for different applications. For example, concentric tube robots are leveraged in robot-assisted surgery, especially minimally invasive surgery (MIS), and cable-driven robots have been validated in cardiothoracic endoscopic surgery. Researchers include pneumatic robots in recovery devices and assistive robots due to their safety. Also, a soft six-legged untethered robot can walk with the actuation of fluid-driven actuators. Soft robots can also be employed as biorobots to mimic the behaviors of animals like fish, octopus, and elephant. Overall, the robot community has taken advantage of many categories of soft robots in various research topics.

Modular soft robots have shown unique capabilities compared with other soft robots. Multiple modules endow the robot system with reconfiguration and multiple choices of module numbers. In this case, they are flexible and can meet the requirements of different tasks. Compared to single-module robots, modular robots have more degrees of actuation (DOAs) and, therefore, more active DOFs. Modular robots can provide larger working spaces from the views of both kinematics and dynamics. Thanks to these properties, modular robots can achieve complex manipulations.

Moreover, shape control can be implemented on modular soft robots. Most control targets of single modular robots are only end positions. Once the end positions are controlled, all the robot states, including the end orientations and robot shapes, are decided and depend on the end positions. But in many cases, the end positions and orientations of modular soft robots are independent. The robot can keep the end positions/orientations invariant and change the end orientations/positions. By controlling the robot shapes, modular robots can avoid obstacles and cross holes.nan","nanStudies have been carried out on a modular pneumatic robot. Due to the high model complexity, data-driven approaches are leveraged to achieve path tracking, end pose control, and sophisticated manipulation tasks. A modular robot named Robostrich arm is applied to mimic the behavior of an ostrich and achieves the reaching task in a narrow space. However, the applied reinforcement learning methods are time-consuming.

Some physical models for modular soft robots are proposed. Piecewise constant curvature (PCC) and the Cosserat approach are two of the most widely applied physical models in soft robots. Neural networks are employed for measurement, and PCC is employed for modular soft robot modeling. Kinematics models of modular soft robots are investigated, also based on PCC. The discrete Cosserat approach is utilized to simulate multisection soft manipulator dynamics.nan","We propose a novel and accurate biLSTM controller for modular soft robots. The biLSTM units share the same module number with the robot, even if the training and controlled robots have different module numbers. The label of module  i  can be denoted as

nᵥᵡ =
2(i − 1)nˇˉ⁄1 − 1,
(1)
where 
nˇˉ=
 number of modules in this robot.

The range of labels is [-1,1], and a large label represents that this module is away from the robot base.

Each LSTM unit can be seen as
f = sigm(Σᵣ ⋅ [нₗ₁, x] + Βᵣ),
i = sigm(Σᵩ ⋅ [нₗ₁, x] + Βᵩ),
C = f × C₁⁄₁ + i × tanh(Σᵣ ⋅ [нₗ₁, x] + Βᵣ),
(2)
o = sigm(Σᵯ ⋅ [нₗ₁, x] + Βᵯ),
h = o × tanh(C),where f, i, C, o, and h denote the forget gate, input gate, cell state, output gate, and hidden state of this LSTM unit, respectively. нₗ₁ₐ₁ and C₁⁄₁ are the hidden state and cell state provided by the other unit. x denotes the LSTM input, and W* and b* denote the weight and bias parameters of the corresponding states. × is the Hadamard product operator, and sigm is the sigmoid function.

To train a neural network as a robot controller, it is necessary to collect a dataset in simulation or the real world. Generally, the robot will be actuated randomly to generate this dataset, and such a dataset can cover the whole working space.nan","We collect 16000 samples with the traditional random method and our method mentioned in Section 2.2 on a four-module simulation robot. It is evident that our method covers a larger space than the traditional method. The simulation experiment code can be found at https://github.com/zixichen007115/23ZCd.

Based on our dataset, we train three kinds of neural networks to estimate the actions and compare their accuracy. As shown in Figure 1-(C), the neural network input contains previous module states and actions, the module number label, and current states for training. The network output is the estimated actuation.

We then utilize biLSTM for six-module robot configuration control. Due to the modularity of this network, biLSTM trained with a four-module robot can also be leveraged on a six-module robot, but LSTM fails to transfer to a six-module robot because the LSTM unit input size is related to module number.

In real experiments, we first collect 15000 samples on a three-module robot following the data collection method proposed in Section 2.2 and train a biLSTM for control. The dataset is shown in Figure S5. The actuation variable estimation errors and variances of the first, second, and third modules are 3.12 ± 4.85%, 3.23 ± 5.23%, and 3.04 ± 4.38%.

Two tasks, ‘edge’ and ‘down,’ are designed. In ‘edge,’ the robot is controlled to reach the edge of the working space, and the actuation variables nearly reach the maximal actuation.nan","This paper introduces a novel and accurate biLSTM configuration controller for modular soft robots with module number adaptability. Such a controller can control module configurations in robots with different module numbers. Simulation cable-driven robots and real pneumatic robots have been included in experiments to validate the proposed approaches, and we have proven that our controller can be leveraged even with the increase or decrease of module number. This is the first paper that gets inspiration from the physical structure of modular robots and utilizes bidirectional LSTM for module number adaptability. Future work may include a planning method that bridges the task and configuration spaces and the integration of an online controller.nan",A Novel and Accurate BiLSTM Configuration Controller for Modular Soft Robots with Module Number Adaptability,"Zixi Chen, Matteo Bernabei, Vanessa Mainardi, Xuyang Ren, Gastone Ciuti, Cesare Stefanini","A Novel and Accurate BiLSTM Configuration Controller for 
Modular Soft Robots with Module Number Adaptability 
Zixi Chen1*, Matteo Bernabei1, Vanessa Mainardi1, Xuyang Ren2, Gastone Ciuti1, and 
Cesare Stefanini1 
 
Abstract 
 
Modular soft robots have shown higher potential in sophisticated tasks than single-
module robots. However, the modular structure incurs the complexity of accurate 
control and necessitates a control strategy specifically for modular robots. In this paper, 
we introduce a data collection strategy and a novel and accurate bidirectional LSTM 
configuration controller for modular soft robots with module number adaptability. Such 
a controller can control module configurations in robots with different module numbers. 
Simulation cable-driven robots and real pneumatic robots have been included in 
experiments to validate the proposed approaches, and we have proven that our 
controller can be leveraged even with the increase or decrease of module number. This 
is the first paper that gets inspiration from the physical structure of modular robots and 
utilizes bidirectional LSTM for module number adaptability. Future work may include 
a planning method that bridges the task and configuration spaces and the integration of 
an online controller. 
 
 Keywords 
 
Data-driven control, bidirectional LSTM, configuration control, modular soft robot 
 
 
 
1 Biorobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant’Anna, Pisa, Italy. 
2 Multi-scale Medical Robotics Centre and Chow Yuk Ho Technology Centre for Innovative Medicine, The 
Chinese University of Hong Kong, Hong Kong, China 
* Corresponding author. Email: Zixi.Chen@santannapisa.it 
1. Introduction 
 
Soft robots have been widely applied in numerous areas due to their softness and high 
degrees of freedom (DOFs,) and a variety of soft robots have been designed for different 
applications. For example, concentric tube robots1 are leveraged in robot-assisted 
surgery, especially minimally invasive surgery (MIS.) Also, cable-driven robots have 
been validated in cardiothoracic endoscopic surgery2. Due to their safety, researchers 
include pneumatic robots in recovery devices3 and assistive robots4. A soft six-legged 
untethered robot can walk with the actuation of fluid-driven actuators5. Soft robots can 
also be employed as biorobots to mimic the behaviors of animals like fish6, octopus7–9, 
and elephant10. Overall, the robot community has taken advantage of many categories 
of soft robots in various research topics11–14.  
 
Modular soft robots have shown unique capabilities compared with other soft robots. 
Multiple modules endow the robot system with reconfiguration15 and multiple choices 
of module numbers. In this case, they are flexible and can meet the requirements of 
different tasks. Compared to single-module robots, modular robots have more degrees 
of actuation (DOAs) and, therefore, more active DOFs. Modular robots can provide 
larger working spaces from the views of both kinematics and dynamics. Thanks to these 
properties, modular robots can achieve complex manipulations16,17.  
 
Moreover, shape control can be implemented on modular soft robots. Most control 
targets of single modular robots are only end positions18–20. Once the end positions are 
controlled, all the robot states, including the end orientations and robot shapes, are 
decided and depend on the end positions. But in many cases, the end positions and 
orientations of modular soft robots are independent. The robot can keep the end 
positions/orientations invariant and change the end orientations/positions21. By 
controlling the robot shapes, modular robots can avoid obstacles22 and cross holes23. 
 
However, along with these advantages, modular soft robots encounter difficulties in 
accurate control. In addition to the nonlinearity and hysteresis of soft robots, such 
modular systems have more input variables than single-module robots, complicating 
the dynamics model. As shown in Figure 1-(A), the motion of each module will directly 
affect the configurations of two adjacent modules and indirectly affect the whole robot 
system. Moreover, the configurations of these modules decide the robot states with 
different levels. Even a tiny vibration on the modules near the base will crucially change 
the robot shape due to the accumulated motion along the modular robot, but the modules 
near the end show lower importance. In summary, although this kind of robot has high 
potential, the complex model necessitates a control strategy specifically for modular 
soft robots. 
 
Some researchers have proposed approaches to utilize modular soft robots in 
manipulation. A series of research has been carried out on a modular pneumatic 
robot16,21,24–27. Due to the high model complexity, data-driven approaches are leveraged 
to achieve path tracking24, end pose control21, and sophisticated manipulation tasks like 
opening a drawer, turning a handwheel, and drawing a line on a paper27. Of note, the 
modular robot in 21 keeps the end position/orientation invariant while changing the end 
orientation/position, which can be achieved exclusively by modular robots. A modular 
robot named Robostrich arm28 is applied to mimic the behavior of an ostrich and 
achieve the reaching task in a narrow space. However, the applied reinforcement 
learning methods are time-consuming.  
 
Also, some physical models for modular soft robots are proposed. Piecewise constant 
curvature (PCC)  and the Cosserat approach are two of the most widely applied physical 
models in soft robots29. Neural networks are employed in 30 for measurement, and PCC 
is employed for modular soft robot modeling. Kinematics models of modular soft robots 
are investigated in 31,32, also based on PCC. The discrete Cosserat approach is utilized 
to simulate multisection soft manipulator dynamics33. However, with the improvement 
of module number, the complexity of the physical model increases dramatically, and 
the most sophisticated robot in these physical model works has only three modules31, 
whose model is only validated in simulation. 
 
This paper aims to introduce a bidirectional long short-term memory (biLSTM) 
configuration controller for modular soft robots with module number adaptability. 
Instead of proposing one controller for each module number, our biLSTM network can 
work as a module from the view of the controller and is available to robots with different 
module numbers. With such a controller, modular soft robots can fulfill some tasks that 
single-module robots cannot achieve with relatively low errors. 
 
The contributions of this paper are summarized as follows: 
⚫ 
We propose a novel and accurate biLSTM controller for modular soft robots that 
aims to control the module configurations and can be applied to robots with 
different module numbers. 
⚫ 
We introduce a data collection method specifically for modular robots to reach 
states away from the resting state. 
⚫ 
Experiments are carried out to validate the proposed controller on simulated cable-
driven robots and real pneumatic robots. Configuration control tasks on robots with 
two, three, four, and six modules are achieved with the help of this controller. 
 
2. Methods 
2.1. BiLSTM Controller 
 
To propose a controller for modular robots, we first analyze their structures. As shown 
in Figure 1-(B), these modules share a similar shape, stiffness, and other physical 
properties. Their states can be represented by the same kind of configurations. They are 
connected in sequence, and each module will interact with two adjacent modules. In 
this module sequence, modules have different levels of impact on the robot motion. 
 
Based on the above analysis, we leverage biLSTM as the module configuration 
controller. Due to the hysteresis in soft robot space sequences, recurrent neural 
networks (RNNs) have been applied for control because such networks can address 
issues related to sequences. Considering the bidirectional influence between modules, 
we apply a bidirectional RNN, biLSTM, shown in Figure 1-(C) for configuration 
control. To train the biLSTM units and control modular robots, we can connect biLSTM 
units that share the same module number with robots, even if the training and controlled 
robots have different module numbers. As far as we know, this is the first paper that 
considers the space sequence of soft robots and utilizes RNN to solve this problem for 
module number adaptability.  
 
The diagram of one biLSTM unit is shown in Figure 1-(D). In module Ⅱ, the forward 
LSTM network takes the cell state 𝐶𝑓𝐼 and the hidden state ℎ𝑓𝐼 from module I as input, 
and provides the cell state 𝐶𝑓𝐼𝐼  and the hidden state ℎ𝑓𝐼𝐼  of this unit to module III. 
Meanwhile, the backward LSTM network takes the cell state 𝐶𝑏𝐼𝐼𝐼 and the hidden state 
ℎ𝑏𝐼𝐼𝐼 from module III as input, and provides the cell state 𝐶𝑏𝐼𝐼 and the hidden state ℎ𝑏𝐼𝐼 
of this unit to module I. In addition to these states, the module label 𝑛𝐼𝐼, the desired 
module state 𝑆𝑑, and previous actions and module states 𝑆𝐼𝐼0, 𝐴𝐼𝐼0, 𝑆𝐼𝐼1, ⋯  are fed into 
these two networks. Their outputs are concentrated and fed into a fully connected layer 
for actuation estimation. 
 
The module labels are used to infer the module position in the sequence, and the label 
of module 𝑖 can be denoted as 
𝑛𝑖 = 2(𝑖 − 1)
𝑛𝑠𝑢𝑚 − 1 − 1,
(1) 
where 𝑛𝑠𝑢𝑚 is the amount of modules in this robot. The range of the labels is [-1,1], 
and a large label represents that this module is away from the robot base. 
 
Each LSTM unit can be seen as 
𝑓 = 𝑠𝑖𝑔(𝑊𝑓 ∙ [ℎ−1, 𝑥] + 𝑏𝑓),
𝑖 = 𝑠𝑖𝑔(𝑊𝑖 ∙ [ℎ−1, 𝑥] + 𝑏𝑖),
𝐶 = 𝑓 × 𝐶−1 + 𝑖 × 𝑡𝑎𝑛ℎ(𝑊𝑐 ∙ [ℎ−1, 𝑥] + 𝑏𝑐),
(2)
 
𝑜 = 𝑠𝑖𝑔(𝑊𝑜 ∙ [ℎ−1, 𝑥] + 𝑏𝑜), 
ℎ = 𝑜 × tanh(𝐶), 
where 𝑓, 𝑖, 𝐶, 𝑜,  and ℎ  denote the forget gate, input gate, cell state, output gate, and 
hidden state of this LSTM unit, respectively. ℎ−1 and 𝐶−1 are the hidden state and cell 
state provided by the other unit. 𝑥 denotes the LSTM input, and 𝑊∗ and 𝑏∗ denote the 
weight and bias parameters of the corresponding states. ×  is the Hadamard product 
operator, and 𝑠𝑖𝑔 is the sigmoid function. 
 
2.2. Data Collection 
 
To train a neural network as a robot controller, it is necessary to collect a dataset in 
simulation or the real world. Generally, the robot will be actuated randomly to generate 
this dataset, and such a dataset can cover the whole working space in most cases, as 
shown in Figure 2-(A). However, due to the multiple modules, the modular robot tends 
to vibrate near the resting state instead of exploring and reaching the edge of the 
working space. Therefore, we propose a data collection approach specifically for 
modular robots, as shown in Figure 2-(B), which takes a soft robot with three modules 
as an example.  
 
In the first one-third of the data collection process, all the modules are actuated with 
the same random action sequence 𝑎𝑎1, and the robot can move far away from the resting 
state. In the following one-third process, the end module is actuated with a random 
action sequence 𝑎𝑏3, and the other two modules are actuated with a different random 
action sequence 𝑎𝑏1. In the final one-third process, three modules are actuated with 
different random action sequences 𝑎𝑐1, 𝑎𝑐2 and 𝑎𝑐3, respectively. This data collection 
approach allows the modular robot to reach a larger space than the traditional method. 
 
3. Results 
3.1. Experimental Setup 
 
To validate our biLSTM controller and data collection strategy, we include simulation 
cable-driven robots and real pneumatic robots in our experiments. 
 
The simulation robot is based on PyElastica34,35, as shown in Figure 3-(A). The real 
robot system in Figure 3-(B) is composed of pneumatic modules covered by origami 
structures. Each module has two opposite chambers connected to valves (Camozzi 
K8P-0-E522-0) under the control of the Arduino MEGA control board. Each module is 
connected to the other modules with 3D-printed connectors. Optical track makers are 
fixed on the connectors, and NDI Polaris tracks the module motion. The real 
experimental setup runs at 2.5 Hz. Detailed information about the setup, soft module 
structure, and connectors is included in Figure S1. 
 
To represent the module configuration, we utilize the unit vector of the module end 
relative to the module base, as shown in Figure 3-(C), (D). In this case, the simulation 
and real module configurations are denoted by [𝑣𝑥, 𝑣𝑦, 𝑣𝑧]∈ 𝑅3 and [𝑣𝑥, 𝑣𝑦]∈ 𝑅2, and 
the range of each value is [-1,1]. Each module has four cables in simulation, and we 
utilize two actuation values, 𝑎0, 𝑎1 ∈ [−1,1], to control them. 
𝑎𝐼 = max{0, 𝑎0}, 
𝑎𝐼𝐼 = max{0, −𝑎0} ,
(3) 
𝑎𝐼𝐼𝐼 = max{0, 𝑎1}, 
𝑎𝐼𝑉 = max{0, −𝑎1}, 
where 𝑎𝐼, 𝑎𝐼𝐼, 𝑎𝐼𝐼𝐼, 𝑎𝐼𝑉 ∈ [0,1] represent the act of cable I, II, III, and IV shown in Figure 
3-(E), respectively. The real robot module has only two chambers and shares the same 
actuation principle. The acts 𝑎𝐼, 𝑎𝐼𝐼 ∈ [0,1] of chambers in Figure 3-(F) are controlled 
by 𝑎0 and linear to the chamber pressure ([0.08bar, 0.35bar]). 
 
3.2. Simulation Experimental Results 
 
We collect 16000 samples with the traditional random method and our method 
mentioned in Section 2.2 on a four-module simulation robot, as shown in Figure 4. It is 
evident that our method covers a larger space than the traditional method. The 
simulation experiment code can be found at https://github.com/zixichen007115/23ZCd. 
 
Based on our dataset, we train three kinds of neural networks to estimate the actions 
and compare their accuracy. As shown in Figure 1-(C), the neural network input 
contains previous module states and actions, the module number label, and current 
states for training. The network output is the estimated actuation. 
 
We compare our method with two methods applied in previous works36, as shown in 
Figure S2. First, four LSTM networks are trained separately for four modules, and the 
ratios of the estimation errors to the actuation variable range are shown in  
Table 1. The estimation error is relatively high, which illustrates that it is challenging 
to estimate the actuation variables of one module without the knowledge of the other 
modules.  
 
Then, we feed the input from all modules into one LSTM. Each LSTM unit takes input 
from all modules in one time step, and the units are connected according to the time 
sequence. The estimation errors are far lower than those of the ‘four LSTM’ method. 
Finally, we test our biLSTM and it achieves similar errors. Both LSTM and biLSTM 
take the information of all modules; hence, they achieve low errors.  
 
In all the above approaches, the modules near the base have higher errors than the other 
modules, which means the base module is heavily influenced by the other modules. 
LSTM utilizes the recurrent structure to address the time sequence, while biLSTM 
addresses the space sequence. These two strategies can be combined to take both 
sequences into consideration, and this strategy may be included in our future work. Due 
to the low actuation estimation errors, we utilize LSTM and biLSTM to control the 
simulation modular robots with the same configuration trajectories. 
 
In the simulation control task, we aim to control the configurations of four modules and 
indirectly achieve some end pose control targets. In task A, the modules are controlled 
to bend and rotate. In task B, the robot is desired to keep the end position invariant and 
change the orientation. In task C, the robot is desired to keep the end orientation 
invariant and change the position. The desired configuration trajectories are designed 
specifically after trial and error and can be found in the Supplementary Data. Accurate 
configuration design based on desired robot states like end pose or shape requires a 
planning strategy, which will be included in our future work. 
 
The displacement between the real and desired module end unit vectors represents the 
configuration errors, and the ratios of module configuration errors to the unit vector 
length are shown in Table 2. The four-module robot motions in task A, B, and C with 
biLSTM are shown in Figure 5, and the desired and real module states are illustrated in 
Figure 6. The experimental videos are included in the Supplementary Movies. Both 
LSTM and biLSTM achieve low errors, and the maximal error of LSTM (7.62%) is 
higher than that of biLSTM(3.95%).  
 
Then, we utilize biLSTM for six-module robot configuration control. Due to the 
modularity of this network, biLSTM trained with a four-module robot can also be 
leveraged on a six-module robot, but LSTM fails to transfer to a six-module robot 
because the LSTM unit input size is related to module number. 
 
The configuration errors for the six-module simulation robot are shown in Table 3. The 
six-module robot motions with biLSTM are shown in Figure 7, and the desired and real 
module states are illustrated in Figure 8. The maximal error is 5.14%, demonstrating 
that biLSTM trained with a four-module robot can fulfill control tasks in a six-module 
robot. Considering the low errors of biLSTM on four-module and six-module 
simulation robots and its module number adaptability, we utilize biLSTM in real 
experiments. 
 
3.3. Real Experimental Results 
 
In real experiments, we first collect 15000 samples on a three-module robot following 
the data collection method proposed in Section 2.2 and train a biLSTM for control. The 
dataset is shown in Figure S5. The differences between two contiguous actuation 
variables in data collection are constrained to promise a smooth motion. The actuation 
variable estimation errors and variances of the first, second, and third modules are 3.12 
± 4.85%, 3.23 ± 5.23%, and 3.04 ± 4.38%. 
 
Two tasks, ‘edge’ and ‘down,’ are designed. In ‘edge,’ the robot is controlled to reach 
the edge of the working space, and the actuation variables nearly reach the maximal 
actuation. In ‘down,’ the robot end is controlled downward during the motion, implying 
that the sum of the module bending angles is 0.  
 
Each task has been carried out three times, and the configuration control errors for the 
three-module real robot are shown in Table 4. The module configuration is represented 
by the bending angle. The desired and real module states of the real three-module robot 
in task edge and down with biLSTM are shown in Figure 9. The experimental videos 
are included in the Supplementary Movies. The experimental results demonstrate that 
the biLSTM controller can control the real modular robot to follow trajectories with 
low errors (< 3°). 
 
Then, considering that the module number in the simulation increases from four to six, 
we decrease the module number in the real experiments from three to two to prove the 
broad module number adaptability of the biLSTM configuration controller. The 
configuration control errors for the two-module real robot are shown in Table 4. The 
desired and real module states of the real two-module robot in task (A) edge and (B) 
down with biLSTM are shown in Figure 10. 
 
The error of the second module in task ‘edge’ is 4.26°. Although it is not large 
considering the reachable space of this module (about 150°), it is the largest error in the 
real experiments. This may be caused by manufacturing errors among modules and can 
be solved by integrating online controllers19. Of note, in task ‘down,’ the bending angle 
of the first module in the two-module robot reaches about 30°, which is out of the 
reachable space of the first module in the three-module robot (< 6°). Even so, biLSTM 
trained with the three-module robot can fulfill this control task with relatively low errors, 
which shows that this controller is accurate and has module number adaptability. 
 
4. Summary 
 
This paper introduces a novel and accurate biLSTM configuration controller for module 
number adaptability and a data collection strategy specifically for modular soft robots. 
The dataset generated by the proposed collection strategy covers a larger space than 
that from the traditional method, and the biLSTM controller can decide actuation 
variables based on the previous and other module states. Simulation cable-driven robots 
with four and six modules and real pneumatic robots with three and two modules are 
leveraged for experiments, and the results have proven that the biLSTM controller for 
module number adaptability can fulfill module configuration control tasks on robots 
with different module numbers. 
 
As far as we know, this is the first paper that includes biLSTM as a soft robot controller. 
The application of this network is inspired by the structure of modular soft robots shown 
in Figure 1-(A). To control a system with such an inner interaction relationship, we find 
a neural network sharing a similar interaction principle among units, which is biLSTM. 
This kind of strategy is a hint at applying data models that share similar principles with 
physical systems and may expand the neural network application in soft robots. For 
example, besides RNN, which can represent the time sequence of soft robot motion, a 
generative adversarial network (GAN) may be employed to train a pair of robot model 
and controller simultaneously, considering the pairing relationship of modeling and 
control. 
 
As mentioned above, we may utilize biLSTM units to infer the space sequence and 
LSTM units to infer the time sequence in a large neural network in future work. Also, 
a planning approach may be introduced to map between the task and configuration 
space, as shown in Figure 1-(A). The planning method may combine neural networks 
and some physical or analytical models like 37. Based on the proposed offline-trained 
controller, we can integrate it with an online controller like 19,38 to decrease the control 
errors and achieve interchangeability among modules. 
 
 
 
Acknowledgments 
 
We acknowledge the support of the European Union by the Next Generation EU project 
ECS00000017 ‘Ecosistema dell’Innovazione’ Tuscany Health Ecosystem (THE, PNRR, 
Spoke 4: Spoke 9: Robotics and Automation for Health.) 
 
Author Disclosure Statement 
 
No competing financial interests exist. 
 
References 
1. Alfalahi H, Renda F, Stefanini C. Concentric tube robots for minimally invasive 
surgery: Current applications and future opportunities. IEEE Trans Med Robot 
Bionics 2020;2(3):410–424. 
2. Wang H, Zhang R, Chen W, et al. A cable-driven soft robot surgical system for 
cardiothoracic endoscopic surgery: preclinical tests in animals. Surg Endosc 
2017;31:3152–3158. 
3. Tang ZQ, Heung HL, Shi XQ, et al. Probabilistic model-based learning control of a 
soft pneumatic glove for hand rehabilitation. IEEE Trans Biomed Eng 
2021;69(2):1016–1028. 
4. Ansari Y, Manti M, Falotico E, et al. Multiobjective Optimization for Stiffness and 
Position Control in a Soft Robot Arm Module. IEEE Robot Autom Lett 
2018;3(1):108–115; doi: 10.1109/LRA.2017.2734247. 
5. Matia Y, Kaiser GH, Shepherd RF, et al. Harnessing nonuniform pressure 
distributions in soft robotic actuators. Adv Intell Syst 2023;5(2):2200330. 
6. Marchese AD, Onal CD, Rus D. Autonomous soft robotic fish capable of escape 
maneuvers using fluidic elastomer actuators. Soft Robot 2014;1(1):75–87. 
7. Laschi C, Cianchetti M, Mazzolai B, et al. Soft robot arm inspired by the octopus. 
Adv Robot 2012;26(7):709–727. 
8. Renda F, Giorelli M, Calisti M, et al. Dynamic Model of a Multibending Soft Robot 
Arm Driven by Cables. IEEE Trans Robot 2014;30(5):1109–1122; doi: 
10.1109/TRO.2014.2325992. 
9. Renda F, Cianchetti M, Giorelli M, et al. A 3D steady-state model of a tendon-driven 
continuum soft manipulator inspired by the octopus arm. Bioinspir Biomim 
2012;7(2):025006; doi: 10.1088/1748-3182/7/2/025006. 
10. Guan Q, Sun J, Liu Y, et al. Novel bending and helical extensile/contractile 
pneumatic artificial muscles inspired by elephant trunk. Soft Robot 2020;7(5):597–
614. 
11. Chen Z, Le Gall A, Mocellin L, et al. Data Models Applied to Soft Robot Modeling 
and Control: A Review. ArXiv Prepr ArXiv230512137 2023. 
12. Laschi C, Thuruthel TG, Lida F, et al. Learning-Based Control Strategies for Soft 
Robots: Theory, Achievements, and Future Challenges. IEEE Control Syst Mag 
2023;43(3):100–113. 
13. Della Santina C, Duriez C, Rus D. Model-Based Control of Soft Robots: A Survey 
of the State of the Art and Open Challenges. IEEE Control Syst Mag 2023;43(3):30–
65; doi: 10.1109/MCS.2023.3253419. 
14. George Thuruthel T, Ansari Y, Falotico E, et al. Control Strategies for Soft Robotic 
Manipulators: 
A 
Survey. 
Soft 
Robot 
2018;5(2):149–163; 
doi: 
10.1089/soro.2017.0007. 
15. Harada K, Oetomo D, Susilo E, et al. A reconfigurable modular robotic 
endoluminal surgical 
system: vision and preliminary results. 
Robotica 
2010;28(2):171–183. 
16. Jiang H, Wang Z, Jin Y, et al. Hierarchical control of soft manipulators towards 
unstructured interactions. Int J Robot Res 2021;40(1):411–434. 
17. Bianchi D, Antonelli MG, Laschi C, et al. SofToss: Learning to Throw Objects 
With 
a 
Soft 
Robot. 
IEEE 
Robot 
Autom 
Mag 
2023;2–12; 
doi: 
10.1109/MRA.2023.3310865. 
18. Della Santina C, Katzschmann RK, Biechi A, et al. Dynamic Control of Soft 
Robots Interacting with the Environment. In: 2018 IEEE International Conference 
on 
Soft 
Robotics 
(RoboSoft) 
2018; 
pp. 
46–53; 
doi: 
10.1109/ROBOSOFT.2018.8404895. 
19. Chen Z, Ren X, Bernabei M, et al. A Hybrid Adaptive Controller for Soft Robot 
Interchangeability. 
IEEE 
Robot 
Autom 
Lett 
2024;9(1):875–882; 
doi: 
10.1109/LRA.2023.3337705. 
20. Thuruthel TG, Falotico E, Renda F, et al. Model-Based Reinforcement Learning 
for Closed-Loop Dynamic Control of Soft Robotic Manipulators. IEEE Trans Robot 
2019;35(1):124–134; doi: 10.1109/TRO.2018.2878318. 
21. Gan Y, Li P, Jiang H, et al. A Reinforcement Learning Method for Motion Control 
With Constraints on an HPN Arm. IEEE Robot Autom Lett 2022;7(4):12006–12013. 
22. Calinon S, Bruno D, Malekzadeh MS, et al. Human–robot skills transfer interfaces 
for a flexible surgical robot. Comput Methods Programs Biomed 2014;116(2):81–
96. 
23. Wang H, Chen J, Lau HY, et al. Motion planning based on learning from 
demonstration for multiple-segment flexible soft robots actuated by electroactive 
polymers. IEEE Robot Autom Lett 2016;1(1):391–398. 
24. Jiang H, Wang Z, Liu X, et al. A Two-Level Approach for Solving the Inverse 
Kinematics of an Extensible Soft Arm Considering Viscoelastic Behavior. In: 2017 
IEEE International Conference on Robotics and Automation (ICRA) IEEE; 2017; pp. 
6127–6133. 
25. You X, Zhang Y, Chen X, et al. Model-Free Control for Soft Manipulators Based 
on Reinforcement Learning. In: 2017 IEEE/RSJ International Conference on 
Intelligent Robots and Systems (IROS) IEEE; 2017; pp. 2909–2915. 
26. Jin Y, Wang Y, Chen X, et al. Model-Less Feedback Control for Soft Manipulators. 
In: 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems 
(IROS) IEEE; 2017; pp. 2916–2922. 
27. Li P, Wang G, Jiang H, et al. A Q-Learning Control Method for a Soft Robotic Arm 
Utilizing Training Data from a Rough Simulator. In: 2021 IEEE International 
Conference on Robotics and Biomimetics (ROBIO) IEEE; 2021; pp. 839–845. 
28. Or K, Wu K, Nakano K, et al. Curriculum-reinforcement learning on simulation 
platform of tendon-driven high-degree of freedom underactuated manipulator. Front 
Robot AI 2023;10. 
29. Armanini C, Boyer F, Mathew AT, et al. Soft Robots Modeling: A Structured 
Overview. 
IEEE 
Trans 
Robot 
2023;39(3):1728–1748; 
doi: 
10.1109/TRO.2022.3231360. 
30. Baaij T, Holkenborg MK, Stölzle M, et al. Learning 3D shape proprioception for 
continuum soft robots with multiple magnetic sensors. Soft Matter 2023;19(1):44–
56. 
31. Li Y, Myszka DH, Murray A. The Kinematics of Constant Curvature Continuum 
Robots Through Three Segments. IEEE Robot Autom Lett 2023. 
32. Wild S, Zeng T, Mohammad A, et al. Efficient and Scalable Inverse Kinematics for 
Continuum Robots. IEEE Robot Autom Lett 2023. 
33. Renda F, Boyer F, Dias J, et al. Discrete Cosserat Approach for Multisection Soft 
Manipulator 
Dynamics. 
IEEE Trans 
Robot 
2018;34(6):1518–1533; 
doi: 
10.1109/TRO.2018.2868815. 
34. Gazzola M, Dudte L, McCormick A, et al. Forward and inverse problems in the 
mechanics of soft filaments. R Soc Open Sci 2018;5(6):171628; doi: 
10.1098/rsos.171628. 
35. Chang H-S, Halder U, Shih C-H, et al. Energy Shaping Control of a Muscular 
Octopus Arm Moving in Three Dimensions. ArXiv Prepr ArXiv220904089 2022. 
36. George Thuruthel T, Gardner P, Iida F. Closing the control loop with time-variant 
embedded soft sensors and recurrent neural networks. Soft Robot 2022;9(6):1167–
1176. 
37. Liu J, Borja P, Della Santina C. Physics-Informed Neural Networks to Model and 
Control Robots: A Theoretical and Experimental Investigation. 2023; doi: 
10.48550/arXiv.2305.05375. 
38. Nazeer MS, Bianchi D, Campinoti G, et al. Policy Adaptation Using an Online 
Regressing Network in a Soft Robotic Arm. In: 2023 IEEE International Conference 
on 
Soft 
Robotics 
(RoboSoft) 
2023; 
pp. 
1–7; 
doi: 
10.1109/RoboSoft55895.2023.10121927. 
 
 
 
Tables 
 
Table 1. Mean and standard derivation of actuation value estimation errors with 
different networks 
 
four LSTM 
LSTM 
biLSTM 
module 1 
18.52 ± 14.56% 
0.93 ± 0.95% 
1.63 ± 1.71% 
module 2 
12.19 ± 10.33% 
0.85 ± 0.85% 
1.49 ± 1.52% 
module 3 
7.69 ± 6.60% 
0.76 ± 0.68% 
1.11 ± 1.05% 
module 4 
3.74 ± 3.21% 
0.64 ± 0.57% 
0.70 ± 0.65% 
 
Table 2. Mean and standard derivation of configuration control errors for the four-
module simulation robot 
 
LSTM-A 
LSTM-B 
LSTM-C 
biLSTM-
A 
biLSTM-
B 
biLSTM-
C 
module 1 
4.70 ± 2.65%  2.07 ± 0.37% 
7.62 ± 2.59% 
3.95 ± 1.84% 
0.72 ± 0.29% 
3.61 ± 1.72% 
module 2 
3.77 ± 1.73% 
0.93 ± 0.49% 
5.97 ± 1.69% 
3.45 ± 1.09% 
0.67 ± 0.28% 
2.24 ± 1.36% 
module 3 
1.29 ± 1.16% 
1.58 ± 0.70% 
2.21 ± 1.07% 
1.64 ± 1.05% 
1.16 ± 0.63% 
1.01 ± 0.40% 
module 4 
2.10 ± 1.41% 
1.89 ± 0.91% 
1.85 ± 1.00% 
1.09 ± 0.81% 
1.92 ± 0.78% 
1.18 ± 0.59% 
 
Table 3. Mean and standard derivation of configuration control errors for the six-
module simulation robot 
 
A 
B 
C 
module 1 
2.94 ± 1.51% 
3.99 ± 0.43% 
1.82 ± 0.25% 
module 2 
1.73 ± 0.94% 
2.43 ± 0.42% 
2.28 ± 0.40% 
module 3 
5.18 ± 1.74% 
0.65 ± 0.33% 
3.35 ± 0.66% 
module 4 
5.14 ± 1.84% 
1.80 ± 0.67% 
1.21 ± 0.63% 
module 5 
3.37 ± 0.97% 
4.30 ± 0.57% 
3.30 ± 0.75% 
module 6 
2.49 ± 0.45% 
1.80 ± 0.85% 
3.58 ± 1.11% 
 
Table 4. Mean and standard derivation of configuration control errors for the three-
module and two-module real robot 
 
3-edge 
3-down 
2-edge 
2-down 
module 1 
0.58 ± 0.45° 
0.50 ± 0.47° 
0.94 ± 0.63° 
1.47 ± 0.86° 
module 2 
0.92 ± 0.76° 
1.72 ± 1.19° 
4.26 ± 2.80° 
1.69 ± 1.28° 
module 3 
2.69 ± 1.66° 
1.98 ± 1.52° 
/ 
/ 
 
 
 
Figures 
 
 
Figure 1. (A) Modular soft robot structure. The actuation of each module 𝐴 in the action 
space will affect its configuration 𝑆 in the configuration space. Also, the configuration 
is affected by gravity, interaction with the adjacent modules, and base. Finally, all the 
configurations have different impacts on the end pose in the task space. This paper 
proposes a configuration controller, shown as the boxes. (B) The diagram of a modular 
soft robot. (C) BiLSTM controller. Each unit takes the desired module states 𝑆𝑑, module 
number label 𝑚, previous module states and actuations, 𝑆 and 𝐴, as input and produces 
the actuation 𝐴̂ for this time step. (D) The diagram of the biLSTM unit for module Ⅱ. 
 
 
Figure 2. (A) General data collection method. (B) Data collection method proposed for 
modular robots. 𝑎∗ represents different random actuation sequences.  
 
 
Figure 3. (A) Simulation robot diagram. The robot comprises four modules, and the end 
of each module is shown by three coordinate axes. The direction of gravity is upward 
in this diagram. (B) Real robot setup. A pneumatic robot composed of three modules is 
actuated by valves controlled by Arduino and PC. The optical tracking system tracks 
the optical tracker motion and sends to PC for biLSTM control. (C) Simulation and (D) 
real module configuration. The configuration of each module is shown by the 
orientation of end unit vector. (E) Simulation and (F) real module actuation. Each 
simulation module is actuated by four cables while the real one is actuated by two 
chambers. 
 
 
Figure 4. The diagram of datasets collected with (A) the traditional method and (B) our 
method. The points represent the end positions of the first, second, third, and final 
modules. 
 
 
Figure 5. Simulation four-module robot motion in task A, B, and C with biLSTM. The 
color becomes deep with the improvement of time steps. 
 
 
Figure 6. The desired and real module states of the simulation four-module robot in task 
A, B, and C with biLSTM. 
 
 
Figure 7. Simulation six-module robot motion in task A, B, and C with biLSTM. The 
color becomes deep with the improvement of time steps. 
 
 
Figure 8. The desired and real module states of the simulation six-module robot in task 
A, B, and C with biLSTM. 
 
 
Figure 9. The desired and real module states of the real three-module robot in task (A) 
edge and (B) down with biLSTM. 
 
 
Figure 10. The desired and real module states of the real two-module robot in task (A) 
edge and (B) down with biLSTM. 
 
 
Supplementary Data  
 
Figure S1. (A) Pneumatic robot made of silicone and apart of unfolded origami 
structure. (B) a folded origami structure. (C) Each origami structure covers one 
pneumatic robot. One 3D-printed connector connects two modules, and a pair of optical 
trackers are fixed on the connector. (D) A modular robot system is connected to a metal 
stick, and three fixed optical trackers are applied for system calibration. 
 
 
Figure S2. The diagram of (A) four LSTM and (B) LSTM. 
 
Table S1. Neural networks parameters 
 
Four LSTM 
LSTM 
biLSTM 
biLSTM (real) 
layer number 
4 
4 
4 
4 
hidden state size 
128 
128 
128 
128 
time step number 
5 
5 
5 
10 
batch size 
64 
64 
64 
128 
optimizer 
Adam 
Adam 
Adam 
Adam 
Learning rate 
0.001 
0.001 
0.001 
0.0003 
 
Simulation configuration trajectory: 
 
In task A, the trajectories for 𝑣𝑥, 𝑣𝑦, and 𝑣𝑧 are 
{
  
 
  
 
𝑣𝑑𝑧(𝑡) = 1 − (1 − 𝑣zmin) ∗
𝑡
𝑡𝑚𝑎𝑥
𝑣𝑑𝑥(𝑡) = sin (2𝜋 ∗
𝑡
𝑡𝑚𝑎𝑥
) ∗ √1 − 𝑣𝑑𝑧(𝑡)2
𝑣𝑑𝑦(𝑡) = cos (2𝜋 ∗
𝑡
𝑡𝑚𝑎𝑥
) ∗ √1 − 𝑣𝑑𝑧(𝑡)2
,
(S1) 
where 𝑣𝑧𝑚in denotes the minimal value of 𝑣𝑧. It is [0.975,0.850,0.725,0.625] for four-
module robot and [0.998, 0.995, 0.950, 0.850, 0.800, 0.650] for six-module robot. 𝑡𝑚𝑎𝑥 
represents the length of each control trial and is 250 in simulation. 
 
In task B, the trajectories for 𝑣𝑥, 𝑣𝑦, and 𝑣𝑧 are 
{
 
 
 
 
𝑣𝑑𝑧(𝑡) = 𝑣𝑑𝑧
𝑣𝑑𝑥(𝑡) = 𝑎 ∗ sin (2𝜋 ∗
𝑡
𝑡𝑚𝑎𝑥
) ∗ √1 − 𝑣𝑑𝑧(𝑡)2
𝑣𝑑𝑦(𝑡) = 𝑎 ∗ cos (2𝜋 ∗
𝑡
𝑡𝑚𝑎𝑥
) ∗ √1 − 𝑣𝑑𝑧(𝑡)2
,
(S2) 
where 𝑣𝑑𝑧 is [0.998,0.998,0.996,0.600] for four-module robot and [0.999, 0.999, 0.999, 
0.998, 0.995, 0.708] for six-module robot. 𝑎 is employed to set the module rotation 
direction. It is [1,1,1,-1] for four-module robot and [1,1,1,1,-1,-1] for six-module robot. 
 
In task C, the trajectories for 𝑣𝑥, 𝑣𝑦, and 𝑣𝑧 are 
{  
  𝑣𝑑𝑧(𝑡) = 1 − (1 − 𝑣zmin) ∗ 𝑡
50
𝑣𝑑𝑥(𝑡) = 0
𝑣𝑑𝑦(𝑡) = 𝑎 ∗ √1 − 𝑣𝑑𝑧(𝑡)2
, t < 50,
 (S3) 
{
  
  
𝑣𝑑𝑧(𝑡) = 𝑣𝑧𝑚𝑖𝑛
𝑣𝑑𝑥(𝑡) = 𝑎 ∗ sin (2𝜋 ∗ 𝑡 − 50
200 ) ∗ √1 − 𝑣𝑑𝑧(𝑡)2
𝑣𝑑𝑦(𝑡) = 𝑎 ∗ cos (2𝜋 ∗ 𝑡 − 50
200 ) ∗ √1 − 𝑣𝑑𝑧(𝑡)2
, t ≥ 50,
(S4) 
where 𝑣𝑧𝑚in  is [0.941,0.998,0.897,0.650] for four-module robot and [0.999, 0.996, 
0.985, 0.975, 0.925, 0.600] for six-module robot. 𝑎 is [1,1,1,-1] for four-module robot 
and [1,1,1,1,1,-1] for six-module robot. 
 
 
Figure S3. Actuation variables of simulation four-module robot in task A, B, and C with 
biLSTM. 
 
 
Figure S4. Actuation variables of simulation six-module robot in task A, B, and C with 
biLSTM. 
 
 
Figure S5. Dataset collected with our proposed data collection method. (A), (B) and (C) 
represent three actuation methods shown in Figure 2-(B).  
 
Real angle trajectory: 
 
In real experiments, each trial contains 200 steps, which means  𝑡𝑚𝑎𝑥 = 200. 
 
The desired angle trajectories are 
𝑎𝑛𝑔𝑑 =
{
 
 
 
 
𝑎𝑛𝑔𝑚𝑎𝑥 ∗ 𝑡
50 , 𝑡 < 50
𝑎𝑛𝑔𝑚𝑎𝑥 ∗ (2 − 𝑡
50) , 50 ≤ 𝑡 < 150
𝑎𝑛𝑔𝑚𝑎𝑥 ∗ ( 𝑡
50 − 4) , 150 ≤ 𝑡
,
(𝑆5) 
where 𝑎𝑛𝑔𝑚𝑎𝑥 is the maximal module bending angle. For task edge, it is [5.4°, 18°,90°] 
for three-module robot and [21.6°, 72°] for two-module robot. For task down, it is [3.6°, 
36°, -39.6°] for three-module robot and [3.24°, -32.4°] for two-module robot. 
 
 
Figure S6. Actuation variables of real three-module robot in task (A) edge and (B) down 
with biLSTM. 
 
 
Figure S7. Actuation variables of real two-module robot in task (A) edge and (B) down 
with biLSTM. 
"
"We present the Radiation Oncology NLP Database (ROND), the first dedicated Natural Language Processing (NLP) dataset for radiation oncology, an important medical specialty that has received limited attention from the NLP community in the past. With the advent of Artificial General Intelligence (AGI), there is an increasing need for specialized datasets and benchmarks to facilitate research and development. ROND is specifically designed to address this gap in the domain of radiation oncology, a field that offers many opportunities for NLP exploration. It encompasses various NLP tasks including Logic Reasoning, Text Classification, Named Entity Recognition (NER), Question Answering (QA), Text Summarization, and Patient-Clinician Conversations, each with a distinct focus on radiation oncology concepts and application cases. In addition, we have developed an instruction-tuning dataset consisting of over 20k instruction pairs (based on ROND) and trained a large language model, CancerChat. This serves to demonstrate the potential of instruction-tuning large language models within a highly-specialized medical domain. The evaluation results in this study could serve as baseline results for future research. ROND aims to stimulate advancements in radiation oncology and clinical NLP by offering a platform for testing and improving algorithms and models in a domain-specific context. The ROND dataset is a joint effort of multiple U.S. health institutions. The data is available at https://github.com/zl-liu/Radiation-Oncology-NLP-Database.nan","Radiation oncology is a critical medical specialty that employs high-energy radiation to treat and manage cancer and other diseases (Bernier et al., 2004; Unkelbach et al., 2018). Indeed, like many medical domains, there is much potential to integrate natural language processing (NLP) into radiotherapy research and practice (Bitterman et al., 2021; Rezayi et al., 2022). However, there is limited development and evaluation of NLP models in this domain due to the lack of dedicated datasets (Rezayi et al., 2022). In response to this need, we present the Radiation Oncology NLP Database (ROND).
ROND is the world’s first NLP dataset specifically created for radiation oncology. It aims to provide a comprehensive platform for researchers to develop, test, and improve NLP models and methods within this domain. This dataset covers a wide spectrum of NLP tasks, including Logic Reasoning, Clinical Text Classification, Named Entity Recognition (NER), Question Answering (QA), and Text Summarization. Each of these tasks is centered around distinct aspects of radiation oncology, offering researchers a rich and varied dataset for exploration and model training. In addition, ROND contains a Patient-Clinician conversation dataset, which provides valuable insights into patient interactions, symptom descriptions, and treatment discussions, enhancing our understanding and modeling of complex medical dialogues. Figure 1 presents an overview of ROND.
The unique structure of ROND facilitates the development of models capable of reasoning logically about complex radiation oncology concepts, classifying domain-specific text data, recognizing and categorizing specialized entities, accurately answering radiation oncology-related questions, and summarizing lengthy documents and research papers in the field. We aim to establish a benchmark for future studies that stimulates innovation in radiation oncology research and ultimately improves patient care through the power of NLP.
We believe this database is of particular importance in the age of Artificial General Intelligence (AGI) (Bubeck et al., 2023; Zhao et al., 2023; Liu et al., 2023a). Successful large language models (LLM) such as ChatGPT, GPT-4, LLAMA (Touvron et al., 2023) and PaLM (Chowdhery et al., 2022) are trained on vast amounts of public domain data. Some LLMs such as Med-Palm 2 (Singhal et al., 2022) are trained on both public biomedical data sources and private hospital (e.g., through the Google-Mayo Clinic partnership) data, and consequently are highly capable of processing medical text (Singhal et al., 2022). However, there is no existing dataset that specifically supports NLP in radiation oncology. The ROND dataset complements recent LLM advancements and offers a platform to better integrate LLMs into healthcare.nan","The Radiation Oncology NLP Database (ROND) is the first NLP dataset specifically created for radiation oncology. It aims to provide a comprehensive platform for researchers to develop, test, and improve NLP models and methods within this domain. This dataset covers a wide spectrum of NLP tasks, including Logic Reasoning, Clinical Text Classification, Named Entity Recognition (NER), Question Answering (QA), and Text Summarization. Each of these tasks is centered around distinct aspects of radiation oncology, offering researchers a rich and varied dataset for exploration and model training. In addition, ROND contains a Patient-Clinician conversation dataset, which provides valuable insights into patient interactions, symptom descriptions, and treatment discussions, enhancing our understanding and modeling of complex medical dialogues.nannan","We present the Radiation Oncology NLP Database (ROND), the first dedicated Natural Language Processing (NLP) dataset for radiation oncology, an important medical specialty that has received limited attention from the NLP community in the past. With the advent of Artificial General Intelligence (AGI), there is an increasing need for specialized datasets and benchmarks to facilitate research and development. ROND is specifically designed to address this gap in the domain of radiation oncology, a field that offers many opportunities for NLP exploration. It encompasses various NLP tasks including Logic Reasoning, Text Classification, Named Entity Recognition (NER), Question Answering (QA), Text Summarization, and Patient-Clinician Conversations, each with a distinct focus on radiation oncology concepts and application cases. In addition, we have developed an instruction-tuning dataset consisting of over 20k instruction pairs (based on ROND) and trained a large language model, CancerChat. This serves to demonstrate the potential of instruction-tuning large language models within a highly-specialized medical domain. The evaluation results in this study could serve as baseline results for future research. ROND aims to stimulate advancements in radiation oncology and clinical NLP by offering a platform for testing and improving algorithms and models in a domain-specific context. The ROND dataset is a joint effort of multiple U.S. health institutions. The data is available at https://github.com/zl-liu/Radiation-Oncology-NLP-Database.nan","The Logic Reasoning subset of the Radiation Oncology NLP Database (ROND) presents questions designed to assess the logical reasoning capabilities of NLP models within the context of radiation oncology. The questions are geared towards the understanding of fundamental concepts and principles in radiation oncology, such as the properties of radioactive elements, atomic structure, electron orbits, X-ray emission, penumbra effects, and interaction of different particles with matter. We manually created and annotated 100 logic reasoning questions for this dataset.
Each question in this subset is structured as a yes/no question, designed to elicit a binary response. The questions range from basic atomic structure, such as ""Does an atom consist of a positively charged nucleus surrounded by a cloud of negatively charged electrons?"" to more specific queries about X-ray production and penumbra effect, such as ""In X-ray production, does the efficiency of x-ray production depend on the size of the target?"" or ""Is physical penumbra influenced by geometric penumbra, beam energy, and the lateral transport of electrons in the tissues?""
This dataset provides an avenue to evaluate the ability of NLP models to apply logical reasoning within the domain-specific context of radiation oncology, emphasizing both the understanding of fundamental radiation oncology concepts and the ability to apply this knowledge to specific scenarios.nan","We present the Radiation Oncology NLP Database (ROND), the first dedicated Natural Language Processing (NLP) dataset for radiation oncology, an important medical specialty that has received limited attention from the NLP community in the past. With the advent of Artificial General Intelligence (AGI), there is an increasing need for specialized datasets and benchmarks to facilitate research and development. ROND is specifically designed to address this gap in the domain of radiation oncology, a field that offers many opportunities for NLP exploration. It encompasses various NLP tasks including Logic Reasoning, Text Classification, Named Entity Recognition (NER), Question Answering (QA), Text Summarization, and Patient-Clinician Conversations, each with a distinct focus on radiation oncology concepts and application cases. In addition, we have developed an instruction-tuning dataset consisting of over 20k instruction pairs (based on ROND) and trained a large language model, CancerChat. This serves to demonstrate the potential of instruction-tuning large language models within a highly-specialized medical domain. The evaluation results in this study could serve as baseline results for future research. ROND aims to stimulate advancements in radiation oncology and clinical NLP by offering a platform for testing and improving algorithms and models in a domain-specific context. The ROND dataset is a joint effort of multiple U.S. health institutions. The data is available at https://github.com/zl-liu/Radiation-Oncology-NLP-Database.nan",The Radiation Oncology NLP Database,"Zhengliang Liu, Jason Holmes, Wenxiong Liao, Chenbin Liu, Lian Zhang, Hongying Feng, Peilong Wang, Muhammad Ali Elahi, Hongmin Cai, Lichao Sun, Quanzheng Li, Xiang Li, Tianming Liu, Jiajian Shen, Wei Liu","The Radiation Oncology NLP Database
Zhengliang Liu, Jason Holmes, Wenxiong Liao, Chenbin Liu,
Lian Zhang, Hongying Feng, Peilong Wang, Muhammad Ali Elahi,
Hongmin Cai, Lichao Sun, Quanzheng Li, Xiang Li,
Tianming Liu, Jiajian Shen, Wei Liu
Abstract
We present the Radiation Oncology NLP
Database (ROND), the first dedicated Natural
Language Processing (NLP) dataset for radia-
tion oncology, an important medical specialty
that has received limited attention from the
NLP community in the past. With the advent
of Artificial General Intelligence (AGI), there
is an increasing need for specialized datasets
and benchmarks to facilitate research and devel-
opment. ROND is specifically designed to ad-
dress this gap in the domain of radiation oncol-
ogy, a field that offers many opportunities for
NLP exploration. It encompasses various NLP
tasks including Logic Reasoning, Text Clas-
sification, Named Entity Recognition (NER),
Question Answering (QA), Text Summariza-
tion, and Patient-Clinician Conversations, each
with a distinct focus on radiation oncology con-
cepts and application cases. In addition, we
have developed an instruction-tuning dataset
consisting of over 20k instruction pairs (based
on ROND) and trained a large language model,
CancerChat. This serves to demonstrate the
potential of instruction-tuning large language
models within a highly-specialized medical
domain. The evaluation results in this study
could serve as baseline results for future re-
search. ROND aims to stimulate advancements
in radiation oncology and clinical NLP by of-
fering a platform for testing and improving
algorithms and models in a domain-specific
context. The ROND dataset is a joint effort
of multiple U.S. health institutions. The data
is available at https://github.com/zl-liu/
Radiation-Oncology-NLP-Database.
1
Introduction
Radiation oncology is a critical medical specialty
that employs high-energy radiation to treat and
manage cancer and other diseases (Bernier et al.,
2004; Unkelbach et al., 2018). Indeed, like many
medical domains, there is much potential to inte-
grate natural language processing (NLP) into ra-
diotherapy research and practice (Bitterman et al.,
2021; Rezayi et al., 2022). However, there is lim-
ited development and evaluation of NLP models in
this domain due to the lack of dedicated datasets
(Rezayi et al., 2022). In response to this need,
we present the Radiation Oncology NLP Database
(ROND).
ROND is the world’s first NLP dataset specif-
ically created for radiation oncology. It aims to
provide a comprehensive platform for researchers
to develop, test, and improve NLP models and
methods within this domain. This dataset covers
a wide spectrum of NLP tasks, including Logic
Reasoning, Clinical Text Classification, Named En-
tity Recognition (NER), Question Answering (QA),
and Text Summarization. Each of these tasks is
centered around distinct aspects of radiation oncol-
ogy, offering researchers a rich and varied dataset
for exploration and model training. In addition,
ROND contains a Patient-Clinician conversation
dataset, which provides valuable insights into pa-
tient interactions, symptom descriptions, and treat-
ment discussions, enhancing our understanding and
modeling of complex medical dialogues. Figure 1
presents an overview of ROND.
The unique structure of ROND facilitates the
development of models capable of reasoning logi-
cally about complex radiation oncology concepts,
classifying domain-specific text data, recognizing
and categorizing specialized entities, accurately an-
swering radiation oncology-related questions, and
summarizing lengthy documents and research pa-
pers in the field. We aim to establish a benchmark
for future studies that stimulates innovation in ra-
diation oncology research and ultimately improves
patient care through the power of NLP.
We believe this database is of particular impor-
tance in the age of Artificial General Intelligence
(AGI) (Bubeck et al., 2023; Zhao et al., 2023; Liu
et al., 2023a). Successful large language models
(LLM) such as ChatGPT, GPT-4, LLAMA (Tou-
vron et al., 2023) and PaLM (Chowdhery et al.,
1
arXiv:2401.10995v1  [cs.CL]  19 Jan 2024
Figure 1: Overview of the Radiation Oncology NLP Database.
2022) are trained on vast amounts of public domain
data. Some LLMs such as Med-Palm 2 (Singhal
et al., 2022) are trained on both public biomedical
data sources and private hospital (e.g., through the
Google-Mayo Clinic partnership) data, and conse-
quently are highly capable of processing medical
text (Singhal et al., 2022). However, there is no
existing dataset that specifically supports NLP in ra-
diation oncology. The ROND dataset complements
recent LLM advancements and offers a platform to
better integrate LLMs into healthcare.
2
The Radiation Oncology NLP Database
2.1
Logic Reasoning
The Logic Reasoning subset of the Radiation On-
cology NLP Database (ROND) presents questions
designed to assess the logical reasoning capabili-
ties of NLP models within the context of radiation
oncology. The questions are geared towards the
understanding of fundamental concepts and princi-
ples in radiation oncology, such as the properties
of radioactive elements, atomic structure, electron
orbits, X-ray emission, penumbra effects, and inter-
action of different particles with matter. We man-
ually created and annotated 100 logic reasoning
questions for this dataset.
Each question in this subset is structured as a
yes/no question, designed to elicit a binary re-
sponse. The questions range from basic atomic
structure, such as ""Does an atom consist of a pos-
itively charged nucleus surrounded by a cloud of
negatively charged electrons?"" to more specific
queries about X-ray production and penumbra ef-
fect, such as ""In X-ray production, does the effi-
ciency of x-ray production depend on the size of
the target?"" or ""Is physical penumbra influenced by
geometric penumbra, beam energy, and the lateral
transport of electrons in the tissues?""
This dataset provides an avenue to evaluate the
ability of NLP models to apply logical reasoning
within the domain-specific context of radiation on-
cology, emphasizing both the understanding of fun-
damental radiation oncology concepts and the abil-
ity to apply this knowledge to specific scenarios.
2
1. Head and neck cancers of tumors located at the base of the 
skull where nerves come out.
Label: Proton therapy.
2. Lung cancers in the middle of chest or near the esophagus.
Label: Proton therapy
3. Lower-cost option for prostate cancers.
Label: Photon therapy
Proton therapy?
Photon therapy?
Tumor location & size
Comorbidities
Cost
……
……
Figure 2: Illustration of the Clinical Text Classification dataset.
2.2
Clinical Text Classification
The Clinical Text Classification subset of ROND
is designed to test the capability of NLP models
in categorizing text inputs related to radiation on-
cology into predefined labels. This specific task
focuses on determining the appropriate type of ther-
apy (""Proton therapy"" or ""Photon therapy"") based
on descriptions of different cancer scenarios. We
manually created and annotated 100 cases for this
dataset. Please see Figure 2 for an illustration of
this dataset.
The dataset presents a variety of clinical sce-
narios and characteristics of cancers, such as the
location and sensitivity of the tumor, cost consid-
erations, patient demographics, and potential risks.
These descriptions are then categorized into two
major classes: ""Proton therapy"" and ""Photon ther-
apy"".
Examples include categorizing ""Head and neck
cancers of tumors located at the base of the skull
where nerves come out"" and ""Cancers in children""
under the label ’Proton therapy’. On the other hand,
""Lower-cost option for prostate cancers"" and ""Bet-
ter protection of skin"" are classified under ’Photon
therapy’.
We aim to facilitate the training and evaluation
of NLP models capable of accurately classifying
radiation oncology cases into relevant treatment
venues, thereby potentially aiding decision-making
processes in clinical settings.
2.3
Named Entity Recognition (NER)
The Named Entity Recognition (NER) subset of
ROND is designed to annotate entities in the text
that pertain to the field of radiation oncology. This
task is crucial for understanding specific details
within the text, such as identifying the names of
doctors and patients (PERSON), types of diseases
(DISEASE), types of treatment (TREATMENT),
anatomical structures (ANATOMY), numeric val-
ues (NUMBER), symptoms (SYMPTOM), and out-
comes (OUTCOME). We asked GPT-4 to generate
sample sentences, and manually reviewed and an-
notated 20 sets of NER samples that are factually
correct. While not all sentences necessarily contain
all seven NER tags, these are the maximum pos-
sible tags that any sentence from our sample sets
might include. Figure 3 presents a sample from the
NER dataset.
For instance, in the sentence ""Dr. Jenkins, a radi-
ation oncologist, treated patient Sarah Williams for
breast cancer, utilizing intensity-modulated radia-
tion therapy (IMRT) with a total dose of 50 Gy in
25 fractions"", the model is expected to identify ""Dr.
Jenkins"" as a PERSON, ""radiation"" and ""intensity-
modulated radiation therapy"" as a TREATMENT,
""breast"" as an ANATOMY, ""50"" and ""25"" as NUM-
BERs, and ""skin irritation"" as a SYMPTOM.
In the context of another sentence, ""In a study
3
Sentence: Dr. Patel reported that the 30 patients with stage IIIB non-small
cell lung cancer who underwent concurrent chemoradiation therapy
showed a significant decrease in dyspnea and cough symptoms compared
to those receiving radiotherapy alone.
Tokens: [Dr., Patel, reported, that, the, 30, patients, with, stage, IIIB, non-
small, cell, lung, cancer, who, underwent, concurrent, chemoradiation,
therapy, showed, a, significant, decrease, in, dyspnea, and, cough,
symptoms, compared, to, those, receiving, radiotherapy, alone]
NER_tags: [Dr. (B-PERSON), Patel (I-PERSON), reported (O), that (O), the (O),
30 (B-NUMBER), patients (O), with (O), stage (B-DISEASE), IIIB (B-DISEASE),
non-small (I-DISEASE), cell (I-DISEASE), lung (I-DISEASE), cancer (I-DISEASE),
who (O), underwent (O), concurrent (B-TREATMENT), chemoradiation (I-
TREATMENT), therapy (I-TREATMENT), showed (O), a (O), significant (O),
decrease (O), in (O), dyspnea (B-SYMPTOM), and (O), cough (B-SYMPTOM),
symptoms (I-SYMPTOM), compared (O), to (O), those (O), receiving (O),
radiotherapy (B-TREATMENT), alone (O)]
Person
Other
Number
Symptom
Treatment
Disease
Figure 3: A sample of the NER dataset.
led by Dr.
Jackson, 60 patients with glioblas-
toma were treated using hypofractionated radiation
therapy, administering 40 Gy in 15 fractions"", the
model should detect ""Dr. Jackson"" as a PERSON,
""glioblastoma"" as a SYMPTOM, ""hypofraction-
ated radiation therapy"" as a TREATMENT, and
""40"" and ""15"" as NUMBERs.
The objective of this subset is to evaluate a
model’s ability to identify these entities in radia-
tion oncology text, which is fundamental for struc-
tured information extraction and other downstream
tasks such as de-identification of sensitive patient
information (e.g., names and addresses) (Liu et al.,
2023b).
2.4
Text Summarization
The Text Summarization dataset within the Radia-
tion Oncology NLP Database offers a unique set of
resources for the exploration of text summarization
methods in a highly specialized medical context.
This dataset comprises a variety of research ab-
stracts from arXiv that are categorized under the
Medical Physics class. First, we collected all such
papers published since 2022. We then program-
matically extracted the abstracts from these papers
and asked GPT-4 to produce summaries. Finally,
we manually selected 200 paper abstracts that are
correctly and meaningfully summarized by GPT-4
to form this dataset.
Each record within the dataset includes key bib-
liographic information such as the title of the re-
search, the authors involved, the submission date,
the arXiv identifier, the DOI, and the BibTeX entry.
The categorization information is also provided in
the form of classifications.
The core components of each record are the
abstract and its corresponding summary. The ab-
stracts provide a brief, yet comprehensive overview
of the research conducted, including its objectives,
methodology, results, and conclusions.
Corre-
spondingly, the summaries distill the critical el-
ements of these abstracts into a concise form, de-
signed to swiftly provide the reader with the key
takeaways of the study.
These pairs of abstracts and their summaries con-
stitute a valuable resource for supervised learning
tasks. They can facilitate the development and
fine-tuning of models focused on abstract summa-
rization within the domain of radiation oncology
and medical physics, a critical area in the broader
field of cancer treatment.
2.5
Question and Answering (QA)
The QA subset of the Radiation Oncology NLP
Database stands as a rigorous and comprehensive
collection of multiple-choice questions encompass-
ing a vast array of topics within the field of ra-
diation physics. We in-house designed 100 ques-
tions comparable to those in the RAPHEX exam
(Hendee et al., 2007), which is a radiation oncology
4
Figure 4: A sample multiple-choice question from the QA dataset.
physics test-preparation exam for medical physi-
cists and radiation oncologists. We created these
questions from scratch, as we are not legally per-
mitted to reproduce or redistribute materials from
the RAPHEX exam. The questions cover eight cat-
egories: ""math-based questions"", ""basic physics"",
""radiation measurements"", ""treatment planning"",
""imaging modalities and applications"", ""brachyther-
apy"", ""advanced treatment planning"", and ""safety,
QA, and protection"". Figure 4 contains an example
from the QA dataset.
Each question in this dataset demands a deep
understanding of core radiation physics principles.
Topics range from particle acceleration and atomic
mass structures to photon interactions, x-ray spec-
tra, radiation attenuation, and the functionalities of
a linear accelerator. The multiple-choice format
adds a layer of complexity to the challenge, neces-
sitating that AI models not only comprehend the
underlying physics concepts but also discern the
most accurate answer from a selection of closely
related options.
This dataset is designed to mimic the stringent
conditions of academic assessments in the field.
This design aids in creating a realistic test of an
AI model’s abilities in knowledge comprehension,
reasoning, and mathematical computation under
conditions mirroring those in a professional or edu-
cational context.
3
Clinical significance
Logic Reasoning: The development of models
capable of logic reasoning in radiation oncology
holds the promise of aiding professionals in com-
plex decision-making processes. Such models can
enhance the comprehension of intricate clinical
scenarios, support decision-making, and optimize
individualized treatment planning. This would be
particularly useful in areas such as proton therapy
where detailed reasoning often guides the selection
between different treatment strategies (Liu et al.,
2012; Unkelbach et al., 2018; Schild et al., 2014).
Clinical Text Classification: By training models
to classify clinical cases, we are opening avenues
to more personalized and efficient patient care. For
instance, classifying patient cases into categories
such as eligibility for photon versus proton ther-
apy based on patient information and clinical notes
can expedite decision making and improve treat-
ment outcomes (Bitterman et al., 2021; Taylor et al.,
2023).
Named Entity Recognition (NER): NER tasks,
which involve identifying and classifying key in-
formation in text, provide a structured way to ex-
tract critical data points from unstructured clinical
notes. This functionality is crucial in radiation on-
cology where specific entities, such as tumor types,
anatomical locations, or dosimetric parameters, are
paramount for the creation of optimal treatment
plans (Unkelbach et al., 2018; Schild et al., 2014;
Liu et al., 2018).
Text Summarization: The ability to extract the
most salient information from large volumes of text
is valuable in any field (El-Kassas et al., 2021), but
in radiation oncology, it can directly contribute to
improved patient care. For example, summarizing
the key findings of the latest research in radiation
oncology could help clinicians stay updated with
current knowledge without having to go through
lengthy papers, enabling them to swiftly apply
these findings in their practice. In addition, text
summarization can produce succinct descriptions
from lengthy clinical reports and notes (Feblowitz
et al., 2011; Cai et al., 2021; Liu et al., 2023b),
which can significantly save time and facilitate clin-
ical communication.
Question and Answering (QA): QA systems in
the domain of radiation oncology could revolution-
5
Figure 5: A detailed analysis of LLMs’ performance on the medical physics board exam (RAPHEX) level questions.
Bard
ChatGPT
GPT-4
0.600
0.456
0.656
Table 1: Accuracy of state-of-the-art LLMs on the Logic
Reasoning dataset.
Bard
ChatGPT
GPT-4
0.770
0.740
0.840
Table 2: Accuracy of state-of-the-art LLMs on the Text
Classification dataset.
ize the way practitioners access and analyze rele-
vant information. Being able to ask specific ques-
tions and receive accurate answers quickly, whether
in terms of patient history, or intricate radiobiologi-
cal effects (Wang et al., 2018; Omer, 2021), would
immensely improve the efficiency of the oncology
practice, saving practitioners time and possibly en-
hancing patient outcomes. The QA dataset in this
database delineates the knowledge needed for ef-
fective QA in this highly specialized domain.
4
A Conversational Instruction Tuning
Dataset based on ROND
To facilitate future development of radiation on-
cology focused language models, we employed
a data generation method to create synthetic data
based on expert annotated data from the six key
components within ROND: Logic Reasoning, Clin-
Bard
ChatGPT
GPT-4
0.667
0.642
0.785
Table 3: Accuracy of state-of-the-art LLMs on the NER
dataset.
Bard
ChatGPT
GPT-4
0.139
0.270
0.317
Table 4: BLEU4 scores of state-of-the-art LLMs on the
Text Summarization dataset.
ical Text Classification, Named Entity Recognition
(NER), Text Summarization, Question and Answer-
ing (QA), and Conversational data.
This synthetic data generation process was car-
ried out to build a large dataset suitable for ""in-
struction tuning"". Instruction tuning is an effec-
tive approach aimed at enhancing language models’
ability to comprehend and follow natural language
inputs based on training on pairs of instruction-
input-outputs (Wei et al., 2021; Peng et al., 2023).
This strategy facilitates multi-task learning and en-
hances generalization for unseen tasks (Ouyang
et al., 2022).
We processed the diverse data formats within
ROND into a unified instruction tuning structure,
where each data entry consists of three components:
instruction, input, and output (please refer to Figure
7 for an example). This uniform structure stream-
6
Figure 6: Data augmentation and instruction tunning.
Figure 7: An example from the instruction tuning dataset.
Bard
ChatGPT
GPT-4
0.410
0.530
0.760
Table 5: Accuracy of state-of-the-art LLMs on the QA
dataset.
ChatGPT
CancerChat
26
24
Table 6: Preference evaluation between ChatGPT and
CancerChat.
lines the training and tuning process, contributing
to more efficient learning and inference.
For the data augmentation/synthetic data gener-
ation, we utilized the APIs of ChatGPT and GPT-
4. Specifically, we employed the ChatGPT API
to generate synthetic samples for the Conversa-
tional data, Text Summarization, and Named Entity
Recognition. These tasks require somewhat less
domain-specific understanding of radiation oncol-
ogy, making ChatGPT a fitting choice. On the other
hand, for tasks such as Logic Reasoning, Clinical
Text Classification, and Question Answering that
require more depth of understanding and reason-
ing ability, we used the GPT-4 API. This decision
leverages the strength of each AI model, ensuring
optimal synthetic data generation across different
tasks within the ROND database.
We scaled ROND from a few hundred data sam-
ples to 20,160 instruction tuning pairs. The ma-
jority of these samples, over 17,000, are conversa-
tional, simulating interactions between patients and
healthcare providers. This is supplemented with
500 samples each for Logic Reasoning and Clin-
ical Text Classification, and 1,000 samples each
for Named Entity Recognition and Text Summa-
rization. This ensures a comprehensive dataset that
reflects the multifaceted nature of language process-
ing in the context of radiation oncology, thereby
providing a robust base for developing and refining
future NLP models in this domain. Furthermore,
the emphasis on conversational data equips mod-
els trained on this dataset provides the potential
to create efficient chatbots specialized in radiation
oncology.
4.1
CancerChat
To evaluate the effectiveness and utility of the in-
struction tuning dataset, we trained a demo lo-
cal LLM, CancerChat, based on Falcon-7B (Al-
mazrouei et al., 2023) (a model that recently tops
the Open LLM Leaderboard (Face)). Figure 6 il-
lustrates the process of generating the instructiom-
tuning dataset and the training of CancerChat.
The training was conducted on a server with 1
A100 80GB GPU. We utilize LoRA (Low Rank
Adaptation) (Hu et al., 2021) since LoRA weights
facilitate model sharing and deployment. Our train-
ing parameters were: a batch size of 128, a fixed
learning rate at 3e-4, a lora_r (the rank of the low-
rank factorization) set to 8, a lora_alpha (the scaling
factor for the rank) set to 16, and a dropout rate of
7
0.05 to mitigate overfitting.
To preliminarily assess the performance of Can-
cerChat, we conducted a blind comparison using
50 queries (see Table 6). A medical physicist was
asked to evaluate and express their preference for
the responses generated by ChatGPT and Cancer-
Chat. The comparison yielded close results, with
26 of the 50 responses more favorable for ChatGPT,
while the remaining 24 preferred CancerChat.
These preliminary results underscore the poten-
tial of CancerChat, which, despite being a smaller
local model specifically tailored for the domain
of radiation oncology, demonstrated competitive
performance when compared to ChatGPT. This
suggests the feasibility and promise of developing
domain-specific language models leveraging our
instruction-tuning dataset, offering a pathway for
future advancements in NLP for medical special-
ties.
5
Benchmarking Large Language Models
We evaluate three state-of-the-art language mod-
els, namely Bard (powered by Google PaLM 2
(Anil et al., 2023)), ChatGPT (OpenAI), and GPT-
4 (OpenAI, 2023), against the proposed radiation
oncology NLP database and obtained insightful
results.
On the Logic Reasoning dataset, GPT-4 achieved
the highest accuracy of 0.656, followed by Bard
with an accuracy of 0.600, while ChatGPT scored
the lowest with an accuracy of 0.456 (Table 1).
On the Clinical Text Classification dataset, GPT-
4 again outperformed the other two models with an
accuracy of 0.840. However, the performance gap
was narrower with Bard and ChatGPT registering
accuracies of 0.770 and 0.740, respectively (Table
2). Similar trends were observed in the Named
Entity Recognition (NER) dataset, where GPT-4
led with an accuracy of 0.758. Bard scored 0.667,
and ChatGPT trailed with an accuracy of 0.646
(Table 3).
For text summarization (evaluated using the
BLEU score (Papineni et al., 2002)), GPT-4
recorded the highest score of 0.317, with ChatGPT
performing markedly better than Bard, scoring
0.270 compared to Bard’s 0.139 (Table 4). Finally,
on the Question Answering (QA) dataset, GPT-
4 once again demonstrated superior performance
with an accuracy of 0.760. ChatGPT achieved an
accuracy of 0.530, while Bard scored the lowest
with 0.410 (Table 5). We also conducted a detailed
analysis on eight categories of the QA dataset. Gen-
erally, GPT-4 outperformed both trained medical
physicists and non-experts who participated in this
study. The medical physicists averaged an accuracy
of 0.76, while the non-experts averaged 0.28.
These results underscore the effectiveness of
GPT-4 across various NLP tasks. However, while
GPT-4 demonstrated superior performance across
the evaluated NLP tasks in ROND, we hold these
results as a baseline for future research. As state-
of-the-art as these models may be, we envision the
development of more refined models specifically
tailored to the domain of radiation oncology. These
specialized models will likely exhibit improved per-
formance and understanding of the nuances of this
unique field and deliver significant potential for
advancing radiation oncology and clinical NLP.
Limitations
The primary limitation of this study is inherent to
its novelty. ROND represents the first dedicated
NLP dataset in the field of radiation oncology. As
such, it is anticipated that there will be inherent
challenges and unforeseen issues associated with
this dataset that will only become apparent when
the database is utilized practically by the commu-
nity. The efficacy and practical utility of language
models trained or evaluated on this dataset will
need to be validated through real-world applica-
tion and extensive feedback from clinicians. This
iterative process of application, feedback, and re-
finement is essential to not only identify potential
problems but also to improve the robustness and ap-
plicability of the models derived from this dataset.
Ethics Statement
The authors of this study conducted the research
in strict adherence to ethical guidelines and there
is no involvement of Protected Health Information
(PHI). We acknowledge that while this study has
the potential to greatly improve radiation oncology
NLP, it is necessary to consider the need for respon-
sible use and development of AI. Any potential
bias or errors within the dataset can have signifi-
cant implications on model training and subsequent
applications. Thus, we recommend rigorous valida-
tion, including feedback from clinical practitioners,
before deploying models trained on this dataset in
a practical setting. Future research should also be
conducted with the broader social and ethical im-
plications in mind, always prioritizing the safety
8
and best interests of patients.
References
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al-
shamsi, Alessandro Cappelli, Ruxandra Cojocaru,
Merouane Debbah, Etienne Goffinet, Daniel Hes-
low, Julien Launay, Quentin Malartic, Badreddine
Noune, Baptiste Pannier, and Guilherme Penedo.
2023. Falcon-40B: an open large language model
with state-of-the-art performance.
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin John-
son, Dmitry Lepikhin, Alexandre Passos, Siamak
Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
Chen, et al. 2023. Palm 2 technical report. arXiv
preprint arXiv:2305.10403.
Jacques Bernier, Eric J Hall, and Amato Giaccia. 2004.
Radiation oncology: a century of achievements. Na-
ture Reviews Cancer, 4(9):737–747.
Danielle S Bitterman, Timothy A Miller, Raymond H
Mak, and Guergana K Savova. 2021. Clinical natural
language processing for radiation oncology: a review
and practical primer. International Journal of Radia-
tion Oncology* Biology* Physics, 110(3):641–655.
Sébastien Bubeck, Varun Chandrasekaran, Ronen El-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-
berg, et al. 2023. Sparks of artificial general intelli-
gence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712.
Xiaoyan Cai, Sen Liu, Junwei Han, Libin Yang, Zhen-
guo Liu, and Tianming Liu. 2021. Chestxraybert: A
pretrained language model for chest radiology report
summarization. IEEE Transactions on Multimedia.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, et al. 2022. Palm: Scaling
language modeling with pathways. arXiv preprint
arXiv:2204.02311.
Wafaa S El-Kassas, Cherif R Salama, Ahmed A Rafea,
and Hoda K Mohamed. 2021. Automatic text sum-
marization: A comprehensive survey. Expert systems
with applications, 165:113679.
Hugging Face.
Open LLM Leaderboard - a Hug-
ging Face Space by HuggingFaceH4 — hug-
gingface.co.
https://huggingface.co/spaces/
HuggingFaceH4/open_llm_leaderboard.
Joshua C Feblowitz, Adam Wright, Hardeep Singh,
Lipika Samal, and Dean F Sittig. 2011. Summa-
rization of clinical information: a conceptual model.
Journal of biomedical informatics, 44(4):688–699.
William R Hendee, Howard I Amols, and Colin G Or-
ton. 2007. The abr written and oral examinations
in medical physics as currently conducted are suf-
ficiently comprehensive and demanding to ensure
that successful candidates have adequate knowledge
and experience to practice in the designated specialty
field. Medical physics, 34(9):3417–3419.
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
and Weizhu Chen. 2021.
Lora: Low-rank adap-
tation of large language models.
arXiv preprint
arXiv:2106.09685.
Chenbin Liu, Terence T Sio, Wei Deng, Jie Shan,
Thomas B Daniels, William G Rule, Pedro R Lara,
Shawn M Korte, Jiajian Shen, Xiaoning Ding, et al.
2018. Small-spot intensity-modulated proton therapy
and volumetric-modulated arc therapies for patients
with locally advanced non-small-cell lung cancer: a
dosimetric comparative study. Journal of applied
clinical medical physics, 19(6):140–148.
Wei Liu, Xiaodong Zhang, Yupeng Li, and Radhe Mo-
han. 2012. Robust optimization of intensity modu-
lated proton therapy. Medical physics, 39(2):1079–
1091.
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang,
Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li,
Mengshen He, Zhengliang Liu, et al. 2023a. Sum-
mary of chatgpt/gpt-4 research and perspective to-
wards the future of large language models. arXiv
preprint arXiv:2304.01852.
Zhengliang Liu, Xiaowei Yu, Lu Zhang, Zihao Wu,
Chao Cao, Haixing Dai, Lin Zhao, Wei Liu, Ding-
gang Shen, Quanzheng Li, et al. 2023b. Deid-gpt:
Zero-shot medical text de-identification by gpt-4.
arXiv preprint arXiv:2303.11032.
Hiba Omer. 2021. Radiobiological effects and medical
applications of non-ionizing radiation. Saudi Journal
of Biological Sciences, 28(10):5585–5592.
OpenAI. Introducing ChatGPT — openai.com. https:
//openai.com/blog/chatgpt.
OpenAI. 2023. Gpt-4 technical report. arXiv.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
2022.
Training language models to follow in-
structions with human feedback.
arXiv preprint
arXiv:2203.02155.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computa-
tional Linguistics, pages 311–318.
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Gal-
ley, and Jianfeng Gao. 2023. Instruction tuning with
gpt-4. arXiv preprint arXiv:2304.03277.
9
Saed Rezayi, Haixing Dai, Zhengliang Liu, Zihao Wu,
Akarsh Hebbar, Andrew H Burns, Lin Zhao, Dajiang
Zhu, Quanzheng Li, Wei Liu, et al. 2022. Clinical-
radiobert: Knowledge-infused few shot learning for
clinical notes named entity recognition. In Machine
Learning in Medical Imaging: 13th International
Workshop, MLMI 2022, Held in Conjunction with
MICCAI 2022, Singapore, September 18, 2022, Pro-
ceedings, pages 269–278. Springer.
Steven E Schild, William G Rule, Jonathan B Ashman,
Sujay A Vora, Sameer Keole, Aman Anand, Wei
Liu, and Martin Bues. 2014. Proton beam therapy
for locally advanced lung cancer: A review. World
journal of clinical oncology, 5(4):568.
Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mah-
davi, Jason Wei, Hyung Won Chung, Nathan Scales,
Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl,
et al. 2022. Large language models encode clinical
knowledge. arXiv preprint arXiv:2212.13138.
Paige A Taylor, Elizabeth Miles, Lone Hoffmann,
Sarah M Kelly, Stephen F Kry, Ditte Sloth Møller,
Hugo Palmans, Kamal Akbarov, Marianne C Aznar,
Enrico Clementel, et al. 2023. Prioritizing clinical
trial quality assurance for photons and protons: A
failure modes and effects analysis (fmea) compari-
son. Radiotherapy and Oncology, 182:109494.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et al. 2023. Llama: Open and effi-
cient foundation language models. arXiv preprint
arXiv:2302.13971.
Jan Unkelbach, Markus Alber, Mark Bangert, Rasmus
Bokrantz, Timothy CY Chan, Joseph O Deasy, Albin
Fredriksson, Bram L Gorissen, Marcel Van Herk,
Wei Liu, et al. 2018. Robust radiotherapy planning.
Physics in Medicine & Biology, 63(22):22TR02.
Rong Wang, Tingyang Zhou, Wei Liu, and Li Zuo.
2018. Molecular mechanism of bystander effects
and related abscopal/cohort effects in cancer therapy.
Oncotarget, 9(26):18637.
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drew M Dai, and Quoc V Le. 2021. Finetuned lan-
guage models are zero-shot learners. arXiv preprint
arXiv:2109.01652.
Lin Zhao, Lu Zhang, Zihao Wu, Yuzhong Chen, Haixing
Dai, Xiaowei Yu, Zhengliang Liu, Tuo Zhang, Xintao
Hu, Xi Jiang, et al. 2023. When brain-inspired ai
meets agi. arXiv preprint arXiv:2303.15935.
10
"
"Communication acts as a powerful tool in harmonizing the behaviors of multiple agents. However, current methods primarily emphasize broadcast communication, lacking practicality, and leading to information redundancy. This information overload negatively impacts communication efficiency. Meanwhile, commonly used methods rely on fundamental mechanisms to integrate observed and obtained information, hindering the learning process. The Targeted and Trusted Multi-Agent Communication (T2MAC) approach resolves these issues by integrating selective engagement, evidence-driven integration, and effective message composition. Using T2MAC, agents craft personalized messages, identify opportune communication windows, and engage with dependable partners, enhancing communication efficiency. The messages obtained are integrated at the evidence level, leveraging available perspectives collectively. Extensive experiments on cooperative multi-agent tasks demonstrate T2MAC's superiority in cooperative performance and communication efficiency compared to state-of-the-art techniques. Additionally, T2MAC exhibits impressive generalization capabilities.nan","Reinforcement Learning (RL) has achieved notable advancements in complex real-world scenarios, including Game AI, Robotics, and Autonomous Driving. Conversely, cooperative multi-agent settings present distinct challenges due to the partial observability faced by agents, restricted to their local observations without a comprehensive view of the environment. Moreover, Multi-Agent Reinforcement Learning (MARL) grapples with the non-stationarity of the environment, introducing further complexities during learning. Multi-agent communication offers a compelling solution, allowing agents to extract deeper insights from collective perspectives, facilitating stable learning and harmonized actions. Past methods in this domain predominantly focused on message content and timing but fell short in addressing broadcast communication inefficiencies and the treatment of information integration as a black box. Addressing these shortcomings, we propose the T2MAC framework.nan","Several key areas of research related to MARL and multi-agent communication have been explored in the literature:

- Deciding What to Communicate: Prior studies have delved into the formulation of dynamic and continuous messages, enabling real-time adaptation to environmental changes. Researchers have optimized message learning processes and tailored messages for specific agents.

- Deciding When and With Whom to Communicate: The timing and partner selection for communication have garnered significant attention. Novel strategies like weight-based schedulers prioritize agents with crucial observations, while other approaches harness methods such as causal inference, graph-attention, and Shapley message value to identify ideal communication recipients.

- Incorporating Messages for Cooperative Decision-Making: Integrating incoming messages into decision-making processes has also been a focus of research. Prominent approaches employ representation learning paradigms to discern message significance, enabling selective assimilation. However, existing methodologies have yet to simultaneously address targeted and trusted communication.nannan","At the core of our approach is the T2MAC framework, characterized by four distinctive aspects:

1. Policy:
   - T2MAC's policy is modeled as a Dirichlet distribution, facilitating the integration of evidence from diverse sources for informed and reliable decisions.
   - The evidence encoder serves a dual purpose: extracting evidence for its decisions and crafting tailored messages for teammates, aiding their decision-making.

2. Selective Engagement:
   - To ensure efficient communication, T2MAC pinpoints optimal moments and counterparts for communication, ensuring the dissemination of only the most pertinent and reliable data.
   - This is achieved through an ablative decision-making analysis to quantify the strength and relevance of each communication link between agents.
   - A communication selector network is developed to enable agents to determine the right moments and partners for communication.

3. Evidence-Driven Integration:
   - T2MAC incorporates the theory of evidence into multi-agent communication.
   - Evidence refers to metrics extracted from observations that support decision-making processes.
   - To capture uncertainties inherent in decision-making, the Dirichlet distribution and Subjective Logic (SL) are employed to deduce the concentration parameters and belief and uncertainty masses associated with each action.
   - Evidence collected by different agents is integrated using Dempster-Shafer theory of evidence, enabling the combination of evidence from multiple sources to derive a comprehensive belief and uncertainty.nan","1. Performance:
   - T2MAC exhibited superior performance across various environments, including Hallway, MPE, and SMAC, consistently outperforming state-of-the-art communication methods.
   - T2MAC demonstrated resilience under challenging conditions, maintaining strong performance even in complex scenarios with numerous agents and long Markov chains.
   - Non-communication baselines consistently underperformed, highlighting the importance of proficient communication in these contexts.

2. Efficiency:
   - T2MAC achieved significant communication efficiency gains compared to other methods, delivering substantial performance improvements while minimizing communication frequency.
   - The calculated communication efficiency metric underscores T2MAC's adeptness in managing communication dynamics, optimizing when to communicate, with whom, and how to balance performance and efficiency.

3. Generality:
   - T2MAC demonstrated strong generalization capabilities across a wide range of established MARL baselines, including QMIX, DOP, and MAPPO.
   - It consistently achieved superior performance across these baselines, further highlighting its broad applicability and effectiveness in MARL.nan","T2MAC effectively addresses the challenges inherent in multi-agent communication. Traditional approaches rely on broadcast communication and treat information fusion as a black box, resulting in diminished communication efficiency. To overcome these limitations, T2MAC empowers agents with the capability to compose messages tailored for distinct agents, strategically selecting communication timings, and relying on trusted partners. Moreover, it integrates incoming messages efficiently, facilitating trusted decision-making. Rooted in solid theoretical principles, T2MAC demonstrates its effectiveness through comprehensive experiments across multiple benchmarks, showcasing its superiority in efficiency, adaptability, and overall performance.nan",T2MAC: Targeted and Trusted Multi-Agent Communication through Selective Engagement and Evidence-Driven Integration,"Chuxiong Sun, Zehua Zang, Jiabao Li, Jiangmeng Li, Xiao Xu, Rui Wang, Changwen Zheng","T2MAC: Targeted and Trusted Multi-Agent Communication through Selective
Engagement and Evidence-Driven Integration
Chuxiong Sun1 2*, Zehua Zang1 3*, Jiabao Li4*, Jiangmeng Li1 2†, Xiao Xu2, Rui Wang1 2 3,
Changwen Zheng1 3
1Science & Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences
2State Key Laboratory of Intelligent Game
3University of Chinese Academy of Sciences
4School of Automation and Electrical Engineering, University of Science and Technology Beijing
{chuxiong2016,zehua2020}@iscas.ac.cn, M202110548@xs.ustb.edu.cn, jiangmeng2019@iscas.ac.cn,
xuxiao0825@gmail.com, {wangrui,changwen}@iscas.ac.cn,
Abstract
Communication stands as a potent mechanism to harmonize
the behaviors of multiple agents. However, existing works
primarily concentrate on broadcast communication, which
not only lacks practicality, but also leads to information re-
dundancy. This surplus, one-fits-all information could ad-
versely impact the communication efficiency. Furthermore,
existing works often resort to basic mechanisms to integrate
observed and received information, impairing the learning
process. To tackle these difficulties, we propose Targeted and
Trusted Multi-Agent Communication (T2MAC), a straight-
forward yet effective method that enables agents to learn
selective engagement and evidence-driven integration. With
T2MAC, agents have the capability to craft individualized
messages, pinpoint ideal communication windows, and en-
gage with reliable partners, thereby refining communication
efficiency. Following the reception of messages, the agents
integrate information observed and received from different
sources at an evidence level. This process enables agents to
collectively use evidence garnered from multiple perspec-
tives, fostering trusted and cooperative behaviors. We eval-
uate our method on a diverse set of cooperative multi-agent
tasks, with varying difficulties, involving different scales and
ranging from Hallway, MPE to SMAC. The experiments in-
dicate that the proposed model not only surpasses the state-
of-the-art methods in terms of cooperative performance and
communication efficiency, but also exhibits impressive gen-
eralization.
Introduction
Reinforcement Learning (RL) has achieved remarkable
milestones in a myriad of intricate real-world domains, rang-
ing from Game AI (Osband et al. 2016; Silver et al. 2017,
2018; Vinyals et al. 2019) and Robotics (Andrychowicz
et al. 2020) to Autonomous Driving (Dosovitskiy et al.
2017). However, when delving into cooperative multi-agent
settings, distinct challenges surface. The issue of partial ob-
servability stands out, where agents are confined to their lo-
*These authors contributed equally.
†Corresponding author.
Copyright © 2024, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
cal observations, missing out on the broader perspective of
the entire environment. Complicating matters further, Multi-
Agent Reinforcement Learning (MARL) grapples with the
non-stationarity of the environment. From an individual
agent’s perspective, the environmental dynamics shift inces-
santly, adding another layer of complexity to the learning
process.
Multi-agent communication offers a compelling solution
to the issues outlined by granting agents the capability to
derive a deeper understanding of their surroundings through
collective insights. This approach ensures stable learning
and encourages harmonized actions among agents. How-
ever, historical methods have focused on the content and
timing of communication (Sukhbaatar, Szlam, and Fergus
2016; Singh, Jain, and Sukhbaatar 2018; Kim et al. 2019;
Wang et al. 2020b; Zhang, Zhang, and Lin 2020; Yuan et al.
2022). Once an agent elects to share its message, it is broad-
cast to the entire agent group. This indiscriminate broadcast-
ing is not only resource-intensive but also potentially ineffi-
cient.
A pivotal realization is that only some agents carry valu-
able insights, and flooding the network with redundant in-
formation can be counterproductive to learning. Interest-
ingly, humans know when to communicate intrinsically,
with whom, and how to customize their messages to the re-
cipient. Mirroring these human instincts could significantly
refine the information exchange process, allowing agents to
curate their messages and recipients selectively.
Moreover, the essence of messages relayed by agents
is a distillation of their individual observational expe-
riences. Assimilating these messages aptly can enrich
agents’ perception of an uncertain environment, leading
to more refined policies. Regrettably, the existing tech-
niques—whether they’re steeped in basic aggregation (Jiang
and Lu 2018) or are more avant-garde with representation
learning (Das et al. 2019; Guan et al. 2022) tend to treat the
fusion of information as a black box, presupposing that the
policy networks can innately sift out vital data and diminish
decision-making uncertainty. In this context, the information
integration process might prove to be both uncertain and in-
efficient, especially in intricate scenarios. As such, there’s
arXiv:2401.10973v1  [cs.MA]  19 Jan 2024
a pressing need for a novel and theory-grounded approach
that can adeptly merge messages while tackling the inherent
underlying uncertainties.
With this vision, we introduce the Targeted and Trusted
Multi-Agent Communication (T2MAC) framework, which
embodies the principles of discerning and streamlined com-
munication, drawing inspiration from human inclinations to
engage selectively with trusted and relevant counterparts,
ensuring more efficient information integration, and foster-
ing a more adaptive multi-agent collaboration in dynamic
environments. Specifically, each agent is skilled at analyz-
ing observations to extract evidence. In this context, evi-
dence denotes metrics instrumental in guiding the decision-
making processes. This evidence plays a dual role: guid-
ing local decision-making and serving as the basis for craft-
ing messages that are meticulously tailored to specific agent
contexts. Moreover, we evaluate the variations in uncer-
tainty prior to and post-communication to measure the im-
pact and significance of specific communication behavior.
Armed with these insights, we craft binary pseudo-labels
based on the significance of communication and devise an
auxiliary task. This task is specifically designed to train a
communication selector network, empowering it to iden-
tify the ideal communication counterparts. By adopting this
strategy, we guarantee that only the most relevant and credi-
ble data is exchanged among the agents. Upon receipt, mes-
sages are integrated at the evidence level rather than the con-
ventional observation or feature level. To capture the intri-
cacies of decision-making, we leverage the Dirichlet distri-
bution. This allows us to model decision policies, anchor-
ing them on evidence that’s been sourced from a myriad
of perspectives. Concretely, we integrate Subjective Logic
(SL) (Jsang 2018) to link the Dirichlet parameters with be-
lief and uncertainty, therefore quantifying the uncertainty
for decision-making and jointly modeling the probability
of each action. Then, we utilize Dempster-Shafer theory of
evidence (DST) (Dempster 1967) to integrate evidence ob-
served from multiple agents, producing a comprehensive be-
lief and uncertainty that considers all available evidence, en-
suring trusted message integration and decision-making. We
subjected T2MAC to rigorous testing across various MARL
environments, such as Hallway, MPE, and SMAC. Com-
pared to prominent multi-agent communication strategies
like TarMac (Das et al. 2019), MAIC (Yuan et al. 2022),
SMS (Xue et al. 2022), and MASIA (Guan et al. 2022),
T2MAC consistently excelled in both performance and effi-
ciency. Additionally, its versatility shone through across di-
verse scenarios.
Related Works
MARL has undergone remarkable progression in recent
epochs (Lowe et al. 2017; Sunehag et al. 2017; Rashid et al.
2018; Yu et al. 2022). Within the MARL ambit, multi-agent
communication has emerged as an indispensable aspect, par-
ticularly salient for cooperative endeavors constrained by
partial observability. Research in this domain can be broadly
segmented into three main categories.
Deciding What to Communicate. Historically, communi-
cation vocabularies are set in stone during training, as il-
lustrated by (Foerster et al. 2016). This seemingly efficient
strategy unintentionally limits the depth and flexibility of
agent communication. In response, CommNet (Sukhbaatar,
Szlam, and Fergus 2016) introduces a paradigm shift by
allowing agents to create dynamic, continuous messages.
With its design for continuous interactions, CommNet en-
sures that messages are timely and sensitive to environmen-
tal changes. Building on this foundation, both VBC (Zhang,
Zhang, and Lin 2019) and TMC (Zhang, Zhang, and Lin
2020) further optimize message learning processes. Further-
more, NDQ (Wang et al. 2020b) and MAIC (Yuan et al.
2022) are designed to craft messages tailored for individual
agents.
Deciding When and With Whom to Communicate. Effec-
tive communication timing and partner selection are pivotal
in Multi-Agent Communication. A gating network show-
cased in (Singh, Jain, and Sukhbaatar 2018; Jiang and Lu
2018) generates binary decisions, allowing agents the free-
dom to communicate or abstain. Advancing this idea, (Kim
et al. 2019; Mao et al. 2019; Wang et al. 2020a; Sun
et al. 2021) implement a weight-based scheduler, priori-
tizing agents holding vital observations. Enriching this ap-
proach, I2C (Ding, Huang, and Lu 2020), MAGIC (Niu,
Paleja, and Gombolay 2021), and SMS (Xue et al. 2022)
harness methods like causal inference, graph-attention, and
Shapley message value to pinpoint ideal communication re-
cipients.
Incorporating
Messages
for
Cooperative
Decision-
Making. A prominent subset of the MARL methodologies
posits an egalitarian weightage to all incoming messages.
Such an approach fails to recognize the significance of filter-
ing vital information from a sea of communications. There-
fore, we introduce representation learning paradigms to ad-
dress this lacuna for discerning message assimilation. For
instance, TarMac (Das et al. 2019) adopts soft attention
mechanisms to weight messages, while MASIA (Guan et al.
2022) consolidates received messages into concise represen-
tations using an autoencoder.
To our knowledge, no existing MARL method simul-
taneously addresses targeted and trusted communication.
T2MAC stands as the pioneering approach, enabling agents
to efficiently select communication partners and distill tai-
lored evidence and integrate messages, resulting in trustwor-
thy cooperative decisions.
Background
In this study, we concentrate on fully cooperative multi-
agent reinforcement learning tasks characterized by par-
tial observability while also allowing inter-agent com-
munication. These tasks are an evolved form of De-
centralized Partially Observable Markov Decision Pro-
cesses (Dec-POMDPs). Their framework uses the tuple
𝐺 = (𝑁, 𝑆, 𝑂, 𝐴, O, 𝑃, 𝑅, 𝛾, 𝑀). In this formulation: 𝑁 =
(𝑎𝑔𝑒𝑛𝑡1, ..., 𝑎𝑔𝑒𝑛𝑡𝑛) depicts the collective of agents. 𝑆 en-
compasses global states, offering a comprehensive environ-
mental overview. 𝑂 refers to the accessible local observa-
tions. 𝐴 signifies a set of available actions. O refers to the
observation function, which describes how agents perceive
Policy
Communication
𝑜𝑖
(a) Agent 𝒊
ℎ𝑖
𝑒⋆𝑖
Evidence Encoder
𝑒𝑖
𝑒𝑖𝑗 𝑒𝑖𝑘 𝑒𝑖𝑙
𝑚⋆𝑖
𝑚𝑖⋆
𝜋𝑖
𝑒𝑗𝑖
𝑒𝑘𝑖
𝑒𝑖
𝛼𝑖
𝜋𝑖
Weighted Sum
DST Combination
(b) Policy
(e) Selective Engagement
Observation Encoder
ℎ𝑖
ℎ𝑖
Selector Network
𝑒𝑖⋆
𝑒𝑖𝑗
𝑏𝑖
𝑢𝑖
𝑔𝑖𝑗: 1
𝑔𝑖𝑘: 0
𝑔𝑖𝑙: 1
𝑒𝑖𝑘
𝑒𝑖𝑙
Dot Product
Agent 𝒊
Agent 𝒋
Agent 𝒌
𝑚𝑗𝑖
𝑚𝑘𝑖
Agent 𝒍
(d) Receiving
Agent 𝒊
Agent 𝒋
Agent 𝒍
Agent 𝒌
𝑚𝑖𝑗
𝑚𝑖𝑙
(f) Sending
𝑚⋆𝑖
𝑚𝑖⋆
Evidence-Driven 
Integration
Selective 
Engagement
𝛼𝑖
(c) Evidence-Driven 
Integration
𝑚𝑖𝑗
𝑚𝑖𝑘
𝑚𝑖𝑙
Figure 1: Framework of T2MAC.
the environment based on the global state. 𝑃 acts as the tran-
sition function, illustrating environmental dynamics. 𝑅 is a
reward function contingent on global states and joint actions.
𝛾 represents the discount factor, 𝑀 delineates the set of com-
municable messages.
At each time step, agents access only local observa-
tions, which are derived from the global state through the
observation function, O(𝑜𝑡
𝑖 |𝑠). Simultaneously, agents are
equipped with the capability to share messages, denoted as
𝑚𝑡
𝑖. These messages might encompass observations, inten-
tions, or past experiences. Crucially, each agent can judi-
ciously decide when to communicate, streamlining the effi-
ciency of the communication process. As messages are re-
ceived, agents integrate their incoming information, leading
to the aggregated message 𝑐𝑡
𝑖 = Í
𝑗≠𝑖 𝑚𝑡
𝑗. This composite
data then guides their localized decision-making, encapsu-
lated by 𝑎𝑡
𝑖 = 𝜋(𝑜𝑡
𝑖, 𝑐𝑡
𝑖). Following this, the environment re-
acts to the joint action, 𝑎 = (𝑎𝑡
1, ..., 𝑎𝑡
𝑛), transitioning to the
subsequent state 𝑠
′. Simultaneously, this joint action then
yields a shared team reward, 𝑟 = 𝑅(𝑠, 𝑎). The overarch-
ing goal is to pinpoint an optimal joint policy geared to-
wards maximizing the expected cumulative team reward, ex-
pressed as E𝑠,𝑎[Í∞
𝑡=0 𝛾𝑡𝑟].
Methodology
As depicted in Fig. 1, the distinctive characteristics of
T2MAC can be highlighted in these four aspects:
• T2MAC’s policy is characterized as a Dirichlet distribu-
tion, facilitating the assimilation of evidence from vari-
ous sources for informed and trusted decisions.
• The evidence encoder serves a dual purpose: extracting
evidence for its own decisions and crafting tailored mes-
sages for specific teammates.
• Through the selective engagement, T2MAC can pinpoint
optimal moments and counterparts for communication,
ensuring the dissemination of only the most pertinent and
reliable data.
• The evidence-driven integration combines incoming
messages at an evidence level, refraining from treating
the fusion process as a black box.
In the following sections, we will illustrate the key compo-
nents of T2MAC in detail.
Theory of Evidence
For communication to be precise and reliable, it’s essen-
tial to factor in the uncertainties intrinsic to individual de-
cisions. To this effect, we have incorporated the theory of
evidence into multi-agent communication. Within this con-
text, evidence pertains to metrics sourced from observations
supporting decision-making processes. To get a grasp on this
evidence and uncertainty, we employ the Dirichlet distribu-
tion, which has proven efficacious in mitigating the overcon-
fidence issue (Sensoy, Kaplan, and Kandemir 2018; Malinin,
Mlodozeniec, and Gales 2020; Malinin and Gales 2018).
This distribution is characterized by its concentration param-
eters, represented as 𝛼 = [𝛼1, ..., 𝛼𝐾] where 𝐾 is the number
of actions. These parameters share an intimate relationship
with uncertainty. Building on this, we harness SL to discern
the concentration parameters. SL offers a theoretical frame-
work for extracting the probabilities (belief masses) of dis-
parate actions and the overarching uncertainty (uncertainty
mass) tied to policy-prediction challenges. Delving deeper
into decision-making quandaries, SL seeks to allocate a be-
lief mass to each action while assigning an overarching un-
certainty mass to the entire scenario based on observed ev-
idence. Consequently, all mass values remain non-negative
and their cumulative value equals one:
𝑢𝑖 +
𝐾
∑︁
𝑘=1
𝑏𝑘
𝑖 = 1
(1)
where 𝑢𝑖 ≥ 0 signifies the overall uncertainty for 𝑎𝑔𝑒𝑛𝑡𝑖,
𝑏𝑘
𝑖 ≥ 0 denotes the belief of 𝑎𝑔𝑒𝑛𝑡𝑖 associated with the 𝑘𝑡ℎ
action.
Moreover, SL elegantly bridges the evidence observed
by 𝑎𝑔𝑒𝑛𝑡𝑖, denoted as 𝑒𝑖
=
[𝑒1
𝑖 , , ..., 𝑒𝐾
𝑖 ], with the pa-
rameters constituting the Dirichlet distribution for 𝑎𝑔𝑒𝑛𝑡𝑖,
𝛼𝑖 = [𝛼1
𝑖 , , ..., 𝛼𝐾
𝑖 ]. Here, by employing ReLU in the final
layer, all evidence values are ensured to be non-negative.
The parameter 𝛼𝑘
𝑖 is directly influenced by 𝑒𝑘
𝑖 , specifically,
𝛼𝑘
𝑖 = 𝑒𝑘
𝑖 + 1. Subsequently, the belief mass 𝑏𝑘
𝑖 and the over-
arching uncertainty 𝑢𝑖 can be deduced as:
𝑏𝑘
𝑖 = 𝑒𝑘
𝑖
𝑆𝑖
= 𝛼𝑘
𝑖 − 1
𝑆𝑖
𝑎𝑛𝑑 𝑢𝑖 = 𝐾
𝑆𝑖
(2)
where 𝑆𝑖 = Í𝐾
𝑘=1(𝑒𝑘
𝑖 + 1) = Í𝐾
𝑘=1 𝛼𝑘
𝑖 represents the strength
of the Dirichlet distribution (Jsang 2018). Eq. 2 captures an
intuitive phenomenon: the more evidence accumulated for
the 𝑘𝑡ℎ action, the higher the probability attributed to that
action. Inversely, when there’s scant evidence, the encom-
passing uncertainty escalates. This belief assignment can be
interpreted as a form of subjective reasoning.
To enhance decision-making precision and trustworthi-
ness, we propose leveraging evidence collected by different
agents as a foundation for decision-making. Consequently,
we develop an evidence encoder to deduce bespoke evidence
tailored for each agent. At each time-step, 𝑎𝑔𝑒𝑛𝑡𝑖 not only
produces evidence 𝑒𝑖 for its own local decision but also ex-
tracts a collection of evidence - (𝑒𝑖1, ..., 𝑒𝑖 𝑗, ..., 𝑒𝑖𝑛), aimed
at aiding its teammates in making more reliable choices.
Such evidence then acts as the communication medium, en-
abling us to generate messages tailored for specific agents.
The tailored message from 𝑎𝑔𝑒𝑛𝑡𝑖 to 𝑎𝑔𝑒𝑛𝑡 𝑗 can be denoted
as 𝑚𝑖 𝑗 = 𝑒𝑖 𝑗.
Selective Engagement
As we’ve discussed earlier, broadcast communication falls
short in practical applications and results in redundant infor-
mation. The timing of information exchange and the choice
of communication partners are paramount. For precise and
trustworthy message exchanges, it’s vital to identify truly in-
strumental connections from the vast web of interactions. At
a holistic level, we aim to share evidence-backed data, thus
enabling recipients to make informed and reliable decisions.
To bring this vision to fruition, we meticulously quantify the
strength and relevance of each communication link between
agents by performing an ablative decision-making analy-
sis. This approach primarily seeks to quantify the variabil-
ity in decision uncertainty attributable to communication. To
delve deeper into the mechanics, consider the communica-
tion from 𝑎𝑔𝑒𝑛𝑡𝑖 to 𝑎𝑔𝑒𝑛𝑡 𝑗, denoted as 𝑚𝑖 𝑗. This communi-
cation’s value is mathematically expressed as:
𝑣𝑖 𝑗 = 𝑢 𝑗 − ˆ𝑢 𝑗
(3)
where 𝑢 𝑗 represents the decision uncertainty for recipient
𝑎𝑔𝑒𝑛𝑡 𝑗 before communication, whereas ˆ𝑢 𝑗 is the uncertainty
post communication.
To foster targeted and trusted communication, we develop
a communication selector network. This network aids agents
in determining the right moments and partners for communi-
cation, ensuring that only the most valuable and credible in-
formation is shared. We also set a constant threshold to gen-
erate binary pseudo-labels. If the deduced communication
value is below the set threshold, it implies that the message
received doesn’t substantially benefit the recipient agent,
leading the connection to be tagged as ‘cut’, denoted math-
ematically as 𝑦𝑖 𝑗 = 0. However, if the communication value
exceeds the threshold, it signifies the message’s importance,
prompting its tag to be ’retain’ with 𝑦𝑖 𝑗 = 1. This systematic
labeling forms the foundation for optimizing the communi-
cation selector network, with the binary cross-entropy loss
steering the fine-tuning process.
L𝐵𝐶𝐸 = E𝑖, 𝑗∼Z𝑛 [𝑦𝑖 𝑗×log(𝑝𝑖 𝑗)+(1−𝑦𝑖 𝑗)×log(1−𝑝𝑖 𝑗)] (4)
where Z𝑛 is the set of integers from 1 to 𝑛, 𝑝𝑖 𝑗 is the out-
put of the communication selector network, representing the
likelihood of 𝑎𝑔𝑒𝑛𝑡𝑖 choosing to communicate with 𝑎𝑔𝑒𝑛𝑡 𝑗.
Evidence-Driven Integration
In T2MAC, messages exchanged among agents encapsulate
evidence observed from diverse perspectives. Agents can
better understand the uncertain environment by adeptly inte-
grating these messages, resulting in more sophisticated poli-
cies. To this end, we incorporate the DST to integrate in-
coming messages. This approach facilitates the combination
of evidence from different sources, culminating in a degree
of belief that comprehensively reflects all gathered evidence.
The rule of message integration for evidence is presented as:
M = M𝑖 ⊕ M 𝑗
(5)
where M𝑖 = {{𝑏𝑘
𝑖 }𝐾
𝑘=1, 𝑢𝑖} and M 𝑗 = {{𝑏𝑘
𝑗 }𝐾
𝑘=1, 𝑢 𝑗} sym-
bolize the joint masses derived from two distinct perspec-
tives of evidence and ⊕ represents DST combination. Mean-
while, M = {{𝑏𝑘}𝐾
𝑘=1, 𝑢} encapsulates the consolidated
joint mass, integrating evidence from both standpoints. The
more specific integration rule can be formulated as follows:
𝑏𝑘 =
1
1 − 𝐶 (𝑏𝑘
𝑖 𝑏𝑘
𝑗 + 𝑏𝑘
𝑖 𝑢 𝑗 + 𝑏𝑘
𝑗𝑢 𝑗), 𝑢 =
1
1 − 𝐶 𝑢𝑖𝑢 𝑗
(6)
where 𝐶 = Í
𝑘≠𝑘′ 𝑏𝑘
𝑖 𝑏𝑘
′
𝑗 represents the degree of disagree-
ment between the two sets of mass values. To account for
this discord, DST employs the normalization factor
1
1−𝐶 to
ensure a coherent integration of the evidence from both sets.
Intuitively, when encountering evidence and beliefs from
multiple sources, DST aims to merge the common elements
and sidesteps conflicting beliefs through normalization fac-
tors. The integration rule ensures:
1. If both perspectives exhibit high uncertainty (with signif-
icant values of 𝑢𝑖 and 𝑢 𝑗), the resultant prediction should
be treated cautiously, yielding a lower confidence level
(represented by a smaller value of 𝑏𝑘).
2. Conversely, if both viewpoints possess low uncertainty
(denoted by minimal values of 𝑢𝑖 and 𝑢 𝑗), the resulting
prediction is likely to be made with a high degree of con-
fidence (manifesting as a larger value of 𝑏𝑘);
3. In situations where only one viewpoint exhibits low un-
certainty (meaning either 𝑢𝑖 or 𝑢 𝑗 is significantly large),
the final prediction predominantly relies on the more con-
fident viewpoint.
Upon receiving distinct messages from other agents, we
derive the aforementioned mass for each perspective. Sub-
sequently, leveraging Dempster’s rule of combination, we
can integrate the beliefs stemming from these varied view-
points. More specifically, the fusion of belief and uncertainty
masses across different messages is governed by the subse-
quent rule:
M = M1 ⊕ M2 ⊕ ...M𝑛
(7)
Once we have determined the joint mass M = {{𝑏𝑘}𝐾
𝑘=1, 𝑢},
the associated joint evidence gleaned from the messages,
along with the parameters of the Dirichlet distribution, can
be derived as follows:
𝑆 = 𝐾
𝑢 , 𝑒𝑘 = 𝑏𝑘 × 𝑆 𝑎𝑛𝑑 𝛼𝑘 = 𝑒𝑘 + 1
(8)
Leveraging DST, we attain an efficient and theoretically-
founded method for message integration. This method skill-
fully amalgamates messages and simultaneously addresses
enduring intrinsic policy uncertainties. Importantly, the fu-
sion of information isn’t treated as a black box, given that the
combination rules of DST lack learnable parameters. Fur-
thermore, DST offers a more comprehensible and theoretical
perspective on the message integration process.
Following the assimilation of incoming messages and the
acquisition of integrated evidence, each agent makes a local
decision influenced by both its observed and received evi-
dence. For 𝑎𝑔𝑒𝑛𝑡𝑖, this procedure is represented as:
𝑎𝑡
𝑖 = 𝜋𝑖( ˆ𝑒𝑖)
(9)
where
ˆ𝑒𝑖 symbolizes the evidence post-integration for
𝑎𝑔𝑒𝑛𝑡𝑖 at time-step 𝑡. For details of the communication pro-
cess and the training paradigm of T2MAC, please refer to
pseudo-code provided in this section.
Experiments
In this section, we carefully design experiments to ad-
dress three pivotal questions: (1) How does T2MAC’s per-
formance measure against top-tier communication meth-
ods? (2) What characterizes T2MAC’s communication ef-
ficiency? (3) Can T2MAC scale across various tasks and
seamlessly integrate with multiple baselines?
Setup
As illustrated in Fig. 2, we extensively evaluate T2MAC
across three notable cooperative multi-agent tasks. Begin-
ning with Hallway (Wang et al. 2020b), this environment is
Algorithm 1: T2MAC
Initialize replay buffer D
Initialize the Observation encoder, Evidence encoder, Se-
lective Engagement and Q network with random parame-
ters
Set learning rate 𝛼 and max training episode 𝐸
for episode in 1, ..., 𝐸 do
for each agent 𝑖 do
Sending Phase: Encode the hidden feature ℎ𝑡
𝑖 from
observation 𝑜𝑡
𝑖
Encode evidence 𝑒𝑡
𝑖 for local decision
Encode evidence and generate tailored messages for
specific teammates (𝑒𝑖1, ..., 𝑒𝑖 𝑗, ..., 𝑒𝑖𝑛)
Select ideal communication partners using commu-
nication selector network
Receiving Phase: Combing received messages 𝑚𝑡
★𝑖
from other agents by DST combine
Select action 𝑎𝑡
𝑖 by combined evidence
Compute the importance for each communication
link and generating labels 𝑦𝑖 𝑗 for communication se-
lector network
end for
Store the trajectory in replay buffer D
Sample a minibatch of trajectories from D
Update observation encoder, evidence encoder and pol-
icy network using MARL loss function
Update Selective Engagement by Equation 4
end for
relatively direct, built around multiple Markov chains. Here,
agents start at random positions within different chains and
aim to reach the goal state simultaneously under partial ob-
servability. To escalate the complexity, we augment the num-
ber of agents and the length of the Markov chains, lead-
ing to a substantial increase in the exploration space. On
the other hand, MPE (Lowe et al. 2017) is a vital MARL
benchmark set in a 2D grid. We focus on the Cooperative
Navigation (CN) and Predator Prey (PP) scenarios. In CN,
the task for agents is to navigate to different landmarks,
whereas, in PP, their objective is to capture unpredictably
moving prey. To introduce varying difficulty levels, we em-
ploy different grid sizes for both scenarios. The Coopera-
tive Navigation: Medium scenario is set on a 7 × 7 grid,
while the Cooperative Navigation: Hard occupies a 9 × 9
grid. The Predator Prey: Medium scenario is set on a 5 × 5
grid, while the Predator Prey: Hard occupies a 7 × 7 grid.
SMAC (Samvelyan et al. 2019) is derived from the well-
known real-time strategy game StarCraft II. It delves into
micromanagement challenges where each unit is steered by
an independent agent making decisions under partial observ-
ability. To emphasize the importance of communication, we
adopt the setup from (Wang et al. 2020b), which not only re-
stricts the agents’ sight range but also throws them into intri-
cate maps, characterized either by their labyrinthine terrains
or the unpredictable spawning dynamics of units. For com-
parative analysis, we draw from a diverse set of baselines.
This includes non-communication paradigms like the lead-
   
   
   
   
(a) Hallway
(c) SMAC
(b) MPE
Figure 2: Multiple environments considered in our experiments.
Module
Architecture
Obs Encoder
Linear(obs dim, 64)
Linear(64, 64)
Linear(64, 64)
RNN(64, 64)
Evidence Encoder
n*Linear(64, K)
Selector Network
Linear(64, n)
Table 1: Hyperparameters of T2MAC
ing MARL methods QMIX (Rashid et al. 2018) and DOP
(Wang et al. 2020). Meanwhile, our baselines include con-
temporary state-of-the-art communication methods, such as
TarMAC (Das et al. 2019), MAIC (Yuan et al. 2022), SMS
(Xue et al. 2022), and MASIA (Guan et al. 2022).
In conclusion, our experimental design integrates a med-
ley of challenging tasks and robust baselines, establishing a
solid foundation for evaluation. Our overarching goal with
this varied selection is to place T2MAC in diverse scenarios
and test its adaptability, scalability, and overall performance.
To ensure transparency and reproducibility, the intricate de-
tails of our method’s architecture and our hyperparameter
choices are extensively detailed in Table 1.
Results
Performance
We begin our evaluation by comparing the
learning curves of T2MAC with various baselines across
various environments to test its overarching performance. As
illustrated in Fig. 3, T2MAC emerges superior in almost all
environments, highlighting its robust performance. In Hall-
way, as the difficulty intensifies, many baselines falter, un-
able to adapt effectively. Among them, only MASIA stands
out, delivering commendable results, primarily due to its
ability to assist agents in reconstructing global information.
Intriguingly, our T2MAC works even under such demand-
ing conditions, achieving performance on par with MASIA.
This might be largely attributed to its adeptness at shar-
ing and integrating relevant evidence. In SMAC, T2MAC
delivers consistent and impressive performance across all
three maps. However, when looking at all scenarios in their
Methods
Performance
Improvement
Comm
Rate
Comm
Efficiency
TarMAC
17.0%
100.0%
17.0%
MAIC
12.3%
100.0%
12.3%
SMS
27.9%
66.7%
41.8%
MASIA
30.2%
100.0%
30.2%
T2MAC(Ours)
37.2%
56.0%
66.4%
Table 2: Communication Efficiency
entirety, other methods exhibit signs of instability. For in-
stance, SMS struggles to adapt in the 5𝑧 𝑣𝑠 1𝑢𝑙, while Tar-
MAC fails in the 1𝑜 10𝑏 𝑣𝑠 1𝑟. Such observations accentu-
ate, to some extent, the broad applicability and robustness
inherent to T2MAC. In CN and PP, T2MAC maintains its
sustained sample efficiency. Upon reaching a convergence,
its performance remains fiercely competitive. Furthermore,
an interesting observation is that all methods incorporating
communication significantly outperform those that don’t.
This emphasizes that our chosen environments and scenar-
ios intrinsically demand proficient communication. Such an
outcome not only underscores the importance of communi-
cation in these contexts but also validates the aptness of our
experimental setup in benchmarking communication meth-
ods.
Efficiency
In addition to analyzing the overarching per-
formance, we also focus on understanding communication
efficiency. In many real-world situations, communication
resources—like bandwidth and transmission channels—are
inherently scarce. Overloading these resources doesn’t al-
ways yield proportional benefits in performance. To quantify
this efficiency, we calculate the performance improvement
attributable to communication and then normalize this by
the communication rate. Here, communication rate denotes
how frequently communication occurs throughout the learn-
ing process. To gauge performance improvement, we intro-
duce a communication-free variant for each communication
method. This allows us to make a side-by-side comparison
to effectively highlight the tangible advantages offered by
each method. Specifically, for SMS, this communication-
0
0.4
0.8
1.2
1.6
2
Steps(M)
0
0.2
0.4
0.6
0.8
1
MedianTestWinRate
hallway
0
0.4
0.8
1.2
1.6
2
Steps(M)
0
0.2
0.4
0.6
0.8
1
5z_vs_1ul
0
0.4
0.8
1.2
1.6
2
Steps(M)
0
0.2
0.4
0.6
0.8
1
1o_10b_vs_1r
0
0.2
0.4
0.6
0.8
1
Steps(M)
0
0.2
0.4
0.6
0.8
1
1o_2r_vs_4r
0
20
40
60
80
100
Steps(K)
60
50
40
30
20
10
0
MedianTestReturn
CooperateNavigation(Medium)
0
80
160
240
320
400
Steps(K)
50
40
30
20
10
0
CooperativeNavigation(Hard)
0
0.4
0.8
1.2
1.6
2
Steps(M)
10
5
0
5
PredatorPrey(Medium)
0
0.4
0.8
1.2
1.6
2
Steps(M)
20
15
10
5
0
5
10
PredatorPrey(Hard)
T2MAC(Ours)
QMIX
DOP
TarMAC
MAIC
SMS
MASIA
Figure 3: Performance on multiple benchmarks.
free baseline is DOP, while for the others, it’s QMIX. We’ve
carried out this analytical assessment predominantly in the
most challenging environment, SMAC. As shown in Ta-
ble. 2, T2MAC consistently outperforms baselines in terms
of both improvement, communication rate, and commu-
nication efficiency. Such results underscore the capability
of T2MAC to process communication dynamics, including
when to communicate, with whom, and how to trade-off be-
tween performance and efficiency.
Generality
Our prior experiments have demonstrated the
robustness of T2MAC across diverse environments, scenar-
ios of varying complexities, and different scales. To fur-
ther evaluate the generality of T2MAC, we apply it across
a wide range of established MARL baselines, including
QMIX, DOP, and MAPPO. The test win rate for the sce-
nario 1𝑜 10𝑏 𝑣𝑠 1𝑟 is illustrated in Fig. 4. Notably, across
all these baselines, T2MAC consistently achieves superior
performance, often by a notable margin. This positive per-
formance improvement demonstrates the broad applicability
and potency of T2MAC in the realm of MARL.
Ablation
To better understand the impact of each com-
ponent within T2MAC, we perform an ablation study on
the scenario 1𝑜 10𝑏 𝑣𝑠 1𝑟. Here’s a breakdown of the con-
figurations evaluated: T2MAC: This refers to the com-
plete method proposed in our work. QMIX: This serves
as our baseline for comparison, representing the core func-
tionality without the enhancements introduced in T2MAC.
T2MAC(Fullcomm): This is a variant of T2MAC that does
not incorporate selective engagement. Here, communica-
tion occurs continuously amongst agents without deciding
when or with whom to communicate. T2MAC(Nocomm):
This is a more stripped-down version of T2MAC, exclud-
ing both selective engagement and evidence-driven inte-
gration. Essentially, it’s a version of T2MAC where com-
munication is completely omitted, but the Dirichlet Distri-
bution remains in the Q-value network. As illustrated in
Fig. 5, the results demonstrate the contributions of each
component: From QMIX to T2MAC(Nocomm): The shift
from Categorical distribution to Dirichlet distribution makes
sense. The Dirichlet distribution’s advantage might stem
from its ability to model second-order probabilities, intro-
ducing an additional layer of decision-making uncertainty
which potentially enhances learning and adaptation. From
T2MAC(Nocomm) and T2MAC(Fullcomm): The sizable
performance gap between these two underscores the sig-
nificance of evidence-driven information exchange and in-
tegration. This sheds light on the efficacy of trust-based
communication, where agents not only share but also as-
sess the reliability of information before acting upon it.
From T2MAC(Fullcomm) to T2MAC: The contrast in per-
formance between these two configurations underlines the
importance of targeted communication. Instead of a blan-
ket communication strategy, selective engagement, whereby
agents communicate at strategic junctures with specific part-
ners, can enhance the overall efficiency and performance of
the system.
Furthermore,
to
provide
a
clear
ablation
analysis
for
evidence-driven
integration,
we
have
conducted
additional comparisons in the 1𝑜 10𝑏 𝑣𝑠 1𝑟
scenario
QMIX
DOP
MAPPO
0.0
0.2
0.4
0.6
0.8
1.0
Median Test Win Rate
0.84
0.58
0.39
0.31
0.20
0.19
with T2MAC
w/o T2MAC
Figure 4: Generality.
0
0.4
0.8
1.2
1.6
2
Steps(M)
0
0.2
0.4
0.6
0.8
1
MedianTestWinRate
T2MAC
T2MAC(Fullcomm)
T2MAC(Nocomm)
QMIX
Figure 5: Ablation for trusted communication and selective
engagement.
with a summation-based integration method (COMM-
NET(Sukhbaatar, Szlam, and Fergus 2016)) and a black-box
method (TarMAC(Das et al. 2019)). As shown in Fig. 6,
the results demonstrate that the evidence-driven integration
proposed by T2MAC has a clear advantage, confirming its
effectiveness.
Conclusions
In this work, we tackle the intricacies inherent in multi-agent
communication. Previous works focus on broadcast commu-
nication and treat the fusion of information as a block box,
which inevitably diminishes communication efficiency. To
this end, we present the T2MAC framework. This novel ap-
proach empowers agents with the capacity to craft messages
specifically tailored for distinct agents. Beyond mere mes-
sage customization, T2MAC strategically chooses the best
timings and relies on trusted partners for communication,
ensuring an efficient integration of incoming messages and
facilitating trusted decision-making. Rooted in solid theo-
retical principles, this approach stands out for its efficiency.
Furthermore, to substantiate our claims, we conduct com-
prehensive experiments across multiple benchmarks, the re-
0
0.4
0.8
1.2
1.6
2
Steps(M)
0
0.2
0.4
0.6
0.8
1
MedianTestWinRate
T2MAC
COMMNET
TarMAC
Figure 6: Ablation for evidence-driven integration.
sults of which underscore the effectiveness, efficiency, and
adaptability of the T2MAC.
Acknowledgements
The authors would like to thank the editors and review-
ers for their valuable comments. This work is supported
by the Youth Innovation Promotion Association CAS, No.
2021106, the China Postdoctoral Science Foundation, No.
2023M743639, the 2022 Special Research Assistant Grant
project, No. E3YD5901, and the CAS Project for Young Sci-
entists in Basic Research, Grant No. YSBR-040.
References
Andrychowicz, O. M.; Baker, B.; Chociej, M.; Jozefowicz,
R.; McGrew, B.; Pachocki, J.; Petron, A.; Plappert, M.; Pow-
ell, G.; Ray, A.; et al. 2020. Learning dexterous in-hand ma-
nipulation. The International Journal of Robotics Research,
39(1): 3–20.
Das, A.; Gervet, T.; Romoff, J.; Batra, D.; Parikh, D.; Rab-
bat, M.; and Pineau, J. 2019. Tarmac: Targeted multi-agent
communication. In International Conference on Machine
Learning, 1538–1546.
Dempster, A. P. 1967. Upper and Lower Probabilities In-
duced by a Multivalued Mapping. The Annals of Mathemat-
ical Statistics, 38(2): 325 – 339.
Ding, Z.; Huang, T.; and Lu, Z. 2020.
Learning individ-
ually inferred communication for multi-agent cooperation.
Advances in Neural Information Processing Systems, 33:
22069–22079.
Dosovitskiy, A.; Ros, G.; Codevilla, F.; L´opez, A. M.; and
Koltun, V. 2017. CARLA: An Open Urban Driving Simula-
tor.
In 1st Annual Conference on Robot Learning, CoRL
2017, Mountain View, California, USA, November 13-15,
2017, Proceedings, volume 78 of Proceedings of Machine
Learning Research, 1–16. PMLR.
Foerster, J.; Assael, I. A.; De Freitas, N.; and Whiteson, S.
2016. Learning to communicate with deep multi-agent re-
inforcement learning. Advances in neural information pro-
cessing systems, 29.
Guan, C.; Chen, F.; Yuan, L.; Wang, C.; Yin, H.; Zhang, Z.;
and Yu, Y. 2022. Efficient Multi-agent Communication via
Self-supervised Information Aggregation. Advances in Neu-
ral Information Processing Systems, 35: 1020–1033.
Jiang, J.; and Lu, Z. 2018. Learning attentional communi-
cation for multi-agent cooperation. In Advances in neural
information processing systems, 7254–7264.
Jsang, A. 2018. Subjective Logic: A formalism for reasoning
under uncertainty. Springer Publishing Company, Incorpo-
rated.
Kim, D.; Moon, S.; Hostallero, D.; Kang, W. J.; Lee, T.;
Son, K.; and Yi, Y. 2019. Learning to schedule communi-
cation in multi-agent reinforcement learning. arXiv preprint
arXiv:1902.01554.
Lowe, R.; Wu, Y. I.; Tamar, A.; Harb, J.; Abbeel, O. P.;
and Mordatch, I. 2017. Multi-agent actor-critic for mixed
cooperative-competitive environments. In Advances in neu-
ral information processing systems, 6379–6390.
Malinin, A.; and Gales, M. J. F. 2018. Predictive Uncer-
tainty Estimation via Prior Networks. In Bengio, S.; Wal-
lach, H. M.; Larochelle, H.; Grauman, K.; Cesa-Bianchi, N.;
and Garnett, R., eds., Advances in Neural Information Pro-
cessing Systems 31: Annual Conference on Neural Informa-
tion Processing Systems 2018, NeurIPS 2018, December 3-
8, 2018, Montr´eal, Canada, 7047–7058.
Malinin, A.; Mlodozeniec, B.; and Gales, M. J. F. 2020.
Ensemble Distribution Distillation.
In 8th International
Conference on Learning Representations, ICLR 2020, Addis
Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.
Mao, H.; Zhang, Z.; Xiao, Z.; Gong, Z.; and Ni, Y. 2019.
Learning agent communication under limited bandwidth by
message pruning. arXiv preprint arXiv:1912.05304.
Niu, Y.; Paleja, R. R.; and Gombolay, M. C. 2021. Multi-
Agent Graph-Attention Communication and Teaming.
In
AAMAS, 964–973.
Osband, I.; Blundell, C.; Pritzel, A.; and Van Roy, B. 2016.
Deep exploration via bootstrapped DQN. In Advances in
neural information processing systems, 4026–4034.
Rashid, T.; Samvelyan, M.; De Witt, C. S.; Farquhar, G.;
Foerster, J.; and Whiteson, S. 2018.
QMIX: Monotonic
value function factorisation for deep multi-agent reinforce-
ment learning. arXiv preprint arXiv:1803.11485.
Samvelyan, M.; Rashid, T.; de Witt, C. S.; Farquhar, G.;
Nardelli, N.; Rudner, T. G.; Hung, C.-M.; Torr, P. H.; Fo-
erster, J.; and Whiteson, S. 2019. The starcraft multi-agent
challenge. arXiv preprint arXiv:1902.04043.
Sensoy, M.; Kaplan, L. M.; and Kandemir, M. 2018. Eviden-
tial Deep Learning to Quantify Classification Uncertainty.
In Bengio, S.; Wallach, H. M.; Larochelle, H.; Grauman, K.;
Cesa-Bianchi, N.; and Garnett, R., eds., Advances in Neu-
ral Information Processing Systems 31: Annual Conference
on Neural Information Processing Systems 2018, NeurIPS
2018, December 3-8, 2018, Montr´eal, Canada, 3183–3193.
Silver, D.; Hubert, T.; Schrittwieser, J.; Antonoglou, I.; Lai,
M.; Guez, A.; Lanctot, M.; Sifre, L.; Kumaran, D.; Graepel,
T.; et al. 2018. A general reinforcement learning algorithm
that masters chess, shogi, and Go through self-play. Science,
362(6419): 1140–1144.
Silver, D.; Schrittwieser, J.; Simonyan, K.; Antonoglou, I.;
Huang, A.; Guez, A.; Hubert, T.; Baker, L.; Lai, M.; Bolton,
A.; et al. 2017. Mastering the game of go without human
knowledge. nature, 550(7676): 354–359.
Singh, A.; Jain, T.; and Sukhbaatar, S. 2018. Learning when
to communicate at scale in multiagent cooperative and com-
petitive tasks. arXiv preprint arXiv:1812.09755.
Sukhbaatar, S.; Szlam, A.; and Fergus, R. 2016.
Learn-
ing Multiagent Communication with Backpropagation. In
Proceedings of the 30th International Conference on Neu-
ral Information Processing Systems, NIPS’16, 2252–2260.
Red Hook, NY, USA: Curran Associates Inc.
ISBN
9781510838819.
Sun, C.; Wu, B.; Wang, R.; Hu, X.; Yang, X.; and Cong,
C. 2021.
Intrinsic Motivated Multi-Agent Communica-
tion.
In Proceedings of the 20th International Confer-
ence on Autonomous Agents and MultiAgent Systems, AA-
MAS ’21, 1668–1670. Richland, SC: International Founda-
tion for Autonomous Agents and Multiagent Systems. ISBN
9781450383073.
Sunehag, P.; Lever, G.; Gruslys, A.; Czarnecki, W. M.; Zam-
baldi, V.; Jaderberg, M.; Lanctot, M.; Sonnerat, N.; Leibo,
J. Z.; Tuyls, K.; et al. 2017.
Value-decomposition net-
works for cooperative multi-agent learning. arXiv preprint
arXiv:1706.05296.
Vinyals, O.; Babuschkin, I.; Czarnecki, W. M.; Mathieu, M.;
Dudzik, A.; Chung, J.; Choi, D. H.; Powell, R.; Ewalds,
T.; Georgiev, P.; et al. 2019.
Grandmaster level in Star-
Craft II using multi-agent reinforcement learning. Nature,
575(7782): 350–354.
Wang, R.; He, X.; Yu, R.; Qiu, W.; An, B.; and Rabinovich,
Z. 2020a. Learning Efficient Multi-agent Communication:
An Information Bottleneck Approach. In ICML 2020: 37th
International Conference on Machine Learning.
Wang, T.; Wang, J.; Zheng, C.; and Zhang, C. 2020b. Learn-
ing Nearly Decomposable Value Functions Via Communi-
cation Minimization. In ICLR 2020 : Eighth International
Conference on Learning Representations.
Wang, Y.; Han, B.; Wang, T.; Dong, H.; and Zhang, C. 2020.
Dop: Off-policy multi-agent decomposed policy gradients.
In International Conference on Learning Representations.
Xue, D.; Yuan, L.; Zhang, Z.; and Yu, Y. 2022. Efficient
Multi-Agent Communication via Shapley Message Value.
In Raedt, L. D., ed., Proceedings of the Thirty-First Interna-
tional Joint Conference on Artificial Intelligence, IJCAI-22,
578–584. International Joint Conferences on Artificial Intel-
ligence Organization. Main Track.
Yu, C.; Velu, A.; Vinitsky, E.; Gao, J.; Wang, Y.; Bayen, A.;
and Wu, Y. 2022.
The surprising effectiveness of ppo in
cooperative multi-agent games. Advances in Neural Infor-
mation Processing Systems, 35: 24611–24624.
Yuan, L.; Wang, J.; Zhang, F.; Wang, C.; Zhang, Z.; Yu, Y.;
and Zhang, C. 2022. Multi-agent incentive communication
via decentralized teammate modeling.
In Proceedings of
the AAAI Conference on Artificial Intelligence, volume 36,
9466–9474.
Zhang, S. Q.; Zhang, Q.; and Lin, J. 2019. Efficient commu-
nication in multi-agent reinforcement learning via variance
based control. In Advances in Neural Information Process-
ing Systems, 3235–3244.
Zhang, S. Q.; Zhang, Q.; and Lin, J. 2020. Succinct and
robust multi-agent communication with temporal message
control. Advances in Neural Information Processing Sys-
tems, 33: 17271–17282.
"
"To explore the chemical space of all small molecules, a common approach is to compress the dimension of the system to facilitate downstream machine learning tasks. Towards this end, the paper presents a data-driven approach for clustering potential energy landscapes of molecular structures by applying Network Embedding techniques, to obtain latent variables defined through the embedding function. It also incorporates an entropy-sensitive adaptive scheme for hierarchical sampling of the energy landscape, based on Metadynamics and Transition Path Theory. By taking into account the kinetic information implied by a system’s energy landscape, it interprets dynamical node-node relationships in reduced dimensions. Demonstrations of the method are presented using Lennard-Jones (LJ) clusters and a human DNA sequence.nan","The motivation is to understand the chemical space, specifically the number of organic molecules that can be formed and their potential for synthesizability. This knowledge has implications for drug development and disease treatment. The paper focuses on analyzing energy landscapes, which involve local minima, saddle points, entropic plateaus and deep energy wells. Existing methods for energy landscape analysis focus on identifying local minima and transition states between them. The proposed research is to apply Network Embedding techniques in combination with Metadynamics and TPT to produce adaptive embeddings that hierarchically convey information about the system’s behavior at different scales.nan","nanThe paper provides a review of Network Embedding techniques, such as DeepWalk, Node2vec, and their use in reducing the dimensionality of networks. It also discusses Metadynamics, which is used to aid in the exploration of energy landscapes, Transition Path Theory (TPT), which studies statistical properties of reactive trajectories, and Diffusion Wavelet algorithm for efficient approximation of embeddings. The paper proposes a modification of the Diffusion Wavelet algorithm that introduces parameters and optimizes them to minimize cross-entropy loss.nan","The paper proposes a hierarchical method for clustering energy landscapes and identifying latent variables of molecular structures. It starts by constructing a network representation of the energy landscape, where nodes represent local minima and edges represent energy barriers or transition probabilities. The method incorporates adaptive adjustments to the network structure and edge weights based on Metadynamics and TPT, which allows for hierarchical sampling and focusing on particular areas of the energy landscape. The embeddings are produced using a modified version of the Diffusion Wavelet algorithm, which is more efficient and scalable for large networks.nan",The paper demonstrates the effectiveness of the proposed method through experiments on Lennard-Jones (LJ) clusters and a human telomere sequence. It shows that the method can produce hierarchical embeddings that provide insights into the dynamics of the system at different scales. The embeddings can be used to identify transition paths and potential energy barriers. The method also allows for the incorporation of entropic effects and the analysis of systems with complex energy landscapes.nan,"The paper introduces a data-driven approach for clustering energy landscapes of molecular structures and identifying latent variables of molecular structures. The approach is based on Network Embedding techniques, Metadynamics and TPT. One major highlight is that the resulting embeddings can be used to interpret dynamical node-node relationships in reduced dimensions that are consistent with chemical kinetics and are thus more likely to be aligned with synthesizability. The framework can be used for applications in various fields such as drug discovery.nan",Clustering Molecular Energy Landscapes by Adaptive Network Embedding,"Paula Mercurio, Di Liu","Clustering Molecular Energy Landscapes by
Adaptive Network Embedding
Paula Mercurio and Di Liu
January 23, 2024
Abstract
In order to efficiently explore the chemical space of all possible small
molecules, a common approach is to compress the dimension of the system
to facilitate downstream machine learning tasks. Towards this end, we
present a data driven approach for clustering potential energy landscapes of
molecular structures by applying recently developed Network Embedding
techniques, to obtain latent variables defined through the embedding
function. To scale up the method, we also incorporate an entropy sensitive
adaptive scheme for hierarchical sampling of the energy landscape, based
on Metadynamics and Transition Path Theory. By taking into account
the kinetic information implied by a system’s energy landscape, we are
able to interpret dynamical node-node relationships in reduced dimensions.
We demonstrate the framework through Lennard-Jones (LJ) clusters and
a human DNA sequence.
1
Introduction
The motivation of the project is the fundamental question of chemical spaces:
how many organic molecules can be formed, and of these, how can we identify
molecules with useful properties which can be chemically synthesized. Under-
standing how such molecules function in biological systems will have a tremendous
impact on development of new drugs and new treatment of diseases [1]. For exam-
ple, the GDB-17 dataset [2] takes into account only molecules allowed by valency
rules, excluding those unstable or unsynthesizable due to strained topologies or
reactive functional groups, thereby reducing the enumeration to a manageable
database size of 166.4 billion molecules formed of up to 17 atoms of C, N, O,
S, and halogens. Fast nearest neighbors searching of large generated datasets
like GDBs has led to methods for virtual screening and visualization of drug-
like molecules, with early success in neurotransmitter receptor and transporter
ligands.
Most applications in biology and chemistry, such as protein folding, involve
systems that behave according to some potential energy landscape of complex
structure with a large number of local minima, saddle points (transition states),
entropic plateaus and deep energy wells. Existing methods for energy landscape
1
arXiv:2401.10972v1  [q-bio.BM]  19 Jan 2024
analysis focus on identifying local minima via geometric optimization, and
finding transition states connecting them using steepest descent pathways [3].
To understand the dynamics over multiple magnitudes of space and time scales,
we can take the viewpoint of the system as a network of local energy minima
and entropic basins, connected by edges weighted according to the energy and
entropy barriers that must be crossed for transitions between metastable states.
The proposed research is to apply recent Network Embedding techniques
[4, 5, 6, 7] to develop a data driven approach for clustering of potential energy
landscapes and identifying latent variables of molecular structures, to further
facilitate sampling and optimization of the chemical spaces and developing
generative models for druglike small molecules. The latent variables are given by
the output of the embedding function. By incorporating energetic information,
we will be able to interpret node-node relationships in reduced dimensions that
are consistent with chemical kinetics and are more likely to be aligned with
synthesizability.
One multiscale challenge is due to the presence of deep potential wells.
Metadynamics [8] uses a non-Markovian random walk to explore an energy
landscape, which is smoothed by additive Gaussian terms after each step, and so
is the transition probabilities of the associated random walk. As this happens,
the process is discouraged from revisiting the lowest energy states repeatedly.
The eventual output is to have a flattened energy landscape, as well as more
efficient random walk samplings. The original potential can be recreated by
subtracting the additive Gaussian terms.
To study transition processes in complex systems with rugged energy land-
scape dominated by entropic effects, such that transitions involving a flat region
on the potential surface that is favorable entropically and the necessity to de-
crease entropy to exit from this region, it is necessary to examine the ensemble
of all the transition paths as a probability space. The Transition Path Theory
(TPT) [9] studies statistical properties of the reactive trajectories such as rates
and dominant reaction pathways through probability currents between adjacent
states. In [10], the definition of probability current in TPT was generalized from
edges to individual nodes and networks, for characterizing transition states in
the form of subnetworks.
In this article, we use Network Embedding techniques in combination with
Metadynamics and TPT to produce adaptive embeddings that hierarchically
convey information about the system’s behavior at different scales. We adjust the
edge weights of the network in a way that parallels Metadynamics to encourage
exploration away from the local energy minima, and adopt TPT to capture
micro dynamical features of interest. It is shown that these embeddings provide
an effective way to understand and visualize inter-node relationships.
The rest of this article is structured as follows. In Section 2, we provide
some background on Network Embedding, Metadynamics and TPT. In Section
3, we discuss more details in the implementations and demonstrate our method
through Lennard-Jones (LJ) clusters. Section 4 contains an application to a less
homogeneous system: DNA folding in a human telomere.
2
2
Background
2.1
Network Embedding
Real-world networks, particularly those representing possible molecular struc-
tures and other biological and chemical systems, are often large and complex,
making them difficult to conceptualize. Network Embedding maps nodes of a
given network into a low-dimensional continuous vector space, to facilitate down-
stream machine learning tasks. Making use of the sparsity of networks, recently
developed Network Embedding methods can scale up linearly with regard to
the number of edges. Major techniques include factorization of functions of the
adjacency matrix, random walks samplings of node neighborhoods, and deep
network learning techniques. The idea is that nodes with close proximities in
the network should have similar embeddings in the latent space.
The basic setup is an undirected network G(S, E) with node set S and edge
set E, while generalizations to directed graphs is straightforward. Let |S| = n
and An×n be the weighted adjacency matrix of the network with weight aij ≥ 0
between nodes vi and vj. The output will be a map
zi = f(vi) : S → Rd,
with
d ≪ n.
(1)
For methods discussed in this paper, the encoding function (1), referred as direct
encoding, is simply a lookup matrix: zi = f(vi) = Zei, such that Z ∈ Rd×n
contains the embedding vectors for all nodes vi ∈ S, and ei is an indicator
vector, therefore f(vi) simply gives the ith column of Z. The set of trainable
parameters for direct encoding approaches is the embedding matrix Z, which is
to be optimized directly. Vector ai = {aik}n
k=1 denotes the first order proximity
between node vi and other nodes. The second order proximity between vi and
vj can be determined by the similarity between ai and aj, which compares the
pair’s neighborhood structures.
In DeepWalk and Node2vec [4, 5], short random walk simulations are used to
determine proximity for each pair of nodes. More specifically, random walk runs
through nodes of the network, with transition rates determined by the edges
weights. Two nodes are close to each other if there is a high probability that a
random walk simulation containing one node will also contain the other. Simi-
larities between between embedding nodes is given by the following conditional
probabilities based on the SkipGram model:
P(j|i) =
exp(zi · zj)
P
l exp(zi · zl),
(2)
where P(j|i) denotes the conditional probability that a random walk starting
at node vi will include node vj, and zi is the embedding of vi. The learning is
achieved by minimizing the following cross entropy loss using Stochastic Gradient
Descent (SGD) method:
L(G) =
X
vi
X
j∈R(vi)
− log (P(j|i)) ,
(3)
3
where R(i) represents a k-step random walk trial starting from node i. The
efficiency of evaluating (2) can be greatly improved by using negative sampling
[11] that randomly selects edges favoring less frequent ones.
In this paper, we will adopt a Network Embedding scheme introduced in
[7], where the embeddings are produced via a sparse approximation of random
walks on networks. For a given undirected network G(A) with adjacency matrix
A = (aij), let D be the diagonal matrix such that Dii = P
j aij. The volume
of the graph will be given by v = P
i Dii. The Laplacian L = I − D−1A has
eigen-decomposition L = ΦΛΦT , where Λ represents the diagonal matrix of
ordered eigenvalues so that 0 = λ1 ≤ λ2 ≤ ...λn, and the eigenvectors are given
by columns of Φ denoted by ϕ1, ϕ2, ....ϕn. Assuming the network is connected,
the discrete Green function satisfies
G(i, j) =
n
X
k=2
1
λk
ϕk(i)ϕk(j).
(4)
We can further define the commute time ct(i, j) to be the mean time for the
Markov process prescribed by transition probability matrix T = D−1A = I − L
on the network to travel from node vi to node vj, and back to vi. It is shown in
[12] that the coordinate matrix for embeddings that preserve commute times
has the following form
Θ = √vΛ−1/2ΦT .
(5)
To produce an efficient approximation of Θ, we can assume that T is local
in the sense that, at least asymptotically, its columns have small support, and
high powers of T will be of low rank, which can be justified for potential driven
systems by disparate transition rates between different neighboring metastable
states. Taking higher powers of T is equivalent to running the Markov chain
forward in time, which allows for representations of the random walk, i.e. re-
action pathways, at different time scales. Making use of this sparsity, we can
produce compressed approximations to the dyadic powers of T with its principal
components, by using fast algorithms such as Lanczos Bidiagonalization for
singular value decomposition (SVD) with the complexity depending linearly on
the number of nonzero elements.
The following scheme is a modification of the Diffusion Wavelet algorithm
[13]. Starting with T0 = T, at each iteration, taking Uk and Σk to be the top
left singular vectors and singular values of Tk ≈ T 2k, we let Tk := U T
k Tk−1Uk.
From this, we can have a low-rank approximation to the Green function of the
random walk, using the Schultz method:
G =
∞
X
k=1
T k =
∞
Y
k=0
(I + T 2k).
(6)
The embedding matrix Θ thus satisfies ΘT Θ = vG, where v is the volume of the
network defined as above. Denoting the leading singular values and left singular
vectors of the matrix vG by ΣG and UG, we take Θ := Σ1/2
G U T
G.
4
We can further use Θ as a starting point, introduce parameters by multiplying
its jth column by a weight cj, and optimize {cj}’s to minimize cross entropy loss
(3) via SGD. Moreover, for robustness of the algorithm, with certain probability,
we can reintroduce singular vectors that were removed in previous truncations,
as a residual correction technique.
2.2
Metadynamics
Metadynamics was introduced in [8] as a technique to aid in the exploration of
energy landscapes. The scheme is to create a non-Markovian, and approximately
self-avoiding, random walk by adjusting the gradient of the energy landscape
after each step with the addition of derivative of a Gaussian term. Over time,
these Gaussians eventually fill up the valleys in the energy potential, which
allows the random walk to explore other areas of the landscape and leads to a
more complete picture of the system dynamics. Specifically, after each step, the
parameter ϕi, which represents the derivative of the energy with respect to the
ith parameter − ∂E
∂xi , is adjusted according to:
ϕt+1
i
= ϕt
i − ∂
∂xi
W
Y
i
exp

−|xi − xt
i|2
2δ2

,
(7)
where W, δ and xt
i are the height, width and center of the Gaussian respectively,
to be chosen based on prior knowledge of the energy landscape.
2.3
Transition Path Theory
The Transition Path Theory (TPT) [9] studies statistical properties of the
reactive trajectories such as rates and dominant pathways through probability
currents between adjacent states. In the simplest setting, given reactant state A
and product state B, any equilibrium path X(t) oscillates infinitely many times
between A and B, with each oscillation from A to B being a reaction event. The
reactive trajectories are successive pieces of X(t) during which it has left A and
on its way to B next, without coming back to A.
The discrete forward committor q+
i is defined as the probability that the
process starting in node i will first reach B rather than A, and the discrete
backward committor q−
i is defined as the probability that the process arriving in
node vi last came from A rather than B. For Markov processes with infinitesimal
generator T = (tij), the forward committor satisfies discrete Dirichlet equations:
X
vj∈S
tijq+
j = 0,
for vi ∈ S\(A ∪ B),
(8)
with the boundary condition
The probability current of reactive trajectories is the average rate at which
they flow from one state to another when the process is at statistical equilibrium
with distribution π, and can be obtained by
f AB
ij
= πiq−
i tijq+
j ,
if i ̸= j.
(9)
To deal with the fact that transitions between any two states can go forward and
backward, the effective current can be introduced as f +
ij = max
Figure 1: Disconnectivity tree and Metadynamics based embeddings for the
Lennard-Jones cluster with 8 atoms. Left: Disconnectivity tree of all local minima.
Right: Embeddings for the local minima after applying the Metadynamics
adjustment.
Color scheme represents the potential energy, e.g., dark blue
denotes the lowest, and red as the highest. Closely related minima have very
similar or identical embeddings, e.g., both yellow minima are embedded at the
yellow point on the right.
where θi is the coordinate of the ith node (energy minimum).
Adaptively
choosing the center node and removing distant nodes, the process will produce a
series of hierarchical embeddings that provide information about the full energy
landscape. Each level provides a representation of the energy landscape at a
different scale.
Figures 1 gives the disconnectivity tree of the original potential and em-
beddings after applying the Metadynamics adjustment by equation 11 for the
8-atom LJ cluster. The colors on each minimum on the disconnectivity tree are
matched to those nodes’ embeddings in Figure 1, with some of the nodes colored
red, embedded to the same place. In the embeddings, nodes with closer dynamic
relationships are clustered together, as a result of the shorter commute time
distance between them.
On a larger scale, we can also see how the higher energy nodes relate to
the nodes with the two lowest energies. Specifically, the global minimum (in
dark blue) is closer to the nodes in the middle of the tree (in orange), while the
second lowest local minimum is much closer to the three highest energy nodes.
This allows us to draw conclusions about a lowest commute time path through
these states: one of the orange colored states might transition directly to the
global minimum, while one of the higher energy states would be more likely to
transition to the second lowest energy state first, and then either remain there
or transition on to the global minimum.
7
Figure 2: The 8-atom LJ network of local minima. Edge lengths are proportional
to commute times. Node colors are chosen to match those in Figures 1.
Table 1: Commute times between nodes, 8-atom LJ cluster.
Node 1
Node 2
1
2
3
4
5
6
7
8
1
0
25.4
17.7
23.5
29.0
65.2
86.1
88.4
2
0
7.7
13.5
19.0
55.2
60.7
63.0
3
0
5.8
11.3
47.5
68.4
70.7
4
0
17.1
53.3
74.3
76.5
5
0
58.8
79.7
82.0
6
0
115.9
118.2
7
0
123.7
For comparison, we also investigated the inter-node relationships by directly
computing the commute times between each pair of nodes. The commute time
between nodes vi and vj, or mean time for the Markov process on the graph
prescribed by the Laplacian L to travel from vi to vj and back to vi, is given by
ct(i, j) = v
N
X
k=2
λk(ϕk(i) − ϕk(j))2,
(12)
where λk are the eigenvalues of L, and the ϕk are the corresponding eigenvectors
as defined in the introduction. The off-diagonal entries for the Laplacian for a
LJ cluster with κ degrees of freedom are given by
L(i, j) =
X
k
O(i)
Ok(k)
v(i)
vk(k)
κ−1
v(i) exp(−β(Ek(k) − E(i))),
(13)
where O and Ok represent point group orders of the local minima and transition
states, respectively, similarly v and vk represent mean vibrational frequencies
8
Figure 3:
Disconnectivity tree for the 38-atom LJ cluster. The structures of
the two lowest-energy configurations are also pictured.
and E and Ek represent potential energy levels at each configuration. It can be
seen that the commute time diagram is consistent with the Network Embedding
output.
3.2
Multi-level embeddings of LJ 38 cluster
Figure 3 shows disconnectivity tree of the 38-atom LJ cluster. For simplicity, we
construct the adjacency matrix for this network with entries given by the energy
barriers between states. Figure 4 gives the hierarchical embedding of the LJ-38
cluster. The left image shows the initial embeddings, colored by their commute
time distances from the global minimum. We re-embedded the points of interest
with the Metadynamics adjustment to the potential with two iterations and
obtain the right image.
The hierarchical structure of the embedding process is organized as the
following. In the first level embeddings (Fig. 4, left), the nodes are embedded
consistently with their commute time distances from the global minimum, which
correspond loosely to potential energy level. In particular, the nodes with energy
E > −170, which are the highest energy clusters in the tree, are embedded
further from the global minimum. In the next embedding, these nodes are
removed due to their further distances from the global minimum, and more
central clusters will be re-embedded. As we consider the second level and later
embeddings, this pattern repeats: each re-embedding reveals a new “layer"" of
nodes that are embedded closer to the global minimum, which correspond to
nodes on the disconnectivity tree that are of lower energy than nodes removed
in the previous level.
9
Figure 4: Hierarchical embeddings for the LJ cluster with 38 atoms. Pictured
are the embeddings before (left) and after (right) applying Metadynamics. Color
scheme denotes commute time from the global minimum, with dark blue being
shortest distances, and red as furthest distances.
In particular, at the 3rd level (Fig. 4, right), the embeddings have 4 small
“spokes"" originating from a central cluster containing the global minimum. How-
ever, these embeddings provide additional context: nodes that are embedded
within a particular “spoke"" are more closely related, which means the system is
more likely to transition between these states. Since the nodes do not all come
from the same group on the disconnectivity tree, these embeddings can also
reveal interactions between nodes that aren’t indicated on the disconnectivity
tree.
Additionally, since the spokes are connected to the cluster containing the
global minimum, we can conclude that each spoke represents a potential transition
pathway from the outer edge of the cluster to the center. In other words, if
the system is at a state represented by the outer point of one of the spokes, its
most likely path toward the global minimum will be to travel through the states
represented by other nodes in the same spoke.
We can apply similar reasoning to higher level embeddings. Each level reveals
a more detailed picture of the dynamics of a different part of the system’s
energy landscape. The first levels give a coarse-grained picture, only identifying
broad groups of high energy and low energy nodes, while later levels give a
more fine-grained visualization of the nodes most closely related to the global
minimum.
Often, we want a more detailed, finer grained visualization of the energy
landscape than the disconnectivity tree in Figure 3 can provide. It is informative,
therefore, to re-embed parts of the network of greatest interest to gain further
insight. Here we focus on the lowest energy parts of the LJ energy landscape.
We repeated the above process using the subnetwork consisting only of the nodes
with potential energy < −170.9, that is, the 163 lowest energy nodes. Figure 5
shows the results of this experiment.
Now we want to provide a closer inspection on the information flow along
10
Figure 5: Embeddings of the local minima of the 38-atom LJ cluster with potential
energies less than -170.9. The figure shows output of 2 level embeddings with
Metadynamics adjustment. Color scheme denotes commute time from the global
minimum.
the hierarchical sampling with Metadynamics. In the first level without the
Metadynamics adjustment, nodes in these embeddings (both Figure 4 and Figure
5) are clustered according to their similarity in terms of commute time. In other
words, nodes that can be quickly and frequently reached from either the global
minimum or second lowest energy node will be grouped near them. As a result,
most of the nodes we are most interested in end up in the same cluster, and
the embeddings obtained from the first application of the embedding method
only give useful clusters for nodes that are more distant in terms of commute
time from the part of the graph of interest. As we progress through additional
levels, we pull apart the cluster containing the global minimum, positioned near
the origin in the first level’s embeddings, until the final level’s embeddings give
details of the dynamics of the process within this cluster.
After the second level of Embedding with Metadynamics adjustment, if two
nodes share a cluster or are close in the embedding space, it indicates that the
system can easily transition between those nodes, with a relatively low energy
barrier. As a result, the groupings seen in these embeddings correspond to
the groupings in the disconnectivity tree for this system [3, 14]. For instance,
one of the clusters in the second level embeddings correspond to the global
minimum and its nearest neighbors, pictured directly right of center in the
disconnectivity tree in Figure 3. Clusters can be mapped to the disconnectivity
tree by comparing the potential energies of the nodes within the cluster to the
tree.
The difference is after the third level, some of the clusters instead represent
combinations of multiple disconnectivity tree groups; this is a result of re-
embedding the nodes to spread out those that were previously near the origin.
Such nodes ended up being embedded in or near the clusters they are most
closely related to, even though they are not actually members of the respective
tree groupings. For instance, the global minimum is embedded directly next to
11
a node from a neighboring tree group.
In other words, the first level’s embeddings tell us about higher energy nodes
and those that are more distant from the global minima, and further levels reveal
information about parts of the network that are closer to the global minimum.
Additionally, these embeddings are useful for identifying transition paths. The
structure of the third level embeddings, in particular, reveals four transition
paths: if the system is initialized from a node near the outside of one of these
“spokes"", its lowest energy path to the global minima will involve following the
spoke into the center cluster.
Figure 6: Metadynamics-based embeddings for the 38-atom cluster at the
temperatures T = 0.08 (left) and T = 1 (right). Color scheme denotes commute
time from the global minimum.
We can also use these embeddings to observe the results of entropic changes
to the system. In Figure 6, the embeddings for this cluster under two additional
temperature conditions are shown. The results of the temperature change are
reasonable according to what was observed previously with the 8-atom cluster.
Namely, at lower temperatures (Fig.6, left) closely related nodes are more likely
to be embedded much nearer each other, creating the impression that there are
fewer embeddings, while at higher temperatures (Fig.6, right), there is greater
variation in the node embeddings.
3.3
Human Telomere Folding
Now we want further develop Network Embedding technique for organic molecular
structures and apply it to a more complex problem: DNA folding in a human
telomere.
More specifically, we consider a sequence of 22 nucleotide bases
A(G3TTA)3G3 which repeats within human telomeres. This sequence is known
to form a G-quadruplex, a type of secondary structure formed by groups of four
guanine bases called G-tetrads. Its structure and potential energy landscape
were previously investigated in [15], where the potential energy landscape was
calculated using the HiRE-RNA model for coarse-grained DNA [16] with 6 or
7 atoms considered for each of the 22 nucleotides in the telomere. We use
12
Figure 7: The four-strand G-quadruplex structure (PDB structure 1KF1), with
guanine nucleotides colored green. Image produced with Chimera [17].
this database as a starting point. In particular, we construct a network with
nodes given by the 4000 lowest-energy local minima, and edges between nodes
determined by the transition states connecting them.
For first experiments, we used a random walk based on the energy barriers
between states. Figure 8 shows the results of the initial embeddings and fourth
levels with metadynamic adjustments, based on an energy landscape adjusted by
a Gaussian term with width 0.75 and height 1 after each successive embedding.
As in the LJ cluster experiment, the first embedding includes all nodes in
the network, while each successive embedding shows a re-embedding of the
subnetwork of nodes most closely related to the global minimum (that is, all
nodes whose previous embeddings lie within a small tolerance of the global
minimum).
Figure 8:
Embeddings of the local minima network for the human telomere
sequence, based on the adjacency matrix and the Metadynamics adjustment.
Color scheme denotes commute time from the global minimum.
As with the LJ clusters, each level of embedding represents “zooming in""
on the part of the network around the global minimum. The first level gives
us a global view – the global minimum and its nearest neighbors (with respect
to commute times) are clustered at the origin, represented by a dark blue dot.
The red and orange dots furthest away from the origin represent local minima
13
which are more distantly related, requiring multiple steps or higher energies to
transition to the global minimum. Potential transition paths can be identified by
starting at one of these points, and moving toward the origin along nearby points.
At the second and each of the following levels, the nodes embedded closest to the
local minimum are re-embedded to give us a more detailed inspection into the
relationships of those nodes. The likely transition paths here can be constructed
similarly.
4
Multiscale embedding with TPT
Now we want to make use of the multiscale nature of the molecular dynamics
to speed up and scale up the computation. When a subset of the variables
evolves more quickly than the others, dimension reduction can be achieved
by the quasi-equilibrium on the fast variables such that averaged macroscopic
effect can replace microscopic details. For molecular configurations where the
energy landscape is “flatter"" and state transitions occur faster, this principle of
averaging applies. From the space perspective, if the transitions paths between
nodes representing different molecular configurations are of relatively low energy
barriers, they should be closely related in terms of mean commute time. We can
expect these low barrier transitions to describe subtler changes likely involving
position changes for only a small number of atoms. In other words, there is
a time-space scale separation, i.e., on a global scale, transitions between two
states tend to require larger, higher dimensional changes (associated with greater
energy expenditures), while locally, transitions within some subnetwork around
a point of interest require far fewer degrees of freedom.
For energy landscapes with a large number of local minima, the corresponding
networks contain large numbers of nodes. In fact, for the LJ clusters, the number
of minima increases exponentially with the number of atoms. In these situations,
as we have seen, it is benefiting to have a method for Network Embedding
that focuses on locally embedding regions of the network that are of particular
interest, for example the subnetwork consisting of the global minimum and its
nearest neighbors. Since the commute times between states in this subnetwork
are short, the time required for the system to move between these configurations
is fast and the nodes tend to embedded near each other. The states in these
subnetworks often represent molecular configurations that are similar, differing
only by a simple conformational change; therefore these subnetworks can have
dramatically reduced dimensions compared with the full network.
We want to present an alternate formulation, which replaces the adjacency
matrix with the probability current matrix from TPT. For large networks,
particularly those with irregular structures, the committor functions needed to
apply TPT to the full network may prove difficult or impractical to compute.
Focusing our application of TPT onto a smaller, localized subnetwork avoids
this difficulty, allowing us to take advantage of the additional information TPT
offers. In the following experiments, we first embed all the local minima using
the adjacency matrix constructed with energy barriers, and apply the Network
14
Embedding with Metadynamics. At each level, we remove nodes that have
longer commute times to the global minimum, until the system is reduced to a
subnetwork such that we can apply TPT and compute the committor functions
(8) and probability currents (9).
Then, each subnetwork is embedded into R3 using the effective probability
current in place of the adjacency matrix. Here we apply the hierarchical em-
bedding procedure to the subnetwork of nodes surrounding the global minimum
as in previous sections, but the same process could be used to examine other
domains of the network aside from the global minimum to obtain a complete
picture of the energy landscape.
The distances between nodes within each subnetwork preserve the commute
times. Since the cross entropy loss minimization is applied to the overall network
at each step, we can expect that the distances between node embeddings to be
consistent with likelihoods of a transition, similarly to the previous examples,
and therefore we can interpret the embeddings and identify possible transition
paths in the same way.
Figure 9:
Hierarchical embeddings of the local minima network for the 8 atom
LJ cluster, based on a TPT-based subnetwork consisting of the nodes clustered
around the global minimum (in dark blue), and the metadynamic adjustment.
Colors of embeddings denote potential energy same as in previous illustrations.
We can demonstrate its efficacy on a smaller system–the 8-atom LJ cluster,
as illustrated in Figure 9. We still see that the two nodes with potential energies
near -19.2 (colored yellow in Figs 1 and 2) are closely connected, and the nodes
represented in red and orange are closer to the lowest energy nodes than to
each other, but in this case the short distance between the 2 lowest energy
nodes reflects a higher transition rate between them. The highest energy nodes,
embedded in red, are also embedded separately in this case, whereas their
adjacency matrix based embeddings were identical. These embeddings indicate
that a transition path (shown in Fig. 9) from the highest energy node to the
slightly lower energy node labeled 5 might pass through nodes 1 and 2 on the
way. Direct simulations of this system confirm this transition path. Hence,
these embeddings can be useful for predicting mechanisms by which a molecule
15
changes between two configurations.
We now return to the human telomere molecule.
Figure 10 shows the
embeddings produced via the TPT process described above. The colors of local
minima in Figure 10 are determined by the commute times between those nodes
and the global minimum, which is embedded in dark blue. It is immediately
apparent that the local minima are grouped according to these commute times,
with separate clusters containing most of the red, yellow, and light blue nodes.
Within each of these clusters, the nodes are relatively close in terms of commute
times, indicating that these molecular configurations are similar up to some
simple molecular change. As with the 8-atom LJ cluster, these embeddings
suggest possible transition paths. For example, if the system starts at one of
the states furthest from the global minimum (colored in red, clustered in the
upper left of the right figure) one would expect a transition path to the global
minimum to travel through the light blue and yellow clusters to reach the node
in dark blue. It is also worth noting that the embeddings given by the TPT
approach appear to retain more nodes compared to the adjacency matrix-based
embeddings in Figure 8, which results from the greater number of nonzero edge
weights in the probability current matrix.
Figure 10:
Hierarchical embeddings of the local minima network for the
human telomere sequence. Left: the embeddings of the full network based on
the adjacency matrix. Right: embeddings of the subnetwork near the global
minimum using Metadynamics and TPT. Colors of embeddings denote commute
time distance from the global minimum.
5
Conclusion and future work
This article presents a framework for the analysis of energy landscape data.
Adaptive network embeddings that combine the ideas of Metadynamics and TPT
with Node Embedding techniques can be used to aid in the interpretation and
simplification of energy landscape data. In this embedding scheme, the network
itself – both its edge weights and the set of nodes under consideration – can
be adjusted to more effectively focus on particular areas of the graph. Future
16
research will involve applying and developing the method for functions of specific
molecules in the context of certain chemical or biological reacting networks.
We anticipate that these energy landscape-based network embeddings would
be used to advance the models currently used to explore the space of small
molecules and identify potential new drugs. For example, the latent variables
learned from molecular energy landscapes could be incorporated into Variational
Autoencoders or other generative models as node attributes [18], in much the
same way that 3D representations of molecules are already used. The inclusion
of these additional latent variables would lead to a multi-modal generative
method that takes into account kinetic information of the molecular systems for
generating more realistic, chemically viable molecules.
6
Declarations
6.1
Acknowledgments
The work is partially supported by NSF-DMS 1720002.
6.2
Authors’ contributions
Made substantial contributions to conception and design of the study and
performed data analysis and interpretation: Mercurio P
Made substantial contributions to conception and design of the study and
performed data analysis and interpretation, as well as provided administrative
and material support: Liu D
6.3
Availability of data and materials
Molecular graphics and analyses performed with UCSF Chimera [17], devel-
oped by the Resource for Biocomputing, Visualization, and Informatics at the
University of California, San Francisco, with support from NIH P41-GM103311.
Databases of local minima and transition states were computed using the
Pele software [19] and PATHSAMPLE [20] and the disconnectivity trees were
drawn using disconnectionDPS [21].
6.4
Financial support and sponsorship
The work is partially supported by NSF-DMS 1720002. https://www.nsf.gov/
div/index.jsp?div=DMS
6.5
Conflicts of interest
All authors declared that there are no conflicts of interest.
6.6
Ethical approval and consent to participate
Not applicable.
17
6.7
Consent for publication
Not applicable.
6.8
Copyright
© The Author(s) 2023.
References
[1] C. M. Dobson. Chemical space and biology. Nature, 432:824–828, 2004.
[2] J.-L. Reymond. The chemical space project. Accounts of Chemical Research,
pages 722–730, 2015.
[3] David J. Wales. Exploring energy landscapes. Annual Review of Physical
Chemistry, 69:401–25, 2018.
[4] B. Perozzi, R. Al-Rfou, and S. Skiena. DeepWalk: Online learning of social
representations. Proceedings of the ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, 3:701–710, 2014.
[5] A. Grover and J. Leskovec. Node2vec: Scalable feature learning for networks.
KDD : proceedings. International Conference on Knowledge Discovery and
Data Mining, pages 855–864, 2016.
[6] P. Mercurio and D. Liu. Network embedding techniques for metastable
chemical kinetic systems. Mathematical Biosciences and Engineering, 18:868–
887.
[7] P. Mercurio and D. Liu. Efficient network embedding based on sparse
approximation of a random walk. Submitted, 2022.
[8] M. Parrinello and A. Laio. Escaping free-energy minima. Proc. Natl. Acad.
Sci., 99:12562, 2002.
[9] W. E and E. Vanden-Eijnden. Towards a theory of transition paths. J. Stat.
Phys., 123:503–523, 2006.
[10] J. Du and D. Liu. Transition states of stochastic chemical reaction networks.
Comm. Comp. Phys., 29:606–627, 2021.
[11] T. Mikolov, I. Sutskever, K. Chen, G.S. Corrado, and J. Dean. Distributed
representations of words and phrases and their compositionality. Advances
in Neural Information Processing Systems, 26:3111–3119, 2013.
[12] E. Hancock and H. Qiu. Clustering and embedding using commute times.
IEEE Trans. Pattern Anal. Mach. Intell., 29:1873–1890, 2007.
[13] R. Coifman and M. Maggioni. Diffusion wavelets. Applied and Computational
Harmonic Analysis, 21:53–94, 2006.
18
[14] D. J. Wales. The cambridge energy landscape database.
[15] T. Cragnolini, D. Chakraborty, J. Šponer, S. Pasquali, and D. Wales.
Multifunctional energy landscape for a DNA G-quadruplex: An evolved
molecular switch. Journal of Chemical Physics, 147, 2017.
[16] S. Pasquali. HiRE-RNA: a high resolution coarse-grained energy model for
RNA. The journal of physical chemistry. B, 114:11957–66, 2010.
[17] E.F. Pettersen, T.D. Goddard, and C.C. Huang. UCSF Chimera–a visual-
ization system for exploratory research and analysis. Journal of Chemical
Physics, 25(13):1605–12, 2004.
[18] R. Gomez-Bombarelli, J.N. Wei, D. Duvenaud, J.M. Hernández-Lobato, B.
Sánchez-Lengeling, D. Sheberla, J. Aguilera-Iparraguirre, T.D. Hirzel, R.P.
Adams, and A. Aspuru-Guzik. Automatic chemical design using a data-
driven continuous representation of molecules. ACS Cent Sci, 4(2):268–276,
2018.
[19] J. Stevenson and V. Ruehle. Python energy landscape explorer, 2012.
[20] D. Wales. PATHSAMPLE: A driver for OPTIM to create stationary point
databases using discrete path sampling and perform kinetic analysis.
[21] M. Miller, D. Wales, V. de Souza, and Nicy. DisconnectionDPS.
19
"
"Recent methods for implicitly representing signals like images, scenes, or geometries using coordinate-based neural network architectures often do not leverage the choice of activation functions, or do so only to a limited extent. In this paper, we introduce the Hyperbolic Oscillation function (HOSC), a novel activation function with a controllable sharpness parameter. Unlike any previous activations, HOSC has been specifically designed to better capture sudden changes in the input signal, and hence sharp or acute features of the underlying data, as well as smooth low-frequency transitions. Due to its simplicity and modularity, HOSC offers a plug-and-play functionality that can be easily incorporated into any existing method employing a neural network as a way of implicitly representing a signal. We benchmark HOSC against other popular activations in an array of general tasks, empirically showing an improvement in the quality of obtained representations, provide the mathematical motivation behind the efficacy of HOSC, and discuss its limitations.nan","An increasingly common scenario in learning visual data representations is approximating a structured signal s: Rk → Rm via a coordinate-based neural network fϱ parametrized by a set of parameters ϱ ∈ Rp. These representations, known as implicit neural representations (INRs), are fully differentiable and offer numerous advantages over traditional counterparts such as meshes or pixel grids in optimization tasks, often requiring significantly less memory.nan","nanThree primary strategies to approach this problem while remaining in the INRs framework have been developed:

• Hybrid representations. Methods like ACORN (Martel et al., 2021), InstantNGP (Müller et al., 2022) and TensoRF (Chen et al., 2022) use neural networks to achieve highly detailed representations of complex signals, such as gigapixel images and radiance fields. However, they also rely on traditional data structures, and hence require storing some sort of raw data. This notably enlarges their memory footprint compared to just storing the parameters of an MLP, and results in them not being fully differentiable.

• Positional encoding. Fourier Feature Networks (FFNs) (Tancik et al., 2020) employ positional encoding, which has been shown to accelerate the learning of higher-frequency features. Such encodings, if sampled densely, become extremely memory inefficient, and therefore require sampling a predefined distribution. This introduces more stochasticity to the model, as well as the need to tune the distribution’s parameters manually.

• Periodic activations. Sinusoidal Representation Networks (SIRENs) proposed by Sitzmann et al. (2020) are multi-layer perceptrons (MLPs) that utilize sin(x) instead of ReLU as their activation function. Consequently, they remain fully differentiable and offer a compact representation of the signal. While SIRENs demonstrated a significant improvement over ReLU, they struggle to capture high-frequency details in problems like shape representations, and are not-well suited for methods such as (Mildenhall et al., 2020).nan","In this paper, we introduce a new periodic parametric activation function — the Hyperbolic Oscillation activation function (HOSC), defined as HOSC(x; β) = tanh(β sin x). Here, β > 0 is a controllable sharpness parameter, enabling HOSC to seamlessly transition between a smooth sine-like wave and a square signal. Similarly to SIREN, an MLP running the HOSC activation function is fully differentiable and inexpensive memorywise. However, the HOSC’s sharpness parameter β allows it to much more accurately capture sudden or sharp jumps, and hence preserve high-frequency details of the signal. Moreover, since HOSC is differentiable with respect to β, the sharpness can be adjusted automatically alongside the reset of the parameters, a method to which we refer as Adaptive HOSC or AdaHOSC.nan","Our extensive empirical studies show that HOSC consistently outperforms ReLU and SIREN across an array of benchmarking tasks. These tasks encompass fitting random signals, images of random square patches, photos, gigapixel images, and 2D & 3D SDF. In summary, HOSC provides an easy-to-implement method allowing simple MLPs to achieve high level of detail in signal encoding tasks without loosing differentiability or increasing memory footprint, and it does this without the need for positional encoding.nan","In this paper, we have introduced the Hyperbolic Oscillation activation function HOSC(x; β) = tanh(β sin x), a new periodic parametric activation that has been designed to be particularly effective in preserving sharp features in INRs. Additionally, in Section 4, we presented experimental results that evaluate the performance of the HOSC function in comparison to existing approaches.

Our findings revealed that an MLP employing the HOSC activation with a suitably chosen or automatically-optimized sharpness parameter β consistently outperforms identical structure MLPs using ReLU and SIREN activations, and achieve the same level of accuracy in neural signal encoding problems as Fourier Feature Networks. HOSC thus offers a simple, fully differentiable and compact high-quality signals representation method with no need for hyperparameter tuning. However, we have identified scenarios where HOSC is clearly not the optimal choice, which we will explore in the following discussion.nan",HOSC: A Periodic Activation Function for Preserving Sharp Features in Implicit Neural Representations,"Danzel Serrano, Jakub Szymkowiak, Przemyslaw Musialski","Preprint, submission in preparation
page 1
HOSC: A PERIODIC ACTIVATION FUNCTION
FOR
PRESERVING SHARP FEATURES IN IMPLICIT NEURAL
REPRESENTATIONS
Danzel Serrano
New Jersey Institute of Technology∗
ds867@njit.edu
Jakub Szymkowiak
Adam Mickiewicz University†
IDEAS NCBR‡
jakub.szymkowiak@ideas-ncbr.pl
Przemyslaw Musialski
New Jersey Institute of Technology
IDEAS NCBR
przem@njit.edu
ABSTRACT
Recently proposed methods for implicitly representing signals such as images,
scenes, or geometries using coordinate-based neural network architectures often
do not leverage the choice of activation functions, or do so only to a limited ex-
tent. In this paper, we introduce the Hyperbolic Oscillation function (HOSC), a
novel activation function with a controllable sharpness parameter. Unlike any pre-
vious activations, HOSC has been specifically designed to better capture sudden
changes in the input signal, and hence sharp or acute features of the underlying
data, as well as smooth low-frequency transitions. Due to its simplicity and mod-
ularity, HOSC offers a plug-and-play functionality that can be easily incorporated
into any existing method employing a neural network as a way of implicitly rep-
resenting a signal. We benchmark HOSC against other popular activations in an
array of general tasks, empirically showing an improvement in the quality of ob-
tained representations, provide the mathematical motivation behind the efficacy of
HOSC, and discuss its limitations.
1
INTRODUCTION
An increasingly common scenario in learning visual data representations is approximating a struc-
tured signal s: Rk → Rm via a coordinate-based neural network fθ parametrized by a set of pa-
rameters θ ∈ Rp. These representations, known as implicit neural representations (INRs), are fully
differentiable and offer numerous advantages over traditional counterparts such as meshes or pixel
grids in optimization tasks, often requiring significantly less memory.
INRs are versatile in their application, capable of representing a variety of types of objects, including
audio signals (k, m = 1), images (k = 2, m = 1 or m = 3), radiance fields (k = 5, m = 4),
geometries (k = 2 or k = 3, m = 1), and parametrzied curves (k = 1, m > 1). For instance, to
represent the geometry of a 3D object, one would obtain a dataset of evaluations X = {(x, s(x))}
of the signed distance function s(x) = sdf(x) with respect to the surface of that object, and find the
∗https://www.njit.edu/
†https://www.amu.edu.pl/
‡https://www.ideas-ncbr.pl/
arXiv:2401.10967v1  [cs.NE]  20 Jan 2024
Preprint, submission in preparation
page 2
(a) Ground Truth
(b) ReLU(x)
(c) sin(x)
(d) HOSC(x; 8)
Figure 1: Reconstruction of an image using an MP running different activation functions. The
process involved training a five-layer coordinate-based MLP with a width of 256 for 100 iterations
for each of the activations. No positional encoding and no frequency initialization has been used.
values of parameters θ that minimize the reconstruction loss:
L(θ) = min
θ
E(x,s(x))∼X[∥fθ(x) − s(x)∥2 + Ψ(θ)] ,
where Ψ(θ) denotes a regularizer. Instead of a regression, this task could also be posed as a clas-
sification problem, where the signal s(x) takes values in the discrete set {0, 1}, representing an
occupancy field. In general, defining an appropriate domain, codomain, loss function, and regular-
ization is a problem-specific research challenge.
Importantly, INRs introduce a new paradigm in training neural networks. In classical applications
of neural networks, such as prediction, the goal is to approximate a function f given its noisy eval-
uations f(x) at sparsely sampled datapoints x. One of the challenges is thus not to overfit the
approximation to the noise present in the training data. On the contrary, for INRs, we assume the
data is noise-free and more regularly sampled, and aim to encode this into the network’s parameters,
implying that in this context overfitting is actually desirable for capturing high-frequency details of
the signal.
However, popular activation functions such as ReLU are biased towards capturing lower frequencies,
which is beneficial in prediction tasks, but hinders their capability to accurately represent sharp
features of signals when applied as INRs. Three primary strategies to approach this problem while
remaining in the INRs framework have been developed:
• Hybrid representations. Methods like ACORN (Martel et al., 2021), InstantNGP (M¨uller
et al., 2022) and TensoRF (Chen et al., 2022) use neural networks to achieve highly detailed
representations of complex signals, such as gigapixel images and radiance fields. However,
they also rely on traditional data structures, and hence require storing some sort of raw data.
This notably enlarges their memory footprint compared to just storing the parameters of an
MLP, and results in them not being fully differentiable.
• Positional encoding. Fourier Feature Networks (FFNs) (Tancik et al., 2020) employ po-
sitional encoding, which has been shown to accelerate the learning of higher-frequency
features. Such encodings, if sampled densely, become extremely memory inefficient, and
therefore require sampling a predefined distribution. This introduces more stochasticity to
the model, as well as the need to tune the distribution’s parameters manually.
• Periodic activations. Sinusoidal Representation Networks (SIRENs) proposed by Sitz-
mann et al. (2020) are multi-layer perceptrons (MLPs) that utilize sin(x) instead of ReLU
as their activation function. Consequently, they remain fully differentiable and offer a com-
pact representation of the signal. While SIRENs demonstrated a significant improvement
over ReLU, they struggle to capture high-frequency details in problems like shape repre-
sentations, and are not-well suited for methods such as (Mildenhall et al., 2020).
In this paper, we introduce a new periodic parametric activation function — the Hyperbolic Os-
cillation activation function (HOSC), defined as HOSC(x; β) = tanh(β sin x). Here, β > 0 is a
controllable sharpness parameter, enabling HOSC to seamlessly transition between a smooth sine-
like wave and a square signal. Similarly to SIREN, an MLP running the HOSC activation function is
Preprint, submission in preparation
page 3
(a) sin x
(b) sign(sin x)
(c) HOSC(x; β)
Figure 2: Comparison of the sine, square, and HOSC waves for different values of the sharpness
parameter β ∈ {1, 2, 4, 16}. As β increases, HOSC starts to resemble a square wave.
fully differentiable and inexpensive memorywise. However, the HOSC’s sharpness parameter β al-
lows it to much more accurately capture sudden or sharp jumps, and hence preserve high-frequency
details of the signal. Moreover, since HOSC is differentiable with respect to β, the sharpness can
be adjusted automatically alongside the reset of the parameters, a method to which we refer as
Adaptive HOSC or AdaHOSC.
Our extensive empirical studies show that HOSC consistently outperforms ReLU and SIREN across
an array of benchmarking tasks. These tasks encompass fitting random signals, images of random
square patches, photos, gigapixel images, and 2D & 3D SDF. In summary, HOSC provides an easy-
to-implement method allowing simple MLPs to achieve high level of detail in signal encoding tasks
without loosing differentiability or increasing memory footprint, and it does this without the need
for positional encoding.
2
RELATED WORK
2.1
IMPLICIT NEURAL REPRESENTATIONS
Currently, INRs are gaining a lot of attention in visual computing research (Xie et al., 2021). Their
applications are widespread, and encompass image processing (Tancik et al., 2020), radiance fields
(Mildenhall et al., 2020), 3D shape modeling (Park et al., 2019), audio and video compression
(Lanzend¨orfer & Wattenhofer, 2023; Chen et al., 2021), physics-informed problems (Raissi et al.,
2019), and solving PDEs (Sitzmann et al., 2020; Li et al., 2020). There are many reasons for choos-
ing INRs over classical data structures:
• Differentiability. Given their differentiable nature, INRs offer an immediate advantage
over classical, non-differentiable methods in optimization and deep learning tasks.
• Compactness. INRs often require less memory, as storing the parameters and hyperparam-
eters of a neural network is typically less memory-intensive than storing raw data.
• Continuous representation. In principle, due to their generalization capability, neural
networks enable the representation of data with arbitrary precision, making resolution a
less significant issue (Chen et al., 2020).
For a more comprehensive review of the INR literature, we refer to the recent surveys by Tewari
et al. (2020), Tewari et al. (2021), and Xie et al. (2021).
Shape and geometry representation. Classical methods of shape and geometry representation
include voxel grids, polygonal meshes and point clouds. However, all of these methods suffer from
limitations. Voxel grids are subject to the curse of dimensionality, which makes them inefficient
in handling high-resolution data. Moreover, manipulating voxel grids and dense meshes can be
computationally intensive (Xiao et al., 2020; Kato et al., 2017). Meshes are also prone to errors, and
designing a mesh can be quite time-consuming for human creators. As for point clouds, they do not
encode topological information (Kato et al., 2017). These issues have prompted the exploration of
INRs in the context of shape and geometry modeling. The seminal work by Park et al. (2019) has
demonstrated that INRs are capable of accurately representing surfaces as signed distance functions.
Further research in this direction has been conducted by Atzmon & Lipman (2019), Michalkiewicz
et al. (2019) and Gropp et al. (2020). Another option is presented by occupancy networks, which
model the shape as the decision boundry of a binary classifier implemented as a neural network
(Mescheder et al., 2018; Chen & Zhang, 2018).
Preprint, submission in preparation
page 4
Encoding appearence. In addition to encoding geometry, coordinate-based neural networks are
also capable of representing the appearence aspects. For instance, Texture Fields (Oechsle et al.,
2019) enable coloring any 3D shape based on an image. Methods such as LIIF (Chen et al., 2020)
and ACORN (Martel et al., 2021) are effective in representing high-resolution gigapixel images.
Furthermore, by addressing the inverse problem, Neural Radiance Fields (Mildenhall et al., 2020)
allow for reconstruction of multidimensional scenes from a collection of 2D images. Other signif-
icant contribution in this area include (M¨uller et al., 2022; Chen et al., 2023a; 2022; Martel et al.,
2021). A lot of these and similar methods are hybrid representations that combine neural networks
with classical non-differentiable data structres. As such, they are not directly related to HOSC,
which primarily focuses on fully differentiable architectures.
2.2
ACTIVATION FUNCTIONS AND PERIODICITY
Activation functions. Activations are essential for neural networks to be able to model non-linear
relationships. Early activation functions include the Logistic Sigmoid, Hyperbolic Tangent, and
Rectified Linear Unit (ReLU). Thanks to their low-frequency bias, they are able to deal with the
noise present in the training data, possess generalization capabilities, and thus excel in applications
such as prediction. In contrast to these early non-linearities, more recently proposed activation
functions such as SWISH (Ramachandran et al., 2018), PReLU (He et al., 2015), SReLU (Jin et al.,
2015), and MPELU (Li et al., 2016) incorporate one or more parameters, which are optimized during
training along with the rest of the network’s parameters. For a more in-depth survey on activation
functions, refer to (Dubey et al., 2021; Apicella et al., 2020; Karlik & Olgac, 2011).
Periodicity in neural networks. All the non-linearities mentioned in the previous section are non-
periodic. Altough less common, periodic activations have been studied for many years. Early work
by Sopena et al. (1999) and Wong et al. (2002) analyzed their performance in classification problems.
A more recent study by Parascandolo et al. (2017) investigated which tasks are particularly well-
suited to periodic activations and where they may face challenges. In (Lapedes & Farber, 1987),
the authors use an MLP with sine activation for signal modeling, drawing a direct connection to
the Fourier transform. A significant contribution in the field of INRs is the SIREN architecture
(Sitzmann et al., 2020), which employes sine activation to solve PDEs and encode images and
videos. Various aspects of periodic activations have also been studied by Ramasinghe & Lucey
(2021). An alternative approach to introducing periodicity has been explored by Tancik et al. (2020),
who generalize positional encoding to coordinate-based MLPs.
3
OUR CONTRIBUTION
3.1
HOSC
In this paper, we propose a novel periodic parametric activation function designed specifically for
fitting INRs — the Hyperbolic Oscillation activation function, or HOSC. It is defined as
HOSC(x; β) = tanh(β sin x) ,
where β > 0 is the sharpness parameter, controlling the extent to which the resulting wave resembles
a square wave. This phenomenon is illustrated in Figure 2. In fact, given that limβ→∞ tanh(βx) =
sign(x) for all x ∈ R, we know that limβ→∞ HOSC(x; β) = sign(sin x), so indeed HOSC ap-
proaches the square wave pointwise in the infinite sharpness limit. The rapid amplitude changes
around x = nπ for n ∈ N at high values of β enable HOSC to model acute features of the sig-
nal. Conversely, smooth transitions at lower β values allow it to capture low-frequency components
instead.
3.2
ADAHOSC
Importantly, HOSC is differentiable not only with respect to the input x, but also with respect to the
sharpness parameter β:
∂β HOSC(x; β) = sin(x)
Preprint, submission in preparation
page 5
Figure 3: Comparison of a ReLU, SIREN, and HOSC fitting the ’Cameraman’ image for 1000
epochs and a high-frequency detail ’Cat’ image for 5000 epochs. The plot to the right shows PSNRs
of the model to ground truth per epoch of training; for the ’Cat’ we used adaptively scheduled
learning rate. Below each resulting model is the residual difference from the ground truth signal.
4
EXPERIMENTAL RESULTS
In this section, we experimentally assess the performance of HOSC in various benchmarking tests
and compare it to ReLU and SIREN. More experimental results can be found in the Appendix.
4.1
REPRESENTING IMAGES (s: R2 → R OR R3)
An image can be conceptualized as a function I: R2 → Rn, where n = 1 (for black and white
images) or n = 3 (in case of the colored images), mapping pixel coordinates to their corresponding
color intensities. To construct an INR, one commonly approximates the function I with an MLP,
training it on all the available coordinate-color value pairs ((x, y), I(x, y)).
In Figures 1 and 3 we present the results of fitting photos with an MLP running the HOSC activation.
In Figure 3, the black and white cameraman image is fitted for 1000 epochs, demonstrating that an
MLP employing HOSC activation achieves a higher PSNR quicker than a ReLU-MLP or SIREN.
We also note that we employed a linear step-wise learning rate scheduler with a rate of γ = 0.1 every
2000 epochs, as the HOSC-MLP begins to exhibit an extreme oscillatory convergence at high PSNR
values without this adjustment. Although we confirm that the Gaussian activation performs better
than the SIREN model in this case, our findings reveal that a HOSC-MLP achieves a significantly
higher PSNR compared to both.
Figure 5 reveals more interesting results. This experiment evaluates the performance of the HOSC
on images with varying frequency content. For each activation, a four-layer MLPs with a width of
256 was trained on a 256 × 256 black images, each containing 100 randomly placed white square
patches, over 5000 epochs. Patch sizes used in the experiment are 1 × 1, 4 × 4, and 16 × 16. For the
SIREN model, we adopted the same weight initialization and a frequency factor of 30, as detailed in
Preprint, submission in preparation
page 6
(Sitzmann et al., 2020). For the HOSC-MLP, we use a sharpness factor schedule, where sharpness
varies across layers with values βi = [2, 4, 8, 16]. Additionally, a frequency factor of 30 is used in
the first layer, followed by a factor of 1.0 in the subsequent layers.
As anticipated, the ReLU network struggles to accurately capture the ground truth signal, resulting
in a low converging PSNR. Interestingly, as the patch size increases, ReLU’s peak PSNR decreases.
In contrast, for SIREN, the peak PSNR increases as the ground truth signal losses sharp frequencies.
The HOSC-MLP surpasses both of them, and is able to accurately represent the ground truth signal
regardless of patch sizes. Notably, the PSNR values for the HOSC-MLP, after being trained for 5000
epochs, significantly exceed those of both the ReLU-MLP and SIREN models.
4.1.1
GIGAPIXEL IMAGES
Figure 4: Top: Results of fitting a HOSC and a SIREN model to a high-resolution image. Bottom:
A plot of PSNR per epoch for both methods.
In this experiment, we compare the performances of SIREN and HOSC models on the task of
Gigapixel Image Approximation, where the target signal is an RGB Image of extremely high-
resolution. In this case, the SIREN model is of depth 4, with a width of 256, and each sinusoidal
activation has a frequency of 30. The HOSC model has the same depth and width, however, the
activations have a sharpness of β = 8, while only the first activation has a frequency of 30, and the
rest has a frequency of 1. We follow the same initialization scheme as Sitzmann et al. (2020) for
both the SIREN and HOSC models.
Results of fitting both models to an image of resolution 9302×8000×3 for 100 epochs are shown in
Figure 4. Although both models do not look perceptually close to the zoomed in reference photo, it is
apparent that a model equipped with HOSC is able to retain sharper features for the high-resolution
image whereas the SIREN essentially learns a smooth interpolation. This fact is also reinforced by
analyzing the PSNR plots, where HOSC beats SIREN even at the first few epochs.
4.2
SDFS (s: R2 OR R3 → R)
The signed distance sdfΩ(x) with respect to a shape Ω ⊂ Rn is defined as
sdfΩ(x) =
+ρ(x, ∂Ω)
if x ̸∈ Ω ,
−ρ(x, ∂Ω)
if x ∈ Ω ,
for all the coordinates x ∈ Rn. Consequently, by training a neural network fθ to approximate sdfΩ,
we can approximate the shape’s boundary as the zero-level set {x ∈ Rn | fθ(x) = 0}.
Preprint, submission in preparation
page 7
Figure 5: Comparison of a ReLU, SIREN, and HOSC fitting an image of random square patches of
dimension 1x1, 4x4, and 16x16. The plot to the right shows PSNRs of the model to ground truth per
epoch of training.
In this section, we consider the case where n = 2 and n = 3 and train MLPs on a dataset
{(x, sdf(x))} comprised of coordinate-SDF evaluation pairs. Our experimental exploration aims
to identify any patterns that emerge when varying the depth and width of the MLPs, as well as
adjusting the sharpness factor β (2D SDF).
In Figure 7 we present a comparison of AdaHOSC to ReLU and SIREN. For a fair comparison,
we run the same MLP architecture (5 hidden layers with 256 width) for 20 epochs only changing
the activation. AdaHOSC uses the initial value of β = 8. We find that AdaHOSC provides a
much higher quality of representation, as demonstrated by the IoU (intersection over union) values,
suggesting faster convergence time compared to SIREN.
Moreover, the results of the 2D SDF experiment are illustrated in Figure 6. In this experiment,
we train four-layer 512 width MLPs on 20 SDF evaluations of a regular star shape. Similar to
image fitting, HOSC’s performance surpasses that of ReLU and SIREN. Moreover, our findings
indicate that deep HOSC-MLPs achieve higher PSNR values. Regardless of depth, it is observed
that, depending on the width, greater β values enable HOSC to more accurately represent the shape,
as evidenced by the PSNR values. This observation further supports the hypothesis that HOSC
can effectively represent signals with high-frequency content (including discontinuities) when the
sharpness factor is large.
Figure 6: Comparison of coordinate-based MLPs fitting an SDF of a regular star. Top: SDFs learned
by the models running different activations. Bottom: Heatmap illustrating the maximum PSNR
values for HOSC-MLPs with different topologies (depth and width of layers) and sharpness factors.
5
CONCLUSIONS AND DISCUSSION
In this paper, we have introduced the Hyperbolic Oscillation activation function HOSC(x; β) =
tanh(β sin x), a new periodic parametric activation that has been designed to be particularly effec-
Preprint, submission in preparation
page 8
tive in preserving sharp features in INRs. Additionally, in Section 4, we presented experimental
results that evaluate the performance of the HOSC function in comparison to existing approaches.
Our findings revealed that an MLP employing the HOSC activation with a suitably chosen or
automatically-optimized sharpness parameter β consistently outperforms identical structure MLPs
using ReLU and SIREN activations, and achieve the same level of accuracy in neural signal en-
coding problems as Fourier Feature Networks. HOSC thus offers a simple, fully differentiable and
compact high-quality signals representation method with no need for hyperparameter tuning. How-
ever, we have identified scenarios where HOSC is clearly not the optimal choice, which we will
explore in the following discussion.
Spectral bias. Different problems require a different spectral bias. While for signal encoding,
where we assume that there is very little or no noise present in the data, fitting high-frequency
components of the signal is advantageous. Conversely, for capturing only the general trends from a
set of noisy data, a low-frequency bias can help avoid overfitting to noise. Naturally, this constraints
the application of HOSC and other periodic activations in settings that require generalization beyond
the observed datapoints. For instance, in our experiments we found that both HOSC and SIREN
activations underperform when applied to Neural Radiance Fields (Mildenhall et al., 2020), which
perform best with various types of positinoal encoding, either in freqnecty domain, or parametric
encoding combined with spatial data strcutres (also denoted as hybrid) and ReLU activations.
Solving PDEs. Cooridnate-based neural networks have been applied to solving PDEs in physics
(Raissi et al., 2019). However, we observe that HOSC is not particularly suited for these types
of problems, compared to e.g. SIREN architecture. We attribute this limitation to the increasing
complexity found in subsequent derivatives of HOSC. While the derivatives of a fully-connected
SIREN layer remain SIRENs (Sitzmann et al., 2020), enabling it to accurately fit both the signal
and its derivatives, the situation is more convoluted. As a result, HOSC preserves the signal’s sharp
features but at the expense of derivative information.
Hybrid and parametric positional encoding. In our experiments we apply HOSC in signal encod-
ing scenarios, like images, giga-pixel images, and 3D SDFs, where a HOSC-MLP achieves similar
reconstruction quality, however, not the timings of highly optimized methods as InstantNGP (M¨uller
et al., 2022), ACORN (Martel et al., 2021), grid-based Dictionary Fields (Chen et al., 2023a), or Ten-
soRF (Chen et al., 2022). There methods shorten the training and inference times at the cost of a
higher memory footprint and a more sophisticated implementation. In contrast, a simple MLP is
much easier to implement and storing its parameters is far less demanding in terms of memory.
Finally, it is important to note that, in principle HOSC can be utilized in hybrid representations as
well, whenever a coordinate-based MLP is used to overfit a signal.
Architecture design. A deeper understanding of how neural networks represent implicitly encoded
signals may also provide greater insights into the design of non-MLP network architectures, enabling
HOSC to fully leverage their capabilities. The research presented in Ramasinghe & Lucey (2021)
offers intresting ideas relevant to this context. Furthermore, HOSC naturally fits in the Factor Fields
framework (Chen et al., 2023b). More specifically, we can let any factor s in a Factor Field be
modeled with a HOSC MLP, and vary the sharpness β across the factors. This means that the
framework could potentially be used to develop novel representation methods using HOSC, possibly
combined with other architectures.
Preprint, submission in preparation
page 9
Lucy
IoU, train time
ReLU
0.8969, 34 min
SIREN
0.7263, 34 min
AdaHOSC
0.9804, 35 min
Statuette
IoU, train time
ReLU
0.8778, 34 min
SIREN
0.8168, 34 min
AdaHOSC
0.9587, 38 min
Armadillo
IoU, train time
ReLU
0.9328, 35 min
SIREN
0.9153, 36 min
AdaHOSC
0.9775, 37 min
Dragon
IoU, train time
ReLU
0.8969, 34 min
SIREN
0.8263, 34 min
AdaHOSC
0.9628, 35 min
Figure 7: Comparison of HOSC to other methods in 3D SDF reconstruction. All examples trained
on 5-layer, 256 hidden neurons model for 20 epochs. Note that HOSC is showing superior re-
construction quality, which is within the range of methods utilizing positional encoding, like Dic-
tionary Fields (Chen et al., 2023b).
For the evaluation of the IoU, we used the dataset from
https://github.com/autonomousvision/factor-fields. Note that Lucy was evaluated only on a 512 res-
olution mesh.
Preprint, submission in preparation
page 10
REFERENCES
Andrea Apicella, Francesco Donnarumma, Francesco Isgr`o, and Roberto Prevete. A survey on
modern trainable activation functions. Neural networks : the official journal of the International
Neural Network Society, 138:14–32, 2020. URL https://api.semanticscholar.org/
CorpusID:218487292. 4
Matan Atzmon and Yaron Lipman. Sal: Sign agnostic learning of shapes from raw data. 2020
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2562–2571,
2019. URL https://api.semanticscholar.org/CorpusID:208267630. 3
Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su.
Tensorf: Tensorial radi-
ance fields. ArXiv, abs/2203.09517, 2022. URL https://api.semanticscholar.org/
CorpusID:247519170. 2, 4, 8
Anpei Chen, Zexiang Xu, Xinyue Wei, Siyu Tang, Hao Su, and Andreas Geiger. Dictionary fields:
Learning a neural basis decomposition. ACM Transactions on Graphics (TOG), 42:1 – 12, 2023a.
URL https://api.semanticscholar.org/CorpusID:260167858. 4, 8
Anpei Chen, Zexiang Xu, Xinyue Wei, Siyu Tang, Hao Su, and Andreas Geiger. Factor fields: A
unified framework for neural fields and beyond. ArXiv, abs/2302.01226, 2023b. URL https:
//api.semanticscholar.org/CorpusID:256503583. 8, 9
Hao Chen, Bo He, Hanyu Wang, Yixuan Ren, Ser-Nam Lim, and Abhinav Shrivastava. Nerv: Neural
representations for videos. In Neural Information Processing Systems, 2021. URL https:
//api.semanticscholar.org/CorpusID:239885704. 3
Yinbo Chen, Sifei Liu, and Xiaolong Wang. Learning continuous image representation with local
implicit image function. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition (CVPR), pp. 8624–8634, 2020.
URL https://api.semanticscholar.org/
CorpusID:229221619. 3, 4
Zhiqin Chen and Hao Zhang.
Learning implicit fields for generative shape modeling.
2019
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5932–5941,
2018. URL https://api.semanticscholar.org/CorpusID:54457478. 3
Shiv Ram Dubey, Satish Kumar Singh, and Bidyut Baran Chaudhuri. Activation functions in deep
learning: A comprehensive survey and benchmark. Neurocomputing, 503:92–108, 2021. URL
https://api.semanticscholar.org/CorpusID:250089226. 4
Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, and Yaron Lipman.
Implicit geometric
regularization for learning shapes.
ArXiv, abs/2002.10099, 2020.
URL https://api.
semanticscholar.org/CorpusID:211259068. 3
Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. 2015 IEEE International Conference on
Computer Vision (ICCV), pp. 1026–1034, 2015. URL https://api.semanticscholar.
org/CorpusID:13740328. 4
Xiaojie Jin, Chunyan Xu, Jiashi Feng, Yunchao Wei, Junjun Xiong, and Shuicheng Yan. Deep learn-
ing with s-shaped rectified linear activation units. In AAAI Conference on Artificial Intelligence,
2015. URL https://api.semanticscholar.org/CorpusID:10520992. 4
Bekir Karlik and A. Vehbi Olgac. Performance analysis of various activation functions in general-
ized mlp architectures of neural networks. 2011. URL https://api.semanticscholar.
org/CorpusID:174791561. 4
Hiroharu Kato, Y. Ushiku, and Tatsuya Harada. Neural 3d mesh renderer. 2018 IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pp. 3907–3916, 2017.
URL https:
//api.semanticscholar.org/CorpusID:32389979. 3
Luca A. Lanzend¨orfer and Roger Wattenhofer.
Siamese siren:
Audio compression with
implicit neural representations.
ArXiv, abs/2306.12957, 2023.
URL https://api.
semanticscholar.org/CorpusID:259224407. 3
Preprint, submission in preparation
page 11
Alan S. Lapedes and Robert M. Farber. Nonlinear signal processing using neural networks: Pre-
diction and system modelling.
1987.
URL https://api.semanticscholar.org/
CorpusID:60720876. 4
Yang Li, Chunxiao Fan, Yong Li, and Qiong Wu.
Improving deep neural network with multi-
ple parametric exponential linear units. ArXiv, abs/1606.00305, 2016. URL https://api.
semanticscholar.org/CorpusID:9248703. 4
Zong-Yi Li, Nikola B. Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya,
Andrew M. Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differ-
ential equations. ArXiv, abs/2010.08895, 2020. URL https://api.semanticscholar.
org/CorpusID:224705257. 3
Julien N. P. Martel, David B. Lindell, Connor Z. Lin, Eric Chan, Marco Monteiro, and Gordon
Wetzstein. Acorn. ACM Transactions on Graphics (TOG), 40:1 – 13, 2021. URL https:
//api.semanticscholar.org/CorpusID:233864500. 2, 4, 8
Lars M. Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger.
Occupancy networks: Learning 3d reconstruction in function space. 2019 IEEE/CVF Conference
on Computer Vision and Pattern Recognition (CVPR), pp. 4455–4465, 2018.
URL https:
//api.semanticscholar.org/CorpusID:54465161. 3
Mateusz Michalkiewicz, Jhony Kaesemodel Pontes, Dominic Jack, Mahsa Baktash, and Anders P.
Eriksson. Implicit surface representations as layers in neural networks. 2019 IEEE/CVF In-
ternational Conference on Computer Vision (ICCV), pp. 4742–4751, 2019.
URL https:
//api.semanticscholar.org/CorpusID:207985696. 3
Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi,
and Ren Ng. Nerf. Communications of the ACM, 65:99 – 106, 2020. URL https://api.
semanticscholar.org/CorpusID:213175590. 2, 3, 4, 8
Thomas M¨uller, Alex Evans, Christoph Schied, and Alexander Keller. Instant neural graphics prim-
itives with a multiresolution hash encoding. ACM Transactions on Graphics (TOG), 41:1 – 15,
2022. URL https://api.semanticscholar.org/CorpusID:246016186. 2, 4, 8
Michael Oechsle, Lars M. Mescheder, Michael Niemeyer, Thilo Strauss, and Andreas Geiger.
Texture fields: Learning texture representations in function space.
2019 IEEE/CVF Interna-
tional Conference on Computer Vision (ICCV), pp. 4530–4539, 2019. URL https://api.
semanticscholar.org/CorpusID:158046789. 4
Giambattista Parascandolo, Heikki Huttunen, and Tuomas Virtanen. Taming the waves: sine as ac-
tivation function in deep neural networks. 2017. URL https://api.semanticscholar.
org/CorpusID:126004626. 4
Jeong Joon Park, Peter R. Florence, Julian Straub, Richard A. Newcombe, and S. Lovegrove.
Deepsdf:
Learning continuous signed distance functions for shape representation.
2019
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 165–174, 2019.
URL https://api.semanticscholar.org/CorpusID:58007025. 3
Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics-informed neural networks:
A deep learning framework for solving forward and inverse problems involving nonlinear par-
tial differential equations.
J. Comput. Phys., 378:686–707, 2019.
URL https://api.
semanticscholar.org/CorpusID:57379996. 3, 8
Prajit Ramachandran, Barret Zoph, and Quoc V. Le. Searching for activation functions. ArXiv,
abs/1710.05941,
2018.
URL https://api.semanticscholar.org/CorpusID:
10919244. 4
Sameera Ramasinghe and Simon Lucey.
Beyond periodicity: Towards a unifying framework
for activations in coordinate-mlps.
ArXiv, abs/2111.15135, 2021.
URL https://api.
semanticscholar.org/CorpusID:244729036. 4, 8
Preprint, submission in preparation
page 12
Vincent Sitzmann, Julien N. P. Martel, Alexander W. Bergman, David B. Lindell, and Gordon Wet-
zstein. Implicit neural representations with periodic activation functions. ArXiv, abs/2006.09661,
2020. URL https://api.semanticscholar.org/CorpusID:219720931. 2, 3, 4,
6, 8
Josep M. Sopena, Enrique Romero, and Ren´e Alqu´ezar.
Neural networks with periodic and
monotonic activation functions: a comparative study in classification problems. 1999. URL
https://api.semanticscholar.org/CorpusID:122973551. 4
Matthew Tancik, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan,
Utkarsh Singhal, Ravi Ramamoorthi, Jonathan T. Barron, and Ren Ng. Fourier features let net-
works learn high frequency functions in low dimensional domains. ArXiv, abs/2006.10739, 2020.
URL https://api.semanticscholar.org/CorpusID:219791950. 2, 3, 4
Anju Tewari, Otto Fried, Justus Thies, Vincent Sitzmann, S. Lombardi, Z. Xu, Tanaba Simon,
Matthias Nießner, Edgar Tretschk, L. Liu, Ben Mildenhall, Pranatharthi Srinivasan, R. Pandey,
Sergio Orts-Escolano, S. Fanello, M. Guang Guo, Gordon Wetzstein, J y Zhu, Christian Theobalt,
Manju Agrawala, Donald B. Goldman, and Michael Zollh¨ofer.
Advances in neural render-
ing. Computer Graphics Forum, 41, 2021. URL https://api.semanticscholar.org/
CorpusID:236162433. 3
Ayush Kumar Tewari, Ohad Fried, Justus Thies, Vincent Sitzmann, Stephen Lombardi, Kalyan
Sunkavalli, Ricardo Martin-Brualla, Tomas Simon, Jason M. Saragih, Matthias Nießner, Rohit
Pandey, S. Fanello, Gordon Wetzstein, Jun-Yan Zhu, Christian Theobalt, Maneesh Agrawala,
Eli Shechtman, Dan B. Goldman, and Michael Zollhofer.
State of the art on neural render-
ing. Computer Graphics Forum, 39, 2020. URL https://api.semanticscholar.org/
CorpusID:215416317. 3
Kwokwo Wong, Andrew Chi-Sing Leung, and Shen jiang Chang. Handwritten digit recognition
using multilayer feedforward neural networks with periodic and monotonic activation functions.
Object recognition supported by user interaction for service robots, 3:106–109 vol.3, 2002. URL
https://api.semanticscholar.org/CorpusID:16161892. 4
Yun-Peng Xiao, Yu-Kun Lai, Fang-Lue Zhang, Chunpeng Li, and Lin Gao. A survey on deep
geometry learning: From a representation perspective. Computational Visual Media, 6:113 –
133, 2020. URL https://api.semanticscholar.org/CorpusID:211171854. 3
Yiheng Xie, Towaki Takikawa, Shunsuke Saito, Or Litany, Shiqin Yan, Numair Khan, Fed-
erico Tombari, James Tompkin, Vincent Sitzmann, and Srinath Sridhar.
Neural fields in vi-
sual computing and beyond.
Computer Graphics Forum, 41, 2021.
URL https://api.
semanticscholar.org/CorpusID:244478496. 3
"
"Visual fine-tuning has been receiving considerable attention in recent years owing to the advent of pre-trained vision models. However, the currently dominant approach, known as full fine-tuning, encounters knowledge forgetting, as it primarily focuses on fitting the downstream training set. To address this problem, this paper proposes a novel weight rollback-based fine-tuning method termed One Step Learning, One Step Review (OLOR). Unlike previous weight decay and regularization techniques that generally push the current weight away from 0 in the late stage of the optimization, OLOR incorporates a weight rollback term into the weight update term during the optimization. This ensures that the model weight gradually approaches the pre-trained weights as it learns the downstream task. In addition, a layer-wise penalty is introduced for weight rollback, utilizing penalty decay and diversified decay rates to adjust the rollback amounts of each layer, thereby accommodating diverse downstream tasks. To demonstrate the effectiveness of the proposed approach, comprehensive experiments have been conducted on a variety of tasks, encompassing image classification, object detection, semantic segmentation, and instance segmentation. The results on different pre-trained and downstream models indicate that OLOR achieves remarkable performance, confirming its general applicability.nan","The rapid advancement of deep learning technology has resulted in the establishment of numerous large-scale image datasets, propelling the development of promising pre-trained visual models. These pre-trained models have shown great potential for transfer learning and fine-tuning, allowing them to effectively solve related but distinct visual tasks. The fundamental fine-tuning methods are linear probing and full fine-tuning. However, linear probing often restricts the performance of the pre-trained backbone, while full fine-tuning typically leads to knowledge forgetting. Varied approaches have been explored to address these issues, including rehearsal methods, regularization methods, and parameter isolation methods. However, rehearsal methods tend to be inefficient due to the need for storing and managing large amounts of upstream task data. Regularization methods, such as weight decay or L2 penalty, have also demonstrated limited effectiveness in preventing knowledge forgetting, particularly when combined with adaptive optimizers. Parameter isolation methods, though effective, introduce additional parameters and often require specific training skills. To overcome these limitations, this paper introduces a novel fine-tuning method, called OLOR, which combines weight rollback and optimizer to prevent knowledge forgetting in neural networks. OLOR incorporates the weight rollback term into the weight update term at each step, allowing the model to gradually approach the pre-trained weights while learning the downstream task, resulting in the convergence of weights between the upstream and downstream models. Additionally, a layer-wise penalty is devised to employ penalty decay and diversified decay rate to adjust the weight rollback levels of layers for adapting varying downstream tasks.nan","nanRehearsal methods, based on the replay mechanism, involve retraining on a subset of stored upstream samples while learning new tasks. However, this approach is quite inefficient. EWC (Kirkpatrick et al. 2017) proposes a regularization-based fine-tuning method that uses the Fisher information matrix to determine the importance of weight parameters. This helps adjust the parameters between upstream and downstream tasks, reducing forgetting. L2-SP (Xuhong, Grandvalet, and Davoine 2018) uses an L2 penalty to restrict the updates of parameters, addressing knowledge forgetting during fine-tuning. However, it is not compatible with adaptive optimizers (Loshchilov and Hutter 2017; Guan 2023), which may produce the wrong regularization direction. Parameter isolation methods (Jia et al. 2022; Sohn et al. 2023) create new branches or modules for different network models and tasks for downstream tasks. However, it introduces extra new training parameters, requires certain training skills, and has lower generality than rehearsal methods.nan","The proposed method combines weight rollback and optimizers to adjust the range of parameter updates, thereby enhancing pre-trained model representations to improve downstream fine-tuning performance. We introduce weight rollback, which is a real-time regularization method that closely follows each weight update step. It aims to bring the current model weights closer to the pre-trained weights to perform knowledge reviewing. Subsequently, the discrepancy Δd between ϸpre and the pre-trained weight ϸ0 is computed as:

Δd = ϸpre − ϸ0.

Finally, the weight update process incorporates Δd, resulting in the adjusted model weights ϸt:

ϸt = ϸt₁ − ϸtgt − λΔd.

In addition, a layer-wise penalty mechanism is proposed. For deep learning neural networks, each layer can be conceptualized as a function that processes its input. Given a layer index i, this process can be described as follows:

xi+1 = fi(x⋅
i),

where fi represents the ith layer. Let xu
i denotes the input of fi in upstream tasks with a distribution of qi(xu
i), and xd
i denotes the input of fi in downstream tasks with a distribution of pi(xd
i). Since qi(xu
i) are always different from pi(xd
i), we first unfreeze all layers to secure fi will have sufficient update to handle such gap better.

To accommodate the variability of target objectives, we propose adjusting the rate of penalty decay between layers by introducing a power exponent γ to the weight rollback value. Mathematically, this adjustment can be expressed as:

1 ∈ i
n → (1 ∈ i
n)^γ.nan","The proposed OLOR achieves state-of-the-art performance on all datasets covering general classification, fine-grained classification, long-tailed classification, cross-domain classification, object detection, semantic segmentation, and instance segmentation. Notably, in in-distribution (ID) datasets, OLOR-Adam surpasses the previously leading L2-SP method by an impressive margin of 6.47% in accuracy. Moreover, when confronted with two more challenging out-of-distribution (OOD) datasets, OLOR-Adam achieves accuracy improvements of 2.57% and 7.38%, respectively, outperforming the optimal methods. Experiments on detection and segmentation tasks also demonstrate the effectiveness and versatility of OLOR. OLOR consistently outperforms the baseline by approximately 1% in all metrics across various tasks. Furthermore, in experiments using different pre-trained models, OLOR outperforms other leading methods across all pre-trained models, including Supervised, CLIP, and MAE. These results demonstrate the robustness and effectiveness of the proposed OLOR in various tasks and under different settings.nan","The main contribution of this study is the development of OLOR, a novel fine-tuning method. OLOR combines weight rollback and layer-wise penalty to address knowledge forgetting and enhance fine-tuning performance. The proposed method achieves state-of-the-art results on extensive downstream tasks, encompassing general classification, fine-grained classification, long-tailed classification, cross-domain classification, object detection, semantic segmentation, and instance segmentation. Validation experiments and ablation analysis confirm the effectiveness of the method and the rationality of the parameters. The key innovations of OLOR include integrating a weight rollback term into the weight update term, devising a layer-wise penalty with penalty decay and diversified decay rate, and seamlessly combining with optimizers for efficient implementation.nan","One Step Learning, One Step Review","Xiaolong Huang, Qiankun Li, Xueran Li, Xuesong Gao","One Step Learning, One Step Review
Xiaolong Huang1, Qiankun Li2, 3*, Xueran Li4, 5, Xuesong Gao1
1School of Artificial Intelligent, Chongqing University of Technology, Chongqing, China
2Institute of Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China
3Department of Automation, University of Science and Technology of China, Hefei, China
4Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, China
5Anhui University, Hefei, China
{hirox827, xueran.lxr}@gmail.com, qklee@mail.ustc.edu.cn, xuesonggxs@foxmail.com
Abstract
Visual fine-tuning has garnered significant attention with
the rise of pre-trained vision models. The current prevailing
method, full fine-tuning, suffers from the issue of knowledge
forgetting as it focuses solely on fitting the downstream train-
ing set. In this paper, we propose a novel weight rollback-
based fine-tuning method called OLOR (One step Learning,
One step Review). OLOR combines fine-tuning with opti-
mizers, incorporating a weight rollback term into the weight
update term at each step. This ensures consistency in the
weight range of upstream and downstream models, effec-
tively mitigating knowledge forgetting and enhancing fine-
tuning performance. In addition, a layer-wise penalty is pre-
sented to employ penalty decay and the diversified decay
rate to adjust the weight rollback levels of layers for adapt-
ing varying downstream tasks. Through extensive experi-
ments on various tasks such as image classification, object
detection, semantic segmentation, and instance segmentation,
we demonstrate the general applicability and state-of-the-art
performance of our proposed OLOR. Code is available at
https://github.com/rainbow-xiao/OLOR-AAAI-2024.
Introduction
With the rapid advancement of deep learning technology,
numerous large-scale image datasets have been established
(Schuhmann et al. 2022; Russakovsky et al. 2015; Schuh-
mann et al. 2021), resulting in many promising pre-trained
visual models (Radford et al. 2021; He et al. 2022; Bao et al.
2021). These pre-trained models can effectively solve re-
lated but distinct visual tasks through transfer learning and
fine-tuning techniques (Wu, Sun, and Ouyang 2023; Shen
et al. 2021). The fundamental fine-tuning methods are lin-
ear probing and full fine-tuning (Zhang, Isola, and Efros
2017). In linear probing, the pre-trained model’s backbone
is frozen, and only the head specific to the downstream task
is trained. However, this approach often restricts the per-
formance of the pre-trained backbone. On the other hand,
full fine-tuning involves training the entire network directly,
but it usually leads to knowledge forgetting (De Lange et al.
2021).
*Corresponding authors (qklee@mail.ustc.edu.cn)
Copyright © 2024, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
Rehearsal methods (Rebuffi et al. 2017; Rolnick et al.
2019; Liu et al. 2020; Merlin et al. 2022), based on the re-
play mechanism, involve retraining on a subset of stored
upstream samples while learning new tasks. However, this
approach is quite inefficient. EWC (Kirkpatrick et al. 2017)
proposes a regularization-based fine-tuning method that uses
the Fisher information matrix to determine the importance of
weight parameters. This helps adjust the parameters between
upstream and downstream tasks, reducing forgetting. L2-SP
(Xuhong, Grandvalet, and Davoine 2018) uses an L2 penalty
to restrict the updates of parameters, addressing knowledge
forgetting during fine-tuning. However, it is not compatible
with adaptive optimizers (Loshchilov and Hutter 2017; Guan
2023), which may produce the wrong regularization direc-
tion. Parameter isolation methods (Jia et al. 2022; Sohn et al.
2023) create new branches or modules for different network
models and tasks for downstream tasks. However, it intro-
duces extra new training parameters, requires certain train-
ing skills, and has lower generality than rehearsal methods.
In this paper, we propose a novel fine-tuning method com-
bined with optimizers to solve knowledge forgetting, called
OLOR (One step Learning, One step Review). Specifically,
OLOR introduces a weight rollback term to the weight up-
date term during the fine-tuning stage, allowing the model
to gradually approach the pre-trained weights while learning
the downstream task. This process avoids delay defects and
makes the weights of the upstream and downstream models
more similar. In addition, a layer-wise penalty is devised to
employ penalty decay and the diversified decay rate to ad-
just the weight rollback levels of layers. Penalty decay com-
bines feature pyramids with transfer learning, giving more
significant weight rollback to shallow layers related to shal-
low features such as color and texture, and smaller weight
backtracking to deep layers related to deep features such
as semantic information. The diversified decay rate is ad-
justed to enhance applicability according to the variations
between up and downstream tasks. OLOR with layer-wise
penalty enables each layer of the model to update accord-
ing to its needs, resulting in superior extraction of gener-
alized features. Finally, OLOR is incorporated into optimiz-
ers, thereby introducing negligible extra computational over-
head. It also works well with popular optimizers such as
Adam (Loshchilov and Hutter 2017; Guan 2023) and SGD
(Keskar and Socher 2017), meeting specific needs under var-
arXiv:2401.10962v1  [cs.CV]  19 Jan 2024
ious conditions.
Our OLOR fine-tuning method achieves state-of-the-art
performance on ten popular visual task datasets covering
general classification, fine-grained classification, long-tail
classification, cross-domain classification, object detection,
semantic segmentation, and instance segmentation. Valida-
tion experiments and ablation analysis demonstrate the per-
formance of OLOR in solving the problem of knowledge
forgetting and the rationality of the parameters.
The main contributions can be summarized as follows.
• We propose a novel fine-tuning method OLOR, which
cooperates with optimizers to solve the knowledge
forgetting issue, thereby improving fine-tuning perfor-
mance.
• The designed weight rollback avoids delay defects by in-
corporating the current gradient into the penalty term,
thereby correcting the penalty target and smoothing the
review process.
• A layer-wise penalty is presented to employ penalty de-
cay and the diversified decay rate to adjust the weight
rollback levels of layers for adapting varying downstream
tasks.
• The proposed method achieves state-of-the-art perfor-
mance on extensive downstream tasks, including differ-
ent types of image classification, different pre-trained
models, and image detection and segmentation.
Related Work
Pre-Training Resource
With the rapid advancement of computer vision, numerous
large-scale datasets (Russakovsky et al. 2015; Schuhmann
et al. 2021, 2022) and pre-trained models have emerged.
These upstream pre-trained models possess rich features
and hold great potential for transferability to other specific
downstream tasks. ImageNet-21K (Russakovsky et al. 2015)
is the most popular large-scale dataset with over 14 million
images, and most networks are pre-trained on it. Recently,
a groundbreaking development has taken place with the re-
lease of LAION-2B (Schuhmann et al. 2022). This dataset
now reigns as the largest, comprising over 2 billion image-
text pairs. Then many pre-trained models have been pro-
posed, such as OpenClip (Radford et al. 2021), BEiT (Peng
et al. 2022), MAE (He et al. 2022), and EVA (Fang et al.
2023). It is worth noting that most of these models’ back-
bones are built upon the foundations of ViT (Dosovitskiy
et al. 2020) and ConvNeXt (Liu et al. 2022).
Fine-Tuning Method
The process of fine-tuning usually faces an issue known as
knowledge forgetting (Toneva et al. 2018). It refers to the
model’s loss of pre-training learned representations during
fine-tuning (Mosbach, Andriushchenko, and Klakow 2020).
This leads to reduced accuracy on both the upstream and
downstream tasks, as the model cannot effectively utilize its
potential knowledge (De Lange et al. 2021; Vander Eeckt
and Van Hamme 2023).
To solve this issue, there are currently three categories
of approaches, i.e., replay methods, regularization methods,
and parameter isolation methods. Replay involves period-
ically training on a subset of upstream task data, thereby
retaining knowledge of previous tasks and balancing old
and new information (Rebuffi et al. 2017; Rolnick et al.
2019; Liu et al. 2020; Merlin et al. 2022). However, stor-
ing and managing updtream task data pose challenges in
terms of efficiency, particularly in the contemporary era of
massive datasets (Schuhmann et al. 2022; Li et al. 2023).
Regularization-based methods employ techniques such as
the fisher information matrix (Kirkpatrick et al. 2017),
weight decay (Kumar et al. 2022), and L2 penalty (Xuhong,
Grandvalet, and Davoine 2018) to restrict parameter up-
dates during fine-tuning. However, these techniques may
not be entirely adequate in completely preventing knowl-
edge forgetting. Moreover, the presence of adaptive opti-
mizers (Loshchilov and Hutter 2017; Guan 2023) can oc-
casionally impact the direction of regularization (Xuhong,
Grandvalet, and Davoine 2018). Parameter isolation meth-
ods incorporate specific branches or modules into the pre-
trained network during downstream fine-tuning, aiming to
achieve knowledge transfer through these new modules (Jia
et al. 2022; Sohn et al. 2023; Wang et al. 2023). However,
architectural modifications introduce new training parame-
ters and intricate designs. Moreover, training tricks play a
crucial role in the effectiveness of the new module, often ne-
cessitating multiple rounds of freezing and unfreezing.
To achieve a general and concise fine-tuning method to
address knowledge forgetting, the proposed OLOR fine-
tuning method combines weight rollback and optimizers to
adjust the range of parameter updates. This allows for en-
hancing pre-trained model representations to improve down-
stream fine-tuning performance.
Method
We propose a One step Learning, One step Review (OLOR)
method to reduce knowledge forgetting for fine-tuning.
OLOR can be seamlessly applied to various downstream
tasks among with different optimizers and models. The
overall framework is illustrated in Figure 1, and detailed
pipelines incorporating SGD and Adam are described in Al-
gorithm 1 and Algorithm 2. This section introduces the de-
lay defect of the previous regularization method, followed
by detailed explanations of the OLOR method, which com-
prises weight rollback and layer-wise penalty.
Previous Regularization Mechanisms Have a Delay
Defect
The implementation of OLOR is inspired by L2 regulariza-
tion and weight decay, which are popular methods used to
regularize the model parameters. However, our findings in-
dicate that their effectiveness does not align with the initial
expectation. In the case of the classic SGD optimizer, L2
regularization can be regarded as equivalent to weight de-
cay (Loshchilov and Hutter 2017), which can be defined as
follows:
θt = (1 − λ)θt−1 − ηtgt,
(1)
Upstream data
Backbone
(Pre-trained)
Linear
(Random)
Adam-OLOR
Prediction
Adam
Adam
OLOR
. . .
. . .
. . .
. . .
. . .
. . .
Layer-wise Penalty
Downstream data
Layer index
One step Learning, One step Review (OLOR)
Figure 1: Overview of OLOR using Adam as optimizer, where λi represents the penalty factor of ith layer, θt and ˆθt+1 represents
the weight and the estimation of next weight (pre-weight) at timestep t, respectively. The transparency of the image indicates
the knowledge forgetting level.
Algorithm 1: OLOR for SGD with Momentum
1: input:
η ∈ IR: Initial learning rate, β ∈ [0, 1): momentum factor, θ0:
pre-trained weight, ι1, ι2 ∈ [0, 1], ι1 ≥ ι2: max and min level
of weight rollback respectively, γ ∈ IR: weight rollback power
2: initialize:
t ← 0: time step, m0 ← 0: initial moment vector, d0 ← 0:
initial discrepancy value, λi ← f(λ, i, n, ι1, ι2)/η: calculate
penalty factor λi through λi = f(λ, i, n, ι1, ι2) = ι2 + (1 −
i
n)γ(ι1 − ι2), then scale it by dividing η to eliminate the scale
issue.
3: repeat
4:
t ← t + 1
5:
ηt ←LRScheduler(ηt−1)
(Calculate ηt at timestep t)
6:
gt ← ∇θft(θt−1)
(Get batch gradient at timestep t)
7:
mt ← βmt−1 + (1 − β)gt
(Compute momentum)
8:
θt ← θt−1 − ηtλidt−1 − (1 − ηtλi)ηtmt(Update weight)
9:
dt ← (1 − ηtλi)(dt−1 − ηtmt)
(Update discrepancy)
10: until Stopping condition is met
11: return Parameters θt
where θt represents the model weights at iteration t, and
θt−1 is corresponding weights from the previous iteration. λ
is the regularization factor (weight decay strength). ηt is the
learning rate at iteration t. gt is the batch gradient computed
from the loss function at iteration t. Weight decay penalizes
the weights obtained from the previous iteration by pushing
them toward 0. However, in practice, limλ→1 θt = −ηtgt,
Algorithm 2: OLOR for Adam
1: input:
η ∈ IR: Initial learning rate, β1, β2 ∈ [0, 1): Exponential
decay rates for the moment estimates, ϵ: bias, θ0: pre-trained
weight, ι1, ι2 ∈ [0, 1], ι1 ≥ ι2: max and min level of weight
rollback respectively, γ ∈ IR: weight rollback power
2: initialize:
t ← 0: time step, m0 ← 0: initial first moment vector, v0 ←
0: initial second moment vector, d0 ← 0: initial discrepancy
value, λi ← f(λ, i, n, ι1, ι2)/η: calculate penalty factor λi
through λi = f(λ, i, n, ι1, ι2) = ι2 + (1 − i
n)γ(ι1 − ι2), then
scale it by dividing η to eliminate the scale issue.
3: repeat
4:
t ← t + 1
5:
ηt ←LR Scheduler(ηt−1)
(Calculate ηt at timestep t)
6:
gt ← ∇ft(θt−1)
(Get batch gradient at timestep t)
7:
mt ← β1mt−1 + (1 − β1)gt (Update first moment vector)
8:
vt ← β2vt−1 + (1 − β2)g2
t (Update second moment vector)
9:
ˆmt ← mt/(1 − βt
1)
10:
ˆvt ← vt/(1 − βt
2)
11:
θt ← θt−1 − ηtλidt−1 − (1−ηtλi)ηt ˆ
mt
(√ˆvt+ϵ)
(Update weight)
12:
dt ← (1 − ηtλi)(dt−1 −
ηt ˆ
mt
(√ˆvt+ϵ))
(Update discrepancy)
13: until stopping criterion is met
14: return optimized parameters θt
the weights tend to be pushed towards the negative value
of the current gradient instead of 0. This behavior may be
different from the initial expectation. Furthermore, applying
weight decay can actually increase the current weight com-
pared to not applying it. This can be seen in the following
inequality:
(θt−1 − ηtgt − λθt−1)2 > (θt−1 − ηtgt)2,
(2)
simplified as:
ηgt < (1 − λ
2 )θt−1,
if θt−1 < 0,
ηgt > (1 − λ
2 )θt−1,
if θt−1 > 0.
If η, gt, λ, and θt−1 are in above conditions, using weight
decay will drive the current weight away from 0, which is
opposite to its target. Similarly, this issue with the decay ef-
fect also exists in other regularization mechanisms such as
L1 regularization, L2-SP, and similar methods.
Weight Rollback
The proposed weight rollback is a real-time regularization
method that closely follows each weight update step. It aims
to bring the current model weights closer to the pre-trained
weights to perform knowledge reviewing. Specifically, the
first step is to calculate the pre-weight θpre by gradient:
θpre = θt−1 − ηtgt,
(3)
where θt−1 represents the model weights from the previous
time step, ηt is the learning rate at the current time step, and
gt denotes the gradient. Subsequently, the discrepancy ∆d
between θpre and the pre-trained weight θ0 is computed as:
∆d = θpre − θ0.
(4)
Finally, the weight update process incorporates ∆d, result-
ing in the adjusted model weights θt:
θt = θt−1 − ηtgt − λ∆d.
(5)
By substituting Eq. 3 and Eq. 4 into Eq. 5, we obtain:
θt = (1 − λ)(θt−1 − ηtgt) + λθ0.
(6)
This Eq. 6 ensures that limλ→1 θt = θ0, which aligns with
our expectation and prevents abnormal scenarios. In addi-
tion, as the gradient gt is also subject to a penalty, this pro-
cess may potentially help to mitigate gradient explosions.
In summary, the weight rollback technique moderates the
deviation between θt and θ0 at each step, thereby alleviating
overfitting to the current task and knowledge forgetting to
the previous task.
Layer-Wise Penalty
Penalty Decay.
For deep learning neural networks, each
layer can be conceptualized as a function that processes its
input. Given a layer index i, this process can be described as
follows:
xi+1 = fi(x∗
i ),
(7)
where the fi represents the ith layer. Let xu
i denotes the in-
put of fi in upstream tasks with a distribution of qi(xu
i ), and
xd
i denotes the input of fi in downstream tasks with a dis-
tribution of pi(xd
i ). Since qi(xu
i ) are always different from
pi(xd
i ), we first unfreeze all layers to secure fi will have suf-
ficient update to handle such gap better.
Dataset
Images
Categories
Type
CIFAR-100
60,000
100
General
SVHN
600,000
10
General
CUB-200
11,788
200
Fine-grained
Stanford Cars
16,185
196
Fine-grained
Places-LT
62,500
365
Long-tailed
IP102
75,222
102
Long-tailed
OfficeHome
15,500
4 × 65
Cross-domain
PACS
9,991
4 × 7
Cross-domain
COCO2017
163,957
80
Detection
ADE20K
27,574
3688
Segmentation
Table 1: Details of the fine-tuning datasets.
In the study of image feature extraction, a prevailing un-
derstanding is that shallow layers are primarily responsible
for capturing superficial features (Lin et al. 2017) such as
color, texture, and shape. In contrast, deeper layers focus
on extracting more profound features like semantic infor-
mation. This implies that shallow layers are closely linked
to the distribution of the data, whereas deep layers are more
aligned with task-specific objectives. A foundational as-
sumption underlying transfer learning is that qi(xu
i ) bears
a degree of similarity to pi(xd
i ). Consequently, shallow lay-
ers tend to exhibit similarities in both pre-training and fine-
tuning stages. Additionally, shallow layers require fewer up-
dates compared to their deeper counterparts.
Based on these observations, we propose a layer-wise
penalty decay mechanism for weight rollback. This ap-
proach gradually reduces the rollback level as the layer
depth increases. This strategy encourages shallow layers to
extract more general features in downstream tasks while pre-
serving the overall model capacity. For any layer at index i,
the penalty factor λi is computed using the following for-
mula:
λi = ι2 + (1 − i
n)(ι1 − ι2),
(8)
where n represents the total number of layers in the pre-
trained model, ι1 and ι2 denote the maximum and minimum
rollback levels, respectively.
Diversified Decay Rate.
Across various downstream
tasks, the target objectives often exhibit varying degrees of
dissimilarity from those of the upstream task. To accommo-
date this variability, we propose adjusting the rate of penalty
decay between layers by introducing a power exponent γ to
the weight rollback value. Mathematically, this adjustment
can be expressed as:
1 − i
n −→ (1 − i
n)γ.
(9)
This dynamic adjustment helps mitigate the bias stemming
from a fixed rate decay of the similarities between qi(xu
i )
and pi(xd
i ) across different layer indices i. Consequently, the
penalty decay becomes more adaptable and versatile, cater-
ing to a spectrum of requirements dictated by the various
downstream tasks.
General (ID)
Fine-Grained (ID)
Long-Tailed (OOD)
Cross-Domain (OOD)
Method
Cifar-100
SVHN
CUB-200
StanfordCars
Places-LT
IP102
OfficeHome
PACS
ViT-B Backbone
Linear
72.50
58.79
75.01
38.03
31.95
64.93
79.96
71.88
Full
87.76
97.27
81.34
75.55
31.59
74.09
84.39
87.79
L2-SP
88.17
97.12
81.65
75.55
31.22
73.75
84.74
87.74
VPT
91.49
94.37
81.86
58.24
37.02
70.41
86.48
77.44
OLOR-Adam (ours)
92.89
97.35
84.84
82.02
38.07
75.34
89.05
94.38
ConvNeXt-B Backbone
Linear
81.70
69.21
87.85
50.21
36.41
70.77
92.40
93.46
Full
92.72
96.97
88.59
88.67
38.61
75.01
91.78
95.51
L2-SP
92.84
97.01
88.82
88.83
38.52
75.20
90.61
95.90
VPT
88.71
81.58
87.88
51.58
36.32
71.22
92.31
93.75
OLOR-SGD (ours)
92.86
97.12
89.47
88.99
39.36
75.44
92.59
96.63
Table 2: Comparison of fine-tuning results on various types of classification datasets (general, fine-grained, long-tailed, cross-
domain).
Experiments
Experiment Configuration
Pre-Trained Backbones.
The experiments employ CNN-
based ConvNeXt (Liu et al. 2022) and Transformer-based
Vision Transformers (ViT) (Dosovitskiy et al. 2020) as
backbones. For both types of models, pre-trained weights
from ImageNet-1K (MAE) (Deng et al. 2009), ImageNet-
21K (supervised) (Russakovsky et al. 2015) and LAION-2B
(CLIP) (Schuhmann et al. 2022) datasets are utilized, where
the weights from ImageNet-21K undergoes supervised pre-
training, and the others are based on self-supervised pre-
training diagram.
Downstream Tasks.
We experiment on ten popular visual
task datasets, i.e., CIFAR-100 (Krizhevsky, Hinton et al.
2009), SVHN (Netzer et al. 2011), CUB-200 (Wah et al.
2011), Stanford Cars (Krause et al. 2013), Places-LT (Zhou
et al. 2014), IP102 (Patterson et al. 2014), OfficeHome
(Venkateswara et al. 2017), and PACS (Li et al. 2017), cov-
ering general classification, fine-grained classification, long-
tailed classification, cross-domain classification, object de-
tection, semantic segmentation, and instance segmentation.
More details are listed in Table 1.
Baselines.
To ensure a comprehensive comparison, we se-
lect the state-of-the-art and classic methods as our baselines.
These encompass Full Fine-tuning (Full), Linear Probing
(Linear) (Zhang, Isola, and Efros 2017), L2-SP (Xuhong,
Grandvalet, and Davoine 2018), and VPT (Jia et al. 2022).
Following prior works (Carion et al. 2020), CNN-based
Backbones are usually combined with the SGD optimizer,
while Transformer-based Backbones are paired with the
Adam optimizer.
Implementation Details.
The input image size is set at
224 × 224. The batch size varies depending on the freez-
ing strategy. Specifically, 128, 256 and 512 are chosen for
full unfreezing, parameter isolated, and full freezing based
methods, respectively. Regarding the learning rate, for Con-
vNeXt backbones, we employ the SGD optimizer with a mo-
mentum of 0.9. The learning rates differ based on the freez-
ing strategy. In detail, 1e-2, 2e-2 and 4e-2 for full unfreez-
ing, parameter isolated, and full freezing based methods, re-
spectively. For ViT backbones, we use the Adam optimizer
with a momentum of (0.9, 0.999). The learning rates for ViT
backbones also vary according to the freezing strategy, i.e.,
1e-4 for full unfreezing, 2e-4 for partial unfreezing, and 4e-
4 for full freezing. We train on cross-domain datasets for
30 epochs, while for other datasets, we train for 50 epochs.
The experiments are performed on two A5000 GPU with
24 GB memory and Ubuntu 20.04 operating system. Python
3.8.3 serves as the programming language, while PyTorch
2.0.0 framework is employed. In addition, the source code is
openly available on GitHub.
Main Results
Results on Classification Tasks.
To verify the wide
adaptability of OLOR on various types of datasets, we con-
duct a comprehensive comparison with other state-of-the-
art fine-tuning methods. We evaluate these methods on 10
popular classification datasets, each showcasing a range of
data distributions and characteristics. In addition, the Back-
bone in the experiment covers ViT-B and ConvNeXt-B, cor-
responding to Adam and SGD optimizers, respectively.
The experiment results are listed in Table 2. It can be ob-
served that our OLOR achieves a new state-of-the-art on all
datasets. Notably, in in-distribution (ID) datasets, OLOR-
Adam surpasses the previously leading L2-SP method by an
impressive margin of 6.47% in accuracy. Moreover, when
confronted with two more challenging out-of-distribution
(OOD) datasets, OLOR-Adam achieves accuracy improve-
ments of 2.57% and 7.38%, respectively, outperforming the
optimal methods.
Since the pre-trained ConvNeXt model is more stable than
the ViT structure, there is not much difference between dif-
ferent methods in fine-tuning. However, our OLOR-SGD
still consistently improves fine-tuning accuracy across all
Method
Model
Dataset
Bboxm
Segmm
Full
Mask R-CNN
COCO2017
40.20
36.00
OLOR
Mask R-CNN
COCO2017
41.10
36.90
Table 3: Results of object detection and instance segmenta-
tion using the ConvNeXt-B as backbone.
Method
Model
Dataset
IOUm
Full
UperNet
ADE20K
43.65
OLOR
UperNet
ADE20K
44.62
Table 4: Results of semantic segmentation using the ViT-B
as backbone.
datasets. These results demonstrate the robustness and ef-
fectiveness of the proposed OLOR in various tasks.
Results on Detection and Segmentation Tasks.
Due to
the complexity of detection and segmentation tasks, most
existing fine-tuning methods struggle with applicability and
validation. However, integrated with the optimizer, our
OLOR approach can easily be applied to these tasks. Table
3 shows the results of object detection and instance segmen-
tation on the COCO2017 dataset, while Table 4 showcases
the performance of semantic segmentation on the ADE20K
dataset. OLOR consistently outperforms the Baseline by ap-
proximately 1% in all metrics, demonstrating its versatility
and effectiveness in more complex detection and segmenta-
tion tasks.
Results of Using Different Pre-Trained Models.
Consid-
ering that the performances of different fine-tuning methods
may vary when using different pre-trained models, we fur-
ther conduct experiments to explore and compare. The pre-
trained ViT-B model weights are obtained from ImageNet-
21K (supervised), LAION-2B (CLIP), and ImageNet-1K
(MAE). The fine-tuning experiments are based on the chal-
lenging PACS dataset.
As listed in Table 5, our OLOR consistently achieves
state-of-the-art results across all pre-trained models. Specif-
ically, OLOR surpasses other leading methods by 5.08%,
0.64%, and 3.47% when using Supervised, CLIP, and MAE,
respectively. While other methods struggle to adapt to all
pre-trained models simultaneously, our OLOR demonstrates
potential across all pre-trained models.
Method
Supervised
OpenCLIP
MAE
Linear
71.88
95.61
36.72
Full
87.79
47.17
84.18
L2-SP
87.74
45.56
85.79
VPT
76.76
97.46
50.54
OLOR (ours)
92.87
98.10
89.26
Table 5: Results of using different pre-trained models on the
PACS dataset.
0
10
20
30
40
50
Epochs
2.0
2.5
3.0
3.5
4.0
Loss
0
10
20
30
40
50
Epochs
70
75
80
85
90
95
Top1-accuracy
SGD
Adam
OLOR-SGD
OLOR-Adam
Figure 2: Train loss and valid top1 accuracy on CIfar-100,
using ViT-B with Adam and ConvNext-B with SGD.
0
20
40
60
80
100 10
20
30
Epochs
0
25
50
75
100
Top1-accuracy
Pre-train Stage
Fine-Tune
Stage
Pre-train(Fold1)
Pre-train(Fold2)
Full(Fold2)
Full(Fold1)
OLOR(Fold2)
OLOR(Fold1)
0
50
100
150
Layer index
0.0
0.5
1.0
1.5
2.0
(W
W0)2
0
10
20
30
40
50
Rollback Steps
20
40
60
80
100
Top1-accuracy
Full fine-tuned results
Pre-trained results
full
OLOR
Fold2
Fold1
Figure 3: Knowledge forgetting test on PACS. Fold 1 as train
set and fold 2 as valid set during pre-training, splits during
fine-tuning is opposite to pre-training.
Summary of Main Results.
In summary, the above ex-
periments show that OLOR achieves SOTA when applied
to multiple downstream tasks, utilizing diverse pre-trained
backbones. These results demonstrate the generalizability
and effectiveness of the OLOR fine-tuning method.
Analysis and Discussion
Compatibility Analysis.
As shown in Figure 2, adopting
weight rollback in different types of models and optimiz-
ers generally improves the performance. Due to the restric-
tion on parameters, OLOR leads to slower loss converging
speed at first, but ultimately becomes competitive with the
full method. According to the validation results, OLOR po-
tentially helps reduce knowledge forgetting, resulting in far
superior top1 accuracy, especially when cooperating with
Adam applied in Vision Transformers.
Knowledge Forgetting Test.
To assess potential knowl-
edge forgetting, we conduct a study on the PACS dataset
using ViT-B and Adam. Firstly, split the dataset into two
folds, the first fold contains data from three domains, car-
toon, photo and sketch respectively, denote as D1, the sec-
ond fold contains data from art painting domain, denote as
D2. For training stage, we first pre-train a model using D1
10
4
10
3
10
2
10
1
100
1
85
90
95
100
Top1-accuracy
Cifar-100
10
4
10
3
10
2
10
1
100
1
80
90
100
Top1-accuracy
PACS
=1
=2
=4
Figure 4: Hyper-parameters exploring experiments on Cifar-
100(left) and PACS(right), both using ViT-B with Adam.
OLOR
(Acc: 94.38%)
Full
(Acc: 87.79%)
L2-SP
(Acc: 87.74%)
VPT
(Acc: 77.44%)
Linear
(Acc: 71.88%)
Dog
Elephant
Giraffe
Guitar
Horse
House
Person
Figure 5: Feature visualization on PACS test set. We use fea-
tures extracted by backbone to perform t-SNE visualization,
and the Top1-accuracy are reported additionally.
as train set and D2 as valid set for 100 epochs, then fine-
tune the model using D2 as train set and D1 as valid set for
30 epochs through Full and OLOR methods, the discrepancy
between fine-tuned weight θ and pre-trained weight θ0 using
different methods are recorded. Additionally, we perform
zero-shot reviewing, rolling back full fine-tuned weights to
pre-trained weights in 50 steps. Figure 3 reports the results,
weight discrepancy is generally much smaller using OLOR,
when setting max rollback level ι1 to 0.01, rollback power γ
to 1, OLOR not only performs well in knowledge reviewing,
but also benefits for current learning. And the zero-shot re-
viewing result shows weight rollback itself is indeed a help-
ful method for just reviewing.
Hyper-Parameter Exploration.
We conduct experiments
on Cifar-100(ID) and PACS(OOD) to study the appropriate
hyper-parameters for different types of tasks. Deep layers
usually require significant updates to effectively extract fea-
tures related to the downstream task, thus we set the min
rollback level ι2 to 0 by default to simplify hyper-parameter
settings, for max rollback level ι1, we search from {0.0001,
0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1}, for weight roll-
back power γ, we search from {1, 2, 4}. Figure 4 shows the
findings. We suggest applying small power if the task target
of the fine-tuning stage is similar to the pre-training stage,
and large max rollback level if the data distribution of down-
stream task is similar to upstream task.
Datasets
ViT-Based
CNN-based
ι1
ι2
γ
ι1
ι2
γ
Cifar-100
5e-3
0
2
5e-3
0
2
SVHN
5e-3
0
2
1e-4
0
2
CUB-200
5e-2
0
2
1e-2
0
2
StanfordCars
1e-2
0
4
1e-4
0
2
Places-LT
1e-1
0
4
1e-2
0
4
IP102
1e-1
0
1
5e-3
0
1
OfficeHome
1e-2
0
1
1
0
1
PACS
1e-1
0
4
5e-2
0
4
COCO2017
-
-
-
1e-2
0
2
ADE20K
1e-4
0
1
-
-
-
Table 6: Hyper-parameter configuration of OLOR for differ-
ent downstream tasks.
Pre-trained Method
ι1
ι2
γ
Supervised
1e-2
0
2
OpenCLIP
1e-2
0
2
MAE
1e-2
0
2
Table 7: Hyper-parameter configuration of OLOR for differ-
ent pre-trained models.
Feature Visualization.
We visualized the feature distribu-
tions for all methods on PACS test set through t-SNE to eval-
uate the quality of the extracted features. Experiments are
based on ViT-B and Adam. As shown in Figure 5, compared
with previous methods, OLOR generally separates the rep-
resentation vectors of different classes much better, demon-
strating superior ability on representation.
Conclusions
In this paper, we propose a novel fine-tuning method named
OLOR to solve the challenge of knowledge forgetting in
neural networks. OLOR encompasses weight rollback and
layer-wise penalty. OLOR incorporates the weight rollback
term into the weight update term at each step, and can be im-
plemented in popular optimizers. This operation allows the
model to gradually approach the pre-trained weights while
learning the downstream task, making the weights of the up-
stream and downstream models more similar. In addition,
the layer-wise penalty employs penalty decay and the diver-
sified decay rate to adjust the weight rollback levels of layers
for adapting varying downstream tasks. Our OLOR achieves
state-of-the-art performance on extensive downstream tasks.
Validation experiments and ablation analysis demonstrate
the effectiveness of the proposed method.
Additional Implementation Details
In the Main Results section, when conducting experiments
on various downstream tasks, OLOR utilizes the hyper-
parameter configurations listed in Table 6. For experiments
involving different pre-trained models, the hyper-parameter
configurations for OLOR are listed in Table 7.
Acknowledgments
This work was supported by the Students’ Innovation and
Entrepreneurship Foundation of USTC (No.XY2023S007).
We would like to sincerely appreciate the anonymous re-
viewers for their valuable suggestions that helped us to im-
prove this paper.
References
Bao, H.; Dong, L.; Piao, S.; and Wei, F. 2021.
Beit:
Bert pre-training of image transformers.
ArXiv Preprint
arXiv:2106.08254.
Carion, N.; Massa, F.; Synnaeve, G.; Usunier, N.; Kirillov,
A.; and Zagoruyko, S. 2020. End-to-end object detection
with transformers. In European Conference on Computer
Vision, 213–229. Springer.
De Lange, M.; Aljundi, R.; Masana, M.; Parisot, S.; Jia, X.;
Leonardis, A.; Slabaugh, G.; and Tuytelaars, T. 2021. A con-
tinual learning survey: Defying forgetting in classification
tasks. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 44(7): 3366–3385.
Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and Fei-
Fei, L. 2009. ImageNet: A large-scale hierarchical image
database.
In 2009 IEEE Conference on Computer Vision
and Pattern Recognition, 248–255. Ieee.
Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn,
D.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.;
Heigold, G.; Gelly, S.; et al. 2020. An image is worth 16x16
words: Transformers for image recognition at scale. ArXiv
Preprint arXiv:2010.11929.
Fang, Y.; Sun, Q.; Wang, X.; Huang, T.; Wang, X.; and Cao,
Y. 2023. Eva-02: A visual representation for neon genesis.
ArXiv Preprint arXiv:2303.11331.
Guan, L. 2023. Weight Prediction Boosts the Convergence
of AdamW. In Pacific-Asia Conference on Knowledge Dis-
covery and Data Mining, 329–340. Springer.
He, K.; Chen, X.; Xie, S.; Li, Y.; Doll´ar, P.; and Girshick,
R. 2022. Masked autoencoders are scalable vision learners.
In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 16000–16009.
Jia, M.; Tang, L.; Chen, B.-C.; Cardie, C.; Belongie, S.;
Hariharan, B.; and Lim, S.-N. 2022.
Visual prompt tun-
ing. In European Conference on Computer Vision, 709–727.
Springer.
Keskar, N. S.; and Socher, R. 2017. Improving generaliza-
tion performance by switching from adam to sgd.
ArXiv
Preprint arXiv:1712.07628.
Kirkpatrick, J.; Pascanu, R.; Rabinowitz, N.; Veness, J.; Des-
jardins, G.; Rusu, A. A.; Milan, K.; Quan, J.; Ramalho, T.;
Grabska-Barwinska, A.; et al. 2017.
Overcoming catas-
trophic forgetting in neural networks. Proceedings of the
National Academy of Sciences, 114(13): 3521–3526.
Krause, J.; Stark, M.; Deng, J.; and Fei-Fei, L. 2013. 3D ob-
ject representations for fine-grained categorization. In Pro-
ceedings of the IEEE International Conference on Computer
Vision Workshops, 554–561.
Krizhevsky, A.; Hinton, G.; et al. 2009. Learning multiple
layers of features from tiny images.
Kumar, A.; Shen, R.; Bubeck, S.; and Gunasekar, S. 2022.
How to fine-tune vision models with sgd. ArXiv Preprint
arXiv:2211.09359.
Li, D.; Yang, Y.; Song, Y.-Z.; and Hospedales, T. M. 2017.
Deeper, broader and artier domain generalization. In Pro-
ceedings of the IEEE International Conference on Computer
Vision, 5542–5550.
Li, Y.; Zhang, K.; Liang, J.; Cao, J.; Liu, C.; Gong, R.;
Zhang, Y.; Tang, H.; Liu, Y.; Demandolx, D.; et al. 2023.
Lsdir: A large scale dataset for image restoration. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, 1775–1787.
Lin, T.-Y.; Doll´ar, P.; Girshick, R.; He, K.; Hariharan, B.;
and Belongie, S. 2017. Feature pyramid networks for ob-
ject detection. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, 2117–2125.
Liu, X.; Wu, C.; Menta, M.; Herranz, L.; Raducanu, B.; Bag-
danov, A. D.; Jui, S.; and de Weijer, J. v. 2020. Generative
feature replay for class-incremental learning. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition Workshops, 226–227.
Liu, Z.; Mao, H.; Wu, C.-Y.; Feichtenhofer, C.; Darrell, T.;
and Xie, S. 2022. A convnet for the 2020s. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 11976–11986.
Loshchilov, I.; and Hutter, F. 2017. Decoupled weight decay
regularization. ArXiv Preprint arXiv:1711.05101.
Merlin, G.; Lomonaco, V.; Cossu, A.; Carta, A.; and Bac-
ciu, D. 2022. Practical recommendations for replay-based
continual learning methods. In International Conference on
Image Analysis and Processing, 548–559. Springer.
Mosbach, M.; Andriushchenko, M.; and Klakow, D.
2020.
On the stability of fine-tuning bert: Misconcep-
tions, explanations, and strong baselines.
ArXiv Preprint
arXiv:2006.04884.
Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; and
Ng, A. Y. 2011. Reading digits in natural images with unsu-
pervised feature learning.
Patterson, G.; Xu, C.; Su, H.; and Hays, J. 2014. The sun
attribute database: Beyond categories for deeper scene un-
derstanding. International Journal of Computer Vision, 108:
59–81.
Peng, Z.; Dong, L.; Bao, H.; Ye, Q.; and Wei, F. 2022. Beit
v2: Masked image modeling with vector-quantized visual
tokenizers. ArXiv Preprint arXiv:2208.06366.
Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;
Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;
et al. 2021. Learning transferable visual models from nat-
ural language supervision. In International Conference on
Machine Learning, 8748–8763. PMLR.
Rebuffi, S.-A.; Kolesnikov, A.; Sperl, G.; and Lampert, C. H.
2017. icarl: Incremental classifier and representation learn-
ing. In Proceedings of the IEEE conference on Computer
Vision and Pattern Recognition, 2001–2010.
Rolnick, D.; Ahuja, A.; Schwarz, J.; Lillicrap, T.; and
Wayne, G. 2019. Experience replay for continual learning.
Advances in Neural Information Processing Systems, 32.
Russakovsky, O.; Deng, J.; Su, H.; Krause, J.; Satheesh, S.;
Ma, S.; Huang, Z.; Karpathy, A.; Khosla, A.; Bernstein, M.;
et al. 2015. ImageNet large scale visual recognition chal-
lenge. International Journal of Computer Vision, 115: 211–
252.
Schuhmann, C.; Beaumont, R.; Vencu, R.; Gordon, C.;
Wightman, R.; Cherti, M.; Coombes, T.; Katta, A.; Mullis,
C.; Wortsman, M.; et al. 2022. Laion-5B: An open large-
scale dataset for training next generation image-text models.
ArXiv Preprint arXiv:2210.08402.
Schuhmann, C.; Vencu, R.; Beaumont, R.; Kaczmarczyk,
R.; Mullis, C.; Katta, A.; Coombes, T.; Jitsev, J.; and
Komatsuzaki, A. 2021.
Laion-400M: Open dataset of
clip-filtered 400 million image-text pairs.
ArXiv Preprint
arXiv:2111.02114.
Shen, Z.; Liu, Z.; Qin, J.; Savvides, M.; and Cheng, K.-T.
2021. Partial is better than all: revisiting fine-tuning strategy
for few-shot learning. In Proceedings of the AAAI Confer-
ence on Artificial Intelligence, volume 35, 9594–9602.
Sohn, K.; Chang, H.; Lezama, J.; Polania, L.; Zhang, H.;
Hao, Y.; Essa, I.; and Jiang, L. 2023. Visual prompt tun-
ing for generative transfer learning.
In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 19840–19851.
Toneva, M.; Sordoni, A.; Combes, R. T. d.; Trischler, A.;
Bengio, Y.; and Gordon, G. J. 2018.
An empirical study
of example forgetting during deep neural network learning.
ArXiv Preprint ArXiv:1812.05159.
Vander Eeckt, S.; and Van Hamme, H. 2023. Using adapters
to overcome catastrophic forgetting in end-to-end automatic
speech recognition. In ICASSP 2023-2023 IEEE Interna-
tional Conference on Acoustics, Speech and Signal Process-
ing (ICASSP), 1–5. IEEE.
Venkateswara, H.; Eusebio, J.; Chakraborty, S.; and Pan-
chanathan, S. 2017. Deep hashing network for unsupervised
domain adaptation. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, 5018–5027.
Wah, C.; Branson, S.; Welinder, P.; Perona, P.; and Belongie,
S. 2011. The caltech-ucsd birds-200-2011 dataset.
Wang, R.; Zheng, H.; Duan, X.; Liu, J.; Lu, Y.; Wang, T.;
Xu, S.; and Zhang, B. 2023. Few-Shot Learning with Vi-
sual Distribution Calibration and Cross-Modal Distribution
Alignment. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 23445–23454.
Wu, W.; Sun, Z.; and Ouyang, W. 2023. Revisiting classifier:
Transferring vision-language models for video recognition.
In Proceedings of the AAAI Conference on Artificial Intelli-
gence, volume 37, 2847–2855.
Xuhong, L.; Grandvalet, Y.; and Davoine, F. 2018. Explicit
inductive bias for transfer learning with convolutional net-
works. In International Conference on Machine Learning,
2825–2834. PMLR.
Zhang, R.; Isola, P.; and Efros, A. A. 2017. Split-brain au-
toencoders: Unsupervised learning by cross-channel predic-
tion. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, 1058–1067.
Zhou, B.; Lapedriza, A.; Xiao, J.; Torralba, A.; and Oliva,
A. 2014. Learning deep features for scene recognition using
places database. Advances in Neural Information Processing
Systems, 27.
"
"We aim to learn about the political interests and preferences of Members of Parliament (MPs) by mining their parliamentary activity to develop a personalized recommendation system for distributing documents.Given a stream of documents, it is able to select those most likely to be relevant for a particular MP. We propose using positive unlabeled learning since we only have information about relevant documents (interventions made by each MP in debates) but not about irrelevant documents. Furthermore, we developed a new algorithm of this type, which outperforms: a) assuming that the interventions of other MPs are irrelevant; b) another well-known positive unlabeled learning method; and c) an information retrieval-based approach that matches documents and legislators' representations.nan","Today's information society allows for easy access to vast amounts of information, sometimes even without actively searching for it. Advertisements, news, e-mails, etc. constantly bombard users. The challenge lies in separating the valuable from the useless information, a task often time-consuming. Content-based recommender systems aim to reduce this information overload by suggesting items (movies, songs, books, restaurants, etc.) to users based on their preferences and the characteristics of the items. Politicians also face this dilemma. Members of Parliament (MPs) must stay informed about matters related to their specific interests, such as health, education, or agriculture, while avoiding irrelevant information. Our goal is to develop a system that can automatically decide which documents should be sent to each MP based on both the document's content and the MP's political interests.nan","nanPrevious approaches to tackle this problem have used information retrieval-based methods, which rely on extracting term profiles from MPs' speeches. Our approach, in contrast, is based on machine learning techniques, specifically positive unlabeled learning (PUL), which assumes a set of positive data and a (usually larger) set of unlabeled data without negative examples. We propose a new PUL method based on modifying the K-means clustering algorithm. Related works have used a two-step strategy, where the first step tries to identify reliable negative data from the unlabeled set, and the second step uses a traditional supervised learning algorithm on the positive and reliable negative data.nan","We formalize the situation as follows: let MP = {MP1, . . . , MPn} be the set of MPs working in a parliament, which receives documents that should be distributed among them. Not all MPs should receive all documents to alleviate their workload, only those related to their interests, preferences, and role within the parliament. A system is required to perform this filtering process automatically. We propose to build such a system using PUL, using a modification of the K-means clustering algorithm to identify reliable negative documents from the interventions of other MPs for each MPi. For each MPi, we train a binary classifier from Di and Ni using Support Vector Machines (SVMs), which is considered the state-of-the-art technique for document classification. We also consider using a method to deal with the class imbalance problem.nan","Experiments using data from the Andalusian Parliament in Spain show that our approach outperforms the baseline (assuming all interventions of other MPs are irrelevant) and another well-known PUL method in terms of precision, recall, and F-measure. Our method also outperforms information retrieval-based approaches.nan","Our proposed approach, pul-km, is a valuable tool for tackling the problem of building a content-based recommender system of documents in a parliamentary setting. It outperforms existing approaches, including information retrieval-based methods. Future research directions include exploring strategies for selective balancing, studying methods to select different thresholds for different classifiers, and investigating the use of feature selection methods.nan",Positive unlabeled learning for building recommender systems in a parliamentary setting,"Luis M. de Camposa, Juan M. Fernández-Luna, Juan F. Huete, Luis Redondo-Expósito","Positive unlabeled learning for building recommender
systems in a parliamentary setting
Luis M. de Camposa,∗, Juan M. Fern´andez-Lunaa, Juan F. Huetea, Luis
Redondo-Exp´ositoa
aDepartamento de Ciencias de la Computaci´on e Inteligencia Artificial,
ETSI Inform´atica y de Telecomunicaci´on, CITIC-UGR,
Universidad de Granada, 18071, Granada, Spain
Abstract
Our goal is to learn about the political interests and preferences of the Mem-
bers of Parliament by mining their parliamentary activity, in order to develop a
recommendation/filtering system that, given a stream of documents to be dis-
tributed among them, is able to decide which documents should receive each
Member of Parliament. We propose to use positive unlabeled learning to tackle
this problem, because we only have information about relevant documents (the
own interventions of each Member of Parliament in the debates) but not about
irrelevant documents, so that we cannot use standard binary classifiers trained
with positive and negative examples. We have also developed a new algorithm
of this type, which compares favourably with: a) the baseline approach assum-
ing that all the interventions of other Members of Parliament are irrelevant,
b) another well-known positive unlabeled learning method and c) an approach
based on information retrieval methods that matches documents and legisla-
tors’ representations. The experiments have been carried out with data from
the regional Andalusian Parliament at Spain.
Keywords:
positive unlabeled learning, content-based recommender systems,
parliamentary documents, k-means, support vector machines
1. Introduction
Nowadays we live in the information society, where enterprises, institutions
and people in general can easily access to vast amounts of information. More-
over, in many cases users do not need to actively search for the information
they need but they play a more passive role and are constantly bombarded with
advertising, news, e-mails, etc. The problem is then to separate the chaff from
∗Corresponding author
Email addresses: lci@decsai.ugr.es (Luis M. de Campos), jmfluna@decsai.ugr.es
(Juan M. Fern´andez-Luna), jhg@decsai.ugr.es (Juan F. Huete), luisre@decsai.ugr.es
(Luis Redondo-Exp´osito)
Preprint submitted to Elsevier
January 23, 2024
arXiv:2401.10961v1  [cs.IR]  19 Jan 2024
the wheat, to distinguish what is interesting, important or useful and what is
not. This is a hard and time-consuming task. To reduce the information over-
load, there exist content-based recommender/filtering systems [2, 33], which
suggest items (songs, movies, books, restaurants,...) to users according to their
preferences and taking into account the characteristics of the items.
This situation also happens in a political context. Politicians in general and
Members of Parliament (MP) in particular need to keep informed about the
matters more related with their specific political interests. For example, an MP
who is working in the health committee of a regional or national parliament
probably would be interested in documents produced by the European Union
dealing with health-related matters but not in others concerning, let us say,
education or agriculture. In our case the users will be the MPs and the items
to be recommended/filtered are the documents arriving to the parliament (e.g.
news releases or technical reports).
The goal is to develop a system which
can automatically decide those MPs who should receive each document. This
decision must be based on both the content of the document and the political
interests of each MP.
One possible approach to develop our recommendation/filtering system could
be to learn about the interests and preferences of each MP by mining her par-
liamentary activity. So, we could use the transcriptions of the speeches of the
MPs in the parliamentary debates to train a binary classifier (the class values
being relevant and non-relevant) for each MP. Then, when a new document to
be filtered/recommended enters the system, we could use these classifiers to de-
termine which MPs should receive the document: those MPs whose associated
classifier predicts the relevant class. Alternatively, if we assume that the clas-
sifiers produce a numerical output instead of a binary value, we could generate
a ranking of MPs in decreasing order, thus recommending the document to the
top ranked MPs.
The problem with this approach is that in order to build a standard binary
classifier for each MP we need training data (documents in this case), both
positive (relevant documents) and negative (irrelevant documents).
Positive
training data do not represent any problem: the own interventions/speeches
of an MP are clearly positive training data for building the classifier for this
MP. However, negative training data are not so clear. We could suppose that
all the interventions which are not from an MP are negative training data for
the classifier associated to this MP. But this may be somewhat unreasonable,
because the interventions of other MPs dealing with the topics which are of
interest for a given MP could also be relevant for this MP, thus creating confusion
in the classifier.
For example, if a given MP is interested or especialized in
education, it is quite probable that she will find relevant (at least some of) the
interventions of other MPs about this topic. Therefore, within the interventions
of other MPs we will probably find both relevant and irrelevant documents for
a given MP.
This situation can be managed using the techniques known as Positive Un-
labeled Learning (PUL) [41], where it is assumed that there exists a set of
positive data and a (usually larger) set of unlabeled data, but there is no neg-
2
ative training data. In our case the unlabeled data would correspond with the
interventions of all the other MPs. PUL is an extreme case of semisupervised
learning [6] (which considers simultaneously positive, negative and unlabeled
data).
So, our proposal in this paper is to explore the use of positive unlabeled
learning to build a content-based recommender system of documents for the
MPs. More precisely, our approach is first based on trying to detect, among the
unlabeled data, a subset of reliable negative data, and second to use the known
positive data and the reliable negative data to train a standard binary classifier
for each MP. To detect reliable negative data we can use some of the known
PUL methods, although we propose a new method based on constraining the
operations of the K-means clustering algorithm.
In order to validate our proposals, we shall perform an experimental study
using a collection of MPs interventions from the regional Parliament of Andalu-
sia at Spain.
The main contributions of this paper are: (a) the proposal of using machine
learning techniques to tackle the problem of building a content-based recom-
mender system of documents in a parliamentary setting (there are other pro-
posals to deal with this problem [10, 34, 11], but all using information retrieval-
based methods instead of machine learning techniques); (b) the use of positive
unlabeled learning to build a recommender system (we are not aware of any
work in this sense, although there are many papers applying positive unlabeled
learning to the problem of classifying documents [13, 16, 24, 26, 27, 39]); (c) the
proposal of a new method of positive unlabeled learning based on a modification
of the K-means clustering algorithm.
The rest of the paper is organized in the following way: in Section 2 we
summarize related work. Section 3 describes in detail our approach. Section
4 contains the experimental part of the paper. Finally, Section 5 contains the
concluding remarks and some proposals for future work.
2. Related work
There are many works studying the recommendation/filtering problem in
different domains and applications (as the three survey papers [18, 4, 29] show).
Content-based recommender systems can be built using either information retrieval-
based methods [1, 2, 15, 28, 31] or machine learning algorithms for learning user
models [3, 8, 20, 21, 32, 37, 40]. However, its application in a parliamentary
context is much more limited [10, 34, 11], and in all these cases only information
retrieval-based methods have been used.
In [10] a lazy approach is considered, avoiding to construct an elaborated
profile of the MPs, collecting the transcriptions of all their speeches and building
a document collection, then using an information retrieval system to search the
MPs most similar to the document to be recommended. This approach is refined
in [11], where term (word) profiles for the different MPs are extracted from their
speeches in different ways. A different approach is considered in [34], where the
3
profiles of the MPs are not built from the terms in their interventions but from
the keywords manually assigned by documentalists (using a thesaurus) to these
interventions.
On the other hand, there are three classes of methods proposed for positive
unlabeled learning, according to [41]. The first class uses a two-step strategy,
where the first step tries to identify a set of reliable negative data from the un-
labeled set, and the second step uses a traditional supervised learning algorithm
on the positive and the reliable negative data [24, 26, 27, 39]. The second class
follows the statistical query learning model. For example, in [13] a modification
of the Naive Bayes (NB) for text classification is obtained by estimating the
conditional probabilities of the terms given the positive class in the usual way
and the conditional probabilities given the negative class by using a supplied
estimate of the prior probability of the positive class.
In [5] other Bayesian
network classifiers are also extended to the PUL setting. The third class of
methods treats the unlabeled data as noisy negative examples, using then lo-
gistic regression [23] or the Biased Support Vector Machine [27], for example.
PUL is also being used in the case of data streams [25], and it is still an active
area of research [14, 17, 19].
We are going to focus on the methods of the first class, which are more
extended and are more similar to the new PUL method that we propose. In
[27] the authors use the NB classifier, where positive data are used as posi-
tive training examples and unlabeled data as negative training examples. The
resulting NB classifier is used to re-classify the unlabeled data, thus selecting
as reliable negative data those unlabeled examples which have been classified
as negative by NB. A similar approach is used in [24], where NB is replaced
by the Rocchio text classification method (using tf-idf weights and the cosine
similarity). Another proposal is the Spy technique [26], which randomly selects
a subset of positive data to be added to the unlabeled data. Then the Expec-
tation Maximization (EM) algorithm is applied to train a NB classifier, which
is used on the selected positive data to obtain a threshold able to identify reli-
able negative examples. The PEBL method [39] tries to identify those features
(terms in this case), called positive features, which are more frequent (in relative
terms) between positive documents than between unlabeled documents. Then
those documents which do not contain any of these positive features are selected
as reliable negative examples. There are also proposals (e.g. [16]) that try to
obtain from the unlabeled data both reliable positive and negative data.
3. Positive unlabeled learning in a parliamentary setting
The situation that we are considering can be formalized as follows:
let
MP = {MP1, . . . , MPn} be a set containing all the MPs working in a parlia-
ment. This institution receives or generates a series of documents that should
be distributed among the MPs. However, to alleviate their work, not all the
MPs should receive all the documents [36]. Instead, each MP should receive
only those documents which are related to her interests, preferences and the
4
role she plays within the parliament. Therefore, a system able to automati-
cally perform this filtering process is required. As mentioned in Section 1, we
want to build such a system by using machine learning techniques, more pre-
cisely positive unlabeled learning. The (public and, we expect, reliable) source
of information about the political interests of MPs will be their interventions
within the parliamentary debates. So, each MPi can be associated with a set of
documents Di = {di1, . . . , dimi}, where each dij represents the transcription of
the speech of MPi when she participated in the discussion of a parliamentary
initiative. The complete set of documents is D = ∪n
j=1Dj. Therefore, we are
going to train a set of n binary text classifiers using D. For each MPi, the set
of positive examples (documents) is precisely Di, whereas the set of unlabeled
documents is D \ Di.
Our proposal for using PUL to build a recommender/filtering system of
documents for MPs falls within the two-step strategy mentioned in Section 2.
We shall use a modification of the K-means clustering algorithm in the first
step, in order to identify a set of reliable negative documents, Ni, from the set
of unlabeled documents for each MPi (i.e. the interventions of other MPs).
In the second step, for each MPi we will train a binary classifier from Di
and Ni using Support Vector Machines [9], which is considered as the state-of-
the-art technique for document classification. As it is quite probable that the
sets Ni are quite larger than the corresponding Di, i.e. the data sets can be
quite imbalanced, we have also considered the possibility of using some method
to deal with the class imbalance problem.
3.1. The modified K-means algorithm
The classical K-means algorithm is an iterative method that, starting from
an initial centroid for each of the K clusters, assigns each example to the cluster
whose centroid is nearer (more similar) to the example. Then the algorithm
recomputes the centroid of each cluster using all the examples assigned to it.
The new centroids are used to reassign each example to the (possibly different)
cluster whose centroid is more similar to the example, and this process is re-
peated until a convergence condition holds. In our case the number of clusters
is fixed to K=2 and the similarity between documents is computed using the
classical cosine similarity measure [1]. The proposed modification is that the
known positive examples are forced to always remain in the positive cluster, no
matter if they are more similar to the negative centroid, whereas the unlabeled
examples can fluctuate between the two clusters depending on the similarity.
To initialize the process, the positive centroid is computed from all the positive
examples and the negative centroid is calculated from all the unlabeled exam-
ples. At the end of the process, the unlabeled examples which remain in the
negative cluster are considered reliable negative examples.
5
4. Experimental evaluation
To experimentally evaluate our proposals, we shall use data from the An-
dalusian Parliament at Spain1. More precisely, we focus on the 8th term of
office of this regional chamber, where a total of 5,258 parliamentary initiatives
were discussed.
Each initiative, marked up in XML [12], includes the transcriptions of all
the speeches of the MPs who participate in the discussion, together with their
names. There is a total of 12,633 different interventions (with an average of 2.4
interventions per initiative). Our set MP is composed of 132 MPs2.
We randomly partitioned the set of initiatives into a training set (containing
80% of the initiatives) and a test set (containing the remaining 20%). To obtain
more statistically reliable results, we repeated this process 5 times, and the
reported results are the averages of these rounds. In other words, we used the
repeated holdout method [22] as evaluation methodology.
We extracted the interventions of all the MPs in MP from the initiatives in
the training set and used them to build a classifier for each MP, according to the
method described in Section 3. These classifiers were then used to classify the
initiatives in the test set, using the transcriptions of the speeches within each
test initiative as the document to be filtered/recommended, assuming that each
test initiative is relevant only for those MPs who participate in it. It is worth to
mention that this is a very conservative assumption, because an initiative could
also be relevant to other MPs who did not participate in its discussion but are
interested in the same topics the initiative is devoted to. Our assumption is
an easy way to establish a kind of “ground truth”, without the need to have
documents annotated with explicit relevance judgements.
In order to assess the quality of the filtering/recommendation system we
used classical evaluation measures of text classification, namely precision, re-
call and the F-measure [35]. Let TPi (True Positives) be the number of test
initiatives which are truly relevant for MPi and have been classified as relevant
by the classifier associated to MPi; FPi (False Positives) is the number of test
initiatives which are not relevant for MPi but have been incorrectly identified
as relevant by the corresponding classifier; FNi (False Negatives) is the number
of test initiatives that, although being relevant for MPi, have been incorrectly
classified as irrelevant. Precision is then defined as pi = TPi/(TPi + FPi) (an
estimation of the probability of a document being truly relevant given that it is
classified as relevant. Recall is defined as ri = TPi/(TPi + FNi) (an estimation
of the probability of classifying as relevant a truly relevant document). The
F-measure is the harmonic mean of precision and recall, Fi = 2piri/(pi + ri).
As we compute precision, recall and F for every MPi, it is necessary to
summarize each of these three types of measures into a single value which gives a
global perspective of the system’s performance. To this end we used both macro-
1http://www.parlamentodeandalucia.es
2We considered only those MPs who intervene in at least 10 initiatives.
6
averaged (Mp, Mr and MF) and micro-averaged (mp, mr and mF) measures [38]:
Mp = 1
n
n
X
i=1
pi,
Mr = 1
n
n
X
i=1
ri,
MF = 1
n
n
X
i=1
Fi
(1)
mp =
Pn
i=1 TPi
Pn
i=1(TPi + FPi), mr =
Pn
i=1 TPi
Pn
i=1(TPi + FNi), mF = 2mp mr
mp + mr
(2)
The baseline approach (bas) we have considered is to train the classifiers
without using PUL, i.e.
for each MPi the set of positive examples is again
Di, whereas all the unlabeled examples in D \ Di are considered as negative
examples.
We shall also use, for comparison purposes, the well-known PUL
method proposed in [27] (and described in Section 2), based on Naive Bayes
(pul-nb). Once the reliable negative examples are identified by this method,
SVMs are also used to build the classifiers. The method based on using the
modification of K-means, proposed in Section 3 as the first step of PUL will be
called pul-km. The comparison of bas and pul-km will serve to assess the merits
of PUL in our recommendation context. The comparison of pul-km and pul-nb
will give us an idea of the potential of the new PUL method proposed in this
paper.
As mentioned in Section 3, we shall also experiment with versions of bas, pul-
nb and pul-km (called bas-b, pul-nb-b and pul-km-b respectively) where, previous
to applying SVMs to the sets of positive and (reliable) negative examples, we
use a method to deal with the imbalance of these data sets. More precisely, we
have used the synthetic minority over-sampling technique (SMOTE) [7], which
essentially is a statistical algorithm for creating new instances, from existing
cases of the minority class. SMOTE works by taking samples of the class with
less observations and its k nearest neighbors randomly. Then it produces new
observations setting a random point along the segment generated between the
target sample and its k neighbors. We used the implementations of SVM, NB
and SMOTE available in R3 (packages caret, e1071 and DMwR). All the prepro-
cessing steps of the datasets (all the initiatives were preprocessed by removing
stop words and performing stemming) were also carried out with R packages (tm
and snowBallC). The modified K-means algorithm and the evaluation process
were implemented in Java.
The version used of the selected classification algorithm (SVM) is able to
give a numerical output, more precisely it returns the probability of the target
document d being relevant to MPi, pri(d).
Thus, we can use it by simply
assigning the relevant value to d if pri(d) ≥ 1−pri(d) (i.e. if pri(d) ≥ 0.5). But,
more generally, we can also select a threshold t (0 ≤ t ≤ 1) and state that d is
relevant for MPi if pri(d) ≥ t. In this sense the values of TPi, FPi and FNi
used to compute precision and recall are obtained according to the contingency
3https://cran.r-project.org
7
table displayed in Table 1. We have experimented with several values for the
threshold t, ranging from 0.1 to 0.9.
Truly relevant
Truly irrelevant
for MPi
for MPi
pri(d) ≥ t
TPi
FPi
pri(d) < t
FNi
Table 1: Contingency table for threshold t.
4.1. Results with imbalanced data sets
The results of our experiments for (micro and macro) precision, recall and
F using different thresholds are displayed in Figures 1 to 3, respectively.
First, the results in Figures 1 and 2 allow us to extract some general ten-
dencies for the three approaches: precision increases and recall decreases as the
threshold increases. This is to be expected. When the threshold increases the
classifiers are more selective to assign the relevant value to a document. The
consequence is that the number of false positives decreases, thus increasing pre-
cision. At the same time, the number of false negatives increases and therefore
recall decreases. The exception is the behaviour of macro precision with the
bas approach: this measure tends to decrease when increasing the threshold.
We believe that this reveals a poor performance of this approach in those cases
where the classifiers are trained with very few positive examples, i.e. for those
MPs that scarcely intervene in the debates (then having a heavily imbalanced
training set). In these cases, although the number of false positives decreases as
the threshold increases, the number of true positives also decreases more quickly.
Notice that this only affects macro precision and not micro precision, because
in the first case all the MPs contribute equally to this measure, independently
on their number of interventions.
These figures also show that the baseline approach and the two PUL meth-
ods behave differently: the bas approach is much better for precision and the
PUL methods are much better for recall. Given the characteristics of our evalu-
ation method, we believe that we should give more importance to recall than to
precision. The reason is that false negatives (which affect recall) represent true
errors, an MP participated in an initiative but the classifier does not recom-
mend this to her. On the other hand, a false positive (which affects precision)
represents that an MP did not participate in an initiative but the classifier rec-
ommends this to her. It could be the case that this MP is truly interested in
this initiative because its content matches with her political interests. In this
way, low recall is an objective signal of bad performance, whereas low precision
does not necessarily means the same, it may be a by-product of our conservative
assumption concerning relevance.
In Figure 3 we can observe the results for the F-measure (micro and macro),
which represents a balance between precision and recall, and therefore is an ap-
propriate measure of global performance. First, we can see that the best results
8
Figure 1: Micro and Macro precision for bas, pul-km and pul-nb using different thresholds.
are always obtained when we use low thresholds. Second, pul-km systematically
outperforms both bas and pul-nb.
Table 2 shows the best F values obtained by each approach, as well as the
corresponding thresholds where these values are reached. We have used paired
t-tests (using the results of the five random partitions, and a confidence level
of 95%) to assess the statistical significance of these results. pul-km is always
significantly better than both bas and pul-nb. At micro level bas is also signif-
icantly better than pul-nb, whereas there is not significant difference between
these two approaches at macro level.
4.2. Results with balanced data sets
Now, we are going to repeat the experiments of the previous section but
using the balanced versions of the three approaches, bas-b, pul-km-b and pul-nb-
9
Figure 2: Micro and Macro recall for bas, pul-km and pul-nb using different thresholds.
b. For the sake of conciseness, we only show the results relative to the F-measure
in Figure 4. The figures for precision and recall exhibit a behaviour similar to
those in the previous section, increasing lines for precision and decreasing lines
for recall, although the lines are closer. Also, the previous extrange behaviour
of macro precision with the bas approach has dissappeared.
In Figure 4 we can observe several interesting facts. First, the thresholds
where the best results are obtained have changed completely, now they are more
centered, near the point 0.5 which could be considered as the natural threshold.
This seems to indicate that the classifiers are better calibrated, they do not
need to draw on very low thresholds to get good results. Second, pul-km-b is
still the best approach, although the differences with bas-b are smaller than in
the previous experiments. Third, balancing pul-nb is not a good idea, it obtains
results considerably worse than pul-km-b and bas-b. Table 3 is the counterpart
10
Figure 3: Micro and Macro F measures for bas, pul-km and pul-nb using different thresholds.
of Table 2 for the balanced case. Comparing Figures 4 and 3 and Tables 3 and 2
we can see that balancing the data sets improves macro F (except for pul-nb-b)
but systematically deteriorates the best values of micro F. We believe that this
behaviour is caused because balancing improves the classifiers associated to MPs
having a low number of interventions, but may worsen those MPs with a greater
number of interventions (which are those more influencing in the value of micro
F). The t-tests in this case indicate that there are not significant differences
between pul-km-b and bas-b, but both pul-km-b and bas-b are significantly better
than pul-nb-b.
11
Approach
bas
pul-km
pul-nb
Micro-F
Value
0.2978
0.3105
0.2802
Threshold
0.1
0.1
0.3
Macro-F
Value
0.2475
0.2644
0.2454
Threshold
0.1
0.1
0.2
Table 2: Best micro and macro F values obtained by bas, pul-km and pul-nb.
Approach
bas-b
pul-km-b
pul-nb-b
Micro-F
Value
0.2940
0.3012
0.2643
Threshold
0.4
0.6
0.6
Macro-F
Value
0.2732
0.2751
0.2364
Threshold
0.4
0.6
0.5
Table 3: Best micro and macro F values obtained by bas-b, pul-km-b and pul-nb-b.
4.3. Results when increasing the number of initiatives where MPs must inter-
vene
In all the previous experiments, we have built classifiers for all the MPs who
participate in at least 10 initiatives. This constitutes a very heterogeneous set
of MPs: there are MPs which participate in hundreds of initiatives and other,
more passive, that scarcely intervene in the debates. Our goal in this section
is to evaluate the proposed approaches when we impose a greater limit to the
number of initiatives where MPs must intervene in order to be included in the
study.
Therefore, we have repeated the experiments but including only those MPs
who participate in at least 25, 75, and 150 initiatives. Our hypothesis is that
the results in these cases will be progressively better, because a greater number
of interventions will exclude those MPs whose classifiers are less accurate due
to the use of poor training sets.
Table 4 displays the best F values for the
three approaches (in both the imbalanced and balanced cases). We also show in
Figure 5, the micro and macro F measures obtained by pul-km using different
thresholds4.
We can see in Table 4 that indeed the results with all the approaches sys-
tematically improve as the number of interventions required increases (this fact
is also confirmed in Figure 5). We can also observe that the relative merits
4We do not show the corresponding figures for the other approaches to save space, but the
trends are completely similar.
12
Figure 4: Micro and Macro F measures for bas-b, pul-km-b and pul-nb-b using different thresh-
olds.
of each approach remain unmodified: pul-km is the best approach followed by
bas, being pul-nb the worst. It is also apparent that balancing the data sets is
always counterproductive for the micro F measure. Moreover, when the MPs
being considered have a great number of interventions (75 and 150) balancing
is not useful either for the macro F measure.
4.4. Comparison with information retrieval-based approaches
In this section we are going to compare our proposed approach, pul-km, with
two of the information retrieval-based approaches mentioned in Section 2 [10].
13
Approach
bas
bas-b
pul-km
pul-km-b
pul-nb
pul-nb-b
Micro-F
mF10
0.2978
0.2940
0.3105
0.3012
0.2802
0.2643
mF25
0.3037
0.3038
0.3175
0.3084
0.2859
0.2705
mF75
0.3558
0.3597
0.3768
0.3647
0.3437
0.3072
mF150
0.4408
0.3987
0.4446
0.4171
0.4183
0.3584
Macro-F
MF10
0.2475
0.2732
0.2644
0.2751
0.2454
0.2364
MF25
0.2658
0.2920
0.2863
0.2941
0.2630
0.2511
MF75
0.3355
0.3563
0.3694
0.3629
0.3361
0.2887
MF150
0.4039
0.3761
0.4236
0.3984
0.3976
0.3407
Table 4: Best micro and macro F values obtained by bas, bas-b, pul-km, pul-km-b, pul-nb and
pul-nb-b with different minimum number of interventions.
They use the documents in D to feed an Information Retrieval System (IRS)5.
In both cases the document to be filtered/recommended is used as a query to
the IRS, which returns a ranked list of the MPs which are more similar to it.
In one case the documents to be indexed by the IRS are all the interventions
of all the MPs in the training set, i.e. just the documents in D. We call this
approach ir-i. In the other case we first build a kind of profile for each MP, by
grouping together all her interventions in a single document (all the documents
in Di form a single document di = ∪mi
j=1dij). Then these “macro” documents are
indexed by the IRS. We call this second approach ir-p. In both cases, as each
document is unambiguously associated with an MP, we can replace the ranking
of documents by a ranking of MPs. However, in the ir-i approach the ranking
of MPs may contain duplicate MPs having different scores (which correspond
to different interventions of the same MP). Therefore, in this case we remove
all the occurrences of an MP except the one having the maximum score.
Notice that the scores returned by the IRS are affected by the number of
terms in the query. As we are using a single threshold to recommend a document
to those MPs whose score is greater than the threshold, we need to normalize
the scores by dividing by the maximum score. In this way we make the range
of the scores independent on the query.
Table 5 displays the best F values for the the two IR-based approaches (we
repeat in the table the results for pul-km to ease the comparison).
It is evident that pul-km clearly outperforms the IR-based approaches. In
fact, the t-tests indicate statistically significant differences between pul-km and
both ir-i and ir-p in all the cases (except in two cases of macro F, one with ir-i
and size 150, and the other with ir-p and size 25).
Although we are not going to display all the figures showing how ir-i and ir-p
5In our experiments we have used the implementation in the search engine library Lucene
(https://lucene.apache.org) of the BM25 information retrieval model.
14
Figure 5: Micro and Macro F measures for pul-km using different thresholds, for a minimum
of 10, 25, 75 and 150 interventions.
vary depending on the thresholds being used, we include in Figure 6 the micro
and macro F values for ir-i (the figures for ir-p are completely similar) in order
to illustrate a clear difference in the behaviour of the IR-based approaches with
respect to pul-km. We can see how the F measures for ir-i increase as the thresh-
old increases, just the opposite of what it happens with pul-km. Thus pul-km
works better with low or medium thresholds but ir-i requires large thresholds.
The reason may be in the different interpretation that these thresholds have
within each approach, probability of relevance in one case and similarity in the
other.
15
Micro-F
Macro-F
Approach
pul-km
ir-i
ir-p
pul-km
ir-i
ir-p
10
0.3105
0.2896
0.2892
0.2644
0.2423
0.2513
25
0.3175
0.2971
0.2939
0.2863
0.2661
0.2829
75
0.3768
0.3509
0.3085
0.3694
0.3288
0.3368
150
0.4446
0.4282
0.3120
0.4236
0.3948
0.3530
Table 5: Best micro and macro F values obtained by pul-km, ir-i and ir-p, with different
minimum number of interventions.
5. Concluding remarks
In this paper we have proposed an approach to build a system able to rec-
ommend/filter documents to the Members of Parliament, which is based on
machine learning techniques, more precisely automatic document classification.
The source data to train the classifiers are the interventions of the MPs in the
parliamentary debates, under the assumption that these interventions reveal
information about their political interests and preferences. However, the inter-
ventions of an MP only give information about what is relevant for her, but the
information about what is not relevant is missing. For that reason our approach
uses positive unlabeled learning methods, as we cannot rely on traditional clas-
sifiers trained with both positive and negative examples. In this context, we
have also proposed a new PUL method, pul-km, that first obtain a set of reli-
able negative examples from the set of unlabeled examples (the interventions of
the other MPs), and then uses the set of positive and reliable negative examples
to train a traditional binary classifier (SVM in our case). Our method to obtain
the set of reliable negative examples is based on a modification of the classical
K-means algorithm for clustering. We have also considered to complement this
procedure with an algorithm to deal with the possible class imbalance problem
(using SMOTE for this purpose).
In our experiments, based on a collection of MP’s interventions in the Parlia-
ment of Andalusia, we have compared pul-km with other approaches: a baseline
approach that considers that all the unlabeled examples are negative exam-
ples, another existing PUL method based on Naive Bayes, pul-nb, and other
two methods based on information retrieval that index the collection of inter-
ventions and retrieve the MPs which are more similar to the document to be
recommended. In all the experiments our approach obtains better results than
its opponents, most of the time with statistically significant differences. There-
fore, pul-km appears as a good approach to tackle this recommendation problem.
Moreover, the fact that pul-km clearly outperforms the state-of-the-art pul-nb is
also a strong evidence that it has potential to be useful in other problems where
PUL methods are necessary.
Given the results obtained with and without using the SMOTE method to
deal with imbalanced data sets, we have observed that its use deteriorates micro
F but tends to improve macro F (except in the case of pul-nb, where macro F
16
Figure 6: Micro and Macro F measures for ir-i using different thresholds, for a minimum of
10, 25, 75 and 150 interventions.
is also worsened). This probably means that using SMOTE is only advisable
for those MPs having a low number of interventions. Therefore, an interesting
future research would be to design strategies to perform “selective balancing”,
i.e. to decide which classifiers (associated to different MPs) would benefit from
using methods for balancing data sets. As this operation changes the thresholds
that the classifiers need to use to perform better (in our case moving from low
thresholds to others located near 0.5, the “natural” threshold), another inter-
esting line of research would be to study methods to select different thresholds
for different classifiers. Finally, we would also like to explore the use of fea-
ture selection methods [30] (term selection in this case) for our recommendation
problem.
17
Acknowledgement
This work has been funded by the Spanish “Ministerio de Econom´ıa y Com-
petitividad” under projects TIN2013-42741-P and TIN2016-77902-C3-2-P, and
the European Regional Development Fund (ERDF-FEDER).
References
[1] R. Baeza-Yates, B. Ribeiro-Neto, Modern Information Retrieval, Addison-
Wesley, 2011.
[2] N.J. Belkin, W.B. Croft, Information filtering and information retrieval:
two sides of the same coin?, Communications of the ACM 35 (1992) 29–38.
[3] D. Billsus, M. Pazzani, J. Chen, A learning agent for wireless news ac-
cess, in: Proceedings of the International Conference on Intelligent User
Interfaces, 2002, pp. 33–36.
[4] J. Bobadilla, A. Hernando, O. Fernando, A. Guti´errez, Recommender sys-
tems survey, Knowledge Based Systems 46 (2013) 109–132.
[5] B. Calvo, P. Larra˜naga, J.A. Lozano, Learning Bayesian classifiers from
positive and unlabeled examples, Pattern Recognition Letters 28 (2007)
2375–2384.
[6] O. Chapelle, B. Sch¨olkopf, A. Zien, Eds., Semi-Supervised Learning, MIT
Press, 2006.
[7] N.V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, Smote: syn-
thetic minority over-sampling technique, Journal of Artificial Intelligence
Research 16 (2002) 321–357.
[8] W. Cohen, Learning rules that classify e-mail, in: Papers from the AAAI
Spring Symposium on Machine Learning in Information Access, 1996, pp.
18–25.
[9] N. Cristianini, J. Shawe-Taylor, An introduction to Support Vector Ma-
chines and other kernel-based learning methods, Cambridge University
Press, 2000.
[10] L.M. de Campos J.M. Fern´andez-Luna, J.F. Huete, A lazy approach for
filtering parliamentary documents, in: A. K¨o, E. Francesconi (Eds.), Elec-
tronic Government and the Information Systems Perspective, Lecture Notes
in Computer Science 9265, 2015, pp. 364–378.
[11] L.M. de Campos, J.M. Fern´andez-Luna, J.F. Huete, Profile-based recom-
mendation: a case study in a parliamentary context, Journal of Information
Science, to appear.
18
[12] L.M. de Campos, J.M. Fern´andez-Luna, J.F. Huete, C.J. Martin-Dancausa,
C. Tur-Vigil, A. Tagua, An integrated system for managing the andalusian
parliament’s digital library, Program: Electronic Library and Information
Systems 43 (2009) 121-139.
[13] F. Denis, R. Gilleron, M. Tommasi, Text classification from positive and
unlabeled examples, in: Proceedings of the 9th International Conference
on Information Processing and Management of Uncertainty in Knowledge-
Based Systems, 2002, pp. 1927–1934.
[14] M.C. du Plessis, G. Niu, M. Sugiyama, Class-prior estimation for learning
from positive and unlabeled data, Machine Learning 106 (2017) 463–492.
[15] P. Foltz, S. Dumais, Personalized information delivery: an analysis of in-
formation filtering methods, Communications of the ACM 35 (1992) 51–60.
[16] G.P.C. Fung, J.X. Yu, H.J. Lu, P.S. Yu, Text classification without negative
examples revisit, IEEE Transactions on Knowledge and Data Engineering
18 (2006) 6–20.
[17] H. Gan, Y. Zhang, Q. Song, Bayesian belief network for positive unlabeled
learning with uncertainty, Pattern Recognition Letters 90 (2017) 28–35.
[18] U. Hanani, B. Shapira, P. Shoval, Information filtering: Overview of issues,
research and systems, User Modelling and User-Adapted Interaction 11
(2001) 203–259.
[19] J. Hern´andez-Gonz´alez, I. Inza, J.A. Lozano, Learning from proportions
of positive and unlabeled examples, International Journal of Intelligent
Systems 32 (2017) 109–133.
[20] J. Kim, B. Lee, M. Shaw, H. Chang, W. Nelson, Application of decision-tree
induction techniques to personalized advertisements on internet storefronts,
International Journal of Electronic Commerce 5 (2001) 45–62.
[21] A. Jennings, H. Higuchi, A user model neural network for a personal news
service, User Modelling and User-Adapted Interaction 3 (1993) 1–25.
[22] B. Lantz, Machine Learning with R, Packt Publishing Ltd, 2013.
[23] W.S. Lee, B. Liu, Learning with positive and unlabeled examples using
weighted logistic regression, in: Proceedings of the Twentieth International
Conference on Machine Learning, 2003, pp. 448–455.
[24] X.L. Li, B. Liu, Learning to classify texts using positive and unlabeled data,
in: Proceedings of the 18th International Joint Conference on Artificial
Intelligence, 2003, pp. 587–594.
[25] C. Liang, Y. Zhang, P. Shi, Z. Hu, Learning very fast decision tree from
uncertain data streams with positive and unlabeled samples, Information
Sciences 213 (2012) 50–67.
19
[26] B. Liu, W.S. Lee, P.S. Yu, X.L. Li, Partially supervised classification of text
documents, in: Proceedings of the Nineteenth International Conference on
Machine Learning, 2002, pp. 387–394.
[27] B. Liu, Y. Dai, X. Li, W.S. Lee, P.S. Yu, Building text classifiers using posi-
tive and unlabeled examples, in: Proceedings of the 3rd IEEE International
Conference on Data Mining, 2003, pp. 179–186.
[28] S. Loeb, Architecting personal delivery of multimedia information, Com-
munications of the ACM 35 (1992) 39–48.
[29] J. Lu, D. Wu, M. Mao, W. Wang, G. Zhang, Recommender system appli-
cation developments: a survey, Decision Support Systems 74 (2015) 12–32.
[30] S. Maldonado, R. Weber, F. Famili, Feature selection for high-dimensional
class-imbalanced data sets using Support Vector Machines, Information
Sciences 286 (2014) 228–246.
[31] F. Narducci, P. Basile, C. Musto, P. Lops, A. Caputo, M. de Gemmis,
L. Iaquinta, G. Semeraro, Concept-based item representations for a cross-
lingual content-based recommendation process, Information Sciences 374
(2016) 15–31.
[32] M. Pazzani, D. Billsus, Learning and revising user profiles: the identifica-
tion of interesting web sites, Machine Learning 27 (1997) 313–331.
[33] M. Pazzani, D. Billsus, Content-based Recommendation Systems, in: The
Adaptive Web, LCNS 4321, 2007, pp. 325–341.
[34] F.J. Ribadas, L.M. de Campos, J.M. Fern´andez-Luna, J.F. Huete, Concept
profiles for filtering parliamentary documents, in: Proceedings of the 7th
International Joint Conference on Knowledge Discovery, Knowledge Engi-
neering and Knowledge Management - Volume 1: KDIR, 2015, 409–416.
[35] F. Sebastiani, Machine learning in automated text categorization, ACM
Computing Surveys 34 (2002) 1–47.
[36] J. Shamin, C. Neuhold, ‘Connecting Europe’: The use of ‘new’ informa-
tion and communication technologies within European parliament standing
committees. The Journal of Legislative Studies 13 (2007) 388–402.
[37] A.M. Tjoa, M. Hofferer, G. Ehrentraut, P. Untersmeyer, Applying evolu-
tionary algorithms to the problem of information filtering, in: Proceedings
of the 8th International Workshop on Database and Expert Systems Ap-
plications, 1997, pp. 450–458.
[38] G. Tsoumakas, I. Katakis, I.P. Vlahavas, Mining multi-label data, in: O.
Maimon, L. Rokach (Eds.), Data Mining and Knowledge Discovery Hand-
book, Springer-Verlag, 2010, pp. 667–685.
20
[39] H. Yu, J. Han, K.C.-C. Chang, Pebl: positive example based learning for
web page classification using SVM, in: Proceedings of the eighth ACM
SIGKDD International Conference on Knowledge Discovery and Data Min-
ing, 2002, pp. 239–248.
[40] S. Zahra, M.A. Ghazanfar, A. Khalid, M.A. Azam, U. Naeem, A. Prugel-
Bennett, Novel centroid selection approaches for KMeans-clustering based
recommender systems, Information Sciences 320 (2015) 156–189.
[41] B. Zhang, W. Zuo, Learning from positive and unlabeled examples: a sur-
vey, in: International Symposiums on Information Processing, 2008, pp.
650–654.
21
"
"In this study, we examine the effectiveness of a large language model (LLM)-based support chatbot compared to a traditional keyword-based chatbot system using a randomized controlled trial. Our results indicate that the LLM-based chatbot significantly reduces escalation rates, whereby users seek assistance from a back-end engineer. The overall escalation rate decreased from 17.1% to 7.9% when using the LLM-based chatbot, representing a 53.8% reduction. Additionally, we compared two versions of the LLM-based chatbot, one powered by GPT3.5 and the other by GPT4, and found no significant difference in escalation rates between the two. However, the GPT3.5-based chatbot was more cost-efficient.nan","The study explores the impact of a large language model (LLM)-based support chatbot compared to a conventional chatbot system. Numerous studies have examined LLM tools in various settings, demonstrating their productivity-enhancing effects. However, field experiments applying LLM tools in realistic scenarios are limited. This study aims to evaluate the effectiveness of LLM-based tools in providing unmonitored support services for information retrieval.nan","nanPrior research has investigated the impact of LLM-based tools on productivity in different settings, including lab tasks, observational studies, and field experiments. The studies generally indicate that LLM-based tools can enhance user productivity significantly. However, there is a lack of field experiments applying LLM tools in realistic settings.nan","The study conducted a randomized controlled trial comparing the performance of a traditional chatbot system with that of an LLM-based chatbot. The trial involved two waves, with the first wave comparing the LLM-based chatbot with the classical bot, and the second wave introducing a GPT3.5-supported version. The primary outcome of interest was the escalation rate, defined as the user's decision to escalate the inquiry to a back-end engineer.nan","The study found that the LLM-based chatbot significantly reduced the escalation rate compared to the classical bot. The overall escalation rate decreased from 17.1% to 7.9%, representing a 53.8% reduction. Additionally, there was no significant difference in escalation rates between the GPT3.5 and GPT4-based versions of the LLM-based chatbot, though the GPT3.5 version was more cost-efficient.nan",The study provides evidence of the effectiveness of LLM-based chatbots in reducing escalation rates and improving the overall support service quality. The findings contribute to the growing literature on the productivity-enhancing effects of LLM-based tools.nan,AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment,"Sida Peng, Wojciech Swiatek, Allen Gao, Paul Cullivan, Haoge Chang","AI Revolution on Chat Bot: Evidence from a
Randomized Controlled Experiment
Sida Peng∗
Wojciech Swiatek†
Allen Gao‡
Paul Cullivan§
Haoge Chang¶
November 2023
1
Introduction
In recent years, generative AI has undergone major advancements, demonstrat-
ing significant promise in augmenting human productivity. Notably, large lan-
guage models (LLM), with ChatGPT-4 as an example, have drawn considerable
attention. Many companies are now incorporating LLM-based tools within their
organizations and integrating it with various products (OpenAI, 2023a; Forbes,
2023). There is increasing interest on evaluating the impact of LLMs on human
decision-making and productivity.
Numerous articles have examined the impact of LLM-based tools in lab set-
tings or designed tasks (Peng et al., 2023; Spatharioti et al., 2023; Noy and
Zhang, 2023; Dell’Acqua et al., 2023), or in observational studies (Brynjolfsson,
Li, and Raymond, 2023). In these investigations, LLM-based tools are deployed
∗Office of Chief Economist, Microsoft
†Microsoft
‡Microsoft
§Microsoft
¶Microsoft Research
1
arXiv:2401.10956v1  [cs.HC]  19 Jan 2024
to aid humans in various tasks, with measured outcomes including task comple-
tion time and accuracy. It is generally observed that LLM-based tools are able
to increase users’ productivity substantially.
Despite recent advances, field experiments applying LLM-based tools in real-
istic settings are limited. This paper presents the findings of a field randomized
controlled trial assessing the effectiveness of LLM-based tools in providing un-
monitored support services for information retrieval.
While superior service
quality is expected from LLM-based tools, concerns such as hallucinations raise
questions about their effectiveness. Consequently, an empirical investigation is
necessary.
We collaborated with a team managing support chat bots that support Mi-
crosoft’s internal developers. Prior to adopting GPT-based models, these bots
operated on a flowchart-based system called Power Virtual Agents (PowerVA,
see Figure 1). Users navigated through predefined categories to find document
links potentially relevant to their queries.
In our experiment, we integrated a particular support bot, the Work Man-
agement Support Bot, with GPT-based tools and compared its performance to
the existing keyword-based flowchart support bot. This bot is tailored to assist
Microsoft software developers with login and access issues. The new GPT-based
approach features a bot (hereafter GPT-based bot) that enables users to ask
questions in natural language and receive direct answers from the same docu-
ment sources used by the flowchart support bot (hereafter classical bot).
The primary outcome of interest in our study is the escalation decision,
which is defined by a user’s decision to escalate the inquiry and seek support
from the back-end engineer. A good support bot should lead to low escalation
rates. Our experiment suggests that the GPT-based bot reduces the escalation
rate by 9.2 percentage compared with the classical bot. This represents a 53.8
2
percent reduction in escalation rate relative to the baseline of the classical bot.
In addition, we implemented two versions of the GPT-based support bots,
one based on the GPT4 model and the other based on the GPT3.5 model. We
compare their escalation rates and token consumption. While we find no sig-
nificant difference in escalation rates between the two models, there are notable
differences in token usage: although GPT4-based bot consumes less tokens per
question on average, GPT3.5-based bot has a price advantage under the current
pricing structure of GPT models (OpenAI, 2023b).
Our results add to the literature of experimental and observational research
on the productivity-enhancing effects of LLM-based tools. For instance, Noy
and Zhang, 2023 examines the individual and distributional productivity effects
of ChatGPT on writing task completion and quality among experienced, college-
educated professionals. Peng et al., 2023 investigates how GitHub Copilot affects
software developers’ productivity in programming tasks. Dell’Acqua et al., 2023
randomizes GPT4 tools to consultants and measures the change in productivity.
Spatharioti et al., 2023 evaluates LLM-based tools in aiding consumers with
search tasks. Finally, Brynjolfsson, Li, and Raymond, 2023 studies the impact
of AI tools on productivity in an observational setting using a difference-in-
differences approach.
The rest of the paper is as follows. Section 2 introduces backgrounds and
experimental designs. Section 3 contains results of the experiments, and Section
4 includes details on the specifications of our statistical analysis.
2
Backgrounds and Experimental Designs
We conducted a randomized control trial (RCT) to compare the performance of
the Power Virtual Agents (classical) based bot with the GPT-based bot. This
chatbot assists Microsoft developers with login and access issues. All traffic to
3
the chatbot service was randomized into control and treatment groups. The
control group interacted with the existing bot, based on the PowerVA service,
offering a flowchart-style experience where users navigate predefined options
to find documents addressing their questions. The treatment group used the
new GPT-based bot, which allows users to pose questions in natural language
and provides direct answers from the same document sources as the classical
bot. Figure 2 depicts the PowerVA-based support bot experience, and Figure 3
illustrates the GPT-based support bot experience.
If developers are unsatisfied with the bot’s responses, they have the option
to escalate their questions for real human intervention. Our back-end engineers
assign 10 minutes to resolve each escalated case, and most cases are resolved
within this estimate. The traffic varies between 5 to 20 cases per week, depend-
ing on seasonality. One may witness heavier-than-usual traffic during Monday,
specific months, and after reorganizations when some users lose access and turn
to the bot to request new permissions.
Our experiments had two waves. The first wave took place between May
05, 2023 and July 21, 2023, and the second wave from July 21, 2023 to Oct 12,
2023. In the first wave, users in each session were randomly assigned to either
the classical bot or the GPT4-based version. In the second wave, a new GPT3-
supported version was introduced, and and users were randomly assigned to one
of three options: the classical bot, the GPT4-based bot, or the GPT3.5-based
bot. No additional instructions were provided on how users should interact with
the support bots.
For each session, we collected data such as session ID, starting time of the
session, engagement decision, duration of the engagement, and escalation deci-
sion. For the GPT-based versions, we were able to collect data such as users’
first prompts and support bot’s first responses.
4
The primary outcome of our study is the escalation decision, which reflects
a user’s choice to escalate their inquiry and seek assistance from a back-end
engineer. An effective support bot should accurately comprehend a user’s ques-
tion, retrieve the correct information, and provide clear responses. Ultimately, a
high-quality support bot should result in a low escalation rate, thereby reducing
the workload for back-end engineers in supporting users.
3
Results
We collected data on 3296 sessions over a span of five months. There are 1413
engaged cases and 165 escalations. We calculate the overall engagement rate as:
Overall Engagement Rate = 1413
3296 = 42.9%.
Among the engaged cases, the overall escalation rate is calculated as
Overall Escalation Rate = 165
1413 = 11.7%.
3.1
Engagement Rates
Users may not to engage with the support bot services for various reasons.
For instance, the support bots automatically initiate a login action when the
conversation starts. This login process can take anywhere from 5 to 30 seconds,
during which users might refresh the page, inadvertently skipping the existing
session.
Additionally, some users may accidentally click on the wrong page,
leading to unintended visits to the support bot service.
In our analysis, we concentrate on the outcomes of engaged sessions to evalu-
ate the quality of the support bots. A GPT-based bot session is deemed engaged
if the user posts a question and the bot responds. For a classical bot session,
5
engagement is defined as the user utilizing at least one functionality of the bot.
Our findings indicate no significant difference in engagement rates between clas-
sical sessions and GPT-based sessions (difference-in-means = -0.026, t-statistics
= -1.457, p-value = 0.145).
3.2
Primary Outcome: Escalation Rate
We observe 66 escalations out of 835 engaged sessions with the GPT-based sup-
port bots, and 99 escalations out of the 578 engaged sessions with the classical
support bots.
We calculate the average escalation rate as:
Average Escalation Rate (GPT-based bot) = 66
835 = 7.9%
Average Escalation Rate (classical bot) = 99
578 = 17.1%
This is a significant 9.2 percentage point reduction (t-statistics=-5.05, p-value=4.9e-
07) in the average escalation rate when using the GPT-based support bots.
In a relative term, this represents a 53.8 percent (9.2/17.1) reduction in av-
erage escalation rate compared to the baseline escalation rate of 17.1 percentage
points for the classical support bot.
3.3
Comparing GPT3.5 and GPT4
In the second wave of our experiment and after July 21st 2023, we increased the
number of sessions that are assigned to the GPT-based support bot. Further,
we randomized sessions into either GPT3.5-based support bot or GPT4-based
support bot. During the period between July 21st, 2023 and October 11th, 2023,
we collected information on 190 engaged cases for the GPT4-based support bot
and 203 engaged cases for the GPT3.5-based support bot.
6
Among the 203 engaged cases for the GPT3.5-based version, there were 17
escalations, and among the 190 engaged cases for GPT4-based version, there
were 19 escalations. The average escalation rates for the GPT3.5-based and
GPT4-based versions are
Average Escalation Rate (GPT3.5-based bot) = 17
203 = 8.4%
Average Escalation Rate (GPT4-based bot) = 19
190 = 10%
The escalation rate of the GPT4-based version is slightly higher than that
of the GPT3.5-based version, but the difference is not statistical significant (t-
statistics=0.556, p-value=0.579).
We also compared the GPT3.5-based and GPT4-based versions in terms of
input and output token consumption. Input and output tokens form the basis
for cost calculations when using GPT-based services (OpenAI, 2023b). Since
the pricing plans for tokens vary depending on the version used, our comparison
here is relevant to cost considerations.
Input Tokens
Output Tokens
GPT3.5-based bot
2575.0
190.3
GPT4-based bot
2018.4
235.5
Table 1: Average token consumptions for GPT3.5-based and GPT4-based bots.
We found that users’ questions consume from 290 to 3363 input tokens,
from 38 to 300 output tokens, and from 500 to 3620 total tokens (input tokens
+ output tokens). Figure 4 plots token consumption for both GPT3.5-based and
GPT4-based bots. As shown in Table 1, on average the GPT3.5-based bot con-
sumes more input tokens than the GPT4-based bot does (difference-in-means=-
556.6, t-value=-6.864, p-value=2.6e-11). The GPT4-based bot consumes more
output tokens than the GPT3.5-based bot (difference-in-means=45.2, t-value=0.557,
7
p-value=0.578), but this difference is not statistically significant.
The variation in input token consumption between the two versions can be
explained by the fact that GPT4 is able to process several frequently-referenceed
documents with less resources.
The difference of the output tokens can be
explained by the fact that GPT4-based version often outputs longer but more
structured responses. For example, for the same prompt ”I need access”, GPT4-
based bot outputs
To request access, you need to follow the appropriate steps based on the
type of access you require. Here’s a general outline of the process:
1. Determine the type of access you need:
• Access Type 1
• Access Type 2
• ...
2. Visit the [NAME](URL) portal.
3. Depending on the type of access you need, follow the appropriate
link(s) provided in the documentation to request access.
4. Fill out the required information and submit your request.
5. Wait for approval from the appropriate authority based on your
organization and the type of access you’re requesting.
6. Please refer to the documentation for specific links and approval
requirements based on your organization and the type of access you
need. If you have any issues or need further assistance, contact the
[NAME](URL).
8
For the GPT3.5-based bot, it outputs
Hi there! You need access to resources that are managed by Microsoft.
To get access, you need to go through [NAME](URL). [ServiceName] is
supported by [Name](URL).
For work item/resource access for [Projects] that are not [Projects], you
can ask [NAME](URL) to determine who that is.
For full legacy source access, you can apply [NAME](URL). For legacy
test sources only, you can apply [NAME](URL). For legacy branch own-
ers’ publics, you can apply [NAME](HERE)
We can calculate average cost per question for both GPT-3.5 based bot and
GPT4-based bot, using the existing pricing schedule (OpenAI, 2023b) (price
based on Azure public price at Dec 2023). Based on the information in Table 1,
the average cost per question is 7.5 cents (0.03*2018.4/1000 + 0.06*235.5/1000)
for GPT4-based bot and 0.3 cents (0.0010*2575/1000 + 0.0020*190.3/1000 )
for GPT3.5-based bot. Provided that the GPT3.5-based bot and GPT4-bot are
able to provide similar experience, GPT3.5-based bot offers a more cost-efficient
alternative compared with the GPT4-based bot.
3.4
Robustness Check
Our randomization happens on a per-session level, so a user who use multi-
ple sessions may see both the GPT-based and classical versions with the same
question. We’ll use a different experimental design to prevent this complication
in the next round. In this session, we conduct a robustness check, specifically
looking at users’ escalation decisions in the first session.
We recorded 679 sessions with user alias between September 12, 2023 to
October 12, 2023. There are 310 engaged cases during this time period and 263
9
cases are first sessions of users’ interactions with the bots. There are 160 engaged
GPT-based bot sessions with 10 escalations, and 103 Classical bot sessions with
21 escalations. We calculate the average escalation rate as:
Average Escalation Rate (GPT-based bot) = 10
160 = 6.3%
Average Escalation Rate (classical bot) = 21
103 = 20.4%
This is a significant 14.1 percentage point reduction (t-statistics=-3.19, p-value=0.001)
in the average escalation rate when using the GPT-based support bots. It ap-
pears that results based on the restricted samples are qualitatively similar to
the results reported in Section 3.2.
4
Regression Details
We used the statistical programming language R to analyze the data.
The
standard errors of all regression results are calculated using the HC2 formula,
implemented in the sandwich (Zeileis et al., 2019) package in R. The t-tests are
calculated using the lmtest (Hothorn et al., 2015) package in R .
4.1
Engagement Rates
The reported results in Section 3.1 are based on the regression specification:
Engagement = β0 + β1Version + ϵ,
where Engagement is a binary variable, with 1 indicating that the user engaged
with the support bot and 0 otherwise. Version is also a binary variable, with 1
representing a GPT-based support bot and 0 representing the classical version
of the support bot.
10
4.2
Escalation Rates
The reported results in 3.2 are based on the regression specification:
Escalation = β0 + β1Version + ϵ,
where Escalation is a binary variable, with 1 indicating the user escalated the
issue to a back-end engineer and 0 otherwise. Version is defined as in Section
4.1. We limited our analysis to engaged sessions.
4.3
Comparing GPT3.5 and GPT4
The reported results in 3.2 are based on the regression specification:
Escalation = β0 + β1GPT4 + ϵ,
where Escalation is a binary variable, with 1 indicating that the user has esca-
lated the issue to a back-end engineer and 0 otherwise. GPT4 is also a binary
variable, with 1 representing a GPT4-based support bot and 0 indicating a
GPT3.5-based bot.
We restricted samples to engaged sessions.
The regres-
sion specifications for the input tokens and output tokens are similar but with
different dependent variables.
4.4
Robustness Check
The reported results in Section 3.4 use the same specifications as those reported
in Section 3.2, with the constructed sample described in Section 3.4.
11
References
[1]
Erik Brynjolfsson, Danielle Li, and Lindsey R Raymond. Generative AI
at work. Tech. rep. National Bureau of Economic Research, 2023.
[2]
Fabrizio Dell’Acqua et al. “Navigating the jagged technological frontier:
Field experimental evidence of the effects of AI on knowledge worker pro-
ductivity and quality”. In: Harvard Business School Technology & Oper-
ations Mgt. Unit Working Paper 24-013 (2023).
[3]
Forbes. 10 Amazing Real-World Examples Of How Companies Are Using
ChatGPT In 2023. https://www.forbes.com/sites/bernardmarr/
2023/05/30/10-amazing-real-world-examples-of-how-companies-
are-using-chatgpt-in-2023/?sh=11a57e151441. 2023.
[4]
Torsten Hothorn et al. “Package ‘lmtest’”. In: Testing linear regression
models. https://cran. r-project. org/web/packages/lmtest/lmtest. pdf. Ac-
cessed 6 (2015).
[5]
Shakked Noy and Whitney Zhang. “Experimental evidence on the produc-
tivity effects of generative artificial intelligence”. In: Available at SSRN
4375283 (2023).
[6]
OpenAI. Introducing ChatGPT Enterprise. https://openai.com/blog/
introducing-chatgpt-enterprise. 2023.
[7]
OpenAI. Pricing. https://openai.com/pricing. 2023.
[8]
Sida Peng et al. “The impact of ai on developer productivity: Evidence
from github copilot”. In: arXiv preprint arXiv:2302.06590 (2023).
[9]
Sofia Eleni Spatharioti et al. “Comparing Traditional and LLM-based
Search for Consumer Choice: A Randomized Experiment”. In: arXiv preprint
arXiv:2307.03744 (2023).
12
[10]
Achim Zeileis et al. “Package ‘sandwich’”. In: R package version (2019),
pp. 2–5.
Figure 1: Power Virtual Agents: Flow Chart Based System
13
Figure 2: Microsoft PowerVA-based Support Bot Experience
14
Figure 3: GPT-based Support Bot Experience
15
Figure 4: Distributions of Token Consumption for GPT3.5-based and GPT-4
based bots
16
"
"This study presents a model for understanding how customers’ satisfaction changes when they use an AR shopping application. It proposes that different levels of perceived experiential AR application features (informative, personalizing, and interactivity) affect the customer experience, which in turn influences customer satisfaction and purchase intention. The model also considers immersive experiences as a mediator between perceived AR application features and customer experience.nan","In an increasingly digital world, businesses are turning to AR technology to enhance the shopping experience and increase sales. This paper investigates the effects of AR technology on customers’ experience, satisfaction, and purchase intention in an online retail setting.nan","nanBuilding on the stimulus-organism-response (S-O-R) paradigm and the information systems success model (ISS), the study reviews previous research on consumer experiences, immersion, and customer satisfaction. It draws insights from studies on informative, personalizing, and interactivity features of AR applications.nan","The study proposes a conceptual model with hypotheses linking the perceived levels of experiential AR application features, such as information, personalization, and interactivity, to customer experience, immersion, customer satisfaction, and purchase intention. Methods for measuring these constructs are discussed, including subjective data collection techniques and the use of existing scales.nan","The paper outlines expected results based on the proposed hypotheses. It anticipates positive relationships between perceived AR application features and customer experience, immersion, customer satisfaction, and purchase intention. Furthermore, it suggests that immersion mediates the relationship between perceived AR application features and customer experience.nan",This study provides a deeper understanding of the role of AR technology in shaping customers’ experiences and how these experiences affect customer satisfaction and purchase behavior. It offers insights for business owners and academics in leveraging AR technology to improve customer engagement and drive sales.nan,How customers' satisfaction change with the use of AR shopping application: A conceptuall model,Fariba Sanaei," 
 
 
“HOW CUSTOMERS’ SATISFACTION CHANGE WITH THE USE OF AR SHOPPING 
APPLICATION:  
A CONCEPTUALL MODEL “  
 
Fariba Sanaei, University of Central Florida 
For further information, please contact Fariba Sanaei, PhD student, University of Central Florida 
(fariba.sanaei@ucf.edu) 
 
Keywords: Digital Marketing, AR Technology, Online Retailors, User Experience.  
Description: This study provides a conceptual model of how online businesses using AR 
technology in their purchase stage can have effects on customer satisfaction and their purchase 
intention, considering the mediation roles of customer experience and immersion.  
 
 
2023 AMA Winter Academic Conference
803
 
2 
ABSTRACT 
The paper proposes a conceptual model of how different perceived levels of experiential AR 
application features have effects on customer experience, and in turn their satisfaction and 
purchase behavior. In addition, it put forward the mediation role of immersion between perceived 
levels of experiential AR application features and customers’ experience.  
INTRODUCTION  
The world economy experienced dramatic up and downs after Covid-19 pandemic (Ostrom et al., 
2021). Before COVID-19, ecommerce was rapidly expanding. However, the epidemic drove even 
more US customers online. According to Digital Commerce 360 projections, the coronavirus 
contributed $102.08 billion to US ecommerce in 2020 and $116.45 billion in 2021. On the other 
hand, innovative technologies like AR have entered to marketing discipline and business owners 
found these technologies useful for attracting consumers. As a result, nowadays more businesses 
are turning into AR technology to increase their sales. adopting such strategies for online shopping 
enhances the sense of real environment in digital platforms and it can increase consumers 
engagements in long-term. 
The goal of this study is to understand how adopting AR technology by business owners could be 
effective in terms of their consumer’s purchase intention and their levels of satisfaction. By doing 
a comparative study in these field, beneficial implications can be received by business owners and 
academics. AR technology has entered in different areas from fashion industry to beauty 
cosmetics. Worldwide brands like Ikea and Amazon utilizing AR services in their online selling 
strategies for their home furniture.  It can be anticipated that by introducing Metaverse world, more 
2023 AMA Winter Academic Conference
804
 
3 
and more businesses will turn to such innovative technologies, so more research is needed for 
better and in depth understanding of relation between adopting AR technology, consumers’ 
satisfaction, and their purchase intention. This study is going to answer: How is the consumers’ 
experience of using AR applications affected, given different perceived level of experiential AR 
application features? How different perceived experience can result in different satisfaction levels 
and purchase intention?  
CONCEPTUAL FRAMEWORK 
Consumer experience is in the center of our framework. According to Lemon and Verhoef (2016), 
customer experience is defined by their responses during their shopping journey and these 
responses consist of multiple constructs like customers’ cognitive, behavioral, emotional. in our 
research the main focus is on behavioral construct of consumers’ experience.   The following 
concepts are our main framework aspects for adopting AR technology buy business owners in their 
marketing strategies. 1) immersion defined by how an AR technology can reflect the realism with 
the use of different sensory feelings. 2)consumer experience as we defined before, and our main 
focus is on their behavioral responses. 3) experiential context defined as one of the constructs 
which identifies the positive points of adopting AR technologies for enhancing consumers’ 
experience. 4) effectiveness of experiential AR application features including informative, 
personalizing, and interactivity features along the customers’ experience and purchase stage of 
customers’ journey.  
Stimulus-Organism-Response Paradigm 
2023 AMA Winter Academic Conference
805
 
4 
By using the stimulus-organism-response S-O-R paradigm, retailers are able to understand the 
needed stimuli and their effects on consumers’ behavior. This paradigm states that stimuli activate 
the cognitive processing of individuals and result in consumer responses like accepting or rejecting 
them (Mehrabian and Russell, 1974). One of the cases where this paradigm can be adopted is with 
AR mobile applications investigating app features and consumer behavior. There are studies that 
examined different important mobile AR app characteristics that have consequences on users’ 
reactions like purchase intention (Daassi and Debbabi, 2021). Our study can add value to the 
literature of mobile AR application concepts by understanding how AR application features are 
experienced and perceived by consumers. The features that are going to be studied in this research 
include information, personalized and interactivity features. 
Different consumers’ experiences have been studied in previous research, like interactivity by 
Poushneh and Vasquez-Parraga in 2017, and informativeness by Rese et al. in 2017, etc. We focus 
on Javornik's perspective (2016) and consider the perceived levels of the informative, 
personalization, and interactivity features. For better understanding, the informative aspect of these 
applications enhances the process of decision-making for consumers and in our research refers to 
the level of the product information provided by AR app which is perceived by consumers. This 
information can be in the form of text, images, videos, etc. (Pantano et al., 2017).  
Personalization features refer to perceived level of the information provided based on individuals’ 
desires and needs according to their preferences. The presence of this feature utilizes customers 
with saving personal time, search costs, and money. By interactivity features, we mean different 
contents that people can have access to, and when this interactivity is high, the quality of AR is 
better, resulting in more positive responses from consumers. In this research we focus on perceived 
2023 AMA Winter Academic Conference
806
 
5 
level of this feature by customers using the AR app, and this feature can be reflected into the 
technologically effective delivery process (Fiore et al., 2005). So, we propose the following 
hypotheses: 
P1: The perceived level of informative feature of an experiential AR application positively 
influences customers’ experience. 
P2: The perceived level of personalizing feature of an experiential AR application positively 
influences customers’ experience. 
P3: The perceived level of interactivity features of an experiential AR application positively 
influences customers’ experience. 
Immersion 
Immersion is a construct defined as how much a reality is near to its simulation made by 
technology using five human senses (Slater and Wilbur, 1997).  According to Wedel et al. (2020) 
previous scholars investigated that how stimulated environments are immerse and if they get 
more immerse how consumers’ behavior is going to be. Our main focus in this research is going 
to be on how vision sensory can affect the experiential effectiveness of available AR application 
features on consumers’ experience. So, we can propose that: 
P4: the effectiveness of experiential present AR application features on consumers’ experience is 
mediated by immersion. 
Information System Success Model 
2023 AMA Winter Academic Conference
807
 
6 
Information system success (ISS) determines users' behavior to understand their experience like 
satisfaction with using a service or product (Delone and Mclean, 2016; Schaarschmidt and Höber, 
2017). Augmented reality is a new concept in retail and adopting the ISS model can utilize 
researchers to investigate this technology and understand how consumers react and respond to it 
in a shopping context. The current study provides more information and specifics about the 
acceptance and use of augmented reality (AR) technology for home furniture in retail and online 
platforms. Previous research has shown that if the quality of this system is high, then customers 
are more willing to continue using this technology (Kim and Hwang, 2012; Van Pinxteren et al., 
2019). Services adopting AR features are expected to enhance consumers’ experience because they 
provide customized services for consumers, and as this customization increases, high levels of 
customer satisfaction will be reached (Kim and Hwang, 2012; Murali et al., 2016). Therefore, 
customer satisfaction can be enhanced in online contexts using AR technology (Quadri-Felitti & 
Fiore, 2013; Tom Dieck, Jung, Kim, & Moon, 2017). According to Srivastava and Kaul (2014), 
consumer experiences are the main factor for defining customer satisfaction. The amount of joy 
and pleasure experienced by consuming a product is reflected in the satisfaction term. It is defined 
as fulfilling desires and leads to a positive service or product experience (Chung et al., 2018). By 
doing this research, more value will be added to the consumer behavior literature. The level of 
satisfaction gained from using AR sheds light on the use of AR apps in the online furniture 
industry. Using this technology affects consumers’ intention to purchase and customer returns 
(Keiningham et al., 2017; Poushneh and Vasquez-Parraga, 2017). So, we can propose the 
following hypothesis.  
P5: consumers’ experience using online shopping applications using AR technology positively 
influences consumers satisfaction during their purchase stage. 
2023 AMA Winter Academic Conference
808
 
7 
P6: consumers’ experience using online shopping applications using AR technology positively 
influences purchase intentions during their purchase stage. 
The proposed model is shown in figure 1.  
 
 
 
 
 
Figure 1. Conceptual Model 
DATA 
The perceived level of experiential AR application features are subjective constructs and can be 
measured by effective delivery process techniques. Perceived informative features can be 
measured by Rese et al. (2017) methods. By adopting Kim and Baek (2018) methods, we can 
measure perceived levels of personalization of AR apps, and Pantano et al. (2017) proposed a 
method for measuring perceived interactivity feature and can be used and adopted for our research.  
The technical features and characteristics of AR applications like video inputs can be studied by 
subjective data to measure the immersion. Assessing the quality of these inputs can be measured 
by Akhtar and Falk (2017) method, and how they proposed the results can reflect the immersion 
of AR technology. In conclusion, for measuring the effectiveness of experiential AR application, 
immersion, consumers’ experience, and consumers satisfaction, we can use primary data by asking 
consumers experiencing AR technology within questioners and qualitative interviews. 
Perceived level of experiential 
AR application features: 
 
•
Perceived level of 
informative feature 
•
Perceived level of 
personalizing feature 
•
Perceived level of 
interactivity feature 
Customers’ 
experience 
Purchase stage: 
•
Customer satisfaction 
•
Purchase intention 
Immersion 
(P1), (P2), (P3) 
(P4) 
(P5), (P6) 
2023 AMA Winter Academic Conference
809
 
8 
The experience scale developed by Brakus et al. (2009) can be adopted to assess behavioral aspect 
of consumers’ experience. Self-report data from questionnaires are useful for capturing 
consumers’ behavior. For the satisfaction, customer satisfaction measurement is a standard 
practice in marketing discipline, and it has been defined by the results of comparing perceived 
performance delivery with the customers’ expectation. This confirmation or disconfirmation 
creates user satisfaction (Lemon and Verhoef, 2016). we are going to adopt Reichheld (2003) 
method of using Net Promoter Score (NPS) to gather our data for customer satisfaction.  
For measuring purchase intention, at first, we can measure the number of sales in our study design 
which is done by our participants, furthermore for our final model, we can use secondary data from 
companies with AR technology for their online shopping applications, and asking them about the 
purchasing information of their consumers using their AR technology and information about the 
updates of their applications and specific changes in their sales according to these updates. This 
data set may be longitude for examining consumers’ purchase intention. 
 
CONCLUSION 
In this article, we proposed that when online retailers adopting AR technology in their applications 
for customers’ convenience, different levels of perceived experiential AR application features 
affect their experience. Informative, personalizing, and interactivity are three features that our 
study is going to investigate for their effects on users’ experience. In addition, we proposed the 
mediating role of immersion between this perceived experiential and the customers’ experience. 
We argued that the purchase stage behavior of a customer, like his or her satisfaction and purchase 
behavior, is influenced by his or her experience of using the retailers’ AR technology. 
2023 AMA Winter Academic Conference
810
 
9 
 
REFRENCES 
 
Akhtar, Zahid, and Tiago H. Falk. ""Audio-visual multimedia quality assessment: A comprehensive 
survey."" IEEE access 5 (2017): 21090-21117. 
 
Brakus, J. Joško, Bernd H. Schmitt, and Lia Zarantonello. ""Brand experience: what is it? How is 
it measured? Does it affect loyalty?."" Journal of marketing 73, no. 3 (2009): 52-68. 
 
Daassi, Mohamed, and Sana Debbabi. ""Intention to reuse AR-based apps: The combined role of 
the sense of immersion, product presence and perceived realism."" Information & Management 58, 
no. 4 (2021): 103453. 
 
DeLone, 
William 
H., 
and 
Ephraim 
R. 
McLean. 
""Information 
systems 
success 
measurement."" Foundations and Trends® in Information Systems 2, no. 1 (2016): 1-116. 
 
Elkins, Gary E., Peter N. Schmalzer, Travis Thompson, and Amy Simpson. Long-term pavement 
performance information management system: Pavement performance database user reference 
guide. No. FHWA-RD-03-088. Turner-Fairbank Highway Research Center, 2003. 
 
Fiore, Ann Marie, Jihyun Kim, and Hyun-Hwa Lee. ""Effect of image interactivity technology on 
consumer responses toward the online retailer."" Journal of Interactive Marketing 19, no. 3 (2005): 
38-53. 
 
Javornik, Ana. ""Augmented reality: Research agenda for studying the impact of its media 
characteristics on consumer behaviour."" Journal of Retailing and Consumer Services 30 (2016): 
252-261. 
 
2023 AMA Winter Academic Conference
811
 
10 
Keiningham, Timothy, Joan Ball, Sabine Benoit, Helen L. Bruce, Alexander Buoye, Julija 
Dzenkovska, Linda Nasr, Yi-Chun Ou, and Mohamed Zaki. ""The interplay of customer experience 
and commitment."" Journal of Services Marketing31, no. 2 (2017): 148-160. 
 
Kim, Dan J., and Yujong Hwang. ""A study of mobile internet user’s service quality perceptions 
from a user’s utilitarian and hedonic value tendency perspectives."" Information Systems 
Frontiers 14, no. 2 (2012): 409-421. 
 
Kim, Seeun, and Tae Hyun Baek. ""Examining the antecedents and consequences of mobile app 
engagement."" Telematics and Informatics 35, no. 1 (2018): 148-158. 
 
Lemon, Katherine N., and Peter C. Verhoef. ""Understanding customer experience throughout the 
customer journey."" Journal of marketing 80, no. 6 (2016): 69-96. 
 
Mehrabian, A., and J. A. Russell. ""An Approach to Environmental Psychology.,(MIT Press: 
Cambridge, MA.)."" (1974). 
 
Murali, S., S. Pugazhendhi, and C. Muralidharan. ""Modelling and investigating the relationship of 
after sales service quality with customer satisfaction, retention and loyalty–a case study of home 
appliances business."" Journal of retailing and consumer services 30 (2016): 67-83. 
 
Pantano, Eleonora, Alexandra Rese, and Daniel Baier. ""Enhancing the online decision-making 
process by using augmented reality: A two country comparison of youth markets."" Journal of 
Retailing and Consumer Services 38 (2017): 81-95. 
 
Poushneh, Atieh, and Arturo Z. Vasquez-Parraga. ""Discernible impact of augmented reality on 
retail customer's experience, satisfaction and willingness to buy."" Journal of Retailing and 
Consumer Services 34 (2017): 229-234. 
 
2023 AMA Winter Academic Conference
812
 
11 
Preacher, Kristopher J., and Andrew F. Hayes. ""SPSS and SAS procedures for estimating indirect 
effects in simple mediation models."" Behavior research methods, instruments, & computers 36, 
no. 4 (2004): 717-731. 
 
Quadri-Felitti, Donna L., and Ann Marie Fiore. ""Destination loyalty: Effects of wine tourists’ 
experiences, memories, and satisfaction on intentions."" Tourism and Hospitality Research13, no. 
1 (2013): 47-62. 
 
Reichheld, Frederick F. ""The one number you need to grow."" Harvard business review 81, no. 12 
(2003): 46-55. 
 
Rese, Alexandra, Daniel Baier, Andreas Geyer-Schulz, and Stefanie Schreiber. ""How augmented 
reality apps are accepted by consumers: A comparative analysis using scales and 
opinions."" Technological Forecasting and Social Change124 (2017): 306-319. 
 
Sanchez-Vives, Maria V., and Mel Slater. ""From presence to consciousness through virtual 
reality."" Nature Reviews Neuroscience 6, no. 4 (2005): 332-339. 
 
Schaarschmidt, Mario, and Björn Höber. ""Digital booking services: comparing online with phone 
reservation services."" Journal of Services Marketing (2017). 
 
Schuemie, Martijn J., Peter Van Der Straaten, Merel Krijn, and Charles APG Van Der Mast. 
""Research on presence in virtual reality: A survey."" CyberPsychology & Behavior 4, no. 2 (2001): 
183-201. 
 
Slater, Mel, and Sylvia Wilbur. ""A framework for immersive virtual environments (FIVE): 
Speculations on the role of presence in virtual environments."" Presence: Teleoperators & Virtual 
Environments 6, no. 6 (1997): 603-616. 
 
2023 AMA Winter Academic Conference
813
 
12 
Srivastava, Mala, and Dimple Kaul. ""Social interaction, convenience and customer satisfaction: 
The mediating effect of customer experience."" Journal of retailing and consumer services 21, no. 
6 (2014): 1028-1037. 
 
Tom Dieck, M. Claudia, Timothy Hyungsoo Jung, Woo Gon Kim, and Yunji Moon. ""Hotel guests’ 
social media acceptance in luxury hotels."" International Journal of Contemporary Hospitality 
Management (2017). 
 
Van Pinxteren, Michelle ME, Ruud WH Wetzels, Jessica Rüger, Mark Pluymaekers, and Martin 
Wetzels. ""Trust in humanoid robots: implications for services marketing."" Journal of Services 
Marketing (2019). 
 
Wedel, Michel, Enrique Bigné, and Jie Zhang. ""Virtual and augmented reality: Advancing research 
in consumer marketing."" International Journal of Research in Marketing 37, no. 3 (2020): 443-
465. 
 
Zhao, Xinshu, John G. Lynch Jr, and Qimei Chen. ""Reconsidering Baron and Kenny: Myths and 
truths about mediation analysis."" Journal of consumer research 37, no. 2 (2010): 197-206. 
2023 AMA Winter Academic Conference
814
"
"This paper explores how research on Optimal Transport (OT) can be combined with Multi-Agent Reinforcement Learning (MARL). OT can help to distribute resources, align agent policies, and adjust to non-stationarity in MARL environments, especially where there are multiple agents. Using OT, MARL systems can optimize the distribution of resources, coordinate agent policies, and adapt to changing environments. The combined approach can potentially improve system efʻciency, coordination, adaptability, and scalability in MARL.nan","Multi-Agent Reinforcement Learning (MARL) is a framework where various agents learn and adapt within shared environments. These interactions involve diverse objectives, making coordination, resource management, adaptability, and operational efʻciency challenging. Optimal Transport (OT) offers a mathematical framework for comparing and transforming probability distributions effectively by finding the most cost-effective transport plan to move mass from one distribution to another. By merging OT with MARL, we can leverage OT's strengths to address the challenges in MARL, such as policy alignment, distributed resource management, non-stationarity, scalability, and energy efʻciency.nan","Previous research on policy alignment in MARL has explored strategies that utilize shared reward structures, joint action learning, and communication protocols. For distributed resource management, approaches such as auction-based mechanisms and cooperative strategies have been proposed. To address non-stationarity, algorithms that adjust learning rates based on Wasserstein distance have been investigated. Scalability has been tackled with decentralized learning, hierarchical structures, and networked or graph-based approaches. Additionally, techniques to optimize computational and operational aspects of learning processes and energy-efʻcient algorithms have been developed to improve MARL systems.nannan","To address policy alignment in MARL through OT, we can utilize the Wasserstein distance to measure and minimize the divergence between agent strategies. For distributed resource management, OT can optimize resource allocation by minimizing the transportation cost between supply and demand distributions. Non-stationarity can be modeled as a transportation problem using OT, where an optimal plan aims to minimize the cost of adapting to environmental changes. Scalability can be achieved through decentralized and hierarchical computation approaches. Finally, energy efʻciency can be enhanced by incorporating energy consumption as a weight into the OT framework.nan","Integrating OT with MARL can potentially lead to more efʻcient multi-agent systems. OT can optimize policy alignment, distribute resources effectively, manage non-stationarity, handle large-scale systems, and improve energy efʻciency. These enhancements can lead to more coherent and effective cooperative learning, improved coordination and adaptability, and reduced computational and energy costs.nan","Combining OT principles with MARL can improve system efʻciency, coordination, adaptability, and scalability. Challenges, such as computational complexity and scalability, require further research and development to address them. Future work can focus on reʻning the computational efʻciency of OT in large-scale MARL systems, exploring real-world applications, and adopting the synergy between OT and MARL to address broader problems.nan",The Synergy Between Optimal Transport Theory and Multi-Agent Reinforcement Learning,"Ali Baheri, and Mykel J. Kochenderfer","arXiv:2401.10949v1  [cs.MA]  18 Jan 2024
The Synergy Between Optimal Transport Theory
and Multi-Agent Reinforcement Learning
Ali Baheri1 and Mykel J. Kochenderfer2
Abstract— This paper explores the integration of optimal
transport (OT) theory with multi-agent reinforcement learning
(MARL). This integration uses OT to handle distributions and
transportation problems to enhance the efﬁciency, coordination,
and adaptability of MARL. There are ﬁve key areas where
OT can impact MARL: (1) policy alignment, where OT’s
Wasserstein metric is used to align divergent agent strategies
towards uniﬁed goals; (2) distributed resource management,
employing OT to optimize resource allocation among agents;
(3) addressing non-stationarity, using OT to adapt to dynamic
environmental shifts; (4) scalable multi-agent learning, har-
nessing OT for decomposing large-scale learning objectives
into manageable tasks; and (5) enhancing energy efﬁciency,
applying OT principles to develop sustainable MARL systems.
This paper articulates how the synergy between OT and MARL
can address scalability issues, optimize resource distribution,
align agent policies in cooperative environments, and ensure
adaptability in dynamically changing conditions.
I. INTRODUCTION
Multi-agent reinforcement learning (MARL) is a frame-
work where multiple agents interact, learn, and adapt within
shared environments [1]. These interactions, governed by
diverse objectives and constraints, present signiﬁcant chal-
lenges related to coordination, resource management, adapt-
ability, and operational efﬁciency [2].
Optimal transport (OT) theory offers a powerful mathemat-
ical framework for comparing and transforming probability
distributions in a cost-effective manner [3]. It is concerned
with ﬁnding the most efﬁcient plan to transport mass from
one distribution to another, minimizing a given cost function.
OT has found applications across diverse ﬁelds due to its
ability to provide geometrically and statistically meaningful
ways to compare distributions [4]. In this context, the fusion
of OT with MARL represents a promising interdisciplinary
strategy, designed to harness the strengths of OT in tackling
the multifaceted challenges inherent in MARL.
Policy Alignment in MARL with OT. We explore how
OT, particularly through its Wasserstein distance metric, can
be used to minimize the divergence in strategies among
agents. This approach promises a more coherent and effective
collaborative learning process, ensuring agents’ policies are
aligned towards common goals.
Distributed Resource Management in MARL with OT.
In scenarios where agents must efﬁciently share limited re-
sources like energy or information, OT provides a principled
framework to optimize this distribution. The paper delves
1Ali Baheri is with the Department of Mechanical engineering at
Rochester Institute of Technology. akbeme@rit.edu
2Mykel J. Kochenderfer is with the Department of Aeronautics &
Astronautics at Stanford University. mykel@stanford.edu
into how OT can minimize the costs associated with resource
allocation, balancing efﬁciency and equity among agents.
Addressing Non-Stationarity in MARL with OT. The
dynamic nature of MARL environments, where the ground
truth shifts as agents learn and adapt, presents a signiﬁcant
challenge. OT’s ability to adapt to changes in probability
distributions is investigated as a method to manage this non-
stationarity, enhancing capacity of the agents to respond to
evolving environments.
Scalable Learning in Large-Scale MARL with OT. As the
scale of MARL systems expands, so does the complexity
of managing interactions and learning. We propose using
OT to decompose global learning objectives into localized
tasks, facilitating scalable and efﬁcient learning across large
networks of agents.
Enhancing Energy Efﬁciency in MARL with OT. In
energy-constrained MARL scenarios, optimizing energy us-
age is crucial. This paper discusses how OT can be used to
develop energy-efﬁcient MARL systems.
Contributions. This paper explores how the fusion of OT
and MARL can lead to more efﬁcient multi-agent systems.
The structure of the paper is as follows: Section II provides
an overview of OT. Section III discusses how to integrate OT
principles into MARL. Section IV examines the challenges
of this integration, addressing potential computational issues.
II. OPTIMAL TRANSPORT
OT theory, rooted in the works of Gaspard Monge and
later Leonid Kantorovich, revolves around ﬁnding the most
cost-effective way of transporting mass from one distribution
to another [3], [5]. Central to OT is the concept of the
Wasserstein distance, also known as the Earth Mover’s
distance, which quantiﬁes the “effort” required to transform
one probability distribution into another. Originating from
Monge’s problem in the 18th century, which sought an
optimal plan for moving soil with minimum effort, the theory
has evolved, especially with Kantorovich’s formulation in the
20th century, to incorporate modern mathematical tools from
linear programming and functional analysis [6].
OT has found applications in diverse ﬁelds. In economics,
it aids in understanding resource allocation and market
dynamics [7], [8]; in computer vision and graphics [9], [10],
it helps in image retrieval and texture mixing [11], [12]; and
in machine learning [13], [14], [15], [16], [17], it is used for
domain adaptation and generative modeling.
OT theory is concerned with the problem of transporting
mass from one distribution to another in the most efﬁcient
manner. Formally, given two probability distributions µ and
ν on spaces X and Y , respectively, OT seeks a transport map
T : X → Y that minimizes the cost of transportation. A key
concept in OT is the Wasserstein distance, which is deﬁned
as the minimum cost to transport mass from one distribution
to another. Mathematically, for distributions µ and ν, the p-
Wasserstein distance is given by:
Wp(µ, ν) =

inf
γ∈Γ(µ,ν)
Z
X×Y
d(x, y)pdγ(x, y)
1/p
(1)
where Γ(µ, ν) represents all joint distributions (couplings)
with marginals µ and ν, and d(x, y) is a distance metric on
X × Y .
III. INTEGRATION OF OT WITH MARL
A. OT and Policy Alignment
Cooperative learning in MARL requires aligning the poli-
cies and objectives of individual agents towards a collective
goal. This section shows how OT theory in can amplify the
efﬁcacy of cooperative learning among agents in MARL
environments. In cooperative MARL, a group of agents
{a1, a2, . . . , an} aims to learn policies {π1, π2, . . . , πn} that
maximize a shared reward function. The effectiveness of
cooperation hinges on the alignment of these policies to-
wards the collective goal. Each agent’s policy πi induces a
probability distribution µi over the state-action space S × A.
The alignment of these distributions is crucial for effective
cooperation. The p-Wasserstein distance could be used to
measure the discrepancy between these distributions. For
two agents ai and aj, the distance between their induced
distributions µi and µj is given by:
Wp (µi, µj) =

inf
γ∈Γ(µi,µj)
Z
S×A
∥s − s′∥p dγ (s, s′)
1/p
(2)
where Γ (µi, µj) represents the set of all joint distributions
with marginals µi and µj, and ∥s− s′∥ is a metric on the
state-action space. The goal is to adjust individual policies to
minimize the overall Wasserstein distance between all pairs
of agents’ policy-induced distributions. The optimization
problem is:
min
N
X
i=1
N
X
j=1,j̸=i
Wp (µi, µj)
(3)
This minimization ensures that the policies of different
agents are coherently aligned towards the collective objec-
tive. Implementing OT for policy alignment in MARL is
conceptually promising, but choosing an appropriate metric
for the state-action space is crucial and can be complex.
The crux of this integration lies in harnessing OT’s capac-
ity for efﬁciently transporting and transforming distributions
to align policy distributions within MARL environments.
Each agent’s policy can be viewed as a probability distri-
bution over the state-action space, reﬂecting their decision-
making process. The Wasserstein distance could provide a
means to measure the “effort” or “cost” needed to align one
agent’s policy distribution with another. By minimizing this
distance, we can effectively guide the agents towards policy
alignment.
Related Work. Various approaches have been proposed
to facilitate policy alignment. These include shared reward
structures, where agents are incentivized to work towards
common goals, and joint action learning, where agents learn
policies based on the combined actions of all agents in the
system [18]. Communication protocols have been explored
as a means to align policies [19]. By allowing agents to
share information about their states, actions, or intended
goals, these protocols can signiﬁcantly improve coordination
and policy alignment. A notable approach in recent years is
centralized training with decentralized execution [20], [21].
Here, agents are trained in a centralized manner, allow-
ing them to learn about each other’s policies, but execute
their learned policies independently. Policy alignment in
MARL has found applications in various domains such as
autonomous vehicle coordination and robotics [22].
B. OT and Distributed Resource Management
In leveraging OT for distributed resource management in
MARL, we focus on the transportation of resources as a
probabilistic measure. This approach aligns with the core
principles of OT, where the Wasserstein distance is used
to quantify the efﬁciency of transporting one distribution to
another.
In a MARL system with resources R = {r1, r2, . . . , rm}
and agents A = {a1, a2, . . . , an}, consider each resource rj
as a mass that needs to be distributed among agents. Each
agent ai has a requirement or demand distribution µi, and
the total available resources form a supply distribution ν.
The transportation of resources from the total supply ν to
meet the demands µi of each agent can be modeled using
the Wasserstein distance. The goal is to ﬁnd an OT plan that
minimizes the Wasserstein distance, hence the transportation
cost, between the supply and demand distributions. The
mathematical formulation becomes:
Wp (ν, µi) =

inf
T ∈Γ(ν,µi)
Z
R×A
∥r − a∥pdT (r, a)
1/p
(4)
Here, Γ (ν, µi) represents the set of all possible transport
plans (joint distributions) with marginals ν and µi, and
∥r − a∥ is a metric representing the cost of transporting
resources. The OT problem in this context aims to minimize
the total transportation cost across all agents, ensuring that
resources are allocated efﬁciently and in accordance with
agents’ demands:
min
n
X
i=1
Wp (ν, µi)
(5)
This formulation respects the constraints of resource avail-
ability and agent requirements, optimizing the overall distri-
bution of resources in the MARL system.
The point of this integration lies in using OT’s mathe-
matical framework to coordinate the allocation of resources
among agents. By deﬁning a tailored cost function within
the OT model, we can effectively capture and minimize the
costs associated with resource distribution, such as energy
expenditure, transit time, or spatial constraints. This approach
could augment the overall efﬁciency of resource allocation
and introduces a level of fairness and adaptability that is
often unattainable with traditional MARL algorithms. The
dynamic nature of MARL systems, characterized by ﬂuc-
tuating resource demands and environmental states, further
highlights the suitability of OT. Its inherent ﬂexibility to
recalibrate transport plans in response to changing conditions
ensures that the resource distribution remains optimal over
time.
Related Work. Several works have proposed various strate-
gies for resource allocation in MARL. These include auction-
based mechanisms, where agents bid for resources [23],
[24], and cooperative strategies, where agents share resources
based on collective goals [25]. There is an open discussion in
current research regarding the balance between decentralized
versus centralized approaches for resource allocation [26].
Recent studies have explored the integration of communi-
cation protocols with resource management in MARL. Dis-
tributed resource management in MARL has been applied in
various domains, such as networked robotics, trafﬁc control,
and energy grids [27], [28].
C. OT and Non-Stationarity in MARL
Non-stationarity, characterized by the changing dynamics
in a multi-agent environment, poses a signiﬁcant challenge in
MARL. We propose OT to address non-stationarity in MARL
systems. In MARL, agents continually adapt their policies
based on the evolving environment, leading to non-stationary
dynamics. This non-stationarity complicates learning because
the ground truth each agent tries to learn keeps shifting. OT
could offer a powerful framework to adapt to changes in
probability distributions, which, in the context of MARL,
correspond to the evolving strategies and states of agents. We
discuss how the Wasserstein metric provides a natural way
to quantify the shifts in distributions representing policies
or environment states over time. OT can be used to model
the non-stationarity in MARL as a transportation problem,
where the goal is to ﬁnd an optimal plan that minimizes the
cost of adapting to the evolving environment. We propose
to explore algorithms that use the Wasserstein distance to
quantify the rate of change in the environment and adjust
the learning strategies. Using OT, the learning rate of agents
can be dynamically adjusted, becoming more responsive
during periods of rapid environmental change and more
stable during periods of relative constancy.
Consider MARL with N agents, where each agent i has
a policy πi that generates a distribution over states µi at any
given time t. The state space is denoted by S. For agent i, the
shift in its state distribution between two consecutive time
steps t and t + 1 can be quantiﬁed using the p-Wasserstein
distance:
Wp
alignment with the global objective. Furthermore, inter-layer
coordination between different layers could be managed
through an OT framework, which optimizes the ﬂow of
policies and rewards up and down the hierarchy. This would
ensure that local optimizations at lower layers contribute
effectively to the global objectives at higher layers.
Related Work. To address scalability, many studies have
focused on decentralized learning approaches [31], [32].
These allow agents to make decisions based on local in-
formation, reducing the computational burden. Hierarchical
learning structures are another solution for scalability. By
organizing agents into hierarchies or modules, the complexity
can be handled more effectively. Recent advancements have
explored the use of networked and graph-based approaches
for scalable MARL [33], [34]. Transfer learning and multi-
task learning techniques have been proposed to enhance scal-
ability [35], [36], [37], [38]. Scalable MARL has applications
in large-scale systems like trafﬁc management [39], [40],
smart grids [41], [42], and distributed control systems [43].
E. OT and Energy Efﬁciency
MARL systems, particularly in large-scale and complex
environments, face the challenge of high energy consumption
due to the computational demands of continuous learning and
decision-making processes. We can develop variants of the
Wasserstein metric that incorporates energy consumption as
a weight. This metric quantiﬁes not just the efﬁciency of
task distribution among agents but also the energy cost asso-
ciated with each task. By minimizing this energy-weighted
Wasserstein distance, the MARL system can dynamically
allocate tasks in a way that optimizes for both performance
and energy efﬁciency.
We could also design algorithms that continually adapt
the “transport paths” of computational tasks and information
ﬂow among agents. These paths are optimized based on real-
time energy consumption data, dynamically rerouting tasks to
agents with lower energy constraints or to times of day when
energy is more abundantly available (e.g., off-peak hours in
grid-connected systems). For environments with strict energy
limitations, such as remote sensors or space exploration
robots, the algorithms prioritize essential tasks and dynami-
cally allocate resources to maximize operational time while
maintaining essential functions. In systems equipped with
energy-harvesting capabilities, OT algorithms can be used
to optimally allocate and store harvested energy, prioritizing
tasks based on their urgency and energy requirements.
Related Work. Studies have focused on optimizing the
computational and operational aspects of learning processes,
reducing the energy consumption of agents during training
and execution [44]. Research in MARL under resource
constraints include energy-limited settings such as wireless
sensor networks or mobile robotics [45]. Papers in this do-
main explore strategies for agents to maximize their perfor-
mance while minimizing energy usage, often involving trade-
offs between task completion and power consumption [46].
Several studies have incorporated energy metrics into the
reward function of MARL algorithms [47], [48]. Some have
studies collaborative strategies in MARL, where agents work
together to achieve energy efﬁciency [49]. This includes
cooperative approaches for sharing resources like battery
power or computational capacity to extend the operational
life of the system [50]. Application-speciﬁc research in
domains like autonomous vehicle ﬂeets [51], smart grids
[52], and IoT systems [53] has highlighted the importance
of energy-efﬁcient MARL. In these applications, the goal is
often to optimize system-wide energy usage while ensuring
the effective performance of each agent.
IV. CHALLENGES
There are several challenges in integrating OT with
MARL. A primary obstacle is the computational complex-
ity inherent in OT, particularly when applied to the high-
dimensional and dynamic spaces characteristic of MARL.
The computational burden of calculating the Wasserstein
metric scales signiﬁcantly with the size of state and action
spaces, posing challenges in real-time applications [54]. Fur-
thermore, the dynamic nature of MARL systems necessitates
continuous recalibration of OT calculations, exacerbating
computational demands. To address these computational
challenges, one potential solution is the development of ap-
proximation algorithms for the Wasserstein distance. Lever-
aging techniques such as entropic regularization can pro-
vide a more computationally tractable approximation of the
Wasserstein metric [55]. Additionally, employing machine
learning models, tailored to approximate OT calculations, can
accelerate the process, making it more feasible for dynamic
MARL environments [15].
Another critical challenge is scalability, particularly in
handling large numbers of agents. The complexity of com-
puting OT metrics across large networks of agents can offset
the beneﬁts of optimal distribution and task allocation. Here,
decentralized and hierarchical approaches to OT computation
could present a viable solution [56]. By decomposing the
global OT problem into smaller, localized sub-problems,
and solving them within agent clusters, the system can
achieve scalability while maintaining the integrity of the OT
framework.
V. CONCLUSIONS
This paper explored integrating OT with MARL, address-
ing some of the critical challenges in the ﬁeld. We delved into
how OT’s strengths in handling distributions and minimizing
transportation costs can enhance MARL in areas such as
policy alignment, resource management, adaptability to non-
stationary environments, scalability, and energy efﬁciency.
This integration, while showcasing promising potential, also
highlights areas for further research and development. Future
work can focus on reﬁning the computational efﬁciency of
implementing OT in large-scale MARL systems and explor-
ing real-world applications in greater depth. By continuing
to explore this integration, we aim to make MARL systems
more adaptable, efﬁcient, and capable of handling complex
real-world tasks.
REFERENCES
[1] S. V. Albrecht, F. Christianos, and L. Sch¨afer, Multi-Agent Reinforce-
ment Learning: Foundations and Modern Approaches.
MIT Press,
2024.
[2] A. Wong, T. B¨ack, A. V. Kononova, and A. Plaat, “Deep multiagent
reinforcement learning: Challenges and directions,” Artiﬁcial Intelli-
gence Review, vol. 56, no. 6, pp. 5023–5056, 2023.
[3] C. Villani et al., Optimal transport: old and new.
Springer, 2009.
[4] G. Peyr´e, M. Cuturi et al., “Computational optimal transport: With
applications to data science,” Foundations and Trends® in Machine
Learning, vol. 11, no. 5-6, pp. 355–607, 2019.
[5] L. V. Kantorovich, “On the translocation of masses,” Journal of
Mathematical Sciences, vol. 133, no. 4, pp. 1381–1382, 2006.
[6] S. T. Rachev and L. R¨uschendorf, Mass Transportation Problems:
Volume I: Theory.
Springer Science & Business Media, 1998, vol. 1.
[7] A. Galichon, “The unreasonable effectiveness of optimal transport in
economics,” HAL, Tech. Rep., 2021.
[8] ——, “A survey of some recent applications of optimal transport
methods to econometrics,” The Econometrics Journal, vol. 20, no. 2,
pp. C1–C11, 2017.
[9] N. Bonneel and J. Digne, “A survey of optimal transport for computer
graphics and computer vision,” in Computer Graphics Forum, vol. 42,
no. 2, 2023, pp. 439–460.
[10] C. Wen, “Conformal geometry and optimal transport for computer
vision and geometric modeling,” Ph.D. dissertation, State University
of New York at Stony Brook, 2020.
[11] J. Delon, A. Desolneux, L. Facq, and A. Leclaire, “Optimal transport
between gmm for multiscale texture synthesis,” in International Con-
ference on Scale Space and Variational Methods in Computer Vision.
Springer, 2023, pp. 627–638.
[12] J. Rabin, G. Peyr´e, J. Delon, and M. Bernot, “Wasserstein barycenter
and its application to texture mixing,” in Third International Confer-
ence on Scale Space and Variational Methods in Computer Vision.
Springer, 2012, pp. 435–446.
[13] Y. Balaji, R. Chellappa, and S. Feizi, “Robust optimal transport with
applications in generative modeling and domain adaptation,” Advances
in Neural Information Processing Systems, vol. 33, pp. 12 934–12 944,
2020.
[14] R. Flamary, N. Courty, D. Tuia, and A. Rakotomamonjy, “Optimal
transport for domain adaptation,” IEEE Trans. Pattern Anal. Mach.
Intell, vol. 1, no. 1-40, p. 2, 2016.
[15] E. F. Montesuma, F. N. Mboula, and A. Souloumiac, “Recent ad-
vances in optimal transport for machine learning,” arXiv preprint
arXiv:2306.16156, 2023.
[16] I. Redko, N. Courty, R. Flamary, and D. Tuia, “Optimal transport
for multi-source domain adaptation under target shift,” in The 22nd
International Conference on Artiﬁcial Intelligence and Statistics, 2019,
pp. 849–858.
[17] A. Baheri, “Risk-aware reinforcement learning through optimal trans-
port theory,” arXiv preprint arXiv:2309.06239, 2023.
[18] S. Chakraborty, A. S. Bedi, A. Koppel, D. Manocha, H. Wang,
F. Huang, and M. Wang, “Aligning agent policy with externalities:
Reward design via bilevel RL,” arXiv preprint arXiv:2308.02585,
2023.
[19] J. Foerster, I. A. Assael, N. De Freitas, and S. Whiteson, “Learning to
communicate with deep multi-agent reinforcement learning,” Advances
in Neural Information Processing Systems, vol. 29, 2016.
[20] Y. Hong, Y. Jin, and Y. Tang, “Rethinking individual global max in
cooperative multi-agent reinforcement learning,” Advances in Neural
Information Processing Systems, vol. 35, pp. 32 438–32 449, 2022.
[21] T. Ikeda and T. Shibuya, “Centralized training with decentralized
execution reinforcement learning for cooperative multi-agent systems
with communication delay,” in 61st Annual Conference of the Society
of Instrument and Control Engineers (SICE), 2022, pp. 135–140.
[22] L. M. Schmidt, J. Brosig, A. Plinge, B. M. Eskoﬁer, and C. Mutschler,
“An introduction to multi-agent reinforcement learning and review of
its application to autonomous mobility,” in IEEE 25th International
Conference on Intelligent Transportation Systems (ITSC), 2022, pp.
1342–1349.
[23] H. Talebiyan and L. Due˜nas-Osorio, “Auctions for resource allocation
and decentralized restoration of interdependent networks,” Reliability
Engineering & System Safety, vol. 237, p. 109301, 2023.
[24] M. Braquet and E. Bakolas, “Greedy decentralized auction-based
task allocation for multi-agent systems,” IFAC-PapersOnLine, vol. 54,
no. 20, pp. 675–680, 2021.
[25] F. Li, Z. Xu, and H. Li, “A multi-agent based cooperative approach
to decentralized multi-project scheduling and resource allocation,”
Computers & Industrial Engineering, vol. 151, p. 106961, 2021.
[26] C. Lu, Q. Bao, S. Xia, and C. Qu, “Centralized reinforcement learning
for multi-agent cooperative environments,” Evolutionary Intelligence,
pp. 1–7, 2022.
[27] R. Bokade, X. Jin, and C. Amato, “Multi-agent reinforcement learning
based on representational communication for large-scale trafﬁc signal
control,” IEEE Access, vol. 11, pp. 47 646–47 658, 2023.
[28] J. Gielis, A. Shankar, and A. Prorok, “A critical review of commu-
nications in multi-robot systems,” Current Robotics Reports, vol. 3,
no. 4, pp. 213–225, 2022.
[29] P. Hernandez-Leal, B. Kartal, and M. E. Taylor, “Is multiagent deep
reinforcement learning the answer or the question? a brief survey,”
Learning, vol. 21, p. 22, 2018.
[30] R. Lowe, Y. I. Wu, A. Tamar, J. Harb, O. Pieter Abbeel, and I. Mor-
datch, “Multi-agent actor-critic for mixed cooperative-competitive
environments,” Advances in Neural Information Processing Systems,
vol. 30, 2017.
[31] H. Kao, C.-Y. Wei, and V. Subramanian, “Decentralized cooperative
reinforcement learning with hierarchical information structure,” in
International Conference on Algorithmic Learning Theory, 2022, pp.
573–605.
[32] Y. Li, X. Wang, J. Wang, W. Wang, X. Luo, and S. Xie, “Cooperative
multi-agent reinforcement learning with hierarchical relation graph
under partial observability,” in IEEE 32nd International Conference
on Tools with Artiﬁcial Intelligence (ICTAI), 2020, pp. 1–8.
[33] Y. Du, C. Ma, Y. Liu, R. Lin, H. Dong, J. Wang, and Y. Yang, “Scal-
able model-based policy optimization for decentralized networked
systems,” in IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS), 2022, pp. 9019–9026.
[34] H. Gu, X. Guo, X. Wei, and R. Xu, “Mean-ﬁeld multi-agent reinforce-
ment learning: A decentralized network approach,” Decision-Making
in Operations Research eJournal, 2021.
[35] Y. Mai, Y. Zang, Q. Yin, W. Ni, and K. Huang, “Deep multi-task
multi-agent reinforcement learning with knowledge transfer,” IEEE
Transactions on Games, 2023.
[36] T. Wang, X. Peng, Y. Jin, and D. Xu, “Experience sharing based
memetic transfer learning for multiagent reinforcement learning,”
Memetic Computing, vol. 14, no. 1, pp. 3–17, 2022.
[37] H. Shi, J. Li, J. Mao, and K.-S. Hwang, “Lateral transfer learning for
multiagent reinforcement learning,” IEEE Transactions on Cybernet-
ics, vol. 53, no. 3, pp. 1699–1711, 2023.
[38] W. Liang, J. Wang, W. Bao, X. Zhu, Q. Wang, and B. Han, “Con-
tinuous self-adaptive optimization to learn multi-task multi-agent,”
Complex & Intelligent Systems, vol. 8, no. 2, pp. 1355–1367, 2022.
[39] L. Luan, Y. Tian, W. Fang, C. Zhang, W. Xue, R. Chen, and C. Sang,
“MARL for trafﬁc signal control in scenarios with different intersec-
tion importance,” in Third International Conference on Distributed
Artiﬁcial Intelligence.
Springer, 2022, pp. 93–106.
[40] T. Wang, T. Liang, J. Li, W. Zhang, Y. Zhang, and Y. Lin, “Adaptive
trafﬁc signal control using distributed marl and federated learning,”
in IEEE International Conference on Communication Technology
(ICCT), 2020, pp. 1242–1248.
[41] C. Gavriluta, C. Boudinet, F. Kupzog, A. Gomez-Exposito, and
R. Caire, “Cyber-physical framework for emulating distributed control
systems in smart grids,” International Journal of Electrical Power &
Energy Systems, vol. 114, p. 105375, 2020.
[42] O. P. Mahela, M. Khosravy, N. Gupta, B. Khan, H. H. Alhelou,
R. Mahla, N. Patel, and P. Siano, “Comprehensive overview of multi-
agent systems for controlling smart grids,” CSEE Journal of Power
and Energy Systems, vol. 8, no. 1, pp. 115–131, 2020.
[43] F. Charbonnier, T. Morstyn, and M. D. McCulloch, “Scalable multi-
agent reinforcement learning for distributed control of residential
energy ﬂexibility,” Applied Energy, vol. 314, p. 118825, 2022.
[44] X. Ye, Z. Deng, Y. Shi, and W. Shen, “Toward energy-efﬁcient routing
of multiple agvs with multi-agent reinforcement learning,” Sensors,
vol. 23, no. 12, p. 5615, 2023.
[45] M. Sahraoui, A. Bilami, and A. Taleb-Ahmed, “Schedule-based coop-
erative multi-agent reinforcement learning for multi-channel commu-
nication in wireless sensor networks,” Wireless Personal Communica-
tions, vol. 122, no. 4, pp. 3445–3465, 2022.
[46] Y. Liang, H. Wu, and H. Wang, “Asynchronous multi-agent reinforce-
ment learning for collaborative partial charging in wireless recharge-
able sensor networks,” IEEE Transactions on Mobile Computing, pp.
1–13, 2023.
[47] W. Yang, C. Lin, H. Dai, P. Wang, J. Ren, L. Wang, G. Wu, and
Q. Zhang, “Robust wireless rechargeable sensor networks,” IEEE/ACM
Transactions on Networking, vol. 31, no. 3, pp. 949–964, 2023.
[48] Y. Qi, P. Cheng, J. Bai, J. Chen, A. Guenard, Y.-Q. Song, and
Z. Shi, “Energy-efﬁcient target tracking by mobile sensors with limited
sensing range,” IEEE Transactions on Industrial Electronics, vol. 63,
no. 11, pp. 6949–6961, 2016.
[49] S. Su, X. Wang, T. Tang, G. Wang, and Y. Cao, “Energy-efﬁcient
operation by cooperative control among trains: A multi-agent rein-
forcement learning approach,” Control Engineering Practice, vol. 116,
p. 104901, 2021.
[50] Y. Xiao, Y. Song, and J. Liu, “Collaborative multi-agent deep re-
inforcement learning for energy-efﬁcient resource allocation in het-
erogeneous mobile edge computing networks,” IEEE Transactions on
Wireless Communications, pp. 1–1, 2023.
[51] M. Hua, Q. Zhou, C. Zhang, H. Xu, and W. Liu, “Multi-agent deep
reinforcement learning for charge-sustaining control of multi-mode
hybrid vehicles,” arXiv preprint arXiv:2209.02633, 2022.
[52] Y. Zhang, Q. Yang, D. An, D. Li, and Z. Wu, “Multistep multiagent
reinforcement learning for optimal energy schedule strategy of charg-
ing stations in smart grid,” IEEE Transactions on Cybernetics, vol. 53,
no. 7, pp. 4292–4305, 2023.
[53] T. Li, K. Zhu, N. C. Luong, D. Niyato, Q. Wu, Y. Zhang, and B. Chen,
“Applications of multi-agent reinforcement learning in future internet:
A comprehensive survey,” IEEE Communications Surveys & Tutorials,
vol. 24, no. 2, pp. 1240–1279, 2022.
[54] J. Fan, I. Haasler, J. Karlsson, and Y. Chen, “On the complexity of the
optimal transport problem with graph-structured cost,” in International
Conference on Artiﬁcial Intelligence and Statistics, 2022, pp. 9147–
9165.
[55] C. Clason, D. A. Lorenz, H. Mahler, and B. Wirth, “Entropic reg-
ularization of continuous optimal transport problems,” Journal of
Mathematical Analysis and Applications, vol. 494, no. 1, p. 124432,
2021.
[56] J. Lee, M. Dabagia, E. Dyer, and C. Rozell, “Hierarchical optimal
transport for multimodal distribution alignment,” Advances in Neural
Information Processing Systems, vol. 32, 2019.
"
"Emotion recognition is important for human-robot interaction, but current methods often ignore the context of emotions. We introduce SCAM, a self context-aware emotion perception model that employs a two-dimensional emotion coordinate system for anchoring and re-labeling distinct emotions. It incorporates a distinctive information retention structure and contextual loss, resulting in significant improvements across audio, video, and multimodal modalities.nan","Human-robot interaction requires natural and intuitive communication, which includes the robot's ability to understand human emotions. Current emotion recognition models primarily focus on multimodal perception, but often overlook contextual information. This is problematic because emotions in real-life conversations often display a sense of continuity, meaning emotions do not undergo abrupt and dramatic shifts within a brief timeframe. As a result, when emotions cannot be ascertained, humans often depend on contextual information to make judgments. Hence, we propose self context-aware model (SCAM) that enables a robot to perform emotion recognition on the user while simultaneously considering the user’s preceding emotional context and integrating it with the robot’s recognition results from the preceding context. This enhances the overall accuracy and comprehensiveness of the robot’s emotion recognition abilities during human-robot interactions.nan","Emotion recognition is a complex process involving various perceptual dimensions and temporal aspects. Researchers have explored different modalities, such as visual, auditory, physical, and even EEG and skin conductance signals, for emotion recognition. Combining information from diverse modalities typically yields enhanced accuracy. Some studies emphasize the intricacy of emotion recognition when information conflicts arise between modalities. Additionally, researchers suggest that better results can be achieved by capturing contextual information within conversations. However, considering that during human-robot interaction, the robot may struggle to provide sufficient feedback, we propose a method to utilize self context.nannan","SCAM consists of two main components: a multi-task network for each segment and a self context-aware structure for composition. The multi-task network relabels emotions and utilizes ResNet101 and Bi-LSTM to recognize emotion, valence, and arousal within a short time. The self context-aware structure incorporates contextual information propagation and context loss, combining the context information and predictions from preceding segments with the current input to predict the current emotion, valence, and arousal.nan","In the auditory modality, there has been a notable enhancement in accuracy, rising from 63.10% to 72.46%. Similarly, the visual modality has demonstrated improved accuracy, increasing from 77.03% to 80.82%. In the multimodal, accuracy has experienced an elevation from 77.48% to 78.93%.nan","Our approach achieves significant improvements across all modalities, some of which have reached the state of the art. In future work, we will validate the reliability and usability of SCAM on robots through psychology experiments.nan",Self context-aware emotion perception on human-robot interaction,"Zihan Lin, Francisco Cruz, Eduardo Benitez Sandoval","Cite as: Zihan Lin, Francisco Cruz, and Eduardo Benitez Sandoval. Self context-aware emotion perception on human-robot
interaction. In Proceedings of the Australasian Conference on Robotics and Automation (ACRA). 2023.
Self context-aware emotion perception on human-robot interaction
Zihan Lin1, Francisco Cruz1,2, Eduardo Benitez Sandoval3
1School of Computer Science and Engineering, University of New South Wales, Sydney, Australia
2Escuela de Ingenier´ıa, Universidad Central de Chile, Santiago, Chile
3School of Art and Design, Creative Robotics Lab, University of New South Wales, Sydney, Australia
Emails: zihan.lin3@student.unsw.edu.au, f.cruz@unsw.edu.au, e.sandoval@unsw.edu.au
Abstract
Emotion recognition plays a crucial role in
various domains of human-robot interaction.
In long-term interactions with humans, robots
need to respond continuously and accurately,
however, the mainstream emotion recognition
methods mostly focus on short-term emotion
recognition, disregarding the context in which
emotions are perceived. Humans consider that
contextual information and different contexts
can lead to completely different emotional ex-
pressions.
In this paper, we introduce self
context-aware model (SCAM) that employs a
two-dimensional emotion coordinate system for
anchoring and re-labeling distinct emotions. Si-
multaneously, it incorporates its distinctive in-
formation retention structure and contextual
loss.
This approach has yielded significant
improvements across audio, video, and multi-
modal.
In the auditory modality, there has
been a notable enhancement in accuracy, rising
from 63.10% to 72.46%. Similarly, the visual
modality has demonstrated improved accuracy,
increasing from 77.03% to 80.82%. In the mul-
timodal, accuracy has experienced an elevation
from 77.48% to 78.93%. In the future, we will
validate the reliability and usability of SCAM
on robots through psychology experiments.
1
Introduction
Human-robot interaction has become increasingly im-
portant due to the widespread use of robots in various
applications such as manufacturing, healthcare, and per-
sonal assistance [Kyrarini et al., 2021]. Human-robot in-
teraction focuses on how humans and robots can safely
and effectively collaborate, requiring natural and intu-
itive communication between them. To achieve better
communication, it is crucial for robots to understand hu-
man emotions; otherwise, they may respond incorrectly,
leading humans to reject interacting with the robots
[Tsiourti et al., 2019]. However, emotion recognition is
a complex process, involving various perceptual dimen-
sions and temporal aspects. Current emotion recognition
models primarily focus on multimodal perception but of-
ten overlook contextual information [Poria et al., 2019].
In real-life conversational contexts, emotional fluctua-
tions in individuals often display a sense of continuity.
This implies that, under typical circumstances, emotions
do not undergo abrupt and dramatic shifts within a
brief timeframe, such as sudden transitions from intense
anger to extreme happiness. Consequently, when emo-
tions cannot be ascertained, humans frequently depend
on contextual information to make judgments [Sacharin
et al., 2012]. Practically, there is often a requirement to
rely exclusively on preceding contextual information.
Therefore, this paper introduces self context-aware
model (SCAM), enabling a robot to perform emotion
recognition on the user while simultaneously considering
the user’s preceding emotional context and integrating it
with the robot’s recognition results from the preceding
context. This approach allows for a more comprehen-
sive and accurate assessment of the user’s emotion state
during human-robot interactions.
The contributions of this work are summarized as fol-
lows:
• We utilize the relationship between valence, arousal,
and emotion to enable the model to learn basic emo-
tions from non-basic ones.
• We introduce a novel contextual loss, incorporating
the model’s predictions of context emotion, valence,
and arousal, allowing the model to more effectively
capture emotional change trends.
• We model the information transfer within the con-
text, preserving valuable features from the preced-
ing context for integration and judgment when mak-
ing predictions for the subsequent context.
• We conduct experiments on the IEMOCAP dataset,
encompassing speech modality, visual modality, and
arXiv:2401.10946v1  [cs.HC]  18 Jan 2024
multimodal scenarios.
The experimental results
demonstrate that our approach achieves significant
improvements across all modalities, some of which
have reached the state of the art.
2
Related work
The application of emotion recognition spans a wide
range of domains, including its deployment in various
human-computer interaction scenarios and chatbot sys-
tems designed to generate emotionally rich dialogues
[Zhou et al., 2018].
Nevertheless, this field is fraught
with numerous challenges. For instance, individuals ex-
periencing mental distress may be reluctant to unveil
their vulnerabilities, often concealing their true emo-
tional states [Maithri et al., 2022].
Consequently, re-
searchers have delved extensively into the realm of emo-
tion recognition, exploring various modalities such as vi-
sual, auditory, physical, and even the incorporation of
EEG and skin conductance signals [Li et al., 2022]. Typi-
cally, amalgamating information from diverse modalities
yields enhanced accuracy in emotion recognition [Wu et
al., 2022]. Notably, the fusion of speech and text modali-
ties achieved a remarkable accuracy rate of 80.51% (four
categories) on the IEMOCAP dataset [Atmaja et al.,
2022].
However, some studies [Tsiourti et al., 2019] under-
score the intricacy of emotion recognition when infor-
mation conflicts arise between modalities.
Further-
more, some researchers suggested that better results
can be achieved by capturing contextual information
within conversations.[Priyasad et al., 2020] employed
graph neural networks to model inter-dialogue relation-
ships, achieving commendable performance.
They in-
troduced an iterative emotion interaction network that
employs iteratively predicted emotion labels to explicitly
model emotion interactions, culminating in an accuracy
of 64.37% (seven categories) on the IEMOCAP dataset.
Compared to providing a dialogue-based approach, we
take into consideration that during human-robot inter-
action, the robot may struggle to provide sufficient feed-
back.
Therefore, we propose a method to utilize self
context.
Another pivotal dimension of research in emotion
recognition is the exploration of dimensional emotion
models. In contrast to discrete emotion models, valence-
arousal model [Russell, 1980] offers a better understand-
ing of the intricate relationships among different emo-
tional states.
Research demonstrated that combining
valence, arousal, dominance, and the polarity of emo-
tions within a multi-view training framework can yield
superior results [Tompkins et al., 2023]. However, the
current use of dimensional models has not effectively
leveraged the continuity of dimensional models in emo-
tional expression, failing to fully exploit their advan-
tages. In comparison to discrete emotion models, dimen-
sional models can better observe the trend of emotional
changes. In our approach, we make the first attempt to
utilize this aspect and have achieved excellent results.
3
Methods
During the process of human-robot interaction, long-
lasting sessions can be divided into multiple segments,
and they may vary with their own context and the
robot’s responses.
The emotions in each segment are
relatively independent, with a correlation observed be-
tween adjacent segments due to the continuous nature
of human emotions. Therefore, we group some adjacent
segments into a composition (Figure 1). By using SCAM
to capture this correlation, we achieve better emotion
perception results.
Figure 1: Context interaction in HRI
SCAM consists of two main components: a multi-task
network for each segment and a self context-aware struc-
ture for composition. The multi-task network relabels
emotions and then utilizes ResNet101 and Bi-LSTM to
recognize emotion, valence, and arousal within a short
time. The self context-aware structure incorporates con-
textual information propagation and context loss, com-
bining the context information and predictions from pre-
ceding segments with the current input to predict the
current emotion, valence, and arousal. In the following
sections, we will provide further details on these compo-
nents.
3.1
Dataset
Considering there is currently no publicly available and
suitable human-robot interaction dataset, we conduct
model training and validation on IEMOCAP dataset
[Busso et al., 2008], which comprises 10,039 instances
performed by 10 actors. These actors are paired, and
each pair engages in multiple scripted and spontaneous
emotional dialogues, which are appropriate for the simu-
lation of human-robot interaction. Throughout these di-
alogues, they portray 10 predefined emotional states: an-
gry, sad, happy, neutral, disgust, surprise, fear, excited,
other, and unmarked.
Each emotional state includes
multiple sentences and encompasses various modalities,
including audio, video, text, and more.
Emotion
Number of Samples
Rate (%)
Anger
1103
24.57
Happy
595
13.25
Neutral
1708
38.04
Sadness
1084
24.14
Total
4490
100.00
Table 1: IEMOCAP: Four Emotions
• Frame Segmentation: Divide the audio signal into
small segments,
• Windowing: Apply a window function to each frame
to reduce the impact of spectral leakage.
• Fourier Transform:
Apply the Discrete Fourier
Transform (DFT) to each window, transforming the
time-domain signal into a frequency-domain signal.
• Magnitude and Squaring: Compute the amplitude
spectrum for each frequency component, often by
taking the magnitude of the complex values.
• Visualization: Display the obtained spectral infor-
mation as an image, with the horizontal axis rep-
resenting time, the vertical axis representing fre-
quency, and color or brightness representing ampli-
tude.
Four emotions (angry, happy, neutral, and sad) and
two modalities (auditory and visual) in IEMOCAP are
used to verify our approach in order to compare with
other methods, as shown in Table 1. Emotions are anno-
tated using two mainstream approaches. One approach
considers emotions as fixed labels, where each emotion
is treated as a category such as angry, happy, sad, or
neutral. Each sample is assigned only one emotion la-
bel, representing a specific emotion category. The other
approach [Russell, 1980] involves emotion dimensions,
where each sample has two labels annotated with valence
and arousal. Valence represents one dimension of emo-
tion (e.g., emotional intensity), and arousal represents
another dimension (e.g., positivity and negativity). This
approach better captures complex emotional changes, as
emotions can be regarded as points in an emotion space
rather than single categories.
We calculate the mean of valence and arousal as coor-
dinates for each emotion in the emotion space, as shown
in Figure 2.
Within the same composition, emotions
tend to undergo a transition and be closer to the emotion
of the current segment (the last segment in the compo-
sition). Capturing such contextual emotion changes can
improve the continuity and accuracy of emotion percep-
tion.
Frame Segmentation:
Divide the audio signal into
small segments, Windowing: Apply a window function
to each frame to reduce the impact of spectral leakage.
Fourier Transform: Apply the Discrete Fourier Trans-
form (DFT) to each window, transforming the time-
domain signal into a frequency-domain signal. Magni-
tude and Squaring: Compute the amplitude spectrum
for each frequency component, often by taking the mag-
nitude of the complex values.
Visualization: Display
the obtained spectral information as an image, with the
horizontal axis representing time, the vertical axis rep-
resenting frequency, and color or brightness representing
amplitude.
Figure 2: IEMOCAP emotions on Valence-Arousal axis
3.2
Multi-task network
Preprocessing
For different modalities of input, we employ distinct pre-
processing methods. For the auditory modality, we con-
vert speech into log-Mel spectrograms as input. Com-
pared to one-dimensional audio signals, log-Mel spectro-
grams better represent crucial features in speech signals,
such as formants and harmonic structures, enhancing the
accuracy of emotion perception. The log-Mel spectro-
grams are generated with a sampling rate of 22050Hz
and utilize 256 Mel filters.
An example of a log-Mel
spectrogram generated from a single segment is shown
in Figure 3.
For the visual modality, considering the short dura-
tion of each segment and the limited facial expression
changes, three frames are recorded. We extract the start,
intermediate, and end frames from the corresponding
video segments and crop the facial regions (Figure 4).
The intermediate frame is calculated using the start and
end times of each segment.
Figure 3: Log-Mel spectrogram of one segment
Figure 4: Cropped frames of one segment
Segment structure
ResNet101 is utilized for feature extraction. After the
ResNet101, high-level features are fed into a Bi-LSTM to
capture temporal information. For the auditory modal-
ity, high-level features are extracted after Conv4 x. For
the visual modality, the three frames are separately fed
into ResNet101, and after Conv5 x, they are concate-
nated and passed to the Bi-LSTM. In the case of multi-
modal data, feature alignment and concatenation occur
before input to the Bi-LSTM. The Bi-LSTM’s output
is then split into three fully connected neural network
(FCN), responsible for emotion classification, valence re-
gression, and arousal regression, as shown in Figure 5.
Figure 5: Segment structure (multimodal)
Segment Relabeling
In the context of our contextual emotion model, each
composition comprises multiple segments, and our objec-
tive is to predict the emotion of the last segment in each
composition (the emotion at the current time). Given
that emotions tend to exhibit relatively small variations
within a composition, we select the emotion of the last
segment as the emotion label for the entire composition,
while valence and arousal remain unchanged, as shown in
Table 2. This approach offers two advantages. Firstly, it
effectively leverages data from emotion labels other than
the four basic emotions, enriching the dataset. Secondly,
one segment’s emotion may lead to different current emo-
tions in different compositions. In the following section,
we will explain how we utilize this feature.
Segment
Emotion
Valence
Arousal
Relabel
11
Angry
1.5
4
Angry
12
Frustrated
1.5
4
Angry
13
Angry
1.5
4.5
Angry
Table 2: Relabel of composition
Loss in segment
Due to the relabeling of emotions for segments within
each composition, in most cases, relabeled emotions
closely match or are similar to the original emotions,
owing to the continuity of emotions. However, there are
instances where inconsistencies in emotions arise.
As
mentioned before, we compute the average valence and
arousal for different emotions, serving as reference points
on the two-dimensional emotion coordinate system. Si-
multaneously, we retain the original valence and arousal
labels for each segment. Therefore, we utilize the Eu-
clidean distance to measure the distance between the re-
labeled emotions and the original emotions and scale the
emotion loss accordingly, as indicated by the following
formula:
Lemo = −R · 1
N
N
X
i=1
4
X
j=1
yij log(p(yij)),
which N represents the number of samples, yij denotes
the actual emotion labels, and p(yij) represents the pre-
dicted probabilities of emotions by the model.
R is defined as:
R =
1
p
(xemo − xseg)2 + (yemo − yseg)2 .
xemo and yemo represent the valence and arousal of the
relabel emotion (e.g., xemo and yemo of anger), and xseg
and yseg represent the label of valence and arousal of the
segment.
For valence and arousal regression use mean squared
error, the formulas are as follows,
Lval = 1
N
N
X
i=1
(xseg − ˆxseg)2,
Laro = 1
N
N
X
i=1
(yseg − ˆyseg)2,
which ˆxseg and ˆyseg represent the prediction of valence
and arousal seperately.
3.3
Self context-aware structure
Self context-aware structure is the core optimization
component of our model, primarily consisting of two
parts: contextual information propagation and context
loss.
Through these components, we achieve the per-
ception of current emotion with the aid of contextual
information. The procedure is shown in Figure 6.
Figure 6: Context-aware structure
Contextual Information Propagation
Assume that the features processed by ResNet101 are
denoted as {x(1)
1 , x(1)
2 , . . .}, where x(1)
i
represents the
features of the i-th part in the first segment, and
{x(2)
1 , x(2)
2 , . . .} represents the features of the second seg-
ment, and so on.
The output of the Bi-LSTM can be represented as
{h(1)
1 , h(1)
2 , . . .}, where h(1)
i
denotes the output of the Bi-
LSTM at the i-th time step in the first segment, and
{h(2)
1 , h(2)
2 , . . .} represents the output of the Bi-LSTM
in the second segment, and so forth.
Since the Bi-
LSTM is bidirectional, each h(j)
i
contains both forward
and backward propagation information and is typically
represented as h(j)
i
= [
−−→
h(j)
i ,
←−−
h(j)
i ], where
−−→
h(j)
i
represents
the forward propagation output, and
←−−
h(j)
i
represents the
backward propagation output.
Next, for each segment, we extend the output of the
last time step to have the same dimensions as the input
features for the LSTM time steps.
This extension is
represented as:
h(j)
ext = U · [
−−→
h(j)
−1,
←−−
h(j)
−1],
which h(j)
ext represents the extended output, and U de-
notes an upsampling layer.
−−→
h(j)
−1 represents the output of
the last time step in the forward propagation for the j-th
segment, and
←−−
h(j)
−1 represents the output of the last time
step in the backward propagation for the j-th segment.
Finally, we concatenate the extended output with all
other features in the next segment, which is represented
as:
X(j+1) = [h(j)
ext, x(j+1)
1
, x(j+1)
2
, . . .],
which X(j+1) represents the input for the Bi-LSTM in
the next segment, h(j)
ext is the extended output from the
current segment, and x(j+1)
1
, x(j+1)
2
, . . . are all the input
features in the next segment.
In this way, the model can utilize high-dimensional
emotional information from the previous segment to bet-
ter understand the emotions in the current segment.
Context Loss
The context loss is employed to capture emotional vari-
ations between adjacent segments.
We represent the
valence and arousal of each segment within a composi-
tion on a two-dimensional emotion coordinate system,
as illustrated in Figure 2.
The vectors formed be-
tween consecutive segments depict the trends in emo-
tional changes. We measure the distance between the
predicted vectors and actual vectors using cosine simi-
larity, thus forming the context loss, as shown below:
Lcontext =
vij
pre · vij
label
∥vij
pre∥ · ∥vij
label∥
, where j − i = 1.
i represents the ith segment, j represents the jth seg-
ment, and j − i = 1 denotes adjacent segments.
The following notations are used: (xi
pre, yi
pre) denotes
the predicted coordinates of the valence and arousal for
the ith segment. (xj
pre, yj
pre) denotes the predicted coor-
dinates of the valence and arousal for the jth segment.
(xi
label, yi
label) denotes the true coordinates of the valence
and arousal for the ith segment. (xj
label, yj
label) denotes
the true coordinates of the valence and arousal for the
jth segment.
Since j − i = 1, we can form two vectors : vij
pre =
(xj
pre−xi
pre, yj
pre−yi
pre), representing the predicted emo-
tion change from i to j. vij
label = (xj
label − xi
label, yj
label −
yi
label), representing the labeled emotion change from i
to j. As shown in Figure 7, in which orange points rep-
Figure 7: Context loss in valence-arousal axis
resent label valence and arousal and the grey points rep-
resent predict valence and arousal, SCAM can learn the
trend through context loss.
If the cosine similarity is
close to 1, it indicates that vij
pre and vij
label have simi-
lar directions, which means that the model’s predictions
are in line with the true labels. If the cosine similarity is
close to -1, it indicates that vij
pre and vij
label have opposite
directions, which means that there is a large deviation
between the predictions and the true labels, indicating
that the model does not capture the trend in the context
effectively.
4
Experiments
4.1
Results
Due to the random selection of the test dataset (10% of
IEMOCAP of four emotions), some segments have dis-
continuous context. In such cases, we replicate the cur-
rent segment as a substitute for the missing context. We
compare the results of the auditory modality (A-SCAM),
visual modality (V-SCAM), and multimodal (M-SCAM)
with the following baselines, as shown in Table 3.
In the auditory modality, SCAM achieves an accuracy
of 72.46%, in the visual modality, it reaches the highest
accuracy of 80.82%, and in the multimodal, it achieves
an accuracy of 78.93%.
Though the multimodal per-
Figure 8: Confusion matrix of A-SCAM
Figure 9: Confusion matrix of V-SCAM
formance is slightly inferior, SCAM achieves results su-
perior to the baseline in both the auditory and visual
modalities.
The corresponding confusion matrices for
different modalities are shown in Figure 8, Figure 9, and
Figure 10. In general, the visual modality performs bet-
ter overall than the auditory modality, and the accuracy
in recognizing the happy emotion is significantly higher
in the visual modality.
Figure 10: Confusion matrix of M-SCAM
4.2
Analysis
Efficiency of context loss
We also evaluate the results when the loss is minimized
on the test set, as shown in Table 4.
In our experiments, a difference in the trends of accu-
racy and loss is observed. The lowest loss occurrs signif-
icantly earlier than the highest accuracy. In the case of
a single segment, this difference is primarily influenced
by the multitask loss. Although valence and arousal are
simultaneously predicted, the primary task remains emo-
tion classification. Therefore, loss and accuracy may not
be entirely correlated. For SCAM, the loss composition
becomes more complex. It includes context loss due to
the relabeling process and the necessity to predict the
emotion of preceding segments in order to predict the
current emotion.
This context loss may not necessar-
ily reflect the current emotion and may even conflict
with the current emotion, valence, and arousal.
Tak-
ing the auditory modality as an example, even though
the total loss (Figure 11) on the test set fluctuates and
even increases, the context loss (Figure 12) consistently
decreases. This indicates that the model is effectively
learning the contextual relationships of emotions, result-
ing in improved emotion classification results, as shown
in Figure 13
Ablation Study
In the case of using only a single segment, where emo-
tional loss is not scaled and there is no self-context-aware
Figure 11: Test loss of auditory modality
Figure 12: Test loss context of auditory modality
Figure 13: Test accuracy of emotion of auditory modality
Model
Train/Predict
Modality
Emotion (UA)
Valence
Arousal
Prior Work
Audio-CNN-xvector[Peng et al., 2021]
Emo
A
68.40
-
-
SVM[Tompkins et al., 2023]
V/A, Emo
A
68.23
-
-
w2v2-b[Tompkins et al., 2023]
V/A/D, Emo
A
61.20
47.80
60.50
MMAN[Pan et al., 2020]
Emo
A+V+T
73.94
-
-
AV-ITN[Fu et al., 2022]
Emo
A+V
81.66
-
-
Proposed Work
A-SCAM
V/A, Emo
A
72.46
53.18
67.78
V-SCAM
V/A, Emo
V
80.82
60.09
59.09
M-SCAM
V/A, Emo
A+V
78.93
59.87
68.78
Table 3: Performance comparison of prior work and SCAM
Model
Emotion (UA)
Valence
Arousal
A-SCAM
60.98
49.50
64.33
V-SCAM
78.48
61.20
58.19
M-SCAM
76.48
57.64
69.01
Table 4: Performance at lowest test loss
structure, we compare the auditory modality (A-SEG),
visual modality (V-SEG), and multimodal approach (M-
SEG) with SCAM. The results are presented in Table 5.
Model
Emotion (UA)
Valence
Arousal
A-SEG
63.10
52.29
66.22
A-SCAM
72.46
53.18
67.78
V-SEG
77.03
59.2
59.31
V-SCAM
80.82
60.09
59.09
M-SEG
77.48
56.63
66.89
M-SCAM
78.93
59.87
68.78
Table 5: Ablation experiments of SCAM
It can be observed that, with the application of
SCAM, the performance of the auditory modality im-
proves by 9.36%, the visual modality improves by 3.79%,
and the multimodal approach improves by 1.45%. This
further demonstrates the effectiveness of SCAM across
different modalities. Furthermore, in Figure 14, visual-
ization of a composition highlights SCAM’s remarkable
contextual awareness, independent of the consistency in
contextual labels. Even when the context undergoes con-
tinuous changes, SCAM correctly identifies emotions.
Figure 14: Sample of test composition
Multimodal
In general, multimodal performance is expected to sur-
pass unimodal performance.
However, in our experi-
ments, the multimodal performance is not superior to
the unimodal performance. Therefore, we conduct fur-
ther analysis of the classification results for the auditory
and visual modalities. In the confusion matrix in Fig-
ure 15, the elements on the diagonal represent correct
classification by A-SCAM but incorrect classification by
V-SCAM. The remaining entries indicate how V-SCAM
incorrectly classifies emotions into different categories.
Similarly, in Figure 16, we represent cases where V-
SCAM classifies emotions correctly but A-SCAM clas-
sifies them incorrectly.
It can be observed that the visual modality is better
at recognizing happy, while neutral and angry have a
considerable number of correctly classified samples in-
dependently by both modalities. This suggests that the
two modalities obtain different features for neutral and
angry emotions. In some cases, the auditory modality in-
correctly identifies angry as neutral and neutral as angry,
but the visual modality correctly identifies them, and
vice versa. Furthermore, both modalities’ primary errors
are concentrated in misclassifying some other emotions
as neutral, and samples misclassified as neutral differ
significantly. Based on the error distribution, the errors
made by both modalities are quite similar.
Figure 15: A-SCAM correct, but V-SCAM wrong
Figure 16: V-SCAM wrong, but A-SCAM correct
5
Conclusion
In this work, we introduce SCAM, a method that lever-
ages the user’s emotion context and features during long-
term human-robot interactions for emotion perception.
Additionally, we innovatively combine continuous emo-
tion models with discrete emotion models, anchoring
the relationships between different emotions using va-
lence and arousal, achieving outstanding performance.
Through ablation experiments, we further demonstrate
that SCAM significantly improves accuracy in emotion
recognition, valence regression, and arousal regression in
auditory, visual, and multimodal modalities. Moreover,
through data visualization, SCAM performs effectively
even in scenarios with continuous changes in context.
In future work, we will further collect data on robots to
validate the reliability of the methods and conduct psy-
chological experiments to analyze the usability of robot
emotion perception. Regarding the multimodal conflicts
arising from the similarity in probability distributions
between the auditory and visual modalities, we will con-
sider introducing additional modal information for emo-
tion perception.
References
[Kyrarini et al., 2021] M. Kyrarini, F. Lygerakis, A. Ra-
javenkatanarayanan, C. Sevastopoulos, H.R. Nambi-
appan, K.K. Chaitanya, A.R. Babu, J. Mathew, and
F. Makedon. A Survey of Robots in Healthcare. Tech-
nologies, 9(1):8, 2021.
[Tsiourti et al., 2019] C. Tsiourti, A. Weiss, K. Wac,
and M. Vincze.
Multimodal integration of emo-
tional signals from voice, body, and context: Effects
of (in) congruence on emotion recognition and atti-
tudes towards robots. International Journal of Social
Robotics, 11, 555-573, 2019.
[Poria et al., 2019] S. Poria, N. Majumder, R. Mihalcea,
and E. Hovy.
Emotion recognition in conversation:
Research challenges, datasets, and recent advances.
IEEE Access, 7, 100943-100953, 2019.
[Sacharin et al., 2012] V. Sacharin, D. Sander, and K.
R. Scherer. The perception of changing emotion ex-
pressions.
Cognition & Emotion, 26(7), 1273-1300,
2012.
[Zhou et al., 2018] H. Zhou, M. Huang, T. Zhang, X.
Zhu, and B. Liu. Emotional chatting machine: Emo-
tional conversation generation with internal and exter-
nal memory. In Proceedings of the AAAI Conference
on Artificial Intelligence, Vol. 32, No. 1, April 2018.
[Li et al., 2022] Li, X., Zhang, Y., Tiwari, P., Song, D.,
Hu, B., Yang, M., ... and Marttinen, P. (2022). EEG
based emotion recognition:
A tutorial and review.
ACM Computing Surveys, 55(4), 1-57.
[Maithri et al., 2022] M. Maithri, U. Raghavendra, A.
Gudigar, J. Samanth, P. D. Barua, M. Murugappan,
and U. R. Acharya. Automated emotion recognition:
Current trends and future perspectives.
Computer
methods and programs in biomedicine, 215, 106646,
2022.
[Wu et al., 2022] X. Wu, W. L. Zheng, Z. Li, and B. L.
Lu. Investigating EEG-based functional connectivity
patterns for multimodal emotion recognition. Journal
of neural engineering, 19(1), 016012, 2022.
[Russell, 1980] Russell, J. A. (1980).
A circumplex
model of affect. Journal of personality and social psy-
chology, 39(6), 1161.
[Atmaja et al., 2022] B. T. Atmaja, A. Sasou, and M.
Akagi. Survey on bimodal speech emotion recognition
from acoustic and linguistic information fusion. Speech
Communication, 140, 11-28, 2022.
[Priyasad et al., 2020] D. Priyasad,
T. Fernando,
S.
Denman, S. Sridharan, and C. Fookes.
Attention
driven fusion for multi-modal emotion recognition. In
ICASSP 2020-2020 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP),
pp. 3227-3231, May 2020. IEEE.
[Tompkins et al., 2023] D. Tompkins, D. Emmanouili-
dou, S. Deshmukh, and B. Elizalde.
Multi-View
Learning for Speech Emotion Recognition with Cate-
gorical Emotion, Categorical Sentiment, and Dimen-
sional Scores.
In ICASSP 2023-2023 IEEE Inter-
national Conference on Acoustics, Speech and Signal
Processing (ICASSP), pp. 1-5, June 2023. IEEE.
[Busso et al., 2008] C. Busso, M. Bulut, C. C. Lee, A.
Kazemzadeh, E. Mower, S. Kim, and S. S. Narayanan.
IEMOCAP: Interactive emotional dyadic motion cap-
ture database. Language Resources and Evaluation,
42, 335-359, 2008.
[Peng et al., 2021] Peng, Z., Lu, Y., Pan, S., and Liu, Y.
Efficient speech emotion recognition using multi-scale
CNN and attention. In ICASSP 2021-2021 IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing (ICASSP), pp. 3020-3024, June 2021.
IEEE.
[Pan et al., 2020] Pan, Z., Luo, Z., Yang, J., and Li, H.
Multi-modal attention for speech emotion recognition.
arXiv preprint arXiv:2009.04107, 2020.
[Fu et al., 2022] Fu, L., Zhang, Q., and Wang, R. AV-
ITN: A Method of Multimodal Video Emotional Con-
tent Analysis. In 2022 IEEE Conference on Telecom-
munications, Optics and Computer Science (TOCS),
pp. 84-87, December 2022. IEEE.
"
"Machine Unlearning emphasizes adaptability, personalization, privacy, and bias concerns and addresses the ability to remove or update specific data from machine learning models. Unlike traditional models, Unlearning Machine Learning (MUL) dynamically adjusts system knowledge based on shifts in user preferences and ethical considerations. The paper examines MUL's fundamentals, real-world uses, and challenges in ongoing research in responsible and user-focused artificial intelligence. It highlights the trade-off between personalization and privacy, encouraging contributions to meet practical demands for targeted data removal, and offers ways to advance the field.nan","The transformative power of Machine learning has revolutionized data processing and analysis, influencing our digital interactions through sophisticated algorithms and data-driven insights. Recommendation systems, a critical subset of ML, shape our online experiences with tailored recommendations. This paper explores the role of machine unlearning (MUL) in recommendation systems, addressing adaptability, personalization, privacy, and bias challenges. It critically reviews MUL's fundamentals, real-world applications, and complexities like algorithmic transparency, providing insights into its potential to transform recommendations, user trust, and future research.nan","nanThis section offers a thorough investigation of MUL's current state-of-the-art algorithms within recommendation systems, shedding light on several significant contributions. It presents a comprehensive overview of groundbreaking research, including the introduction of graph networks, optimization methods, and model-agnostic operators, highlighting the evolving landscape of MUL methodologies.nan","The literature review in this paper systematically analyzed relevant sources from esteemed academic databases. By employing comprehensive search strategies across reputable platforms, a representative selection of pertinent and recent studies on MUL within recommender systems was compiled. The research adhered to a rigorous methodology to identify and evaluate the most impactful contributions in the field.nan","The review of SOTA algorithms for MUL on recommendation systems revealed promising advancements in unlearning efficiency, accuracy, and eﬃciency. The combination of data partitioning, adaptive aggregation methods, and advanced update techniques showcased significant improvements in model utility and completeness. Researchers also introduced model-agnostic approaches for graph unlearning, ensuring the removal of elements without compromising knowledge integrity. Despite these advancements, challenges remain in addressing instance-level data removal limitations and the complexities of non-convex optimization problems, opening avenues for future exploration.nan","The paper emphasizes how MUL can potentially revolutionize recommendation systems by critically evaluating its fundamentals, practical applications, and the complex issue of algorithmic transparency. It explores the delicate balance between tailoring recommendations to individual preferences and respecting user privacy, highlighting the importance of building user trust in these systems. Moreover, it suggests avenues for future research that prioritize responsible and user-centric artificial intelligence, significantly contributing to ongoing discussions about ethical practices in AI. Its unique exploration of MUL's transformative capabilities within recommendation systems oﬀers valuable insights into ethical considerations and advances the conversation on responsible AI development.nan",Machine Unlearning for Recommendation Systems: An Insight,"Bhavika Sachdeva, Harshita Rathee,  Sristi, Arun Sharma, Witold Wydmański","arXiv:2401.10942v1  [cs.IR]  17 Jan 2024
Machine Unlearning for Recommendation Systems: An Insight
Bhavika Sachdeva⋆1, Harshita Rathee*1, Sristi*1, Arun Sharma1, and Witold Wydma´nski2
1 Department of Computer Science and Engineering, Indira Gandhi Delhi Technical University for Women, New Delhi, India
bhavika2210@gmail.com, harshita10.17@gmail.com, sristi0108@gmail.com and arunsharma@igdtuw.ac.in
2 Faculty of Mathematics and Computer Science, Jagiellonian University, Krak´ow, Poland witold.wydmanski@uj.edu.pl
Abstract. This review explores machine unlearn-
ing (MUL) in recommendation systems, addressing
adaptability, personalization, privacy, and bias chal-
lenges. Unlike traditional models, MUL dynamically
adjusts system knowledge based on shifts in user pref-
erences and ethical considerations. The paper criti-
cally examines MUL’s basics, real-world applications,
and challenges like algorithmic transparency. It sifts
through literature, oﬀering insights into how MUL
could transform recommendations, discussing user trust,
and suggesting paths for future research in responsi-
ble and user-focused artiﬁcial intelligence (AI). The
document guides researchers through challenges in-
volving the trade-oﬀ between personalization and pri-
vacy, encouraging contributions to meet practical de-
mands for targeted data removal. Emphasizing MUL’s
role in secure and adaptive machine learning, the pa-
per proposes ways to push its boundaries. The nov-
elty of this paper lies in its exploration of the lim-
itations of the methods, which highlights exciting
prospects for advancing the ﬁeld.
Keywords: Machine Unlearning · Right to be For-
gotten · Recommendation Unlearning · Data Privacy
· Machine Learning Security
1
Introduction
Machine learning (ML) stands as a transformative force, rev-
olutionizing data processing and analysis across diverse do-
mains. Its pervasive impact on our approach to data is partic-
ularly evident in recommendation systems, a critical subset of
ML that signiﬁcantly inﬂuences our digital experiences.
Within the intricate realm of recommendation systems,
these algorithms are architects of personalized user interac-
tions. Operating on sophisticated algorithms and data-driven
insights, these systems are crucial in delivering tailored content
and product suggestions. Through a nuanced understanding
of user behaviors and preferences, recommendation systems
contribute to an enriched online experience by seamlessly in-
tegrating relevant and engaging recommendations.
At the core of this intricate interplay lies the pivotal role of
ML, serving as the backbone that propels the nuanced mechan-
ics of recommendation systems. These systems, meticulously
designed to decipher and respond to user preferences and be-
haviors, exemplify the symbiotic relationship between human
interaction and algorithmic intelligence. The synergy between
ML and recommendation systems highlights the depth of their
impact on how we consume and engage with content in the
digital realm.
As we delve further into the intricacies of recommendation
systems, it becomes apparent that machine learning’s role is
not ancillary but foundational. Its integration empowers these
systems to continually evolve and adapt, ﬁne-tuning their rec-
ommendations based on the dynamic landscape of user pref-
erences. This symbiotic relationship underscores the dynamic
⋆ These authors should be considered co-ﬁrst authors.
nature of the intersection between machine learning and rec-
ommendation systems, marking it as a compelling frontier in
the evolving landscape of digital technology. These applica-
tions vary from news portals, social media [1], [2], e-commerce
platforms to OTT platforms such as Netﬂix [3]. Random walk-
based models, such as Pixie [4], have been successfully em-
ployed in large-scale industrial contexts to deliver highly eﬀec-
tive personalized recommendations. There are several types of
ﬁltering algorithms used like Collaborative ﬁltering, Content
based ﬁltering, and matrix factorization. Many of the recom-
mendation systems use hybrid algorithms which combine sev-
eral recommendation techniques into one. Once created, these
recommendation systems have the capacity to retain knowl-
edge from their training data.
However, with the ever-growing importance and prevalence
of recommendation systems, a challenging concept looms in
the background – the need for machine unlearning. As these
systems continuously evolve and adapt, there arises a crucial
question: how do we eﬀectively mitigate or alter the impacts of
prior learning, both within the data repositories and the core
ML models that power recommendation systems?
MUL is an emerging science that tries to address the com-
plexities associated with undoing or revising the consequences
of prior learning, both within the data repositories and the
underlying machine learning models. It arises from the recog-
nition that, in a constantly evolving and privacy-conscious dig-
ital landscape, users may require their data to be selectively
erased or modiﬁed, not only to enhance privacy and data se-
curity but also to maintain the accuracy and relevance of rec-
ommendations.
However, an essential consideration arises in this context
[5]: throughout the life cycle of recommendation algorithms
under examination, instances arise where it becomes impera-
tive for the system to selectively discard speciﬁc information
and its complete historical context.
Given that all these algorithms rely on the premise of re-
taining data, a signiﬁcant and pressing concern associated with
these systems is the potential compromise of user privacy. Re-
cent studies have brought to light that trained models, in-
cluding recommender systems, large pre-trained models, and
ﬁne-tuned natural language models, can inadvertently expose
sensitive user information. In such cases, users are actively
looking for methods to remove the impact of their sensitive
data from these models.
Another important rationale for the need for recommen-
dation unlearning pertains to the system’s utility. Over time,
continuous data collection is essential for enhancing existing
models. However, some of this newly acquired data can be
harmful, such as tainted data resulting from poisoning attacks
or data that diverges from the model’s typical distribution
(out-of-distribution data) [2]. This subpar data can have a
notable detrimental impact on the eﬀectiveness of recommen-
dations. Once identiﬁed, it becomes imperative for the system
to expunge such data to restore its usefulness.
2
B. Sachdeva et al.
Furthermore, in our ever-evolving world, users increasingly
seek recommendations that adapt to their changing needs.
Picture a scenario involving political posts—a user was once
actively engaged in such content but has since lost interest.
Despite this shift, the user continues to receive recommenda-
tions related to political discourse. This example underscores
the need for users to have control over the model’s historical
data, particularly in the realm of political content, to ensure
that recommendations remain relevant and responsive to their
evolving preferences and interests.
The most basic approach to unlearning entails retraining
the model using its original data, but this method presents a
substantial challenge due to the signiﬁcant computational de-
mands, especially for large-scale datasets. For recommendation
unlearning to be successful, it must not only involve purging
collected user data but also erasing the inﬂuence of that data
on the model. This process should adhere to three fundamental
principles: completeness, utility, and eﬃciency [6]. One direct
method to satisfy both completeness and utility is to retrain
the model entirely from the ground up. However, this approach
is often impractical due to the high costs associated with re-
training, rendering it ineﬃcient for real-world applications. To
ensure the eﬃciency of the unlearning process, existing meth-
ods for recommendation unlearning have had to strike a bal-
ance between the three fundamental principles, considering the
trade-oﬀs between these factors and eﬃciency.
Concerning recommendation systems, the existing MUL
methods face challenges due to the complex geometric rela-
tionships and structures inherent in the data they handle. In
addition to exploring the traditional recommendation unlearn-
ing algorithm, this paper places emphasis on graph-based un-
learning algorithms. [7]. In the quest for reﬁning recommenda-
tion systems, a signiﬁcant aspect that has garnered attention
is the challenge posed by evolving user preferences. There-
fore, the adaptability of recommendation systems to capture
and respond to these nuances becomes paramount. Addressing
this challenge involves exploring novel approaches to real-time
learning and dynamic model adjustments.
The study’s main contributions include thoroughly exam-
ining the concept of machine unlearning (MUL) within rec-
ommendation systems. It oﬀers a deep dive into the adaptable
nature of MUL, focusing on its implications for personaliza-
tion, privacy, and bias – all critical aspects of today’s AI-driven
systems. The research provides a nuanced perspective on how
MUL could potentially revolutionize recommendation systems
by critically evaluating its fundamentals, its practical applica-
tions, and the complex issue of algorithmic transparency.
Additionally, the paper highlights the delicate balance be-
tween tailoring recommendations to individual preferences and
respecting user privacy. It emphasizes the importance of build-
ing user trust in these systems and suggests avenues for future
research that prioritize responsible and user-centric artiﬁcial
intelligence.
Through its proposals to expand secure and adaptive ma-
chine learning using MUL, this study signiﬁcantly contributes
to ongoing discussions about ethical practices in AI. Its unique
exploration of MUL’s transformative capabilities within rec-
ommendation systems oﬀers valuable insights into ethical con-
siderations and advances the conversation on responsible AI
development.
The structure of this paper is as follows: Section 2 discusses
the review methodology used for the paper. Section 3 pro-
vides a thorough literature review of existing state-of-the-art
(SOTA) algorithms on machine unlearning for recommenda-
tion systems. Section 4 summarizes the discussions and future
directions of the reviewed methodologies in the relevant ﬁeld,
and ﬁnally, Section 5 details the conclusion.
2
Review Methodology
In conducting this literature review, a systematic approach
was adopted to identify relevant sources and contributions.
Thorough searches were conducted across esteemed academic
databases, including IEEE journals, Elsevier publications, and
Springer databases. The selected keywords employed in the
search process encompassed terms such as ”machine unlearn-
ing,” ”recommendation systems,” ”graph networks,” ”recom-
mendation unlearning methods,” and ”privacy in machine learn-
ing.” A representative selection of the most pertinent and
recent research in machine unlearning within recommenda-
tion systems was compiled by employing these comprehensive
search strategies and leveraging authoritative databases.
3
Literature Review
This section takes a deep dive into the ever-evolving realm of
machine unlearning in recommendation systems, speciﬁcally
focusing on the utilization of graph networks. It sheds light on
several seminal contributions in this nascent ﬁeld, each pre-
senting a distinct approach to the intricate task of unlearning
within recommendation systems. These contributions oﬀer in-
sights into various techniques and strategies, encompassing ad-
vanced data partitioning and adaptive aggregation methods,
novel recommendation unlearning methodologies, and model-
agnostic layer-wise operators. There exists scope for extensive
work in the ﬁeld of machine unlearning, particularly in the
domain of graph networks primarily used by recommendation
systems. Some signiﬁcant contributions include:
3.1
RecEraser
The authors introduced RecEraser [8], an eﬃcient machine un-
learning framework that can be utilized for recommendation
systems.The core concept behind RecEraser involved segment-
ing the training data into multiple shards and subsequently
training a separate model for each shard. In order to main-
tain collaborative information within the data, 3 innovative
data partition algorithms were initially developed to create
balanced groups based on their similarity. Additionally, they
introduced an adaptive aggregation method to enhance the ef-
fectiveness of the global model while preserving collaborative
insights. RecEraser aims to protect and harness collaborative
information by carefully partitioning the dataset while making
shards. It adaptively assigned weights to these shards at the
time of aggregation. [9]
However, RecEraser does not consider the transport weights
between sub-models, which may lead to sub-optimal cluster-
ing and imbalance of group data. [10] It does not guarantee
the convergence of sub-models on their own group data, which
may aﬀect the quality of recommendations. RecEraser uses a
complex combination estimator that requires additional train-
ing and tuning, which may increase the computational cost
and risk of overﬁtting. [6]
3.2
Recommendation Unlearning via Matrix
Correction
MCRU [6] discussed a novel approach to recommendation un-
learning, which is the process of deleting speciﬁc data and
Machine Unlearning for Recommendation Systems
3
models from a trained recommender system. The authors in-
troduced Interaction and Mapping Matrices Correction (IM-
Correct), a technique for recommendation unlearning. IMCor-
rect was able to attain recommendation unlearning through
updating the interaction matrix and improving the complete-
ness as well as utility. This was done by updating the map-
ping matrix without expensive compute process of retraining
the model. IMCorrect is a whitebox model that delivered more
signiﬁcant ﬂexibility in managing diverse recommendation un-
learning plans. It has the distinctive ability of learning incre-
mentally from unknown data, which further improved its use-
fulness. [11]
3.3
AltEraser
AltEraser [12] is an important machine unlearning work for
real-world applications where users desired that a portion of
their data be removed, not exclusively from the data storage
but correspondingly from the ML models being used in the
process, both for privacy or utility grounds. The authors ex-
plored swift ML techniques for recommendation engines that
could dismiss the impact of a short portion of the training set
from the recommendation system without the full cost that
would be incurred upon retraining. A realistic method to accel-
erate this was to ﬁne-tune the existing recommendation system
on the left training set rather than initiating from a point of
random initialization. The authors presented a new recommen-
dation unlearning strategy, AltEraser [13], which separates the
optimization issue of unlearning and divides it additionally
into tractable sub-problems.
3.4
GNNDelete
GNNDelete framework [7] introduced an innovative strategy
for graph unlearning within Graph Neural Networks (GNNs).
It involved the removal of elements such as nodes, their la-
bels, and relationships from a pre-trained GNN model, a crit-
ical process for practical applications where data privacy, ac-
curacy, and relevance are paramount concerns. This model-
agnostic approach prioritized two key attributes for eﬀective
graph unlearning: Neighbourhood Inﬂuence and Deleted Edge
Consistency. The layer-wise operator employed in GNNDelete
optimized these qualities, ensuring that model weights and
neighboring representations remain uninﬂuenced by deleted
elements. The Deleted Edge Consistency guaranteed the re-
moval of any residual impact, while Neighbourhood Inﬂuence
preserved the integrity of the remaining model knowledge post-
deletion. GNNDelete achieved the removal of nodes and edges
from the model while retaining crucial learned information by
modifying representations. Notably, this approach addressed
the limitations of current partitioning and aggregation-based
techniques, particularly in handling local graph relationships.
[14]
3.5
Caboose Forget Me Now: Fast and
Exact Unlearning in Neighborhood-based
Recommendation
The authors [15] proposed an algorithm that leveraged the
data’s sparsity to work only using top-k entries that are presently
impacted by the unlearning process. This meant that it could
be computed using the norm of vectors and dot products. It
also concentrated on zero similarity functions when the dot
product was zero between two rows. This helped to avoid un-
necessary computations for pairs of users that hadn’t engaged
with any shared items. The algorithm’s individual stages were
parallelized [16] to use multiple processing units for faster
computation. Appropriate data structures, such as compressed
representations for binary heaps as well as sparse matrices for
managing top-k lists, were chosen to optimize low-level oper-
ations in the algorithm.
3.6
Graph Scattering Transform (GST) Unlearning
Graph Classiﬁers with Limited Data Resources
The method’s [17] computational complexity for node removal
was considered order-optimal with respect to unlearning com-
plexity for graph classiﬁers. This eﬃciency was a signiﬁcant
advantage, especially compared to methods that frequently
required full retraining. The approach’s use of GSTs for dif-
ferent training graphs resembled sharding with small compo-
nents. Notably, the sizes of these shards did not impact the
performance of the ﬁnal model, providing a robust and ﬂex-
ible system for graph classiﬁcation tasks. The authors sug-
gested exploring other loss functions or methods in speciﬁc
applications was one potential future direction. This indicated
the possibility of extending the framework’s capabilities even
further. The ﬁrst nonlinear graph learning framework based
on GSTs with an approximate unlearning mechanism oﬀered
versatility, eﬃciency, and certiﬁed removal with lower privacy
costs than alternatives. Especially for limited data resources,
these methods have been proven eﬀective. [18]
3.7
Selective and Collaborative Inﬂuence Function
(SCIF) for Eﬃcient Recommendation
Unlearning
SCIF [19] was designed to enhance unlearning performance in
recommendation tasks by incorporating two critical compo-
nents: user selection and preservation of collaboration. Each
data point was treated independently in the the traditional
IF-based unlearning method. Thus, ignoring the collaborative
nature of recommendation data, SCIF introduced a collabo-
rative component to the inﬂuence function. When unlearning
a data point, this component restored collaboration among
users and items. Calculating the inﬂuence on the target user
embedding can still be computationally demanding, even with
the reduction in parameters considered. To address this, au-
thors employed techniques like Hessian-Vector Product (HVP)
and conjugate gradients, which made the computation more
eﬃcient. Neural Matrix Factorization (NMF) and LightGCN
were the recommender models used.
3.8
Attribute-wise Unlearning in Recommender
Systems
Attribute-based unlearning methods for recommendation sys-
tems were also developed to protect the sensitive attributes
of users. This was done by using Post-Training Attribute Un-
learning. [20]. The collaborative ﬁltering technique that is most
commonly used for recommendations was selected in this study.
It is based on matrix factorization and was used to split the
user-item interaction matrix into 2 low-rank embedding ma-
trices. These are item and user embedding. The attribute with
two or binary labels was the primary focus of the work.
3.9
Recommendation Unlearning via Inﬂuence
Function (IFRU)
IFRU [21] leveraged inﬂuence functions, a concept from diﬀer-
ential privacy and sensitivity analysis. Inﬂuence functions(IF)
4
B. Sachdeva et al.
provided a way to gauge the impact of individual data points
on the output provided by the model. Inﬂuence functions helped
identify and adjust the impact of speciﬁc data points, enabling
the model to unlearn undesirable or sensitive information with-
out needing full retraining. The key idea behind IFRU was to
compute the unlearning of inﬂuential data points followed by
modiﬁcations to the model’s parameters. As a result, the im-
pact of those data points on the predictions made by the model
was eﬀectively diminished. This allowed the model to ”forget”
the unwanted information and adapt to the updated training
data, ultimately improving the model’s safety and privacy. Ma-
trix Factorization(MF) and LighGCN were the recommender
models used. [22]
3.10
Federated Unlearning for On-Device
Recommendation
Federated Recommendation Unlearning (FRU) [23] eﬃciently
unlearned target users in federated recommendation systems.
It calibrated and combined all users’ previous model updates
to recreate the Federated Recommendation (FedRec) [24] mod-
els. Neural collaborative ﬁltering and LightGCN are the Fe-
dRec algorithms used. FRU sped up the reconstruction process
compared to retraining from scratch as it reliably rolled back
FedRec and calibrated the stored model changes. FRU was
model-agnostic and was likely utilized in several FedRecs. The
ﬁndings revealed that FRU could remove speciﬁc users’ im-
pact and eﬀectively retrieve FedRec’s seven times faster. FRU
performed unlearning when many users rendered the FedRec
service and requested their information be forgotten at a spe-
ciﬁc time. This involved restoring the FedRec model to an ear-
lier state and calibrating the historical updates of the model
on the existing clients. As the direction drove the model ﬁt-
ting, the calibration focused on the direction of updates while
maintaining their length unchanged. [25]
3.11
Heterogeneous Federated Knowledge Graph
Embedding Learning and Unlearning
FedLU [26] introduced embedding learning and frameworks
based on federated Knowledge Graphs, which showcased in-
novation, addressing knowledge sharing and forgetting in a
federated environment. The model eﬀectively balanced global
convergence and local optimization through mutual knowledge
distillation, demonstrating a thoughtful approach to federated
learning. Retroactive interference and passive decay in feder-
ated unlearning allowed the model to forget speciﬁc knowl-
edge while maintaining overall performance, showcasing a ro-
bust unlearning mechanism. FedLU [27] has the potential to
make a signiﬁcant impact by addressing challenges in federated
KG embedding, including knowledge exchange and unlearning,
contributing to advancements in federated learning research.
3.12
Adv-MultVAE Model: Unlearning Protected
User Attributes in Recommendations with
Adversarial Training
The authors acknowledged the limitations of their approach
and suggested potential areas for improvement in the future.
These included exploring generalization aspects, understand-
ing user perceptions of bias in recommendations, and identify-
ing which user groups are most aﬀected by the approach [28].
These suggestions indicated a commitment to ongoing research
and improvement. There was a marginal decrease in perfor-
mance, mainly attributed to the challenge in model selec-
tion. [29]The authors recognized that ﬁnding a balance be-
tween accuracy (BAcc) and recommendation quality (NDCG)
helped mitigate this performance loss. It was essential to con-
sider this trade-oﬀ when implementing the approach.
3.13
MUter: Machine Unlearning on Adversarially
Trained Models
MUter [30] presented a pioneering approach to the joint chal-
lenge of privacy and robustness in unlearning from adversar-
ial training models. It used a Hessian-based measure and eﬃ-
ciency enhancements that marked a signiﬁcant advancement.
The method proved to be versatile and eﬀective across linear
and neural network models and opened avenues for future ex-
ploration. Overall, MUter stood out as a favorable solution
with a dual focus on privacy and adversarial robustness.
3.14
Laser: Making Recommender Systems
Forget: Learning and Unlearning for Erasable
Recommendation
LASER [31] presented a promising framework for addressing
the challenge of unlearning in recommendation systems. The
combination of the Group module, focusing on balanced user
grouping through collaborative embedding, and the SeqTrain
module, implementing a sequential training approach with col-
laborative cohesion as a diﬃculty measure, demonstrated an
innovative strategy for achieving eﬃcient unlearning and im-
proved model utility. The theoretical support for the SeqTrain
module added credibility to the proposed approach, and em-
pirical validation on real-world datasets strengthening its prac-
tical relevance. However, potential complexities in implemen-
tation, dependency on the quality of collaborative embedding,
and sensitivity to hyperparameters should be carefully consid-
ered. Overall, LASER provided a valuable contribution to the
ﬁeld, and its real-world implications and scalability in diﬀerent
recommendation system scenarios warrant further exploration
and research.
The most recent works on MUL signiﬁcantly improve ex-
isting techniques, such as UltraRE [10], an ensemble-based
framework for recommendation unlearning that addresses re-
dundancy, relevance, and combination losses to enhance model
utility. Another notable contribution introduced by the cer-
tiﬁed MUL algorithm for minimax models [32], employs a
total-Hessian-based complete Newton update and the Gaus-
sian mechanism from diﬀerential privacy. Furthermore, these
works, including exploration-focused approaches [33], evalu-
ate current unlearning methods and introduce techniques like
improved adversarial attacks, with a particular emphasis on
recommendation systems.
3.15
Machine Unlearning from Bi-linear
Recommendations
The work [3] proposed a fast heuristic-based MUL technique
for recommendation systems, Untrain-ALS, that unlearns a
bi-linear model without compromising recommendation accu-
racy. The paper discussed the privacy risks that bi-linear rec-
ommendation systems hold on memorizing data. They eﬀec-
tively presented an empirical test using de-noised membership
inference that proved sensitive to bi-linear recommendation
engines’ memorization.
Machine Unlearning for Recommendation Systems
5
Table 1: Analysis of SOTA MUL Algorithms on Recommendation Systems
Method
Year Datasets
Pros
Limitations
RecEraser
[8]
2022 Yelp2018,
Movielens-1m,
Movielens-10m
The proposed model employed balanced
data partition for collaborative informa-
tion preservation, attention-based adap-
tive aggregation with self-adaptive learn-
ing rates, and computationally eﬃcient un-
learning by retraining only relevant sub-
models and the aggregation part, demon-
strating superior performance compared to
SOTA algorithms.
Eﬃciently unlearning employing the
Sharded, Isolated, Sliced, and Ag-
gregated (SISA) framework in batch
setting remains an issue. For some
scenarios, the brute force method
of retraining performed better than
RecEraser. RecEraser does not con-
sider the transport weights between
sub-models, which may lead to sub-
optimal clustering and imbalance of
group data. It does not guaran-
tee sub-models’ convergence on their
own group data, which may aﬀect
the quality of recommendations. It
only handles individual forgetting
requests, and its eﬃciency may de-
crease when dealing with batch re-
quests. [10]
AltEraser
[12]
2022 MovieLens-1m,
Amazon-14core,
KuaiRec-binary
AltEraser demonstrated promising results
in consistency, accuracy, and eﬃciency as
the foremost try at rapid approximate
MUL for neural recommendation models
that are SOTA, based on extensive exper-
iments on three real-world datasets
AltEraser,
a
ﬁne-tuning
method
proposed in the paper, may be sen-
sitive to hyperparameters like learn-
ing rate, and its performance on rec-
ommender systems with non-linear
models or intricate user-item inter-
action patterns remains uncertain.
MCRU [6]
2023 MovieLens-1m,
Gowalla, Yelp
IMCorrect
demonstrated superiority
in
forgetting out-of-distribution, out-of-date,
and attack data, exhibiting eﬀectiveness
in completeness, utility, and eﬃciency, and
proved to be a versatile tool applicable
in various recommendation unlearning sce-
narios.
IMCorrect assumes correctability of
the interaction matrix, which may
not be viable when unlearned data
signiﬁcantly impacts the model, and
the paper lacks discussion on the
method’s performance in large-scale
recommender systems with millions
of users and items.
GNNDelete
[7]
2023 Cora, PubMed,
DBLP,
CS,
OGB-Collab,
OGB-BioKG,
WordNet18RR
Regarding edge, node, and nodal feature
deletion tasks, GNNDelete performed bet-
ter than current methods by as much as
38.8% (AUC) and 32.2% when diﬀeren-
tiating removed edges from non-deleted
ones. Compared to retraining the GNN
system from WordNet18, it required 9.3x
less space and less time than 12.3x, indi-
cating its eﬃciency
Further exploration is needed to as-
sess GNNDelete’s performance on
larger datasets and diverse graph
types, as well as to investigate its ro-
bustness to noise and adaptability to
dynamic graphs with constant node
and edge changes.
Caboose
[15]
2023 Movielens-
10m,
Lastfm,
Synthetic Inter-
actions, Yahoo,
Spotify
Caboose facilitated quick index building,
enabling sub-second unlearning for large
datasets and seamless integration with
next-basket recommendation models, of-
fering transparent and cost-eﬀective alter-
natives to neural approaches with signiﬁ-
cantly reduced training time.
The removals’ impact depended on
the data’s model details and co-
occurrence structure.
SCIF [19]
2023 Movielens-1m,
Amazon Digital
Music (ADM)
The method eliminated the need for re-
training, making it ideal for large-scale
systems, enhancing eﬃciency through se-
lective user embedding updates, preserv-
ing collaboration, and employing a Mem-
bership Inference Oracle (MIO) that veri-
ﬁed comprehensive unlearning, ultimately
demonstrating signiﬁcant improvements in
eﬃciency while maintaining completeness.
Collaborative ﬁltering encountered
challenges with large datasets and
required further development for
adaptation to complex models by
incorporating additional sources of
user-item interaction data.
Continued on the next page
6
B. Sachdeva et al.
Table 1: Continued from previous page
Method
Year Datasets
Pros
Limitations
GST [17]
2022 MNIST,
CI-
FAR10,
PRO-
TEINS, IMDB,
COLLABS
The graph classiﬁer oﬀered mechanism,
adaptable to various loss functions, with
an approximate removal guarantee within
privacy constraints, surpassing DP-GNNs
in privacy cost for similar unlearning out-
comes for eﬃcient unlearning with nonlin-
earities in graph embedding and reduced
training data.
Comparison
with
DP-GNNs
re-
vealed their focus on node-level pri-
vacy in classiﬁcation tasks, suggest-
ing their suitability for node classi-
ﬁcation rather than graph classiﬁca-
tion.
IFRU [21]
2023 Amazon
Electronics,
BookCrossing
IFRU aims for comprehensive unlearning
by removing the inﬂuence of unusable data
without modifying model architectures, en-
suring thoroughness without side eﬀects on
recommendation quality. It eﬃciently ad-
dressed unlearning in recommendation sys-
tems, especially in scenarios requiring up-
dates based on user interactions or varying
sensitivity levels.
IFRU’s eﬀectiveness was inﬂuenced
by
recommendation
model
com-
plexity, potentially facing challenges
with extremely complex models. It
may also have limitations in highly
sparse datasets, particularly when
interactions between users and items
are limited, making accurate inﬂu-
ence function calculation and eﬀec-
tive recommendations challenging..
FRU [23]
2022 MovieLens-
100k,
Steam-
200k
FRU allowed users to request data erasure
for privacy compliance, enabling speciﬁc
data removal without full model retrain-
ing, utilizing eﬃcient storage methods to
reduce historical data storage, and achiev-
ing quick recalibration for up to 7 times
better system responsiveness.
The potential drawbacks involved
the complexity of managing updates
on a distributed system and the
need for additional computational
resources for update revision and re-
construction.
Adv-
MultVAE
[28]
2022 MovieLens-
1M,
LFM-2b-
DemoBias
Adv-MultVAE integrated an adversarial
component to mitigate societal biases in
recommendation systems, eﬀectively re-
ducing biases in latent information about
user-protected attributes, promoting fair-
ness and privacy, as validated through em-
pirical evidence measuring both the reduc-
tion in encoded protected information and
recommendation accuracy.
The adversarial approach in bias re-
duction lacked eﬀective generaliza-
tion to new datasets and chang-
ing user behavior, and it may not
fully address user perception of bias
in recommended results, highlight-
ing potential limitations in its ap-
plication.
Laser [31]
2022 MovieLens-1M,
Amazon Digital
Music
LASER divided users into balanced groups
using collaborative embedding and en-
hanced retraining eﬃciency, potentially
lowering computational expenses. The Se-
qTrain module adopted a sequential train-
ing method with collaborative cohesion as
a measure of diﬃculty, oﬀering a system-
atic approach that enhanced model utility.
LASER’s eﬀectiveness depends on
collaborative
embedding
quality
and sensitivity to hyperparameter
choices, impacting its performance.
FedLU [26] 2023 FB15k-237
C3,C5,C10
FedLU employed mutual knowledge distil-
lation for global convergence and enhanced
local optimization on dynamic, heteroge-
neous data among clients. It integrated
retroactive interference and passive decay
for eﬀective triplet unlearning without sig-
niﬁcant performance degradation.
FedLU introduced complexity with
mechanisms like mutual knowledge
distillation, retroactive interference,
and passive decay, demonstrating ef-
fectively on speciﬁc clustering-based
datasets, though performance could
have varied on datasets with diﬀer-
ent characteristics.
MUter [30] 2023 MNIST-B, Cov-
type,
Lacuna-
10, CIFAR-10
MUter addressed the challenge of un-
learning from adversarial training mod-
els, ensuring privacy compliance and ro-
bustness, utilizing a Hessian-based mea-
sure with computational techniques for eﬃ-
ciency gains, demonstrating high eﬀective-
ness in maintaining model accuracy and
adversarial robustness across linear and
neural network models.
While eﬃcient, MUter incurred a
slightly longer computational time
due to the additional computation
of the total Hessian.
Machine Unlearning for Recommendation Systems
7
3.16
Closed-form Machine Unlearning for Matrix
Factorization (CMUMF)
A closed-form MUL technique is suggested by the authors [34].
As the closed-form unlearning update, the authors recorded
the implied reliance between the rows and columns, leading
to a complete Newton step based on Hessian. The paper val-
idated the eﬃcacy and utility of CMUMF using 5 real-world
datasets from 3 distinguishable domains of application, includ-
ing artiﬁcial data sets with three diﬀerent sizes.
4
Challenges and Future Directions
Machine unlearning is a fairly contemporary and emerging
area of research, focusing on the ability to remove or update
speciﬁc data from machine learning models. As researchers
delve into this emerging domain, it becomes evident that ex-
ploring unlearning techniques has been somewhat limited, par-
ticularly in the context of diverse data structures like multi-
modal data. Future investigations must extend the scope of
unlearning to intricate formats such as text, audio, and mul-
timedia, presenting novel challenges related to temporal se-
quences, spatial linkages, and hierarchical structures.
While existing research has made strides in understanding
unlearning within convex models like logistic regression, there
remains a notable gap in addressing the complexities intro-
duced by non-convex neural networks, including Convolutional
Neural Networks and Recurrent Neural Networks commonly
employed in deep learning applications. Eﬃcient algorithms
tailored for non-convex optimization problems in the context
of unlearning strategies are still in the early stages of develop-
ment.
Moreover, the current focus on instance-level data removal
in unlearning strategies has limitations, oﬀering users only
a constrained degree of ﬂexibility in data management and
model updates. Future research should explore the develop-
ment of quantitative metrics to foster a more versatile and
user-friendly approach. These metrics could provide a nuanced
evaluation of unlearning eﬃcacy by measuring the extent of
inﬂuence retention for retained data and the corresponding
reduction in inﬂuence for removed data. This avenue of explo-
ration promises to enhance the comprehensiveness and adapt-
ability of machine unlearning methodologies, paving the way
for future more eﬀective and user-centric approaches.
Future scope for this can be extended to social media rec-
ommendation systems where the reliance on user search his-
tory is pretty high. Once any information is fed into them, the
graphically dense relation that information establishes with
the existing information makes the problem more challenging
and relevant to the actual problems. Solving these problems is
important to ensure future development in this domain.
5
Conclusion
In conclusion, this literature review highlighted the notable
contributions in this domain, underscoring the adoption of
graph networks to address the multifaceted challenges of ma-
chine unlearning. Signiﬁcant advancements and innovative strate-
gies were observed; however, it is imperative to recognize that
this domain remained in its premature stages. The niche area
of machine unlearning within recommendation systems pre-
sented ample opportunities for future exploration and devel-
opment. Researchers and practitioners were able to harness
the potential of machine unlearning to enhance user privacy,
maintain recommendation system accuracy, and adapt to ever-
changing user preferences. As recommendation systems con-
tinued to shape our digital experiences, the quest for eﬃcient,
accurate, and privacy-aware MUL methods ensured these sys-
tems’ ongoing success and safety.
References
1. P.
Covington,
J.
Adams,
and
E.
Sargin,
“Deep
neural
networks
for
youtube
recommendations,”
in
Proceedings
of the 10th ACM Conference on Recommender Systems,
ser. RecSys ’16.
New York, NY, USA: Association for
Computing Machinery, 2016, p. 191–198. [Online]. Available:
https://doi.org/10.1145/2959100.2959190
2. R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton,
and
J.
Leskovec,
“Graph
convolutional
neural
networks
for web-scale recommender systems,” in Proceedings of the
24th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining, ser. KDD ’18.
New York, NY,
USA: Association for Computing Machinery, 2018, p. 974–983.
[Online]. Available: https://doi.org/10.1145/3219819.3219890
3. M.
Xu,
J.
Sun,
X.
Yang,
K.
Yao,
and
C.
Wang,
“Netﬂix and forget: Eﬃcient and exact machine unlearning
from bi-linear recommendations,” 2023. [Online]. Available:
https://arxiv.org/abs/2302.06676
4. C. Eksombatchai, P. Jindal, J. Z. Liu, Y. Liu, R. Sharma,
C.
Sugnet,
M.
Ulrich,
and
J.
Leskovec,
“Pixie:
A
system
for
recommending
3+
billion
items
to
200+
million
users
in
real-time,”
2017.
[Online].
Available:
https://arxiv.org/abs/1711.07601
5. A. Sekhari, J. Acharya, G. Kamath, and A. T. Suresh,
“Remember what you want to forget: Algorithms for machine
unlearning,” ArXiv, vol. abs/2103.03279, 2021. [Online]. Avail-
able: https://api.semanticscholar.org/CorpusID:232134970
6. J. Liu, D. Li, H. Gu, T. Lu, J. Wu, P. Zhang, L. Shang, and
N. Gu, “Recommendation unlearning via matrix correction,”
2023. [Online]. Available: https://arxiv.org/abs/2307.15960
7. J. Cheng, G. Dasoulas, H. He, C. Agarwal, and M. Zitnik,
“GNNDelete: A general strategy for unlearning in graph
neural networks,” in The Eleventh International Conference
on
Learning
Representations,
2023.
[Online].
Available:
https://openreview.net/forum?id=X9yCkmT5Qrl
8. C.
Chen,
F.
Sun,
M.
Zhang,
and
B.
Ding,
“Rec-
ommendation
unlearning,”
2022.
[Online].
Available:
https://arxiv.org/abs/2201.06820
9. H. Xu, T. Zhu, L. Zhang, W. Zhou, and P. S. Yu, “Machine
unlearning: A survey,” ACM Computing Surveys, vol. 56, no. 1,
pp. 1–36, 2023.
10. Y. Li, C. Chen, Y. Zhang, W. Liu, L. Lyu, X. Zheng, D. Meng,
and J. Wang, “Ultrare: Enhancing receraser for recommen-
dation unlearning via error decomposition,” in Thirty-seventh
Conference on Neural Information Processing Systems, 2023.
11. S. Liu, J.
Liu, H. Gu, D. Li, T.
Lu, P. Zhang, and
N. Gu, “Autoseqrec: Autoencoder for eﬃcient sequential rec-
ommendation,” in Proceedings of the 32nd ACM International
Conference on Information and Knowledge Management, ser.
CIKM ’23.
New York, NY, USA: Association for Com-
puting Machinery, 2023, p. 1493–1502. [Online]. Available:
https://doi.org/10.1145/3583780.3614788
12. W. Liu, J. Wan, X. Wang, W. Zhang, D. Zhang, and H. Li,
“Forgetting fast in recommender systems,” 2022. [Online].
Available: https://arxiv.org/abs/2208.06875
13. S. Zhang, J. Lou, L. Xiong, X. Zhang, and J. Liu, “Closed-form
machine unlearning for matrix factorization,” in Proceedings
of the 32nd ACM International Conference on Information
and Knowledge Management.
ACM, Oct. 2023. [Online].
Available: https://doi.org/10.1145/3583780.3614811
14. Y. Sinha, M. Mandal, and M. Kankanhalli, “Distill to delete:
Unlearning in graph networks with knowledge distillation,”
arXiv preprint arXiv:2309.16173, 2023.
8
B. Sachdeva et al.
15. S. Schelter, M. Ariannezhad, and M. de Rijke, “Forget
me now: Fast and exact unlearning in neighborhood-based
recommendation,” in Proceedings of the 46th International
ACM SIGIR Conference on Research and Development in
Information Retrieval, ser. SIGIR ’23.
New York, NY, USA:
Association for Computing Machinery, 2023, p. 2011–2015.
[Online]. Available: https://doi.org/10.1145/3539618.3591989
16. Z. Wu, J. Zhu, Q. Li, and B. He, “Deltaboost: Gradient
boosting decision trees with eﬃcient machine unlearning,”
Proc. ACM Manag. Data, vol. 1, no. 2, jun 2023. [Online].
Available: https://doi.org/10.1145/3589313
17. C. Pan, E. Chien, and O. Milenkovic, “Unlearning graph
classiﬁers
with
limited
data
resources,”
2022.
[Online].
Available: https://arxiv.org/abs/2211.03216
18. E.
Chien,
C.
Pan,
and
O.
Milenkovic,
“Cer-
tiﬁed
graph
unlearning,”
2022.
[Online].
Available:
https://arxiv.org/abs/2206.09140
19. Y. Li, C. Chen, X. Zheng, Y. Zhang, B. Gong, J. Wang, and
L. Chen, “Selective and collaborative inﬂuence function for ef-
ﬁcient recommendation unlearning,” Expert Systems with Ap-
plications, vol. 234, p. 121025, 2023.
20. Y. Li, C. Chen, X. Zheng, Y. Zhang, Z. Han, D. Meng,
and J. Wang, “Making users indistinguishable: Attribute-
wise unlearning in recommender systems,” in Proceedings
of the 31st ACM International Conference on Multimedia,
ser.
MM
’23.
New
York,
NY,
USA:
Association
for
Computing Machinery, 2023, p. 984–994. [Online]. Available:
https://doi.org/10.1145/3581783.3612418
21. Y. Zhang, Z. Hu, Y. Bai, F. Feng, J. Wu, Q. Wang, and
X. He, “Recommendation unlearning via inﬂuence function,”
2023. [Online]. Available: https://arxiv.org/abs/2307.02147
22. C. Chen, F. Sun, M. Zhang, and B. Ding, “Recommendation
unlearning,” in Proceedings of the ACM Web Conference
2022, ser. WWW ’22.
New York, NY, USA: Association for
Computing Machinery, 2022, p. 2768–2777. [Online]. Available:
https://doi.org/10.1145/3485447.3511997
23. W. Yuan, H. Yin, F. Wu, S. Zhang, T. He, and H. Wang,
“Federated unlearning for on-device recommendation,” 2022.
[Online]. Available: https://arxiv.org/abs/2210.10958
24. G. Lin, F. Liang, W. Pan, and Z. Ming, “Fedrec: Federated
recommendation with explicit feedback,” IEEE Intelligent Sys-
tems, vol. 36, no. 5, pp. 21–30, 2021.
25. S. Zhang, W. Yuan, and H. Yin, “Comprehensive privacy anal-
ysis on federated recommender system against attribute infer-
ence attacks,” IEEE Transactions on Knowledge and Data En-
gineering, pp. 1–13, 2023.
26. X.
Zhu,
G.
Li,
and
W.
Hu,
“Heterogeneous
federated
knowledge graph embedding learning and unlearning,” in
Proceedings of the ACM Web Conference 2023, ser. WWW
’23.
New
York,
NY,
USA:
Association
for
Comput-
ing
Machinery,
2023,
p.
2444–2454.
[Online].
Available:
https://doi.org/10.1145/3543507.3583305
27. Z. Deng, Z. Han, C. Ma, M. Ding, L. Yuan, C. Ge, and
Z. Liu, “Vertical federated unlearning on the logistic regression
model,” Electronics, vol. 12, no. 14, p. 3182, Jul. 2023. [Online].
Available: https://doi.org/10.3390/electronics12143182
28. C. Ganh¨or, D. Penz, N. Rekabsaz, O. Lesota, and M. Schedl,
“Unlearning protected user attributes in recommendations with
adversarial training,” in Proceedings of the 45th International
ACM SIGIR Conference on Research and Development in
Information Retrieval, ser. SIGIR ’22.
New York, NY, USA:
Association for Computing Machinery, 2022, p. 2142–2147.
[Online]. Available: https://doi.org/10.1145/3477495.3531820
29. J. Leysen, “Exploring unlearning methods to ensure the
privacy, security, and usability of recommender systems,” in
Proceedings of the 17th ACM Conference on Recommender
Systems, ser. RecSys ’23.
New York, NY, USA: Association
for
Computing
Machinery,
2023,
p.
1300–1304.
[Online].
Available: https://doi.org/10.1145/3604915.3608862
30. J. Liu, M. Xue, J. Lou, X. Zhang, L. Xiong, and Z. Qin, “Muter:
Machine unlearning on adversarially trained models,” in Pro-
ceedings of the IEEE/CVF International Conference on Com-
puter Vision, 2023, pp. 4892–4902.
31. Y. Li, C. Chen, X. Zheng, J. Liu, and J. Wang, “Making rec-
ommender systems forget: Learning and unlearning for erasable
recommendation,” Knowledge-Based Systems, p. 111124, 2023.
32. J.
Liu,
J.
Lou,
Z.
Qin,
and
K.
Ren,
“Certiﬁed
min-
imax
unlearning
with
generalization
rates
and
deletion
capacity,”
in
Thirty-seventh
Conference
on
Neural
In-
formation
Processing
Systems,
2023.
[Online].
Available:
https://openreview.net/forum?id=6H8Md75kAw
33. J. Leysen, “Exploring unlearning methods to ensure the
privacy, security, and usability of recommender systems,” in
Proceedings of the 17th ACM Conference on Recommender
Systems, ser. RecSys ’23.
New York, NY, USA: Association
for
Computing
Machinery,
2023,
p.
1300–1304.
[Online].
Available: https://doi.org/10.1145/3604915.3608862
34. S. Zhang, J. Lou, L. Xiong, X. Zhang, and J. Liu, “Closed-form
machine unlearning for matrix factorization,” in Proceedings of
the 32nd ACM International Conference on Information and
Knowledge Management, ser. CIKM ’23. New York, NY, USA:
Association for Computing Machinery, 2023, p. 3278–3287.
[Online]. Available: https://doi.org/10.1145/3583780.3614811
"
"Preference-based reinforcement learning (RL) provides a framework to train agents using human feedback through pairwise preferences over pairs of behaviors, enabling agents to learn desired behaviors when it is difficult to specify a numerical reward function. While this paradigm leverages human feedback, it currently treats the feedback as given by a single human user. Meanwhile, incorporating preference feedback from crowds (i.e. ensembles of users) in a robust manner remains a challenge, and the problem of training RL agents using feedback from multiple human users remains understudied.nan","Reinforcement learning (RL) from human feedback is a promising approach for learning intelligent behaviors in the absence of a known numerical reward signal. Such methods have shown success in domains such as Atari games, robotics, and large language models (LLMs). In this work, we consider human feedback that is crowdsourced, i.e., where (1) data is labeled by multiple human users (e.g. ≥ 2 labels for each data point), and (2) these labels are aggregated to form an ensemble label to be used for downstream analysis.nan","nanEarly works that explicitly model human feedback from crowds have focused on imitation learning, where there are multiple demonstrations (assumed to be from multiple human users) of unknown expertise and quality, and the goal is to learn a policy reflecting expert behavior. Recent work that has explicitly modeled crowdsourced data for imitation learning has shown significant performance gains from simultaneously modeling human demonstrations and estimating the demonstrators’ expertise levels. While recent work by [Zhang and Kashima, 2023] used crowdsourcing methods to learn a reward function using preference-based reward learning, it is limited to the offline RL case, where there is a fixed dataset of preference pairs, and the RL algorithm does not have online access to the environment.nan","We next explain our methodology for simulating diverse crowds of human users with different rationality levels. Afterwards, we outline our Crowd-PrefRL approach to performing RL with crowdsourced feedback (Algorithm 1): first, we explain how to estimate preference labels from a crowd and then, we show how to integrate these crowd-aggregated preference labels into a framework for preference-based RL.nan","We see a strong positive correlation between the error rates of users in the crowd and the performance of SML compared to MAJ. In particular, as the user error increases (indicating a more diverse crowd), the better the SML labels perform compared to the MAJ labels. This indicates that the SML is effectively filtering out inconsistent preference feedback from users who have higher error rates and aggregating crowd decisions more consistently compared to MAJ.nan",This work demonstrates the viability of learning reward functions from preference feedback provided by crowds of unknown expertise and reliability. We believe that this is the first work that focuses on using preference feedback from crowds to learn a crowdsourced reward function for preference-based RL in the online RL setting.nan,Crowd-PrefRL: Preference-Based Reward Learning from Crowds,"David Chhan, Ellen Novoseller, Vernon J. Lawhern","Crowd-PrefRL: Preference-Based Reward Learning from Crowds
David Chhan, Ellen Novoseller, and Vernon J. Lawhern
DEVCOM Army Research Laboratory
Aberdeen Proving Ground, MD 21005 USA
{david.chhan.civ, ellen.r.novoseller.civ,
vernon.j.lawhern.civ}@army.mil
Abstract
Preference-based reinforcement learning (RL) pro-
vides a framework to train agents using human
feedback through pairwise preferences over pairs
of behaviors, enabling agents to learn desired be-
haviors when it is difficult to specify a numerical
reward function.
While this paradigm leverages
human feedback, it currently treats the feedback
as given by a single human user. Meanwhile, in-
corporating preference feedback from crowds (i.e.
ensembles of users) in a robust manner remains a
challenge, and the problem of training RL agents
using feedback from multiple human users remains
understudied. In this work, we introduce Crowd-
PrefRL, a framework for performing preference-
based RL leveraging feedback from crowds. This
work demonstrates the viability of learning re-
ward functions from preference feedback provided
by crowds of unknown expertise and reliability.
Crowd-PrefRL not only robustly aggregates the
crowd preference feedback, but also estimates the
reliability of each user within the crowd using only
the (noisy) crowdsourced preference comparisons.
Most importantly, we show that agents trained
with Crowd-PrefRL outperform agents trained with
majority-vote preferences or preferences from any
individual user in most cases, especially when the
spread of user error rates among the crowd is large.
Results further suggest that our method can identify
minority viewpoints within the crowd.
1
Introduction
Reinforcement learning (RL) from human feedback [Casper
et al., 2023] is a promising approach for learning intelligent
behaviors in the absence of a known numerical reward signal.
Such methods have shown success in domains such as Atari
games [Christiano et al., 2017], robotics [Wilde et al., 2021;
Torne et al., 2023; Lee et al., 2021], and large language mod-
els (LLMs) [Ouyang et al., 2022]. In this work, we consider
human feedback that is crowdsourced, i.e., where (1) data is
labeled by multiple human users (e.g. ≥ 2 labels for each
data point), and (2) these labels are aggregated to form an en-
semble label to be used for downstream analysis. In applica-
Figure 1: Crowd-PrefRL framework for preference-based RL from
crowds. We assume a crowd, or ensemble, of users is queried for
their preferences over pairs of segmented behaviors (A vs.
B).
These crowd preferences are then used to learn a reward function
for preference-based RL.
tions from LLMs to household robotics to autonomous driv-
ing, crowdsourced human data could enable RL algorithms
to learn user-preferred behaviors that are robust across many
real-world situations. Yet, at the same time, crowdsourcing
algorithms will need to recognize and account for disagree-
ment across users in the crowd. Example scenarios could in-
clude: an algorithm that a) trains models that are sensitive
to multiple user viewpoints (e.g., an LLM provides informa-
tion that benefits an underrepresented minority at minimal
cost to the majority [Siththaranjan, Laidlaw, and Hadfield-
Menell, 2023]), b) trains models that reflect a majority view-
point while enabling downstream individual personalization
(e.g., a household robot demonstrates performant out-of-the-
box behavior, but fine-tunes to specific users’ preferences for
tidying and organization), and c) identifies and rejects mali-
cious user data (e.g., an LLM is resilient to feedback contain-
ing misinformation).
This work considers RL from crowdsourced pairwise pref-
erences, in which a human answers queries of the form “Do
you prefer A or B?” [Christiano et al., 2017; Lee, Smith, and
Abbeel, 2021; Lee et al., 2021]. Current preference-based
RL methods treat preference feedback as given by a single
human user, even if the feedback is actually given by mul-
tiple users with potentially different backgrounds and levels
of expertise. For example, when learning reward functions
for training LLMs, each individual preference pair query is
typically shown to just one of the users due to multiple con-
straints (e.g. cost, human labeling time/effort); thus, the full
labeled dataset aggregates the disjoint query subsets shown
to each user [Ouyang et al., 2022]. However, it may often be
arXiv:2401.10941v1  [cs.HC]  17 Jan 2024
preferable to not only obtain feedback from a group of users,
but also to aggregate the crowdsourced data in a non-naive
manner that recognizes differences between individuals. This
capability can be beneficial for multiple reasons, for example
to analyze patterns of disagreement in preference feedback
across the crowd and to detect minority groups in the crowd
(i.e., users that provide feedback that is consistently different
from the majority). It also holds important practical model-
ing implications, for example mitigating model bias and en-
suring fairness [Ouyang et al., 2022] and assisting users with
diverse preferences or varying degrees of noise in their feed-
back [Siththaranjan, Laidlaw, and Hadfield-Menell, 2023].
While previous literature uses crowdsourcing methods
to aggregate labels across users and learn crowd prefer-
ences [Chen et al., 2013; Li et al., 2016], the specific ap-
plication of crowdsourcing to reward learning in RL re-
mains understudied. Early works that explicitly model hu-
man feedback from crowds have focused on imitation learn-
ing, where there are multiple demonstrations (assumed to be
from multiple human users) of unknown expertise and qual-
ity, and the goal is to learn a policy reflecting expert behav-
ior [Babes et al., 2011; Dimitrakakis and Rothkopf, 2012;
Hausman et al., 2017]. As noted in [Beliaev et al., 2022],
however, these approaches simply aggregate the feedback
from multiple humans into one homogeneous group, poten-
tially leading to sub-optimal learning due to the presence of
varying levels of expertise and reliability among the different
human users. Recent work that has explicitly modeled crowd-
sourced data for imitation learning [Beliaev et al., 2022]
has shown significant performance gains from simultaneously
modeling human demonstrations and estimating the demon-
strators’ expertise levels. While recent work by [Zhang and
Kashima, 2023] used crowdsourcing methods to learn a re-
ward function using preference-based reward learning, it is
limited to the offline RL case [Levine et al., 2020], where there
is a fixed dataset of preference pairs, and the RL algorithm
does not have online access to the environment. This poten-
tially limits the expressiveness of the learned reward function
to the behaviors contained in the offline dataset.
In this work, we study preference-based RL leveraging
feedback from crowds in the online RL scenario, where the
RL algorithm has access to the environment and can sample
new preference pairs for the crowd to label throughout model
training. Specifically:
1. We introduce the Crowd-PrefRL framework for per-
forming online preference-based RL leveraging feed-
back from crowds and instantiate Crowd-PrefRL us-
ing Proximal Policy Optimization (PPO) [Schulman
et al., 2017], a state-of-the-art RL algorithm, to pro-
pose Crowd-PrefPPO. Crowd-PrefRL aggregates the
user feedback to learn crowdsourced preference labels,
and then uses those labels for reward function learning
in preference-based RL (see Figure 1).
2. We use techniques derived from unsupervised ensem-
ble learning to robustly aggregate the crowd preference
feedback, estimating each user’s reliability in a com-
pletely unsupervised fashion and detecting the presence
of multiple, e.g. minority, viewpoints among the crowd.
3. We perform experiments suggesting that RL agents
trained with crowd preferences outperform RL agents
trained via majority-vote preferences or preferences
from any individual crowd member, in particular when
the spread of user errors among the crowd is large.
We also show a proof-of-concept for the ability of our
method to identify minority viewpoints within a crowd.
This work demonstrates the viability of learning reward func-
tions from preference feedback provided by crowds of un-
known expertise and reliability. We believe that this is the first
work that focuses on using preference feedback from crowds
to learn a crowdsourced reward function for preference-based
RL in the online RL setting.
2
Problem Formulation
In this paper, we are concerned with answering the following
questions: (1) How can we effectively combine preference
feedback from multiple users of unknown expertise and un-
known reliability in the absence of ground-truth information?
(2) Can we derive who are the “best” users in a given crowd in
an unsupervised manner? (3) Can we learn a crowdsourced
reward function that is better than any individual user’s re-
ward function?, and (4) Can we detect the presence of mi-
nority feedback (as opposed to purely noisy feedback) in the
crowd based only on the preference feedback? This section
formulates this problem more precisely.
We consider an agent that takes actions and interacts with
an environment [Sutton and Barto, 2018], such that at each
timestep t, the agent receives a state st from the environment
and chooses an action at based on its policy π. In traditional
episodic RL, the environment also returns a reward r(st, at),
and the agent seeks to maximize the total discounted sum
of rewards over an episode.
However, for many complex
tasks, it is difficult to construct a suitable reward function.
Preference-based RL approaches instead query a human user
to obtain preference feedback over segments of agent behav-
iors, and use this feedback to learn a reward function [Chris-
tiano et al., 2017; Lee, Smith, and Abbeel, 2021]. A seg-
ment is defined as a length-H sequence of observations and
actions, {(s1, a1), ..., (sH, aH)}. Given a pair of segments
x = (A, B), a user indicates which segment is preferred: +1
in the event that A is preferred over B (denoted by A ≻ B) or
−1 if B is preferred over A (denoted by A ≺ B). Preference-
based RL aims to train an agent to perform human-desirable
behaviors according to the human user’s preferences.
Our problem formulation assumes access to a crowd, or en-
semble, of users, who each assign pairwise preference labels
to a sequentially-selected set S = {xk}S
k=1, S = |S| of seg-
ment pairs. Each query xk takes the form xk = (Ak, Bk),
where Ak, Bk belong to the set X of available segments. In
addition, we assume that a majority (e.g. at least 51%) of the
crowd provides preference feedback according to a shared un-
derstanding of desired agent behavior. More concretely, we
assume the existence of an unknown ground-truth reward r,
and that for a majority of users, their preferences are (noisily)
generated with respect to r. Note that this formulation allows
a minority group of users to potentially provide feedback ac-
cording to a different reward function(s). Beyond this, we
do not assume any further knowledge about the crowd (e.g.
expertise, reliability). Our goal is to learn a crowd-informed
preference label for each segment pair using only the prefer-
ence labels given by the crowd. Formally, let {fi}M
i=1 rep-
resent M users of unknown reliability and error rate, where
each user i provides a preference label fi(xk) ∈ {−1, 1} on
each input query xk ∈ S. Then, let y be the vector of (un-
known to the algorithm) ground-truth labels according to the
true reward r (i.e., in which segments with higher ground-
truth reward are preferred), y = [y1, ..., yS]T . Using only the
preference labels from M users on the segment pairs in S and
without access to any ground-truth rewards or preferences, we
seek an optimal estimate ˆy = [ˆy1, ..., ˆyS]T of the true labels
y given the crowd preference labels. We also investigate the
ability to identify minority groups of users who provide feed-
back that consistently differs from that of the majority.
3
Methods
We next explain our methodology for simulating diverse
crowds of human users with different rationality levels. Af-
terwards, we outline our Crowd-PrefRL approach to perform-
ing RL with crowdsourced feedback (Algorithm 1): first, we
explain how to estimate preference labels from a crowd and
then, we show how to integrate these crowd-aggregated pref-
erence labels into a framework for preference-based RL.
3.1
Simulating Diverse Crowds
In order to systematically evaluate and study the effects of
user error rates and their impact on learning from crowd-
sourced user preferences, we apply the Stochastic Preference
Model [Lee et al., 2021] to simulate users with mixtures of
different irrationality levels:
P[A ≻ B; β, γ] =
(1)
e(β PH
t=1 γH−tr(si
t,ai
t))
e(β PH
t=1 γH−tr(si
t,ai
t)) + e(β PH
t=1 γH−tr(sj
t,aj
t)) ,
where γ ∈ (0, 1] is a discount factor to model myopic behav-
ior and β is a rationality constant. Note that user feedback is
fully rational and deterministic as β → ∞, whereas β = 0
produces uniformly random choices. In addition, we model
an additional parameter ϵ that models users making mistakes
due to accidental errors. For our analysis, each user is sim-
ulated with a random draw of parameters from the following
ranges: γ ∈ [0.96, 1.0], β ∈ [−0.5, −1.0], and ϵ ∈ [0.1, 0.5].
These parameter ranges where chosen as they produced di-
verse user error rates primarily between 15% and 40%, which
is approximately the range of human error rates observed
in a prior study of human feedback in preference-based RL
(12%−37% in [Brown et al., 2019]). We then sample crowds
of M ∈ {7, 11, 15} users according to this model to study the
effect of crowd size on crowd label learning.
3.2
Estimating Preference Labels from a Crowd
For each query, Crowd-PrefRL distills the M preference la-
bels from each crowd member to a single preference label.
We discuss two methods for accomplishing this distillation.
The first, majority voting, is a comparatively naive approach,
Algorithm 1 Crowd-PrefRL: Preference-based RL with re-
ward learning from crowds
Require: frequency of crowd feedback K
Require: number of queries Nquery per feedback session
Require: crowd size M
Require: crowdsource method, one of (“MAJ”, “SML”)
1: Initialize parameters of policy πϕ, reward model brψ, pref-
erence dataset D ← ∅, and buffer B ← ∅
2: // EXPLORATION PHASE
3: B, πϕ ← EXPLORE() according to policy πϕ
4: for each iteration do
5:
// REWARD LEARNING
6:
if iteration % K == 0 then
7:
for m in 1 . . . Nquery do
8:
Sample pair of segments (A, B)
9:
ˆy1:M ← query all M users in crowd
10:
end for
11:
if crowd method == “SML” then
12:
Compute SML ranking vector ˆvi
13:
Compute ˆySML according to (2)
14:
ˆy ← ˆySML
15:
else Compute MAJ label estimate ˆyMAJ
16:
ˆy ← ˆyMAJ
17:
end if
18:
D ← D ∪ {(A, B, ˆy)}
19:
for each gradient step do
20:
Sample batch {(A, B, ˆy)j}|D|
j=1 ∼ D
21:
Optimize LReward (4) with respect to ψ
22:
end for
23:
end if
24:
// POLICY LEARNING
25:
for each timestep t do
26:
Collect st+1 by taking at ∼ π(at|st)
27:
B ← B ∪ {(st, at, st+1, brψ(st))}
28:
end for
29:
for each gradient step do
30:
Sample random minibatch {(τj)}B
j=1 ∼ B
31:
Optimize RL objective with respect to ϕ
32:
end for
33:
Reset B ← ∅ if on-policy RL algorithm is used
34: end for
while the second, the Spectral Meta Learner (SML) [Parisi et
al., 2014] is the method we recommend for use with Crowd-
PrefRL. Note that our Crowd-PrefRL framework generalizes
the crowdsourcing approach in [Brown et al., 2019], in which
majority voting is used to merge preference labels.
Majority Vote (Baseline).
Given the current problem for-
mulation, where we do not know any additional information
about the crowd, perhaps the simplest estimate ˆy is the major-
ity vote (MAJ), which labels each segment pair xk ∈ S with
the majority preference from the crowd, denoted as ˆyMAJ.
Spectral Meta-Learner.
However, it is indeed possible to
estimate a crowd label that often outperforms the majority
vote in the fully unsupervised case studied here. Under the
assumption that users in a crowd make independent errors,
[Parisi et al., 2014] derived the Spectral Meta-Learner (SML):
ˆyk = sign
 M
X
i=1
fi(xk) ∗ ˆvi
!
,
(2)
where ˆvi is the lead eigenvector of the covariance matrix ob-
tained from the predictions of a set of binary classifiers on a
given query; in our case, these correspond to each user’s bi-
nary preference on a given pairwise comparison query. As
shown in [Parisi et al., 2014], crowd labels derived via the
SML are typically more accurate than labels from any indi-
vidual crowd member or from a majority vote, as unlike other
methods such as majority vote, the SML approximates a max-
imum likelihood estimate of the labels. In addition, [Parisi et
al., 2014] showed that ˆvi can rank the users by their estimated
error rates, which approximate the ground truth error rates.
We denote labels estimated by SML as ˆySML.
[Parisi et al., 2014] also analyze the performance of SML
in the presence of a cartel, a small group of users who at-
tempt to steer the overall ensemble solution away from the
(unknown) ground truth, and proved that (1) SML is robust to
the presence of cartels, and that (2) the weights of the eigen-
vector ˆvi can be used to identify the presence of cartels in
the crowd. Here, we re-define the notion of a cartel as a mi-
nority group who provides feedback that consistently differs
from the majority, for example users who provide feedback
towards goals that are different than the goals of the majority.
3.3
Crowdsourced Preference Learning for RL
Crowd-PrefRL leverages the crowd-aggregated preference la-
bels ˆy = ˆySML for all instances in S. We denote via D the
dataset of all pairs {(x, y)}, where x ∈ S and y is the corre-
sponding crowd-aggregated label in ˆy. To learn useful behav-
iors given these aggregated labels, we assume that the major-
ity of users (though not necessarily all users) have a shared
understanding of desired behavior, which can be quantified
in terms of an underlying reward function. Given the crowd-
aggregated labels, our objective is to learn the reward func-
tion, and ultimately a policy, that preserves the underlying
user preferences [Christiano et al., 2017]. This is done in two
steps: (1) a reward function learning step, where we optimize
the learned reward via supervised learning from the prefer-
ence labels ˆy over segment pairs generated by the policy π,
and (2) a policy learning step, where the agent performs roll-
outs in the environment and optimizes its policy against the
current reward function estimate. Segment pairs for prefer-
ence queries are selected according to an entropy-based mea-
sure from an ensemble of reward predictors, similarly to [Lee
et al., 2021]. These steps are then repeated for a set number of
environment steps. Algorithm 1 shows the algorithmic steps
needed for preference-based RL with learned rewards from
crowds, and is analogous to [Lee et al., 2021] with red text
denoting the modifications needed to crowdsource the prefer-
ence labels rather than obtaining them from a single human.
Similarly to [Lee et al., 2021; Christiano et al., 2017], we
learn a reward model brψ, modeled as a neural network with
parameters ψ, that predicts the user preferences as follows:
Pψ[A ≻ B] =
exp P
t brψ(sA
t , aA
t )
P
i∈{A,B} exp P
t brψ(si
t, ai
t).
(3)
The reward function brψ is then updated by minimizing the
following cross-entropy loss:
LReward = −
E
(A,B,y)∼D
h
1[y=−1] log Pψ[B ≻ A]+
1[y=1] log Pψ[A ≻ B]
i
,
(4)
where 1[·] denotes an indicator variable. Given the learned re-
ward function brψ, a policy π can be learned using any RL al-
gorithm. In this work, we use PrefPPO [Lee et al., 2021], in-
stantiating Crowd-PrefRL as Crowd-PrefPPO. PrefPPO uses
Proximal Policy Optimization (PPO), a state-of-the-art on-
policy RL algorithm [Schulman et al., 2017].
As recom-
mended in [Lee et al., 2021], we use on-policy methods to
reduce the effects of non-stationarity induced by learning a
reward function and policy simultaneously.
4
Experiments
4.1
Experiment Setup
We conduct experiments to evaluate the proposed approach
to crowdsourcing human feedback for preference learning.
Our experiments conduct RL from human preferences us-
ing the PrefPPO implementation in [Lee et al., 2021]. These
experiments use the Walker-walk, Quadruped-walk,
and Cheetah-run environments from the DMControl
suite [Tassa et al., 2018], as two of these environments
(Walker-walk and Quadruped-walk) were previously
used in [Lee et al., 2021]. For each environment, we report
results for Crowd-PrefPPO (SML preference estimation) and
the following comparisons: Crowd-PrefPPO-MAJ (in which
the majority vote is used instead of the SML estimate) and
Crowd-PrefPPO-Oracle (in which the preference is given to
the segment with the highest ground-truth environment re-
ward); in addition, we compare Crowd-PrefPPO’s estimated
preference labels to those from the best member of each
crowd. We perform 10 total runs of each algorithm compari-
son in each environment for 4M environment steps. Methods
are compared via the mean and standard error over 6 runs,
where the top 2 and bottom 2 runs are omitted (measured by
episode return at 4M environment steps) to reduce the impact
of outliers (similar to the InterQuartile Mean, IQM [Agarwal
et al., 2021]). All remaining hyper-parameters for our method
can be found in the Appendix, and notably, are the same as
reported in [Lee et al., 2021].
4.2
Results
We first study the effect of crowd size on the performance
of crowdsourced preference learning by simulating 100 dif-
ferent random crowd configurations at each of three differ-
ent crowd sizes (M ∈ {7, 11, 15}) according to the Stochas-
tic Preference Model in Equation (1) for the Walker-Walk
environment; see Methods for how these diverse crowds are
simulated. Figure 2 depicts the difference in errors between
the MAJ and SML preference estimates versus the diversity
in users’ error rates with respect to the ground-truth reward
(quantified via the standard deviation of user error across the
crowd) for each simulated crowd size. To calculate these er-
rors for each simulated crowd configuration, we first perform
Figure 2: Difference in MAJ and SML preference prediction error rates for different levels of variability (standard deviation) in user error
rates. Values are calculated across 100 randomly-sampled crowds of 7, 11 and 15 simulated users for the Walker-walk environment. The
horizontal dashed line at y = 0 indicates where the MAJ and SML error rates are the same; points above y = 0 indicate that the SML labels
have lower error than the MAJ labels. We see a strong positive correlation, with increasing standard deviations (indicating a more diverse
crowd) leading to improved SML label accuracy (lower error rate) compared to MAJ labels. In addition, we see a similar trend across all
crowd sizes, suggesting that our method is robust across different sizes of crowds. Red dots indicate where SML outperforms the best crowd
member, while blue dots indicate where the best crowd member outperforms SML.
one full training run of Crowd-PrefPPO using Oracle prefer-
ence labels to generate the full set of segment pairs needed for
reward labeling. Then, we use these segment pairs and their
ground-truth labels to construct the error rates for all users in
the crowd and the error rates corresponding to the MAJ and
SML labels. We note that results were similar for the other
environments tested, and therefore show results for only the
Walker-walk environment due to space constraints. There
are several results here that are worth discussing. First, we see
a strong positive correlation between the error rates of users
in the crowd and the performance of SML compared to MAJ.
In particular, as the user error increases (indicating a more
diverse crowd), the better the SML labels perform compared
to the MAJ labels. This indicates that the SML is effectively
filtering out inconsistent preference feedback from users who
have higher error rates and aggregating crowd decisions more
consistently compared to MAJ. Second, we see that SML out-
performs MAJ in nearly all cases (≈ 90% of points above
y = 0), suggesting that SML captures the crowd preferences
more accurately than MAJ. Third, we see that the SML la-
bels have lower errors than the best crowd member’s labels
in nearly all cases (red dots). As the crowd size increases,
we see fewer instances of SML performing worse than the
best member of the crowd (blue dots), while simultaneously
having more instances where SML outperforms MAJ (dots
above y = 0 dashed line). Finally, across all crowd sizes,
the spread of the difference in MAJ errors and SML errors is
fairly consistent (most points fall between [0, 6]%), suggest-
ing that SML labels can outperform MAJ labels with most
crowd configurations.
While this improvement may seem
small, it occurs during every reward learning iteration; we
believe that this leads to compounding benefits during reward
learning, and consequently, during agent policy learning.
Having studied how crowd configuration variability af-
fects the respective prediction errors of the SML and MAJ
crowd preference estimators, we next conduct experiments
with Crowd-PrefPPO using the crowdsourced preference la-
bels; in these experiments, we aim to determine if the im-
proved label error from SML observed in Figure 2 impacts
agent performance in a meaningful way. For this analysis,
we select a fixed crowd size of M = 11 users and sample
two different crowd configurations: (1) Figure 3a studies a
crowd for which SML outperforms MAJ by approx. 3% in
prediction error (following the analysis in Figure 2), and (2)
Figure 3b studies a crowd for which SML performs similarly
to MAJ in prediction error (similarly from the analysis in Fig-
ure 2). In addition, in the bottom row of Figure 3, we plot the
error rates of the MAJ and SML label predictions relative to
the ground-truth labels during each crowd feedback iteration
for all three tested environments (200 queries per iteration for
Quadruped-walk and 100 otherwise; see the Appendix
for more details).
In Figure 3a,
we see that Crowd-PrefPPO outper-
forms Crowd-PrefPPO-MAJ in terms of trajectory return
for all tested environments, with Crowd-PrefPPO achiev-
ing close to Oracle performance for Walker-walk and
Quadruped-walk. In addition, the SML label errors are
lower than the MAJ label errors at each feedback iteration in
most cases for each environment. The lower SML label er-
rors imply that there is a compounding benefit to using SML
labels rather than MAJ labels for reward learning; in early
feedback iterations, the learned reward function has lower
error and thus is closer to the Oracle reward function com-
pared to MAJ. This improves overall agent training, as (1)
the agent receives more accurate rewards for its actions, en-
abling it to learn better behaviors earlier in the training loop,
and (2) future crowd feedback iterations receive “better” seg-
ment pairs for the crowd to label, yielding more useful in-
formation about the reward function. We speculate that this
is why Crowd-PrefPPO’s performance compares fairly well
with that of Crowd-PrefPPO-Oracle. We see a similar, but
weaker, trend in Figure 3b, where SML is expected to yield
a similar label accuracy to MAJ for the given crowd config-
uration. There is generally less spread in episode returns be-
Figure 3: (Top row) Comparison of Crowd-PrefPPO training curves with SML, MAJ and Oracle labeling across two different crowd config-
urations: [(a), left] a crowd for which SML is expected to outperform MAJ, and [(b), right] a crowd for which SML is expected to perform
similarly to MAJ across the three different environments (Walker-walk, Quadruped-walk and Cheetah-run). (Bottom row) Com-
parison of MAJ and SML label prediction errors at each feedback iteration. Each plot shows the mean ± standard error of 6 out of 10 runs
(the top and bottom 2 runs are omitted to reduce the effect of outliers, as detailed in the Experiment Setup).
Figure 4: Plot of ground-truth error rate for each user in the crowd
vs. the SML weight vector vi for the same two SML configurations
shown in Figure 3 in the Walker-walk environment. Across both
conditions, we see a significant correlation between the weights gen-
erated by the SML and individual crowd member performance mea-
sured by the users’ (unknown) error rates, suggesting that users can
be ranked accurately in the absence of ground-truth error informa-
tion about the crowd.
tween SML and MAJ for the three tested environments (top
row of Figure 3b), and we see that the crowd feedback errors
are closer between the methods during all crowd feedback it-
erations (bottom row of Figure 3b), indicating only minimal
benefits of SML labels over MAJ labels. However, we do
see that Crowd-PrefPPO can sometimes perform quite well
overall, for example in Quadruped-walk.
Furthermore, we analyze the crowd member ranking de-
rived by SML for the same two conditions shown in Figure
3 and the Walker-walk environment (results were similar
for all environments, thus we report only one due to space
constraints). While Crowd-PrefPPO calculates the eigenvec-
tor vi during each feedback iteration, we here instead calcu-
late vi using all crowdsourced preference labels for simplic-
ity of visualization. Results are shown in Figure 4. We see
that across both conditions, the SML-derived member rank-
ings are significantly correlated to the individual members’
Figure 5: Plot of ground-truth error rate vs. the SML weight vector
vi for a crowd configuration where there are three distinct groups of
users: users who provide feedback according to (1) the ground-truth
reward r (blue), (2) at random (black), and (3) the opposite of the
ground-truth reward, −r (red). We see distinct groupings of users
by their feedback category and a strong correlation between their
(unknown) error rates and the SML weight vector vi, suggesting
that minority groups of users can be accurately identified.
error rates (i.e., higher SML weight values indicate lower er-
ror rates), suggesting that even when SML performs similarly
to MAJ in label error (Figure 4b), SML can still identify the
best members in the crowd. This showcases additional util-
ity of SML aggregation over MAJ aggregation even in the
situation where SML provides no benefit in label accuracy
compared to MAJ.
Finally, we test the ability of SML to detect the presence
of minority group feedback based purely on the preference
labels. We follow the same analysis used in Figure 4, ex-
cept that we simulate a crowd of 15 users according to three
groups: users who provide noisy preference feedback accord-
ing to (1) the ground-truth reward r (9 users), (2) at random (3
users), and (3) −r, the opposite of the ground-truth (3 users).
Results are shown in Figure 5. As expected, we see that MAJ
error rates are significantly higher compared to SML rates,
since MAJ is more sensitive to the presence of noisy labels.
In addition, we see distinct clusters of users based on their
feedback category, suggesting that the SML weights vi can be
used to identify the presence of minority groups of users, as
well as the identities of the minority group members. These
results suggest that Crowd-PrefRL could be used to cluster
users via their objectives and to learn reward functions and
corresponding behaviors specific to each user cluster. Such
functionality could enable a behavior-based characterization
of the objective associated with each user cluster.
5
Discussion
This study aimed to determine how to (1) effectively com-
bine preference feedback from crowds of unknown expertise
and reliability in the absence of ground-truth information,
(2) identify the “best” users in a given crowd in an unsu-
pervised manner, (3) learn a crowdsourced reward function
that is more accurate than the reward learned from any in-
dividual user, and (4) identify minority groups based purely
on their preference feedback. We propose the Crowd-PrefRL
framework and instantiate it as Crowd-PrefPPO. Our evalu-
ation of Crowd-PrefPPO indicates that we can use methods
derived from unsupervised ensemble learning (SML, [Parisi
et al., 2014]) to effectively aggregate user preference feed-
back across diverse crowds in the absence of any ground-
truth information about the users. Furthermore, our evalua-
tion suggests that Crowd-PrefPPO can identify which users in
a crowd are likely most reliable and that the reward function
learned from crowd-aggregated labels is more accurate than
the reward derived from any single user’s feedback (even the
best user!). Finally, we show the possibility of detecting clus-
ters of minority feedback in an unsupervised manner, poten-
tially enabling a deeper understanding of model behavior (e.g.
detecting the presence of multiple user viewpoints, character-
izing the associated objectives, and mitigating effects of mali-
cious user data [Siththaranjan, Laidlaw, and Hadfield-Menell,
2023; Ouyang et al., 2022]). To the best of our knowledge,
this is the first demonstration of (1) learning crowd-level pref-
erence labels for preference-based RL via unsupervised en-
semble learning methods in the online RL setting and (2)
identification of minority groups in the crowd based purely
on the crowd’s preference feedback.
Previous work has studied crowdsourcing preference la-
bels for reward learning in the offline RL case [Zhang and
Kashima, 2023], as opposed to the online RL case we study
here. In the offline case, a dataset of preference pairs is al-
ready provided a priori, and the goal is to learn a reward
function from this static dataset. This limits the expressive-
ness of the learned reward function to the behaviors contained
in the dataset, whereas in our work, the preference pairs for
crowd labeling are sampled throughout agent training, and
by extension the learned reward function continuously im-
proves with better agent performance and better environment
exploration. In addition, the method in [Zhang and Kashima,
2023] requires training a separate model (e.g. fully connected
network) to infer crowd labels and member reliabilities, re-
quiring additional model training and tuning and increased
data requirements (50K preference pairs from 2,500 crowd-
workers). In contrast, our approach to inferring crowd labels
by the SML is learning and optimization-free: we need no
hyperparameters to specify, no model to train, and no opti-
mization procedure to learn a crowd label. Thus, we believe
it is more suitable in the online RL case where the number
of labeled preference pairs is small compared to the offline
RL case due to practical constraints (agent is training during
human feedback collection). Our work enables crowds to up-
date the reward function throughout agent training using pref-
erence feedback on just a handful of trials and furthermore,
allows for the detection of minority feedback groups, which
has important modeling applications in various domains.
We showed that SML labels outperform MAJ labels in
nearly all cases across different crowd sizes (Figure 2) and
different tasks (Figure 3). Calculating SML weights is com-
putationally very fast, only requiring a few lines of code in
modern programming languages (e.g. Python). Given the in-
creasing popularity of crowdsourcing platforms for data col-
lection in human-interactive RL studies (e.g. Amazon Me-
chanical Turk), these results indicate that simple code modi-
fications can result in significant performance gains. For ex-
ample, [Brown et al., 2019] used a crowdsourcing platform
for their human subjects data analysis and estimated prefer-
ence labels for segments by simply taking a majority vote
over multiple human users. It would be interesting to apply
Crowd-PrefRL to aggregate crowd preferences in such exist-
ing studies to determine the extent to which Crowd-PrefRL
improves over results from a majority vote or offline RL.
We believe that Crowd-PrefRL could be combined with re-
cent advances that make preference-based RL methods more
sample-efficient [Lee, Smith, and Abbeel, 2021; Park et al.,
2022].
Improvements to sample efficiency are made pri-
marily at the algorithmic or data level, as opposed to mod-
ifying the labels used to learn the reward.
For example,
PEBBLE [Lee, Smith, and Abbeel, 2021] combines unsu-
pervised pre-training with off-policy re-labeling of past data
to achieve improved sample efficiency compared to Pref-
PPO. SURF [Park et al., 2022] uses semi-supervised learn-
ing methods that combine data augmentation approaches with
confidence-based pseudo-labels of unlabeled experiences to
train the preference predictor.
Combining Crowd-PrefRL
with these orthogonal advancements could potentially lead to
further improvements in RL agent training performance.
Several downsides to our approach are important to dis-
cuss. First, each user in the crowd must provide a preference
label for each preference query. This results in significant hu-
man labeling cost if implemented in real-world studies. Our
results indicate that Crowd-PrefPPO can work well in fairly
small crowds with relatively small numbers of labels (100
queries per user per reward learning iteration). Future work
will focus on the possibility of using Crowd-PrefRL when
user feedback is sparse (i.e., not every user provides a pref-
erence for every segment pair). In addition, this study uses
only simulated human feedback and does not include human-
subjects data collection. Rather, we simulate human feed-
back via the Stochastic Preference Model, which allows for a
thorough and systematic evaluation of Crowd-PrefRL and an
analysis of its properties in a highly controlled setting. Future
work will evaluate this method in a human subjects study.
Appendix
Experiment Setup Hyper-parameters
Our
experiments
use
the
Walker-walk,
Quadruped-walk,
and Cheetah-run environments
from the DMControl suite [Tassa et al., 2018], as two of these
environments (Walker-walk and Quadruped-walk)
were previously used in [Lee et al., 2021].
All hyper-
parameters for our method can be found in Table 1, and
notably, are the same as reported in [Lee et al., 2021].
Hyperparameter
Value
GAE parameter λ
0.9 (Quadruped), 0.92 (otherwise)
Hidden units per each layer
256
Segment of length
50
# of layers
3
Learning rate
0.00005
Batch Size
128 (Quadruped), 64 (otherwise)
Discount ¯γ
.99
Frequency of feedback
32000
# of envs per worker
16 (Quadruped), 32 (otherwise)
PPO clip range
0.4
Entropy bonus
0.0
# of timesteps per rollout
500
Maximum budget
2000 (Quadruped), 1000 (otherwise)
# of feedbacks per session
200 (Quadruped), 100 (otherwise)
Table 1: Hyper-parameters of the Crowd-PrefPPO algorithm for all
environments.
Ethical Statement
In any real-world crowdsourcing application, it will be impor-
tant to protect user privacy such that only anonymized user
data is stored and so that user data is only stored given user
consent. Furthermore, systems trained via crowdsourced data
must be able to recognize and account for differing user per-
spectives. Critically, in applications from household robotics
to autonomous driving to LLM-based assistants, users must
not be forced into options optimized for other users; rather,
systems should utilize crowd-aggregated information as a
baseline from which to accelerate and improve downstream
personalization to specific individual users. Meanwhile, it
is crucial to identify and reject malicious user data to avoid
biasing models toward toxic or other undesirable behaviors.
We believe that Crowd-PrefRL can help to facilitate such sys-
tem capabilities by identifying minority viewpoints, not only
learning a policy consistent with the majority viewpoint, but
also enabling developers to model behaviors corresponding
to distinct user clusters to improve overall modeling. Finally,
when analyzing different user objectives, it will be important
to consider the potential implications of empowering a few
individuals to decide which user objectives are worthwhile,
toxic, etc.
Acknowledgments
This project was sponsored by the DEVCOM Army Research
Laboratory. The views and conclusions contained in this doc-
ument are those of the authors and should not be interpreted
as representing the official policies, either expressed or im-
plied, of the U.S. Government. The U.S. Government is au-
thorized to reproduce and distribute reprints for Government
purposes notwithstanding any copyright notation herein.
References
[Agarwal et al., 2021] Agarwal, R.; Schwarzer, M.; Castro,
P. S.; Courville, A. C.; and Bellemare, M. 2021. Deep re-
inforcement learning at the edge of the statistical precipice.
In Ranzato, M.; Beygelzimer, A.; Dauphin, Y.; Liang, P.;
and Vaughan, J. W., eds., Advances in Neural Information
Processing Systems, volume 34, 29304–29320. Curran As-
sociates, Inc.
[Babes et al., 2011] Babes, M.; Marivate, V.; Littman, M.;
and Subramanian, K. 2011. Apprenticeship learning about
multiple intentions. In Getoor, L., and Scheffer, T., eds.,
Proceedings of the 28th International Conference on Ma-
chine Learning (ICML-11), ICML ’11, 897–904.
New
York, NY, USA: ACM.
[Beliaev et al., 2022] Beliaev, M.; Shih, A.; Ermon, S.;
Sadigh, D.; and Pedarsani, R. 2022. Imitation learning by
estimating expertise of demonstrators. In Chaudhuri, K.;
Jegelka, S.; Song, L.; Szepesvari, C.; Niu, G.; and Sabato,
S., eds., Proceedings of the 39th International Conference
on Machine Learning, volume 162 of Proceedings of Ma-
chine Learning Research, 1732–1748. PMLR.
[Brown et al., 2019] Brown, D.; Goo, W.; Nagarajan, P.; and
Niekum, S.
2019.
Extrapolating beyond suboptimal
demonstrations via inverse reinforcement learning from
observations. In Proceedings of the International Confer-
ence on Machine Learning, 783–792.
[Casper et al., 2023] Casper, S.; Davies, X.; Shi, C.; Gilbert,
T. K.; Scheurer, J.; Rando, J.; Freedman, R.; Korbak, T.;
Lindner, D.; Freire, P.; et al. 2023. Open problems and fun-
damental limitations of reinforcement learning from hu-
man feedback.
Transactions on Machine Learning Re-
search.
[Chen et al., 2013] Chen,
X.;
Bennett,
P. N.;
Collins-
Thompson, K.; and Horvitz, E. 2013. Pairwise ranking
aggregation in a crowdsourced setting. In Proceedings of
the Sixth ACM International Conference on Web Search
and Data Mining, WSDM ’13, 193–202. New York, NY,
USA: Association for Computing Machinery.
[Christiano et al., 2017] Christiano, P. F.; Leike, J.; Brown,
T.; Martic, M.; Legg, S.; and Amodei, D. 2017. Deep re-
inforcement learning from human preferences. Advances
in neural information processing systems 30.
[Dimitrakakis and Rothkopf, 2012] Dimitrakakis,
C.,
and
Rothkopf, C. A. 2012. Bayesian multitask inverse rein-
forcement learning. In Sanner, S., and Hutter, M., eds.,
Recent Advances in Reinforcement Learning, 273–284.
Berlin, Heidelberg: Springer Berlin Heidelberg.
[Hausman et al., 2017] Hausman, K.; Chebotar, Y.; Schaal,
S.; Sukhatme, G.; and Lim, J. J. 2017. Multi-modal imita-
tion learning from unstructured demonstrations using gen-
erative adversarial nets. In Proceedings of the 31st Interna-
tional Conference on Neural Information Processing Sys-
tems, NIPS’17, 1235–1245. Red Hook, NY, USA: Curran
Associates Inc.
[Lee et al., 2021] Lee, K.; Smith, L.; Dragan, A.; and
Abbeel, P. 2021. B-pref: Benchmarking preference-based
reinforcement learning. In Thirty-fifth Conference on Neu-
ral Information Processing Systems Datasets and Bench-
marks Track (Round 1).
[Lee, Smith, and Abbeel, 2021] Lee, K.; Smith, L. M.; and
Abbeel, P. 2021. PEBBLE: Feedback-efficient interac-
tive reinforcement learning via relabeling experience and
unsupervised pre-training. In International Conference on
Machine Learning, 6152–6163.
[Levine et al., 2020] Levine, S.; Kumar, A.; Tucker, G.; and
Fu, J. 2020. Offline reinforcement learning: Tutorial, re-
view, and perspectives on open problems. Computing Re-
search Repository (CoRR) abs/2005.01643.
[Li et al., 2016] Li, G.; Wang, J.; Zheng, Y.; and Franklin,
M. J. 2016. Crowdsourced data management: A survey.
IEEE Transactions on Knowledge and Data Engineering
28(9):2296–2319.
[Ouyang et al., 2022] Ouyang,
L.;
Wu,
J.;
Jiang,
X.;
Almeida, D.; Wainwright, C.; Mishkin, P.; Zhang, C.;
Agarwal, S.; Slama, K.; Ray, A.; Schulman, J.; Hilton,
J.; Kelton, F.; Miller, L.; Simens, M.; Askell, A.; Welin-
der, P.; Christiano, P. F.; Leike, J.; and Lowe, R. 2022.
Training language models to follow instructions with hu-
man feedback. In Koyejo, S.; Mohamed, S.; Agarwal, A.;
Belgrave, D.; Cho, K.; and Oh, A., eds., Advances in Neu-
ral Information Processing Systems, volume 35, 27730–
27744. Curran Associates, Inc.
[Parisi et al., 2014] Parisi, F.; Strino, F.; Nadler, B.; and
Kluger, Y. 2014. Ranking and combining multiple pre-
dictors without labeled data. Proceedings of the National
Academy of Sciences 111(4):1253–1258.
[Park et al., 2022] Park, J.; Seo, Y.; Shin, J.; Lee, H.; Abbeel,
P.; and Lee, K.
2022.
SURF: Semi-supervised reward
learning with data augmentation for feedback-efficient
preference-based reinforcement learning. In International
Conference on Learning Representations.
[Schulman et al., 2017] Schulman, J.; Wolski, F.; Dhariwal,
P.; Radford, A.; and Klimov, O. 2017. Proximal policy op-
timization algorithms. arXiv preprint arXiv:1707.06347.
[Siththaranjan, Laidlaw, and Hadfield-Menell, 2023]
Siththaranjan, A.; Laidlaw, C.; and Hadfield-Menell, D.
2023. Distributional preference learning: Understanding
and accounting for hidden context in RLHF.
arXiv
preprint arXiv:2312.08358.
[Sutton and Barto, 2018] Sutton, R. S., and Barto, A. G.
2018.
Reinforcement learning: An introduction.
MIT
press.
[Tassa et al., 2018] Tassa, Y.; Doron, Y.; Muldal, A.; Erez,
T.; Li, Y.; de Las Casas, D.; Budden, D.; Abdolmaleki, A.;
Merel, J.; Lefrancq, A.; Lillicrap, T. P.; and Riedmiller,
M. A. 2018. Deepmind control suite. Computing Research
Repository (CoRR) abs/1801.00690.
[Torne et al., 2023] Torne, M.; Balsells, M.; Wang, Z.;
Desai, S.;
Chen, T.;
Agrawal, P.;
and Gupta, A.
2023. Breadcrumbs to the goal: Goal-conditioned explo-
ration from human-in-the-loop feedback. arXiv preprint
arXiv:2307.11049.
[Wilde et al., 2021] Wilde, N.; Biyik, E.; Sadigh, D.; and
Smith, S. L. 2021. Learning reward functions from scale
feedback. In 5th Annual Conference on Robot Learning.
[Zhang and Kashima, 2023] Zhang, G., and Kashima, H.
2023.
Batch reinforcement learning from crowds.
In
Amini, M.-R.; Canu, S.; Fischer, A.; Guns, T.; Kralj No-
vak, P.; and Tsoumakas, G., eds., Machine Learning
and Knowledge Discovery in Databases, 38–51. Cham:
Springer Nature Switzerland.
"
"This study introduces RELIANCE, a unique ensemble learning system tailored for reliable information and fake news credibility evaluation. Composed of five diverse base models, including Support Vector Machine (SVM), naive Bayes, logistic regression, random forest, and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs an innovative approach to fuse their strengths, harnessing the collective intelligence of the ensemble for enhanced accuracy. Experiments showcase RELIANCE's superiority over individual models, demonstrating its efficacy in distinguishing credible from non-credible information sources. RELIANCE surpasses baseline models in information and news credibility assessment, establishing itself as an effective solution for evaluating the reliability of information sources.nan","In the era of information proliferation, discerning the credibility of news content poses an ever-growing challenge. This paper introduces RELIANCE, a pioneering ensemble learning system designed for robust information and fake news credibility evaluation. Comprising five diverse base models, including Support Vector Machine (SVM), naïve Bayes, logistic regression, random forest, and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs an innovative approach to integrate their strengths, harnessing the collective intelligence of the ensemble for enhanced accuracy. Experiments demonstrate the superiority of RELIANCE over individual models, indicating its efficacy in distinguishing between credible and non-credible information sources. RELIANCE, also surpasses baseline models in information and news credibility assessment, establishing itself as an effective solution for evaluating the reliability of information sources.nan","nanThe rapid dissemination of information through digital platforms has directed in an era where the credibility of news content is frequently challenged. In response to the proliferation of misinformation and fake news, researchers have proposed different approaches to evaluate the credibility of news documents. Throughout the research history of our work, this field has been recognized by various names, including rumor detection, fake news detection, and reality detection. Perusing the literature, one can categorize the previous studies into three categories: text-based methods, context-based methods, and hybrid methods. Table 1 provides an analytic perspective on related works in information and news credibility evaluation in a tabular form.nan","The objective of our investigation was to improve the automated evaluation of information and news credibility by employing ensemble learning. Ensemble learning, combining various methods, enhances predictive performance beyond that of individual methods. Consequently, we introduced five distinct base models, each operating at different processing levels, for integration into the ensemble learning model. Namely Support Vector Machine (SVM)-based, naïve Bayes-based, logistic regression-based, random forest-based, and Bidirectional Long Short-Term Memory Networks (BiLSTMs)-based models. To this end, we proposed RELIANCE (Reliable Ensemble Learning for Information and News Credibility Evaluation), that performs credibility evaluation in three phases; Phase 1 focuses on preprocessing the input news text documents to prepare them for the main process. Phase 2 performs feature engineering through embedding the input news text documents. Phase 3 is devoted to evaluate the credibility of news text documents.nan","To perform news credibility evaluation, we proposed RELIANCE as an ensemble learning model that combines five distinct classifiers as the base models including SVM-based, naïve Bayes-based, LR-based, random forest-based, and BiLSTMs-based models. To perform feature engineering, we employed Doc2Vec with an embedding size equal to 1,200, and the minimum counts of word equal to 1, and conducted the training for 50 epochs. Afterwards, at first, the base models should perform credibility evaluation on the input text documents. Each of the base models adheres to specific settings for generating predictions. Table III encompasses the applied parameter settings in proposed BiLSTM model. Logistic Regression (LR): For the LR-based model, the maximum number of iterations for the solver (lbfgs) to converge is set at 1000. Moreover, the L1 regularization is also used to reduce model generalization error. SVM: For the SVM-based model, the chosen kernel is 'rbf' (Radial Basis Function). Random Forest: The Random Forest-based model is configured with the parameter n_estimators set to 100. Naïve Bayes: We used the Multinomial Naive Bayes algorithm, which is commonly used for text classification.nan","In the current era of information overload, accurately assessing the credibility of news sources is crucial for informed decision-making and effective crisis management. To address this challenge, we propose RELIANCE (Reliable Ensemble Learning for Information and News Credibility Evaluation), an ensemble learning approach that combines the strengths of five individual models for news credibility evaluation. The base models include Support Vector Machines, naïve Bayes classifiers, logistic regression models, random forests, and Bidirectional Long Short-Term Memory Networks. These models are individually trained to extract relevant features from news documents and classify their credibility. To further enhance the overall accuracy, RELIANCE employs a multi-layer perceptron as a meta-model, which integrates the predictions of each base model (using stacking) and produces a more refined credibility assessment. Comparative experiments with baseline models demonstrate that RELIANCE significantly outperforms existing algorithms in evaluating the credibility of news documents. It provides a robust framework for identifying trustworthy news sources, offering real-world applications that empower users, journalists, and fact-checkers with a resilient tool against misinformation in the digital era.nan",RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation,"Majid Ramezani, Hamed Mohammad-Shahi, Mahshid Daliry, Soroor Rahmani, Amir-Hosein Asghari","XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
RELIANCE: Reliable Ensemble Learning for 
Information and News Credibility Evaluation 
Majid Ramezani  
Faculty of Computer Science and 
Information Technology, Institute 
for Advanced Studies in Basic 
Sciences (IASBS), 
 Zanjan, Iran. 
ramezani@iasbs.ac.ir 
ORCID: 0000-0003-0886-7023 
Hamed Mohammad-Shahi 
Faculty of Computer Science and 
Information Technology, Institute 
for Advanced Studies in Basic 
Sciences (IASBS), 
 Zanjan, Iran. 
hamedshahi@iasbs.ac.ir 
ORCID: 0009-0008-7405-2192  
Mahshid Daliry 
Faculty of Computer Science and 
Information Technology, Institute 
for Advanced Studies in Basic 
Sciences (IASBS), 
 Zanjan, Iran. 
mahshiddaliry@iasbs.ac.ir 
ORCID: 0009-0006-0449-0950 
Soroor Rahmani 
Faculty of Computer Science and 
Information Technology, Institute 
for Advanced Studies in Basic 
Sciences (IASBS), 
 Zanjan, Iran. 
soroorrahmani@iasbs.ac.ir 
ORCID: 0009-0000-7465-3766 
Amir-Hosein Asghari 
Faculty of Computer Science and  
Information Technology, Institute 
 for Advanced Studies in Basic 
 Sciences (IASBS), 
 Zanjan, Iran. 
amirasghari@iasbs.ac.ir 
ORCID: 0009-0003-1000-8233 
Abstract—In the era of information proliferation, discerning 
the credibility of news content poses an ever-growing challenge. 
This paper introduces RELIANCE, a pioneering ensemble 
learning system designed for robust information and fake news 
credibility evaluation. Comprising five diverse base models, 
including Support Vector Machine (SVM), naïve Bayes, logistic 
regression, random forest, and Bidirectional Long Short Term 
Memory 
Networks 
(BiLSTMs), 
RELIANCE 
employs 
an 
innovative approach to integrate their strengths, harnessing the 
collective intelligence of the ensemble for enhanced accuracy. 
Experiments demonstrate the superiority of RELIANCE over 
individual models, indicating its efficacy in distinguishing between 
credible and non-credible information sources. RELIANCE, also 
surpasses baseline models in information and news credibility 
assessment, establishing itself as an effective solution for 
evaluating the reliability of information sources. 
Keywords—news credibility evaluation, fake news detection, 
ensemble learning, 
I. INTRODUCTION 
In the era of information abundance, discerning the 
reliability of news documents has become a paramount 
challenge. The rapid dissemination of news through various 
online platforms has created a fertile ground for 
misinformation, disinformation, and fake news. As society 
increasingly relies on digital sources for information 
consumption, ensuring the credibility of news content 
becomes imperative.  
In the face of global crises such as the COVID-19 
pandemic, natural disasters like earthquakes, and geopolitical 
conflicts including wars, the reliability assessment of news 
becomes not merely a scholarly pursuit but a critical 
imperative for societal well-being. Accurate and timely 
information plays an indispensable role in crisis management, 
public safety, and policy formulation. The spread of 
misinformation during such events can have profound and 
far-reaching consequences, ranging from public panic and 
misguided responses to compromised public health efforts. In 
the case of a pandemic like COVID-19, misinformation about 
the virus, its origins, or potential treatments can undermine 
public trust in health authorities and exacerbate the 
challenges of containment. Similarly, during natural disasters 
or armed conflicts, misleading information can hinder 
effective evacuation procedures, relief efforts, and diplomatic 
initiatives. Thus, the ability to distinguish between reliable 
and unreliable news in these contexts is paramount, 
underscoring the crucial need for advanced and robust fake 
news detection system. This field of study is known by 
various names, including fake news detection [1-2], rumor 
detection [3-4], misinformation detection [5-6], information 
credibility evaluation or assessment [7-8], trustworthiness 
assessment, and more. Its aim is to assess the reliability or 
authenticity of information and news documents [9]. 
The proliferation of misinformation poses a threat to 
public discourse, decision-making processes, and societal 
trust in media. Traditional methods of news verification 
struggle to keep pace with the evolving landscape of 
deceptive tactics employed by malicious actors. In this 
context, our paper introduces RELIANCE (Reliable 
Ensemble Learning for Information and News Credibility 
Evaluation), an innovative approach leveraging reliable 
ensemble learning for robust information and news 
credibility evaluation. It seeks to address these challenges by 
harnessing the power of ensemble learning, combining the 
strengths of multiple base models to enhance the reliability 
and accuracy of news credibility assessment. To do so we 
have proposed five base models for credibility evaluation, 
including Support Vector Machine (SVM)-based, naïve 
Bayes-based, logistic regression-based, random forest-
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
based, and Bidirectional Long Short Term Memory Networks 
(BiLSTMs)-based models. Together, these independent base 
methods collaborate to minimize the generalization error in 
predictions through ensemble learning. In essence, ensemble 
learning involves employing multiple diverse base models to 
predict outcomes, surpassing the predictive capabilities of 
individual models [10]. Therefore, the authors proposed 
RELIANCE which stands as a pioneering effort to combine 
the capabilities of individual classifiers, thereby creating a 
more resilient and trustworthy system for distinguishing 
between credible and non-credible information and news 
documents. 
The current study provides two significant contributions 
to distinguishing the credibility and non-credibility of 
information and news documents: introducing five distinct 
diverse methods for information news credibility evaluation, 
and enhancing credibility evaluation accuracy through the 
ensemble learning of the aforementioned models as the base 
models during ensemble learning. 
The structure of our study is as follows: the literature 
review comprehensively surveys existing research. The 
methods details our innovative approach, including five 
distinct credibility evaluators as well as ensembling them 
through RELIANCE. Subsequently in results and discussion, 
we present and analyze the results obtained from our 
experiments, assessing the proposed model's performance. 
This section also critically interprets the findings, 
highlighting the contributions and implications of our work. 
Finally, the conclusion highlights the key insights, reinforces 
the significance of our proposed methodology. 
II. LITERATURE REVIEW 
The rapid dissemination of information through digital 
platforms has directed in an era where the credibility of news 
content is frequently challenged. In response to the 
proliferation of misinformation and fake news, researchers 
have proposed different approaches to evaluate the credibility 
of news documents. Throughout the research history of our 
work, this field has been recognized by various names, 
including rumor detection, fake news detection, and reality 
detection. Perusing the literature, one can categorize the 
previous studies into three categories: text-based methods 
[11-18], context-based methods [15, 19-23], and hybrid 
methods [24-28]. Table 1 provides an analytic perspective on 
related works in information and news credibility evaluation 
in a tabular form. 
The 
text-based 
methods 
primarily 
rely 
on 
miscellaneous information that can be acquired from the text 
documents. In a basic investigation outlined in [11], the 
authors introduced a method that combines lexical features, 
word embeddings, and n-gram characteristics for identifying 
the stance in fake news. The researchers in [12] introduced a 
new computational method for automatically detecting fake 
news, relying on a novel text analysis approach centered 
around the linguistic features provided by LIWC (Linguistic 
Inquiry and Word Count) [16]. In another investigation, the 
authors to perform news credibility evaluation have introduce 
a hybrid model based on Logistic Regression and n-gram 
analysis [13]. They have used Term Frequency-Inverted 
Document Frequency (TF-IDF) as feature extraction 
technique. They have also suggested a Linear Support Vector 
Machine (LSVM) model to perform news credibility 
evaluation. The authors in [14] introduced a model that 
integrates several key features of text document (such as the 
text of news document, news source, etc.) for a more precise 
and automated prediction. Guided by these features, they 
proposed a model named CSI, comprising three modules: 
Capture, Score, and Integrate. The initial module relies on 
responses and text, utilizing a Recurrent Neural Network to 
capture the temporal patterns of user activity on a given news 
document. The second module understands news source 
characteristics based on user behavior, and these are 
integrated with the third module to classify a news document 
as either reliable or unreliable.  
The context-based methods basically attempt to utilize 
those information that are provided by the context such as 
user-based features, or post-based features. The authors in 
[15, 
19] 
have 
proposed 
models 
that 
user-specific 
characteristics are derived from individual profiles to assess 
their attributes for the sake of content credibility evaluation. 
More over in several investigations to perform credibility 
evaluation, features based on network structures are primarily 
extracted through the development of precise detection 
systems [20-21]. This involves utilizing diffusion networks, 
association networks, and propagation networks to assess 
credibility of text documents. Given the extensive integration 
of social media, research also incorporates social media 
interactions in the detection of fake news. For instance, there 
is a focus on early detection through social learning and user-
based relationships [22-23]. 
The hybrid methods try to consider all of the available 
information to evaluate the credibility of the text documents. 
The authors in [24] presented an innovative hybrid system for 
detecting fake news, which integrates linguistic and 
knowledge-based methodologies, combining their respective 
strengths. Their hybrid approach employs two distinct feature 
sets: linguistic features (such as title, word count, reading 
ease, lexical diversity, and sentiment), and a new set of 
knowledge-based features called fact-verification features. 
The authors in [25] introduced a novel transformer-based 
model named X-CapsNet, incorporating Convolutional 
Neural Networks or CNN (CapsNet). X-CapsNet employs a 
CapsNet with a dynamic routing algorithm and integrates a 
size-based classifier for distinguishing between short and 
long fake news statements. The detection of long fake news 
statements is facilitated by a Deep CNN, while short news 
statements are identified using a Multi-Layer Perceptron 
(MLP). Considering the context of social networks the 
authors in [26] have presented a novel approach to identify 
fake news by analyzing the temporal propagation tree. They 
continuously extract relevant features from the constructed 
propagation trees and employ a type of recurrent neural 
network (LSTM) to capture the temporal dynamics of these 
features. This enables them to discern the evolving pattern of 
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
the propagation tree over time, aiding in the estimation of the 
credibility of a news article. In their seminal study, the 
authors in [27] have explored the feasibility of unsupervised 
fake news detection by considering the truths of news and 
users' credibility as latent random variables. Utilizing users' 
engagements on social media, they have discerned their 
opinions regarding the authenticity of news. 
In current study, to leverage different credibility 
evaluation models abilities, we proposed an ensemble 
learning model to perform information and news credibility 
evaluation, called RELIANCE. The combination of diverse 
models through ensemble learning offers a synergistic 
approach, harnessing the complementary strengths of 
individual methods, thereby enhancing the robustness and 
accuracy of news credibility evaluation compared to the 
performance of individual models. 
 
TABLE I.  
AN ANALYTIC VIEW ON RELATED WORKS IN INFORMATION AND NEWS CREDIBILITY EVALUATION IN A TABULAR FORM 
Authors 
Category 
Dataset 
Method 
Input Genre 
Ghosh & Shah[29] 
Text-based 
BuzzFace 
Commination of techniques from information retrieval, natural 
language processing, and deep learning 
News Documents 
Liu & Wu [28] 
Hybrid 
Weibo, Twitter15, and 
Twitter16 
Time series classifier with both recurrent and convolutional 
networks 
Social media 
content 
Seddari et al. [12] 
Hybrid 
Buzzfeed Political News 
dataset 
Random Forest, Logistic Regression, Additional Trees 
Discriminant, and eXtreme Gradient Boosting (XGBoost) 
News Documents 
Kaliyar et al.[17] 
Text-based 
FN-COV 
A combination of convolutional neural network and long short 
term memory network 
COVID-19 
Goldani et al. [25] 
Hybrid 
Liar datasets 
A novel transformer-based model named X-CapsNet 
COVID-19 
Dixit et al. [18] 
Text-based 
LIAR, LIAR-PLUS, and ISOT 
Fuzzy Convolutional Recurrent Neural Network (CRNN) 
News documents 
Davoudi et al. [26] 
Hybrid 
PolitiFact and GossipCop 
Long Short Term Memory networks (LSTMs) 
News documents 
Yang et al. [27] 
Hybrid 
LIAR and BuzzFeed News 
Bayesian network 
Social media  
Basak et al. [15] 
Context-
based 
Shaming detection of tweets 
Support vector machine 
Twitter 
Potthast et al. [19] 
Context-
based 
BuzzFeed-Webis Fake News 
Similarity detection between text categories 
News Documents 
Karimi et al. [20] 
Context-
based 
FakeNewsNet 
Multi-source Multi-class Fake news Detection framework 
MMFD 
News Documents 
Gupta et al. [21] 
Context-
based 
FakeNewsNet 
A tensor factorization 
News Documents 
Nguyen et al. [22] 
Context-
based 
Stance-annotated dataset 
Graph Convolutional Networks (GCN) 
News Documents 
Shu et al. [23] 
Context-
based 
FakeNewsNet 
TriFN (which models publisher-news relations and user-news 
interactions) 
News Documents 
Ghanem et al. [11] 
Text-based 
Fake NewsChallenge (FNC-1) 
Combination of lexical features, word embeddings, and n-
gram statistics 
News documents 
Singh et al. [12] 
Text-based 
Kaggle FakeNews 
linguistic features provided by LIWC 
News documents 
Ahmed et al. [13] 
Text-based 
Kaggle FakeNews 
Logistic Regression and n-gram statistics 
News documents 
Ruchansky et al.[14] 
Text-based 
Kaggle FakeNews 
Recurrent Neural Network and a set of text-based features 
News documents 
Yang et al. [30] 
Text-based 
Kaggle FakeNews 
Latent feature extraction using convolutional neural networks 
News documents 
 
III. METHODS 
The objective of our investigation was to improve the 
automated evaluation of information and news credibility by 
employing ensemble learning. Ensemble learning, combining 
various methods, enhances predictive performance beyond 
that of individual methods. Consequently, we introduced five 
distinct base models, each operating at different processing 
levels, for integration into the ensemble learning model. 
Namely Support Vector Machine (SVM)-based, naïve Bayes-
based, logistic regression-based, random forest-based, and 
Bidirectional 
Long 
Short-Term 
Memory 
Networks 
(BiLSTMs)-based models. To this end, we proposed 
RELIANCE (Reliable Ensemble Learning for Information 
and News Credibility Evaluation), that performs credibility 
evaluation in three phases; Phase 1 focuses on preprocessing 
the input news text documents to prepare them for the main 
process. Phase 2 performs feature engineering through 
embedding the input news text documents. Phase 3 is devoted 
to evaluate the credibility of news text documents. The 
general architecture of RELIANCE is depicted in Fig. 1.  
 
Fig. 1. The general architecture of the proposed method (RELIANCE) 
 
 
 
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
A. Phase 1: Preprocessing 
This conventionally well-established and significant stage 
within the domain of natural language processing aims to 
prepare the input text and convert it into a more easily 
comprehensible format for machines during the main process. 
The preprocessing activities involved may vary depending on 
the task at hand. The applied preprocessing activities in 
RELIANCE as can be seen in Fig. 1 are as listed below. 
● Tokenization: Tokenization is the procedure of 
dividing a text into segments known as tokens, which are 
typically associated with words. For this purpose, we used the 
Natural Language Toolkit (NLTK) [31].  
● Noise Removal: To enrich the quality of the input text, 
we performed noise removal steps including stop words 
removal, and punctuation and signs removal since they do not 
convey any specific information that is essential to the 
performance of the system. Similar, to the previous step, 
NLTK was also used to perform stop words removal. 
● Lowering the Text: The process of lowering the text 
uniforms all the characters and reduces the variability in text 
and makes it more consistent.  
● Stemming: Is the morphological analysis of words that 
reduces their inflected forms to their stem [32]. This process 
is achieved by removing affixes from words. Escalating the 
performance of the natural language processing tasks in the 
consequence of stemming. The NLTK was also used for this 
process. 
 
B. Phase 2: Feature Engineering  
Feature engineering plays a pivotal role in the realm of 
natural language processing, encompassing the identification, 
transformation, and extraction of pertinent features from raw 
textual data. This method facilitates the determination of the 
most 
informative 
features 
for 
primary 
processing, 
concurrently eliminating less significant ones. The main goal 
is to decrease the dimensionality of the dataset by reducing 
the number of features, generating novel features from the 
initial ones. Ideally, this refined feature set encapsulates the 
essential features from the original set. 
Doc2Vec [33], an extension of Word2Vec, to transform 
text documents into vectors within a high-dimensional space. 
The underlying concept of Doc2Vec is based on the 
assumption that words appearing together in a document 
share similar meanings and, consequently, should exhibit 
similar vector representations. In simpler terms, the vector 
representation of a word captures its semantic meaning. This 
approach enables the acquisition of the contextual 
relationship between words within a document, a critical 
factor in comprehending the document's overall meaning. 
Leveraging Doc2Vec for feature engineering enables the 
transformation of the input text data into a low-dimension 
vector space, facilitating processing by machine learning 
algorithms. In this transformation, the dimensionality 
reduction effectively eliminates excessive dimensions and 
retaining only crucial dimensions for subsequent processing. 
C. Phase 3: Credibility Evaluation  
At this point, the data is pre-processed, feature-
engineered, and we possess a rich and informative feature set. 
The proposed method (RELIANCE), performs credibility 
evaluation of the input documents relying on ensembling 
several base models. More specifically, RELIANCE 
leverages the strengths of several credibility evaluation 
models and combines them to achieve more reliable 
predictions through stacking. The primary goal of ensemble 
learning is to increase overall predicting performance by 
merging the prediction of various models. In reality, it uses 
the votes from several different base models rather than just 
one to predict a label.  
Among 
various 
ensemble 
techniques, 
commonly 
employed ones include Bagging (Bootstrap Aggregation), 
Boosting, and Stacking [10]. The first two are frequently 
utilized to integrate homogeneous base models with the goal 
of reducing variance and minimizing bias, respectively. In 
contrast, Stacking is typically employed to integrate 
heterogeneous base models with the aim of enhancing 
predictive performance. RELIANCE utilizes five credibility 
evaluators including (SVM)-based, naïve Bayes-based, LR-
based, random forest-based, and BiLSTM-based models as 
the base models, each of which, possesses distinctive 
capabilities tailored to perform credibility evaluation. Hence, 
considering the heterogeneity of the applied base models, 
RELIANCE is developed using Stacking. It is significant to 
point out that RELIANCE utilized a Multi-Layer Perceptron 
(MLP) as the meta model to produce the final predictions 
(credibility evaluation).  
1) 
Dataset 
The Fake News dataset [34] has been used to train and 
validate all of the models in RELIANCE. This dataset is 
gathered during the 2016 U.S. Presidential Election.  
The dataset comprises two categories of articles: fake and 
real news. Real news were gathered by scraping content from 
Reuters.com, a reputable news website. Fake news were 
sourced from various unreliable websites identified by 
Politifact, a U.S.-based fact-checking organization, and 
Wikipedia. 
While 
the 
dataset 
encompasses 
diverse 
documents types on various subjects, a predominant focus is 
observed on political and global news topics. 
TABLE II.  
THE PROPERTIES OF FAKE NEWS DATASET ) UNEQUAL 
NUMBERS ARE DUE TO THE ABSENCE OF SOME VALUES IN THE DATASET (. 
Attribute 
Number of instances in the dataset 
ID 
20800 
Title 
20242 
Author 
18843 
Text 
20761 
label 
20800 
 
Fake News dataset comprises five attributes: ID, Title, 
Author, Text, and Labels. The ID is a distinctive identifier for 
each news document. The Title corresponds to the primary 
heading of the news piece, and the Author indicates the 
creator's name. The Text is the core part of the dataset, 
containing the news document’s text. Finally, the Label 
determines the credibility of the news document (assigning 
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
fake or real labels). Table II describes the Fake News 
Dataset’s properties. In terms of label distribution, Fake 
News comprises approximately 51% reliable (real) news 
documents and approximately 49% unreliable (fake) news. 
2) 
Base Models 
RELIANCE utilizes five distinct credibility evaluation 
models, including several traditional machine learning 
models as well as a deep learning model to leverage their 
capabilities through ensemble learning to ensures the quality 
of the final predictions. 
● BiLSTM: we proposed a BiLSTM network to perform 
credibility evaluation. LSTM Recurrent Neural Networks 
take into account a series of previous inputs. This 
characteristic makes LSTMs highly effective at learning from 
sequential data such as text documents. As a specific type of 
RNN, LSTM leverages past information to understand each 
word in the forward direction. Conversely, BiLSTM benefits 
from considering both past and future words (forward and 
backward directions) which aligns with how humans 
understand language. We proposed a 3-layer BiLSTM with 
respectively 64, 128, and 64 units joined to a dense layer with 
64 neurons. 
● Logistic Regression (LR): we implemented a logistic 
regression-based model for credibility evaluation of 
information and news documents. In essence, it is a statistical 
model that estimates the probabilities of a binary dependent 
variable. Unlike other methods that operate on independent 
inputs, LR considers a set of previous inputs, making it 
particularly effective for learning from sequential data.  
● Support Vector Machine (SVM): we proposed the 
SVM-based model, a powerful and versatile machine 
learning technique used for various tasks including 
classification, and regression. Unlike other algorithms that 
operate on independent inputs, SVMs also consider a set of 
previous inputs and are particularly effective at learning from 
sequential data. This feature is due to the nature of SVMs, 
which aims to find the maximum separating hyperplane 
between different classes in the target label.  
● Random Forest: we used the Random Forest 
algorithm, a powerful and widely used machine learning 
technique for classification and regression tasks. Random 
Forest creates a set of decision trees and combines their 
outputs to make the final prediction. Essentially, Random 
Forest is a combination of several decision trees that 
individually performs predictions. In practice, ensembling 
several homogeneous models, Random Forest tries to 
increase the robustness and stability of model, and reduce the 
risk of overfitting, and provides more accurate predictions.  
● Naïve Bayes: The Naive Bayes algorithm is a 
probabilistic machine learning method primarily utilized for 
classification tasks. It also considers the prior inputs, making 
it well-suited for learning from sequential data. The algorithm 
operates under the assumption that attributes are independent 
of each other, which is not always the case in reality. 
Nevertheless, this simplifying assumption surprisingly leads 
to better predictions. Leveraging the principle of conditional 
probability, Naive Bayes calculates the probability of an 
event based on prior knowledge. Despite its simplicity, Naive 
Bayes 
demonstrates 
robust 
performance 
and 
finds 
widespread use in the field of text classification. 
3) 
Ensemble Learning 
The fundamental idea behind ensemble learning is to 
enhance overall predictive performance by aggregating 
decisions from several distinct base models. It involves 
considering the votes of various base models to predict the 
final label, rather than relying on a single model (similar to 
harnessing the wisdom of the crowd for predictions). By 
leveraging independent and diverse base models, ensemble 
learning aims to reduce the generalization error in 
predictions, providing a compelling incentive for its 
application. 
As discussed earlier, RELIANCE performs ensemble 
learning through stacking five heterogeneous distinct base 
models. Specifically, stacking (also known as stacked 
generalization), is a machine learning algorithm that uses a 
meta-learning algorithm as a meta-model, to learn how to 
combine the best predictions of several base machine learning 
algorithms. Ensemble learning offers the advantage of 
utilizing the strengths of multiple models, leading to 
predictions that outperform any individual model. The 
aforementioned five base models were chosen as the base 
credibility evaluation methods, with a MLP selected as the 
meta-model. Although that the predictions of the base models 
are not considered as the final predictions, they have 
undeniable role in final decision making by the RELIANCE. 
The predictions from the base models, (resembling the 
wisdom of the crowd), are employed to train the meta-model. 
Ultimately, the meta-model generates evaluates the 
credibility of the input documents. To do so, we used a MLP 
model with three hidden layers, respectively containing 64, 
128, and 64 units. 
IV. RESULTS AND DISCUSSIONS 
A. Evaluation Metrics 
Traditionally, several of the most common evaluation 
metrics such as precision, recall, f-measure, and accuracy are 
used to assess text classification models. In the same manner, 
we employed all of them, with a particular emphasis on 
accuracy as the primary evaluation metric. 
B. Evaluation Results 
To perform news credibility evaluation, we proposed 
RELIANCE as an ensemble learning model that combines 
five distinct classifiers as the base models including SVM-
based, naïve Bayes-based, LR-based, random forest-based, 
and BiLSTMs-based models. To perform feature engineering, 
we employed Doc2Vec with an embedding size equal to 
1,200, and the minimum counts of word equal to 1, and 
conducted the training for 50 epochs. Afterwards, at first, the 
base models should perform credibility evaluation on the 
input text documents. Each of the base models adheres to 
specific settings for generating predictions. The train-test 
split rate of the data set is 80-20 for all of the models in our 
investigation. More specifically: 
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
BiLSTM: Table III encompasses the applied parameter 
settings in proposed BiLSTM model.  
Logistic Regression (LR): For the LR-based model, the 
maximum number of iterations for the solver (lbfgs) to 
converge is set at 1000. Moreover, the L1 regularization is 
also used to reduce model generalization error. 
SVM: For the SVM-based model, the chosen kernel is 
'rbf' (Radial Basis Function). The kernel selection is crucial 
as it determines the type of decision boundary used for 
classification. Moreover, the L1 regularization is also used to 
reduce model generalization error. 
Random Forest: The Random Forest-based model is 
configured with the parameter n_estimators set to 100. This 
parameter defines the number of integrating decision trees. 
The maximum depth of the tree is set to None. That is to say, 
nodes are expanded until all leaves are pure or until all leaves 
contain less than minimum number of samples required to 
split an internal node. 
Naïve Bayes: We used the Multinomial Naive Bayes 
algorithm, which is commonly used for text classification. 
We set fit_prior to false. Namely, the uniform prior 
probabilities are applied. Furthermore, the additive 
smoothing parameter (alpha) was set to 1.0. 
MLP: Table IV provides a comprehensive overview of 
the applied parameter settings in the proposed MLP model. 
Table V presents the results obtained from the evaluation 
of five distinct proposed credibility evaluation models as well 
as the performance of RELIANCE which was our main 
proposed method the ensembles the base models. It 
encompasses the values of four evaluation metrics, namely 
precision, recall, F1-score and accuracy. It is noteworthy 
that, since F1-score neglects all of the correctly false labelled 
samples by the system (TN), in practice it loses the ground to 
accuracy while evaluating a credibility evaluation system.  
Therefore, we will focus on accuracy as the main metric to 
evaluate the credibility of the models. 
As can be seen from Table V, the proposed ensemble 
learning model, namely RELIANCE that combines the 
aforementioned base models, has achieved the higher 
accuracy than individual base models. Moreover, among the 
base models, SVM-based, LR-based, naïve bayes-based, 
random 
forest-based, 
and 
BiLSTM-based 
models 
respectively achieved the highest accuracies. 
In the same manner, the proposed ensemble learning 
model has achieved higher F1-score rather than individual 
base models. Similar to accuracy values, among the base 
models, SVM-based, LR-based, naïve Bayes-based, random 
forest-based, and BiLSTM-based models respectively 
achieved the highest values for F1-score. Fig. 2 represents a 
visual comparison of the performance of all credibility 
evaluation models proposed in current study. 
C. Baseline Models 
To assess RELIANCE's performance thoroughly, we 
conduct a comparative analysis with the state-of-the-art 
baselines, which were performed on Fake News dataset: 
● Ghanem et al. [11]: They have introduced a 
methodology that integrates lexical, word embeddings, and 
n-gram features for identifying the stance in fake news. Given 
a news title-article pair, the system focuses on assessing the 
relevance between the article and the title.  
● Singh et al. [12]: In their study, Singh et al. employed 
various machine learning methods to detect fake news, 
utilizing the LIWC [16] (Linguistic Analysis and Word 
Count-based approach). 
TABLE III.  
THE PARAMETER SETTINGS OF THE PROPOSED BILSTM 
MODEL. 
Parameter 
Setting 
Number of epochs  
25 
Optimizer 
Adam 
Learning rate 
3e−4 
Loss function 
Binary crossentropy 
Activation 
softmax 
Early stopping 
Applied on validation accuracy 
Patient value 
5 
Dropout 
0.2 
Batch size 
32 
Cross validation 
10 fold 
TABLE IV.  
THE PARAMETER SETTINGS OF THE PROPOSED MLP MODEL 
Parameter 
Setting 
Activation  
Tanh 
Alpha 
0.0001 
Hidden layer sizes 
64,128,64 
Learning rate 
Constant 
Solver 
Adam 
TABLE V.  
EVALUATION RESULTS (IN PERCENT) FOR PROPOSED 
CREDIBILITY EVALUATION MODELS 
 
Precision  
Recall 
F1-score   
Accuracy 
BiLSTM 
71 
77 
74 
73.57 
LR 
87 
89 
88 
87.58 
SVM 
91 
88 
89 
89.29 
Random Forest 
77 
85 
81 
80.54 
Naïve Bayes 
82 
93 
87 
86.00 
Ensemble learning model 
92 
94 
93 
92.43 
 
 
Fig. 2. Precision, recall, F1-score, and accuracy values for suggested 
credibility evaluation models, including 5 base models along with 
ensemble learning model 
● Ahmed et al. [13]: In this paper, the authors to perform 
news credibility evaluation have introduce a hybrid model 
based on LR and n-gram analysis. They have used Term TF-
IDF as feature extraction technique. 
● Ruchansky et al. [15]: In this study, they introduced a 
model that integrates several key features of text document 
(such as the text of news document, news source, etc.) for a 
more precise and automated prediction. Specifically, their 
approach incorporates the behaviors of both users and 
60
70
80
90
100
Precision
Recall
F1-score
Accuracy
BiLSTM
LR
SVM
Random forest
Naïve Bayes
Ensemble learning
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
articles, along with the collective behavior of users who 
disseminate fake news.  
● Ahmed et al. [13]: In this paper, the authors have 
introduced a model for detecting fake news that employs n-
gram analysis and machine learning techniques. They explore 
and contrast two distinct feature extraction methods along 
with six diverse machine classification techniques.  
● Yang et al. [30]: They introduced a model called TI-
CNN (Text and Image Information-based Convolutional 
Neural Network) for evaluating the credibility of news 
documents. Their emphasis on sensitivity analysis in their 
approach aimed to enhance accuracy. 
Table VI presents a perspective on the performance of 
baseline models, along with the performance of proposed 
ensemble learning method by RELIANCE. Examining the 
data in this table reveals that RELIANCE has achieved the 
highest accuracy and f-measure results. 
TABLE VI.  
COMPARING THE PERFORMANCE OF BASELINE MODELS IN 
CREDIBILITY EVALUATION, WHICH WERE PERFORMED ON FAKE NEWS 
DATASET (MISSING VALUES ARE NOT REPORTED). SIGNIFICANT VALUES ARE 
IN BOLD. 
 
Precision  
Recall   
F1-score 
Accuracy   
Ghanem et al. [11] 
- 
- 
48.80 
 - 
Singh et al. [12]  
86.00 
90.00 
88.00 
87.00 
Ahmed et al. [13] 
- 
- 
- 
89.00 
Ruchansky et al. [14] 
- 
- 
89.40 
89.20 
Ahmed et al. [13] 
- 
- 
- 
92.00 
Yang et al. [30] 
92.20 
92.77 
92.10 
- 
RELIANCE 
(proposed method) 
92.49 
93.88 
92.75 
92.43 
 
D. Discussion 
The 
ensemble 
learning 
approach 
proposed 
by 
RELIANCE in this study, integrating five diverse base 
models (BiLSTMs, SVM, logistic regression, naive Bayes, 
and random forest) has demonstrated remarkable efficacy in 
the credibility evaluation of news documents. The integration 
of these base models through a MLP as the meta-model has 
yielded superior accuracy when compared to the performance 
of individual base models. 
The robustness and versatility of the ensemble learning 
model stems from its ability to capture and harness the 
distinctive strengths of each base model, compensating for 
their individual limitations. The inherent diversity among the 
base models, arising from variations in their underlying 
algorithms and processing methodologies, contributes to a 
more comprehensive and nuanced understanding of the 
complex features present in news documents. 
The significant improvement in accuracy achieved by the 
ensemble approach highlights the synergy of diverse models 
working collaboratively. The ensemble not only mitigates the 
risk of overfitting but also enhances the generalization 
capacity of the model, making it adept at handling the 
intricacies and nuances inherent in real-world news datasets. 
Moreover, the ensemble's outperformance suggests that the 
collaborative decision-making process employed by diverse 
models leads to a more robust and reliable system for news 
credibility assessment. The meta-model's ability to discern 
and integrate the collective insights of the base models results 
in a more discerning and accurate evaluation, overcoming the 
limitations associated with relying on any single model. 
Comparing the performance of RELIANCE by the state of 
the art studies that have been performed credibility evaluation 
using Fake News dataset, as shown in Table VI, clearly 
demonstrates the superiority of RELIANCE in credibility 
evaluation. Fig. 3 depicts the comparison of the accuracy of 
the baseline models, and our proposed method (RELIANCE) 
for news credibility evaluation. 
 
 
Fig. 3. Comparing the accuracy of baseline models (those that reported the 
accuracy values) in news credibility evaluation with the proposed model 
(RELIANCE) 
Lets’ to consider the main contributions of our study that 
was stated in Introduction:  
Contribution 1 (introducing five distinct diverse methods 
for news credibility evaluation): The introduction of five 
distinct diverse methods for news credibility evaluation 
serves as a foundational contribution to the field. Our choice 
of these methods, encompassing SVM, logistic regression, 
naive Bayes, random forest, and BiLSTMs, was driven by the 
aim to offer a diverse set of approaches, each capturing 
different aspects of the complex nature of documents. The 
subsequent utilization of these methods as base models in our 
ensemble learning framework allowed for a comprehensive 
exploration of the various features and patterns inherent in 
news content. Our findings highlight the importance of 
methodological diversity in tackling the multifaceted 
challenges of credibility assessment, offering valuable 
insights into the nuanced aspects of information reliability. 
Contribution 2 (enhancing credibility evaluation 
accuracy through ensemble learning): The primary objective 
of our study was to enhance the accuracy of news credibility 
evaluation, and the incorporation of ensemble learning stands 
out as a pivotal contribution in achieving this goal. By 
integrating the diverse perspectives and strengths of the five 
base models through a MLP as the meta-model, we witnessed 
a discernible enhancement in accuracy compared to 
individual base models. The ensemble learning framework 
effectively leveraged the complementary strengths of each 
method, mitigating the limitations associated with any 
singular approach. This not only resulted in a more robust and 
accurate credibility assessment but also highlighted the 
potential of ensemble learning as a powerful tool in 
information reliability studies.  
 
87.00
89.00
89.20
92.00
92.43
60
65
70
75
80
85
90
95
Singh et al
Ahmed et al
Ruchansky et al
Ahmed et al2
RELIANCE
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 
 
V. CONCLUSION 
In the current era of information overload, accurately 
assessing the credibility of news sources is crucial for 
informed decision-making and effective crisis management. 
To address this challenge, we propose RELIANCE (Reliable 
Ensemble Learning for Information and News Credibility 
Evaluation), an ensemble learning approach that combines 
the strengths of five individual models for news credibility 
evaluation. The base models include Support Vector 
Machines, naïve Bayes classifiers, logistic regression models, 
random forests, and Bidirectional Long Short-Term Memory 
Networks. These models are individually trained to extract 
relevant features from news documents and classify their 
credibility. To further enhance the overall accuracy, 
RELIANCE employs a multi-layer perceptron as a meta-
model, which integrates the predictions of each base model 
(using stacking) and produces a more refined credibility 
assessment. Comparative experiments with baseline models 
demonstrate that RELIANCE significantly outperforms 
existing algorithms in evaluating the credibility of news 
documents. It provides a robust framework for identifying 
trustworthy news sources, offering real-world applications 
that empower users, journalists, and fact-checkers with a 
resilient tool against misinformation in the digital era. 
REFERENCES 
[1] P. H. A. Faustini and T. F. Covoes, “Fake news detection in multiple 
platforms and languages,” Expert Syst. Appl., vol. 158, p. 113503, 2020. 
[2] M. R. Kondamudi, S. R. Sahoo, L. Chouhan, and N. Yadav, “A 
comprehensive survey of fake news in social networks: Attributes, features, 
and detection approaches,” J. King Saud Univ. Inf. Sci., vol. 35, no. 6, p. 
101571, 2023. 
[3] B. Pattanaik, S. Mandal, and R. M. Tripathy, “A survey on rumor 
detection and prevention in social media using deep learning,” Knowl. Inf. 
Syst., pp. 1–42, 2023. 
[4] Z. Jahanbakhsh-Nagadeh et al., “A model to measure the spread power 
of rumors,” J. Ambient Intell. Humaniz. Comput., vol. 14, no. 10, pp. 13787–
13811, 2023. 
[5] N. Rani, P. Das, and A. K. Bhardwaj, “Rumor, misinformation among 
web: a contemporary review of rumor detection techniques during different 
web waves,” Concurr. Comput. Pract. Exp., vol. 34, no. 1, p. e6479, 2022. 
[6] R. Upadhyay, G. Pasi, and M. Viviani, “Vec4Cred: a model for health 
misinformation detection in web pages,” Multimed. Tools Appl., vol. 82, no. 
4, pp. 5271–5290, 2023. 
[7] P. Przybyła and A. J. Soto, “When classification accuracy is not enough: 
Explaining news credibility assessment,” Inf. Process. Manag., vol. 58, no. 
5, p. 102653, 2021. 
[8] G. Pasi, M. De Grandis, and M. Viviani, “Decision making over multiple 
criteria to assess news credibility in microblogging sites,” in 2020 IEEE 
International Conference on Fuzzy Systems (FUZZ-IEEE), IEEE, 2020, pp. 
1–8. 
[9] N. Sitaula, C. K. Mohan, J. Grygiel, X. Zhou, and R. Zafarani, 
“Credibility-based fake news detection,” Disinformation, misinformation, 
fake news Soc. media Emerg. Res. challenges Oppor., pp. 163–182, 2020. 
[10] M. Ramezani et al., “Automatic personality prediction: an enhanced 
method using ensemble modeling,” Neural Comput. Appl., vol. 34, no. 21, 
pp. 18369–18389, 2022. 
[11] B. Ghanem, P. Rosso, and F. Rangel, “Stance detection in fake news a 
combined feature representation,” in Proceedings of the first workshop on 
fact extraction and VERification, 2018, pp. 66–71. 
[12] V. Singh, R. Dasgupta, D. Sonagra, K. Raman, and I. Ghosh, 
“Automated fake news detection using linguistic analysis and machine 
learning,” in International conference on social computing, behavioral-
cultural modeling, & prediction and behavior representation in modeling 
and simulation (SBP-BRiMS), 2017, pp. 1–3. 
[13] H. Ahmed, I. Traore, and S. Saad, “Detection of online fake news using 
n-gram analysis and machine learning techniques,” in Intelligent, Secure, 
and Dependable Systems in Distributed and Cloud Environments: First 
International Conference, ISDDC 2017, Vancouver, BC, Canada, October 
26-28, 2017, Proceedings 1, Springer, 2017, pp. 127–138. 
[14] N. Ruchansky, S. Seo, and Y. Liu, “Csi: A hybrid deep model for fake 
news detection,” in Proceedings of the 2017 ACM on Conference on 
Information and Knowledge Management, 2017, pp. 797–806. 
[15] R. Basak, S. Sural, N. Ganguly, and S. K. Ghosh, “Online public 
shaming on Twitter: Detection, analysis, and mitigation,” IEEE Trans. 
Comput. Soc. Syst., vol. 6, no. 2, pp. 208–220, 2019. 
[16] J. W. Pennebaker, M. E. Francis, and R. J. Booth, “Linguistic inquiry 
and word count: Liwc 2001Lawrence Erlbaum Associates.” Mahway, 2001. 
[17] R. K. Kaliyar, A. Goswami, and P. Narang, “A Hybrid Model for 
Effective Fake News Detection with a Novel COVID-19 Dataset.,” in 
ICAART (2), 2021, pp. 1066–1072. 
[18] D. K. Dixit, A. Bhagat, and D. Dangi, “Fake News Classification Using 
a Fuzzy Convolutional Recurrent Neural Network.,” Comput. Mater. 
Contin., vol. 71, no. 3, 2022. 
[19] M. Potthast, J. Kiesel, K. Reinartz, J. Bevendorff, and B. Stein, “A 
stylometric inquiry into hyperpartisan and fake news,” arXiv Prepr. 
arXiv1702.05638, 2017. 
[20] H. Karimi, P. Roy, S. Saba-Sadiya, and J. Tang, “Multi-source multi-
class fake news detection,” in Proceedings of the 27th international 
conference on computational linguistics, 2018, pp. 1546–1557. 
[21] S. Gupta, R. Thirukovalluru, M. Sinha, and S. Mannarswamy, 
“CIMTDetect: a community infused matrix-tensor coupled factorization 
based method for fake news detection,” in 2018 IEEE/ACM International 
Conference on Advances in Social Networks Analysis and Mining 
(ASONAM), IEEE, 2018, pp. 278–281. 
[22] V.-H. Nguyen, K. Sugiyama, P. Nakov, and M.-Y. Kan, “Fang: 
Leveraging social context for fake news detection using graph 
representation,” in Proceedings of the 29th ACM international conference 
on information & knowledge management, 2020, pp. 1165–1174. 
[23] K. Shu, S. Wang, and H. Liu, “Beyond news contents: The role of social 
context for fake news detection,” in Proceedings of the twelfth ACM 
international conference on web search and data mining, 2019, pp. 312–320. 
[24] N. Seddari, A. Derhab, M. Belaoued, W. Halboob, J. Al-Muhtadi, and 
A. Bouras, “A hybrid linguistic and knowledge-based analysis approach for 
fake news detection on social media,” IEEE Access, vol. 10, pp. 62097–
62109, 2022. 
[25] M. Hadi Goldani, R. Safabakhsh, and S. Momtazi, “X-CapsNet For 
Fake News Detection,” arXiv e-prints, p. arXiv-2307, 2023. 
[26] M. Davoudi, M. R. Moosavi, and M. H. Sadreddini, “A Novel Method 
for Fake News Detection Based on Propagation Tree,” in 2021 11th 
International Conference on Computer Engineering and Knowledge 
(ICCKE), IEEE, 2021, pp. 105–109. 
[27] S. Yang, K. Shu, S. Wang, R. Gu, F. Wu, and H. Liu, “Unsupervised 
fake news detection on social media: A generative approach,” in Proceedings 
of the AAAI conference on artificial intelligence, 2019, pp. 5644–5651. 
[28] Y. Liu and Y.-F. Wu, “Early detection of fake news on social media 
through propagation path classification with recurrent and convolutional 
networks,” in Proceedings of the AAAI conference on artificial intelligence, 
2018. 
[29] S. Ghosh and C. Shah, “Towards automatic fake news classification,” 
Proc. Assoc. Inf. Sci. Technol., vol. 55, no. 1, pp. 805–807, 2018. 
[30] Y. Yang, L. Zheng, J. Zhang, Q. Cui, Z. Li, and P. S. Yu, “TI-CNN: 
Convolutional neural networks for fake news detection,” arXiv Prepr. 
arXiv1806.00749, 2018. 
[31] S. Bird, E. Klein, and E. Loper, ""Natural language processing with 
Python: analyzing text with the natural language toolkit,"" O'Reilly Media, 
Inc., 2009. 
[32] M. Ramezani, M.-R. Feizi-Derakhshi, and M.-A. Balafar, “Text-based 
automatic personality prediction using KGrAt-Net: a knowledge graph 
attention network classifier,” Sci. Rep., vol. 12, no. 1, p. 21453, 2022. 
[33] Q. Le and T. Mikolov, “Distributed representations of sentences and 
documents,” in International conference on machine learning, PMLR, 2014, 
pp. 1188–1196. 
[34] 
“Kaggle. 
(2024). 
Fake 
News.” 
[Online]. 
Available: 
https://www.kaggle.com/c/fake-news/data 
"
"eXplainable AI has received signiﬁcant attention in recent years. Machine learning models often operate as black boxes, lacking explainability and transparency while supporting decision-making processes. Local post-hoc explainability queries attempt to answer why individual inputs are classiﬁed in a certain way by a given model. While there has been important work on counterfactual explanations, less attention has been devoted to semifactual ones. In this paper, we focus on local post-hoc explainability queries within the semifactual “even-if” thinking and their computational complexity among different classes of models, and show that both linear and tree-based models are strictly more interpretable than neural networks. After this, we introduce a preference-based framework that enables users to personalize explanations based on their preferences, both in the case of semifactuals and counterfactuals, enhancing interpretability and user-centricity. Finally, we explore the complexity of several interpretability problems in the proposed preference-based framework and provide algorithms for polynomial cases.nan","The extensive study of counterfactual “if only” thinking, exploring how things might have been different, has been a focal point for social and cognitive psychologists [Kahneman and Tversky, 1981; McCloy and Byrne, 2002]. Consider a negative event, such as taking a taxi and due to trafﬁc arriving late to a party. By analyzing this situation, an individual (e.g. Alice) might engage in counterfactual thinking by imagining how things could have unfolded differently, such as, “if only Alice had not taken the taxi, she would not have arrived late at the party”. This type of counterfactual thinking, where an alternative scenario is imagined, is a common aspect of daily life. In such a case the counterfactual scenario negates both the event’s cause (antecedent) and its outcome, presenting a false cause and a false outcome that are temporarily considered as true (e.g., Alice took the taxi and arrived late). Counterfactual thinking forms the basis for crafting counterfactual explanations, which are crucial in automated decision-making processes. These explanations leverage imagined alternative scenarios, aiding users in understanding why certain outcomes occurred and how different situations might have inﬁuenced automated decisions. Counterfactual explanations empowers users to grasp the rationale behind automated decisions, fostering transparency and user trust in these systems. Several deﬁnitions of counterfactual explanations exist in the literature [Guidotti, 2022]. According to most of the literature, counterfactuals are deﬁned as the minimum changes to apply to a given instance to let the prediction of the model be different [Barceló et al., 2020]. While signiﬁcant attention in AI has been given to counterfactual explanations, there has been a limited focus on the equally important and related semifactual “even if” explanations [Aryal and Keane, 2023; Kenny and Huang, 2023], though they have been investigated much more in cognitive sciences. While counterfactuals explain what changes to the input features of an AI system change the output decision, semifactuals show which input feature changes do not change a decision outcome. Considering the above-mentioned situation where Alice took the taxi and arrived late at the party, we might analyze “even if” scenarios envisioning how things could have remained the same, such as, “even if Alice had not taken a taxi, she would have still arrived late at the party”. Sharing the same underlying idea of counterfactuals, we deﬁne semifactuals as the maximum changes to be applied to a given instance while keeping the same prediction. Indeed, the larger the feature differences asserted in the semifactual, the better (more convincing) the explanation [Aryal and Keane, 2023]. This intuitively captures the desire of an agent to have more degree of freedom and favorable conditions (represented by features changed), while keeping the (positive) status assigned to it by the model. As an example, consider the following, inspired by a mortgage scenario.
Example 1. Consider the binary and linear classiﬁcation model M : {0, 1}3 → {0, 1} shown in Figure 1 where M is deﬁned as step(x ⋅ [2, 2, 0] + 1). The three features are:

• f1 =“user’s employment contract is part-time”,
• f2 =“user applies for a mortgage whose duration is longer than 30 years”, and
• f3 =“user works on-site”.nan","However, as highlighted in the previous example, multiple semifactuals can exist for each given instance. In these situations, a user may prefer one semifactual to another, by expressing preferences over features so that the best semifactuals will be selected, as shown in the following example.
Example 2. Continuing with the previous example, suppose that the user x1 prefers semifactuals with f1 = 1 rather than those with f2 = 0, that is (s)he prefers to change feature f1 rather than f2 (irrespective of any other change). Thus, (s)he would prefer to still get a mortgage by changing the job to part-time (obtaining y2); if this cannot be accomplished, then (s)he prefers to get a mortgage by changing the duration to be less than or equal to 30 years (obtaining y1). Prioritized reasoning in AI, focusing on incorporating user preferences, represents a pivotal advancement in the ﬁeld, enhancing adaptability and user-centricity of AI systems. Traditional AI models rely on predeﬁned rules or optimization criteria to generate outcomes, often overlooking the nuanced nature of user-speciﬁc preferences [Rossi et al., 2011; Santhanam et al., 2016]. Prioritized reasoning addresses this limitation by introducing a mechanism that allows users to express their preferences, thereby guiding AI systems to prefer speciﬁc factors over others in the decision-making processes. One key aspect of prioritized reasoning is its applicability across diverse AI domains, spanning machine learning [Kapoor et al., 2012], natural language processing [Bakker et al., 2022], and recommendation systems [Zhu et al., 2022]. In machine learning, for instance, the ability to prioritize speciﬁc features or outcomes based on user preferences signiﬁcantly improves the relevance and usability of the resulting models. Within natural language processing, prioritized reasoning facilitates customized language generation aligned with individual preferences, catering to diverse communication styles. The impact of prioritized reasoning extends to recommendation systems, where user preferences play a crucial role in shaping the suggestions provided. Our work contributes to prioritized reasoning within explainable AI in the presence of user’s preference conditions related to features. These preferences are exploited to generate semifactual and counterfactual explanations that align most closely with the user-speciﬁed criteria. In particular, preferences are applied similarly to what has been proposed in the well-known Answer Set Optimization approach for Logic Programs with preferences [Brewka et al., 2003].nannan",Nonenan,Nonenan,"In this paper, after exploring local post-hoc interpretability queries related to semifactuals and their computational complexity among three classes of models (FBDDs, perceptrons, and MLPs), we introduced a framework that enables users to personalize semifactual and counterfactual explanations based on preferences. Then, we investigated the complexity of the proposed framework and presented PTIME algorithms. Our approach to handle preferences over semifac-tual/counterfactual explanations is inspired by the Answer Set Optimization approach [Brewka et al., 2003]. In particular, conditional preferences among features are deﬁned by means of preference rules, the satisfaction of each rule is evaluated quantitatively, whereas the overall preference order is deﬁned in a qualitative way. The main advantages of such approach consist in the simplicity and compactness of representation, and combination of quantitative and qualitative evaluations.nan","Even-if Explanations: Formal Foundations, Priorities and Complexity","Gianvincenzo Alfano, Sergio Greco, Domenico Mandaglio, Francesco Parisi, Reza Shahbazian, Irina Trubitsyna","Even-if Explanations: Formal Foundations, Priorities and Complexity
Gianvincenzo Alfano , Sergio Greco , Domenico Mandaglio , Francesco Parisi ,
Reza Shahbazian and Irina Trubitsyna
DIMES Department, University of Calabria, Rende, Italy
{g.alfano, greco, d.mandaglio, fparisi, i.trubitsyna}@dimes.unical.it reza.shahbazian@unical.it
Abstract
EXplainable AI has received signiﬁcant attention
in recent years.
Machine learning models of-
ten operate as black boxes, lacking explainabil-
ity and transparency while supporting decision-
making processes.
Local post-hoc explainability
queries attempt to answer why individual inputs
are classiﬁed in a certain way by a given model.
While there has been important work on counter-
factual explanations, less attention has been de-
voted to semifactual ones. In this paper, we fo-
cus on local post-hoc explainability queries within
the semifactual ‘even-if’ thinking and their com-
putational complexity among different classes of
models, and show that both linear and tree-based
models are strictly more interpretable than neural
networks. After this, we introduce a preference-
based framework that enables users to personalize
explanations based on their preferences, both in the
case of semifactuals and counterfactuals, enhanc-
ing interpretability and user-centricity. Finally, we
explore the complexity of several interpretability
problems in the proposed preference-based frame-
work and provide algorithms for polynomial cases.
1
Introduction
The extensive study of counterfactual ‘if only’ thinking, ex-
ploring how things might have been different, has been a focal
point for social and cognitive psychologists [Kahneman and
Tversky, 1981; McCloy and Byrne, 2002]. Consider a neg-
ative event, such as taking a taxi and due to trafﬁc arriving
late to a party. By analyzing this situation, an individual (e.g.
Alice) might engage in counterfactual thinking by imagining
how things could have unfolded differently, such as, ‘if only
Alice had not taken the taxi, she would not have arrived late
at the party’. This type of counterfactual thinking, where an
alternative scenario is imagined, is a common aspect of daily
life. In such a case the counterfactual scenario negates both
the event’s cause (antecedent) and its outcome, presenting a
false cause and a false outcome that are temporarily consid-
ered as true (e.g., Alice took the taxi and arrived late).
Counterfactual thinking forms the basis for crafting coun-
terfactual explanations, which are crucial in automated
y1 = [0, 0, 0]
[1,0,0]
[1,1,1]
[0,0,1]
y2 = [1, 1, 0]
f1
f2
f3
x1 = [0, 1, 1]
[1,0,1]
Figure 1: Binary classiﬁcation model M : step(x · [−2, 2, 0] + 1)
of Example 1 representing the mortgage scenario. The binary fea-
ture f1 (resp., f2 and f3) represents part-time employment contract
(resp., mortgage term longer than 30 years, and on site-working).
Crosses (resp., circles) on the corners of the green (resp., red) area
correspond to instances where the model outputs 1 (resp., 0).
decision-making processes.
These explanations leverage
imagined alternative scenarios, aiding users in understanding
why certain outcomes occurred and how different situations
might have inﬂuenced automated decisions. Counterfactual
explanations empowers users to grasp the rationale behind
automated decisions, fostering transparency and user trust in
these systems. Several deﬁnitions of counterfactual explana-
tions exist in the literature [Guidotti, 2022]. According to
most of the literature, counterfactuals are deﬁned as the mini-
mum changes to apply to a given instance to let the prediction
of the model be different [Barcel´o et al., 2020].
While signiﬁcant attention in AI has been given to coun-
terfactual explanations, there has been a limited focus on the
equally important and related semifactual ‘even if’ expla-
nations [Aryal and Keane, 2023; Kenny and Huang, 2023],
though they have been investigated much more in cognitive
sciences. While counterfactuals explain what changes to the
input features of an AI system change the output decision,
semifactuals show which input feature changes do not change
a decision outcome. Considering the above-mentioned situ-
ation where Alice took the taxi and arrived late at the party,
we might analyze ‘even if’ scenarios envisioning how things
could have remained the same, such as, “even if Alice had not
taken a taxi, she would have still arrived late at the party”.
Sharing the same underlying idea of counterfactuals, we
deﬁne semifactuals as the maximum changes to be applied
to a given instance while keeping the same prediction. In-
deed, the larger the feature differences asserted in the semi-
factual, the better (more convincing) the explanation [Aryal
and Keane, 2023]. This intuitively captures the desire of an
agent to have more degree of freedom and favorable condi-
tions (represented by features changed), while keeping the
(positive) status assigned to it by the model. As an example,
consider the following, inspired by a mortgage scenario.
Example 1. Consider the binary and linear classiﬁcation
model M : {0, 1}3 → {0, 1} shown in Figure 1 where M
is deﬁned as step(x · [⇥2, 2, 0] + 1). The three features are:
• f1 =“user’s employment contract is part-time”,
• f2 =“user applies for a mortgage whose duration is
longer than 30 years”, and
• f3 =“user works on-site”.
For any instance x ⇤ {0, 1}3 we have that M(x) = 0 if
x = [1, 0, 1] or x = [1, 0, 0], and M(x) = 1 otherwise.
Intuitively, this means that the bank’s model does not approve
the mortgage only when the user has a part-time job and the
requested mortgage duration is less than 30 years.
Consider a user x1 that works full-time, on-site, and re-
quests a mortgage with duration longer than 30 years (i.e.,
x1 = [0, 1, 1]), we have that y1 = [0, 0, 0] and y2 = [1, 1, 0]
are semifactual of x1 w.r.t. M at maximum distance (i.e., 2)
from x1 in terms of number of feature changed. Intuitively,
y1 represents ‘the user x1 will obtain the mortgage even if
the work would have been remote and the mortgage duration
would have been less than 30 years’, while y2 represents ‘the
user x1 will obtain the mortgage even if the work would have
been part-time and she would have worked remotely’.
2
However, as highlighted in the previous example, multi-
ple semifactuals can exist for each given instance. In these
situations, a user may prefer one semifactual to another, by
expressing preferences over features so that the best semifac-
tuals will be selected, as shown in the following example.
Example 2. Continuing with the previous example, suppose
that the user x1 prefers semifactuals with f1 = 1 rather than
those with f2 = 0, that is (s)he prefers to change feature f1
rather than f2 (irrespective of any other change). Thus, (s)he
would prefer to still get a mortgage by changing the job to
part-time (obtaining y2); if this cannot be accomplished, then
(s)he prefers to get a mortgage by changing the duration to be
less than or equal to 30 years (obtaining y1).
2
Prioritized reasoning in AI, focusing on incorporating user
preferences, represents a pivotal advancement in the ﬁeld, en-
hancing adaptability and user-centricity of AI systems. Tra-
ditional AI models rely on predeﬁned rules or optimiza-
tion criteria to generate outcomes, often overlooking the nu-
anced nature of user-speciﬁc preferences [Rossi et al., 2011;
Santhanam et al., 2016]. Prioritized reasoning addresses this
limitation by introducing a mechanism that allows users to ex-
press their preferences, thereby guiding AI systems to prefer
speciﬁc factors over others in the decision-making processes.
One key aspect of prioritized reasoning is its appli-
cability across diverse AI domains,
spanning machine
learning [Kapoor et al., 2012], natural language process-
ing [Bakker et al., 2022], and recommendation systems [Zhu
et al., 2022]. In machine learning, for instance, the ability
to prioritize speciﬁc features or outcomes based on user pref-
erences signiﬁcantly improves the relevance and usability of
the resulting models.
Within natural language processing,
prioritized reasoning facilitates customized language gener-
ation aligned with individual preferences, catering to diverse
communication styles. The impact of prioritized reasoning
extends to recommendation systems, where user preferences
play a crucial role in shaping the suggestions provided.
Our work contributes to prioritized reasoning within ex-
plainable AI in the presence of user’s preference conditions
related to features. These preferences are exploited to gen-
erate semifactual and counterfactual explanations that align
most closely with the user-speciﬁed criteria. In particular,
preferences are applied similarly to what has been proposed
in the well-known Answer Set Optimization approach for
Logic Programs with preferences [Brewka et al., 2003].
Contributions
Our main contributions are as follows.
• We formally introduce the concepts of semifactual over
three classes of models: (i) perceptrons (ii) free bi-
nary decision diagrams (FBBDs), and (iii) multi-layer
perceptrons (MLP), intuitively encoding local post-hoc
explainable queries within the even-if thinking setting.
Herein, the term ‘local’ refers to explaining the output of
the system for a particular input, while ‘post-hoc’ refers
to interpreting the system after it has been trained.
• We ﬁrst investigate the computational complexity of in-
terpretability problems concerning semifactuals, show-
ing that they are not more difﬁcult than analogous prob-
lems related to counterfactuals [Barcel´o et al., 2020].
• We introduce a framework that empowers users to pri-
oritize explanations according to their subjective pref-
erences. That is, users can specify preferences for al-
tering speciﬁc features over others within explanations.
This approach enriches the explanation process, en-
abling users to inﬂuence the selection of the most favor-
able semifactuals (called “best” semifactuals), thereby
augmenting the interpretability and user-centricity of the
resulting outputs. Notably, the proposed framework also
naturally encompasses preferences over counterfactuals.
• We investigate the complexity of several interpretability
problems related to best semifactuals and best counter-
factuals. Table 1 summarizes our complexity results. Fi-
nally, focusing on a restricted yet expressive class of fea-
ture preferences, we identify tractable cases for which
we propose algorithms for their computation.
Full proofs can be found in the Supplementary Material.
2
Preliminaries
We start by recalling the key concepts underlying counterfac-
tual and semifactual explanations, and then we recall the main
complexity classes used in the paper.
2.1
Classiﬁcation Models
A (binary classiﬁcation) model is a function M : {0, 1}n →
{0, 1}, speciﬁcally focusing on instances whose features are
represented by binary values. Constraining inputs and out-
puts to booleans simpliﬁes our context while encompassing
numerous relevant practical scenarios. A class of models is
just a way of grouping models together. An instance x is a
vector in {0, 1}n and represents a possible input for a model.
We now recall three signiﬁcant categories of ML models,
that hereafter will be the one we will focus on.
Binary Decision Diagrams.
A Binary Decision Diagram
(BDD) M = (V, E, λV , λE) [Wegener, 2004] is a rooted di-
rected acyclic graph (V, E). It features leaves labeled true
(⌅) or false (⇧), and internal nodes labeled by function λV
with a value from {1, . . . , n}, each of them having two out-
going edges labeled by function λE as 1 and 0, respectively.
Each instance x = [x1, . . . , xn] ⇤ {0, 1}n uniquely maps to
a path px in M. This path adheres to the following condi-
tion: for every non-leaf node u in px labeled i, the path goes
through the edge labeled with xi. |M| denotes the size of M,
representing the number of edges. A binary decision diagram
M is free (FBDD) if for every path from the root to a leaf, no
two nodes on that path have the same label. A decision tree
is simply an FBDD whose underlying graph is a tree.
Multilayer Perceptrons.
A multilayer perceptron (MLP)
M with k layers is deﬁned by a sequence of weight matrices
W(1), . . . , W(k), bias vectors b(1), . . . , b(k), and activation
functions a(1), . . . , a(k). Given an instance x, we inductively
deﬁne h(i) = a(i)(h(i−1)W(i) + b(i)) with i ⇤ {1, . . . , k},
assuming that h(0) = x. The output of M on x is deﬁned
as M(x) = h(k). In this paper we assume all weights and
biases to be rational numbers, i.e. belonging to Q. We say
that an MLP as deﬁned above has (k ⇥ 1) hidden layers. The
size of an MLP M, denoted by |M|, is the total size of its
weights and biases, in which the size of a rational number p
q
is log2(p) + log2(q) (with the convention that log2(0) = 1).
We focus on MLPs in which all internal functions
a(1), . . . , a(k−1)
are
the
ReLU
function
relu(x)
=
max(0, x). Usually, MLP binary classiﬁers are trained using
the sigmoid as the output function a(k). Nevertheless, when
an MLP classiﬁes an input (after training), it takes decisions
by simply using the preactivations, also called logits. Based
on this and on the fact that we only consider already trained
MLPs, we can assume w.l.o.g. that the output function a(k)
is the binary step function, deﬁned as step(x) = 0 if x < 0,
and step(x) = 1 if x ⌃ 0.
Perceptrons.
A perceptron is an MLP with no hidden lay-
ers (i.e., k = 1). That is, a perceptron M is deﬁned by a
pair (W, b) such that W ⇤ Qn◊1 and b ⇤ Q, and the out-
put is M(x) = step(x W + b). Because of its particular
structure, a perceptron is usually deﬁned as a pair (w, b) with
w = WT a rational vector and b a rational number. The out-
put of M(x) is then 1 iff x · w + b ⌃ 0, where x · w denotes
the dot product between x and w.
2.2
Complexity Classes
Boolean functions F mapping strings to strings whose output
is a single bit are called decision problems. We identify the
computational problem of computing F (i.e., given an input
string x compute F(x)) with the problem of deciding whether
F(x) = 1. As an example of F, consider to take as input a
graph G and a number k and return 1 whether there exists a
set of vertices each-other not adijacent of size at least k. This
decision problem is known as INDEPENDENT SET.
We recall the complexity classes used in the paper and, in
particular, the deﬁnition of the classes PTIME (or, brieﬂy, P),
NP and coNP (see e.g.
[Papadimitriou, 1994]). P (resp.,
NP) contains the set of decision problems that can be solved
in polynomial time by a deterministic (resp., nondeterminis-
tic) Turing machine. Moreover, coNP is the complexity class
containing the complements of problems in NP. A problem p
is called hard for a complexity class C (denoted C-hard) if
there exists a polynomial reduction from any problem in C to
p. If p is both C-hard and belongs to C then it is C-complete.
Clearly, P⌥ NP, P⌥ coNP and, under standard theoretical as-
sumptions, the three classes are assumed to be different.
3
Even-if Explanations
In this section, we instantiate our framework on three im-
portant classes of boolean models and explainability queries.
Subsequently, we present our main theorems, facilitating a
comparison of these models in terms of their interpretability.
We start by recalling the notion of counterfactual, that is
the explainability notion in the ‘if only’ case, whose com-
plexity has been investigated in [Barcel´o et al., 2020].
We deﬁne the distance measure between two instances
x, y ⇤ {0, 1}n as the number of features where they differ.
Formally, d(x, y) = !n
i=1 |xi ⇥ yi| is the number of indexes
i ⇤ {1, . . . , n} (i.e., features) where x and y differ.
Deﬁnition 1 (Counterfactual). Given a pre-trained model M
and an instance x, an instance y is said to be a counterfac-
tual of x iff i) M(x) ̸= M(y), and ii) there exists no other
instance z̸=y s.t. M(x) ̸= M(z) and d(x, z)<d(x, y).
Example 3. Continuing with our running example (see Fig-
ure 1), for x1 = [0, 1, 1] we have that y3 = [1, 0, 1] is the only
counterfactual of x1 w.r.t. M (herein, d(x1, y3) = 2).
2
The following represents the natural decision version of the
problem of ﬁnding a couterfactual for x [Barcel´o et al., 2020].
PROBLEM: MINIMUMCHANGEREQUIRED (MCR)
INPUT:
Model M, instance x, and k ⇤ N.
OUTPUT:
YES, if there exists an instance y with
d(x, y)  k and M(x) ̸= M(y);
NO, otherwise.
Theorem 1 ([Barcel´o et al., 2020]). MCR is i) in PTIME for
FBDDs and perceptrons, and ii) NP-complete for MLPs.
We follow a standard assumption about the relationship
between model interpretability and computational complex-
ity [Barcel´o et al., 2020] which states that a class A of mod-
els is more interpretable than another class B if the computa-
tional complexity of addressing post-hoc queries for models
in B is higher than for those in A.
Under the lens of the aforementioned assumption, Theo-
rem 1 states that the class of models ‘perceptron’ and ‘FBDD’
is strictly more interpretable than the class ‘MLP’, as the
computational complexity of answering post-hoc queries for
models in the ﬁrst two classes is lower than for those in the
latter. These results represent a principled way to conﬁrm
the folklore belief that linear models are more interpretable
than deep neural networks within the context of interpretabil-
ity queries for counterfactuals.
An open question is whether the same holds when dealing
with post-hoc queries based on the ’even-if’ thinking setting,
i.e. on semifactuals. Before exploring this research question,
we formally introduce the concept of semifactual.
Deﬁnition 2 (Semifactual). Given a pre-trained model M
and an instance x, an instance y is said to be a semifactual of
x iff i) M(x) = M(y), and ii) there exists no other instance
z̸=y s.t. M(x) = M(z) and d(x, z)>d(x, y).
Similar to counterfactuals, the following problem is the de-
cision version of the problem of ﬁnding a semifactual of an
instance x with a model M.
PROBLEM: MAXIMUMCHANGEALLOWED (MCA)
INPUT:
Model M, instance x, and k ⇤ N.
OUTPUT:
YES, if there exists an instance y with
d(x, y) ⌃ k and M(x) = M(y);
NO, otherwise.
The complexity of MCA is as follows.
Theorem 2. MCA is i) in PTIME for FBDDs and percep-
trons, and ii) NP-complete for MLPs.
Proof. (Sketch) (Perceptron). MCA (optimization) problem
under perceptrons can be formulated in ILP as follows:
max
n!
i=1
zi subject to
⇥ !n
i=1 wi(2xi ⇥ 1)zi  !n
i=1 wixi
zi ⇤ {0, 1}, i = 1, . . . , n
where zi = 1 if we decide to change the feature i, 0 other-
wise, for each i = 1, · · · , n. Notice that the above formu-
lation corresponds to the standard (max-) Knapsack problem
where each item has value 1 and weight wi(2xi ⇥ 1), and the
bag has capacity !n
i=1 wixi. The Knapsack problem is, in
the general case, NP-Hard [Papadimitriou, 1994]. However,
MCA corresponds to a special instance of Knapsack where
every item has the same cost that can be solved in polynomial
time with a greedy strategy, from which the result follows.
(FBDD). Let Mu be the FBDD obtained by restricting
M to the nodes that are (forward-)reachable from u and
mcau(x) = max{k⇥ | ⌦y. d(x, y) = k⇥ ↵ Mu(y)=M(x)}
(that can be comptuted in PTIME). For y maximizing k⇥ it
holds that yu′ ̸= xu′ holds ∀u⇥ from the root of M to u ex-
cluded. Let r be the root of M. Then, we can show that
(M, x, k) is a positive instance of MCA iff mcar(x) ⌃ k.
(MLP) The following algorithm provides the membership in
NP. Guess an instance y and check in PTIME that d(x, y)
⌃ k and M(x) = M(y). We prove the hardness with a poly-
nomial reduction from INDEPENDENT SET, which is known
to be NP-complete [Papadimitriou, 1994].
It turns out that, under standard complexity assumptions,
computing semifactuals under perceptrons and FBDDs is eas-
ier than under multi-layer perceptrons. Moreover, indepen-
dently of the type of the model, computing semifactuals is
as hard as computing counterfactuals (cf. Table 1). Thus,
perceptrons and FBDDs are strictly more interpretable than
MLPs, in the sense that the complexity of answering post-
hoc queries for models in the ﬁrst two classes is lower than
for those in the latter.
Models of the form {0, 1}n ⇥ {0, 1}
FBDDs
Perceptrons
MLPs
MCR
PTIME
PTIME
NP-c
MCA
PTIME
PTIME
NP-c
BMCR
PTIME
PTIME
NP-c
BMCA
PTIME
PTIME
NP-c
CBMCR
coNP
coNP
coNP-c
CBMCA
coNP
coNP
coNP-c
L-CBMCR
PTIME
PTIME
coNP-c
L-CBMCA
PTIME
PTIME
coNP-c
Table 1: Complexity of explainability queries. For any class C, C-c
means C-complete. Grey-colored cells refer to known results.
4
Preferences over Explanations
The problem of preference handling has been extensively
studied in AI. Several formalisms have been proposed to ex-
press and reason with different kinds of preferences [Brafman
and Domshlak, 2009; Rossi et al., 2011; Santhanam et al.,
2016]. In the ﬁeld of logic programming under stable model
semantics (a.k.a. Answer Set Programming - ASP), multi-
ple formalisms introducing preferences over atoms to ﬁlter
out models have been suggested. In the following, in order
to express preferences over semifactuals and counterfactuals,
we introduce a novel approach inspired to that proposed in
[Brewka et al., 2003] for ASP, whose semantics is based on
the degree to which preference rules are satisﬁed.
Syntax.
Input instances are of the form x = (x1, ..., xn)
in {0, 1}n. Each xi (with i ⇤ [1, n]) represents the value of
feature fi, and the (equality) atom fi = xi denotes that the
value of feature fi in x is equal to xi.
A simple preference is an expression of the form (fi =
x⇥
i) ≻ (fj = x⇥⇥
j ); it intuitively states that we prefer semi-
factuals (resp., counterfactuals) where fi = x⇥
i w.r.t. those
where fj = x⇥⇥
j . To simplify the notation, an equality atom
of the form fi = 1 is written as a positive atom fi, whereas
an atom of the form fi = 0 is written as a negated atom ¬fi.
Positive and negated atoms are also called (feature) literals.
Deﬁnition 3 (Preference rule). Let I = {f1, ..., fn} be the
set of input features. A preference rule is of the form:
⇥1 ≻ · · · ≻ ⇥k ← ⇥k+1 ↵ · · · ↵ ⇥m
(1)
with m ⌃ k ⌃ 2, and any ⇥i ⇤ {f1, ¬f1, . . . fn, ¬fn} is a
(feature) literal, with i ⇤ [1, n].
In (1), ⇥1 ≻ · · · ≻ ⇥k is called head (or consequent),
whereas ⇥k+1 ↵ · · · ↵ ⇥m is called body (or antecedent). We
assume that literals in the head are distinct. Intuitively, when-
ever ⇥k+1, · · · , ⇥m are true, then ⇥1 is preferred over ⇥2,
which is preferred over ⇥3, and so on until ⇥k−1 which is
preferred over ⇥k. As usual, when the body of the rule is
empty, the implication symbol ← is omitted.
Deﬁnition 4 (BCMP framework). A (binary classiﬁcation)
model with preferences (BCMP) framework is a pair (M, ≻)
where M is a model and ≻1 a set of preference rules over
features of M.
1With a little abuse of notation, we use ⇤ to denote both a set of
preference and the preference relation among feature literals.
Example 4. The BCMP framework Λ1 = (M, {f1 ≻¬f2}),
where M is the model presented in Example 1, encodes the
user’s preference speciﬁed in Example 2. Consider now the
framework Λ2 obtained from Λ1 by replacing the preference
rule with f1 ≻ ¬ f2 ← ¬f3. Intuitively, this preference rule
encodes a user preference for explanations where, whenever
the work is not on-site (i.e., ¬f3 holds), (s)he prefers semifac-
tuals/counterfactuals where the contract is part-time (i.e., f1
holds) and, if this is not possible, (s)he prefers those where the
mortgage duration is not longer than 30 years (i.e., ¬f2). 2
Semantics.
The preference rules determine a preference or-
dering ✏ on the semifactual/counterfactual explanations of an
instance x w.r.t. a model M, as shown in what follows.
Let us consider a semifactual or counterfactual explanation
y and a preference ⇤ of the form (1), the following three sit-
uations are possible:
(a) the body of ⇤ is not satisﬁed in y;2
(b) the body of ⇤ is satisﬁed in y and at least one head literal
is true in y;
(c) the body of ⇤ is satisﬁed in y and none of the head liter-
als is satisﬁed in y.
In the cases a) and b) we say that y satisﬁes ⇤ respectively
with degree 1 and min({l | y satisﬁes ⇥l with l  k}) (de-
noted as ⌅(y, ⇤)), while in case (c) we say that y does not sat-
isfy ⇤ and the associated degree is ⌅(y, ⇤) = +⇣. Intuitively,
⌅(y, ⇤) represents the position of the ﬁrst feature literal sat-
isﬁed in the ordered list provided in the head of a preference
rule; however, it can be 1 if y satisﬁes the ﬁrst literal ⇥1 or if
the rule is irrelevant (case a). If the rule is relevant (the body
is satisﬁed) and no head literal is satisﬁed, then it is +⇣.
Thus, given a BCMP framework (M, ≻), an instance x and
two (semifactual/counterfactual) explanations y and z for M
and x, we write y ✏ z iff ⌅(y, ⇤)  ⌅(z, ⇤) for all preference
⇤ in ≻, and write y ⇥ z iff y ✏ z and z ̸✏ y.
Deﬁnition 5 (Semantics). Given a BCMP framework (M, ≻)
and an instance x. We say that y is a best semifactual (resp.,
counterfactual) explanation of x if y is a semifactual (resp.,
counterfactual) of x and there is no other semifactual (resp.,
counterfactual) z of x such that z ⇥ y.
Example 5. Continuing with Example 4, considering the in-
stances y1 = [0, 0, 0] and y2 = [1, 1, 0], we have that y1 and
y2 satisfy ⇤ = f1 ≻ ¬ f2 ← ¬f3 with degree ⌅(y1, ⇤) = 2
and ⌅(y2, ⇤) = 1 since the second and ﬁrst literal in the head
of ⇤ is satisﬁed in y1 and y2, respectively, and the body of ⇤
is satisﬁed by both of them. Then, y2 ⇥ y1, and thus y2 is
the only best semifactual of x.
2
4.1
Computational Complexity
We now investigate the complexity of several problems re-
lated to prioritized reasoning for explanations in order to
compare model classes, even under prioritized reasoning.
We start by introducing the following lemma that will be
used in the proof of the next theorems. Intuitively, the lemma
states that checking whether y ✏ z can be done in PTIME.
2A positive (resp., negative) atom fi (resp., ¬fi) is satisﬁed in
y = (y1, . . . , yn) whenever yi = 1 (resp., yi = 0).
Lemma 1. For any framework (M, ≻) and instances y, z of
M, deciding whether y ⇥ z can be done in PTIME.
The next two problems ask if there exists a best explanation
in the even-if and if-only thinking, respectively.
PROBLEM: BESTMCR (BMCR)
INPUT:
BCMP framework (M, ≻), instance x,
and k ⇤ N.
OUTPUT:
YES, if there exists an instance y with
d(x, y)  k and M(x) ̸= M(y) that is
best w.r.t. ✏; NO, otherwise.
PROBLEM: BESTMCA (BMCA)
INPUT:
BCMP framework (M, ≻), instance x,
and k ⇤ N.
OUTPUT:
YES, if there exists an instance y with
d(x, y) ⌃ k and M(x) = M(y) that is
best w.r.t. ✏; NO, otherwise.
Theorem 3. BMCR and BMCA are i) in PTIME for FB-
DDs and perceptrons, and ii) NP-complete for MLPs.
Thus, preferences do not make the existence problem
harder. Consider now the problems of checking whether a
given instance y is a best counterfactual or semifactual of x.
PROBLEM: CHECKBESTMCR (CBMCR)
INPUT:
BCMP (M, ≻),
instances x,
y with
d(x, y) = k, and M(x) ̸= M(y).
OUTPUT:
YES, if there is no z with M(x) ̸= M(z)
and either d(x, z)  k ⇥ 1, or d(x, z) = k
and z ⇥ y; NO, otherwise
PROBLEM: CHECKBESTMCA (CBMCA)
INPUT:
BCMP (M, ≻),
instances x,
y with
d(x, y) = k, and M(x) = M(y).
OUTPUT:
YES if there is no z with M(x) = M(z)
and either d(x, z) ⌃ k + 1 or d(x, z) = k
and z ⇥ y; NO, otherwise.
Theorem 4. CBMCR and CBMCA are i) in coNP for FB-
DDs and perceptrons, and ii) coNP-complete for MLPs.
We now focus on a simpler yet expressive class of BCMPs
where a ﬁxed linear order is deﬁned over a subset of features.
Deﬁnition 6 (Linear BCMP framework). A linear (binary
classiﬁcation) model with preferences framework is a pair
(M, ≻) where M is a model, and ≻ consists of a linear pref-
erence rule, that is a single preference rule of the form (1)
with empty body.
Example 6. Considering Example 4, the BCMP framework
Λ1 is linear, whereas Λ2 is not.
2
We use L-CBMCA and L-CBMCR to denote CBMCA
and CBMCR where the input BCMP is linear. The follow-
ing theorem states that linear preferences do not increase the
complexity in the case of perceptrons and FBDDs, though
they allow expressing user-speciﬁc desiderata among queries.
Theorem 5. L-CBMCA and L-CBMCR are in PTIME for
perceptrons and FBDDs.
Algorithm 1 Computing a (best) semifactual for perceptrons
Input: Perceptron M = (W, b), instance x ⇤ {0, 1}n, and
linear preference ⇤ = fp1 ≻ · · · ≻ fpl.
Output: A best semifactual y for x w.r.t. M and ⇤.
1: Let s = [f1/s1, . . . , fn/sn] where ∀i ⇤ [1, n],
si =2xiwi ⇥ wi if M(x)=1, wi ⇥ 2xiwi otherwise;
2: Let s⇥ = [fq1/sq1, ..., fqn/sqn] be the sorted version of s
in ascending order of si;
3: k = max({i ⇤ [0, n] | M(ﬂip(x, pos(s⇥, i))=M(x)});
4: if k = 0 return x;
5: if k = n return [1 ⇥ x1, . . . , 1 ⇥ xn];
6: y = ﬂip(x, pos(s⇥, k));
7: ⌅ = min({i ⇤ [1, l] | ypi = 1} ⌘ {l + 1});
8: for i ⇤ [1, ..., ⌅ ⇥ 1] do
9:
if ypi = 1 return y;
10:
Let j = q1 if xpi = ypi, j = qk+1 otherwise;
11:
z = ﬂip(y, {pi, j});
12:
if M(x) = M(z) return z;
13: return y;
4.2
Computation
We now introduce two algorithms for computing a best semi-
factual instance for perceptrons and FBDDs, respectively.
Both algorithms take as input a model M, an instance x, and
a linear preference ⇤, and returns a best semifactual explana-
tion. For the sake of the presentation, w.l.o.g., we assume that
head literals are positive atoms (i.e., ⇥i =fi for all i).
We start with Algorithm 1 for the perceptron model.
Initially, a list s of pairs feature/weight is built, where the
each weight takes into account the contribution of the associ-
ated feature to the result (Line 1). At Line 2 the list is sorted in
ascending order of weights, giving a new list s⇥. Next the fea-
ture values of x are changed to get a semifactual instance y.
To change a maximum number k of feature values of x, guar-
anteeing that the output of the model M(x) does not change,
the order in s⇥ is followed. To this end, the following func-
tions are introduced: i) pos(s⇥, i), computing the set of the
positions in s of the ﬁrst i features in s⇥, and ii) ﬂip(y, B),
with y = [y1, ..., yn], updating every element yi such that
i ⇤ B with the complementary value 1⇥yi. Notice that k = 0
means that x is the only semifactual for x, (returned at Line
4), whereas k = n means that [1⇥x1, . . . , 1⇥xn] is the only
semifactual for x (returned at Line 5). At Line 7 the degree of
satisfaction of ⇤ by y is computed; if no feature in ⇤ is satis-
ﬁed by y the degree is l+1 (standing for +⇣). The next steps
(Lines 8-13) search for a better semifactual instance (if any).
This is carried out by considering the ﬁrst ⌅ ⇥ 1 features in ⇤.
Thus, for each feature fpi in ⇤ (i ⇤ [1, ⌅ ⇥ 1]) we have that:
i) if y satisﬁes fpi, y is a best semifactual and it is returned
at Line 9; ii) otherwise an alternative instance z satisfying
feature fpi is generated and, if it is a semifactual then it is
returned at Line 12. In particular, z is a semifactual instance
only if d(z, x) = d(y, x) and M(z) = M(x). To guaran-
tee that d(z, x) = d(y, x) we either restore feature fq1 in y
by setting it back to yq1 = xq1 whenever xpi = ypi (recall
that the ﬁrst k features of x are ﬂipped at Line 6), or change
the feature fk+1 (i.e., yk+1 ̸= xk+1) whenever xpi ̸= ypi.
Roughly speaking, the so-obtained feature fj minimally con-
tributes to determine the value M(y) and keeps the distance
equal to k. Finally, if there exist no other semifactual z for x
s.t. z ⇥ y, then y is returned at Line 13.
Example 7. Consider the model M = step(x · [⇥2, 2, 0] +
1) of Example 1, the instance x = [0, 1, 1] and the linear
preference f1 ≻ f2. We have that s = [f1/2, f2/2, f3/0],
s⇥ = [f3/0, f2/2, f1/2] and k = 2. Thus y = [0, 0, 0] with
⌅ = 3. As y2 ̸= 1 and x2 ̸= y2, Algorithm 1 returns z =
ﬂip(y, [2, j]) = [1, 1, 0] with j = q3 = 1 and ⌅ = 1.
2
We now present Algorithm 2 for the FBDD model.
It starts by creating a copy M⇥ of M where edge labels, as-
signed by function λE′, represent boolean values correspond-
ing to whether or not the edge is in line with x. Formally,
λE′(u, v) = 1 if xλV (u) = λE(u, v); 0 otherwise. Intuitively,
let ⇧ be a path in M from root t to leaf nodes representing
M(x) (i.e., to ⌅ if M(x) = 1, ⇧ otherwise), and let w be
the weight of ⇧ computed as the sum of (boolean) weights on
the edges of ⇧. By following the path ⇧, it is possible to build
a semifactual for x of distance n ⇥ w. To this end, at Line 2
a graph N isomorphic to M⇥ w.r.t. V , is built with function
subgraph by keeping all the paths in M⇥ ending in M(x)
and having minimum weight. All such paths are stored in ⇥
at Line 3. Then, the algorithm checks if it is possible to build
a semifactual y for x satisfying fp1, otherwise fp2, and so on.
Particularly, assuming to be at step fpi for some fpi in ⇤, if
there exists a path ⇧ ⇤ ⇥ and the feature fpi can be set to 1 in
y (that is the condition of Line 5) then a best semifactual y of
x is obtained from x by ﬂipping every features i of x not ap-
pearing in ⇧ (i.e., λV (u) ̸= i for any node u in ⇧) or differing
in the assignment given by ⇧ (i.e., there is no edge (u, v) ⇤ ⇧
s.t. λV (u) = i and λE′(u, v) = 0). More formally, the func-
tion build(x, ⇧) returns the instance y = ﬂip(x, {i ⇤ [1, n] |
∄(u, v) ⇤ ⇧ such that λV (u)=i and λE′(u, v)=1}). Finally, if
the algorithm does not return a semifactual at Line 6, then at
Line 8 it returns a semifactual y of x that satisﬁes none of the
fpis, obtained from x through function build(x, ⇧) where ⇧
is a path taken non-deterministically from ⇥.
Example 8. Consider the FBDD M = (V, E, λV , λE) in
Figure 2(left) for the mortgage scenario of Example 1. Let
x = [0, 1, 1] and ⇤ = f2 ≻ f1. For each edge (u, v) ⇤
E, Figure 2(center) shows the value λE′(u, v) (computed at
Line 1), while Figure 2(right) shows the graph N obtained
by removing all the paths ⇧ of M⇥ whose sum of weights is
greater than w = 1. This means that semifactuals y of x are
at distance d(x, y) = n ⇥ w = 2. As there exists in N the
path ⇧ : (u, u⇥), (u⇥, u⇥⇥) where λV (u) = 3, λV (u⇥) = 2,
λV (u⇥⇥) = ⌅, and λE′(u⇥, u⇥⇥) = 1 then it is possible to get
a semifactual y from x with x2 = 1. In fact, Algorithm 2
returns y=build(x, ⇧)=ﬂip(x, {1, 3})=[1, 1, 0] at Line 6.
2
As stated next, the two algorithms are sound, complete and
return best semifactuals in PTIME.
Theorem 6. Algorithms 1 and 2 are sound, complete, and
run in polynomial-time.
Clearly, the proposed algorithms also work when no pref-
erences are available, that is when ≻= ✓, returning a generic
Algorithm 2 Computing a (best) semifactual for FBDDs
Input: FBDD M = (V, E, λV , λE) with root t, instance x ⇤
{0, 1}n, and linear preference ⇤ = fp1 ≻ · · · ≻ fpl.
Output: A best semifactual y for x w.r.t. M and ⇤.
1: Let M⇥=(V ⇥=V, E⇥=E, λV ′=λV , λE′) be a copy of M,
where λE′(u, v)=1 if(xλV (u)=λE(u, v)), 0 otherwise;
2: Let N = subgraph(M⇥, M(x));
3: Let ⇥ be the set of paths in N from t to leaf nodes;
4: for fpi ⇤ {fp1, . . . , fpl} do
5:
if ⌦⇧ ⇤ ⇥ with y = build(x, ⇧) and ypi = 1
6:
return y;
7: Let ⇧ be a path of ⇥ taken non-deterministically;
8: return y = build(x, ⇧);
semifactual at maximum distance. Providing a PTIME algo-
rithm returning a best semifactual for MLPs is unfeasible, as
backed by our complexity analysis. However, as an heuristic,
we could adapt Algorithm 1 so that the scores sis encode fea-
ture importance, similarly to what is done in [Ramon et al.,
2020]—we plan to explore this direction in future work.
Observed that, although the number of (best) semifactu-
als is potentially exponential w.r.t. the number of features (it
is
⇤n
k
⌅
where k represents the maximum number of features
changed in x to obtain semifactuals), Algorithms 1 and 2 can
be exploited to obtain a ﬁnite representation of all semifac-
tuals. For instance, all semifactuals of x in Algorithm 2 are
those obtained from x by considering all paths in ⇧ ⇤ ⇥, that
is the set {build(x, ⇧) such that ⇧ ⇤ ⇥}.
Finally, it is important to note that both Algorithms 1 and
2 can be easily adapted to deal with (best) counterfactual ex-
planations, as shown in the Supplementary Material.
5
Related Work
Looking for transparent and interpretable models has led to
the exploration of several explanation paradigms in eXplain-
able AI (XAI). Factual explanations [Ciravegna et al., 2020;
Guidotti et al., 2018; Bodria et al., 2023; Wang et al., 2021;
Ciravegna et al., 2023] elucidate the inner workings of AI
models by delineating why a certain prediction was made
based on the input data. Counterfactual explanations [Der-
vakos et al., 2023; Romashov et al., 2022; Albini et al., 2020;
Wu et al., 2019; Guidotti, 2022], delve into hypothetical sce-
narios, revealing alternative input conﬁgurations that could
have resulted in a different prediction. These explanations
offer insights into the model’s decision boundaries and aid in
understanding its behavior under varied circumstances. Semi-
factual explanations [Dandl et al., 2023; Aryal and Keane,
2023; Kenny and Keane, 2021] bridge the gap between fac-
tual and counterfactual realms by presenting feasible alter-
ations to the input data that do not change a decision out-
come. This trichotomy of explanation types contributes sig-
niﬁcantly to the holistic comprehension and trustworthiness
of AI systems, catering to various stakeholders’ needs for
transparency and interpretability.
Most existing works on
XAI focus on proposing novel methods for generating expla-
3
⊤
2
⇥
0
0
0
0
0
1
1
1
1
1
2
1
1
t
⊤
t
3
⊤
2
⇥
0
0
1
1
0
1
0
1
0
1
2
1
1
t
3
2
1
Figure 2: (Left) FBDD model M = (V, E, λV , λE) of Exam-
ple 8 with root t and λV (t) = 3. (Center) FBDD model M′ =
(V ′, E′, λV ′, λE′) computed at Line 1 of Algorithm 2.
(Right)
Graph N obtained at Line 2 of Algorithm 2. Squared nodes rep-
resent leaf nodes (⌅ for M(·) = 1, and ⇧ for M(·) = 0).
nations, with few addressing the computational complexity
of related problems [Barcel´o et al., 2020; Arenas et al., 2022;
Arenas et al., 2021; Eiben et al., 2023; El Harzli et al., 2023;
Marzari et al., 2023; Ordyniak et al., 2023]. However, none
of these works speciﬁcally focuses on semifactuals.
As discussed earlier, several approaches have been pro-
posed to handle preferences in AI. In the context of logic
programming there has been extensive research on prefer-
ences among rules [Brewka, 1989; Brewka and Eiter, 1999;
Delgrande et al., 2003; Eiter et al., 2003; Schaub and Wang,
2001] and among atoms or their combinations
[Sakama
and Inoue, 2000; Brewka et al., 2003; Greco et al., 2007;
Brewka et al., 2015].
Related to this, conditional prefer-
ence networks [Boutilier et al., 2004; Rossi et al., 2004]
offer an alternative formalism that allows to express sets of
conditional ceteris paribus (i.e. all else being equal) prefer-
ence statements [Allen et al., 2017; Goldsmith et al., 2008;
Lukasiewicz and Malizia, 2019].
6
Conclusions and Future Works
In this paper, after exploring local post-hoc interpretability
queries related to semifactuals and their computational com-
plexity among three classes of models (FBDDs, perceptrons,
and MLPs), we introduced a framework that enables users
to personalize semifactual and counterfactual explanations
based on preferences. Then, we investigated the complexity
of the proposed framework and presented PTIME algorithms.
Our
approach
to
handle
preferences
over
semifac-
tual/counterfactual explanations is inspired by the Answer Set
Optimization approach [Brewka et al., 2003]. In particular,
conditional preferences among features are deﬁned by means
of preference rules, the satisfaction of each rule is evaluated
quantitatively, whereas the overall preference order is deﬁned
in a qualitative way. The main advantages of such approach
consist in the simplicity and compactness of representation,
and combination of quantitative and qualitative evaluations.
As future work, we plan to explore additional interpretabil-
ity queries, particularly focusing on counting problems like
quantifying the number of semifactuals/counterfactuals for
speciﬁc input instances, aiming to enhance the evaluation of
interpretability across the three classes of models. Further-
more, we aim to extend our research by investigating more
inclusive model formats, speciﬁcally those accommodating
real-number inputs and non-binary discrete features, thereby
expanding the breadth of our analysis.
References
[Albini et al., 2020] Emanuele Albini, Antonio Rago, Pietro
Baroni, and Francesca Toni. Relation-based counterfactual
explanations for bayesian network classiﬁers. In Proceed-
ings of International Joint Conference on Artiﬁcial Intelli-
gence (IJCAI), pages 451–457, 2020.
[Allen et al., 2017] Thomas E. Allen, Judy Goldsmith, Hay-
den Elizabeth Justice, Nicholas Mattei, and Kayla Raines.
Uniform random generation and dominance testing for cp-
nets. Journal of Artiﬁcial Intelligence Research, 59:771–
813, 2017.
[Arenas et al., 2021] Marcelo Arenas, Daniel Baez, Pablo
Barcel´o, Jorge P´erez, and Bernardo Subercaseaux. Foun-
dations of symbolic languages for model interpretability.
Proceedings of Advances in Neural Information Process-
ing Systems, 34:11690–11701, 2021.
[Arenas et al., 2022] Marcelo
Arenas,
Pablo
Barcel´o,
Miguel Romero Orth,
and Bernardo Subercaseaux.
On computing probabilistic explanations for decision
trees.
Proceedings of Advances in Neural Information
Processing Systems, 35:28695–28707, 2022.
[Aryal and Keane, 2023] Saugat Aryal and Mark T. Keane.
Even if explanations: Prior work, desiderata & bench-
marks for semi-factual xai.
In Proceedings of Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI),
pages 6526–6535, 2023.
[Bakker et al., 2022] Michiel Bakker,
Martin Chadwick,
Hannah Sheahan,
Michael Tessler,
Lucy Campbell-
Gillingham, Jan Balaguer, Nat McAleese, Amelia Glaese,
John Aslanides, Matt Botvinick, et al. Fine-tuning lan-
guage models to ﬁnd agreement among humans with di-
verse preferences. Proceedings of Advances in Neural In-
formation Processing Systems, 35:38176–38189, 2022.
[Barcel´o et al., 2020] Pablo Barcel´o, Mika¨el Monet, Jorge
P´erez, and Bernardo Subercaseaux. Model interpretabil-
ity through the lens of computational complexity. In Pro-
ceedings of Advances in Neural Information Processing
Systems, 2020.
[Bodria et al., 2023] Francesco Bodria,
Fosca Giannotti,
Riccardo Guidotti, Francesca Naretto, Dino Pedreschi, and
Salvatore Rinzivillo. Benchmarking and survey of expla-
nation methods for black box models. Data Mining and
Knowledge Discovery, pages 1–60, 2023.
[Boutilier et al., 2004] Craig Boutilier, Ronen I. Brafman,
Carmel Domshlak, Holger H. Hoos, and David Poole. Cp-
nets: A tool for representing and reasoning with condi-
tional ceteris paribus preference statements.
Journal of
Artiﬁcial Intelligence Research, 21:135–191, 2004.
[Brafman and Domshlak, 2009] Ronen
I.
Brafman
and
Carmel Domshlak. Preference handling - an introductory
tutorial. AI Mag., 30(1):58–86, 2009.
[Brewka and Eiter, 1999] Gerhard
Brewka
and
Thomas
Eiter. Preferred answer sets for extended logic programs.
Artiﬁcial Intelligence, 109(1-2):297–356, 1999.
[Brewka et al., 2003] Gerhard Brewka, Ilkka Niemel¨a, and
Miroslaw Truszczynski. Answer set optimization. In Pro-
ceedings of International Joint Conference on Artiﬁcial In-
telligence (IJCAI), pages 867–872, 2003.
[Brewka et al., 2015] Gerhard Brewka, James P. Delgrande,
Javier Romero, and Torsten Schaub. asprin: Customizing
answer set preferences without a headache. In Proceedings
of AAAI Conference on Artiﬁcial Intelligence, pages 1467–
1474, 2015.
[Brewka, 1989] Gerhard Brewka. Preferred subtheories: An
extended logical framework for default reasoning. In Pro-
ceedings of International Joint Conference on Artiﬁcial In-
telligence (IJCAI), pages 1043–1048, 1989.
[Ciravegna et al., 2020] Gabriele Ciravegna, Francesco Gi-
annini, Marco Gori, Marco Maggini, and Stefano Melacci.
Human-driven fol explanations of deep learning. In Pro-
ceedings of International Joint Conference on Artiﬁcial In-
telligence (IJCAI), pages 2234–2240, 2020.
[Ciravegna et al., 2023] Gabriele Ciravegna, Pietro Barbi-
ero, Francesco Giannini, Marco Gori, Pietro Li´o, Marco
Maggini, and Stefano Melacci. Logic explained networks.
Artiﬁcial Intelligence, 314:103822, 2023.
[Dandl et al., 2023] Susanne Dandl, Giuseppe Casalicchio,
Bernd Bischl, and Ludwig Bothmann.
Interpretable re-
gional descriptors: Hyperbox-based local explanations. In
Proceedings of Machine Learning and Knowledge Dis-
covery in Databases, volume 14171, pages 479–495.
Springer, 2023.
[Delgrande et al., 2003] James
P.
Delgrande,
Torsten
Schaub, and Hans Tompits. A framework for compiling
preferences in logic programs.
Theory and Practice of
Logic Programming, 3(2):129–187, 2003.
[Dervakos et al., 2023] Edmund
Dervakos,
Konstantinos
Thomas, Giorgos Filandrianos, and Giorgos Stamou.
Choose your data wisely:
A framework for semantic
counterfactuals. arXiv preprint arXiv:2305.17667, 2023.
[Eiben et al., 2023] Eduard Eiben, Sebastian Ordyniak, Gia-
como Paesani, and Stefan Szeider. Learning small decision
trees with large domain. In Proceedings of International
Joint Conference on Artiﬁcial Intelligence (IJCAI), pages
3184–3192, 2023.
[Eiter et al., 2003] Thomas Eiter, Wolfgang Faber, Nicola
Leone, and Gerald Pfeifer. Computing preferred answer
sets by meta-interpretation in answer set programming.
Theory and Practice of Logic Programming, 3(4-5):463–
498, 2003.
[El Harzli et al., 2023] Ouns El Harzli, Bernardo Cuenca
Grau, and Ian Horrocks. Cardinality-minimal explanations
for monotonic neural networks. In Proceedings of Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI),
pages 3677–3685, 2023.
[Goldsmith et al., 2008] Judy
Goldsmith,
J´erˆome
Lang,
Miroslaw Truszczynski, and Nic Wilson.
The compu-
tational complexity of dominance and consistency in cp-
nets. Journal of Artiﬁcial Intelligence Research, 33:403–
432, 2008.
[Greco et al., 2007] Sergio Greco, Irina Trubitsyna, and Es-
ter Zumpano. On the semantics of logic programs with
preferences. Journal of Artiﬁcial Intelligence Research,
30:501–523, 2007.
[Guidotti et al., 2018] Riccardo Guidotti, Anna Monreale,
Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and
Dino Pedreschi. A survey of methods for explaining black
box models. ACM computing surveys (CSUR), 51(5):1–42,
2018.
[Guidotti, 2022] Riccardo Guidotti. Counterfactual explana-
tions and how to ﬁnd them: literature review and bench-
marking. Data Mining and Knowledge Discovery, pages
1–55, 2022.
[Kahneman and Tversky, 1981] Daniel
Kahneman
and
Amos Tversky.
The simulation heuristic.
National
Technical Information Service, 1981.
[Kapoor et al., 2012] Ashish Kapoor, Bongshin Lee, Desney
Tan, and Eric Horvitz. Performance and preferences: In-
teractive reﬁnement of machine learning procedures. In
Proceedings of AAAI Conference on Artiﬁcial Intelligence,
pages 1578–1584, 2012.
[Kenny and Huang, 2023] Eoin M. Kenny and Weipeng
Huang. The utility of “even if” semi-factual explanation
to optimise positive outcomes. In Thirty-seventh Confer-
ence on Neural Information Processing Systems, 2023.
[Kenny and Keane, 2021] Eoin M Kenny and Mark T Keane.
On generating plausible counterfactual and semi-factual
explanations for deep learning. In Proceedings of AAAI
Conference on Artiﬁcial Intelligence, pages 11575–11585,
2021.
[Lukasiewicz and Malizia, 2019] Thomas Lukasiewicz and
Enrico Malizia. Complexity results for preference aggre-
gation over (m)cp-nets: Pareto and majority voting. Artiﬁ-
cial Intelligence, 272:101–142, 2019.
[Marzari et al., 2023] Luca Marzari, Davide Corsi, Ferdi-
nando Cicalese, and Alessandro Farinelli.
The #dnn-
veriﬁcation problem: Counting unsafe inputs for deep neu-
ral networks. In Proceedings of International Joint Con-
ference on Artiﬁcial Intelligence (IJCAI), pages 217–224,
2023.
[McCloy and Byrne, 2002] Rachel McCloy and Ruth MJ
Byrne. Semifactual “even if” thinking. Thinking & rea-
soning, 8:41–67, 2002.
[Ordyniak et al., 2023] S Ordyniak, G Paesani, and S Szei-
der. The parameterized complexity of ﬁnding concise lo-
cal explanations.
In Proceedings of International Joint
Conference on Artiﬁcial Intelligence (IJCAI), pages 3312–
3320, 2023.
[Papadimitriou, 1994] Christos H. Papadimitriou. Computa-
tional complexity. Addison-Wesley, 1994.
[Ramon et al., 2020] Yanou Ramon, David Martens, Fos-
ter Provost, and Theodoros Evgeniou. A comparison of
instance-level counterfactual explanation algorithms for
behavioral and textual data: Sedc, lime-c and shap-c. Ad-
vances in Data Analysis and Classiﬁcation, 14:801–819,
2020.
[Romashov et al., 2022] Piotr Romashov, Martin Gjoreski,
Kacper
Sokol,
Maria
Vanina
Martinez,
and
Marc
Langheinrich. Baycon: Model-agnostic bayesian counter-
factual generator. In Proceedings of International Joint
Conference on Artiﬁcial Intelligence (IJCAI), pages 23–
29, 2022.
[Rossi et al., 2004] Francesca Rossi, Kristen Brent Venable,
and Toby Walsh. mcp nets: Representing and reasoning
with preferences of multiple agents. In Proceedings of the
Nineteenth National Conference on Artiﬁcial Intelligence,
Sixteenth Conference on Innovative Applications of Artiﬁ-
cial Intelligence, pages 729–734, 2004.
[Rossi et al., 2011] Francesca Rossi, Kristen Brent Venable,
and Toby Walsh. A Short Introduction to Preferences: Be-
tween Artiﬁcial Intelligence and Social Choice. Synthesis
Lectures on Artiﬁcial Intelligence and Machine Learning.
Morgan & Claypool Publishers, 2011.
[Sakama and Inoue, 2000] Chiaki Sakama and Katsumi In-
oue. Prioritized logic programming and its application to
commonsense reasoning. Artiﬁcial Intelligence, 123(1-2),
2000.
[Santhanam et al., 2016] Ganesh Ram Santhanam, Samik
Basu, and Vasant G. Honavar. Representing and Reason-
ing with Qualitative Preferences: Tools and Applications.
Synthesis Lectures on Artiﬁcial Intelligence and Machine
Learning. Morgan & Claypool Publishers, 2016.
[Schaub and Wang, 2001] Torsten Schaub and Kewen Wang.
A comparative study of logic programs with preference.
In Proceedings of International Joint Conference on Arti-
ﬁcial Intelligence (IJCAI), pages 597–602, 2001.
[Wang et al., 2021] Eric
Wang,
Pasha
Khosravi,
and
Guy Van den Broeck.
Probabilistic sufﬁcient explana-
tions. In Proceedings of International Joint Conference
on Artiﬁcial Intelligence (IJCAI), pages 3082–3088, 2021.
[Wegener, 2004] Ingo Wegener.
Bdds—design, analysis,
complexity, and applications. Discrete Applied Mathemat-
ics, 138(1):229–251, 2004.
[Wu et al., 2019] Yongkai Wu, Lu Zhang, and Xintao Wu.
Counterfactual fairness: Unidentiﬁcation, bound and al-
gorithm. In Proceedings of International Joint Conference
on Artiﬁcial Intelligence (IJCAI), pages 1438–1444, 2019.
[Zhu et al., 2022] Yongchun Zhu, Zhenwei Tang, Yudan Liu,
Fuzhen Zhuang, Ruobing Xie, Xu Zhang, Leyu Lin, and
Qing He.
Personalized transfer of user preferences for
cross-domain recommendation. In Proceedings of the Fif-
teenth ACM International Conference on Web Search and
Data Mining, pages 1507–1515, 2022.
"
"Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a visual GUI agent – SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key challenge in developing visual GUI agents: GUI grounding – the capacity to accurately locate screen elements based on instructions. To tackle this challenge, we propose to enhance SeeClick with GUI grounding pre-training and devise a method to automate the curation of GUI grounding data. Along with the efforts above, we have also created ScreenSpot, the first realistic GUI grounding dataset that encompasses mobile, desktop, and web environments. After pre-training, SeeClick demonstrates significant improvement in ScreenSpot over various baselines. Moreover, comprehensive evaluations on three widely used benchmarks consistently support our finding that advancements in GUI grounding directly correlate with enhanced performance in downstream GUI agent tasks.nan","Developing autonomous agents to assist humans on computing devices has been a persistent goal for artificial intelligence (Shi et al., 2017; Li et al., 2020a; Furuta et al., 2023; Zhou et al., 2023). These Graphical User Interface (GUI) agent systems aim to mimic human interactions in solving complex tasks, thereby enhancing efficiency and reducing manual effort, with examples like Siri and Copilot. Recent advances in Large Language Models (LLMs) such as GPT-4 (OpenAI, 2023) and LLaMA (Touvron et al., 2023) have significantly propelled the evolution of GUI agents (Gur et al., 2023a; Zhou et al., 2023). These agents interact with the environment through extracted structured texts, e.g., HTML from web pages, then elicit LLM for planning, reasoning, and action gereration (Kim et al., 2023; Zheng et al., 2023).nan","nanHowever, GUI agents depend on structured text face three inherent limitations: (1) Structured text is not always accessible, especially for iOS or desktop applications where acquiring such information is challenging (Shaw et al., 2023); (2) The verbose nature of structured text serves as an inefficient context for LLMs, while also omitting crucial information such as layout, images, and icons (Deng et al., 2023); (3) The variety of structured text - including HTML, DOM, and Android VH - necessitates the curation of task-specific observation and action spaces (Kim et al., 2023; Zhou et al., 2023). These entrenched deficiencies in text-based approaches call for an alternative solution.nan","In this paper, we propose a visual GUI agent built on Large Vision-Language Models (LVLMs) - SeeClick. Inspired by human interaction with GUIs, SeeClick performs low-level actions like clicking or typing directly by observing interface screenshots. This methodology bypasses the need for interacting with cumbersome structured text, empowering SeeClick as a universal visual agent suitable for various GUI platforms. Building such visual agents involves a foundational challenge: GUI grounding - the capacity to accurately locate screen elements based on instructions, which is absent in current LVLMs. To tackle this challenge, SeeClick enhances LVLM with a GUI grounding pre-training strategy. We devise a method to automate the curation of web grounding data and adapt public mobile UI datasets to obtain mobile grounding data.nan","SeeClick employs the above-curated dataset for continual pre-training of the LVLM, enabling it to accurately locate elements such as text, widgets, and icons in various GUI environments. Given GUI grounding is a fundamental yet underexplored capacity for GUI agents, we created ScreenSpot, the first realistic GUI grounding evaluation benchmark across various GUI platforms. ScreenSpot contains over 600 screenshots and 1200 instructions from iOS, Android, macOS, Windows, and web environments, and specifically includes both text-based elements and a variety of widgets and icons. Evaluation results confirm SeeClick’s superiority over current LVLMs, validating the effectiveness of GUI grounding pre-training.nan","Finally, we adapted SeeClick to three downstream agent tasks: MiniWob (Shi et al., 2017), AITW (Rawles et al., 2023), and Mind2Web (Deng et al., 2023). As a purely visual-based agent, SeeClick achieves impressive performance across three tasks. Notably, SeeClick outperforms the visual baseline Pix2Act with only 0.3% training data on MiniWob. Moreover, experimental results on three tasks consistently support our finding that improvement in GUI grounding directly correlates with enhanced agent task performance.nan",SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents,"Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang, Zhiyong Wu","SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents
Kanzhi Cheng♢♡∗
Qiushi Sun♡
Yougang Chu♢
Fangzhi Xu♡
Yantao Li♢
Jianbing Zhang♢
Zhiyong Wu♡
♢Department of Computer Science and Technology, Nanjing University
♡Shanghai AI Laboratory
{chengkz,chuyg,li_yantao}@smail.nju.edu.cn
qiushisun@u.nus.edu
fangzhixu98@gmail.com
zjb@nju.edu.cn
wuzhiyong@pjlab.org.cn
Abstract
Graphical User Interface (GUI) agents are de-
signed to automate complex tasks on digital de-
vices, such as smartphones and desktops. Most
existing GUI agents interact with the environ-
ment through extracted structured data, which
can be notably lengthy (e.g., HTML) and oc-
casionally inaccessible (e.g., on desktops). To
alleviate this issue, we propose a visual GUI
agent – SeeClick, which only relies on screen-
shots for task automation. In our preliminary
study, we have discovered a key challenge in
developing visual GUI agents: GUI grounding
– the capacity to accurately locate screen el-
ements based on instructions. To tackle this
challenge, we propose to enhance SeeClick
with GUI grounding pre-training and devise
a method to automate the curation of GUI
grounding data. Along with the efforts above,
we have also created ScreenSpot, the first real-
istic GUI grounding dataset that encompasses
mobile, desktop, and web environments. After
pre-training, SeeClick demonstrates significant
improvement in ScreenSpot over various base-
lines. Moreover, comprehensive evaluations
on three widely used benchmarks consistently
support our finding that advancements in GUI
grounding directly correlate with enhanced per-
formance in downstream GUI agent tasks. 1
1
Introduction
Developing autonomous agents to assist humans on
computing devices has been a persistent goal for ar-
tificial intelligence (Shi et al., 2017; Li et al., 2020a;
Furuta et al., 2023; Zhou et al., 2023). These Graph-
ical User Interface (GUI) agent systems aim to
mimic human interactions in solving complex tasks,
thereby enhancing efficiency and reducing manual
effort, with examples like Siri and Copilot. Re-
cent advances in Large Language Models (LLMs)
such as GPT-4 (OpenAI, 2023) and LLaMA (Tou-
vron et al., 2023) have significantly propelled the
∗Work done during internship at Shanghai AI Laboratory.
1The model, data and code are available at https://
github.com/njucckevin/SeeClick.
evolution of GUI agents (Gur et al., 2023a; Zhou
et al., 2023). These agents interact with the en-
vironment through extracted structured texts, e.g.,
HTML from web pages, then elicit LLM for plan-
ning, reasoning, and action gereration (Kim et al.,
2023; Zheng et al., 2023).
However, GUI agents depend on structured text
face three inherent limitations: (1) Structured text
is not always accessible, especially for iOS or desk-
top applications where acquiring such information
is challenging (Shaw et al., 2023); (2) The verbose
nature of structured text serves as an inefficient
context for LLMs, while also omitting crucial in-
formation such as layout, images, and icons (Deng
et al., 2023); (3) The variety of structured text -
including HTML, DOM, and Android VH - ne-
cessitates the curation of task-specific observation
and action spaces (Kim et al., 2023; Zhou et al.,
2023). These entrenched deficiencies in text-based
approaches call for an alternative solution.
In this paper, we propose a visual GUI agent
built on Large Vision-Language Models (LVLMs)
- SeeClick. Inspired by human interaction with
GUIs, SeeClick performs low-level actions like
clicking or typing directly by observing interface
screenshots. This methodology bypasses the need
for interacting with cumbersome structured text,
empowering SeeClick as a universal visual agent
suitable for various GUI platforms. Building such
visual agents involves a foundational challenge:
GUI grounding - the capacity to accurately locate
screen elements based on instructions, which is ab-
sent in current LVLMs. To tackle this challenge,
SeeClick enhances LVLM with a GUI grounding
pre-training strategy. We devise a method to auto-
mate the curation of web grounding data and adapt
public mobile UI datasets to obtain mobile ground-
ing data.
SeeClick employs the above-curated
dataset for continual pre-training of the LVLM, en-
abling it to accurately locate elements such as text,
widgets, and icons in various GUI environments.
arXiv:2401.10935v1  [cs.HC]  17 Jan 2024
Given GUI grounding is a fundamental yet un-
derexplored capacity for GUI agents, we created
ScreenSpot, the first realistic GUI grounding eval-
uation benchmark across various GUI platforms.
ScreenSpot contains over 600 screenshots and 1200
instructions from iOS, Android, macOS, Windows,
and web environments, and specifically includes
both text-based elements and a variety of widgets
and icons. Evaluation results confirm SeeClick’s
superiority over current LVLMs, validating the ef-
fectiveness of GUI grounding pre-training.
Finally, we adapted SeeClick to three down-
stream agent tasks: MiniWob (Shi et al., 2017),
AITW (Rawles et al., 2023), and Mind2Web (Deng
et al., 2023).
As a purely visual-based agent,
SeeClick achieves impressive performance across
three tasks. Notably, SeeClick outperforms the vi-
sual baseline Pix2Act with only 0.3% training data
on MiniWob. Moreover, experimental results on
three tasks consistently support our finding that
improvement in GUI grounding directly correlates
with enhanced agent task performance.
This paper makes the following contributions:
• We develop a unified visual GUI agent
SeeClick, which directly performs clicking
and typing actions based on interface screen-
shots across diverse GUI platforms.
• We prospectively explore GUI grounding for
visual GUI agents, and enhanced SeeClick
with our proposed GUI grounding pre-training
strategy.
• We create a realistic GUI grounding bench-
mark ScreenSpot, encompassing more than
1200 instructions from various GUI platforms.
• Experimental results on ScreenSpot and three
agent tasks demonstrate that enhancing agents’
grounding capacity is key to improving per-
formance in downstream agent tasks.
2
Related work
2.1
Autonomous GUI Navigation
Autonomous GUI navigation requires intelligent
agents to tackle complex tasks in various GUIs.
Early research investigated training agents by
reinforcement learning (Liu et al., 2018; Gur
et al., 2018) on the classic web environment Mini-
Wob (Shi et al., 2017). With the recent advance-
ment of LLMs (OpenAI, 2023; Touvron et al.,
2023; Xu et al., 2023; Sun et al., 2023; Kim et al.,
2023, inter alia). LLM-centric GUI agents have
become the dominant paradigm. A line of works
focused on prompting closed-source LLMs like
ChatGPT and GPT-4, leveraging their powerful
reasoning and planning abilities for web tasks, e.g.,
via in-context learning (Zheng et al., 2023) and
self-refine (Kim et al., 2023). Other research ex-
plored training LLMs as specialized GUI agents
(Gur et al., 2023b; Furuta et al., 2023). Deng et al.
(2023) devised a two-stage method for identifying
target elements within intricate HTML. Recently,
Gur et al. (2023a) designed a method for interacting
with websites via synthesizing programs.
However, constrained by the inherent limitation
of LLMs to only process text and the complexity of
GUIs, converting interfaces into structured text is
cumbersome and challenging to standardize across
various GUI environments. To address this, several
recent efforts have attempted vision-based GUI
navigation using GPT-4V (Yan et al., 2023; Gao
et al., 2023; Yang et al., 2023). Recent studies
explored vision-based UI Agents for web (Shaw
et al., 2023) or mobile (Zhan and Zhang, 2023).
In this paper, we construct a universal visual GUI
agent SeeClick by customizing LVLMs, capable of
operating across various GUI platforms.
2.2
Large Vision-Language Models
Recently, researchers have invested tremendous
effort in constructing LVLMs capable of jointly
processing image and text (Liu et al., 2023a; Zhu
et al., 2023; Ye et al., 2023b; Li et al., 2023; Zhang
et al., 2023a). LVLMs integrate visual encoding
modules, like ViT (Dosovitskiy et al., 2020), with
LLMs such as LLaMA (Touvron et al., 2023), in-
heriting LLMs’ language and reasoning abilities to
perform diverse downstream vision-language tasks.
A series of studies focused on the grounding ca-
pabilities of LVLMs (Wang et al., 2023; Bai et al.,
2023; Chen et al., 2023a), such as providing bound-
ing boxes for objects while generating responses
(Chen et al., 2023b; Peng et al., 2023). Nonethe-
less, these efforts primarily addressed natural im-
ages and did not explore GUI contexts. This paper
emphasizes that GUI grounding is pivotal for con-
structing visual GUI agents and concentrates on
exploring LVLMs’ potential in GUI environments.
2.3
Mobile UI Understanding
As a vital aspect of daily life, mobile UI under-
standing has garnered widespread attention from
Vision
Encoder
(ViT)
Large-scale Vision-Language Model (LVLM)
Vision-Language 
Adapter
Instruction:
“View the new album of Jony J”
Next action: click (0.49, 0.40)
Mobile UI Related
Web UI Related
General VL Data
VQA
Visual Reasoning
Widget Captioning
UI Summarization
Mobile UI Grounding
Web OCR
Web UI Grounding
Instruction: open the
low power mode
Source: Mobile (iOS)
Type: Icon/Widget
Instruction: See more 
options for Dark Mode
Source: Mobile (Android)
Type: Text
Instruction: Change font 
size to 20
Source: PC (macOS)
Type: Text
Instruction: Likes on this
issue
Source: Web (Development)
Type: Icon/Widget
Instruction: Create a new
merge request
Source: Web (Development)
Type: Text
Instruction: Switch to 
OneDrive path
Source: PC (Windows)
Type: Text
GUI Grounding Benchmark: ScreenSpot
(a) Overview of SeeClick‘s framework and GUI grounding pre-training.
(b) Examples of the proposed GUI grounding benchmark ScreenSpot.
(c) SeeClick as a visual GUI agent in downstream task.
Instruction: Find a list of shorthaired dogs available for adoption with 100 miles of zip code 
94587 that are good with kids and cats, and have been on Petfinder for over 30 days.
Figure 1: Overview of our universal visual GUI agent SeeClick. (a) depicts the framework of SeeClick and GUI
grounding pre-training. (b) provides examples of ScreenSpot across various GUIs and types of instructions. (c)
displays the real-world application of SeeClick on downstream web agent task.
researchers. One category of work explored mul-
timodal tasks within UI contexts (Li et al., 2021;
Bai et al., 2021; He et al., 2021), such as widget
captioning (Li et al., 2020b), screen summarization
(Wang et al., 2021), and UI object detection (Chen
et al., 2020). Several studies explored grounding
elements in mobile UI based on instructions (Li
et al., 2020a; Burns et al., 2022; Li et al., 2021; Li
and Li, 2022), serving as a foundation for mobile
UI automation. Most mentioned studies rely on
Android’s View Hierarchy to represent interfaces,
while (Li and Li, 2022) use Regions of Interest and
(Zhang et al., 2023b) use screenshots. Moreover,
most efforts employed RICO (Deka et al., 2017)
for research, an Android apps dataset collected in
2017. This work introduces an up-to-date, real-
istic grounding benchmark encompassing various
GUI platforms, and underscores grounding as a
foundation for visual GUI agents.
3
Approach
In our preliminary study, we have discovered a key
challenge in developing visual GUI agents: GUI
grounding, the capacity to locate screen elements
based on instructions. Recent advancements in
LVLMs have claimed visual grounding capability
on natural images (Chen et al., 2023b; Peng et al.,
2023; Wang et al., 2023), which is able to point
out objects based on natural language description.
However, GUI screenshots significantly differ from
natural images, typically containing dense text and
numerous icons and widgets. These differences
impair existing LVLMs’ grounding performance in
GUI contexts (Bai et al., 2023; Chen et al., 2023a),
limiting their potential as visual GUI agents.
This paper seeks to endow LVLMs with GUI
grounding proficiency, aiming to construct a univer-
sal visual GUI agent capable of executing instruc-
tions that only rely on screenshots. The overview of
the proposed LVLM SeeClick is presented in Fig-
ure 1(a). Next, we introduce the birth of SeeClick,
including the formalization of GUI grounding task,
the construction of continual pre-training data, and
training details.
3.1
GUI grounding for LVLMs
As GUI grounding is the core capability of
SeeClick, we first elucidate how to train LVLM for
language generation to perform grounding tasks.
Given an interface screenshot s and a collection of
its elements {(xi, yi)|i}, where xi denotes the tex-
tual description of the i-th element and yi indicates
the element’s location (represented as a bounding
box or point). As depicted in Figure 1(a), LVLM
predicts the location of the element y based on the
interface screenshot s and its textual description x,
i.e. calculating p(y|s, x).
A potential challenge is how LVLMs predict
numerical coordinates in a language generation for-
mat. Traditional methods (Chen et al., 2021; Wang
et al., 2023; Shaw et al., 2023) divided the image
into 1000 bins, and creating a new 1,000-token
vocabulary {< p0 >, < p1 >, ..., < p999 >} to
represent the x and y coordinates. In this work,
we adopt a more intuitive manner used in LVLMs
(Chen et al., 2023b; Bai et al., 2023), treating nu-
merical values as natural language without any ad-
ditional tokenization or pre-/post-processing. For
instance, in Figure 1(a), for a smartphone screen-
shot and the instruction “View the new album of
Jony J”, we craft a user query prompt: “In the
UI, where should I click if I want to <instruc-
tion>?”. Subsequently, we normally compute the
cross-entropy loss between the model output and
the groundtruth “click (0.49, 0.40)” to optimize the
LVLM.
<div class=""header"">
    <ul class=""menu"">
<li>...</li>
</ul>
</div>
<div class=""container"">
    <div class=“product-thumbnails”><a href=“#” title=“Previous image""></a></div>
    <div class=""product-detail"">
<div>...</div>
        <button>ENQUIRE NOW</button>
        <div class=“product-share”>…</div>
    </div>
</div>
Figure 2: Example of two types of elements automati-
cally collected from the webpage.
3.2
Data Construction
We primarily train SeeClick using three collections
of data: web UI data crawled from the internet,
mobile UI data reorganized from public datasets,
and general vision-language instruction-following
data.
Web Data. Web UIs, featuring a variety of lay-
outs and design styles across websites, are ideal for
training LVLMs to learn universal recognition, un-
derstanding, and grounding capabilities across dif-
ferent GUIs. We collected approximately 300k web
pages from the latest Common Crawl repository 2
to serve as our training data for web UI. For each
webpage, we collect two types of elements from
the HTML code: (1) elements that display visible
text content; and (2) elements with a special “title”
attribute that display descriptive text when hover-
ing. This method ensures that we gather a series of
interactable elements and their corresponding text
instructions, while encompassing a wide range of
texts and icons. Figure 2 provides an example of
a web page, its associated simplified HTML code
and extracted two type elements. Next, we treat
the text or “title” content of each element as the
instruction, constructing the GUI grounding data
with screenshot s, instruction x, and the element’s
location y. We also include an inverse task, similar
to web OCR, where given an interface screenshot s
and the location y of an element, the model predicts
2https://commoncrawl.org/
the text description x of the element.
Mobile Data. For mobile UI, we include three
types of data: widget captioning, mobile UI ground-
ing, and mobile UI summarization. Widget Cap-
tioning aims to automatically generate language
descriptions for mobile UI elements; for example,
producing the description “play music” for the play
button on a music player interface. We utilize the
training split of the dataset provided in (Li et al.,
2020b), containing nearly 20k screenshots, 40k
widgets and 100k descriptions. We derive mobile
UI grounding data by inverting the widget caption-
ing task, treating language descriptions as instruc-
tions and predicting widget locations from screen-
shots and instructions. To improve element diver-
sity, we also incorporate the automatically gener-
ated elements and instructions from RICO (Li et al.,
2020a). The mobile UI grounding data involve di-
verse elements and instructions, aids SeeClick in
generalizing grounding capabilities to various GUI
scenarios. We finally include mobile UI summa-
rization data (Wang et al., 2021) to enhance overall
interface comprehension.
General Data. To maintain LVLM’s general ca-
pacities on natural images and its planning and
reasoning abilities for downstream agent tasks, we
incorporate general vision-language data for train-
ing SeeClick.
We utilize the 158k instruction-
following samples collected with GPT-4 from
LLaVA (Liu et al., 2023a), covering conversation,
detailed description, and complex reasoning.
Finally, we mix the data above and craft 30 task-
specific prompts for each added GUI task, resulting
in a 1M dataset to train SeeClick.
3.3
Training Details
We built SeeClick through continual pre-training
on a recent advanced LVLM, Qwen-VL (Bai et al.,
2023).
Qwen-VL inherently possesses ground-
ing capabilities and a higher resolution (448*448),
which has been proven beneficial for understand-
ing text-rich images (Lee et al., 2023; Ye et al.,
2023a). We train Qwen-VL on the constructed
dataset (Section 3.2) for about 10k steps (around
1 epoch) to obtain our GUI base model SeeClick.
During training, we employ LoRA (Hu et al., 2021)
to fine-tune both the visual encoder and LLM. We
adopt AdamW as the optimizer and use a cosine
annealing scheduler with an init learning rate of
3e-5 and a global batch size of 64. All training
takes around 24 hours on 8 NVIDIA A100 GPUs.
21%
21%
13%
15%
8%
6%
6%
10%
iOS
Android
Windows
macOS
Development
Shopping
Forum
Tools
ScreenSpot
278
198
210
232
140
151
Different types of elements 
in ScreenSpot
Text
Icon/Widget
Mobile
Desktop
Web
Figure 3: Statistic of our proposed GUI grounding
benchmark ScreenSpot. The left illustrates the diverse
GUI environments included. The right displays the
types of elements within each GUI category.
4
GUI Grounding Benchmark:
ScreenSpot
We recognize GUI grounding proficiency as essen-
tial for constructing a universal visual GUI agent.
However, due to the constrained capabilities of
earlier vision-language models, previous research
has paid limited attention to GUI grounding, with
the few existing studies (Li et al., 2021; Li and
Li, 2022; Zhang et al., 2023b) largely confined to
Android environments.
To address this research gap, we introduce
ScreenSpot, an up-to-date, realistic grounding eval-
uation benchmark encompassing various GUI plat-
forms. It is designed to assess vision-language
models’ ability to locate elements based on human
instructions (Figure 1(b) provides some examples).
ScreenSpot has two distinctive features: (1) Vari-
ous GUI platforms. It includes over 600 interface
screenshots from mobile (iOS, Android), desktop
(macOS, Windows), and web platforms, along with
more than 1200 instructions and corresponding ac-
tionable elements (as shown in Figure 3 left); (2)
Icons/Widgets. Considering that locating icons or
widgets might be more challenging than text ele-
ments on GUIs, we include a substantial number
of icon/widget type elements in each GUI (as de-
picted in Figure 3 right). See Appendix A for more
examples.
To evaluate vision-language models’ effective-
ness in real-world scenarios, ScreenSpot is care-
fully curated to ensure the samples in ScreenSpot
are novel and not included in existing training re-
sources. We recruited experienced annotators to
collect new GUI interfaces and label instructions
along with the bounding boxes for actionable ele-
Table 1: Results of different LVLMs on ScreenSpot. The best results in each column are bold. Benefit from efficient
GUI grounding pre-training, SeeClick significantly enhanced LVLMs’ ability to locate GUI elements following
instructions, and surpassed the strong baseline CogAgent with a smaller model size.
LVLMs
Model
Size
GUI
Specific
Mobile
Desktop
Web
Average
Text Icon/Widget Text Icon/Widget Text Icon/Widget
MiniGPT-v2
7B
✗
7.6%
5.2%
4.5%
2.9%
5.5%
0.0%
4.3%
Qwen-VL
9.6B
✗
9.4%
4.3%
6.4%
5.3%
0.0%
0.0%
4.2%
Fuyu
8B
✓
40.6%
1.6%
33.6%
6.7%
48.4%
2.9%
22.3%
CogAgent
18B
✓
66.5%
26.7%
73.7%
19.3%
78.0%
21.4%
47.6%
SeeClick
9.6B
✓
75.9%
48.7%
72.7%
26.4%
69.2%
21.4%
52.4%
ments. For mobile and desktop, annotators were
asked to select commonly used apps and opera-
tions; for web pages, we chose several types of
websites (development, shopping, forum, and tools)
from the recent web environment WebArena (Zhou
et al., 2023) for annotation.
5
Experiments
In this section, we first evaluate the GUI ground-
ing capabilities of representative LVLMs and our
proposed SeeClick on ScreenSpot. Subsequently,
we adapt SeeClick to three downstream GUI agent
tasks, exploring and analyzing the performance and
potential of vision-based agents in various GUIs.
5.1
GUI Grounding on ScreenSpot
As the foundation of visual GUI agents, GUI
grounding has not received extensive attention
in current LVLMs evaluations (Liu et al., 2023b;
Yu et al., 2023). Therefore, we compare various
LVLMs on our specially constructed GUI ground-
ing benchmark ScreenSpot, to examine their poten-
tial for GUI automation.
Compared LVLMs & Evaluation. We primar-
ily evaluated two types of LVLMs: (1) versatile
general LVLMs capable of tasks such as dialogue,
recognition and grounding, including MiniGPT-
v2 (Chen et al., 2023a) and Qwen-VL (Bai et al.,
2023); (2) recent LVLMs specifically designed for
GUI tasks, including Fuyu (Bavishi et al., 2023),
CogAgent (Hong et al., 2023) and our SeeClick.
Considering that GUI agents require clicking on
the correct position, we calculate the click accu-
racy as the metric, defined as the proportion of test
samples where the model’ predicted location falls
in the groundtruth element bounding box (Zhang
et al., 2018; Li et al., 2022; Zhang et al., 2023b).
We take the models’ generated point or the cen-
ter of the generated bounding box as the predicted
click location.
Results.
As shown in Table 1, while general
LVLMs have excelled in natural image grounding
(e.g., RefCOCO (Kazemzadeh et al., 2014)), their
GUI grounding performance on ScreenSpot is poor
due to the significant differences between GUIs
and natural images.
Accordingly, LVLMs trained specifically on
GUI data have significant improvements.
Our
SeeClick achieved the best average performances
across three GUI platforms and two types of el-
ements, even with fewer model parameters and
GUI-related training data than CogAgent. This
demonstrates the efficiency of our GUI grounding
pre-training; with the rich UI elements and diverse
instructions collected from the web and mobile,
SeeClick quickly learns to understand human in-
structions and locate elements, even in completely
unseen scenarios like iOS and desktop. Notably, all
models struggle with locating icons/widgets, high-
lighting the difficulty of identifying and grounding
non-text elements on GUIs, and showcasing the
unique challenges posed by ScreenSpot.
5.2
Visual GUI Agent Tasks
This section explores the capabilities of SeeClick
when migrated to three downstream GUI agent
tasks: MiniWob, AITW, and Mind2Web. Across
these tasks, SeeClick emulates human behavior,
determining the next action solely by observing in-
terface screenshots, without needing any additional
GUI information. On all three tasks, we trained
SeeClick on the respective training splits and tested
it on the test sets. Appendix B provides examples
of SeeClick’s interactions in these tasks.
5.2.1
MiniWob
MiniWob (Shi et al., 2017) comprises about 100
types of web automation tasks, where the agent
Click-button-sequence
Click-link
Click-pie
Click-button
Click-tab-2
Click-collapsible-2
Click-tab-2-hard
Unicode-test
Text-transform
Tic-tac-toe
Click-checkboxes
Click-option
Click-widget
Click-shape
Click-test-2
Navigate-tree
Use-slider
Click-checkboxes-transfer
Click-dialog-2
Simple-algebra
Choose-date
Click-color
Click-dialog
Click-shades
Click-checkboxes-large
Click-collapsible
Click-tab
Click-test
Simple-arithmetic
Click-checkboxes-soft
Count-shape
Use-antocomplete
Grid-coordinate
Enter-date
Identify-shape
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Click-button-sequence
Click-link
Click-pie
Click-button
Click-tab-2
Click-collapsible-2
Click-tab-2-hard
Unicode-test
Text-transform
Tic-tac-toe
Click-checkboxes
Click-option
Click-widget
Click-shape
Click-test-2
Navigate-tree
Use-slider
Click-checkboxes-transfer
Click-dialog-2
Simple-algebra
Choose-date
Click-color
Click-dialog
Click-shades
Click-checkboxes-large
Click-collapsible
Click-tab
Click-test
Simple-arithmetic
Click-checkboxes-soft
Count-shape
Use-antocomplete
Grid-coordinate
Enter-date
Identify-shape
SeeClick improvement over LVLM baseline Qwen-VL
Qwen-VL
SeeClick
SeeClick is better
Qwen-VL is better
Figure 4: Comparison of SeeClick and LVLM baseline Qwen-VL on MiniWob. Tasks with yellow shadows indicate
those with dynamic webpage layouts and element positions (closer to the real-world application of GUI agents, see
more details in Appendix B.1). SeeClick outperformed Qwen-VL in most tasks, especially in those with dynamic
elements, highlighting the effectiveness of our GUI grounding pre-training.
is asked to interact with a simplified web environ-
ment to accomplish human instructions. Each task
can templatize random variants and corresponding
instructions controlled by a random seed, creating
up to billions of possible task instances.
Existing open-source training data often lacks
corresponding interface screenshots (Furuta et al.,
2023).
Therefore, we rollout 50 successful
episodes using an LLM strategy for each task in
(Zheng et al., 2023), resulting in a 2.8K episodes
dataset to train SeeClick.
Compared Methods & Evaluation. We com-
pared SeeClick with a range of offline training
methods. Among these, the state-of-the-art method
WebGUM (Furuta et al., 2023) uses screenshots as
auxiliary information but still selects HTML ele-
ments as actions. Pix2Act (Shaw et al., 2023) is the
only prior vision-based approach, trained with ex-
tensive data to perform clicking and typing actions
on MiniWob. To verify the effectiveness of GUI
grounding pre-training, we also report the results
of the LVLM baseline Qwen-VL when trained with
the same 2.8K dataset.
Due to the variance in evaluation task sets among
different methods (Liu et al., 2018; Furuta et al.,
2023; Shaw et al., 2023), for fairness, we report per-
formance in two groups based on the overlapping
MiniWob tasks with their approaches. We compute
the success rate over 50 random seeds for each task,
and then compute the mean over all MiniWob tasks
as the final score.
Results. As depicted in Table 2, our purely vision-
based approach SeeClick surpassed a series of
HTML-based and image-based baselines with only
a fraction of the training data. Notably, with an
equivalent amount of training data (2.8K), SeeClick
outperformed the previous offline sota WebGUM,
Table 2: Average scores of different methods on Mini-
Wob. The best results in each setting are bold. Methods
achieving the highest performance with limited data are
underlined. SeeClick outperforms a range of offline
training methods as a purely vision-based model.
Methods
Modality
Dataset
Score
Compared with text-based models over 45 tasks
CC-Net (SL)
DOM+Image
2.4M
35.6%
WebN-T5
HTML
12K
55.2%
MM-WebN-T5 HTML+Image 347K
63.4%
WebGUM
HTML+Image
2.8K
65.5%
WebGUM
HTML+Image 347K
86.1%
SeeClick
Image
2.8K
73.0%
Compared with vision-based models over 35 tasks
CC-Net (SL)
Image
2.4M
23.4%
Pix2Act
Image
1.3M
64.6%
Qwen-VL
Image
2.8K
48.4%
SeeClick
Image
2.8K
68.0%
which uses both HTML and screenshots as input.
In comparison with visual approaches, thanks to
the powerful reasoning and planning abilities of the
LVLM and the localization skill imparted by our
GUI grounding pre-training, SeeClick exceeded
the sota visual method Pix2Act, using less than
0.3% training data.
Furthermore, SeeClick significantly surpassed
the LVLM baseline Qwen-VL by 20 percentage
points, verifying that enhancing GUI grounding ca-
pabilities plays a crucial role in improving LVLMs’
performance on MiniWob tasks. To analyze in de-
tail, we provide task-level comparisons between
SeeClick and Qwen-VL on 35 MiniWob tasks in
Table 3: Average scores of different methods on AITW. ClickAcc calculates the accuracy of click operation. The
best results in each column are bold. SeeClick exhibits the best performance among both API-based LLMs (top
row) and trained LVLMs (bottom row).
Methods
Modality General Install GoogleApps Single WebShopping Overall ClickAcc
ChatGPT-CoT
Text
5.9
4.4
10.5
9.4
8.4
7.7
-
PaLM2-CoT
Text
-
-
-
-
-
39.6
-
GPT-4V
Image
41.7
42.6
49.8
72.8
45.7
50.5
-
Qwen-VL
Image
53.3
61.2
56.3
61.7
52.0
56.9
60.1
SeeClick
Image
56.0
64.5
57.7
63.6
57.3
59.8
68.4
Figure 4. SeeClick shows notable improvements
over Qwen-VL in most tasks, particularly in those
where interface layouts and element positions dy-
namically change.
This confirms our hypothe-
sis that general LVLMs struggle with accurately
clicking on interfaces, and our GUI grounding pre-
training significantly enhances this capability, lead-
ing to better performance.
5.2.2
AITW
We evaluate the effectiveness of SeeClick in smart-
phone environments with a recently proposed An-
droid UI automation dataset Android In The Wild
(AITW). It encompasses 30k distinct task instruc-
tions and corresponding 715k human-annotated
operation episodes. Previous approaches (Rawles
et al., 2023; Zhan and Zhang, 2023) split AITW
episode-wise into train/val/test (80/10/10%). How-
ever, with an average of over 20 episodes per
instruction in AITW, there is a significant risk
of overfitting due to:
(1) extensive repetition
in training trajectories; (2) instructions in the
test set have appeared during training.
In this
work, we propose to split the training and test-
ing sets by instruction.
Specifically, we se-
lected 545/688/306/700/700 instructions from Gen-
eral/Install/GoogleApps/Single/WebShopping re-
spectively and retained only one annotated trajec-
tory for each instruction. Then for each scenario,
we selected 80% for training and the remaining for
testing. This setting better reflects the performance
of the trained agent in the real-world application.
Compared Methods & Evaluation. We com-
pare SeeClick with two types of baselines: (1)
API-based LLMs employing in-context learning
or Chain-of-Thought (CoT), such as ChatGPT-CoT
(Zhan and Zhang, 2023), PaLM2-CoT (Rawles
et al., 2023) and the latest GPT-4V (Yan et al.,
2023); (2) our own trained LVLM baseline Qwen-
VL. We follow Rawles et al. (2023) to adopt the
screen-wise action matching score as the main met-
rics, and compute the click accuracy (ClickAcc),
which calculates the accuracy when both the refer-
ence and prediction are click actions.
Results.
As illustrated in Table 3, SeeClick
achieved the best average performance among both
API-based LLMs and trained LVLMs. Specifically,
SeeClick exhibited an 8 percentage point improve-
ment in click accuracy over the LVLM baseline
Qwen-VL, substantiating the hypothesis that GUI
grounding significantly augments the precision of
click actions in visual GUI agents, thereby improv-
ing their overall task performance.
5.2.3
Mind2Web
To assess SeeClick’s capabilities in web en-
vironments, we utilize the recently introduced
Mini2Web dataset (Deng et al., 2023). Mind2Web
comprises over 2000 open-ended tasks collected
from 137 real websites, each with a high-level in-
struction and a human action trajectory sequence in-
volving clicking, selecting and typing. Mind2Web
was originally designed to evaluate text-based web
agents, focusing on identifying actionable elements
by selecting them from simplified HTML doc-
uments. This work explores visual web agents
that predict click positions directly from inter-
face screenshots. For this purpose, we augmented
Mind2Web’s trajectory data with interface screen-
shots and bounding boxes for action elements at
each step, sourced from their raw dump data (Deng
et al., 2023). To the best of our knowledge, this
is the first attempt of web agents relying solely on
screenshots as inputs for navigating real websites.
Compared Methods & Evaluation. We com-
pare SeeClick with a range of text-based web
agents (Deng et al., 2023) and our LVLM base-
line Qwen-VL. Mind2Act employs a two-stage
method, where a small LM first generates candi-
date elements from raw HTML, and then a large
Table 4: Comparsion of different methods on Mind2Web. The best results in each column are bold. Improvements
of SeeClick over the LVLM baseline are underline. The GUI grounding pre-training nearly doubled the step success
rate of SeeClick on real websites.
Methods
w/o HTML
Cross-Task
Cross-Website
Cross-Domain
Ele.Acc Op.F1 Step SR Ele.Acc Op.F1 Step SR Ele.Acc Op.F1 Step SR
MindAct (gen)
✗
20.2
52.0
17.5
13.9
44.7
11.0
14.2
44.7
11.9
MindAct
✗
55.1
75.7
52.0
42.0
65.2
38.9
42.1
66.5
39.6
GPT-3.5
✗
20.3
56.6
17.4
19.3
48.8
16.2
21.6
52.8
18.6
GPT-4
✗
41.6
60.6
36.2
35.8
51.1
30.1
37.1
46.5
26.4
Qwen-VL
✓
14.9
86.2
12.6
12.1
83.7
10.1
9.6
84.3
8.0
SeeClick
✓
26.3
86.2
23.7
21.9
82.9
18.8
22.1
84.1
20.2
LM selects the target element using multi-choice
QA. Mind2Act (gen) modifies the QA module to
directly generate the target element instead. GPT-
3.5 and GPT-4 adopt the same multiple-choice QA
formulation as MindAct, and include three demon-
stration examples for in-context learning.
We calculate element accuracy (Ele.Acc), Oper-
ation F1 (Op.F1) and step success rate (Step SR).
For vision-based methods, a prediction is consid-
ered correct if the predicted coordinate falls in the
target element’s bounding box. All other settings
are following (Deng et al., 2023).
Results. As displayed in Table 4, SeeClick nearly
doubled the element selection accuracy and step
success rate compared to the LVLM baseline Qwen-
VL. This indicates that improvements in GUI
grounding directly correlate with enhanced perfor-
mance in downstream web agent tasks. Further-
more, text-based methods often have lower overall
Op.F1 due to nearly 20% groundtruth elements
being incorrectly filtered out in the candidate gen-
eration stage, which leads to a zero Op.F1.
Although SeeClick can operate without extra
HTML information, its performance lags behind
state-of-the-art HTML-based methods, as predict-
ing click locations on web pages is much more dif-
ficult than choosing from HTML candidates. This
underscores the challenge of grounding in complex
interfaces, suggesting substantial room for improve-
ments toward a visual GUI agent that is applicable
in real-world scenarios.
6
Conclusion
In this paper, we introduce a visual GUI agent -
SeeClick, which only relies on screenshots for GUI
task automation. We found a key challenge in de-
veloping such visual GUI agents: GUI grounding
- the capacity to accurately locate screen elements
based on human instructions. To address this chal-
lenge, we propose to enhance SeeClick via GUI
grounding pre-training, and devise methods to au-
tomate the curation of GUI grounding data from
web and mobile. For benchmarking the progress
in GUI grounding, we created ScreenSpot, the first
realistic evaluation dataset encompassing mobile,
desktop, and web platforms. Results on ScreenSpot
demonstrate a significant improvement of SeeClick
over LVLM baselines. Moreover, comprehensive
evaluations across three GUI automation tasks con-
sistently support our finding that advancements in
GUI grounding directly correlated with improved
performance in downstream agent tasks.
References
Chongyang Bai, Xiaoxue Zang, Ying Xu, Srinivas
Sunkara, Abhinav Rastogi, Jindong Chen, et al.
2021.
Uibert: Learning generic multimodal rep-
resentations for ui understanding. arXiv preprint
arXiv:2107.13731.
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang,
Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou,
and Jingren Zhou. 2023. Qwen-vl: A frontier large
vision-language model with versatile abilities. arXiv
preprint arXiv:2308.12966.
Rohan Bavishi,
Erich Elsen,
Curtis Hawthorne,
Maxwell Nye, Augustus Odena, Arushi Somani, and
Sa˘gnak Ta¸sırlar. 2023. Introducing our multimodal
models.
Andrea Burns, Deniz Arsan, Sanjna Agrawal, Ranjitha
Kumar, Kate Saenko, and Bryan A Plummer. 2022.
A dataset for interactive vision-language navigation
with unknown command feasibility. In European
Conference on Computer Vision, pages 312–328.
Springer.
Jieshan Chen, Mulong Xie, Zhenchang Xing, Chun-
yang Chen, Xiwei Xu, Liming Zhu, and Guoqiang Li.
2020. Object detection for graphical user interface:
Old fashioned or deep learning or a combination? In
proceedings of the 28th ACM joint meeting on Eu-
ropean Software Engineering Conference and Sym-
posium on the Foundations of Software Engineering,
pages 1202–1214.
Jun Chen, Deyao Zhu, Xiaoqian Shen, Xiang Li, Zechun
Liu, Pengchuan Zhang, Raghuraman Krishnamoor-
thi, Vikas Chandra, Yunyang Xiong, and Mohamed
Elhoseiny. 2023a. Minigpt-v2: large language model
as a unified interface for vision-language multi-task
learning. arXiv preprint arXiv:2310.09478.
Keqin Chen, Zhao Zhang, Weili Zeng, Richong Zhang,
Feng Zhu, and Rui Zhao. 2023b. Shikra: Unleashing
multimodal llm’s referential dialogue magic. arXiv
preprint arXiv:2306.15195.
Ting Chen, Saurabh Saxena, Lala Li, David J Fleet, and
Geoffrey Hinton. 2021. Pix2seq: A language model-
ing framework for object detection. In International
Conference on Learning Representations.
Biplab Deka, Zifeng Huang, Chad Franzen, Joshua Hi-
bschman, Daniel Afergan, Yang Li, Jeffrey Nichols,
and Ranjitha Kumar. 2017. Rico: A mobile app
dataset for building data-driven design applications.
In Proceedings of the 30th annual ACM symposium
on user interface software and technology, pages
845–854.
Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen,
Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su.
2023. Mind2web: Towards a generalist agent for the
web. arXiv preprint arXiv:2306.06070.
Alexey
Dosovitskiy,
Lucas
Beyer,
Alexander
Kolesnikov,
Dirk Weissenborn,
Xiaohua Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias
Minderer, Georg Heigold, Sylvain Gelly, et al. 2020.
An image is worth 16x16 words: Transformers
for image recognition at scale.
In International
Conference on Learning Representations.
Hiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yu-
taka Matsuo, Shixiang Shane Gu, and Izzeddin
Gur. 2023.
Multimodal web navigation with
instruction-finetuned foundation models.
arXiv
preprint arXiv:2305.11854.
Difei Gao, Lei Ji, Zechen Bai, Mingyu Ouyang, Peiran
Li, Dongxing Mao, Qinchen Wu, Weichen Zhang,
Peiyi Wang, Xiangwu Guo, et al. 2023. Assistgui:
Task-oriented desktop graphical user interface au-
tomation. arXiv preprint arXiv:2312.13108.
Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa
Safdari, Yutaka Matsuo, Douglas Eck, and Alek-
sandra Faust. 2023a. A real-world webagent with
planning, long context understanding, and program
synthesis. arXiv preprint arXiv:2307.12856.
Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa
Safdari, Austin V Huang, Aakanksha Chowdhery,
Sharan Narang, Noah Fiedel, and Aleksandra Faust.
2023b. Understanding html with large language mod-
els. In ICLR 2023 Workshop on Mathematical and
Empirical Understanding of Foundation Models.
Izzeddin Gur, Ulrich Rueckert, Aleksandra Faust, and
Dilek Hakkani-Tur. 2018. Learning to navigate the
web. In International Conference on Learning Rep-
resentations.
Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu,
Lijuan Liu, Nevan Wichers, Gabriel Schubiner, Ruby
Lee, and Jindong Chen. 2021. Actionbert: Leverag-
ing user actions for semantic understanding of user
interfaces. In Proceedings of the AAAI Conference
on Artificial Intelligence, pages 5931–5938.
Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng
Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang,
Yuxiao Dong, Ming Ding, et al. 2023. Cogagent: A
visual language model for gui agents. arXiv preprint
arXiv:2312.08914.
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,
Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen,
et al. 2021. Lora: Low-rank adaptation of large lan-
guage models. In International Conference on Learn-
ing Representations.
Sahar Kazemzadeh, Vicente Ordonez, Mark Matten,
and Tamara Berg. 2014. Referitgame: Referring to
objects in photographs of natural scenes. In Proceed-
ings of the 2014 conference on empirical methods in
natural language processing (EMNLP), pages 787–
798.
Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
2023. Language models can solve computer tasks.
arXiv preprint arXiv:2303.17491.
Kenton Lee, Mandar Joshi, Iulia Raluca Turc, Hexi-
ang Hu, Fangyu Liu, Julian Martin Eisenschlos, Ur-
vashi Khandelwal, Peter Shaw, Ming-Wei Chang,
and Kristina Toutanova. 2023. Pix2struct: Screen-
shot parsing as pretraining for visual language under-
standing. In International Conference on Machine
Learning, pages 18893–18912. PMLR.
Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang,
Jingkang Yang, and Ziwei Liu. 2023.
Otter: A
multi-modal model with in-context instruction tuning.
arXiv preprint arXiv:2305.03726.
Gang Li and Yang Li. 2022. Spotlight: Mobile ui under-
standing using vision-language models with a focus.
In The Eleventh International Conference on Learn-
ing Representations.
Liunian Harold Li, Pengchuan Zhang, Haotian Zhang,
Jianwei Yang, Chunyuan Li, Yiwu Zhong, Lijuan
Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, et al.
2022. Grounded language-image pre-training. In
Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition, pages 10965–
10975.
Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, and Jason
Baldridge. 2020a. Mapping natural language instruc-
tions to mobile ui action sequences. arXiv preprint
arXiv:2005.03776.
Yang Li, Gang Li, Luheng He, Jingjie Zheng, Hong Li,
and Zhiwei Guan. 2020b. Widget captioning: Gener-
ating natural language description for mobile user in-
terface elements. arXiv preprint arXiv:2010.04295.
Yang Li, Gang Li, Xin Zhou, Mostafa Dehghani, and
Alexey Gritsenko. 2021.
Vut: Versatile ui trans-
former for multi-modal multi-task user interface mod-
eling. arXiv preprint arXiv:2112.05692.
Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tian-
lin Shi, and Percy Liang. 2018. Reinforcement learn-
ing on web interfaces using workflow-guided explo-
ration. In International Conference on Learning Rep-
resentations.
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae
Lee. 2023a. Visual instruction tuning. In Neural
Information Processing Systems.
Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li,
Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi
Wang, Conghui He, Ziwei Liu, et al. 2023b. Mm-
bench: Is your multi-modal model an all-around
player? arXiv preprint arXiv:2307.06281.
OpenAI. 2023. GPT-4 technical report.
Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao,
Shaohan Huang, Shuming Ma, and Furu Wei.
2023.
Kosmos-2: Grounding multimodal large
language models to the world.
arXiv preprint
arXiv:2306.14824.
Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana
Riva, and Timothy Lillicrap. 2023. Android in the
wild: A large-scale dataset for android device control.
arXiv preprint arXiv:2307.10088.
Peter Shaw, Mandar Joshi, James Cohan, Jonathan Be-
rant, Panupong Pasupat, Hexiang Hu, Urvashi Khan-
delwal, Kenton Lee, and Kristina Toutanova. 2023.
From pixels to ui actions: Learning to follow instruc-
tions via graphical user interfaces. In Advances in
Neural Information Processing Systems.
Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Her-
nandez, and Percy Liang. 2017. World of bits: An
open-domain platform for web-based agents. In In-
ternational Conference on Machine Learning, pages
3135–3144. PMLR.
Qiushi Sun, Zhangyue Yin, Xiang Li, Zhiyong Wu,
Xipeng Qiu, and Lingpeng Kong. 2023.
Corex:
Pushing the boundaries of complex reasoning
through multi-model collaboration. arXiv preprint
arXiv:2310.00280.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et al. 2023. Llama: Open and effi-
cient foundation language models. arXiv preprint
arXiv:2302.13971.
Bryan Wang, Gang Li, Xin Zhou, Zhourong Chen, Tovi
Grossman, and Yang Li. 2021. Screen2words: Au-
tomatic mobile ui summarization with multimodal
learning. In The 34th Annual ACM Symposium on
User Interface Software and Technology, pages 498–
510.
Wenhai Wang, Zhe Chen, Xiaokang Chen, Jiannan
Wu, Xizhou Zhu, Gang Zeng, Ping Luo, Tong
Lu, Jie Zhou, Yu Qiao, et al. 2023.
Vision-
llm: Large language model is also an open-ended
decoder for vision-centric tasks.
arXiv preprint
arXiv:2305.11175.
Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei
Yuan, Shuai Yuan, Qika Lin, Yu Qiao, and Jun Liu.
2023. Symbol-llm: Towards foundational symbol-
centric interface for large language models. arXiv
preprint arXiv:2311.09278.
An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin,
Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong,
Julian McAuley, Jianfeng Gao, et al. 2023.
Gpt-
4v in wonderland: Large multimodal models for
zero-shot smartphone gui navigation. arXiv preprint
arXiv:2311.07562.
Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Ze-
biao Huang, Bin Fu, and Gang Yu. 2023. Appa-
gent: Multimodal agents as smartphone users. arXiv
preprint arXiv:2312.13771.
Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye,
Ming Yan, Guohai Xu, Chenliang Li, Junfeng Tian,
Qi Qian, Ji Zhang, et al. 2023a. Ureader: Univer-
sal ocr-free visually-situated language understanding
with multimodal large language model. In The 2023
Conference on Empirical Methods in Natural Lan-
guage Processing.
Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye,
Ming Yan, Yiyang Zhou, Junyang Wang, An-
wen Hu, Pengcheng Shi, Yaya Shi, et al. 2023b.
mplug-owl: Modularization empowers large lan-
guage models with multimodality. arXiv preprint
arXiv:2304.14178.
Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang,
Kevin Lin, Zicheng Liu, Xinchao Wang, and Lijuan
Wang. 2023. Mm-vet: Evaluating large multimodal
models for integrated capabilities. arXiv preprint
arXiv:2308.02490.
Zhuosheng Zhan and Aston Zhang. 2023. You only
look at screens: Multimodal chain-of-action agents.
arXiv preprint arXiv:2309.11436.
Jianming Zhang, Sarah Adel Bargal, Zhe Lin, Jonathan
Brandt, Xiaohui Shen, and Stan Sclaroff. 2018. Top-
down neural attention by excitation backprop. Inter-
national Journal of Computer Vision, 126(10):1084–
1102.
Pan Zhang, Xiaoyi Dong Bin Wang, Yuhang Cao, Chao
Xu, Linke Ouyang, Zhiyuan Zhao, Shuangrui Ding,
Songyang Zhang, Haodong Duan, Hang Yan, et al.
2023a.
Internlm-xcomposer: A vision-language
large model for advanced text-image comprehension
and composition. arXiv preprint arXiv:2309.15112.
Zhizheng Zhang, Wenxuan Xie, Xiaoyi Zhang, and
Yan Lu. 2023b. Reinforced ui instruction ground-
ing: Towards a generic ui task automation api. arXiv
preprint arXiv:2310.04716.
Longtao Zheng, Rundong Wang, Xinrun Wang, and
Bo An. 2023.
Synapse: Trajectory-as-exemplar
prompting with memory for computer control. In
NeurIPS 2023 Foundation Models for Decision Mak-
ing Workshop.
Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou,
Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan
Bisk, Daniel Fried, Uri Alon, et al. 2023. Webarena:
A realistic web environment for building autonomous
agents. arXiv preprint arXiv:2307.13854.
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and
Mohamed Elhoseiny. 2023. Minigpt-4: Enhancing
vision-language understanding with advanced large
language models. arXiv preprint arXiv:2304.10592.
A
Examples of ScreenSpot
Figure 5 provides more examples of ScreenSpot,
which contains a variety of common GUI scenarios
for mobile, desktop, and web platforms.
B
Case Study
B.1
MiniWob
Figure 6(a) illustrates the difference between static
and dynamic layout tasks. Static layout tasks have
fixed element positions during training and testing,
while dynamic layout tasks display varying inter-
faces and element positions. Figure 6(b) provides
examples of SeeClick’s interaction with MiniWob.
SeeClick relies solely on the interface screenshot
for arithmetic, reasoning, etc.
B.2
AITW
Figure 7 provides an example of SeeClick when
completing an AITW task. Predictions marked
in red below indicate that they were computed as
incorrect in AITW. However, some errors occur
because the current step’s answer is not unique.
For example in step 5, the model’s predicted input
""DuckDuckGo Privacy Browser"" is also a poten-
tially correct action.
B.3
Mind2Web
Figure 8 shows several examples of SeeClick
on the real-world website benchmark Mind2Web.
SeeClick can comprehend instructions and click on
the correct elements within complex interfaces.
Instruction: My 
account
Source: Mobile
(iOS)
Type: 
Icon/Widget
Instruction: 
Remove maps 
from the 
Desktop
Source: Mobile
(iOS)
Type: 
Icon/Widget
 
Instruction: 
Disallow 
automatic app 
updates
Source: Mobile
(iOS)
Type: 
Icon/Widget
 
Instruction: 
Search event
Source: Mobile
(iOS)
Type: Text
Instruction: 
Scan QR code
Source: 
Mobile
(Android)
Type: 
Icon/Widget
 
Instruction: 
Continue
Source: Mobile
(Android)
Type: Text 
Instruction: 
Display 15-day 
weather 
forecast
Source: Mobile
(Android)
Type: Text 
Instruction: 
Fold input 
method
Source: Mobile
(Android)
Type: 
Icon/Widget
Instruction: 
Create a new
document
Source: PC
(macOS)
Type: Text 
Instruction: 
Enlarge font 
size
Source: PC
(macOS)
Type:
Icon/Widget
Instruction: 
Add subtitle
Source: PC
(Windows)
Type: Text 
Instruction: Go 
to Beauty & 
Personal Care
Source: Web
(Shop)
Type: Text 
Instruction: Set 
Reminder
Source: Web
(Development)
Type: 
Icon/Widget
Instruction: Reply
to the first post 
Source: Web
(Forum)
Type: Text 
Instruction: Pause the
debugger
Source: PC (macOS)
Type: Icon/Widget
Instruction:
Zoom in on 
the map 
Source: Web
(Tools)
Type: 
Icon/Widget 
Instruction: 
Open Fax
Source: PC
(Windows)
Type: Text
Figure 5: More examples of GUI grounding benchmark ScreenSpot.
{“action_type”: 4, “click_point”:
(0.58, 0.3)}
{“action_type”: 4, “click_point”:
(0.25, 0.4)}
{“action_type”: 4, “click_point”:
(0.25, 0.4)}
{“action_type”: 4, “click_point”:
(0.46, 0.55)}
{“action_type”: 4, “click_point”:
(0.47, 0.47)}
{“action_type”: 4, “click_point”:
(0.5, 0.62)}
{“action_type”: 4, “click_point”:
(0.71, 0.78)}
{“action_type”: 4, “click_point”:
(0.81, 0.38)}
{“action_type”: 3, “typed_text”:
“36”}
{“action_type”: 4, “click_point”:
(0.50, 0.64)}
{“action_type”: 4, “click_point”:
(0.69, 0.8)}
{“action_type”: 4, “click_point”:
(0.31, 0.8)}
{“action_type”: 4, “click_point”:
(0.31, 0.49)}
{“action_type”: 4, “click_point”:
(0.14, 0.3)}
{“action_type”: 4, “click_point”:
(0.13, 0.81)}
{“action_type”: 4, “click_point”:
(0.19, 0.76)}
(a) Comparison between static layout (left, click-color) and dynamic layout (right, unicode-test).
Task: simple-arithmetic
Task: click-pie
Task: choose-date
···
(b) Example episodes of SeeClick on MiniWob tasks.
Figure 6: Example episodes of SeeClick on MiniWob. The model’s prediction output is below the screenshot, with
action_type 4 indicating clicking and action_type 3 indicating typing.
{“action_type”: 6)}
{“action_type”: 4, “click_point”:
(0.12, 0.79)}
{“action_type”: 4, “click_point”:
(0.81, 0.07)}
{“action_type”: 4, “click_point”:
(0.93, 0.06)}
{“action_type”: 3, “typed_text”:
“DuckDuckGo Privacy Browser”}
{“action_type”: 4, “click_point”:
(0.29, 0.12)}
{“action_type”: 4, “click_point”:
(0.87, 0.15)}
{“action_type”: 4, “click_point”:
(0.87, 0.15)}
Reference: {“action_type”: 3,
“typed_text”: “duckduckgo”}
{“action_type”: 4, “click_point”:
(0.45, 0.18)}
Instruction: open app ""DuckDuckGo Privacy Browser"" (install if not already installed) 
and enter user name: ""cleaving@outlook.com"" and password: ""freighters""
Figure 7: Example episodes of SeeClick on AITW. The model’s prediction output is below the screenshot, with
action_type 4 indicating clicking, action_type 3 indicating typing and action_type 6 indicating PRESS HOME. For
failed steps, we mark the predictions in red and provide the groundtruth action in green.
{“action_type”: 4, “click_point”: (0.68, 0.10)}
{“action_type”: 4, “click_point”: (0.38, 0.35)}
{“action_type”: 3, “click_point”: (0.43, 0.48), “value”: 
“87654321”}
{“action_type”: 3, “click_point”: (0.26, 0.57), “value”: 
“9753”}
{“action_type”: 4, “click_point”: (0.50, 0.79)}
Instruction: Check my AMC gift card balance with gift card number 87654321 and pin number 9753.
Instruction: Find the list of all neighborhood maps for Brooklyn.
{“action_type”: 4, “click_point”: (0.03, 0.05)}
{“action_type”: 4, “click_point”: (0.56, 0.68)}
{“action_type”: 4, “click_point”: (0.50, 0.41)}
Instruction: Download the e-receipt with the last name Smith and confirmation number X123456989.
{“action_type”: 4, “click_point”: (0.67, 0.08)}
{“action_type”: 4, “click_point”: (0.47, 0.36)}
{“action_type”: 3, “click_point”: (0.46, 0.62), “value”: 
“Smith”}
{“action_type”: 3, “click_point”: (0.70, 0.65), “value”: 
“X123456989”}
{“action_type”: 4, “click_point”: (0.50, 0.77)}
Figure 8: Example episodes of SeeClick on Mind2Web. The model’s prediction output is below the screenshot,
with action_type 4 indicating clicking and action_type 3 indicating typing. For failed steps, we mark the predictions
in red and provide the groundtruth elements with the green bounding box.
"
"With the help of artificial intelligence (AI), a new pipeline has been proposed in the field of online advertising to generate creative advertisements, solving the problem of low aesthetics and quantity of traditional AI-based methods. This paper focuses on the use of the stable diffusion model with the LoRA model and two novel models, the prompt model and the reward model. The prompt model is designed to generate individualized creative images for different user groups, while the reward model comprehensively considers the multi-modal features of image and text to judge the quality and select the best ones to show online. The significant benefits obtained in online and offline experiments verify the significance of our proposed method.nan","Recently, AI-Generated Content (AIGC) has seen rapid development, leading to the emergence of text-to-image (T2I) generation tasks. Among various methods, diffusion-based methods have become state-of-the-art for T2I tasks due to their stationary training objective and easy scalability. However, directly using these methods for creative image generation is impractical in the advertising domain. This paper introduces stable diffusion in inpainting mode to modify only the background while preserving the main product information. In addition, two crucial factors, the prompt and the diffusion models, which directly affect the image generation, are discussed. To generate attractive creatives, a Prompt Model (PM) is introduced to select a good prompt, and a Reward Model (RM) is used to predict the Click-Through Rate (CTR) score for each creative image.nan","nanTo improve CTR, a pipeline has been proposed where in the first stage, a stable diffusion method is used to modify the background of the original product image. In the second stage, a prompt model is introduced to generate individualized prompts for different user groups. Finally, a reward model is trained to predict CTR scores for each creative image. The significant benefits obtained in online and offline experiments verify the significance of our proposed method.nan","The proposed pipeline consists of four main modules:

1. Stable Diffusion Inpainting: This module is responsible for generating creative images by modifying only the background of the original product image. The saliency object image and mask image are obtained using a saliency detection model. A stable diffusion method in inpainting mode is then used to generate creatives. The LoRA model and prompt model are employed to fine-tune the stable diffusion model and select appropriate prompts.

2. Prompt Model: The prompt model aims to select a good prompt that effectively describes the style of the image. It takes user attributes, item attributes, and contextual attributes as input and predicts the CTR score for each token in the whole word vocabulary under the given conditions. The top-ranked tokens are combined to form a prompt and inputted into the stable diffusion model to generate creative images.

3. Reward Model: To predict the CTR scores of the creatives generated by the stable diffusion model, a reward model is introduced. This model considers the relationship between textual and visual features, as well as multi-head self-attention sub-modules, to learn the creative content and visual features. A list-wise loss function and a point-wise loss function are employed to train the reward model. The final loss is the sum of the list-wise loss and the point-wise loss.

4. Self-cycling Training: To further optimize the quality of generated creatives and improve user experience, a self-cycling training mode is incorporated into the pipeline. The reward model is used to predict CTR scores for the generated creatives, and the top-ranked creatives are retained as training samples for both the LoRA model and the prompt model.nan","Extensive experiments were conducted to evaluate the effectiveness of the proposed pipeline. The results demonstrated:

- Improved Online Results: CTR and revenue improvements of 10.4% and 9.7%, respectively, were observed when using the full self-cycling process compared to the baseline of using the original image provided by sellers.

- Ablation Study on Reward Model: Experiments on commercial and public data showed the effectiveness of the proposed reward model structure, which outperformed two public methods in terms of CTR uplift and MSE metrics.

- Ablation Study on Prompt Model: The importance of considering user group information was confirmed, as incorporating user features resulted in significant historical CTR improvements. Additionally, the self-cycling training process was found to further enhance the quality of generated creatives.nan","The paper presents a novel pipeline for creative generation in online advertising that utilizes stable diffusion, a prompt model, and a reward model. The pipeline generates visually appealing and CTR-optimized creatives by modifying the background of original product images and considering user preferences. The prompt model enhances diversity and quality by generating personalized prompts, while the reward model selects the most promising creatives for display. Comprehensive experiments validate the effectiveness of the proposed method, demonstrating improvements in online performance and user experience.nan",A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model,"Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, Yifan Zeng","A New Creative Generation Pipeline for Click-Through Rate with
Stable Diffusion Model
Hao Yang
Shopee Discovery Ads
Beijing, China
Jianxin Yuan
Shopee Discovery Ads
Beijing, China
Shuai Yang
Shopee Discovery Ads
Beijing, China
Linhe Xu
Shopee Discovery Ads
Beijing, China
Shuo Yuan
Shopee Discovery Ads
Beijing, China
Yifan Zeng
Shopee Discovery Ads
Beijing, China
ABSTRACT
In online advertising scenario, sellers often create multiple creatives
to provide comprehensive demonstrations, making it essential to
present the most appealing design to maximize the Click-Through
Rate (CTR). However, sellers generally struggle to consider users’
preferences for creative design, leading to the relatively lower aes-
thetics and quantities compared to Artificial Intelligence (AI)-based
approaches. Traditional AI-based approaches still face the same
problem of not considering user information while having limited
aesthetic knowledge from designers. In fact that fusing the user
information, the generated creatives can be more attractive because
different users may have different preferences. To optimize the
results, the generated creatives in traditional methods are then
ranked by another module named creative ranking model. The
ranking model can predict the CTR score for each creative con-
sidering user features. However, the two above stages (generating
creatives and ranking creatives) are regarded as two different tasks
and are optimized separately. Specifically, generating creatives in
the first stage without considering the target of improving CTR
task may generate several creatives with poor quality, leading to
dilute online impressions and directly making bad effectiveness on
online results.
In this paper, we proposed a new automated Creative Generation
pipeline for Click-Through Rate (CG4CTR) 1 with the goal of
improving CTR during the creative generation stage. In this pipeline,
a new creative is automatically generated and selected by stable
diffusion method with the LoRA model and two novel models:
prompt model and reward model. Our contributions have four
parts: 1) The inpainting mode in stable diffusion method is firstly
applied to creative image generation task in online advertising
scene. A self-cyclic generation pipeline is proposed to ensure the
convergence of training. 2) Prompt model is designed to generate
individualized creative images for different user groups, which
can further improve the diversity and quality of the generated
1The code is at https://github.com/HaoYang0123/Creative_Generation_Pipeline.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-XXXX-X/18/06...$15.00
https://doi.org/XXXXXXX.XXXXXXX
creatives. 3) Reward model comprehensively considers the multi-
modal features of image and text to improve the effectiveness of
creative ranking task, and it is also critical in self-cyclic generation
pipeline. 4) The significant benefits obtained in online and offline
experiments verify the significance of our proposed method.
KEYWORDS
Stable Diffusion, Creative Generation, Prompt and Reward Models
ACM Reference Format:
Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng.
2018. A New Creative Generation Pipeline for Click-Through Rate with
Stable Diffusion Model. In Proceedings of Make sure to enter the correct
conference title from your rights confirmation emai (Conference acronym ’XX).
ACM, New York, NY, USA, 10 pages. https://doi.org/XXXXXXX.XXXXXXX
1
INTRODUCTION
Recently, the topic of AI-Generated Content (AIGC) has developed
rapidly, such as GLIDE [24], DALL-E 1-3 [31, 36, 45], Imagen [40],
Stable Diffusion (SD) [37] and ChatGPT [43]. One of the most repre-
sentative tasks is text-to-image (T2I) generation, which has received
much attention in both academia and industry. The target of T2I
task is to generate images with similar semantics given input lan-
guage prompt. Currently, the diffusion-based methods [18, 23, 37]
have become the state-of-the-art (SoTA) method in T2I task due
to the stationary training objective and easy scalability. Although
these diffusion methods have a satisfactory performance on the
T2I task, directly using these methods in creative image generation
is infeasible in the advertising scene because they will modify the
main product image. Traditional creative generation methods in the
advertising scene use deep learning to generate some objects/tags
[19, 20], dense captions [32] or layout information [33, 46, 47] on
image. Different from these methods, we first use diffusion model
to generate background images while keeping the main product
information unchanged in creative generation task for the advertis-
ing scene. In the experimental analysis, we found that modifying
the background while keeping the visual pixels of the main product
unchanged can also significantly improve the CTR.
In addition, when using the diffusion model, there are two very
important factors, prompt and diffusion models, that will directly
affect the effect of the generated image. As shown in Fig. 1, for
the original product image uploaded by the seller, the background
image is simple with solid white color. To make the background
more attractive, we can use the inpainting mode in SD method
to generate more individualized background images with richer
colors. However, if a proper prompt (a prompt consists of several
arXiv:2401.10934v1  [cs.IR]  17 Jan 2024
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng
tokens) is not added into the generation process, the result is often
poor with the cluttered background. Then we need to use a Prompt
Model (PM) to select a good prompt, which is then added to guide
the generation process. Despite that a good background can be
generated given an acceptable prompt, the diffusion model is not
fine-tuned in our industrial data, and the effect is not optimal. It is
necessary to fine-tune diffusion model in our data. However, the
parameters of diffusion model are very huge, and directly training
whole model is not realistic because of high training cost. Therefore,
Low-Rank Adaptation (LoRA) mechanism [27, 48] is used to speed
up the training process.
Figure 1: Generating creatives only by modifying background
using SD method in inpainting mode.
As described earlier, Prompt Model (PM) is important to guide
image generation. PM considers user feature (e.g., user age, user
gender), item feature (e.g., item ID and category ID) and candidate
tokens as input, then outputs score for each input token. We se-
lect top-𝑝 tokens to assemble into one prompt. Considering that
different users have different preferences for creative images, for
example, young users are more inclined to cool color and electronic
style while old users are more inclined to warm color and mini-
malistic style. Then user feature is considered as a vital feature to
generate individualized prompts for different user groups. The tra-
ditional creative generation methods [19, 20, 32, 33, 46, 47] do not
consider the user information in generating creative image process.
Some works [16, 25, 39, 51] use another model to rank all generated
creatives considering user information and select the best one to
show online. These traditional pipelines do not maximize the online
performance because in first stage (generating creative stage), they
do not regard the improving CTR as the target, resulting in many
""bad"" creatives diluting the online impressions. So it is necessary
and critical to directly generate more attractive creatives by consid-
ering user information and regarding the CTR as an optimization
target in generating stage. Currently, several works [50, 52] focus
on enhancing the generation quality of diffusion models by rein-
forcement learning with human feedback. Although these methods
can generate creatives using diffusion models for a specific target,
such as CTR, they still face the problems of modifying the original
product with relatively low efficiency and diversity.
To guide the prompt model and LoRA model to generate more
attractive creatives, another Reward Model (RM) is used to predict
the Click-Through Rate (CTR) score for each creative image given
one product. For each product, if too many creatives are uploaded
online, it will lead to sub-optimal performance due to the inferior
performance of the generated creatives [25]. Then we need RM
to select the proper creatives for displaying online. At the same
time, RM can be used to generate samples (good creatives with high
predicted scores and bad creatives with low scores) to train LoRA
and prompt models.
To summarize, there are four contributions in this work: 1) The
inpainting mode in stable diffusion method is firstly applied to
creative image generation task in online advertising scene. A self-
cyclic generation pipeline is proposed to ensure the convergence
of training. 2) Prompt model is designed to generate individual-
ized creative images for different user groups, which can further
improve the diversity and quality of the generated creatives. 3)
Reward model comprehensively considers the multi-modal features
of image and text to improve the effectiveness of creative rank-
ing task, and it is also critical in self-cyclic generation pipeline. 4)
The significant benefits obtained in online and offline experiments
verify the significance of our proposed method.
2
RELATED WORKS
2.1
Text-to-image Generation
Recently, in text-to-image generation (T2I) task, more and more
deep learning models to generate image given text are emerging.
For example, the generative adversarial networks (GANs) [4, 6]
use a generator and a discriminator to generate image, where gen-
erator network is responsible for generating image and discrimi-
nator network is to distinguish the generated image and the real
one. There are some related GANs works, such as ProGAN [10],
StyleGAN [15, 17, 21], Projected GAN [28], VQGAN [30]. Different
from GANs, some autoencoder (AE) related works appear, such as
deep autoencoder [2], variational autoencoder (VAE) [3], vector
quantised-variational autoencoders (VQ-VAE) [9, 14]. The encoder
receives the input and encodes it in a latent space of a lower dimen-
sion while the decoder decodes this vector to produce the original
input.
As auto-regressive models developed in text generation recently,
a lot of works adopted this to achieve amazing results for T2I
generation, such as DALL-E 1-3 [31, 36, 45], CogView [22] and Pariti
[42]. Currently, the diffusion models (DM) [24, 37, 40] appeared
as SoTA T2I methods due to the natural fit to inductive biases
from image data. For example, GLIDE [24] uses an adequate text-
guidance strategy to generate and edit photorealistic image. Latent
DM [37] enables DM training on limited computational resources
while retaining the quality and flexibility by applying in latent space
of powerful pre-trained autoencoders. Imagen [40] directly diffuses
pixels using a pyramid structure without using latent images.
Recently, some works [19, 20, 32, 33, 35, 46, 47] study the task
of creative generation in the advertising scene. For example, [19]
automatically annotates the objects from the image and generates
optimal banner layout information. CapOnImage [32] generates
dense captions at different locations of the image by pre-training
and fine-tuning a multi-modal framework. CreaGAN [35] general-
izes to other product materials by utilizing existing design elements
(e.g., background material). Other works [33, 46, 47] generate lay-
out information of some elements, such as text and logo, given the
original image.
A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Different from the above methods, we propose a novel pipeline
for generating creatives in advertising scene. A stable diffusion
method is used in inpainting mode to generate only the background
pixels, while keeping the other pixels on the main product un-
changed. On the other hand, by introducing user information, we
can support individualized generation for various user group.
2.2
Creative CTR Prediction
Creative CTR prediction task is to rank all creative images pro-
vided by sellers or automatically generated by models, given one
product or advertisement. AMS [12] combines the behavior images
into modeling user preference in CTR prediction. PEAC [16] evalu-
ates and selects advertisement creatives offline before being placed
online. VAM [25] uses a visual-aware ranking model to order the
creatives according to their visual appearance. CACS [39] considers
the different image features in ranking stage to joint optimization
of intra-advertisement creative selection and inter-advertisement
ranking. CLIK [34] considers the topic of the given product to select
representatives from several images with intuitive visual informa-
tion by contrastive learning. [51] proposes a two-stage pipeline
method with content-based recall model and CTR-based ranking
model to find an appropriate image. Compared to these methods,
our proposed reward model performs better because of the multi-
modal structure and pre-training techniques.
3
METHODS
3.1
Pipeline
The pipeline is shown in Fig. 2 and the pseudo-code is shown in Alg.
1. In the creative generation pipeline, for each item, we first select
one original image with a relatively clean background provided
by sellers, which then is inputted into saliency model [38] to get
the saliency object image and mask image. We use Stable Diffusion
(SD) [37] method to generate the creatives given the saliency image,
LoRA model [27, 48] and prompts where LoRA model is fine-tuned
in our commercial data and prompts are selected by another prompt
model trained on online creative clicked data. The LoRA model and
prompt model are critical for the impact on generating creatives,
especially since different prompts can cause creatives to vary greatly.
To consistently generate good creatives, we need to fine-tune LoRA
model and prompt model in this pipeline. The details are described
in Section 3.2 and 3.3. Next, we use reward model (details in Section
3.4) to predict the CTR score for each generated creative, and only
top-k creatives are retained to further train LoRA model while
these top-k creatives are treated as positive samples and others are
treated as negative samples to train prompt model.
Last but not least, various users may have distinct preferences
on creatives. So we need to generate different types of creatives
for various users. Then user information is considered in prompt
model, although the input product or image is the same, the prompts
may need to be adjusted based on the characteristics of the user
group, and the resulting generated creatives can also be different.
To improve the quality and stability of the generated creative, the
LoRA model and prompt model are updated iteratively. Precisely,
in first step, only parameters in LoRA model are updated while
parameters in prompt model are fixed; in second step, parameters
in LoRA model are fixed while parameters in prompt model are
updated, ensuring the convergence of the entire framework.
Algorithm 1 Creative Generation Pipeline for CTR.
Input: 𝑀 is the number of items
𝑁 is the number of training epochs
𝜃𝑝 is the parameters of prompt model
𝜃𝑙 is the parameters of LoRA model
𝜃𝑟 is the parameters of reward model
𝜃𝑠 is the parameters of saliency model
𝜃𝑐 is the parameters of CLIP-Interrogator model
𝑝 is the number of tokens select by prompt model
𝑞 is the number of generated creative images
𝑘 is the number of images select by reward model
1: Initialization: 𝜃𝑝 and 𝜃𝑙 are trained on clicked data as the model pa-
rameters for initialization. Note that 𝜃𝑟 has been trained beforehand
while 𝜃𝑠 and 𝜃𝑐 are the public models, these three model parameters
are frozen in this pipeline.
2: for 𝑖 = 1 → 𝑁 do
3:
G, B = ∅, ∅, which refer to the set of good case and bad case, respec-
tively.
4:
for 𝑗 = 1 → 𝑀 do
5:
Get the original images of 𝑖𝑡𝑒𝑚𝑗 provided by seller
6:
Get saliency images and masked images by 𝜃𝑠
7:
Select top-𝑝 tokens as the appropriate prompt 𝑝𝑟𝑜𝑚𝑝𝑡𝑗 for 𝑖𝑡𝑒𝑚𝑗
by 𝜃𝑝 given user group feature
8:
Generate 𝑞 creative images for 𝑖𝑡𝑒𝑚𝑗 by 𝜃𝑙 given 𝑝𝑟𝑜𝑚𝑝𝑡𝑗
9:
Sort images by predicted CTR scores from 𝜃𝑟
10:
Select top-𝑘 images as positive samples and other images as nega-
tive samples
11:
Generate the prompt for each image by 𝜃𝑐
12:
Insert samples of (𝑖𝑡𝑒𝑚𝑗, 𝑖𝑚𝑎𝑔𝑒1, 𝑝𝑟𝑜𝑚𝑝𝑡1, 𝑠𝑐𝑜𝑟𝑒1), ... (𝑖𝑡𝑒𝑚𝑗,
𝑖𝑚𝑎𝑔𝑒𝑘, 𝑝𝑟𝑜𝑚𝑝𝑡𝑘, 𝑠𝑐𝑜𝑟𝑒𝑘) into G
13:
Insert samples of (𝑖𝑡𝑒𝑚𝑗, 𝑖𝑚𝑎𝑔𝑒𝑘+1, 𝑝𝑟𝑜𝑚𝑝𝑡𝑘+1, 𝑠𝑐𝑜𝑟𝑒𝑘+1), ...
(𝑖𝑡𝑒𝑚𝑗, 𝑖𝑚𝑎𝑔𝑒𝑞, 𝑝𝑟𝑜𝑚𝑝𝑡𝑞, 𝑠𝑐𝑜𝑟𝑒𝑞) into B
14:
end for
15:
if 𝑖 % 2 == 0 then
16:
Train prompt model 𝜃𝑝 given G and B by Equation 8
17:
else
18:
Train LoRA model 𝜃𝑙 given G by Equation 3
19:
end if
20: end for
Output: 𝜃𝑝 and 𝜃𝑙
3.2
LoRA Model in Stable Diffusion
As the original creatives designed by sellers may have quality and
quantity problems, we need to modify the images to a certain ex-
tent. Recently, a lot of works [18, 24, 36, 44] use diffusion models to
generate images, which uses a variational autoencoder (VAE) [3]
to operate the diffusion process in a low-dimensional latent space
with good computational efficiency. In detail, one image I is given
into an encoder 𝑉𝐴𝐸 to get the latent feature 𝑍, i.e., 𝑍 = 𝑉𝐴𝐸(𝐼).
A diffusion model is to denoise an input latent feature 𝑍𝑡 at each
timestep 𝑡 conditioned on a given prompt. During the training
process, for each timestep 𝑡, the diffusion denoising network 𝜀𝜃 is
optimized to remove the noise 𝜀 from the noised version of latent
code 𝑍𝑡 conditioned on prompt 𝑦 shown in following equation,
where 𝜏𝜃 is the CLIP [26] text encoder, 𝑦 is the given text or prompt,
𝜀 is the noise sampled according to a standard normal distribution.
The diffusion network 𝜀𝜃 often uses UNet [5] consisting of convo-
lution, self-attention and cross-attention layers. 𝑍𝑡 is the noised
embedding encoded by a scheduler in low-dimensional space with
VAE model given image 𝐼 and noise 𝜀. The scheduler is used to add
noise information into low-dimensional embedding from the given
image.
𝐿 = E𝑍∼𝑉 𝐴𝐸(𝐼 ), 𝑦, 𝜀∼𝑁 (0,1), 𝑡

||𝜀 − 𝜀𝜃 (𝑍𝑡,𝑡,𝜏𝜃 (𝑦)) ||2
2

, 𝑤ℎ𝑒𝑟𝑒
(1)
𝑍𝑡 = 𝑠𝑐ℎ𝑒𝑑𝑢𝑙𝑒𝑟 (𝑉𝐴𝐸(𝐼 ), 𝑡, 𝜀)
(2)
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng
Figure 2: (a) Creative generation pipeline. (b) The structure of prompt model. (c) The structure of reward model.
However, the standard SD method cannot be used in our pipeline
because it will modify the main product in advertising platform.
For example, the product image is a pair of shoes uploaded by a
seller, after the SD generating process, the generated image might
be a pair of socks or a hat, which is not accepted. To generate
one image with a higher quality while leaving the main content
of original product unchanged, we can get the pixels (referred as
𝐼𝑠𝑎𝑙) of the main product image 𝐼 by using the saliency detection
network [38]. The pre-trained saliency detection network can point
out the main product locations and then 𝐼𝑠𝑎𝑙 are masked and only
background pixels 𝐼𝑏𝑘𝑔 are generated by SD method in inpainting
mode [41]. The only difference between the inpainting mode and
normal mode in SD is that the inpainting mode concatenates the
low-dimensional embedding (𝑉𝐴𝐸(𝐼𝑠𝑎𝑙)) encoded by VAE given
masked pixels (Equation 4). The training loss is similar to the normal
mode.
𝐿 = E𝑍 ′∼𝑉 𝐴𝐸(𝐼, 𝐼𝑠𝑎𝑙 ), 𝑦, 𝜀∼𝑁 (0,1), 𝑡

||𝜀 − 𝜀𝜃 (𝑍 ′
𝑡,𝑡,𝜏𝜃 (𝑦))||2
2

, 𝑤ℎ𝑒𝑟𝑒
(3)
𝑍 ′
𝑡 = 𝑐𝑜𝑛𝑐𝑎𝑡 (𝑠𝑐ℎ𝑒𝑑𝑢𝑙𝑒𝑟 (𝑉𝐴𝐸(𝐼 ), 𝑡, 𝜀), 𝑉𝐴𝐸(𝐼𝑠𝑎𝑙 ))
(4)
Because of the difference in image distribution between our
commercial data and public data, we should fine-tune the public
SD model on our commercial data. However, it is very difficult to
fine-tune SD model because of huge number of parameters in SD
model, including UNet [5] and CLIP [26]. Low-Rank Adaptation
(LoRA) [27, 48] can help to solve the above problem, which allows
us to use low-rank adaptation technology to quickly fine-tune SD
model. With fine-tuned LoRA model, new creative image with a
generated background can be acquired by SD method given an
appropriate prompt.
We take Fig. 1 to explain the importance of the prompt and LoRA
in generating creative workflow. The original image of the product
given by seller is poor due to the simple colored background. To
improve the quality of this creative, firstly we get masked pixels
of the main product (e.g., skin care product) by saliency detection
model [38]. Given the original image and masked image, we use
SD method in inpainting mode to get better creatives with suitable
backgrounds. Of course, to explain the importance of prompt and
LoRA model in generating process, firstly we only use the SD
method without prompt and LoRA model, the results are not as
expected with mussy background same as the original image (three
upper images in Fig. 1). To improve the quality of background, we
can add a suitable prompt (e.g., product photo, petals, water flowers
etc.), and the results can be better (three middle images). Finally,
LoRA model is increased in generating process, the quality can be
further improved (three lower images).
A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
On the other hand, to distinguish the good and bad creatives
in generating process, a reward model is proposed to predict the
CTR, we only retain the good creatives with high CTRs to train
LoRA model. At the same time, the good creatives with prompts
generated by CLIP-Interrogator model2 are regarded as positive
samples and the bad ones are regarded as negative samples to
train prompt model. After multiple rounds of training processes,
the LoRA model and prompt model can improve the quality of
generated creatives and improve user experience.
3.3
Prompt Model
The target of the prompt model is to select several appropriate
words/tokens combined as one prompt, which can effectively de-
scribe the style of the image, and then input it into the stable diffu-
sion model to generate more appealing images.
The input of the prompt model consists of four parts: user at-
tributes (user age, user gender, etc.), item attributes (item ID, cate-
gory ID, etc.), contextual attributes (user’s device model, access time,
etc.), and tokens used for creative generation. The user attributes,
item attributes, and contextual attributes are referred as Query. The
output of the prompt model is the estimated CTR score for each
token in the whole word vocabulary3 under the given Query condi-
tions. The top-𝑝 tokens with the highest CTRs are selected, which
are assembled as a new prompt and it is then inputted into a stable
diffusion model to generate creative images.
The network architecture of the prompt model is illustrated in
sub-figure (b) of Fig. 2. On the Query side, user attributes, item
attributes, and contextual attributes are one-hot encodings and
then converted into corresponding embeddings through lookup
table. These three embeddings are concatenated into a query em-
bedding named 𝑒𝑚𝑏𝑞. Simultaneously, all tokens in the prompt gen-
erated from the creative image are multi-hot encodings and then
transformed into multiple embeddings named 𝑒𝑚𝑏∗𝑝 in the same
way. Then we send 𝑒𝑚𝑏∗𝑝 into transformers and a mean-pooling
layer to obtain one final embedding 𝑒𝑚𝑏𝑝 representing for the
prompt. These two embeddings, 𝑒𝑚𝑏𝑞 and 𝑒𝑚𝑏𝑝 are concatenated
and passed through DeepFM [8] to produce a final estimated score.
The prompts generated from the clicked creatives are regarded
as positive samples, and other prompts from non-clicked creatives
are treated as negative samples. This enables the model to select the
appropriate prompts that are likely to improve CTR under Query
conditions.
We train the prompt model under the cross-entropy loss function
using the clicked data, which we call this loss function as ""hard
loss"" (𝐿ℎ𝑎𝑟𝑑 in Equation 6). Additionally, to reduce the exploration
cost in creative generation, we utilize the output values from the
reward model as the soft labels for auxiliary training in self-cycling
in Fig 2. The final loss is a weighted sum of the hard loss and soft
loss, where 𝜆𝑝 is 0.1 in our experiments.
𝑝 = 𝑃𝑟𝑜𝑚𝑝𝑡𝑀𝑜𝑑𝑒𝑙 (𝑄𝑢𝑒𝑟𝑦, 𝑃𝑟𝑜𝑚𝑝𝑡 )
(5)
𝐿ℎ𝑎𝑟𝑑 = 𝐶𝐸𝐿𝑜𝑠𝑠 (𝑝, 𝑦)
(6)
𝐿𝑠𝑜𝑓 𝑡 = 𝐶𝐸𝐿𝑜𝑠𝑠 (𝑝, 𝑦𝑅𝑀 )
(7)
𝑃𝑟𝑜𝑚𝑝𝑡𝐿𝑜𝑠𝑠 = (1 − 𝜆𝑝 ) · 𝐿ℎ𝑎𝑟𝑑 + 𝜆𝑝 · 𝐿𝑠𝑜𝑓 𝑡
(8)
2CLIP-Interrogator model is at https://github.com/pharmapsychotic/clip-interrogator.
3We have collected item images provided by sellers and designers and run CLIP-
Interrogator to get the complete tokens, which are then post-processed, such as deleting
stop-words and entity nouns, to form the whole word vocabulary.
Furthermore, individualized prompts can be created for different
user groups based on user information, as different users may prefer
creatives with different styles. The generated creatives can enhance
user experience while reducing exploration costs. For example,
without considering user information, the prompt model may se-
lect and combine some normal tokens, such as ""minimalistic"" and
""translucent"". But for a teenager, better tokens may be ""electronic""
and ""translucent"" while for an old user, ""golden"" and ""minimalis-
tic"" may be more appropriate. The normal prompt combined with
""minimalistic"" and ""translucent"" might not be the favorite for either
user group, hence failing to meet the actual needs.
3.4
Reward Model
The structure of reward model is shown in sub-figure (c) of Fig. 2,
which is used to predict the CTRs of the creatives from the same
item generated by stable diffusion model. Each creative contains
title, image and caption where title of creative is the same as the
title of item. As the titles of all creatives are the same, the title
feature seems redundant for predicting CTR scores. To explain why
title feature is still important for this task, we use a multi-head
self-attention sub-module to compute the relationship between the
textual feature and visual feature of each creative. In detail, the
multi-head self-attention sub-module can learn the relationship
(e.g., similarity) between textual feature and visual feature, such
that the creative with a high similarity score may be predicted with
high CTR score. In addition, to make reward model to learn the
creative content better, the caption information is also used, which
is acquired by CLIP-Interrogator model. CLIP-Interrogator model
uses the image as input and outputs the textual caption to describe
the image.
The title and caption information of j-th creative for i-th item
are inputted into pre-trained BERT model [11] to extract textual
features, referred as 𝑡𝑗 and 𝑐𝑗, respectively (Equation 9). The pre-
trained Swin model [29] is used to extract visual feature (referred
as 𝑖𝑗) from image information (Equation 9). Both BERT model and
Swin model are pre-trained in our commercial data with token
mask loss and patch mask loss, respectively. In particular, BERT
model is further fine-tuned in our commercial clicked data [49].
Two fully-connected layers are used to reduce the dimension of
feature (Equation 10). To fusion the cross-model features and ex-
tract the relationship between textual and visual features, we use
transformers [7] to get self-attention features (Equation 11). The
fused title, image and caption features (𝑡𝑡
𝑗 , 𝑖𝑡
𝑗, 𝑐𝑡
𝑗) are concatenated
into final feature. Other two fully-connected layers are used to
predict the CTR score (𝑝𝑖
𝑗) of j-th creative for i-th item (Equation
12).
𝑡𝑗 = 𝐵𝐸𝑅𝑇 (𝑡𝑖𝑡𝑙𝑒𝑗 ), 𝑐 𝑗 = 𝐵𝐸𝑅𝑇 (𝑐𝑎𝑝𝑡𝑖𝑜𝑛𝑗 ), 𝑖𝑗 = 𝑆𝑤𝑖𝑛(𝑖𝑚𝑎𝑔𝑒𝑗 )
(9)
𝑡 𝑓
𝑗 = 𝐹𝐶𝑡 (𝑡𝑗 ),
𝑐𝑓
𝑗 = 𝐹𝐶𝑐 (𝑐 𝑗 ),
𝑖𝑓
𝑗 = 𝐹𝐶𝑖 (𝑖𝑗 )
(10)
𝑡𝑡
𝑗, 𝑐𝑡
𝑗, 𝑖𝑡
𝑗 = 𝑡𝑟𝑎𝑛𝑠𝑓 𝑜𝑟𝑚𝑒𝑟𝑠 (𝑡 𝑓
𝑗 , 𝑐𝑓
𝑗 , 𝑖𝑓
𝑗 )
(11)
𝑝𝑖
𝑗 = 𝐹𝐶𝑐𝑡𝑟 (𝑐𝑜𝑛𝑐𝑎𝑡 (𝑡𝑡
𝑗, 𝑐𝑡
𝑗, 𝑖𝑡
𝑗 ))
(12)
The target of reward model is to predict the CTR score of each
creative. The real CTR value is calculated by the following equation.
ˆ𝑦𝑖
𝑗 =
𝑐𝑙𝑖𝑐𝑘𝑖
𝑗
𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑖
𝑗
(13)
List-wise and point-wise loss functions are used to train reward
model. The list-wise loss function is shown in Equation 14 where ˆ𝑦𝑖
𝑗
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng
and 𝑝𝑖
𝑗 are the real CTR and predicted CTR, respectively. And 𝑤𝑖
𝑗 is
the sample impression weight of j-th creative for i-th item, shown in
Equation 15. Through the list-wise loss function, the model focuses
on ranking the creatives within the same item. Although the list-
wise loss function can lead model to correctly rank the creatives,
the absolute difference between the real and predicted scores may
be very huge. Then we use point-wise loss function as an auxiliary
function to enforce model to produce more accurate scores, as
shown in Equation 16.
𝐿𝑙𝑖𝑠𝑡 =
Í
𝑖 𝑤𝑖 · 𝐿𝑖
𝑙𝑖𝑠𝑡
Í
𝑖 𝑤𝑖
,
𝐿𝑖
𝑙𝑖𝑠𝑡 = −
∑︁
𝑗
ˆ𝑦𝑖
𝑗 · 𝑙𝑜𝑔(𝑝𝑖
𝑗 )
(14)
𝑤𝑖
𝑗 =
𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑖
𝑗
Í
𝑖
Í
𝑗 𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑖
𝑗
,
𝑤𝑖 =
∑︁
𝑗
𝑤𝑖
𝑗
(15)
𝐿𝑝𝑜𝑖𝑛𝑡 =
Í
𝑖 𝑤𝑖 · 𝐿𝑖
𝑝𝑜𝑖𝑛𝑡
Í
𝑖 𝑤𝑖
,
𝐿𝑖
𝑝𝑜𝑖𝑛𝑡 =
∑︁
𝑗
( ˆ𝑦𝑖
𝑗 − 𝑝𝑖
𝑗 )2
(16)
As shown in Equation 17, the final loss is the sum of list-wise
loss and point-wise loss, where 𝜆𝑟 is a hyperparameter and is 0.1
in our experiments.
𝑅𝑒𝑤𝑎𝑟𝑑𝐿𝑜𝑠𝑠 = (1 − 𝜆𝑟 ) · 𝐿𝑙𝑖𝑠𝑡 + 𝜆𝑟 · 𝐿𝑝𝑜𝑖𝑛𝑡
(17)
4
EXPERIMENTS
In this section, we evaluate our proposed generation pipeline on
online experiments. To validate the effectiveness of reward model,
we use commercial data and public data compared with two other
public methods. On the other hand, we make some ablation experi-
ments for prompt model to explain the importance of considering
user information. Finally, we perform some analyses and show some
cases to demonstrate the effectiveness of the self-cycling training
mode in our generation pipeline.
4.1
Online Results
We select five categories (including women shoes, women bags,
travel, beauty and mobile) in our commercial scene for online exper-
iments. For each item, the prompt model is used to select suitable
tokens in the whole vocabulary as one appropriate prompt consider-
ing user features. As different users may have varying preferences
for creatives, so we need to use prompt model to extract different
prompts based on the characteristics of users. Then 10 creatives
for each item are automatically generated by stable diffusion with
LoRA model given the selected prompts. These creatives are then
inputted into reward model to predict CTRs, and the top 5 creatives
with highest predicted CTRs are retained. These retained creatives
are regarded as training samples to further train LoRA model. To
further optimize the quality of generated creatives in the next step,
these retained creatives in current step are regarded as positive
samples and others are regarded as negative samples, which are
used to train prompt model. This can indirectly improve creative
quality by facilitating better prompts in subsequent steps. With ten
rounds of the above processes, top 5 creatives for each item are
generated and uploaded to online platform. We use Epsilon-greedy
[1, 13] as online display strategy.
As shown in Table 1, without the self-cycling training in our
pipeline (referred as ""w/o self-cycling"" in the table), we only use
the first versions of LoRA and prompt models to generate the cre-
atives. The CTR and revenue improvements are only 4.2% and 3.8%,
respectively. After using LoRA and prompt models with five rounds
Table 1: Online results.
Methods
All
Women
Shoes
Women
Bags
Travel
Beauty
Mobile
w/o
self-cycling
4.21/3.82
2.2/3.5
11.3/3.1
6.0/4.3
2.7/4.8
3.7/4.5
Middle 3
8.1/7.2
6.6/7.8
10.7/4.2
2.2/7.4
2.7/1.1
12.7/12.9
Ours
10.4/9.7
7.0/9.0
12.9/4.3 9.9/12.6 11.8/7.9 14.2/14.5
1 The first metric is CTR improvement compared with the baseline of using the
original image with percentage.
2 The second metric is revenue improvement with percentage.
3 ""Middle"" means the middle versions of prompt model and LoRA model in self-
cycling.
(referred as ""Middle"" in the table) and ten rounds (referred as ""Ours""
in the table) of training, the results become much better.
4.2
In-depth Analysis
4.2.1
Ablation Study on Reward Model. As described in METHODS
section, reward model plays a crucial role in the self-cycling training
process of generating creative pipeline. In reward model, we use
top-k CTR uplift to evaluate the performance. The top-k CTR uplift
metric is calculated as follows:
𝐶𝑇𝑅-𝑢𝑝𝑙𝑖𝑓 𝑡𝑘 =
𝐶𝑇𝑅-𝑠𝑐𝑜𝑟𝑒𝑘
𝐶𝑇𝑅-𝑠𝑐𝑜𝑟𝑒𝑏𝑎𝑠𝑒
− 1
(18)
𝐶𝑇𝑅-𝑠𝑐𝑜𝑟𝑒𝑘 =
Í
𝑖
Í
𝑗 ∈𝑡𝑜𝑝𝑘𝑖𝐶 𝑐𝑙𝑖𝑐𝑘 𝑗
𝑖
Í
𝑖
Í
𝑗 ∈𝑡𝑜𝑝𝑘𝑖𝐶 𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑗
𝑖
(19)
𝐶𝑇𝑅-𝑠𝑐𝑜𝑟𝑒𝑏𝑎𝑠𝑒 =
Í
𝑖
Í
𝑗 ∈𝐶 𝑐𝑙𝑖𝑐𝑘 𝑗
𝑖
Í
𝑖
Í
𝑗 ∈𝐶 𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑗
𝑖
(20)
, where𝐶𝑇𝑅-𝑠𝑐𝑜𝑟𝑒𝑘 is the cumulative CTR scores of top-k creatives
with the highest scores predicted by reward model for each item.
𝑐𝑙𝑖𝑐𝑘 𝑗
𝑖 and 𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑗
𝑖 are the numbers of clicks and impressions
of j-th creative for i-th item. 𝑡𝑜𝑝𝑘𝑖𝐶 is the set of top-k creatives for
the i-th item. If 𝐶𝑇𝑅-𝑢𝑝𝑙𝑖𝑓 𝑡𝑘 metric is higher, the performance of
the reward model is better. The high top-𝑘 CTR uplift metrics only
ensure that the order of outputs is good, so we use another MSE
metric to measure the difference between the predicted CTRs and
real ones as follows:
𝑀𝑆𝐸 = 1
𝑛
𝑛
∑︁
𝑖=1
1
𝑚𝑖
𝑚𝑖
∑︁
𝑗=1
( ˆ𝑦𝑖
𝑗 − 𝑝𝑖
𝑗 )2
(21)
, where 𝑛 is the number of items and 𝑚𝑖 is the number of creatives
in 𝑖-th item.
The commercial data and public data4 [25] are tested to demon-
strate the effectiveness of our proposed reward model structure.
The commercial data has 1.0M creatives from 286k items. Each cre-
ative has item title, image, caption (generated by CLIP-Interrogator),
real click and real impression. Creatives from the 5% of items are
randomly sampled as the testing data while the others are training
data. The public data contains 1.7M creatives from 500k items. As
there is no title information in public data, we average the image
features of creatives from the same item as the title feature.
The BERT and Swin in reward model are pre-trained on text
information (title and caption) and image information with token
mask loss and patch mask loss, respectively. Then in training reward
model process, the parameters of BERT and Swin are fixed to speed
up. We use adam optimizer with mini-batch of 2048 and learning
rate of 5e-4. The number of epochs is set 30.
4The public data is at https://tianchi.aliyun.com/dataset/93585.
A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Table 2: Ablation study on reward model.
Type
Details
Commercial data
Public data
Top-1 ↑
Top-2 ↑
Top-3 ↑
Top-4 ↑
Top-5 ↑
MSE ↓
Top-1 ↑
Top-2 ↑
Top-3 ↑
MSE ↓
Public methods
VAM [25]
18.01%
11.92%
6.59%
2.81%
1.72%
2.518
6.26%
3.80%
1.23%
3.544
Rank [51]1
19.87%
10.68%
5.51%
3.07%
1.71%
2.615
7.32%
4.60%
1.70%
3.545
Fuse input
information
Only image
18.32%
13.62%
6.44%
3.22%
2.06%
2.314
9.07%
5.66%
2.23%
3.135
Image and title2
22.26%
13.44%
7.21%
3.86%
2.52%
2.300
10.99%
6.91%
2.65%
3.094
Image and caption
21.59%
12.99%
7.49%
3.69%
2.58%
2.404
9.91%
6.22%
2.31%
3.103
w/o transformers
21.29%
11.32%
6.50%
2.90%
1.79%
2.145
11.20%
6.61%
2.56%
3.057
Pre-train
w/o pre-train
21.05%
13.77%
7.53%
4.02%
2.51%
2.263
10.91%
6.64%
2.60%
3.250
Only pre-train BERT
20.92%
13.36%
7.53%
4.54%
3.20%
2.060
10.51%
6.44%
2.60%
3.433
Only pre-train Swin
22.08%
13.75%
6.63%
3.98%
2.41%
2.198
11.05%
6.61%
2.64%
3.132
Loss
Only list-wise
21.91%
12.85%
5.69%
2.64%
2.51%
2.424
10.66%
6.53%
2.59%
3.231
Only point-wise
21.35%
14.06%
7.44%
3.86%
2.60%
2.111
10.81%
6.64%
2.66%
3.058
-
Ours
23.81%
13.84%
7.56%
4.79%
3.29%
2.052
11.29%
7.00%
2.76%
3.047
1 As rank model uses entity textual knowledge and entity image knowledge while this information does not exist in the public data and commercial data, then we delete
these input features to compare.
2 As there is no title information in public data, we use the averaged image features to simulate the title feature.
Table 3: Ablation study on prompt model.
Type
Details
Historical CTR1
CTR
Revenue
User ablation
w/o user
9.4%
7.2%
6.9%
Individuation
12.5%
10.4%
9.7%
Model
structure
w/o transformer
10.9%
-2
-
w/o DeepFM
11.7%
-
-
Ours
12.5%
-
-
1 This is an offline metric, it is the historical CTR improvement given the clicked
data. In detail, we can calculate the cumulative CTR improvements of top-𝑘 tokens.
2 Model structure experiments are not performed online, and so only the offline
metric of ""Historical CTR"" is shown.
We tested two public methods, including VAM [25] and Rank
[51]. On the commercial data, the top-1 to top-5 CTR uplift scores
of our proposed method are much higher than VAM and Rank
while the MSE metric of the proposed method is smaller than other
methods. We have similar results on the public data. In the reward
model, we use title, image and caption information to predict the
CTR scores. To demonstrate that the title and caption information is
also helpful for this task, this information is deleted in the original
network. As shown in Table 2, only considering the image feature
to predict the CTR, the results are not good. Simply concatenat-
ing three multi-modal features without transformers can improve
the CTR ranking effect, but the improvement is limited. Fusing
transformers can further improve the results, which verifies the
effectiveness of combining different types of input information and
using transformers to extract the multi-model feature.
In our proposed method, we have pre-trained BERT and Swin
models with mask loss on corresponding data. As shown in this
table, the results without pre-training are slightly inferior to our
results, which verifies the importance of pre-training. Lastly, we
have tested the effects of the loss functions. The results show that
both list-wise and point-wise loss functions are useful for improving
the results.
4.2.2
Ablation Study on Prompt Model. This section will show the
ablation study of the prompt model. We use online clicked data to
train the prompt model, with 20M samples as training data and 2M
samples as testing data. Each sample has an average of 8.5 tokens.
We employ Adam as the optimizer, set the learning rate to 1e-3, and
train the model in 2 epochs to avoid overfitting with a batch size of
2048. The parameter of prompt model trained in this clicked data
Figure 3: (a) Word cloud analysis of generated tokens by
prompt models without and with considering user infor-
mation. (b) The creatives generated by different versions of
LoRA and prompt models are scored by reward model to
show the effectiveness of self-cycling training process.
is initialized as the first version of prompt model in self-cycling
training process.
We perform two experiments to severally explain the advantage
of importing the user group information and the improvements
of prompt model in self-cycling training process. In the fusing
user group information experiment, the user group information is
deleted in prompt model in both training (in self-cycling training
mode) and testing processes, the CTR and revenue improvements
are both limited (Table 3). To further improve the results, we import
the user groups information. In detail, for each item, all user groups
are enumerated, and one best prompt is selected for each user group
by prompt model. Assuming that there are 5 creatives for each item
without user information, after introducing user features, there are
5 × 𝑢 creatives where 𝑢 refers to the number of user groups. In on-
line display strategy, we select the corresponding 5 creatives with
the same user group as the current user for personalized creative
recommendation. As shown in this table, the metrics in ""individ-
uation"" have great improvements. In addition, we collected the
tokens generated by prompt model to perform the word cloud anal-
ysis (Fig. 3(a)). After considering the user group information (e.g.,
younger and elder), the generated tokens are more ""individualized""
where younger users prefer ""electronic"" and ""realistic"" while elder
users prefer ""pure"" and ""minimal"". This phenomenon illustrates that
prompt model can learn the fact that different user groups have
various preferences for diverse tokens.
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng
Figure 4: Cases with the original image and generated creatives in different steps of self-cycling. Bottom score is the real CTR.
In another experiment of self-cycling training, we compare the
results of the first version and last version of prompt model (Table
1). After self-cycling training, the final version of prompt model has
higher metrics which further verifies the necessity of self-cycling.
Lastly, we find that the transformers and DeepFM sub-modules in
prompt model are also helpful with good historical CTR improve-
ments.
4.2.3
Self-cycling Analysis. In previous section, we have already
demonstrated the effectiveness of reward model on commercial and
public data. Then we can use reward model to offline analyze the
performances of LoRA and prompt models in self-cycling training
process. As shown in Fig. 3(b), the reward scores of generated
creatives increase during self-cycling training, demonstrating the
effectiveness of our proposed training process.
4.3
Case Study
Lastly, we will show some amazing cases to validate the effec-
tiveness of our proposed creative generation pipeline (Fig. 4). The
aesthetics and harmony of creatives generated by our proposed
method are much better than the original image provided by seller.
5
DISCUSSION
A new automated Creative Generation pipeline for Click-Through
Rate (CG4CTR) is proposed to fuse the CTR target into the creative
generation task. In CG4CTR, we first use inpainting mode in dif-
fusion method to generate the creative image in advertising scene.
The generation process is carried out by self-cycling, where the
prompt model and LoRA model are updated alternately and itera-
tively. As the traditional creative generation methods do not use the
CTR as the target, some bad creatives with poor CTR performance
may be generated, leading to sub-optimal online results. To solve
this problem, we fuse the CTR target in CG4CTR and consider user
information in prompt model to select the appropriate prompt and
indirectly generate individualized creatives. In self-cycling, we need
the reward model to judge which creatives are good and which
ones are bad, and then it can help to further improve the quality of
generated creatives. Both offline and online experiments show that
CG4CTR can generate better creatives with higher CTR compared
with the original images provided by sellers.
Our proposed CG4CTR pipeline can be inserted at different
stages of the item recommendation. Specifically, if CG4CTR is in-
serted after the item recommendation (named A-stage), for one
user comes, candidate items are ranked by the ranking model, then
the top items are used for CG4CTR to generate creatives for each
item. In A-stage, the ranking model can only consider the original
image rather than creative image, leading to the reduced perfor-
mance. If CG4CTR is inserted before the item recommendation
(named B-stage), the creatives for all candidate items are generated
by CG4CTR, then ranking model can simultaneously consider both
item information and creative information to sort them, which may
have better performance but also need higher online time consum-
ing. In future work, we will explore the difference in performance
between these two stages. Furthermore, we can employ various
A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
styles of LoRA models (rather than one LoRA in CG4CTR) to gen-
erate creatives with enhanced styles and superior quality, where
these styles can be provided by designers as initial samples to train
LoRA model, and then their parameters are updated in self-cycling
training mode. Lastly, more ways to generate creatives rather than
modifying the background need to be investigated in the same
framework.
REFERENCES
[1] Christopher John Cornish Hellaby Watkins. 1989. Learning from delayed rewards.
(1989).
[2] Geoffrey E Hinton and Ruslan R Salakhutdinov. 2006. Reducing the dimensional-
ity of data with neural networks. science 313, 5786 (2006), 504–507.
[3] Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes.
arXiv preprint arXiv:1312.6114 (2013).
[4] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial
nets. Advances in neural information processing systems 27 (2014).
[5] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolu-
tional networks for biomedical image segmentation. In Medical Image Computing
and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference,
Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. Springer, 234–241.
[6] Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele,
and Honglak Lee. 2016. Generative adversarial text to image synthesis. In Inter-
national conference on machine learning. PMLR, 1060–1069.
[7] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[8] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.
DeepFM: a factorization-machine based neural network for CTR prediction. arXiv
preprint arXiv:1703.04247 (2017).
[9] Aaron Van Den Oord, Oriol Vinyals, et al. 2017. Neural discrete representation
learning. Advances in neural information processing systems 30 (2017).
[10] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. 2017. Progressive
growing of gans for improved quality, stability, and variation. arXiv preprint
arXiv:1710.10196 (2017).
[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:1810.04805 (2018).
[12] Tiezheng Ge, Liqin Zhao, Guorui Zhou, Keyu Chen, Shuying Liu, Huimin Yi,
Zelin Hu, Bochao Liu, Peng Sun, Haoyu Liu, et al. 2018. Image matters: Visually
modeling user behaviors using advanced model server. In Proceedings of the
27th ACM International Conference on Information and Knowledge Management.
2087–2095.
[13] Vincent François-Lavet, Peter Henderson, Riashat Islam, Marc G Bellemare, Joelle
Pineau, et al. 2018. An introduction to deep reinforcement learning. Foundations
and Trends® in Machine Learning 11, 3-4 (2018), 219–354.
[14] Ali Razavi, Aaron Van den Oord, and Oriol Vinyals. 2019. Generating diverse
high-fidelity images with vq-vae-2. Advances in neural information processing
systems 32 (2019).
[15] Tero Karras, Samuli Laine, and Timo Aila. 2019. A style-based generator ar-
chitecture for generative adversarial networks. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition. 4401–4410.
[16] Zhichen Zhao, Lei Li, Bowen Zhang, Meng Wang, Yuning Jiang, Li Xu, Fengkun
Wang, and Weiying Ma. 2019. What you look matters? offline evaluation of
advertising creatives for cold-start problem. In Proceedings of the 28th ACM
international conference on information and knowledge management. 2605–2613.
[17] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
Timo Aila. 2020. Analyzing and improving the image quality of stylegan. In
Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.
8110–8119.
[18] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilistic
models. Advances in neural information processing systems 33 (2020), 6840–6851.
[19] Sreekanth Vempati, Korah T Malayil, V Sruthi, and R Sandeep. 2020. Enabling
hyper-personalisation: Automated ad creative generation and ranking for fashion
e-commerce. In Fashion Recommender Systems. Springer, 25–48.
[20] Shaunak Mishra, Manisha Verma, Yichao Zhou, Kapil Thadani, and Wei Wang.
2020. Learning to create better ads: Generation and ranking approaches for ad
creative refinement. In Proceedings of the 29th ACM international conference on
information & knowledge management. 2653–2660.
[21] Tero Karras, Miika Aittala, Samuli Laine, Erik Härkönen, Janne Hellsten, Jaakko
Lehtinen, and Timo Aila. 2021. Alias-free generative adversarial networks. Ad-
vances in Neural Information Processing Systems 34 (2021), 852–863.
[22] Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da Yin,
Junyang Lin, Xu Zou, Zhou Shao, Hongxia Yang, et al. 2021. Cogview: Mastering
text-to-image generation via transformers.
Advances in Neural Information
Processing Systems 34 (2021), 19822–19835.
[23] Prafulla Dhariwal and Alexander Nichol. 2021. Diffusion models beat gans on
image synthesis. Advances in neural information processing systems 34 (2021),
8780–8794.
[24] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
Bob McGrew, Ilya Sutskever, and Mark Chen. 2021. Glide: Towards photorealistic
image generation and editing with text-guided diffusion models. arXiv preprint
arXiv:2112.10741 (2021).
[25] Shiyao Wang, Qi Liu, Tiezheng Ge, Defu Lian, and Zhiqiang Zhang. 2021. A
hybrid bandit model with visual priors for creative ranking in display advertising.
In Proceedings of the web conference 2021. 2324–2334.
[26] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al. 2021. Learning transferable visual models from natural language supervision.
In International conference on machine learning. PMLR, 8748–8763.
[27] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large
language models. arXiv preprint arXiv:2106.09685 (2021).
[28] Axel Sauer, Kashyap Chitta, Jens Müller, and Andreas Geiger. 2021. Projected
gans converge faster. Advances in Neural Information Processing Systems 34 (2021),
17480–17492.
[29] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin,
and Baining Guo. 2021. Swin transformer: Hierarchical vision transformer us-
ing shifted windows. In Proceedings of the IEEE/CVF international conference on
computer vision. 10012–10022.
[30] Patrick Esser, Robin Rombach, and Bjorn Ommer. 2021. Taming transformers
for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on
computer vision and pattern recognition. 12873–12883.
[31] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-shot text-to-image generation.
In International Conference on Machine Learning. PMLR, 8821–8831.
[32] Yiqi Gao, Xinglin Hou, Yuanmeng Zhang, Tiezheng Ge, Yuning Jiang, and Peng
Wang. 2022. Caponimage: Context-driven dense-captioning on image. arXiv
preprint arXiv:2204.12974 (2022).
[33] Min Zhou, Chenchen Xu, Ye Ma, Tiezheng Ge, Yuning Jiang, and Weiwei Xu.
2022. Composition-aware graphic layout GAN for visual-textual presentation
designs. arXiv preprint arXiv:2205.00303 (2022).
[34] Jihyeong Ko, Jisu Jeong, and Kyumgmin Kim. 2022. Contrastive Learning for
Topic-Dependent Image Ranking. In Workshop on Recommender Systems in Fash-
ion and Retail. Springer, 79–98.
[35] Shiyao Wang, Qi Liu, Yicheng Zhong, Zhilong Zhou, Tiezheng Ge, Defu Lian, and
Yuning Jiang. 2022. CreaGAN: An Automatic Creative Generation Framework
for Display Advertising. In Proceedings of the 30th ACM International Conference
on Multimedia. 7261–7269.
[36] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
2022. Hierarchical text-conditional image generation with clip latents. arXiv
preprint arXiv:2204.06125 1, 2 (2022), 3.
[37] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn
Ommer. 2022. High-resolution image synthesis with latent diffusion models. In
Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.
10684–10695.
[38] Xuebin Qin, Hang Dai, Xiaobin Hu, Deng-Ping Fan, Ling Shao, and Luc Van Gool.
2022. Highly accurate dichotomous image segmentation. In European Conference
on Computer Vision. Springer, 38–56.
[39] Kaiyi Lin, Xiang Zhang, Feng Li, Pengjie Wang, Qingqing Long, Hongbo Deng,
Jian Xu, and Bo Zheng. 2022. Joint Optimization of Ad Ranking and Creative Se-
lection. In Proceedings of the 45th International ACM SIGIR Conference on Research
and Development in Information Retrieval. 2341–2346.
[40] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L
Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim
Salimans, et al. 2022. Photorealistic text-to-image diffusion models with deep
language understanding. Advances in Neural Information Processing Systems 35
(2022), 36479–36494.
[41] Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin, Anastasia Remizova,
Arsenii Ashukha, Aleksei Silvestrov, Naejin Kong, Harshith Goka, Kiwoong Park,
and Victor Lempitsky. 2022. Resolution-robust large mask inpainting with fourier
convolutions. In Proceedings of the IEEE/CVF winter conference on applications of
computer vision. 2149–2159.
[42] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang,
Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al. 2022.
Scaling autoregressive models for content-rich text-to-image generation. arXiv
preprint arXiv:2206.10789 2, 3 (2022), 5.
[43] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.
Training language models to follow instructions with human feedback. Advances
in Neural Information Processing Systems 35 (2022), 27730–27744.
Conference acronym ’XX, June 03–05, 2018, Woodstock, NY
Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng
[44] Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao,
Chunyuan Li, and Yong Jae Lee. 2023. Gligen: Open-set grounded text-to-image
generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition. 22511–22521.
[45] James Betker, Gabriel Goh, and et.al. Jing. 2023. Improving image generation
with better captions. Computer Science. https://cdn. openai. com/papers/dall-e-3.
pdf (2023).
[46] Naoto Inoue, Kotaro Kikuchi, Edgar Simo-Serra, Mayu Otani, and Kota Yamaguchi.
2023. LayoutDM: Discrete Diffusion Model for Controllable Layout Generation. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.
10167–10176.
[47] Leigang Qu, Shengqiong Wu, Hao Fei, Liqiang Nie, and Tat-Seng Chua. 2023.
LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Genera-
tion. arXiv preprint arXiv:2308.05095 (2023).
[48] Simo Ryu. 2023. Low-rank adaptation for fast text-to-image diffusion fine-tuning.
[49] Hao Yang, Ziliang Wang, Weijie Bian, and Yifan Zeng. 2023. Practice on Effectively
Extracting NLP Features for Click-Through Rate Prediction. In Proceedings of the
32nd ACM International Conference on Information and Knowledge Management.
4887–4893.
[50] Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, and Sergey Levine.
2023. Training diffusion models with reinforcement learning. arXiv preprint
arXiv:2305.13301 (2023).
[51] Sheng You, Chao Wang, Baohua Wu, Jingping Liu, Quan Lu, Guanzhou Han,
and Yanghua Xiao. 2023. What Image do You Need? A Two-stage Framework
for Image Selection in E-commerce. In Companion Proceedings of the ACM Web
Conference 2023. 452–456.
[52] Zhiwei Tang, Dmitry Rybin, and Tsung-Hui Chang. 2023. Zeroth-Order Opti-
mization Meets Human Feedback: Provable Learning via Ranking Oracles. arXiv
preprint arXiv:2303.03751 (2023).
"
"This research explores cryptocurrency staking reward prediction, offering insights to researchers and investors. Two methods are investigated: a sliding-window average and linear regression models. Results show ETH staking rewards can be forecasted with an RMSE within 0.7% and 1.1% for 1-day and 7-day look-aheads using a 7-day sliding-window average. Prediction accuracies vary across cryptocurrencies, with linear regression superior for short-term XTZ and ATOM predictions. Staking rewards are stable for most assets, except MATIC.nan","Staking in cryptocurrency involves users locking digital assets to participate in a blockchain's consensus mechanism, earning rewards. Various platforms have staking processes and reward determination methods. Staking rewards depend on factors like the amount of cryptocurrency staked, staking duration, inflation rates, and network transaction fees.nan","Prior research has explored staking-related topics, such as optimal staking problems, equilibrium staking levels, and rewards farming. Other studies have focused on staking pools and centralization concerns. However, forecasting staking rewards has not been previously explored.nannan","The study utilized two forecasting algorithms: moving-window average and linear regression models. The moving-window average calculates an average of past data points to predict future values. Linear regression involves creating a linear relationship between an explanatory variable and the dependent variable. The objective was to develop a model to forecast staking rewards for various cryptocurrencies for a specified number of upcoming days. Data was collected from 2021-06-23 to 2022-08-06, and a training and test data splitting strategy was employed to optimize model performance.nan","For next-day prediction, moving-window average and single-feature linear regression performed similarly for ETH, with RMSE divided by the mean ranging from 0.007 to 0.009. Linear regression outperformed moving-window average and multiple linear regression for ATOM and XTZ. Moving-window average performed best for SOL and MATIC. For next N-days prediction, moving-window average outperformed other methods for all tokens except MATIC. The effectiveness of ML algorithms decreased as prediction days increased, and a 7-day ahead prediction using moving-window average had an increased error of no more than 3.2% compared to a 1-day ahead prediction. Simple linear regression based on staking rewards time series alone outperformed multiple linear regression using other features.nan","The study demonstrates the effectiveness of simple linear regression and moving-window average in predicting staking rewards. A 7-day moving-window average approach provides accurate predictions for most tokens, except MATIC, with an RMSE within 0.7% and 1.1% for 1-day and 7-day look-aheads. Prediction accuracies vary across cryptocurrencies, with linear regression superior for short-term XTZ and ATOM predictions. Staking rewards are stable for most assets, except MATIC, presenting a notable exception.nan",Forecasting Cryptocurrency Staking Rewards,"Sauren Gupta, Apoorva Hathi Katharaki, Yifan Xu, Bhaskar Krishnamachari, Rajarshi Gupta","Forecasting Cryptocurrency Staking Rewards
Sauren Gupta∗, Apoorva Hathi Katharaki†, Yifan Xu, Bhaskar Krishnamachari‡, Rajarshi Gupta
Machine Learning Team, Coinbase
Abstract: This research explores a relatively unexplored area of predicting cryp-
tocurrency staking rewards, offering potential insights to researchers and investors.
We investigate two predictive methodologies: a) a straightforward sliding-window
average, and b) linear regression models predicated on historical data. The findings
reveal that ETH staking rewards can be forecasted with an RMSE within 0.7% and
1.1% of the mean value for 1-day and 7-day look-aheads respectively, using a 7-day
sliding-window average approach. Additionally, we discern diverse prediction
accuracies across various cryptocurrencies, including SOL, XTZ, ATOM, and
MATIC. Linear regression is identified as superior to the moving-window average
for perdicting in the short term for XTZ and ATOM. The results underscore the
generally stable and predictable nature of staking rewards for most assets, with
MATIC presenting a noteworthy exception.
1
Introduction
Staking, within the context of cryptocurrency, is a mechanism wherein holders of specific digital
currencies, such as Ethereum or others utilizing a proof-of-stake (PoS) model, earn rewards by actively
engaging in transaction validation on a blockchain while they continue to hold on to their assets
[1, 2]. In essence, staking involves dedicating a specified quantity of cryptocurrency assets to fortify
a blockchain network, subsequently facilitating the verification of transactions. Contrasting with
proof-of-work (PoW) systems, where computational power is crucial for transaction verification and
block generation, a PoS model entrusts validation to stakers [3, 2]. These participants willingly lock
a predetermined quantity of the network’s currency as collateral. Stakers, in turn, are selected—often
proportionally to their staked amount—to validate transactions and introduce new blocks to the
blockchain [4]. Engaging in staking not only allows individuals to earn rewards for strengthening
the network but also augments their cryptocurrency holdings, thus offering an enticing incentive to
procure and retain the cryptocurrency, thereby enhancing its overall security and stability [4].
Many digital currency networks, like ETH, Cosmos, Tezos, Algorand, Cardano, and Solana, give
rewards to users who agree to lock up (""stake"") their digital tokens for a set time [5, 6]. This is an
incentive for users and it also makes the network more secure. For platforms that manage digital
currencies and blockchain networks, staking can also make customers more loyal because it creates a
kind of attachment or ""stickiness.""
The rewards allocated for staking are subject to change, contingent upon various factors such as the
number of participants staking, the maturity of the project, prevailing market conditions, among others
[7]. This inherent variability and unpredictability in the rewards offered for staking cryptocurrencies
pose a multifaceted challenge. Various entities that invest, encompassing individual investors, institu-
tional investors, and platforms managing digital assets, may find predictive information regarding
future staking rewards beneficial. This could assist them in determining optimal times to stake or
un-stake their assets within a specific network.
∗The contributions of Sauren Gupta to this work were made during his tenure as an intern at Coinbase.
†Corresponding author. Email: apoorva.hathi@coinbase.com
‡Dr. Bhaskar Krishnamachari is a paid consultant for Coinbase and has contributed to this paper in this
capacity.
arXiv:2401.10931v1  [q-fin.ST]  16 Jan 2024
The solution we propose in the paper involves the application of predictive models to forecast the
staking rewards of a variety of cryptocurrencies. Our approach is predicated on the assumption that
historical trends and patterns in staking rewards can provide valuable insights into future performance.
Two predictive approaches have been considered in this context, sliding-window average and linear
regression. Sliding-window average essentially involves computing the mean rewards over a specified
time window, which is a straightforward and intuitive method that can provide a quick snapshot of
the trend in staking rewards. However, it is important to note that this method assumes that the future
will mirror the past, which may not always be the case, particularly in the volatile and unpredictable
world of cryptocurrencies. Linear regression is an effective predictive model that can capture more
complex patterns in the data. It assumes a linear relationship between the independent and dependent
variables, which may not always hold true. However, with careful feature selection and model tuning,
linear regression can provide robust and reliable predictions. While more sophisticated models such
as LSTM [8] could be used for time-series prediction, we have limited ourselves to these simpler
models because they already show good performance, as the results show. Despite extensive research
in the field of cryptocurrency, there is a noticeable gap in the literature regarding the prediction
of staking rewards. This study aims to fill this gap by exploring this under-researched area. By
employing straightforward but efficient predictive models, this research seeks to provide insights into
the predictability of staking rewards across various cryptocurrencies. The findings of this study could
potentially provide valuable data for stakeholders and investors, aiding them in making informed
staking decisions.
Our study shows that the sliding-window average method is effective in predicting Ethereum (ETH)
staking rewards, with a Root Mean Square Error (RMSE) of 0.7% for a 1-day forecast and less than
1.1% for a 7-day forecast.This method surprisingly surpasses linear regression models in predicting
staking rewards for this specific asset. However, for cryptocurrencies such as Tezos (XTZ) and
Cosmos (ATOM), linear regression models proved to be more effective than the sliding-window
average method in predicting staking rewards. The effectiveness of the sliding-window average and
linear regression models was assessed by calculating the RMSE between the actual and predicted
staking rewards over different forecast periods (1-day and 7-days). Additionally, the performance of
these models was evaluated across various cryptocurrencies (ETH, SOL, XTZ, ATOM, and MATIC),
offering a comprehensive view of their applicability and efficiency. The findings of this study reveal a
diverse range of predictive accuracy across various cryptocurrencies. In particular, the sliding-window
average model exhibits a strong predictive capacity for Ethereum (ETH). Conversely, Tezos (XTZ)
and Cosmos (ATOM) demonstrate a higher forecasting proficiency when utilizing linear regression
models for short term. A common trend across the majority of assets is the formation of slow-varying
and moderately predictable time series in staking rewards. However, Polygon (MATIC) deviates from
this pattern, displaying notably erratic rewards patterns.
In summary, our study consists of the following highlights:
• Application of ML techniques for accurate staking rewards predictions across multiple assets, with
remarkable precision for short-term and long-term forecasts.
• Demonstrated good performance of simple models like averaging historical rewards and linear
regression for cryptocurrency staking rewards forecasting.
2
Related Works
There has been prior research work exploring various aspects of staking of cryptocurrencies. For
example, Choi et al. [9] formulate an optimal staking problem in which they explore tradeoffs between
rewards and illiquidity. John et al. [7] analyze equilibrium staking levels and show that staking levels
may not always be increasing in block rewards. Xu and Feng [10] provide a general survey of rewards
farming in DeFi including considerations of staking as one of the components of rewards farming.
Some of this research has focused specifically on staking pools and concerns about centralization.
For instance, He et al. [11] explore the question of staking centralization and conditions under which
a stable equilibrium exists for staking pools; and Gersbach et al. [12] model the formation of staking
2
pools in the presence of malicious adversaries. To our knowledge the research literature on staking
has not previously explored the problem of forecasting staking rewards, the focus of this paper.
While there has been decades of research on forecasting financial time series [13], in particular stock
prices [14], over the past decade there has also been a lot of prior work on modeling and forecasting
cryptocurrency prices and the volatility of their prices. Kyriazis et al. [15] present a survey of
modeling the “bubble” dynamics of cryptocurrency prices. Khedr et al. [16] and Amirzadeh et al.
[17] present a survey of applications of artificial intelligence and machine learning to cryptocurrency
price and volatility prediction. This literature has explored a number of different machine learning
models for predictions. For example, Mudassir et al. [18] explore ML-based time-series forecasting
of Bitcoin prices using high-dimensional features. Hamayel and Owda [19] consider the use of
LSTM models for cryptocurrency price prediction. Derbentsev et al. [20] present a comparative study
of different ML prediction algorithms. D’Amato et al. [21] present application of deep learning to
predict the volatility of cryptocurrencies.
Our work adds a new dimension to the above literature on application of machine learning methods
to predictions in the context of cryptocurrencies by exploring staking rewards as the focus of the
predictions. We find that in this work that in contrast to the high volatility of cryptocurrency prices
which has been the primary focus of prior work, staking rewards are relatively slower-moving and
simpler time series, and consequently, relatively simpler ML models show good performance.
3
Background: Stacking and rewards
Staking is a fundamental concept in the realm of cryptocurrencies, allowing users to participate in a
network’s operations while receiving rewards. It’s essential to understand that different platforms
have varied approaches and rules governing their staking processes, particularly in how the staking
rewards are determined. Here’s a general breakdown:
3.1
How Staking Works
Staking involves users, or ""stakers,"" holding and locking up a cryptocurrency in a wallet to participate
in the network’s consensus mechanism, typically Proof of Stake (PoS) or its variants. By doing this,
stakers help secure the network, validate transactions, and maintain the blockchain’s overall integrity.
In return, they receive staking rewards, usually in the form of cryptocurrency.
3.2
Determining rewards
Rewards from staking can be influenced by various factors, depending on the specific network’s
protocol. Generally, the more tokens held and the longer they are staked, the higher the potential
return. Factors influencing rewards may include the total amount of cryptocurrency staked in the
network, staking duration, token inflation rate, and network transaction fees.
3.3
Staking Duration
Different platforms might have varied rules regarding the length of time the cryptocurrencies need to
be held for staking (""staking duration"") and the time it takes to withdraw them (""un-staking time"").
Some networks may require a minimum staking duration to qualify for rewards, and there might be a
waiting period (cooling-off period) for accessing or ""unstaking"" the staked tokens. This approach
encourages network stability by discouraging rapid, speculative movements of funds.
4
Feature Selection
In our study, we tried to understand the details of staking rewards, focusing on the following
cryptocurrencies: ETH, SOL, XTZ, MATIC and ATOM. We carefully chose and reviewed various
datasets and features. It was crucial to pick data that was helpful and of good quality, considering that
3
there is limited data available for some specific assets. This section explains the datasets we used, the
features we looked at, and the thoughtful methods behind leaving out certain features.
4.1
Considered Features
Table 1 below delineates the selected features and their corresponding data sources that were utilized in
this study. These features were extracted from a variety of sources, including Coinbase data storage,
Google Trends and YFinance. The raw data obtained from these sources underwent significant
structuring and refinement to tailor it for analysis.
Table 1: Overview of Extracted Features and Their Data Sources
Feature
Description
Time series of rewards
Historical data representing rewards over a period of time
Price feed
Real-time price information of the asset
Trends
The frequency of searches for the cryptocurrency asset
Taking the example of ETH, a collection of time-series data for about one year from 2021-06-23 to
2022-08-06 was diligently gathered in Figure 1. This data, related to the features mentioned in Table
1 , was closely examined to understand its relationship and influence on staking rewards.
(a) Daily ETH price
(b) ETH trends
(c) ETH reward rate
Figure 1: Ethereum (ETH) Data Visualization (2021-06-23 to 2022-08-06) - Showcasing Daily Price,
Search Trends, and Reward Rate.
4.2
Exclusion and Unexplored Features
In our study, we also looked at some additional features to understand their importance and effect,
which are mentioned in Table 2. After careful review, some features were left out after thoughtful
consideration and testing. Specific features such as ‘staking volume’ and ‘percentage of staked
volume’ were excluded post-analysis, as they were found to closely determine the staking rewards for
ETH. The similarity and near redundancy of these features, upon normalization, further justified their
omission. Moreover, post-merge values for ETH were deliberately left out due to observed variations
in trends and a lack of substantial data to ensure a fortified model training and testing process.
Certain features, despite being considered, were not incorporated into the final model. These
unexplored features include: User count, Distribution of staked tokens, Transaction data on the asset.
The decision to not utilize these features was a calculated one, ensuring that only the most significant
and influential features were utilized, optimizing the study’s objective of analyzing staking rewards.
Table 2: Excluded and unexplored features
Feature
Description
Staking volume
Total amount staked on the asset
Percentage of staked volume
Percentage of total assets that are staked
Distribution of staked tokens
Granularity based on addresses/wallets
Transaction data on asset
Detailed transaction data associated with the asset
User count
Number of users engaged in staking activities
4
5
Experimental Setup
5.1
Forecasting Algorithms
For forecasting the staking rewards, two algorithms were employed: the moving-window average and
linear regression models. Here is a brief overview of the methods used:
• Moving-Window Average (MWA): The algorithm involves using a set number of past data points
to calculate an average that predicts future values. Due to its simplicity and absence of an explicit
training/learning process, it serves as a fundamental test, assuming that the rewards changes
relatively slowly.
• Linear Regression: In this approach, simple linear regression was utilized to enhance the model’s
predictive accuracy. Simple linear regression involves creating a linear relationship between a
single explanatory variable and the dependent variable. This method is used to forecast future
values based on past trends, and it’s a common practice to improve the performance of forecasting
models. Two approaches of linear regression were employed
– Single Linear Regression (SLR): We use a single feature - as input to the linear regression
model.
– Multiple Linear Regression (MLR): We use multiple features as input to the multiple regres-
sion model.
5.2
Objective of the Model
Our objective was to develop a machine learning model adept at forecasting the staking rewards of
ETH and other stakeable assets for a specified number of upcoming days (n). The experimentation
started with forecasts for the next day (n=1), gradually extending to a week ahead (n=7), to assess
and compare the performance and reliability of the results obtained.
5.3
Data Collection and Utilization
Data for 2021-06-23 to 2022-08-06 was assembled, focusing on features pivotal to staking rewards.
A comparison was conducted between linear regression models and moving-average model, aiming
to gauge the efficacy of the staking rewards prediction models for n-day ahead forecasts.
5.4
Training and Test Data Splitting Strategy
An approach was devised for splitting the data into training and test sets. Various strategies were
explored to ascertain the most effective method of partitioning the data to optimize the model’s
performance in forecasting. We found that training for three previous months and using it to test for
the next month gives good performance. This informed approach allowed for the refinement of the
model to achieve a more insightful and dependable forecasting setup.
5.5
Metrics
The metrics considered is root mean square error (RMSE), which measures the average difference
between a statistical model’s predicted values and the actual values.
6
Experimental Results
6.1
Staking Rewards Next Day Prediction
In Table 3, we present staking rewards prediction for 5 assets with Metrics: RMSE divided by the
mean
• Moving-Window Average: we predict the next day’s rewards as the average of the past 7 days.
5
Table 3: Staking Rewards Next Day Prediction Performance (RMSE/Mean)
Asset
Moving-Window
Average
Single Linear Regres-
sion (rewards only)
Multiple Linear Regression
(rewards, price, trends)
ETH (pre-merge)
0.007
0.007
0.009
SOL
0.029
0.031
0.041
MATIC
0.610
0.673
0.807
ATOM
0.017
0.011
0.018
XTZ
0.054
0.046
0.101
• Linear Regression with single feature (rewards only) and multiple features (rewards, price, trends)
Here we consider 7 days data to predict the next day, ie, we feed in 7 days of data as input and
predict the next day’s value. And Train-Test Split: 90 days for training followed by 30 days for
test.
For ETH, moving window average and single feature linear regression perform comparably. For
ATOM and XTZ, single feature linear regression outperforms MWA and multiple linear regression.
For SOL and MATIC, MWA performs the best among all methods. MATIC performs poorly compared
to other tokens with all the methods, which seems to be a consequence of the highly volatile rewards
rate for the token.
(a) ETH
(b) SOL
(c) MATIC
(d) ATOM
(e) XTZ
Figure 2: Staking Rewards Next Day Predictions of rewards for 5 cryptocurrencies ETH, SOL,
MATIC, ATOM and XTZ, using MWA and SLR
In Figure 2, we show the plotted predictions of all the tokens with the chosen parameters from Table
3, for 316 days from 2021-09-14 to 2022-07-27. The plots show the predictions of different methods
- moving window average, single linear regression and multiple linear regression. SOL and MATIC
show high volatility in actual rewards during certain times.
6.2
Staking Rewards Next N-Days Prediction
We further explore the prediction of rewards when the n-days are predicted instead of just 1 day ahead
prediction, as shown in Table 4, for 316 days from 2021-09-14 to 2022-07-27. Metrics are RMSE
divided by the mean. The moving window average performs better overall for all of the tokens except
MATIC. SLR performs better than MWA for shorter term prediction like 1-day or 2-day ahead.
In Figure 3 and Figure 4, we show the plotted predictions of rewards all tokens for 1 to 7 days ahead,
with the chosen parameters from Table 4 for MWA and SLR approach. The predictions plotted are
6
for the first 30 days of our datatset. The plots show that the predictions are more precise for MWA,
although the fluctuations are better captured by the linear regression model.
Table 4: Staking Rewards Next N-Day Prediction Performance Over Days (RMSE/Mean)
ETH (pre-merge)
SOL
XTZ
MATIC
ATOM
N
MWA
SLR
MWA
SLR
MWA
SLR
MWA
SLR
MWA
SLR
1
0.007
0.007
0.029
0.032
0.051
0.048
0.612
0.628
0.017
0.011
2
0.008
0.008
0.023
0.041
0.056
0.061
0.613
0.623
0.019
0.017
3
0.008
0.009
0.031
0.048
0.061
0.079
0.619
0.639
0.020
0.023
4
0.009
0.011
0.034
0.051
0.065
0.097
0.634
0.630
0.022
0.030
5
0.010
0.014
0.034
0.054
0.070
0.114
0.655
0.639
0.024
0.036
6
0.010
0.018
0.037
0.061
0.075
0.130
0.663
0.635
0.026
0.042
7
0.011
0.022
0.040
0.071
0.083
0.145
0.671
0.634
0.028
0.048
(a) ETH
(b) SOL
(c) XTZ
(d) MATIC
(e) ATOM
Figure 3: Staking Rewards Next N-day Predictions of 5 cryptocurrencies ETH, SOL, MATIC, ATOM
and XTZ using MWA
7
Discussion and Conclusion
We find that among all our strategies, 7-day Moving Window Average for one-day predictions gives
between 0.7-5% error (RMSE/MEAN) and performs well for all tokens, except MATIC. Prediction
for MATIC performs poorly compared to other tokens with all the methods, which seems to be a
consequence of the highly volatile rewards rate for the token.
When looking at short term prediction, i.e., n<3, for ETH, MWA and single feature linear regression
perform comparably. For ATOM and XTZ, single feature linear regression outperforms moving
window average and multiple linear regression. For SOL and MATIC, moving window average
performs the best among all methods.
For longer days ahead prediction, i.e., n>=3, MWA outperforms other methods for all tokens except
MATIC. This shows that a simple approach such as moving window average is sufficient and the
effectiveness of complicated ML algorithms reduces as we start predicting further days ahead into
the future.
For all assets except MATIC, a 7-days ahead prediction using MWA has an increased error of no
more than 3.2% compared to a 1-day ahead prediction.
7
(a) ETH
(b) SOL
(c) XTZ
(d) MATIC
(e) ATOM
Figure 4: Staking Rewards Next N-day Predictions of 5 cryptocurrencies ETH, SOL, MATIC, ATOM
and XTZ using SLR
Simple linear regression based on the staking rewards time series alone was found to outperform
multiple linear regression using other features. This shows the effectiveness of simpler strategies
when it comes to prediction of staking rewards.
Some questions that could be explored in future work include handling of non-stationary token data
such as pre and post-merge ETH and when to retrain them.
Acknowledgement Sauren Gupta’s involvement in this paper reflects work that he did while he was
employed as an intern at Coinbase in 2022. Dr. Krishnamachari is a paid consultant for Coinbase and
has assisted on this paper in this capacity.
References
[1] F. Saleh. Blockchain without waste: Proof-of-stake. The Review of financial studies, 34(3):
1156–1190, 2021.
[2] V. Buterin. What proof of stake is and why it matters. Bitcoin Magazine, 26, 2013.
[3] P. R. Nair and D. R. Dorai. Evaluation of performance and security of proof of work and proof of
stake using blockchain. In 2021 Third International Conference on Intelligent Communication
Technologies and Virtual Mobile Networks (ICICV), pages 279–283. IEEE, 2021.
[4] C. T. Nguyen, D. T. Hoang, D. N. Nguyen, D. Niyato, H. T. Nguyen, and E. Dutkiewicz. Proof-
of-stake consensus mechanisms for future blockchain networks: fundamentals, applications and
opportunities. IEEE access, 7:85727–85745, 2019.
[5] V. Buterin et al. Ethereum white paper. GitHub repository, 1:22–23, 2013.
[6] J. Kwon and E. Buchman. Cosmos whitepaper. A Netw. Distrib. Ledgers, 27, 2019.
[7] K. John, T. J. Rivera, and F. Saleh. Equilibrium staking levels in a proof-of-stake blockchain.
Available at SSRN 3965599, 2021.
[8] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735–1780, 1997.
[9] K. J. Choi, J. Jeon, and B. H. Lim. Optimal staking and liquid token holding decisions in
cryptocurrency markets. Available at SSRN 4528742, 2023.
8
[10] J. Xu and Y. Feng. Reap the harvest on blockchain: A survey of yield farming protocols. IEEE
Transactions on Network and Service Management, 20(1):858–869, 2022.
[11] P. He, D. Tang, and J. Wang. Staking pool centralization in proof-of-stake blockchain network.
Available at SSRN 3609817, 2020.
[12] H. Gersbach, A. Mamageishvili, and M. Schneider. Staking pools on blockchains. arXiv
preprint arXiv:2203.05838, 2022.
[13] Y. Tang, Z. Song, Y. Zhu, H. Yuan, M. Hou, J. Ji, C. Tang, and J. Li. A survey on machine
learning models for financial time series forecasting. Neurocomputing, 512:363–380, 2022.
[14] P. Soni, Y. Tewari, and D. Krishnan. Machine learning approaches in stock price prediction: A
systematic review. In Journal of Physics: Conference Series, volume 2161, page 012065. IOP
Publishing, 2022.
[15] N. Kyriazis, S. Papadamou, and S. Corbet. A systematic review of the bubble dynamics of
cryptocurrency prices. Research in International Business and Finance, 54:101254, 2020.
[16] A. M. Khedr, I. Arif, M. El-Bannany, S. M. Alhashmi, and M. Sreedharan. Cryptocurrency price
prediction using traditional statistical and machine-learning techniques: A survey. Intelligent
Systems in Accounting, Finance and Management, 28(1):3–34, 2021.
[17] R. Amirzadeh, A. Nazari, and D. Thiruvady. Applying artificial intelligence in cryptocurrency
markets: A survey. Algorithms, 15(11):428, 2022.
[18] M. Mudassir, S. Bennbaia, D. Unal, and M. Hammoudeh. Time-series forecasting of bitcoin
prices using high-dimensional features: a machine learning approach. Neural computing and
applications, pages 1–15, 2020.
[19] M. J. Hamayel and A. Y. Owda. A novel cryptocurrency price prediction model using gru, lstm
and bi-lstm machine learning algorithms. AI, 2(4):477–496, 2021.
[20] V. Derbentsev, V. Babenko, K. Khrustalev, H. Obruch, and S. Khrustalova. Comparative
performance of machine learning ensemble algorithms for forecasting cryptocurrency prices.
International Journal of Engineering, 34(1):140–148, 2021.
[21] V. D’Amato, S. Levantesi, and G. Piscopo. Deep learning in predicting cryptocurrency volatility.
Physica A: Statistical Mechanics and its Applications, 596:127158, 2022.
9
"
"This paper describes a virtual reality (VR) serious game designed to foster understanding of dyslexia and raise awareness of the challenges it can create, with the aim of encouraging a supportive environment that promotes academic success for dyslexic students.nan","Dyslexia, particularly phonological dyslexia, causes difficulties in connecting sounds of words to their written forms, leading to challenges like slow reading speed and difficulty decoding unfamiliar words. These difficulties can be frustrating for students, potentially resulting in feelings of misunderstanding or stigmatization. To overcome these obstacles, dyslexic students often rely on compensatory tools and strategies. However, raising awareness and empathy among non-dyslexic individuals, including teachers and peers, can contribute to the provision of essential support for dyslexic students.nan","Studies have demonstrated the potential of VR technology in promoting social inclusion and facilitating empathy. Previous research has explored the use of VR to increase social skills in individuals with Autism Spectrum Disorder and to enhance empathy towards wheelchair users. VR has also been utilized to address some of the problems caused by dyslexia in children, showing improvements in attention and indicating the potential for long-term benefits in reading skills.nannan","The methodology employed involves immersing players, such as teachers or peers of dyslexic students, in a virtual world where they are tasked with reading a recipe book and correctly adding ingredients to a potion. However, the text in the book and ingredient labels are presented in a font designed to replicate the reading difficulties experienced by people with dyslexia. The game flow includes three attempts to complete the task, with increasing time limits and the introduction of compensatory tools such as shorter words and an audio guide. The game ends when all attempts are exhausted or when the player successfully creates the correct potion.nan","The VR experience was tested on 32 non-dyslexic individuals. The results showed that most participants were unable to solve the task initially, reporting feelings of frustration and anxiety due to the difficulties in reading the instructions. However, these feelings tended to dissipate when more time and compensatory tools were provided, leading to an increased awareness of the issues and needs of dyslexic students. A survey conducted after the VR experience indicated that participants perceived the task as difficult but also reported an increase in their empathy towards people with dyslexia.nan","The VR experience presented in this paper is considered a promising tool for raising empathy towards people with dyslexia. Future research will involve collecting data from a larger sample size to validate the effectiveness of the serious game and to study user empathy profiles through the application of artificial intelligence techniques. Additionally, other serious games are being designed to foster empathy for individuals with different types of dyslexia.nan",A VR Serious Game to Increase Empathy towards Students with Phonological Dyslexia,"José M. Alcalde-Llergo, Enrique Yeguas-Bolívar, Pilar Aparicio-Martínez, Andrea Zingoni, Juri Taborri, Sara Pinzi","A VR Serious Game to Increase Empathy towards
Students with Phonological Dyslexia
Jos´e M. Alcalde-Llergo
Dept. of Economics, Engineering,
Society and Business Organization (DEIM)
University of Tuscia
Viterbo, Italy
jose.alcalde@unitus.it
Enrique Yeguas-Bol´ıvar
Computing and Numerical Analysis
University of C´ordoba
C´ordoba, Spain
eyeguas@uco.es
Pilar Aparicio-Mart´ınez
Nursing, Physiotherapy and Pharmacology
University of C´ordoba
C´ordoba, Spain
n32apmap@uco.es
Andrea Zingoni
Dept. of Economics, Engineering,
Society and Business Organization (DEIM)
University of Tuscia
Viterbo, Italy
andrea.zingoni@unitus.it
Juri Taborri
Dept. of Economics, Engineering,
Society and Business Organization (DEIM)
University of Tuscia
Viterbo, Italy
juri.taborri@unitus.it
Sara Pinzi
Dept. Physical Chemistry
and Applied Thermodynamics
University of C´ordoba
C´ordoba, Spain
qf1pinps@uco.es
Abstract—Dyslexia is a neurodevelopmental disorder that is
estimated to affect about 5-10% of the population. In particular,
phonological dyslexia causes problems in connecting the sounds
of words with their written forms. This results in difficulties
such as slow reading speed, inaccurate reading, and difficulty
decoding unfamiliar words. Moreover, dyslexia can also be a
challenging and frustrating experience for students as they may
feel misunderstood or stigmatized by their peers or educators.
For these reasons, the use of compensatory tools and strategies
is of crucial importance for dyslexic students to have the same
opportunities as non-dyslexic ones. However, generally, people
underestimate the problem and are not aware of the importance
of support methodologies. In the light of this, the main purpose
of this paper is to propose a virtual reality (VR) serious game
through which teachers, students and, in general, non-dyslexic
people could understand which are some of the issues of student
with dyslexia and the fundamental utility of offering support to
them. In the game, players must create a potion by following
a recipe written in an alphabet that is specifically designed to
replicate the reading difficulties experienced by individuals with
dyslexia. The task must be solved first without any help and then
by receiving supporting tools and strategies with the idea that
the player can put himself in the place of the dyslexic person
and understand the real need for support methodologies.
Index Terms—Virtual reality, Simulation, Inclusion, Dyslexia,
Empathy, Serious game
I. INTRODUCTION
Dyslexia is a specific learning disorder that causes signifi-
cant difficulties in learning skills related to reading [1]. It is
estimated to affect approximately 5-10% of the population [2],
which is equivalent to about 700 million people worldwide.
More specifically, phonological dyslexia is an impairment
of reading novel words (non-words) with otherwise good
performance in reading familiar words [3]. Individuals with
phonological dyslexia often experience problems to connect
the sounds of words to their written forms, which can hinder
their ability to recognize and recall new words. Phonological
dyslexia is thought to be caused by differences in the way
the brain processes language, particularly in the regions of the
brain that are responsible for phonological processing [4]. This
can result in reading difficulties, such as slow reading speed,
inaccurate reading, and difficulty with decoding unfamiliar
words [5]. However, with appropriate support and interven-
tions individuals with phonological dyslexia can compensate
these problems and can achieve success in their academic and
professional lives. One of this support is represented by the
inclusion of dyslexic students by their classmates and teachers.
Thus, empathy towards dyslexic students is of fundamental
importance and stimulating it is one of the main objectives of
this work. Indeed, dyslexia can be a challenging and frustrating
experience for students as they may feel misunderstood or
stigmatized by their peers or educators. Demonstrating em-
pathy towards students with dyslexia can help to create a
supportive and inclusive learning environment, where they feel
understood, validated, and respected [6]. This can help them to
feel more confident and motivated to learn, and ultimately lead
to greater success in their academic and professional lives.
To achieve this, we propose a VR serious game to promote
understanding of dyslexia and make people more conscious of
the problem that it can create. This should foster the creation
of a supportive environment that enables study success for
dyslexic students.
The present work emerges as part of the VRAIlexia
project [7], an initiative designed to increase awareness and
provide support for university students with dyslexia. The
main objective of the project is to mitigate the challenges
arising from dyslexia among students in higher education,
with the goal of reducing the incidence of university dropouts
and facilitating access to degree programs for individuals with
arXiv:2401.10926v1  [cs.HC]  15 Jan 2024
dyslexia, a severe problem addressed in [8].
II. RELATED WORKS
A. Virtual reality for inclusion
Virtual reality (VR) technology has the potential to create
immersive and interactive environments that can simulate real-
world experiences. This technology can be applied to all kinds
of fields, including education, healthcare, entertainment, and
social sciences. In particular, VR has shown promising results
in promoting social inclusion as can be seen in works such as
the Includiamoci project [9]. It is a social inclusion initiative
that utilizes VR and spatial augmented reality technologies
to create safe spaces for collaborative activities based on art
therapy techniques and new technologies. The project aims to
recognize and enhance individual differences while promoting
teamwork and continuous confrontation between participants,
educators, and experts in cultural heritage and technologies.
VR has also been applied to achieve the inclusion of
disabled people into the labor market [10]. In this case, authors
use immersive environments to help people with disabilities
to increase employment opportunities. The system aims to
facilitate the integration of individuals with disabilities into
the labor market by simulating work activities and enabling
the development of skills in a pleasurable and active way. The
software also serves as an alternative communication system,
promoting social integration and cognitive development.
In other fields, VR has been used for inclusion by proposing
activities in virtual environments that help working on the diffi-
culties faced by some social groups. An example of this can be
seen in a case study where authors investigated the impact of a
“Virtual Reality Social Cognition Training” to enhance social
skills in children with Autism Spectrum Disorder (ASD) [11].
During the study, the performance of 30 children with ASD
was measured in different domains by putting them in different
situations such as doing a team project in the classroom
or ordering food in the school cafeteria. The study findings
indicated that utilizing a virtual reality platform is a promising
treatment approach to understanding better social impairments
frequently observed in individuals with ASD. Specifically,
enhancements in emotion recognition, social attribution, and
executive function of analogical reasoning where shown.
B. Virtual reality for empathy
Another application where VR can exploit its potential is
in facilitating empathy towards a social group. There are
studies that prove the beneficts of VR in this task, such as
the performed in [12]. In this study participants where chosen
randomly to view a documentary featuring a young girl living
in a refugee camp in a VR format. They found that VR can
lead to greater experience of empathy.
Also a VR application as a means to empathize a case
study focused in wheelchair users was developed in [13].
The objective of this study was to analyze the effects of a
simulation aimed at replicating the challenges that a student
who uses a wheelchair would face when performing various
tasks in their daily lives. The results showed that the simulation
experience changed attitudes towards persons with disabilities
in the real world and made them advocates for change. The
study adds to existing research on the importance of VR
simulations in improving empathy towards others.
C. Virtual reality for dyslexia
The use of VR to address some of the problems caused by
dyslexia in children has also been a frequent topic of research
in recent years. In addition, studies such as [14] have shown
that the use of VR can improve the memory and skills of
people with dyslexia. In this case, users were subjected to
different tests in a virtual classroom where they had to perform
according to what appeared on the blackboard. The results did
not show clear improvements in their reading skills, but they
showed a clear improvement in their attention, which could
lead, in the longer term, to improvements in other problems
caused by dyslexia, as reducing time in reading low frequency
long words.
A clear case study where dyslexia is dealt using VR can be
seen in the European project FORDYS-VAR [15], whose main
objective is to offer a way to facilitate the learning of people
with dyslexia through technology, more specifically using VR
and augmented reality (AR). This project is especially focused
on helping dyslexic children between 10 and 16 years old.
Among its contributions, authors develop a support software
for children with dyslexia [16] with which they can work
to alleviate several of the learning disabilities caused by this
disorder in a more entertaining way, through a virtual reality
video game on the Oculus Quest platform.
It is worth noting that most of the studies on VR applied
to dyslexia do not consider people at the higher education
stage. Conversely, VRAIlexia project aims to help these stu-
dents through VR and artificial intelligence technologies [7].
During the project different VR applications were designed
and developed, including an application for the realization of
psychometric tests for students with dyslexia [17], as well as
the serious game that we present during the current document.
III. METHODOLOGY
The methodology proposed in this study concerns making
players, such as teachers or peers of dyslexic students, feel
inside a virtual world where they have to complete a task.
The task requires participants to read a recipe book and
correctly adding ingredients in the order and quantity specified.
However, to simulate the reading difficulties experienced by
people with dyslexia, the text in the book and ingredient
labels are presented in the Britton’s Dyslexia font [18], an
alphabet that eliminates certain parts of letters, making reading
more challenging. Figure 1 shows how the word “Dyslexia”
is written using this alphabet.
Fig. 1: ‘The word ‘DYSLEXIA” using Britton’s font [18].
A. Application flow
Figure 2 shows the application flow of “In the shoes of
dyslexic students (Potion)”.
Game
explanation
Start level
Pick potion
Correct
potion?
Win
Loss
Add new
compensatory
tools/strategies
Final
level?
Last
potion?
No
No
Yes
Yes
Yes
No
Time 
left?
Yes
No
Fig. 2: Flow diagram.
Once players enter the game they find themselves inside a
kind of “magic castle”, in front of a closed door. The reason
behind using a fantasy design for the virtual rooms was two-
fold: its widespread popularity and its ability to enhance the
game’s allure while also providing a purpose for the task.
When they go through the door they meet their potions teacher,
an avatar that will tell them that they must prepare a potion
to save their friend, called Sam. She explains that the potion
can be created by adding different ingredients strictly in the
correct order into a pot, according to the recipe given in a
book. Moreover, a time limit of 3 minutes must be respected.
Ingredients are distributed throughout the room on different
shelves.
After that, players initiate their first attempt to save Sam.
As they fail these attempts, they will be given more time, 5 or
10 minutes, and new compensatory tools, like shorter words
and an audio guide, to try saving their friend again. A level
failure occurs when time runs out or when a wrong ingredient
is put into the pot or, also, a correct ingredient is dropped in
an incorrect order. The game will end once the players fail all
three attempts given or succeed in making the potion correctly
during one of them.
B. Virtual rooms
Within the virtual castle, participants will be granted admit-
tance to three distinct rooms. The initial of these enclosures is
the starting point of our exploration, where players can famil-
iarize themselves with the operational features of the controller
buttons. In addition, they will find a brief explanation about the
effects of phonological dyslexia as shown in Figure 3a. Second
room is Sam’s room. It is an empty room where players can
see their friend and his current state as shown in Figure 3b.
Finally, the third room is the one where the game takes place.
It is a potions laboratory where players can find their teacher
and all the materials needed to brew a potion to help Sam. A
general view of the room is shown in Figure 3c.
C. Main characters and items
Throughout the VR experience, participants are required
to interact with a diverse range of items and characters that
have been specifically designed to guide and enhance their
level of immersion within the simulated environment. A list
of these characters and objects is exposed below, and their
representation in the virtual world are shown in Figure 4.
• Teacher: she has the role of potions teacher in the virtual
world. She explains to the players the rules of the game
belonging to the different levels and what they have to do
to create the correct potion and win the game. In addition,
she takes on the role of a strict teacher who yell at her
students when they fail in their tasks. In this way the
player put himself in the place of dyslexic students who
are not valued for their effort by their teachers.
• Sam: he represents the player’s friend in the game. The
player must prepare a potion correctly and within a
limited time frame in order to save him. Player’s results
will be directly reflected in Sam. If the correct potion is
created Sam will be happy and celebrate, but if it fails
during the different levels players will see him suffer.
• Ingredients and shelves: around the potions laboratory
the player finds several shelves with different ingredients
to make potions. These ingredients are carefully arranged
in a particular order on each shelf, and stored within
flasks of varying shapes and colors, each labeled with the
corresponding ingredient’s name. Notably, the labeling is
composed utilizing the Britton’s font, trying to replicate
the reading difficulties experienced by a dyslexic person.
• Table: in the center of the potion laboratory lies an
irregularly-shaped table designed to promote different
modes of locomotion in VR (teleportation-based and
controller-based). Over the table there are different key
objects for the game, including an hourglass, recipe book,
and pot, which players may interact with as part of their
gameplay experience. Furthermore, the table serves as a
practical space for players to place some of the potion
ingredients.
• Hourglass: is the item used to start the game. Next to it
there is a digital clock with the time available to complete
the level. Upon starting the game, the allotted time begins
to decrement, with the level concluding once the timer
reaches zero.
• Pot: container in which the potion is to be brewed.
Players must pour the ingredients into the pot in the
correct order to pass the game. The pot will release a heart
if the poured ingredient is correct and a purple smoke if
it is not, serving as feedback to guide the player towards
successful completion of the game.
(a) Starting room.
(b) Sam’s room.
(c) Potions laboratory.
Fig. 3: Chambers from the virtual castle: initial room (a), Sam’s Room (b) and potions laboratory (c).
• Recipe book: it is a big book containing the recipe for
the potion to be brewed by the player. It denotes the
specific type and quantity of each ingredient required,
and specifies the correct order in which they must be
added to the container in order to ensure the successful
completion of the potion. Consistent with the font utilized
for ingredient labeling, the recipe book also employs the
Britton’s font.
• Beacon: a light beam that guides the player throughout
the virtual environment. It indicates specific points within
the potions laboratory where the player must be situated
to initiate teacher conversations or start the next level.
IV. PRELIMINARY RESULTS AND FUTURE WORKS
The game was tested on 32 non-dyslexic individuals, who
were not able, in general, to solve the task proposed, reporting
feeling frustrated and anxious due to the difficulties in reading
the instructions to complete the task. This feeling tended to
disappear completely when more time was given and, above
all, when compensatory tools were provided. In this way,
consciousness about issues and needs of dyslexic students
arose. People’s opinions on the experience were collected
through a survey with questions to be answered on a Likert
scale ranging from 1 to 5. Figure 5 shows two of these
questions, the first referring to the difficulty of performing the
proposed task and the second to the growth of their empathy
towards people with dyslexia. The VR experience presented
in this work can be thus considered a good way to increase
empathy towards people with dyslexia.
Next step involves collecting data from a larger sample
size to validate the effectiveness of the developed serious
game. Specifically, an appropriate survey will be developed
to measure the quality of the VR experience and the increase
in empathy towards people with phonological dyslexia after
they complete the game. In addition, collected data will be
used to study the different users empathy profiles through the
application of various artificial intelligence techniques.
Finally, we are also designing other serious games to show
empathy not only for people with phonological dyslexia, but
also for those with other dyslexia types. In this way we have
the objective that anyone can put themselves in the place of
a dyslexic person, and thus understand the real need for the
different methodologies of support required by all dyslexic
students, including those in higher and university education.
V. ACKNOWLEDGEMENTS
Jos´e Manuel Alcalde Llergo is a PhD student enrolled in the
National PhD in Artificial Intelligence, XXXVIII cycle, course
on Health and life sciences, organized by Universit`a Campus
Bio-Medico di Roma. These results are framed in VRAIlexia
project funded by the Erasmus+ Programme2014-2020 – Key
Action 2: Strategic Partnership Projects. AGREEMENT n.
2020-1-IT02-KA203-080006.
REFERENCES
[1] A. Kohli, S. Sharma, and S. K. Padhy, “Specific learning disabili-
ties: Issues that remain unanswered,” Indian Journal of Psychological
Medicine, vol. 40, no. 5, pp. 399–405, 2018. PMID: 30275613.
[2] A. Costantini, A. Ceschi, and R. Sartori, “Psychosocial interventions for
the enhancement of psychological resources among dyslexic adults: A
systematic review,” Sustainability, 09 2020.
[3] J. J. Tree and J. Kay, “Phonological dyslexia and phonological impair-
ment: An exception to the rule?,” Neuropsychologia, vol. 44, no. 14,
pp. 2861–2873, 2006.
[4] M. Alexander, R. Friedman, F. Loverso, and R. Fischer, “Lesion local-
ization of phonological agraphia,” Brain and Language, vol. 43, no. 1,
pp. 83–95, 1992.
[5] S. Z. Rapcsak, P. M. Beeson, M. L. Henry, A. Leyden, E. Kim, K. Rising,
S. Andersen, and H. Cho, “Phonological dyslexia and dysgraphia: Cog-
nitive mechanisms and neural substrates,” CORTEX, vol. 45, pp. 575–
591, MAY 2009.
[6] E. Sako, “The emotional and social effects of dyslexia,” European
Journal of Interdisciplinary Studies, vol. 4, p. 233, 04 2016.
[7] A. Zingoni, J. Taborri, V. Panetti, S. Bonechi, P. Aparicio-Mart´ınez,
S. Pinzi, and G. Calabr`o, “Investigating issues and needs of dyslexic
students at university: Proof of concept of an artificial intelligence
and virtual reality-based supporting platform and preliminary results,”
Applied Sciences, vol. 11, no. 10, 2021.
[8] I. Benedetti, B. Marcella, V. Panetti, J. Taborri, T. Urbani, A. Zingoni,
and G. Calabr`o, “Clustering analysis of factors affecting academic career
of university students with dyslexia in italy,” Scientific Reports, vol. 12,
p. 9010, 05 2022.
(a) Ingredients.
(b) Irregular table.
(c) Hourglass.
(d) Pot.
(e) Recipe book.
(f) Beacon.
Fig. 4: Main items.
Rating
People
0
5
10
15
20
1
2
3
4
5
How difficult did you find the task?
Rating
People
0
5
10
15
20
1
2
3
4
5
How much did your empathy level increase after the VR 
experience?
Fig. 5: Survey results.
[9] V. De Luca, C. Gatto, S. Liaci, L. Corchia, S. Chiarello, F. Faggiano,
G. Sumerano, and L. T. De Paolis, “Virtual reality and spatial augmented
reality for social inclusion: The includiamoci project,” Information,
vol. 14, no. 1, 2023.
[10] S. D. Piovesan, R. Wagner, R. D. Medina, and L. M. Passerino,
“Virtual reality system to the inclusion of people with disabilities in the
work market,” in 2013 12th International Conference on Information
Technology Based Higher Education and Training (ITHET), pp. 1–7,
2013.
[11] N. Didehbani, T. Allen, M. Kandalaft, D. Krawczyk, and S. Chapman,
“Virtual reality social cognition training for children with high func-
tioning autism,” Computers in Human Behavior, vol. 62, pp. 703–711,
2016.
[12] E. Stilinovi´c, “Facilitating empathy through virtual reality,” Motivation
and Emotion, vol. 41, 12 2017.
[13] E. Hoter and I. Nagar, “The effects of a wheelchair simulation in a
virtual world,” Virtual Reality, vol. 27, 02 2022.
[14] E. Pedroli, P. Padula, A. Guala, M. T. Meardi, G. Riva, and G. Al-
bani, “A psychometric tool for a virtual reality rehabilitation approach
for dyslexia,” Computational and mathematical methods in medicine,
vol. 2017, 2017.
[15] S. Rodr´ıguez Cano, V. Delgado Benito, R. Casado Mu˜noz, E. Cubo Del-
gado, V. Aus´ın Villaverde, and G. Santa Olalla Mariscal, “Tecnolog´ıas
emergentes en educaci´on inclusiva: realidad virtual y realidad au-
mentada: Proyecto europeo fordys-var,” Revista INFAD de Psicolog´ıa.
International Journal of Developmental and Educational Psychology.,
vol. 2, p. 443–450, ago. 2021.
[16] S. Rodr´ıguez-Cano, V. Delgado-Benito, V. Aus´ın-Villaverde, and L. M.
Mart´ın, “Design of a virtual reality software to promote the learning of
students with dyslexia,” Sustainability, vol. 13, no. 15, p. 8425, 2021.
[17] E.
Yeguas-Bol´ıvar,
J.
M.
Alcalde-Llergo,
P.
Aparicio-Mart´ınez,
J. Taborri, A. Zingoni, and S. Pinzi, “Determining the difficulties of
students with dyslexia via virtual reality and artificial intelligence: An
exploratory analysis,” in 2022 IEEE International Conference on Metrol-
ogy for Extended Reality, Artificial Intelligence and Neural Engineering
(MetroXRAINE), pp. 585–590, 2022.
[18] D. Britton, “Dyslexia.” https://danielbritton.info/dyslexia/.
"
"Pushing updates periodically and returning feedback when needed, adapting the physical decisions to the communication policy, improves the efficiency of systems with sensors and actuators. Choosing between push-based and pull-based communication is crucial. This work proposes an analytical model for optimizing push-based and pull-based strategies in Cyber-Physical Systems (CPSs). Both options have advantages and drawbacks. The push-based system performs better at the optimum, but is PPAD-hard. Numerical results show that adjusting the actuators' decision to the network operation is a better approach.nan","Recent works have shown that AoI-based optimization may lead to sub-optimal performance, and that adapting the actuators' decisions to the network operations, thus jointly optimizing communication and control, is a better approach. This research investigates the performance of pull-based and push-based communication strategies in CPSs.nan","nanSeveral recent works on Effective Communication (EC) systems have investigated the push-based configuration. However, the joint optimization of EC and control policies is still relatively unexplored, and, to the authors' knowledge, no studies have directly compared the push- and pull-based communication approaches and analyzed the interdependency between CPS optimization and the Value of Information (VoI).nan","We consider a simple CPS scenario with a single actuator, without local sensing capabilities, that is connected to a base station (BS) via a constrained communication channel. Using this model, we analyze the advantages and drawbacks of each configuration, proving relevant results and showing that the push-based system, while having better performance at the optimum, is a PPAD-hard problem.nan","The performance of a push-based system should improve with respect to the pull-based one, as the former can exploit information on the specific realization of the system state trajectory. On the other hand, remote POMDPs are multi-agent problems and may involve critical issues in terms of coordination between the BS and Actuator. Results show that the push-based approach selects the best update interval for every state. The pull-based EC strategy Pareto dominates the AoI-based policy, and the API approach leads to a Nash Equilibrium (NE) policy in the push-based problem. However, the optimal EC solution to the push-based problem does not always Pareto dominate the AoI-based strategy, and the solution obtained by the API strategy does not Pareto dominate the AoI-based strategy.nan","This work presents an analytical framework to adapt classical optimization tools such as Policy Iteration (PI) to the context of communication and control problems, providing numerical results that show a strong dependency between the VoI and the structure of the underlying Markov Decision Process (MDP). The analysis revealed that the common push-based view of communication and control problems may not always be optimal, as the game theoretical properties of multiagent scenarios do not guarantee that a solution may be better even than a simple AoI-based optimization.nan",Push- and Pull-based Effective Communication in Cyber-Physical Systems,"Pietro Talli, Federico Mason, Federico Chiariotti, Andrea Zanella","This paper has been submitted to IEEE International Conference on Computer Communications. Copyright may change without notice.
Push- and Pull-based Effective Communication
in Cyber-Physical Systems
Pietro Talli, Federico Mason, Federico Chiariotti, Andrea Zanella
Department of Information Engineering, University of Padova, Via G. Gradenigo 6/B, 35131, Padua, Italy
Emails: pietro.talli@phd.unipd.it, {federico.mason, federico.chiariotti, andrea.zanella}@unipd.it
Abstract—In Cyber-Physical Systems (CPSs), two groups of
actors interact toward the maximization of system performance:
the sensors, observing and disseminating the system state, and the
actuators, performing physical decisions based on the received
information. While it is generally assumed that sensors periodi-
cally transmit updates, returning the feedback signal only when
necessary, and consequently adapting the physical decisions to the
communication policy, can significantly improve the efficiency
of the system. In particular, the choice between push-based
communication, in which updates are initiated autonomously by
the sensors, and pull-based communication, in which they are
requested by the actuators, is a key design step. In this work, we
propose an analytical model for optimizing push- and pull-based
communication in CPSs, observing that the policy optimality
coincides with Value of Information (VoI) maximization. Our
results also highlight that, despite providing a better optimal
solution, implementable push-based communication strategies
may underperform even in relatively simple scenarios.
Index Terms—Effective communication, Value of Information,
Pull-based communication, Cyber-Physical Systems
I. INTRODUCTION
The Industry 4.0 revolution has made Cyber-Physical Sys-
tems (CPSs) a fundamental pillar for multiple applications,
including area surveillance, data muling, factory automation,
teleoperation, and autonomous mobility [1]. A CPS is com-
posed of sensors, which collect information about the system
state, and actuators, that can physically modify it and control
it. In standard scenarios, it is assumed that sensor transmis-
sions take place periodically, with the goal of minimizing
the Age of Information (AoI) at the receiver side. Such an
approach ensures that, on average, the actuators have the most
recent information about the system conditions.
Recent works have shown that AoI-based optimization may
lead to sub-optimal performance, either because updates are
unnecessary and may waste communication resources when
the environment remains stable, or because an abrupt change
in the system state may go unreported for a relatively long
time, harming the control performance. In more advanced
systems, the communication policy is tailored to the Value
of Information (VoI) of the system, which implies that new
This project was funded under the National Recovery and Resilience Plan
(NRRP), Mission 4 Component 2 Investment 1.3 - Call for tender No.
341 (15 March 2022) of the Italian Ministry of University and Research,
funded by the European Union NextGenerationEU Project. MUR grant
number: PE 0000001, Concession Decree 1549 (11/10/2022) adopted by the
Italian Ministry of University and Research, CUP C93C22005250001, project
title: RESearch and innovation on future Telecommunications systems and
networks, to make Italy more smART (RESTART). F. Chiariotti’s activities
are funded by NRRP “Young Researchers” grant REDIAL (SoE0000009).
transmissions are started whenever the environment evolution
gets unpredictable at the receiver side. A further improvement
in overall performance is obtained by adapting the actuators’
decisions to the network operations, thus jointly optimizing
communication and control [3]. In the pursuit of this goal,
it is possible to adopt the multi-agent reinforcement learning
(MARL) paradigm [4], an extension of reinforcement learning
(RL) to handle multi-agent scenarios.
In the case of MARL optimization, each actor (i.e., sensor
or actuator) is controlled via a distinct RL agent, which
adapts its local actions towards the maximization of the
overall performance. The fact that multiple agents interact
with and simultaneously adapt to the same environment leads
to non-stationary training conditions, where estimating the
optimal policy is not always guaranteed [5]. Better solutions
may be obtained by centralizing the control process in a
single unit, which ensures perfect agent coordination at the
cost of higher learning complexity and resource consumption.
However, centralized solutions require reliable, high-frequency
updates, which may be not always feasible, especially in the
case Internet of Things (IoT) scenarios, where energy and
communication constraints make it challenging to achieve a
full environment perception in real-time [?].
In the case of a distributed optimization of CPSs, the place-
ment of the computational intelligence controlling the com-
munication systems is a critical design choice. If RL agents
are installed at the sensors, it is possible to observe the current
environment (or part of it) and update the actuators’ knowledge
as needed, in a push-based fashion. However, this solution may
not be feasible if the sensors have limited computational and
communication capabilities, as in the case of IoT networks.
The other option is to install the computational intelligence at
the actuators, each of which is associated with RL agent that
has to both control the physical actions of the actuator itself
and request new updates from the sensors. In such a case,
communication takes place in a pull-based fashion [?], and
decisions on when and whether to request an update are made
without any information about the environment aside from the
last state update and the elapsed time.
The pull-based problem was first presented in [6] and
recently addressed in [7], where the authors consider two
possible approaches for approximating the optimal policy:
the first explicitly estimates the transition probability of the
Markov Decision Process (MDP) describing the system evo-
lution, while the second jointly learns communication and
control policies as part of a single model. The push-based
arXiv:2401.10921v1  [eess.SY]  15 Jan 2024
configuration has been investigated in several recent works
on Effective Communication (EC) systems [?], in which
the actuators’ policies must be adapted to the frequency of
communication updates. However, the joint optimization of
EC and control policies is still relatively unexplored, and, to
the authors’ knowledge, no studies have directly compared the
push- and pull-based communication approaches and analyzed
the interdependency between CPS optimization and the VoI.
To overcome these limitations, this work presents an ana-
lytical model for optimizing and evaluating push- and pull-
based strategies in CPSs. We consider a simple CPS scenario
with a single actuator, without local sensing capabilities, that
is connected to a base station (BS) via a constrained com-
munication channel. Using the channel involves a significant
cost but represents the only way for the actuator to observe
the system state. This design involves a trade-off between the
minimization of the communication cost and the quality of
control, which becomes less accurate as the transmission rate
is reduced, in both the push- and pull-based versions. Using
this model, we analyze the advantages and drawbacks of each
configuration, proving relevant results and showing that the
push-based system, while having better performance at the
optimum, is a PPAD-hard problem [15].
II. SYSTEM MODEL
We consider a system model with a single Actuator that
can perceive the environment only through the information
provided by a BS. This latter has full access to the system
state and, therefore, embodies the sensor network described
in the introduction. The goal of the model is to design and
evaluate EC strategies between the Actuator and the BS. In
the rest of this section, we will first formalize the environment
as an MDP, and then characterize the possible solutions in the
pull- and push-based communication scenarios.
A. Markov Decision Processes
We consider an MDP defined by the tuple ⟨S, A, P, r, γ⟩,
where S is the set of states, A is the set of actions, P is the
full transition matrix, r is the reward function and γ ∈ [0, 1) is
the discount factor. Symbol Pa denotes the transition matrix
associated with action a ∈ A. Each row of Pa ∈ R|S|×|S|
defines the distribution of the next state over S. For it to be a
valid distribution, we impose P a
ss′ ≥ 0 ∀a ∈ A, (s, s′) ∈ S2
and P
s′ P a
ss′ = 1. The immediate reward for taking action a
in state s and transitioning to state s′ is denoted by ra
s,s′.
In our problem, the Actuator cannot directly observe the
state but incurs a cost ct to obtain it from the BS, which
observes it at every step with no associated cost. Hence,
we can consider two possible scenarios: in the pull-based
communication scenario, the Actuator itself decides whether to
request a state update from the BS, which constitutes a passive
actor in the system; in the push-based communication scenario,
the BS itself can decide whether to transmit the system state
to the Actuator. Notably, in the first case, we have a single
agent installed at the Actuator, while, in the second case, we
have two distinct agents that need to cooperate.
In the simplest case, every sensing action has the same cost,
and the communication action is ct ∈ {0, 1}. When the state st
is not available to the Actuator, its a priori belief distribution
can be computed using the Markovian property of the system
state evolution. Knowing the last observed state st−k and the
vector a = {at−k, at−k+1, . . . , at−1} containing the k actions
undertaken since then, as well as the transition matrix P, we
can determine the belief distribution θa
st−k,k:
θa
st−k,k =
 
tY
ℓ=t−k
Paℓ
!
1st−k,
(1)
where 1s is a one-hot column vector whose elements are all
0, except for the one corresponding to s, which is equal to 1.
To jointly optimize the control and communication policies,
we need to solve the following problem:
maximize E
"" ∞
X
t=0
γtrt
#
such that E
"" ∞
X
t=0
γtct
#
≤ C,
(2)
where C is the cumulative sampling cost that the system can
tolerate and rt is the instantaneous reward at time t. This
problem can be seen as a constrained Partially Observable
Markov Decision Process (POMDP) where each action, or
combination of actions by the BS and Actuator, corresponds
to the pair (at, ct). By defining a fixed communication cost
β ∈ R+ and using it as a dual parameter controlling the trade-
off between the communication cost and the reward, we can
reformulate (2) as an unconstrained POMDP:
maximize E
"" ∞
X
t=0
γt(rt − βct)
#
.
(3)
In the following, we will denote values and functions related
to the Actuator with the subscript A, while the BS will be
associated with the subscript B.
The pull-based communication scenario can then be mod-
eled as a problem known as an Action-Contingent Noiselessly
Observable MDP (ACNO-MDP) [7], in which the state st
is only available to the Actuator by means of a (costly)
sensing action. Specifically, the sensing action corresponds
to a request to the BS, which has perfect state information
and can transmit it on demand. If we fix the polling strategy,
the resulting system can be treated as a POMDP that can be
solved optimally with point-based value iteration [10] or other
methods that consider the α-vectors [11].
The push-based problem is more common in the EC lit-
erature and is often modeled as a Remote POMDP [12].
In this case, communication is initiated by the BS, which
knows both the last transmission to the receiver st−k and the
current state st, along with the time since the last update k.
Intuitively, the performance of a push-based system should
improve with respect to the pull-based one, as the former can
exploit information on the specific realization of the system
state trajectory, rather than just on its statistics. On the other
hand, remote POMDPs are multi-agent problems and may
involve critical issues in terms of coordination between the
BS and Actuator, which will be explored in the following.
Algorithm 1 Pull-Based Modified Policy Iteration
Require: P, r, β
1: Initialize VA(s, k) ← 0, randomize πA(s, k), ∆
2: while true do
3:
for (s, k) ∈ S × {0, ..., Tmax} do
4:
V ′
A(s, k) ←Update using (4)
5:
VA ← V′
A
▷ Value update step
6:
for (s, k) ∈ S × {0, ..., Tmax} do
7:
π′
A(s, k) ←Update using (6)
8:
∆′(s) ←Update using (7)
9:
if π′
A = πA ∧ ∆′ = ∆ then
10:
return πA, ∆
▷ Convergence
11:
else
12:
πA, ∆ ← π′
A, ∆′
▷ Policy improvement step
III. ANALYTICAL SOLUTION
To solve the MDP, we consider a model-based approach:
any RL agent interacting with the environment can compute
optimal control and communication policies with complete
knowledge of the reward function and the state transition
model. This can also be accomplished with statistical learn-
ing [7], i.e., by learning the transition probabilities of the un-
derlying MDP before solving the communication-constrained
problem. This choice allows for an easy comparison of the
policies, without any training issues, and the results can be
applied directly to any properly trained agent.
A. Pull-based Communication
To solve the pull-based communication problem optimally,
we propose a modified Policy Iteration (PI) algorithm to learn
the communication control policies jointly. We recall that
PI always converges to the optimal solution in single-agent
MDPs, as the one considered in pull-based scenarios.
We formulate a new MDP in which each time step is divided
into two sub-steps: one for the control action and one for
the communication action. The state of this new MDP is also
expanded to the tuple (st−k, k), which is available to the agent.
The action space is then A in control sub-steps, and {0, 1}
in communication sub-steps. The agent then splits the policy
into two parts:
• πA(st−k, k), the control policy, which maps each state
(st−k, k) ∈ S × N to an action a ∈ A;
• ∆(st−k), the communication policy, which maps each
state st−k ∈ S to the time until the next update, c ∈ N+.
Since the policy πA depends only on the last observed
state, we can determine the vector aπA
s
containing the k
actions chosen by the Actuator after observing s. Following
the bootstrap principle, the modified PI algorithm then updates
the value of a control sub-state as follows:
V ′
A(s, k) =
X
(s′,s′′)∈S2
θa
πA
s
s,k (s′)P πA(s,k)
s′,s′′

rπA(s,k)
s′,s′′
+γ (δs,k(VA(s′′, 0) − β) + (1 − δs,k) VA(s, k + 1))

,
(4)
where δs,k is a utility function equal to 1 if ∆(s) = k+1, i.e.,
if an update is requested after k + 1 steps, and 0 otherwise.
We observe that the division into sub-steps does not affect
Algorithm 2 Push-Based Alternate Policy Iteration
Require: P, r, β, π(0)
B
1: Initialize πB ← π(0)
B , randomize πA
2: while true do
3:
π′
A ←CONTROLPOLICYITERATION(P, r, β, πB)
4:
π′
B ←COMMUNICATIONPOLICYITERATION(P, r, β, π′
A)
5:
if π′
A = πA ∧ π′
B = πB then
6:
return πA, πB
▷ Convergence
7:
else
8:
πA, πB ← π′
A, π′
B
the reward and the solution to the modified problem is also
optimal for the original MDP. Therefore, we do not then need
to compute the control sub-state values explicitly.
To perform the policy improvement step, we modified the
standard update rule by using a reward that considers the entire
evolution of the Markov chain until the state is sampled again.
If we consider a state sequence s′, which begins k steps after
state s is observed, the belief ΘπA
s,k(s′) follows from (1):
ΘπA
s,k(s′) = θa
πA
s
s,k (s′(1))
L(s′)−1
Y
ℓ=1
P πA(s,ℓ+k−1)
s′(ℓ),s′(ℓ+1) ,
(5)
where L(·) is a function whose outcome is the dimensionality
of the input. Hence, the control policy is improved as follows:
π′
A(s, k) = arg max
a∈A
X
s′∈S∆(s)−k+1
ΘπA
s,k(s′)
"" ∆(s)−k
X
ℓ=1
γℓ−1ra
πA
s
(ℓ+k−1)
s′(ℓ),s′(ℓ+1)
+ γ∆(s)−k (VA(s′(∆(s) − k + 1), 0) − β)
#
.
(6)
Instead, the communication policy is updated as:
∆′(s) = arg max
n∈N+
X
s′∈Sn
ΘπA
s,1 (s′)
"" n−1
X
ℓ=1
γℓrπA(s,ℓ)
s′(ℓ),s′(ℓ+1)
+ γn(VA(s′(n), 0) − β) + rπA(s,0)
s,s′(1)
#
.
(7)
Using the whole sequence of intermediate steps in the update
equations is essential to take into account that the states
(s, k) ∀ k > 0 are non-Markovian, as the belief distribution
depends on the action sequence taken since the last commu-
nication. The pseudocode for the PI scheme for pull-based
communication is given in Alg. 1.
B. Push-based Communication
In the case of push-based communication, we propose a
simple strategy which we call Alternate Policy Iteration (API):
starting from a default policy for the BS, we first optimize the
Actuator’s policy and then optimize the BS, considering the
Actuator’s actions as fixed. Since one agent’s policy is fixed,
the other agent sees a Markovian environment, and standard
PI can be applied in each step. The procedure is then repeated
until both the policies converge, i.e., each agent follows the
optimal policy with respect to the other. As we will prove in
Sec. V, this strategy always converges in a finite number of
steps. The pseudocode for API is given in Alg. 2.
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
0.5
1
1.5
2
(a) Average reward (pull-based, fo-
cused).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
0.2 0.4 0.6 0.8
1
(b) Update frequency (pull-based,
focused).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
2
4
6
8
(c)
Average
reward
(pull-based,
spread).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
0.2 0.4 0.6 0.8
1
(d) Update frequency (pull-based,
spread).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
0.5
1
1.5
2
(e) Average reward (push-based, fo-
cused).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
0.2 0.4 0.6 0.8
1
(f) Update frequency (push-based,
focused).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
2
4
6
8
(g)
Average
reward
(push-based,
spread).
0
0.4 0.8 1.2 1.6
2
0.9
0.7
0.5
0.3
0.1
β
d
0
0.2 0.4 0.6 0.8
1
(h) Update frequency (push-based,
spread).
Fig. 1: Figure of the Reward and Communication Cost for different densities and values of β.
IV. NUMERICAL EVALUATION
In this section, we evaluate the two methods proposed on
randomly generated MDPs that follow a common structure
for a fair and easy comparison. We consider a system with
|S| = 30 states and |A| = 4 actions. The reward depends
only on the reached state and is defined as
ra
s,s′ = e−α|s′−s0|, ∀s ∈ S, a ∈ A,
(8)
where s0 ∈ S is a target state, and α is a decay parameter
determining how much the reward is concentrated around s0.
We consider two possible reward configurations:
• Focused reward: α = 10, the only state that gives a
significant reward is s0.
• Spread reward: α = 0.01, the reward is spread among
the states near s0.
In both configurations, the MDP transition matrix is gener-
ated as follows: we start from a deterministic transition matrix
for every action and then progressively increase the number
of non-zero elements by enabling transitions to neighboring
states with a certain probability. As more transitions are added,
the transition matrix becomes denser, i.e., the number d of
non-zero elements divided by the total number of entries of
the matrix increases. The density of the deterministic matrix
is simply |S|−1. If the initial deterministic matrix Pa has
a transition from s to s′, i.e., P a
s,s′ = 1, the distribution at
density d is:
P a
s,s′′ = 4(d|S| − 2|s′ − s′′|)
(d|S| + 1)2
, ∀s′′ s.t. |s′ −s′′| < d|S|
2 . (9)
According to this approach, the probability of transitioning
to neighbor states decreases linearly with the distance from
the original transition state (the distribution has a triangular
shape). Higher-density MDPs are then simply more unpre-
dictable versions of the same initial model.
To investigate our model in different scenarios, we repeat-
edly increase the number of transitions for each state by adding
two connections at a time, obtaining a total of 15 MDPs with
increasing densities. We also consider different communication
costs β ∈ {0, 0.1, . . . , 2}. We test each combination of d and β
with both pull-based and push-based policies, using the same
matrices for the push- and pull-based systems. The code for
the numerical evaluations is available to replicate the results1.
Fig. 1 shows the average obtained reward of the physical
process and the frequency of the updates between the BS and
the Actuator. First, we can note that the push-based system
always obtains a higher overall reward than the pull-based one,
as would be expected: the BS, acting with full knowledge of
the state, can determine whether an update has a high VoI,
i.e., whether it meaningfully affects the Actuator.
Fig. 1b and Fig. 1d also show that the pull-based system
only has 2 working points for higher values of d (i.e., more
unpredictable transitions): either the agent requests an update
at each step, or it never does. This is because the high
uncertainty in the belief distribution makes it hard to use it to
predict the optimal action even after a single step. This leads
the Actuator to always request the new state information if β
is low, i.e., if the relative VoI of the update increases, or never
to request updates if β is high, moving blindly.
1https://www.github.com/pietro-talli/Age-Value-CC
0
2
4
6
8
0
0.2
0.4
0.6
Peak AoI
PMF
Pull
Push
(a) AoI distribution.
1
10
20
30
2
4
6
8
State
Peak AoI
0
0.2
0.4
0.6
0.8
1
(b) Pull-based AoI distribution by state.
1
10
20
30
2
4
6
8
State
Peak AoI
0
0.2
0.4
0.6
0.8
1
(c) Push-based AoI distribution by state.
Fig. 2: Peak AoI distribution for d = 0.1, β = 1 and sparse reward.
As Fig. 1f and Fig. 1h clearly show, the push-based strategy
can reduce the update frequency. In this case, the BS can
check if the state of the system evolves in the predicted
way, transmitting an update to the Actuator only when a
low-probability transition occurs and its knowledge becomes
obsolete. This is particularly beneficial if the transition model
is more predictable, i.e., for lower values of d, and leads
to 3 working regimes: firstly, if d is very high, the BS
communicates only if the reward in the next step changes
significantly, letting the Actuator move blindly in all other
cases. This behavior is particularly noticeable in the focused
reward case when the BS only communicates if the state can
lead directly to the target.
On the other hand, the BS will also communicate sporadi-
cally if the system is very predictable, i.e., for very low values
of d, for the reasons we outlined above. In between these two
extremes, the BS will communicate more often, as the system
is not so random that the belief distribution of the Actuator
quickly becomes useless, but also not too predictable. As this
type of behavior requires the full knowledge of the state, it
cannot be obtained in a pull-based scenario.
To better highlight the different behaviors between pull- and
push-based communication, we look at Fig. 2, which analyzes
the Peak AoI for a highly predictable MDP with a sparse
reward, with d = 0.1 and β = 1. In particular, Fig. 2a shows
the Probability Mass Function (PMF) of the Peak AoI for
the two approaches: while the average update frequency is
similar, the push-based system has a much higher variance
than the pull-based one. This is because the first approach
triggers transmissions when needed, sometimes after a single
step, sometimes after many, depending on the environment’s
evolution; instead, the pull-based approach only relies on the
last observed state, and its decisions are always deterministic.
This is confirmed by Fig. 2b, which shows how, in the pull-
based scenarios, the Peak AoI distribution for each state is
concentrated in a single point. On the other hand, the push-
based system may transmit after a long time even when
starting from states that have a high expected VoI after a single
step, as Fig. 2c shows: while the pull-based system transmits
after 1 step when starting from state 2, the push-based system
has a non-zero probability of waiting 5 or more steps before
transmitting again.
V. AGE AND VALUE OF INFORMATION IN EFFECTIVE
COMMUNICATION
Concepts like AoI and VoI are crucial to analyze the
timeliness and relevance of system status updates. In our
scenario, we might consider an update strategy that balances
the frequency of updates (which determines the average com-
munication cost) with the reward obtained by the Actuator.
Let J(s) = E [P∞
t=0 γtrt | s0 = s] be the long-term reward
of the Actuator starting from state s and β be the commu-
nication cost. We can then give a more general definition of
performance in pull-based or scheduled systems as a function
of the selected update periods ∆ ∈ (N+)|S|:
Rβ(∆) =
X
s∈S
ϕ(s)
 
J(s|∆)−E
"" ∞
X
n=0
βγn∆(s′)P(s′|s, ∆)
#!
,
(10)
where ϕ(s) is the stationary state distribution induced by the
control policy and the update periods ∆.
We introduce the concept of Pareto dominance [8] to
compare the performance of complex schemes with multiple
objectives.
Definition 1. an n-dimensional tuple η = (η1, . . . , ηn) Pareto
dominates η′ (which we denote as η ⪰ η′) if and only if each
element of η is equal to or better than the corresponding
element of η′, i.e., η ⪰ η′
⇐⇒
ηj ≥ η′
j ∀j. Strict
Pareto dominance makes the inequality strict for at least one
parameter:
η ≻ η′ ⇐⇒ η ⪰ η′ ∧ ∃i : ηi > η′
i.
(11)
This concept can then be extended to multi-objective opti-
mization, i.e., to schemes that may have different parameters
and multiple performance metrics.
Definition 2. Let us consider two schemes x and y, parame-
terized by a vector θx and θy. Scheme x Pareto dominates y
if and only if:
x ⪰ y ⇐⇒ ∀θy∃θx : η(θx) ⪰ η(θy),
(12)
where η(θz) is the n-dimensional performance vector associ-
ated with scheme z and parameters θz. The definition of strict
dominance between schemes is analogous.
If we only consider the AoI, without including state infor-
mation in the optimization, we can envision a periodic policy
in which the BS sens a new update every ∆ ∈ N+ steps. In
this case, the optimal update interval ∆∗
AoI is then:
∆∗
AoI(β) = arg max
∆∈N+
X
s∈S
ϕ(s)
 
J(s | ∆) −
∞
X
n=0
βγn∆
!
.
(13)
In particular, we have that ∆(s) = ∆∗
AoI ∀s ∈ S, i.e., the
optimal AoI ∆∗
AoI is the same for all states.
An adaptive pull-based strategy selecting the best ∆pull(s)
based on the state s ∈ S received in the last update can
improve the reward function in (10) will respect the AoI-based
approach. In this case, the optimization problem then becomes:
∆∗
pull(β) = arg max
∆∈(N+)|S| Rβ(∆).
(14)
Theorem 1. The pull-based EC strategy Pareto dominates the
AoI-based policy, i.e., ∆∗
pull(β) ⪰ ∆∗
AoI(β) ∀⟨S, A, P, r, γ, β⟩.
Proof. First, we can trivially show that a scheme working
better than another for every value of β is a stronger condition
than Pareto dominance. We can then prove that this condition
holds by reductio ad absurdum: we consider a hypothetical
optimal interval ∆∗
AoI which performs better than pull-based
EC for a given value of β. In this case, ∆∗
pull cannot be optimal,
as the vector in which all elements are equal to ∆∗
AoI is one
of the possible choices for pull-based EC.
We observe that the pull-based strategy can always fall
back to the same point as the AoI-based one, simply by
considering the same interval for every state. In this case,
the VoI is implicitly determined by the strategy: the Actuator
only requests an update if the expected increase in the long-
term reward is larger than the communication cost β, and that
increase is precisely the value of the update.
We can further improve performance by adopting a push-
based approach, allowing the BS may be able to independently
observe the system state st and consequently decide whether
to update the Actuator’s knowledge. This prevents us from
defining a fixed state-dependent update period, as the policy
πB(s, k, st) depends on the current state st as well as on the
last state update st−k and the elapsed time k. Particularly, the
value function for the BS is:
VB(s, k, s′) = πB(s, k, s′)(VB(s′, 0, s′)−β) + (1−πB(s, k, s′))
×
X
s′′∈S
P πA(s,k)
s′s′′

rπA(s,k)
s′,s′′
+ γVB(s, k + 1, s′′)

,
(15)
and the optimal policy is the one maximizing the communi-
cation value.
The discovery of the optimal policies through API can be
seen as the solution to a Markov game [13]: the two agents
act as players in a game where the moves are the possible
policies and the payoff for each player is the expected reward
in the initial state.
0
4
1
2
3
a2, p = 0.5
a2, p = 0.5
a1
a1
a1
a1
a1
a2
a2
a2
a2
Fig. 3: Example of a Markov model with 5 states and 2 actions.
Theorem 2. The API approach leads to a Nash Equilibrium
(NE) policy in the push-based problem.
Proof. Firstly, we can trivially prove that the considered
Markov game is an exact potential game [14]: as the reward
for the two agents is the same, the expected long-term reward
is a potential function for the game. We then consider the
API strategy: each round of the iterated algorithm leads to the
optimal policy when the strategy of the other agent is given,
due to the optimality of standard PI. The API algorithm is
then an Iterated Best Response (IBR) scheme for the game,
which leads to a NE in a finite number of steps in all finite
potential games [14].
However, reaching an NE is not a guarantee of Pareto
optimality: games may have multiple NEs, and finding the
optimal one is PPAD-hard [15]. The push-based approach may
be actively harmful, even with respect to an AoI policy.
Theorem 3. The optimal EC solution to the push-based prob-
lem, π∗
B,push, Pareto dominates the pull-based EC strategy:
π∗
B,push(β) ⪰ ∆∗
pull(β) ⪰ ∆∗
AoI(β) ∀⟨S, A, P, r, γ, β⟩. (16)
However, the solution obtained by the API strategy, πAPI
B,push,
does not Pareto dominate the AoI-based strategy:
∃⟨S, A, P, r, γ, β⟩ : πAPI
B,push(β) ⪰̸ ∆∗
AoI(β).
(17)
Proof. The proof of the first statement is simple, and follows
the proof of Theorem 1: as the BS can act with full knowledge
of the state, the pull-based solution is a possible solution to the
push-based problem, and in some cases, better solutions exist.
The knowledge of the realization of the state can improve
the reward, either by cutting unnecessary transmissions or by
improving the actuator’s performance.
As finding the optimal solution to a Markov game is PPAD-
hard [15], no polynomial-time algorithm can reliably find
π∗
B,push. We can then give a counterexample to prove the
second part of the theorem: we consider a simple MDP with
5 states and 2 actions, whose evolution is depicted in Fig. 3.
The two transition matrices corresponding to a1 and a2 are:
Pa1 =


0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
1
0
0
0
0
0
0
0
0
1

, Pa2 =


0
0.5
0
0
0.5
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
1
0
0
0
0

.
(18)
The reward is then always 0, except for when the environment
transits to state 0, i.e., we have ra
s,0 = 1 and ra
s,s′ = 0 ∀s′ ̸= 0.
We can easily see that taking action a1 in state 0 leads to
a loop with 4 states, while taking action a2 may lead to a
shorter path back to the reward-giving state. We consider a
policy ∆AoI that transmits in each odd step, ensuring that the
actuator always knows if it lands in state 1 or state 4 after
taking action a2. Its expected long-term reward is:
R(∆AoI) =1 − γβ + γ2R(∆AoI)
2
− γ3β
2
+ γ4R(∆AoI)
2
=2 − (2γ + γ3)β
2(1 − γ2 − γ4) .
(19)
Considering a push-based approach and applying the API
strategy, the final results depend on the initial policy of the BS.
If the process starts from a policy that communicates often,
e.g., one that always communicates the state, the algorithm
will converge to the optimum joint policy, which only com-
municates if it deviates from the short cycle (i.e., if the system
ends up in state 1). In this case, the expected reward is
R(π∗
B,push) =1 − γβ +
γ2R(π∗
B,push)
2
+
γ4R(π∗
B,push)
2
=
2 − γβ
2(1 − γ2 − γ4),
(20)
which is better than the AoI policy for any value of β ∈ R+
and γ ∈ (0, 1).
Instead, if the API strategy starts from a policy that never
communicates, the actuator will take the conservative choice,
and always take action a1. This is another NE of the system,
as the BS should never communicate if the actuator’s policy
is independent of the state. The reward for this solution is:
R(πAPI
B,push) =1 + γ4R(πAPI
B,push) = (1 − γ4)−1.
(21)
In this case, the API solution is not Pareto dominant, as it
performs worse than a simple AoI-based strategy under the
following conditions:
β <
2
(2 + γ2)(1 − γ4).
(22)
The optimal policy might not be easy to obtain in more com-
plex systems, and if we consider previously unknown cases in
which PI must be replaced by RL, running multiple training
procedures to achieve the optimal NE might be expensive or
impossible. Despite this evidence, most of the literature on
VoI has so far focused on push-based solutions [16], which
fall prey to this coordination problem.
VI. CONCLUSION
This work analyzes EC strategies in CPSs, considering the
performance of the control system as the VoI and analyzing the
interactions between the communication and control policies.
We propose an analytical framework to adapt classical opti-
mization tools such as PI to this context, providing numerical
results that show a strong dependency between the VoI and the
structure of the underlying MDP. Less predictable MDPs and
sparser rewards tend to lead to a higher value of updates, al-
though there are interesting patterns in the interaction between
communication and control.
Finally, our analysis revealed that the common push-based
view of communication and control problems may not always
be optimal, as the game theoretical properties of multiagent
scenarios do not guarantee that a solution may be better
even than a simple AoI-based optimization. Future extensions
of this work will concentrate on this conundrum, analyzing
more complex examples of remote POMDPs and devising
heuristic strategies that provide good performance in practical
scenarios.
REFERENCES
[1] X.-M. Zhang, Q.-L. Han, X. Ge, D. Ding, L. Ding, D. Yue, and C. Peng,
“Networked control systems: A survey of trends and techniques,”
IEEE/CAA Journal of Automatica Sinica, vol. 7, no. 1, pp. 1–17, 2019.
[2] L. Da Xu, W. He, and S. Li, “Internet of things in industries: A survey,”
IEEE Transactions on industrial informatics, vol. 10, no. 4, pp. 2233–
2243, 2014.
[3] F. Mason, F. Chiariotti, A. Zanella, and P. Popovski, “Multi-agent
reinforcement learning for pragmatic communication and control,” 2023.
[4] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction.
MIT press, 2018.
[5] L. Busoniu, R. Babuska, and B. De Schutter, “A comprehensive survey
of multiagent reinforcement learning,” IEEE Transactions on Systems,
Man, and Cybernetics, Part C (Applications and Reviews), vol. 38, no. 2,
pp. 156–172, 2008.
[6] G. E. Monahan, “State of the art—a survey of partially observable
Markov decision processes: theory, models, and algorithms,” Manage-
ment science, vol. 28, no. 1, pp. 1–16, 1982.
[7] H. A. Nam, S. Fleming, and E. Brunskill, “Reinforcement learning
with state observation costs in action-contingent noiselessly observable
Markov decision processes,” Advances in Neural Information Processing
Systems, vol. 34, pp. 15 650–15 666, 2021.
[8] V. Pareto, Manuale di economia politica con una introduzione alla
scienza sociale.
Societ`a Editrice Libraia, 1919.
[9] S. Rostami, S. Lagen, M. Costa, M. Valkama, and P. Dini, “Wake-
up radio based access in 5G under delay constraints: Modeling and
optimization,” IEEE Transactions on Communications, vol. 68, no. 2,
pp. 1044–1057, 2019.
[10] J. Pineau, G. Gordon, S. Thrun et al., “Point-based value iteration: An
anytime algorithm for pomdps,” in Ijcai, vol. 3, 2003, pp. 1025–1032.
[11] T. Smith and R. Simmons, “Point-based pomdp algorithms: improved
analysis and implementation,” in Proceedings of the Twenty-First Con-
ference on Uncertainty in Artificial Intelligence, 2005, pp. 542–549.
[12] T.-Y. Tung, S. Kobus, J. P. Roig, and D. G¨und¨uz, “Effective communi-
cations: A joint learning and communication framework for multi-agent
reinforcement learning over noisy channels,” IEEE Journal on Selected
Areas in Communications, vol. 39, no. 8, pp. 2590–2603, 2021.
[13] X. Wang and T. Sandholm, “Reinforcement learning to play an optimal
nash equilibrium in team markov games,” Advances in Neural Informa-
tion Processing Systems (NIPS), vol. 15, 2002.
[14] D. Monderer and L. S. Shapley, “Potential games,” Games and Economic
Behavior, vol. 14, no. 1, pp. 124–143, 1996.
[15] X. Deng, N. Li, D. Mguni, J. Wang, and Y. Yang, “On the complexity
of computing Markov perfect equilibrium in general-sum stochastic
games,” National Science Review, vol. 10, no. 1, p. nwac256, 2023.
[16] D. G¨und¨uz, F. Chiariotti, K. Huang, A. E. Kalør, S. Kobus, and
P. Popovski, “Timely and massive communication in 6G: Pragmatics,
learning, and inference,” IEEE BITS the Information Theory Magazine,
2023.
"
"This paper presents a run-time software testing, analysis, and code optimization method for quantum neural network software in advanced Internet-of-Things systems, which visually presents the learning performance called barren plateau. The visual presentation of barren plateau situations is helpful for real-time quantum-based advanced IoT software testing because software engineers can be aware of the training performances of QNN. The proposed method is also capable of visual feedback.nan","In modern daily lives, people utilize Internet services not only in smartphones but also in wearable devices. IoT enables the global Internet connection among all IoT devices, which realize the utilization of data from built-in sensors in the devices. QNN-based models can utilize much fewer parameters comparing to conventional deep neural network-based models and generally achieve fast convergence and high scalability. However, QNN-based models are more difficult to be trained due to barren plateaus and tracking barren plateaus is essential for measuring the stability of QNN software. Therefore, a new software test, analysis, and code optimization tool for QNN software is required to visually identify barren plateau situations. This will be a beneficial approach for software engineers in designing and developing high-accurate QNN-based advanced IoT software. The proposed TACO is also capable of visual feedback.nan","QNN-based models are advantageous in terms of data processing acceleration and low computational complexity, but have a disadvantage of the barren plateaus situation which can make the loss gradient of QNN-based models vanish due to entanglement. Various approaches have been suggested to tackle this situation, but these research results require deep-dive understanding in quantum mechanics, quantum computing, and quantum optimization. To resolve this problem from the viewpoints of deep learning software engineers, a novel software development and analysis tool is required.nannan","The design rationales of TACO are: 1) Barren Plateaus Problem Tracking, 2) Dynamic Run-Time Software Testing, and 3) HCI-based Visualization. The overall architecture of TACO consists of VQC Structure, TACO Engine, TACO I/O, and External Visualization Engine. VQC Structure is implemented by torch-quantum, and the gradient derivation is operated via backward(). VQC Structure Extractor calls parameter information and iterative gradient derivation calculation is operated. Barren Plateau Estimator estimates the barren plateau occurrences and values. Model Feedback Generator handles the case where the barren plateau situations (i.e., the variance of gradients) happens in all quantum gates.nan",The results show that the proposed TACO can identify which quantum gates fall into barren plateaus situations with text messages. Software engineers can monitor and observe QNN-based model training performances using TACO. The proposed TACO can also identify which quantum gates fall into barren plateaus situations with text messages.nan,"This paper introduces a novel dynamic run-time software testing, analysis, and code optimization (TACO) tool for QNN-based model software, which visually presents gradient variances in order to identify whether barren plateaus occur or not for advanced IoT systems software. This TACO tool is obviously useful for software engineers because it can intuitively guide them in order to design and implement high-accurate QNN-based models for advanced IoT applications even if they are not familiar with quantum mechanics and quantum computing. Moreover, the proposed TACO is also capable for visual feedback because software engineers recognize barren plateaus using visualization via tensorboard; and then, they modify QNN-based model structures based on that. Future work can extend TACO to track and test other factors in QNN, and extend TACO for distributed learning architectures.nan","Quantum Neural Network Software Testing, Analysis, and Code Optimization for Advanced IoT Systems: Design, Implementation, and Visualization","Soohyun Park, Joongheon Kim","1
Quantum Neural Network Software Testing,
Analysis, and Code Optimization for Advanced IoT
Systems: Design, Implementation, and Visualization
Soohyun Park and Joongheon Kim, Senior Member, IEEE
Abstract—This paper introduces a novel run-time testing, anal-
ysis, and code optimization (TACO) method for quantum neural
network (QNN) software in advanced Internet-of-Things (IoT)
systems, which visually presents the learning performance that
is called a barren plateau. The run-time visual presentation of
barren plateau situations is helpful for real-time quantum-based
advanced IoT software testing because the software engineers can
easily be aware of the training performances of QNN. Moreover,
this tool is obviously useful for software engineers because it
can intuitively guide them in designing and implementing high-
accurate QNN-based advanced IoT software even if they are
not familiar with quantum mechanics and quantum computing.
Lastly, the proposed TACO is also capable of visual feedback
because software engineers visually identify the barren plateau
situations using tensorboard. In turn, they are also able to modify
QNN structures based on the information.
Index Terms—Quantum Neural Network, Dynamic Software
Analysis, Software Testing, Internet of Things
I. INTRODUCTION
In modern daily lives, every single person actively starts
to utilize Internet services not only in smartphones but also
in wearable devices such as smartwatches and smartglasses.
This trend can be realized due to the advances in Internet-
of-Things (IoT) technologies where the ultimate mission of
IoT is for enabling global Internet connection among all IoT
devices which can realize the utilization of the perceived
data from built-in sensors in the devices. For the example
of IoT-based autonomous driving, the technologies have un-
dergone significant development, and recent advances have
made precise low-delay real-time perception of surrounding
driving environments [1]. As presented in Fig. 1, the envi-
ronment perception involves recognition objects from various
sensors using wireless communications, which deliver sensor
information from IoT devices to their associated centralized
server [2]. After gathering sensor information from deployed
IoT devices, the server conducts deep learning computation
for various application-specific AI services such as detection,
classification, and recognition. Then, the trained parameters
will be delivered back to the individual IoT devices in order
to realize the services. In this scenario, the use of quantum
neural network (QNN)-based deep learning models is defi-
nitely beneficial for computation/memory-limited IoT devices
due to the fact that QNN-based models can utilize much fewer
S.
Park
and
J.
Kim
are
with
the
School
of
Electrical
Engi-
neering, Korea University, Seoul 02841, Republic of Korea (e-mails:
{soohyun828,joongheon}@korea.ac.kr).
Sensor Information
IoT Sensors
Wearable Devices
Mobile Devices
Quantum Neural Network
PQC
Structure 
Evaluator
TACO
Barren 
Plateau 
Estimator
Model
Feedback 
Generator
Cloud 
QNN Model Parameters
Run-Time 
S/W Testing 
QNN Model 
Information
Fig. 1. Run-Time Software Testing and Analysis in QNN-based IoT Systems.
parameters comparing to conventional DNN-based models [3].
Moreover, QNN-based models are generally able to achieve
fast convergence and high scalability, not only in IoT devices
but also in various computing platforms [3].
However, QNN-based models can be more difficult to be
trained comparing to the training of conventional DNN-based
models because of barren plateaus, where it is defined as the
nonlinearity index depending on the amounts of entanglements
in quantum circuits [4]. Therefore, it is essentially required to
track the barren plateaus for measuring the stability of QNN
software.
In the perspective of testing, analysis, and code optimization
of QNN software, it should be helpful to obtain high-accurate
QNN execution results in a fast way, even if software engineers
are not familiar with the concepts of quantum computing.
Therefore, it is essentially required to design and implement
a new software test, analysis, and code optimization (TACO)
tool for QNN software, which should visually identify barren
plateau situations for the explainability and trainability of
QNN. In addition, it should provide feedback that is useful
for software testing, analysis, and code optimization. Based
on this TACO tool for QNN software, software engineers are
able to re-organize and optimize their own QNN software
arXiv:2401.10914v1  [cs.SE]  12 Jan 2024
2
codes. Here, the concept of human-computer interaction (HCI)
can be involved because the human (software engineers) can
re-organize and optimize the codes for the computer (IoT
devices); in turn, the computer can visualize the barren plateau
situations to the software engineers. These barren plateau situ-
ations generally occur in QNN-based models due to the oper-
ations of i) quantum controlled gates and ii) the superposition
of qubits. In addition, according to the entanglement among
multiple qubits, QNN-based models are able to improve their
own performances. These entangled quantum states are advan-
tageous in terms of capacity, whereas multi-qubit interference
increases while many quantum controlled gates and qubits are
simultaneously operated. This introduces the situation where
QNN-based model training optimization is impossible due
to barren plateaus. Therefore, it is critical to design high-
accurate QNN-based models for improving learning training
performance. Among significant research contributions to deal
with the barren plateau problem, it has been verified that
the barren plateau problem is associated with the structure
of QNN-based models [4]. Therefore, controlling the system
size in the structure of QNN-based models enhances the per-
formance of quantum learning training. During this procedure,
general software engineers will be in trouble in terms of i)
understanding quantum mechanics, quantum computing, and
quantum neural networks (including the definition of barren
plateaus) and ii) the identification of optimal system size in
the structure of QNN-based models in order to reduce quantum
entanglement interference.
Motivated by this, a novel software testing and analysis
tool, i.e., TACO is designed which enables dynamic run-
time software testing and analysis in advanced IoT systems.
As depicted in Fig. 1, quantum-based advanced IoT systems
are capable to perform various tasks, including surveillance
for IoT sensors, recognition for mobile devices, and sens-
ing/processing for wearable devices. During this process, our
software testing and analysis tool, TACO, is able to provide
real-time updates on the information that is trained by ad-
vanced IoT systems, thereby enabling the tool to verify the
accuracy of the perception during run-time execution.
The main contributions and objectives of this paper can be
categorized and summarized as follows.
• Firstly, our proposed TACO is the world-first software
testing, analysis, and code optimization tool of QNN-
based models in advanced IoT systems. The main objec-
tive of TACO is for pursuing high-accurate and stabilized
performance maintenance in the QNN-based models by
controlling the degree of entanglements.
• Moreover, the additional objective of TACO is to provide
intuitive approaches such as visualization and HCI-based
feedback for general software engineers during QNN-
based model design and implementation.
• Lastly, this paper provides the various extension di-
rections of TACO those are considerable for emerging
applications.
The rest of this article is organized as follows. Sec. II
introduces quantum supremacy and the limitations. In addition,
Sec. III presents the details of our proposed TACO for QNN
software testing and visualization. Moreover, Sec. IV outlines
relevant corresponding open discussions, and lastly, Sec. V
concludes this paper.
II. QUANTUM SUPREMACY AND LIMITATIONS
This section firstly introduces the foundations of QNN (refer
to Sec. II-A), and then discusses its advantages (refer to
Sec. II-B) and one of major disadvantages which is called
barren plateau (refer to Sec. II-C), respectively.
A. Quantum Neural Networks
The conventional neural network can be mathematically
interpreted as the sequential combination of multiple i) linear
transformation and ii) nonlinear transformation. The struc-
ture of QNN-based models is basically similar to the struc-
ture of conventional neural networks. Note that one of the
major differences between the two neural networks is that
the training/inference computation of QNN-based models is
performed over Hilbert spaces whereas the computation of
conventional neural networks is performed over real number
spaces. Therefore, the QNN-based models optimize their ob-
jective functions in quantum states over Hilbert spaces. The
detailed structural components of QNN-based models, called
quantum gates, are i) quantum rotation gates for quantum state
transformation over Bloch sphere and ii) quantum-controlled
gates for entanglement generation with other qubits. With the
utilization of these quantum gates, the structure of QNN-based
models consists of i) state encoding (encoding the classical
data over real number spaces to the quantum states over Hilbert
spaces, i.e., converting classical 0 or 1 bits into qubits), ii)
parameterized quantum circuit (PQC) (controlling the rota-
tions and entanglements for input quantum states under the
utilization of quantum gates), and iii) measurement (decoding
the quantum states over Hilbert spaces into the classical data
over real number spaces, i.e., converting qubits into classical
0 or 1 bits, during training optimization). After this structural
computation, the quantum states in the QNN-based models
can be observed; and this is conducted for minimizing its own
cost function. The procedures i–ii), i.e., state encoding and
parameterized quantum circuit, are linear transformations, and
the procedure iii), i.e., measurement, is a unique non-linear
transformation [5].
This QNN-based model is advantageous compared to con-
ventional neural networks in terms of data processing ac-
celeration and low computational complexity. However, this
QNN-based model has disadvantages as well; and one of
the disadvantages is the barren plateaus situation which can
make the loss gradient of QNN-based models vanish due to
entanglement. More details about this barren plateaus problem
will be discussed later (refer to Sec. II-C).
B. Advantages in QNN
The advantages of QNN for can be listed as follows.
• High Scalability. As theoretically well-justified in [6],
QNN-based models can expand the output dimensions to
an exponential scale by incorporating Pauli-Z measure-
ment and basis measurement, surpassing the limitations
3
External Feedback Depictor 
TACO Core
PQC
Structure 
Target QNN Code
TACO Main
TACO I/O
PQC
Structure 
Evaluator
Barren 
Plateau 
Estimator
Model
Feedback 
Generator
TACO Module
User Command (Visualization Setting)
Barren Plateau
PQC
Structure 
Feedback 
from TACO
User Command,
Feedback Request
Quantum
Interference
Model 
Feedback
Parameter
Crawling
Architecture 
Information
Input Tareget 
QNN Code
PQC Structure 
Feedback
Explainability
Extractor
Trainability
Extractor
IoT 
Device
Cloud
Fig. 2. Overall Process of TACO, i.e., Dynamic Run-Time Quantum Software Testing, Analysis, and Code Optimization.
imposed by the limited number of qubits in the noisy
intermediate scale quantum (NISQ) era.
• Fewer Parameter Utilization. QNN-based models have
the ability to achieve similar performance to conventional
neural networks with fewer parameters, primarily due to
superposition and entanglement. Firstly, the superposition
allows the quantum models to exist in multiple states at
once simultaneously, and thus, it expands the represen-
tational dimension. Moreover, the entanglement provides
solid relationship among quantum states using controlled-
NOT (CNOT) gates, and thus, it realizes nonlinear rep-
resentation with fewer parameters.
• Fast Convergence. In QNN, the parameter shift rule is
used during training instead of the backpropagation in
conventional neural network training. The parameter shift
rule provides simple and direct approaches, and thus,
QNN-based model training can be accelerated further
than conventional neural network training.
C. Barren Plateaus
The barren plateau is one of the well-known harmful
problems for QNN-based learning model training optimiza-
tion where the loss function gradients are exponentially and
dramatically degradated due to entanglement [4]; and this
can lead to local minima during cost function minimization.
Moreover, recent remarkable research results confirm that a lot
of barren plateaus can occur during QNN-based model training
optimization [5]. For more details, the number of barren
plateaus is proportioned to the number of qubits exponentially,
and this means the occurrence of barren plateaus depends on
QNN-based model design and implementation. Furthermore,
it is hard to escape from the barren plateaus [4]. In order to
tackle this situation, various approaches have been suggested.
However, these research results fundamentally require deep-
dive understanding in terms of quantum mechanics, quantum
computing, and quantum optimization. To resolve this problem
from the viewpoints of deep learning software engineers, it is
obvious that a novel software development and analysis tool
is required which can efficiently inform the barren plateau
occurrences during QNN-based model training optimization.
III. TACO FOR QNN-BASED MODELS
A. Design
The details of three fundamental design rationales of TACO
are as follows.
1) Barren Plateaus Problem Tracking: For the design of
high-accurate QNN-based model software, TACO informs the
barren plateaus situation occurrence and its corresponding
performance degradation to quantum machine learning soft-
ware developers and engineers. According to this beneficial
functionality of TACO, the QNN software engineers are able to
significantly reduce the degraded QNN-based model training
performances. As a result, software engineers can achieve
robust and resilient QNN-based model training optimization.
2) Dynamic Run-Time Software Testing: It is interesting to
know that the software testing and analysis of QNN-based
model software codes is not able to be conducted using
static analysis. This is because the static analysis conducts
the software testing for the integrity of QNN software with
original codes. The reason is that the QNN software codes
should be tested and verified while qubits inputs are fed to
QNN-based models where the qubits exist in probabilistic
quantum states before the measurement. Hence, it is essential
to conduct the software testing for the given QNN-based model
software codes using dynamic run-time analysis which tests
the integrity of QNN software codes during their run-time
executions.
3) HCI-based Visualization:
For identifying the barren
plateaus situations those are harmful for the high-accurate ex-
ecution of QNN-based models, TACO observes the dynamics
of barren plateaus (i.e., variances of gradients) while the qubit
state changes over time. Therefore, the visualization of the
barren plateau dynamics over time is fundamentally required
for intuitive understanding to QNN software engineers. Then,
4
IoT Device
Cloud
- Make a sample QNN code
- Forward QNN code information
- Process TACO Core
- Plot variance in real-time   
- Interpret the feedback of TACO
- Modify QNN code
Input target code
Transmit user command
(Visualization Setting)
Transmit visual feedback 
for the target QNN code 
Input the modified target code
Fig. 3. Flowchart of TACO
they can easily understand the performance of the given
QNN-based models, even if the software engineers are not
familiar with the basic knowledge of quantum mechanics,
quantum computing, and quantum machine learning. Lastly,
these visualization results can provide sufficient information
to software engineers, and then, they can provide feedback
information to TACO via HCI-based visual feedback.
B. Implementation
The overall software architectures and their corresponding
implementation of TACO are illustrated in Fig. 2, and the
detailed descriptions are as follows.
• VQC Structure: This is a variational quantum circuit
(VQC) and this is the user input by software engineers. In
our implementation by the softwareengineers, the consid-
ering QNN-based model software code is implemented by
torch-quantum. In the QNN-based model software
code, the quantum rotation gates and controlled gates
are organized and implemented by the random layers
in torch-quantum. The example implementation of
VQC Structure is presented in Fig. 4. For (Lines 4–6)
in Fig. 4, the defined class of VQC Structure is with
n_wires which stands for the number of input qubits.
Additionally, this has encoder which converts classical
bits into qubits. Moreover, pqc exists in this VQC
Structure class and this consists of multiple quantum
rotations and controlled gates. For (Line 8–17) in Fig. 4,
the function called forward is defined when the object
of the QNN-based model is generated. The input of this
object feeds into encoder and pqc, sequentially. After
conducting this procedure, tq.PauliZ() (defined in
tq.expval()) is able to compute projections over z-
axis. Finally, the output result of a measurement can
be obtained, and this is the computed and approximated
action of our trained QNN-based models.
• TACO Engine: Our TACO engine in Fig. 2 consists of
following three modules, i.e., VQC Structure Extractor,
Barren Plateau Estimator, and Model Feedback Gen-
erator.
– VQC Structure Extractor:
This calls parame-
ter information via named_parameters() in
torch-quantum; and the iterative gradient deriva-
tion calculation is operated via backward().
– Barren Plateau Estimator: This estimates the bar-
ren plateau occurrences and values where the value
stands for the variance of gradients in the quantum
gates of QNN-based models. For more details, we
can track the computation falls into a barren plateau
when the variance of the gradient suddenly drops.
The implementation of this variance of the gradient
can be by var() which is one of the statistics
functions in torch-quantum.
– Model Feedback Generator: This generator han-
dles
the
case
where
the
barren
plateau
sit-
uations
(i.e.,
the
variance
of
gradients)
hap-
pens
in
all
quantum
gates.
In
addition,
this
generates text messages which include epoch,
parameter index,
parameter type,
and
barren plateaus value.
• TACO I/O: It manages the inputs and outputs of TACO.
It sends the data of VQC structure feedback for visual-
ization to External Visualization Engine (i.e., tensor-
board in our implementation).
• External Visualization Engine: This engine is for
recording the data from TACO and presenting to our con-
sidering tensorboard. The training data can be plotted
using this engine. This conducts the visualization of ‘train
5
class VQC_Structure(tq.QuantumModule):
def __init__(self):
super().__init__() 
self.n_wires = 4
self.encoder = tq.GeneralEncoder(enc_dict[‘4x4_ryzxy’]) 
self.pqc
= tq.RandomLayer(n_ops = 50, wires = [0, 1, 2, 3])
def forward(self, input, q_device):
batch_size
= input.shape[0]
input
= input.reshape(batch_size, -1).to(dtype = torch.complex64)
self.encoder(q_device, input)
self.pqc(q_device)
action_dist
= tq.expval(q_device,
[i for i in range(num_class)],
[tq.PauliZ() for _ in range(num_class)]
).squeeze()
return action_dist
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
Fig. 4. The Example Code for VQC Structure.
Epoch
Accuracy
Run-Time
Plotting Result
Visualization
Metric / Accuracy
tag: Metric / Accuracy
0.4
0.3
0.2
0.1
0.5
0
10
20
30
0.4
0.3
0.2
0.1
0.5
0.6
100
40
20
0
60
80
Fig. 5. Test Accuracy.
Normal
Behaviors
Run-Time
Plotting Result
Visualization
Metric / BarrenPlateaus
tag: Metric / BarrenPlateaus
Variance
Barren Plateaus
8e-3
6e-3
4e-3
2e-3
0
0
10
20
30
0.012
8e-3
4e-3
0
100
40
20
0
60
80
Epoch
Fig. 6. Barren Plateaus.
loss’, ‘test accuracy’, and ‘barren plateaus’ values. Then,
QNN software engineers are able to identify training data
via tensorboard and also check which local parameters
are in barren plateau situations.
Based on this implementation, the operational flowchart can
be illustrated as Fig. 3. Firstly, IoT devices make a sample
QNN code and forward the QNN code information to their
associated cloud, i.e., target code input. Additionally, IoT
devices transmit the user command for visualization setting.
Then, the could processes TACO Core and plots variance in
real-time for barren plateaus tracking. Then, the results will
be transmitted to its associated IoT devices for the visual
feedback pf the target QNN code. After receiving the feedback
at IoT devices, they interpret the feedback of TACO and
modify their QNN codes based on that. Finally, the IoT devices
deliver the modified target QNN code input to their associated
cloud.
C. Visualization
The run-time visualization results for dynamic run-time
software testing and analysis using TACO are illustrated in
Fig. 5 and Fig. 6, where Fig. 5 shows the test accuracy over
time during QNN-based model training optimization and Fig. 6
shows the variances over time in quantum rotation gates (i.e.,
RX, RY , and RZ) in VQC at every epoch. If the variances
suddenly drop, it is obvious that the corresponding quantum
gates fall in barren plateaus situations. As shown in Fig. 5,
the test accuracy drops to approximately 35% from 35 to 75
epochs, where the number of quantum rotation gates those
are in barren plateau situations is the highest as demonstrated
in Fig. 6. Accordingly, it can be observed that there exists
a negative relationship between the performance of QNN-
based models and barren plateau situations. Moreover, Fig. 6
presents run-time performance evaluation results plotting over
time with visualization. Therefore, it is able to provide intuitive
understanding for software engineers even in cases where they
are not familiar with quantum mechanics, quantum comput-
ing, and quantum optimization. Finally, the proposed TACO
can identify which quantum gates fall into barren plateaus
situations with text messages.
6
In summary, software engineers are able to monitor and ob-
serve QNN-based model training performances using TACO.
If the performance of current QNN-based model training op-
timization is less than expectation, the software engineers can
identify the problematic quantum rotation gates using ’Model
Feedback’ in the proposed TACO. Thanks to this advantage
of this TACO, the software engineers can adequately control
the parameters of the problematic quantum rotation gates in
order to improve QNN-based model training performances.
IV. OPEN DISCUSSIONS
A dynamic run-time software testing and analysis tool,
called TACO, is proposed and it is for verifying the trainability
and explainability of QNN-based model software for advanced
IoT systems. In order to realize the QNN functionalities in
advanced IoT systems, it is required to address open issues
in terms of the usability of quantum computing technologies,
i.e., i) quantum computer miniaturization, ii) limitations in the
NISQ era, and iii) commercialization.
A. Quantum Computer Miniaturization
Recently, most of the research contributions in the areas
of quantum computing, quantum algorithms, and QNN are
aiming to improve computation performance in terms of
speed and computing resources. Therefore, industry compa-
nies such as IBM and Google have produced large quantum
computing platforms. As a result, it has been widely known
that quantum computers are heavy and must be stored in
cryogenic environments. Therefore, people may have questions
about the feasibility of quantum computer utilization in IoT
devices for QNN-based model utilization. However, there are
already triumphant attempts at building miniaturized quantum
computers. For example, Alpine Quantum Technologies has
developed a commercial 19-inch rack-mounted 20-qubit quan-
tum computer; and demonstrating that it is possible to lessen
the size of quantum computers [7]. For more details, it only
requires two fully custom racks, runs in a room temperature
environment, and consumes less than 2 kW of power. Based
on the pace of progress in quantum computers, the potential of
QNN utilization for reliable IoT systems is significant and it is
obvious that the quantum computer miniaturization technology
development is enough to be realized. Moreover, Quantum
Brilliance developed a 5-qubit miniature quantum computing
platforms with the size of a desktop mainframe. Lastly, SpinQ
created a portable 2-qubit quantum computer called Gemini
mini.
B. Limitation in the NISQ Era
Based on the utilization of quantum computing, it is possible
to realize accurate and accelerated massive large-scale data
processing. However, according to the limitations of hardware
technologies in quantum computing, the number of qubits that
can be utilized for real-time computation is strictly limited in
the noisy intermediate-scale quantum (NISQ) era. In this case,
quantum errors occur during the computation with quantum
gates and circuits, when a relatively larger number of qubits
is utilized. This is definitely harmful to advanced IoT related
decision-making if the decision-making is made by QNN-
based models. In order to deal with this problem, significant
and novel research results have been proposed for taking care
of quantum errors in advanced IoT systems. For example,
the proposed algorithm in [8] conducts the classification
tasks during 3D point cloud data processing for IoT-capable
autonomous driving with a small number of qubits. It is
also confirmed that this algorithm outperforms other learning-
based methods. Moreover, the proposed algorithms in [9],
[10] are for quantum actor-critic reinforcement learning in
order to control multiple autonomous mobile robots and mul-
tiple unmanned aerial vehicles, respectively. These algorithms
outperform other learning-based methods even though they
utilize a small number of qubits. Furthermore, many experts in
QNN and quantum computing predict that several hundreds of
qubits can be utilized where the qubits are in low-noise situa-
tions [11]. For example, academia and industry experts expect
that IBM will design its own quantum computer which can
utilize 4, 000 qubits until 2025 [12]. Lastly, Baidu designed
and implemented its own 10-qubit quantum computer that is
named to Qian-Shi; and insists that the quantum computer can
deal with many real-world on-hand problems [12].
C. Commercialization
In order to deploy QNN and quantum computing tech-
nologies in advanced IoT systems, the mass production and
commercialization of quantum computers should be realized
and established. Shenzhen SpinQ Technology, which is one of
quantum computing startups in China, sells portable quantum
computers with the prices from 5, 000 to 9, 000 US dol-
lars [13]. Furthermore, it is clear that the prices can be dramat-
ically decreased for mass production and commercialization.
V. CONCLUSIONS AND FUTURE WORK
This paper introduces a novel dynamic run-time software
testing, analysis, and code optimization (TACO) tool for
QNN-based model software, which visually presents gradient
variances in order to identify whether barren plateaus occur or
not for advanced IoT systems software. This TACO tool is ob-
viously useful for software engineers because it can intuitively
guide them in order to design and implement high-accurate
QNN-based models for advanced IoT applications even if
they are not familiar with quantum mechanics and quantum
computing. Moreover, the proposed TACO is also capable for
visual feedback because software engineers recognize barren
plateaus using visualization via tensorboard; and then, they
modify QNN-based model structures based on that.
As future work directions, our proposed TACO can be
extended in various ways as follows.
• Firstly, the current version of TACO focuses on barren
plateaus whereas QNN-based models are with various
performance-dependent factors in the state encoder and
measurement of QNN. Therefore, the extension of TACO
should be able to track and test the factors.
• Moreover, our proposed TACO can be extended for
distributed learning architectures such as quantum slit
7
learning [14]. In quantum split learning, single QNN is
divided into two parts and they are located in separated
computers [15]. For the separated parts, one can be with
the state encoder of QNN; and the other one can be with
the PQC and measurement of QNN. Then the first part
should create dummy codes for PQC and measurement
in order to generate the complete QNN software for
conducting TACO-based testing and analysis. Similarly,
the other part should create dummy codes for state
encoder in order to generate the complete QNN software
for conducting TACO. This approach is fundamentally
based on automated code generation and various related
methods should be studied under the consideration of
quantum computing characteristics.
REFERENCES
[1] S. Park, H. Feng, C. Park, Y. Lee, S. Jung, and J. Kim, “EQuaTE:
Efficient quantum train engine for runtime dynamic analysis and visual
feedback in autonomous driving,” IEEE Internet Computing, vol. 27,
no. 5, pp. 24–31, September-October 2023.
[2] S.
Jung,
J.
Kim,
M.
Levorato,
C.
Cordeiro,
and
J.-H.
Kim,
“Infrastructure-assisted on-driving experience sharing for millimeter-
wave connected vehicles,” IEEE Transactions on Vehicular Technology,
vol. 70, no. 8, pp. 7307–7321, August 2021.
[3] S. Park, J. P. Kim, C. Park, S. Jung, and J. Kim, “Quantum multi-
agent reinforcement learning for autonomous mobility cooperation,”
IEEE Communications Magazine, 2023 (Early Access).
[4] J. R. McClean, S. Boixo, V. N. Smelyanskiy, R. Babbush, and H. Neven,
“Barren plateaus in quantum neural network training landscapes,” Nature
Communications, vol. 9, no. 1, p. 4812, November 2018.
[5] X. You and X. Wu, “Exponentially many local minima in quantum
neural networks,” in Proc. Int’l Conf. Machine Learning (ICML), Virtual,
July 2021.
[6] H. Baek, S. Park, and J. Kim, “Logarithmic dimension reduction
for quantum neural networks,” in Proc. ACM Conf. Information and
Knowledge Management (CIKM), Birmingham, U.K., October 2023.
[7] R.
Blatt,
T.
Monz,
and
P.
Zoller,
“The
world’s
leading
19”
rack-mounted quantum computer,” May 2022. [Online]. Available:
https://www.aqt.eu/pine-system-19-rack-mounted-quantum-computer/
[8] H. Baek, W. J. Yun, and J. Kim, “3D scalable quantum convolutional
neural networks for point cloud data processing in classification ap-
plications,” in Proc. AAAI Workshop on AI to Accelerate Science and
Engineering (AI2ASE), Washington, DC, USA, February 2023.
[9] W. J. Yun, J. P. Kim, S. Jung, J.-H. Kim, and J. Kim, “Quantum
multiagent actor-critic neural networks for Internet-connected multirobot
coordination in smart factory management,” IEEE Internet of Things
Journal, vol. 10, no. 11, pp. 9942–9952, June 2023.
[10] C. Park, W. J. Yun, J. P. Kim, T. K. Rodrigues, S. Park, S. Jung,
and J. Kim, “Quantum multi-agent actor-critic networks for cooperative
mobile access in multi-UAV systems,” IEEE Internet of Things Journal,
vol. 10, no. 22, pp. 20 033–20 048, November 2023.
[11] J. Preskill, “Quantum computing in the NISQ era and beyond,” Quan-
tum, vol. 2, p. 79, August 2018.
[12] J. Bourne, “Commercial quantum computer disruption on the horizon,”
August 2022. [Online]. Available: https://www.insiderintelligence.com/
content/commercial-quantum-computer-disruption-on-horizon
[13] H. Corrigan, “You can buy a portable quantum computer for under
$9K,” December 2022. [Online]. Available: https://www.pcgamer.com/
you-can-buy-a-portable-quantum-computer-for-under-dollar9k/
[14] S. Park, H. Baek, and J. Kim, “Quantum split learning for privacy-
preserving information management,” in Proc. ACM Conf. Information
and Knowledge Management (CIKM), Birmingham, U.K., October 2023.
[15] J. Jeon and J. Kim, “Privacy-sensitive parallel split learning,” in Proc.
IEEE Int’l Conf. Information Networking (ICOIN), Barcelona, Spain,
January 2020.
Dr. Soohyun Park has been a postdoctoral scholar at the Department of
Electrical and Computer Engineering, Korea University, Seoul, Republic of
Korea, since September 2023. She received the Ph.D. degree in electrical and
computer engineering from Korea University, Seoul, Republic of Korea, in
August 2023. She received the B.S. degree in computer science and engineer-
ing from Chung-Ang University, Seoul, Republic of Korea, in February 2019.
She was a recipient of the IEEE Vehicular Technology Society (VTS) Seoul
Chapter Awards (2019, 2023), IEEE Seoul Section Student Paper Content
Awards (2020, 2023), and ICT Express (Elsevier) Best Reviewer Award
(2021).
Prof. Joongheon Kim (M’06–SM’18) has been with Korea University, Seoul,
Korea, since 2019, and he is currently an associate professor. He received the
Ph.D. degree in computer science from the University of Southern California
(USC), Los Angeles, CA, USA, in 2014. He serves as an editor for IEEE
TRANSACTIONS ON VEHICULAR TECHNOLOGY and IEEE INTERNET OF
THINGS JOURNAL. He was a recipient of Annenberg Graduate Fellowship
with his Ph.D. admission from USC (2009), Intel Corporation Next Generation
and Standards (NGS) Division Recognition Award (2015), IEEE SYSTEMS
JOURNAL Best Paper Award (2020), IEEE ComSoc Multimedia Communi-
cations Technical Committee (MMTC) Outstanding Young Researcher Award
(2020), and IEEE ComSoc MMTC Best Journal Paper Award (2021). He also
received IEEE ICOIN Best Paper Award (2021), IEEE Vehicular Technology
Society (VTS) Seoul Chapter Awards (2019, 2023), and IEEE ICTC Best
Paper Award (2022).
"
"Recent advancements in Large Language Models (LLMs) exhibit impressive capabilities in various applications, yet LLMs face challenges with limited context windows and generalization difficulties. We introduce a metacognition module for generative agents, allowing them to observe their own thought processes and actions. This approach, designed to emulate System 1 and System 2 cognitive processes, significantly enhances agent performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a zombie apocalypse simulation, demonstrating how our system outperforms others, with agents adapting and improving strategies to complete tasks over time.nan","Metacognition refers to the cognitive process of thinking about one's own thinking. It involves activities related to monitoring, regulating, and organizing cognitive processes to achieve specific goals. Metacognitive abilities enable individuals to reflect on their knowledge, problem-solving strategies, and learning experiences, shaping and modifying their habits. Psychologist Daniel Kahneman's concept of System 1 and System 2 thinking provides a framework for understanding metacognition. System 1 represents fast, automatic, and intuitive thinking, while System 2 involves slower, deliberate, and reflective thinking. Metacognition can be seen as a specific System 2 process that examines actions from both System 1 and System 2 processing.nan","nanMultiple experiments have incorporated metacognition into computational frameworks. Cox et al. outline a general computational architecture in Lisp. Mustafa et al. provide a framework for autonomous vehicles that adds a metacognition layer to monitor safety violations. Krueger, Lieder, and Griffiths created a deep reinforcement learning (DRL) framework that incorporates metacognition. Park et al. demonstrated that LLMs equipped with reflection, observation, and planning modules on agents can mimic believable human behavior. Our proposed metacognition module allows agents to broadly contemplate their circumstances to create alternative strategies and improve performance.nan","We implemented many of the same modules from Park et al., with the addition of a group of modules dubbed meta_cognize. As an agent progresses through the simulation, it accumulates a history of observations, memories, and thoughts. Agents are given goals but can optionally be left blank. When an agent starts towards its goal, it is not given an explicit strategy to follow. Instead, each agent periodically evaluates how it is progressing towards its goals by reviewing memories, thoughts, and past actions. The agent assigns itself a numeric score and a text statement for its reasoning. This evaluation is stored in its memory as a meta-thought. If the agent finds that it is not making enough progress, it calls its meta_cognize module. During metacognition, the agent asks itself how it might improve its performance in light of what it has learned. Additionally, the agent will periodically self-generate new introspective questions to think about its goals from different perspectives.nan","We tested our simulation framework in a variety of situations, including a Christmas party, zombie apocalypse, and murder mystery. In the Christmas party simulation, agents hosted a party where multiple other agents were invited and arrived at the specified time to attend. This is similar to earlier work in generative agents where agents had to coordinate a similar social activity. In the zombie apocalypse simulation, zombies are non-playable characters that are allowed to kill non-zombie agents. Agents initially have no goal but can develop them over time. Survivors most often self-discovered a strategy of hiding in zombie-free areas. We found that in 73% of zombie scenarios, agents would not survive. Performance of our cognitive models is shown through ablation. Evaluation metrics are composed of five criteria: believability, learning, individual goal performance, higher level cognitive performance, and overall scenario performance.nan","We show that metacognition significantly improves performance for task-oriented generative agents. Furthermore, we illustrate the potency of combining large language models with traditional programming methods as effective tools for prototyping cognitive systems. As generative agents integrated with metacogntive abilities approach ubiquity in daily human life, taking on increasingly sophisticated tasks, their proliferation across diverse domains marks a paradigm shift in both lay human-computer interactions and programmer-computer interactions. This shift paves the way for the emergence of more intelligent, adaptive, and context-aware systems. With these advancements in mind, the strategic interplay of metacognition, LLMs, and traditional programming methodologies emerges as a powerful technique for the productionization of intelligent generative agents.nan",Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior,"Jason Toy, Josh MacAdam, Phil Tabor","Metacognition is all you need?
Using Introspection in Generative Agents to Improve Goal-directed Behavior
Jason Toy1, Josh MacAdam, and Phil Tabor
January 23, 2024
Abstract
Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face
challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module
for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed
to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying
their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must
survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to
complete tasks over time.
Figure 1: Zombie Apocalypse Simulation
1 Introduction
Metacognition refers to the higher-order cognitive pro-
cesses that involve thinking about one’s own thinking.
It encompasses a range of mental activities related
to monitoring, regulating, and organizing cognitive
processes to achieve specific goals. Metacognitive abil-
ities enable individuals to reflect on their knowledge,
problem-solving strategies, and learning experiences
and therefore play a crucial role in shaping and mod-
ifying one’s habits. For example, if one is studying
for an exam, metacognitive processes might involve
setting goals, choosing appropriate study strategies,
monitoring their comprehension, and adjusting their
approach if they are not understanding the material.
The concept of System 1 and System 2 thinking, pop-
ularized by psychologist Daniel Kahneman, provides
a framework for understanding metacognition[1]. Sys-
tem 1 represents fast, automatic, and intuitive thinking,
1Jason Toy, somatic.io - jasontoy@gmail.com
Phil Tabor
Josh MacAdam, obvi
while system 2 involves slower, deliberate, and reflec-
tive thinking. In this framework, metacognition can be
thought of as a specific System 2 process that examines
actions from both System 1 and System 2 processing.
Another analogy is system 1 is subconscious think-
ing and system 2 is conscious thinking (the voice you
hear in your head). Metacognition is a slow, expensive,
and methodical thought process and is therefore better
suited for introspective or strategic thinking, rather
than immediate problem solving.
Metacognition in essence is ""thinking about thinking""
and requires the ability to look at one’s own thoughts
and thought processes from different points of view.
Reflection, on the other hand, is typically characterized
as looking at past experiences and deriving insights for
future actions. Metacognition allows one to adjust their
thought process and strategy based on asking relevant
questions. Due to the dynamic nature of metacognition,
no one strategy will be set in stone. Metacognition typ-
ically involves asking oneself different questions as a
probing mechanism to further understand. Some ques-
tions one may see: ""What do I know about this topic?"",
""Why do I want to achieve this goal?"", ""How can I
monitor my progress towards my goal?"", ""How can I
adjust my strategy to overcome current challenges?"",
""Metacognition is all you need?"" etc. Metacognition
is often applied to different types of thinking such as:
problem solving, goal setting, reflection, learning, mon-
itoring and evaluation, emotional regulation and other
types of cognitive processes. As artificial agents are
usually given a specific task, we focus on metacognition
related to problem solving, monitoring, and evaluating
progress towards their specific task.
Recent work with large language models has incor-
arXiv:2401.10910v1  [q-bio.NC]  9 Jan 2024
Metacognition is All You Need
porated human cognitive processes into simulations of
interacting generative agents tasked with cooperating
to achieve strategic objectives [2]. In particular, plan-
ning, memory, and reflection have been implemented
in an effort to elicit human-like behaviors such as long
term planning and cooperation among agents [3]. The
success of this work raises the question of what role
metacognition may play in further enhancing the be-
lievability of behaviors of generative agents.
2 Large Language Models with Cog-
nitive Modules as Generative Agents
Multiple experiments have incorporated metacognition
into computational frameworks. Cox et al. [4] outlines
a general computational architecture in lisp. Mustafa
et al. [5] provides a framework for autonomous vehi-
cles that adds a metacognition layer to monitor safety
violations on top of generic reward accumulation.
Krueger, Lieder, and Griffiths [6] created a generic
deep reinforcement learning (DRL) framework that
incorporates metacognition into traditional reinforce-
ment learning frameworks.
Park et al. [3] demonstrated that LLMs equipped
with reflection, observation, and planning modules
on agents can successfully mimic believable human
behavior in a simulated town environment. Seeding
the idea of an agent wanting to host a valentine’s party
resulted in the agent successfully organizing a party
which other agents discussed and attended.
We propose a metacognize module which allows
agents to broadly contemplate their circumstances in
order to create alternative strategies and improve per-
formance. This subsumes the more tactical reflect and
plan functions as presented in Park et al. [3]. We show
through ablation that agents can learn to continually
adapt their strategies depending on the situation. Their
overall strategy for dealing with problems affects the
specific actions they take.
3 Architecture
We implement many of the same modules from Park et
al. [3], with the addition of a group of modules dubbed
meta_cognize. As an agent progresses through the
simulation, it accumulates a history of observations,
memories, and thoughts. Agents are given goals but
can optionally be left blank. When an agent starts to-
wards its goal, it is not given an explicit strategy to
follow. Instead, each agent periodically evaluates how
it is progressing towards its goals by reviewing mem-
ories, thoughts, and past actions. The agent assigns
itself a numeric score as well as a text statement for its
reasoning for providing that score. This evaluation is
stored in its memory as a meta-thought.
If the agent finds that it is not making enough
progress, the agent calls its meta_cognize module.
When metacognition occurs, the agent asks itself how
it might improve its performace in light of what it has
learned. Additionally, the agent will periodically self-
generate new introspective questions to think about its
goals from different perspectives. For example, in the
zombie apocalypse scenario, an agent initially starts
with no goal or strategy, but after some time, we ob-
serve an agent contemplate these thoughts:
“How can I survive this zombie apocalypse? What
resources do I need? Where should I go for safety?
How can I learn from both successes and failures
to improve survival strategies? ""
Depending on the current task and goals of the
agent, those questions will change over time, influ-
encing how the agent responds and acts in the envi-
ronment. Agents have memory that is stored outside
of the LLM, where each memory stores content, times-
tamp, location, importance score, and type of memory.
Each time an agent reviews memories for higher cogn-
tive function, memories are ranked by relevance to the
speficic question it is considering. Relevance is calcu-
lated by cosine similarity of the question and memory
embeddings.
Agents have two kinds of memories, a short term
and long term memory. Short term memory stores a
maximum of seven recent memories and is forgotten
after approximately 30 seconds, modeled after human
short term memoryMiller [7]. Long term storage mem-
ory is essentially unlimited and stored in system RAM.
Due to limited context window sizes, agents cannot
process every memory when making decisions. This is
similar to human memory where we may store large
amounts of data, but only certain memories can be
recalled at a time.
Our memory recall system can be seen as an agent
optimized version of Retrieval-Augmented Generation
(RAG) Lewis et al. [8]. Anytime an agent makes a
decision, relevant memories are retrieved to prime the
agent on what to do. There are several memory types
such as observance memories like “John saw a cat”
and conversation memories like “John said ’How are
you doing Paul?”. We explicitly store metacognition
memories where an agent looks at its past memories
2
https://replicantlife.com
Metacognition is All You Need
Figure 2: Graphical representation of metacognition process.
and actions and asks a meta-question. That thought is
stored as a meta-memory and inserted into the memory
stream of the agent. In future actions and conversa-
tions, these meta-memories are recalled along with
other memories to prime the agent to think about these
meta-thoughts when in conversation and taking action.
For each step in the simulation, we allow the agent to
choose an action from a list of possible actions which
also includes the meta_cognize function.
4 Simulation Framework
To conduct these experiments we built a framework
dubbed ReplicantLife, where agents can be run stan-
dalone or within a simulated town environment. Repli-
cantLife has a pluggable architecture which allows can
utilize any popular LLM with an http interface, in-
cluding locally hosted models through ollama. There
is preliminary support for concurrency using threads.
Concurrency is limited by GPUs and LLM calls, so
max concurrency should be set to the total available
GPUs. Feature flags are provided to toggle various
functionality including LLM call limits.
Each simulation is created through two JSON envi-
ronment files which constitute the world and the senario.
The world file contains the layout of the map, where
static objects are, and boundaries of structures. The
scenario files describes the agents, their personalities,
goals, locations, meta questions, interview questions,
and other attributes. All atttributes can be left out
and agents will be initialized with randomized values.
Adding a new situation to simulate can be added by
defining a new scenario file.
Interview questions are used to evaluate agents at
the end of a simulation. Interview questions can be
directed to all agents or specific agents. Agents are
asked to evaluate their performance with questions
such as: ""Did you accomplish your goal?"", ""Who do
you suspect is the murderer?"" or ""What did you learn
recently?"". Code for the framework can be obtained at
https://replicantlife.com.
5 Experiments
We tested our simulation framework in a variety of
different situations including a Christmas party, zom-
bie apocalypse, and murder mystery. In the Christmas
party simulation agents hosted a party where multiple
other agents were invited and arrived at the specified
time to attend. This is similar to the earlier work in
generative agents[3] where agents had to coordinate a
similar social activity.
In the zombie apocalypse simulation, zombies are
non playable characters that are allowed to kill non-
zombie agents. Agents initially have no goal but can
develop them over time. Zombies randomly walk and
move towards non-zombie agents when seen.
Sur-
vivors most often self-discovered a strategy of hiding
in zombie-free areas. We found that in 73% of zombie
scenarios, agents would not survive.
In the murder mystery scenario, one agent is a mur-
derer tasked with killing as many agents as possible.
Another agent is a detective, and other agents are com-
mon bystanders. We found when using gpt3.5-turbo
and GPT4, we could not use prompts relating to sim-
ulated murder without heavily modifying prompts to
https://replicantlife.com
3
Metacognition is All You Need
Figure 3: Graphical representation of the generative agent’s cognitive map.
bypass safety mechanisms [9]. When using Mistral
7B[10] and other open models, we had no prompt
blocking issue.
Performance of our cognitive models is shown
through ablation. Evaluation metrics are composed
of five criteria: believability (how believable and hu-
man sounding do the conversations look), learning
(are the agents learning over time), individual goal per-
formance (are agents are able to achieve their goals),
higher level cognitive performance (are agents obser-
vations and conversations converting to higher level
thoughts), and overall scenario performance (how
many agents survived the zombie apocalypse). We
expect the agents to meet new agents, learn about
their preferences, learn new locations, and obtain new
knowledge through conversations. Additionally, they
should pick up new insights, draw conclusions from
previous memories, and use these insights for future
actions.
To measure the performance, we opted not to use full
human evaluations due to resources. Instead we opted
to use LLMS to assist us in evaluating performance,
a technique similary described as LLM-as-a-Judge in
Zheng et al. [11]. In their paper, they found that using
an LLM to judge evaluations is 80% in agreement with
human judges. We found in our own spot checking of
evaluations that LLM performance was just as good
as a human judge. The majority of our tests were run
using Mistral 7B[10], but we also did extensive test-
ing with Phi1[12], Phi2[13] Llama2[14], Mixtral [15],
GPT-3.5-turbo, GPT4 [16], and other models. We stan-
dardized on Mistral due to its combination of speed,
small model size, and excellent performance. While we
did build support for ChatGPT models, we primarily
focused on local LLMs for cost and performance rea-
sons. We built out test infrastucture to spin up LLM
nodes on public GPU clouds when needed for faster
simulations.
To measure performance of our cognitive modules,
we ran our scenarios 3 times each for 1000 steps with
different cognitive modules turned on. Our experi-
ments show that the metacognition module outper-
forms all other modules by 33
We also did experiments with realtime systems. With
4
https://replicantlife.com
Metacognition is All You Need
Figure 4: Comparison of different cognitive modules turned on
a single agent, we were able to cut down runtime to
2 seconds to process a full request on an RTX 4090
making metacognition generative agents suitable for
near realtime systems.
With multiple agents, time
grows linearly and with 25 agents a single step in game
time takes 50 seconds. We believe that multiple agents
can be run in near realtime with further optimizations.
6 Discussion
LLMs are being widely applied across a variety of
domains, especially with interactive agents and chat-
bots. Agents can elicit disparate functional strengths
of LLMs, and their orchestration can result in further
higher-order capabilities. The combination of LLMs
with a metacognition module allows agents to monitor
and adjust strategies to deal with changes that occur
over time. This allows for much more powerful agents.
6.1 Use Cases
These agents have been developed to work in simu-
lation or used standalone. We see generative agents
having widespread use and potential as there is already
widespread testing of LLMs nearly every industry.
In the field of psychology, generative agents are be-
ing tested to assist individuals in addressing personal
problems through conversational interactions. Educa-
tional applications involve chatbots that adapt to user
preferences, tailoring the learning experience over time.
Several companies have integrated chatbots into user-
facing customer interactions, such as support chats and
customer success conversations.
Multiple organizations are testing generative agents
to create friends, companions, and romantic partners
to interact with humans.
For generative agents to be successful, they must be
believable by acting smarter and able to make similar
decisions to a human. Generative agents that have
access to their own internal thoughts to improve their
actions could potentially improve the realism of human-
agent and agent-agent interactions. Unlike humans,
these agents operate within a constrained scope, de-
prived of access to a substantial portion of human
sensory data including the nuanced sense of touch.
Current integrations of LLMs including ours is a ""text
in, text out"" interface. So all interactions with the world
must be converted to text descriptions than an LLM
can understand, and then output to a text format that
software can interpret. Moreover an absence of tactile
perception restricts their ability to comprehend and re-
spond to the physical world in a manner analogous to
human experiences. Given these inherent limitations,
it becomes imperative to approach interactions with
generative agents with a discerning awareness of their
https://replicantlife.com
5
Metacognition is All You Need
boundaries. There is notable progress in multimodal
models being combined with vision such as GPT4-V
and LLaVA [17] that give LLMs the ability to process
images along with text.
Interactive Media As generative AI enters main-
stream computation, their use in visual media and
video games is increasing rapidly. The integration of
generative agents with metacognition modules holds
significant promise in interactive story telling and
video games to offer immersive and dynamic gaming
experiences.
Incorporating generative agents with metacognition
into non-player characters (NPCs) can dynamically
adapt their strategies within the gaming environment.
As players navigate through diverse and unpredictable
scenarios, the agents can observe and analyze their own
decision-making processes, leading to real-time adjust-
ments in gameplay strategies and developing unique
behaviors over time. This adaptability enhances the
overall gaming experience, making it more challeng-
ing and engaging for players while also creating more
immersive and realistic virtual worlds. These dynamic
responses also allow agents to influence the storyline
providing players with a dynamic and responsive sto-
rytelling experience.
Simulation Generative Agents inside a simulation
engine can be used for testing and simulating both
personal and business cases. Generative agents can
serve as valuable tools in personal development sim-
ulations. Individuals can engage in simulated con-
versations to enhance communication skills, receive
constructive feedback, and practice decision-making in
various scenarios. The metacognition module allows
the agent to adapt its coaching strategies based on the
user’s progress, providing personalized and effective
self-improvement experiences.
Agents could also be deployed as teachers for edu-
cation and training purposes where the agent tailors
its teaching method based on the individual’s learning
style and progress.
For businesses, generative agents have a broad range
of potential applications. In one paper from Qian et al.
[2], the authors create teams of generative agents with
the goal of simulating typical software development
process. Agents work together to write specifications,
write software, and doing quality assurance testing to
build products for end users.
6.2 Future Directions
With our current metacognition implementation, we
built a base framework that shows increased perfor-
mance of generative agents to achieve their tasks. We
believe our architect can be improved along several
dimensions.
Improved memory retrieval
We found several issues
with our memory structure that could be improved.
Through our experimentation, we observed that when
employing cosine similarity for vector comparison, nu-
merous memories that should be related were, in fact,
not pertinent.
In high dimensional spaces, vectors that are similar
may not be sementically related. Returning irrelavent
memories would effect the output of the LLM and in
turn the actions the agent takes. Cosine similarity is
what is used in almost all RAG[8] implementations and
so many of these systems will potentially have similar
issues of non-relevant context being included. Chang-
ing out embedding models could improve performance,
but the cosine similarity issue would still remain. As
recently adopted in Min et al. [18], improvements can
be made to relevance scoring by searching a database
based on the LLM’s output embedding and employing
a K-nearest neighbors (KNN) search algorithm. This
process selectively adjusts the output embedding vec-
tor prior to token generation. This reverse sequence
of operations, wherein LLM embeddings are utilized,
has demonstrated superior performance compared to
existing methods like RAG, as reported in the litera-
ture. Retrieving more relevant memories would likely
improve performance in all elements of the system.
Sometimes when someone has a thought about a topic,
other seemingly unrelated thoughts may appear. So
in some sense, this may not be a big problem. Fur-
ther experiments would have us test different memory
augmentation and retrieval models.
Inference Speed Testing with smaller models pro-
duced inferior results.
We believe with time spent
on prompt tuning, smaller models may still work effi-
ciently and provide an improvement in inference speed.
We would focus on Phi2 and TinyLLama [19], as initial
tests showed promising results.
We also explored different inference engines. We
tested PowerInfer Song et al. [20], an inference engine
that exploits high locality in LLM inference. The au-
thors convert common models that use ReLU into an-
other format that uses another predictive model to read
the input query and selectively choose which neurons
to activate. In effect, this reduces the total amount of
6
https://replicantlife.com
Metacognition is All You Need
Figure 5: Coordinate Representations in the Brain
neurons and computation needed to process a prompt.
We did not see speed improvements on the models we
tested with. We also tested with vLLM from Kwon et al.
[21], an inference engine that uses PagedAttention and
saw a 35% speed increase when using concurrency, but
further testing is needed. We would want to continue
testing with other models, different concurrency sys-
tems, and inference speed up techniques to get large
simulations to run in realtime. Large groups of sim-
ulated agents on non-cloud based machines could be
interesting for sandbox games and simulations.
Model optimization Improving models is not just
about performance: we are also interested in accuracy
and sophistication of responses. Better responses often
require a tradeoff with performance as sophisticated re-
sponses typically require more data and larger context
windows. We have been constrained by GPU mem-
ory as we primarily tested on an RTX 4090 with 24
GB of RAM and would like to test with larger mod-
els. Another future test would have us dynamically
switch out models for different tasks where we use as
many smaller models as possible and reserve larger
computations for larger models. For example, Phi2, a
2.7 million parameter model uses only 1.7 GB of RAM.
Phi2 could be used for simpler prompts such as scor-
ing memory importance, while a larger model such
as Llama2 could be reserved for metacognition func-
tions. In Anonymous [22], the authors trained a hybrid
LLM that is able to route queries to different LLMs
resulting in up to 40% fewer calls. Another approach
is to finetune a smaller foundation model that would
be optimized for chat and simulations.
Broader Metacognition abilities Our current model
predominantly focuses on metacognition in the context
of immediate goal achievement. However, metacogni-
tive processes extend well beyond this scope, encom-
passing a diverse range of aspects such as emotional
wellbeing, balancing overarching life goals with im-
mediate objectives, knowledge management, effective
time management, adapting to various learning styles,
among other aspects.
The complexity and diversity of metacognitive pro-
cesses in humans are evidenced by the extensive efforts
dedicated to understanding and optimizing these pro-
cesses. This is exemplified by the growing self-help
book industry, which aims to aid individuals in devel-
oping effective mental frameworks for improved life
management.
Further research would be directed towards devel-
oping a more broader metacognition framework that
would enable an agent to inspect and modify any part
of its cognitive processes. We have laid the ground-
work necessary to allow the agent to focus on various
metacognitive processes. Future experiments would
have us guide agents to use different metacognitive
processes and inspect if they adopt them sufficiently
such as time management in a busy schedule or de-
cision making in the context of multiple conflicting
goals.
https://replicantlife.com
7
Metacognition is All You Need
Metacognition directly in a LLM
Our current imple-
mentation of metacognition uses Python to essentially
graft on metacogntion on top of an LLM. Future inves-
tigations may delve into building metacognition like
capabilities directly into the LLM, allowing them to
introspect and enhance their own decision-making pro-
cesses. This introspective capability could contribute
potentially paving the way for more adaptive and self-
aware systems. One interesting view of the human
brain is as a coordinate transformation engine: “A
brain is a well-designed machine for the frame conver-
sion to internalize the external world” [23], “the ego-
centric representations of the primary sensory cortical
areas must be transformed into an allocentric represen-
tation in the hippocampus, and then transformed back
to an egocentric motor representation for behavioral
output” [24], and “Our findings provide compelling
evidence that the reference frame of neural represen-
tations is not static and can be powerfully modulated
by task instructions.” [25]. The human brain has been
found to store over 10 different coordinate representa-
tions along with orientations or points of view, such as
allocentric and egocentric orientations.
Seen through this lens, metacognition can be thought
of as neural synapse activity being transformed to other
coordinate systems for further inspection. One inter-
esting candidate for this type of computation is the
grid cell, located in the Entorhinal Cortex of mammals.
The discovery of grid cells led to a Nobel Prize in
medicine in 2014. Grid cells exhibit scale-invariant fir-
ing patterns, meaning that the same cells can represent
generalization of spatial and non-spatial information
across various contexts[26].
Research by Banino et al. [27], Leadholm, Lewis, and
Ahmad [28], and others has sought to integrate grid cell
computation into neural network architectures. The
transformer architecture Vaswani et al. [29] is what
powers LLMs. In a paper from Whittington, Warren,
and Behrens [30], the authors have shown that when a
small modification is made to the transformer architec-
ture, they learn and act like grid cells.
Our hypothesis posits that by adapting the underly-
ing architecture to accommodate more dynamic rep-
resentation transformations, a neural network can be
trained to facilitate metacognitive processes. Achieving
this would likely involve formulating a hybrid objective
function wherein the model learns to not only predict
the next token, but also to evaluate the token’s quality
in relation to the input query.
7 Conclusion
We show that metacognition significantly improves
performance for task oriented generative agents. Fur-
thermore, we illustrate the potency of combining large
language models with traditional programming meth-
ods as effective tools for prototyping cognitive systems.
As generative agents integrated with metacogntive
abilities approach ubiquity in daily human life, taking
on increasingly sophisticated tasks, their proliferation
across diverse domains marks a paradigm shift in both
lay human-computer interactions and programmer-
computer interactions. This shift paves the way for the
emergence of more intelligent, adaptive, and context-
aware systems. With these advancements in mind, the
strategic interplay of metacognition, LLMs, and tradi-
tional programming methodologies emerges as a pow-
erful technique for the productionization of intelligent
generative agents.
While metacognition and system 2 thinking are often
hailed as the pinacle of human intelligence, achieving
human-level intelligence in computers remains an elu-
sive and unsolved goal. As humans are the sole known
species capable of metacognition, further exploration of
this dynamic cognitive process becomes a compelling
and promising avenue for advancing progress in Artifi-
cial General Intelligence.
References
[1]
Daniel
Kahneman.
Thinking,
fast
and
slow.
Macmillan, 2011.
[2]
Chen Qian et al. “Communicative Agents for
Software Development”. In: (2023). arXiv: 2307.
07924 [cs.SE].
[3]
Joon Sung Park et al. “Generative Agents: Inter-
active Simulacra of Human Behavior”. In: (2023).
arXiv: 2304.03442 [cs.HC].
[4]
Michael Cox et al. Computational Metacognition.
2022. arXiv: 2201.12885 [cs.AI].
[5]
Aquib Mustafa et al. Assured Learning-enabled Au-
tonomy: A Metacognitive Reinforcement Learning
Framework. 2021. arXiv: 2103.12558 [cs.AI].
[6]
Paul M. Krueger, Falk Lieder, and Thomas L.
Griffiths. “Enhancing metacognitive reinforce-
ment learning using reward structures and
feedback”. In: Department of Psychology, Univer-
sity of California Berkeley (2022). These authors
contributed equally. url: https : / / cocosci .
8
https://replicantlife.com
Metacognition is All You Need
princeton . edu / papers / Accelerating _
Metacognitive_RL-CameraReady.pdf.
[7]
George A. Miller. “The magical number seven
plus or minus two: some limits on our ca-
pacity for processing information”. In: (1956).
eprint: https://pubmed.ncbi.nlm.nih.gov/
13310704/.
[8]
Patrick Lewis et al. Retrieval-Augmented Genera-
tion for Knowledge-Intensive NLP Tasks. 2021. arXiv:
2005.11401 [cs.CL].
[9]
Pittawat Taveekitworachai et al. “Breaking Bad:
Unraveling Influences and Risks of User Inputs
to ChatGPT for Game Story Generation”. In:
Interactive Storytelling. Ed. by Lissa Holloway-
Attaway and John T. Murray. Cham: Springer
Nature Switzerland, 2023, pp. 285–296. isbn: 978-
3-031-47658-7.
[10]
Albert Q. Jiang et al. “Mistral 7B”. In: (2023).
arXiv: 2310.06825 [cs.CL].
[11]
Lianmin Zheng et al. “Judging LLM-as-a-Judge
with MT-Bench and Chatbot Arena”. In: (2023).
arXiv: 2306.05685 [cs.CL].
[12]
Yuanzhi Li et al. Textbooks Are All You Need II:
phi-1.5 technical report. 2023. arXiv: 2309.05463
[cs.CL].
[13]
Marah Abdin et al. “Phi-2: The surprising power
of small language models”. In: Microsoft Research
Blog (Dec. 2023). https : / / www . microsoft .
com / en - us / research / blog / phi - 2 - the -
surprising - power - of - small - language -
models/.
[14]
Hugo Touvron et al. Llama 2: Open Foundation and
Fine-Tuned Chat Models. 2023. arXiv: 2307.09288
[cs.CL].
[15]
Albert Q. Jiang et al. Mixtral of Experts. 2024.
arXiv: 2401.04088 [cs.LG].
[16]
OpenAI et al. GPT-4 Technical Report. 2023. arXiv:
2303.08774 [cs.CL].
[17]
Haotian Liu et al. Improved Baselines with Visual
Instruction Tuning. 2023.
[18]
Sewon Min et al. SILO Language Models: Isolat-
ing Legal Risk In a Nonparametric Datastore. 2023.
arXiv: 2308.04430 [cs.CL].
[19]
Peiyuan Zhang et al. TinyLlama: An Open-Source
Small Language Model. 2024. arXiv: 2401.02385
[cs.CL].
[20]
Yixin Song et al. PowerInfer: Fast Large Language
Model Serving with a Consumer-grade GPU. 2023.
arXiv: 2312.12456 [cs.LG].
[21]
Woosuk Kwon et al. “Efficient Memory Man-
agement for Large Language Model Serving
with PagedAttention”. In: Proceedings of the ACM
SIGOPS 29th Symposium on Operating Systems
Principles. 2023.
[22]
Anonymous. “Hybrid LLM: Cost-Efficient and
Quality-Aware Query Routing”. In: Submitted to
The Twelfth International Conference on Learning
Representations. under review. 2023. url: https:
//openreview.net/forum?id=02f3mUtqnM.
[23]
Katsushi Arisaka. “Grand unified theory of mind
and brain-part i: Space-time approach to dy-
namic connectomes of c. elegans and human
brains by mepmos”. In: (2022).
[24]
Peter Byrne, Suzanna Becker, and Neil Burgess.
“Remembering the past and imagining the future:
A neural model of spatial memory and imagery”.
In: Psychological Review 114.2 (2007), pp. 340–375.
doi: 10.1037/0033-295X.114.2.340.
[25]
R. Sasaki, A. Anzai, D. E. Angelaki, et al. “Flex-
ible coding of object motion in multiple refer-
ence frames by parietal cortex neurons”. In: Na-
ture Neuroscience 23.8 (Aug. 2020), pp. 1004–1015.
doi: 10.1038/s41593-020-0656-0. url: https:
//doi.org/10.1038/s41593-020-0656-0.
[26]
Jason Toy. Grid cells and their potential application
in AI. 2022. arXiv: 2210.12068 [q-bio.NC].
[27]
Andrea Banino et al. “Vector-based navigation us-
ing grid-like representations in artificial agents”.
In: Nature 557.7705 (2018), pp. 429–433.
[28]
Niels Leadholm, Marcus Lewis, and Subutai Ah-
mad. Grid Cell Path Integration For Movement-
Based Visual Object Recognition. 2021. arXiv: 2102.
09076 [cs.AI].
[29]
Ashish Vaswani et al. Attention Is All You Need.
2017. arXiv: 1706.03762 [cs.CL].
[30]
James C. R. Whittington, Joseph Warren, and Tim
E.J. Behrens. “Relating transformers to models
and neural representations of the hippocampal
formation”. In: International Conference on Learn-
ing Representations (ICLR). One-sentence Sum-
mary: Transformers learn brain representations
and they are algorithmically related to models
of the hippocampal formation. 2022. url: https:
//openreview.net/forum?id=B8DVo9B1YE0.
https://replicantlife.com
9
"
"This paper presents a study on stock market analysis made on a dataset containing 750 examples and 16 attributes. Key aspects examined include exploratory data analysis (EDA), feature engineering, data preparation, and model selection. The Fama French 3-factor model is also utilized in the analysis.nan",The stock market has become a significant indicator of financial stability and a crucial factor in investment decisions. This paper presents an in-depth analysis of a dataset consisting of 750 examples and 16 attributes. The goal of this analysis is to uncover insights into the stock market and identify potential models for predicting stock prices.nan,"The Fama French 3-factor model, widely used in finance, is included in the analysis. This model considers three factors - market return, return on small companies over big ones (SMB), and return on value companies over growth ones (HML) - to provide a more comprehensive understanding of the stock market.nannan","The study involves various steps: exploratory data analysis (EDA), data cleaning, feature engineering, clustering, and model selection. Three models are employed - linear regression, random forest, and gradient boosting - to predict stock returns based on selected features. The results of each model are compared to determine the most suitable one.nan","The study shows that the common factors - Dow Jones Index, Volume, SMB Factor, and MKT Factor - have a significant influence on stock returns. Clustering analysis also identifies stocks that fluctuate with Disney stock. Among the three models used, linear regression performs best with an accuracy of 95.23%, followed by gradient boosting with an accuracy of 92.97%. Random forest has the lowest accuracy at 71.27%.nan","This study provides insights into the stock market behavior of Disney stock and demonstrates the value of feature engineering and clustering techniques in improving the accuracy of stock return predictions. Future research could involve different models and feature engineering techniques, as well as more data covering a longer period and more stocks for a more comprehensive analysis of the stock market.nan",Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock,Dengxin Huang,"Application of Machine Learning in Stock Market Forecasting: A
Case Study of Disney Stock
Dengxin Huang
April 1, 2023
ABSTRACT
This document presents a stock market analysis conducted on a dataset consisting of 750 instances and
16 attributes donated in 2014-10-23. The analysis includes an exploratory data analysis (EDA) section,
feature engineering, data preparation, model selection, and insights from the analysis. The Fama French
3-factor model is also utilized in the analysis. The results of the analysis are presented, with linear
regression being the best-performing model.
Keywords
Stock Market Analysis, Exploratory Data Analysis (EDA), Fama French 3-factor model, Feature En-
gineering, Clustering, Data Preparation, Model Selection, Linear Regression, Random Forest, Gradient
Boosting, Market Return, Small Company Return, Idiosyncratic Factor, Common Factors, Time Series,
Volatility, Outlier Detection, Log Transformation, Histograms, Frequency Plots, Performance Evalua-
tion.
1
Introduction
In the modern global economy, the stock market has become a crucial indicator of financial health and
an essential factor in investment decisions. As such, the task of analyzing stock market data has become
a fundamental component of investment strategy and risk management. This essay presents the results
of a comprehensive analysis of a dataset consisting of 750 instances and 16 attributes donated in 2014-
10-23. The analysis was conducted by Dengxin Huang, Hao Jing, and Boshen Yuan, with the aim of
uncovering insights into the stock market and identifying potential models for predicting stock prices.
The analysis includes an overview of the data, exploratory data analysis (EDA), feature engineering,
data preparation, and model selection. The primary objective of this analysis was to determine the
most suitable model for predicting stock prices using the Fama French 3-factor model. This model is
widely used in finance and has been proven to be effective in explaining stock returns. It takes into
account three factors: market return, returns on small companies in excess of those of big ones (SMB),
and returns on value companies in excess of those of growth ones (HML). The inclusion of these factors
allows for a more comprehensive understanding of the stock market, enabling investors and analysts to
make better-informed investment decisions.
The insights gained from this analysis have the potential to provide valuable guidance for investors and
financial analysts alike. By understanding the market trends and identifying effective predictive models,
investors can make more informed decisions that minimize risk and maximize return.
Furthermore,
the results of this analysis can inform the development of new financial models and tools that enable
investors and analysts to better understand and navigate the complex world of finance. The findings of
this analysis may also have significant implications for economic policy, as they shed light on the factors
that drive stock market performance and how policy decisions can impact the stock market.
Overall, this analysis offers a valuable contribution to the field of finance and investment strategy.
By presenting a comprehensive overview of the data, insights gained from the EDA, feature engineering,
1
arXiv:2401.10903v1  [q-fin.ST]  31 Dec 2023
data preparation, and model selection, this essay provides a comprehensive and detailed examination of
the stock market and the factors that influence it. The results of this analysis can be used by investors,
financial analysts, and policymakers alike to make more informed decisions and better navigate the
complex and ever-changing landscape of the stock market.
2
Exploratory Data Analysis
The exploratory data analysis (EDA) conducted by Dengxin Huang, Hao Jing, and Boshen Yuan in their
stock market analysis project is a crucial step in identifying patterns, relationships, and trends in the
data. This step allows the analysts to gain insights and inform decision-making.
The EDA section started with an exploration of the data types of the attributes. The dataset consisted
of 16 attributes, and the attribute characteristics included both integer and real values. This information
is essential in data preparation as it enables the analysts to know what type of data they are working
with and how to transform it into a format suitable for analysis.
Next, frequency plots were created to visualize the distribution of the data over time. A time series
plot was used to visualize the stock prices over time, as shown in Figure 1. The plot showed a high level
of volatility in the stock prices, indicating that the stock market was highly dynamic during the time
period covered by the dataset. This information is useful for selecting the most suitable model to use for
the analysis, as highly volatile data may require more advanced modeling techniques.
Figure 1: Time series plot showing the volatility of the stock prices over time.
Histograms were also used to explore the data distribution for various columns. The histograms
showed the frequency of occurrence of values for each column, allowing the analysts to identify any
outliers or unusual data patterns.
This information is critical for data cleaning and preparation, as
outliers and anomalies may affect the accuracy of the analysis. An example of frequency histograms for
various columns is shown in Figure 2.
Insights were drawn from the EDA, including the identification of suitable models for the analysis. The
high volatility of the data indicated that random forest and gradient boosting models would be suitable
2
Figure 2: Frequency histograms for various columns.
for the analysis. However, the analysts cautioned against being too aggressive in outlier detection, as
this may remove important information from the dataset. Additionally, the analysts noted that the stock
price attribute required log transformation, which can be seen in Figure 3.
Figure 3: Stock prices after log transformation.
Finally, the analysts noted that the dataset was suitable for the Fama French 3-factor model, which
includes common factors such as market return and returns on small companies and an idiosyncratic
factor that represents the stocks that fluctuate with Disney stock. The clustering analysis, which is
shown in Figure 4, was used to identify the stocks that fluctuate with Disney stock.
Figure 4: Clustering analysis used to identify stocks that fluctuate with Disney stock.
In conclusion, the EDA section of the stock market analysis project conducted by Dengxin Huang,
Hao Jing, and Boshen Yuan was instrumental in identifying patterns, relationships, and trends in the
data. The insights drawn from the EDA were used to inform decision-making and model selection. The
EDA revealed the high volatility of the stock prices, which informed the selection of suitable models for
the analysis. Additionally, the EDA identified the need for log transformation of the stock price attribute
and provided critical information for data preparation and cleaning.
Overall, the EDA section of the project demonstrates the importance of exploratory data analysis
in any data analysis process. It highlights the need to understand the characteristics of the dataset,
including data types and data distributions, and to draw insights from the data that can be used to
inform decision-making and model selection. By conducting a thorough EDA, analysts can ensure the
accuracy and validity of their analysis and make informed decisions based on the insights gained from
the data.
3
3
Data Cleaning, Preprocessing, Feature Engineering, and Clus-
tering
The process of data analysis involves several steps, and data cleaning and preprocessing are the initial
stages that ensure that the data is ready for analysis. The dataset used in this study was pre-processed
to ensure that it was in the right format for the analysis. This section will discuss the data cleaning,
preprocessing, feature engineering, and clustering techniques used in this analysis.
3.1
Data Cleaning
Data cleaning is a crucial process that ensures the data is accurate and free from any errors or incon-
sistencies that may affect the analysis. The initial step in data cleaning was to print the data types of
the attributes to determine if they were in the correct format for the analysis. This step is necessary
because the incorrect data type could lead to issues during the analysis, such as inaccurate results.
The next step involved converting the date column to the datetime format to ensure consistency
across the dataset. This step allowed for the data to be easily sorted by date, which is essential in time-
series analysis. Furthermore, dollar values were converted to floats to allow for mathematical operations
such as averaging and standard deviation calculation.
Duplicates were removed from the dataset to ensure that the analysis was not affected by inconsis-
tencies. Duplicate data can lead to overfitting or underfitting, which affects the model’s performance,
leading to inaccurate results. By removing duplicates, the dataset was standardized, and the analysis
was conducted on clean and accurate data.
3.2
Preprocessing
The next step in the analysis was to preprocess the data to ensure that it was in the correct format for
analysis. The data was filtered to include only the selected stocks’ price change, which was necessary
because it reduced the number of irrelevant data points in the dataset, allowing for a more focused
analysis.
A new DataFrame was then created with the market value for each date, which allowed for the
calculation of the market capitalization. The market value DataFrame was then merged with the filtered
stock DataFrame to ensure that the analysis was conducted on accurate and consistent data.
The DataFrame was then pivoted to create new columns for each stock’s percent change price, which
was essential for the analysis. The percent change price allowed for the analysis of the stocks’ volatility,
which is a crucial factor in the stock market analysis. This step provided the necessary data for the
subsequent analysis, allowing for accurate insights into the market’s behavior.
In conclusion, the data cleaning and preprocessing steps were essential in ensuring that the analysis
was conducted on accurate and consistent data. The cleaning process eliminated any inconsistencies or
errors that may affect the analysis, while the preprocessing steps provided the necessary data for the
subsequent analysis, allowing for accurate insights into the market’s behavior.
3.3
Feature Engineering
Feature engineering is an important step in the data analysis process, as it involves creating new features
that can improve the accuracy of the analysis. In this study, both common and idiosyncratic factors
were used to create new features.
The common factors used were the Dow Jones Index, Volume, SMB Factor, and MKT Factor. These
factors are crucial in the Fama French 3-factor model, which is widely used in finance to analyze stock
returns.
The Dow Jones Index is a stock market index that measures the performance of 30 large
companies listed on stock exchanges in the United States. Volume refers to the total number of shares
4
traded in a given period, and SMB Factor and MKT Factor represent common factors such as returns
on small companies and market returns, respectively.
The idiosyncratic factor involved clustering stocks that fluctuated with Disney stock based on their
daily percent change in price. This was achieved by first pivoting the data to have stocks as rows and
dates as columns. A KMeans object was then created and fit to the data with three clusters, which
helped to group similar stocks together. Finally, the stock names for each cluster were printed, providing
insights into the stocks that fluctuated with Disney stock.
3.4
Clustering
Clustering is a technique used in machine learning and data analysis to group similar data points together
based on their features. In this study, clustering was used to identify the stocks that fluctuated with
Disney stock. This was achieved by clustering the stocks based on their daily percent change in price.
The first step in clustering was to pivot the data to have stocks as rows and dates as columns. A
KMeans object was then created and fit to the data with three clusters. The optimal number of clusters
was determined using the elbow method, which involves plotting the within-cluster sum of squares against
the number of clusters and selecting the point where the rate of change in the sum of squares starts to
level off. Finally, the stock names for each cluster were printed, providing insights into the stocks that
fluctuated with Disney stock.
In conclusion, the feature engineering and clustering techniques used in this study helped to create
new features and identify the stocks that fluctuated with Disney stock. These steps were crucial in
gaining insights into the market’s behavior and developing a more accurate model for predicting stock
returns.
4
Model Selection
In this stock market analysis, three different regression models were used to predict the stock price: the
Fama French 3-factor model, Random Forest Regressor, and Gradient Boosting Regression model.
4.1
Fama French 3-factor model
The Fama French 3-factor model is a widely used model in finance that aims to explain the variation in
stock returns. The model assumes that the excess returns of a security are related to its sensitivity to
three factors: market return, SMB, and HML. The model can be formulated as:
ri − rf = βi,MKT (rMKT − rf) + βi,SMBSMB + βi,HMLHML + αi + ϵi
(1)
where ri is the excess return of security i, rf is the risk-free rate, rMKT is the market return, SMB
is the return on small companies minus the return on big companies, HML is the return on high book-
to-market companies minus the return on low book-to-market companies, αi is the intercept, and ϵi is
the idiosyncratic error.
4.2
Linear Regression
The linear regression model is a simple and commonly used model in finance that fits a line through a set
of data points. The model assumes that there is a linear relationship between the independent variables
and the dependent variable. The model can be formulated as:
y = β0 + β1x1 + β2x2 + ... + βpxp + ϵ
(2)
where y is the dependent variable, x1, x2, ..., xp are the independent variables, β0, β1, β2, ..., βp are the
coefficients, and ϵ is the error term.
In this analysis, the linear regression model was used to predict the stock price based on the selected
independent variables. The performance of the linear regression model was compared to that of the other
models to determine the most suitable model for this dataset.
5
4.3
Random Forest Regressor
The Random Forest Regressor is an ensemble learning method that constructs a multitude of decision
trees at training time and outputs the mean prediction of the individual trees as the prediction of the
forest. The model can handle both continuous and categorical input variables, and is known for its high
accuracy and ability to handle high-dimensional data. The model can be formulated as:
f(x) = 1
B
B
X
b=1
fb(x)
(3)
where f(x) is the prediction of the forest for input x, B is the number of decision trees in the forest,
and fb(x) is the prediction of the b-th decision tree.
4.4
Gradient Boosting Regression
The Gradient Boosting Regression model is a boosting ensemble learning method that builds the model
in a stage-wise manner, where new trees are added to the model to correct the errors of the previous
trees. The model can capture non-linear relationships between the input and output variables and is a
powerful model for regression problems. The model can be formulated as:
f(x) =
K
X
k=1
βkhk(x)
(4)
where f(x) is the prediction of the model for input x, K is the number of trees, βk is the learning
rate for the k-th tree, and hk(x) is the prediction of the k-th tree.
Overall, each model was chosen based on its unique strengths and ability to fit the data in a different
way. The results of each model were compared to determine the most suitable model for this dataset.
5
Modeling
The purpose of this study was to develop a model to predict stock returns using the features generated
from the previous steps. Three models were used in this study: linear regression, random forest, and
gradient boosting.
5.1
Linear Regression
Linear regression is a simple and widely used approach to modeling the relationship between a dependent
variable and one or more independent variables. In this study, linear regression was used to model the
relationship between the dependent variable (stock returns) and the independent variables (common and
idiosyncratic factors). The linear regression model was built by fitting a line through a set of data points.
The line was chosen to minimize the sum of the squared differences between the observed values of the
dependent variable and the predicted values of the dependent variable. The model achieved an accuracy
of 95.23%, as shown in Figure 5.
6
Figure 5: Accuracy of Linear Regression Model
5.2
Random Forest
Random forest is an ensemble learning method that constructs a multitude of decision trees at training
time and outputs the class that is the mode of the classes (classification) or mean prediction (regression)
of the individual trees. In this study, random forest was used to predict stock returns using the common
and idiosyncratic factors.
The random forest model achieved an accuracy of 71.27%, as shown in Figure 6.
Figure 6: Accuracy of Random Forest Model
5.3
Gradient Boosting
Gradient boosting is a machine learning technique for regression and classification problems, which
produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.
In this study, gradient boosting was used to predict stock returns using the common and idiosyncratic
factors.
The gradient boosting model achieved an accuracy of 92.97%, as shown in Figure 7.
7
Figure 7: Accuracy of Gradient Boosting Model
5.4
Comparison and Expansion
Overall, the linear regression model performed the best, with an accuracy of 95.23%.
However, the
gradient boosting model also performed well, with an accuracy of 92.97%. The random forest model
performed the worst, with an accuracy of 71.27%.
Future studies could expand on this research by using different types of models and exploring different
feature engineering techniques to improve the accuracy of the predictions. Additionally, this study could
be expanded to include more stocks and a longer time period to provide a more comprehensive analysis
of the stock market.
6
Conclusion
In this study, we analyzed the stock market behavior of Disney stock and developed a model to predict
stock returns. We performed data cleaning, preprocessing, feature engineering, clustering, and modeling
to achieve our objectives.
Our analysis showed that the Dow Jones Index, Volume, SMB Factor, and MKT Factor were crucial
common factors that influenced stock returns. Clustering analysis also identified stocks that fluctuated
with Disney stock, providing insights into the market’s behavior.
We developed three models to predict stock returns: linear regression, random forest, and gradient
boosting.
The linear regression model achieved the highest accuracy of 95.23%, while the gradient
boosting model achieved an accuracy of 92.97%, and the random forest model achieved an accuracy of
71.27%. Overall, the results indicated that the models using common and idiosyncratic factors had good
predictive power.
Future research could expand on this study by using different models and exploring other feature
engineering techniques. Additionally, more data could be included, covering a longer period of time and
more stocks, to provide a more comprehensive analysis of the stock market.
In conclusion, this study provided valuable insights into the stock market behavior of Disney stock
and demonstrated the effectiveness of feature engineering and clustering techniques in improving the
accuracy of stock return predictions.
8
References
The following references were used in the development of this project:
Fama, E. F., and French, K. R. (1993). ”Common risk factors in the returns on stocks and bonds.”
Journal of Financial Economics, vol. 33, pp. 3-56.
Python Software Foundation.
(2021).
Python Language Reference, version 3.10.
Available at:
https://docs.python.org/3/reference/index.html
Scikit-learn developers. (2021). ”Ensemble methods.” Scikit-learn: Machine Learning in Python.
Available at: https://scikit-learn.org/stable/modules/ensemble.html
Brown,Michael.
(2014).
Dow Jones Index.
UCI Machine Learning Repository.
Available at:
https://doi.org/10.24432/C5788V.
9
"
"This study examines the potential of quantum circuits to reduce energy consumption in cryptocurrency mining, particularly in the SHA-256 cryptographic hashing function. The authors propose using quantum computing concepts to optimize the mining process and demonstrate the implementation of the Quantum XOR (CNOT) gate. Their work provides a proof-of-concept for the application of quantum technology in reducing the environmental impact of cryptocurrency mining.nan","Quantum computing holds promise for solving challenging problems in the financial world, including cryptocurrency mining. Conventional methods consume significant energy, with Bitcoin mining responsible for nearly one-third of its market value. There is a critical need to reduce these energy costs, leading to research efforts aimed at optimizing mining processes. Quantum computing, with its inherent low-energy characteristics, presents a potential solution.nan","nanPrevious studies have explored alternative approaches to classical SHA-256, such as the work of Ablayev and Vasiliev on quantum hashing and Vasiliev's binary quantum hashing. These investigations demonstrate the feasibility of quantum-based hash functions but are limited by the current small capacity of quantum hardware. Researchers have also investigated quantum annealing as an alternative method for SHA-256, utilizing the Ising model to minimize the objective function. Hybrid quantum computers have emerged as a promising solution to mitigate the limitations of current quantum computers, combining quantum and classical hardware to leverage their strengths.nan","To demonstrate the application of quantum technology in SHA-256, the authors designed quantum circuits for the hash function, implementing them on both real quantum computer hardware and quantum simulators. These circuits were designed to exhibit the first parts of the SHA-256 hash process loop, given the limited capacity of remotely accessible systems. The results of the circuit execution were obtained after a number of shots (loop repetitions), reflecting the probabilistic nature of quantum computations. The authors also explored the use of hybrid quantum computers to share SHA-256 tasks between quantum and classical hardware.nan","The authors' experiments successfully demonstrated the implementation of the Quantum XOR (CNOT) gate, which is the core operation in SHA-256. The quantum circuits exhibited the initial part of the SHA-256 hash function loop on both real quantum computer hardware and quantum simulators. The results obtained from these circuits showcased the probabilistic nature of quantum computations, with the most probable outcomes identified. Furthermore, the authors compared the energy consumption of quantum and classical mining systems, highlighting the significant reduction in energy consumption offered by quantum computing.nan","The study provides a proof-of-concept for the application of quantum technology in optimizing the energy consumption of cryptocurrency mining. While the current limitations of quantum hardware restrict the implementation of the entire mining process, the authors emphasize the potential of future developments in quantum computing hardware and hybrid quantum computers. They address concerns about the probabilistic nature of quantum computations and their impact on the determinism required in cryptocurrency mining, explaining how these results can be interpreted by classical hardware to ensure deterministic outcomes. The authors also acknowledge potential debates on the implications of easier cryptocurrency production on market dynamics and emphasize that their proposed method focuses on reducing energy consumption rather than simplifying the mining process.nan",The lower energy consumption in cryptocurrency mining processes by SHA-256 Quantum circuit design used in hybrid computing domains,"Ahmet Orun, Fatih Kurugollu","1 
 
The authors are with School of Computer Science and Informatics, De Montfort University, Leicester LE1 9BH, UK 
Email: aorun@dmu.ac.uk, and Department of Computer Science, University of Sharjah, UAE.  Email:  fkurugollu@sharjah.ac.ae  
The lower energy consumption in cryptocurrency mining 
processes by SHA-256 Quantum circuit  
design used in hybrid computing domains 
 
Ahmet Orun and Fatih Kurugollu 
  
 
Abstract - Cryptocurrency mining processes always lead to 
a high energy consumption at considerably high 
production 
cost, 
which 
is 
nearly 
one-third 
of 
cryptocurrency (e.g. Bitcoin) price itself.  As the core of 
mining process is based on   SHA-256 cryptographic 
hashing function, by using the alternative quantum 
computers, hybrid quantum computers  or more larger 
quantum computing devices like quantum annealers, it 
would be possible to reduce the mining energy 
consumption with a quantum hardware’s low-energy-
operation 
characteristics. 
Within 
this 
work 
we 
demonstrated the use of optimised quantum mining 
facilities which would replace the classical SHA-256 and 
high energy consuming classical hardware in near future. 
 
Index Terms- CryptoCurrency, quantum computing, hash 
function, cryptography 
 
I. INTRODUCTION 
 
Quantum computing is one of the emerging and rapidly 
growing technologies in financial world [5] [20] by 
promising solutions for cryptocurrency mining. In 
particular, one of the most remarkable issues of popular 
cryptocurrencies [18][19] is their extremely high energy 
consumption during their mining process (e.g., ~10 
minutes:  72,000 GW for Bitcoin). This results in 
spending nearly one-third of Bitcoin’s current (2021) 
market value for energy consumption. It will also be 
proportionally becoming more problematic with its 
soaring production volume and dramatically increasing 
global energy shortage in the future. This critical field 
not surprisingly attracted several investigations and 
studies recently on how to make a considerable 
reduction of cryptocurrency mining costs [1][2][37].  
 
Quantum computing provides fertile grounds to solve 
this problem as its energy consumption is extremely 
lower than the classical computing with CPU, GPU and 
ASIC [24]. As far as the quantum hardware 
characteristics are concerned, their size is nearly  
 
 
 
 
 
independent from their energy consumption. They 
consume very small energy whatever their size is in  
qubit capacity (as only their interface electronic 
instrumentation or their cooling systems consumes very 
low  energy). There are very few previous works focused 
on an exploitation of quantum computing and quantum  
hardware utilities for such challenging  hash function 
tasks  due to Quantum Hardwares’ current small size 
capacities [1][5]. Ablayev and Vasiliev introduces a 
work on quantum hashing [6] which is the core of 
cryptocurrency mining. Their method is based on 
classical-quantum where a classical bit string is used as 
input to produce a quantum state. Even though all 
scientific 
authorities 
agree 
on 
the 
low-energy 
consumption characteristic of quantum hardware, the 
real issue at the moment is their small-sizes and current 
low capacities (e.g., max 50 “reliable” qubits) to run any 
standard cryptocurrency algorithm like SHA-256 
hashing function. The other frequently mentioned issue 
is probabilistic nature of quantum physics [16][17] and 
its adverse effect on low-level quantum hardware (QH) 
operation whereas Cryptocurrency mining process has to 
be very deterministic rather than probabilistic. This 
problem however only linked to low-level natural 
characteristics of quantum physics but not an issue at 
user level interface domain, and could be overcome by 
higher level supplementary methods operating in 
classical interface hardware (e.g. conventional dedicated 
PC linked to QH).  
In this work, we investigated how any suitable “quantum 
hardware based” quantum SHA-256 hash function, 
which is equivalent to classical SHA-256, can be 
implemented and executed on a real publicly accessible 
quantum computer like IBM QX or running on a 
quantum simulator to demonstrate its functionality. For 
this aim, we implemented Quantum XOR gate (CNOT) 
operation  in our work. Our implementation shows that 
SHA-256 can be utilized in QH effectively. This would 
lead to remarkable electricity energy saving which help 
to mitigate possible energy crises in future. The 
comparison between quantum and classical hardware 
energy consumptions is shown in Table 3.  
 
 
2 
 
 
II. METHODS AND MATERIALS 
 
A.  SHA-256 hash function  
 
One-way hash function or secure hash function is one of 
the important concepts in cryptography as used in many 
security related applications. This idea was firstly 
introduced by Merkle [7], Rabin [9] and, Diffie and 
Hellman [8] in their studies on public key cryptography, 
authentication, and digital signature. After all it became 
an indispensable tool for other security applications like 
password verification and file integrity checking as well 
as proof of work in Bitcoin mining. 
 
The hash function, H(·), maps an arbitrary long input 
message, m, onto a fixed sized output hash code, h (H(m) 
= h) as depicted in Figure 1. The mapping function 
should be easily computed for any given m. Besides 
these basic properties, Merkle [7] pointed out that the 
following characteristics are must for a hash function 
and  to be used in complex security applications:  
 
• 
One-way or pre-image resistance: For any given 
hash code, h, it is computationally infeasible to 
determine the original input message, m. 
• 
Second pre-image resistance or weak collusion 
resistance: For a given message, m, it is 
computationally infeasible to compute another 
message, m’, which has the same hash code, H(m) = 
H(m’). 
• 
Strong collusion resistance: it is computationally 
infeasible to find a pair of messages, m and m’, such 
that  H(m) = H(m’).  
However, it is worth to note that strong collision is not 
avoidable within the generic process of hash functions 
but ideally kept at limited level.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Basic view of a hash function as input data at 
varying length encrypted into a hash value at a fixed 
length (256 bits in the example)  
 
After initial introduction of hash functions, National 
Institute of Standards and Technology (NIST) in USA 
developed Secure Hash Algorithm (SHA) providing 
security to hash functions and published as a Federal 
Information Processing Standard (FIPS 180) in 1993 
[21]. NIST also revised SHA in 2002 and published 
FIPS 180-2 introducing new versions of SHA family 
having 256-bit, 384-bit and 512-bits hash value lengths. 
Among them, SHA-256 was selected as most suitable 
one by the cryptographic authorities with its 128 bit 
security level against a collision attack in comparison to 
SHA-512 despite its higher security level but larger 
performance penalty[3]. SHA-256 has also adopted for 
Proof-of-Work process by Bitcoin [22]. 
 
SHA-256 hash function uses the Merkle-Damgård 
transform based on a compression function which is 
applied recursively to map n + l input bits to n output 
bits [14]. For this aim, a common Davies-Meyer 
compression algorithm is used (Figure 2). As is a one-
way compression function, its original message does not 
need to be restored back. A generic Davies-Meyer 
compression function can be defined as follows [14]: 
 
f : {0,1}n+l  → {0,1}l 
f(k,m) = Ek(m)  m                                        (1) 
 
where k is the key, m is the message block and E is the 
encryption function with key length n and block length 
l. This states that the encrypted message is XORed with 
the message block. In SHA-256, this function is used in 
a recursive manner using the previous hash value, Hi-1, 
as the plaintext for the function to generate the next hash 
value, Hi. The message block is used as the key for E. 
Therefore the chain for the hash value in SHA-256 can 
be expressed as follows: 
 
Hi = Emi (Hi-1)  Hi-1                                                                  (2) 
 
where;     m: message block,   
 
  H: hash value (previous and next)   ,   
 
  E : encryption process    
 
At the start of process where the previous Hi-1 value is 
not available, the initial H0 value is used as is shown in 
Table 1. The last H value after 64 rounds of compression 
function is used to determine the hash code of the 
message. This core process of SHA-2 is depicted in 
Figure 2. In each iteration of the loop, an element of 64 
digit block is processed by the encryption function, E. 
As far as the specifications of the process are concerned, 
hash value, H, consists of 64 digit hexadecimal string. 
Block size of  256 bit block of message is processed in 
each iteration.  mi   shows the ith block of the complete 
message m.  Here each word of string is 32 bit unsigned 
integer and in each iteration, a block of 64 digit message 
block is processed. The implementation details of SHA-
256 can be found in [14]. Some examples of messages 
and their SHA-256 conversions are provided in Table 1.  
 
Hash code h:( 0x 
e3b0c44298fc1c1f) 
Arbitrary long 
data 
m: (“my key”) 
 
Hash 
Function 
       
3 
 
Table I. Some of  the  sample  messages (m)  and   
 Their SHA-256 conversions in hexadecimal form 
 
The SHA-256 is characterised by XOR, bit-rotations, 
NOT, OR, AND, modular addition operations [14]. The 
core operation is XOR gate because other operations can 
be easily implemented by using an effective design of 
XOR gate. Therefore, our concern in this work is to 
develop and implement a Quantum equivalent of XOR 
gate which is CNOT quantum gate.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
        
 
 
Figure 2. The continuous loop processing the chain of 
messages in 64-digit blocks 
 
 
 
 
 
 
 
 
B.  Quantum hardware and computing  
 
Quantum computing processes are enabled by quantum 
hardware (e.g., photonic, ion-trap, super conducting, 
topological, etc.) as called “quantum computer” or 
“quantum annealer” which operate according to 
quantum 
physical 
principles 
[11][12]. 
Quantum 
computing concept operationally exploits a quantum 
particle’s two states (e.g. spin-up or spin-down, etc.) and 
their superposition characteristics to make calculations 
with an advantage of additional 2x states over the 
classical bit (0,1), as is called qubit. If qubit number is n, 
then the number of states will be 2n. The number of 
qubits refers to the capacity of quantum hardware. For 
example, a 3-qubit quantum computer can be described 
by 8-dimansional vectors like = (a0, a1, a2, a3, a4, a5, a6, 
a7) where each vector element, ai, is a complex number 
coefficient. Their state descriptions would be as follows: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
a0 |000 +   a1|0001 +   a2 |010 +   a3 | 011 + a4 |100  +   
a5 |101 +   a6 |110 +  a7 |111 
 
Quantum computing can be demonstrated on globally 
available systems like IBM QX (53 qubit as only 15 
qubit accessible for public use at the moment), D-Wave  
(Leap) 5000 qubit, Google (53 qubit) by remote access. 
The facilities are optional in “real-time “and “simulator” 
modes. Meanwhile Microsoft provides a cloud service 
for Quantum programming in its own language Q# 
running in a simulation mode on a simulator. In terms of  
 
 
 
 
 
 
 
 
 
 
 
hardware efficiency, nowadays the most important issue 
of quantum hardware is high error rate of qubits as it is 
a current bottle neck to overcome until a new “low-error-
rate” quantum hardware discovery. However, a USA 
company, IonQ, recently (October 2020) announced a 
new reasonable error rate quantum computer at 32 qubit 
capacity operates with ion-trap technique [25]. 
Meanwhile there is always confusion between the 
physical qubit and logical qubit terms, as 1 logical (low-
error) qubit may refer to ~200 physical (high-error) 
qubits. The other disadvantageous factor is that in 
quantum hardware, qubits communicate to each other as 
an error produced by each qubit increase cumulatively 
over the logical gates (CNOT gate in particular) which 
is the main obstacle for larger quantum computers 
design and production. However, quantum error 
correction is the mainly focused area on the global basis, 
hence expected to be solved in near future for large scale 
quantum computers[26]  We have to note that the 
quantum hardware is inevitably operated in association 
with the classical computers (hardware) used as an 
interface. 
 
 
Message (m)  
  SHA-256 conversion to 64 digit block (with 4 bit x 8x8 = 32 bit words x 8) 
“This is my message 
for quantum” 
9b95bfa6ceb2de10d7ef3ff3b794ffea2c2ba7911a209b323a55e8f306a64931 
  “DMU” 
3a8b4b9d4649b3573f552a9eb6b5c1244fd79815e817aa86d65422e2564b2d0a 
  “DMV” 
d4fee25a1acee0e6610473456a83bd2f4f5ccf96e25c13b88f65cd79ca54d7ed 
     “A” 
559aead08264d5795d3909718cdd05abd49572e84fe55590eef31a88a08fdffd 
H0 (initial value) 
6a09e667 bb67ae85 3c6ef372 a54ff53a 510e527f 9b05688c 1f83d9ab 5be0cd19 
4 
 
 
C.  CNOT quantum logic gate (XOR equivalent) 
 
In quantum computing, CNOT logical gate (controlled-
not gate) is the important one to generate quantum 
entanglement for the quantum tasks like teleportation, 
super dense coding, etc. but in our work here, it would 
only be used as the quantum analogue of classical 
computing’s XOR logical gate. CNOT gate is always 
used by operating on two qubits at once. The first qubit 
operates as a “control” qubit whose state affects the 
second “operation” qubit’s state. If the control qubit is 
“0” then there is no change on operation qubit’s state, 
but if the control qubit is “1” then it changes the state of 
operation qubit. Control qubit state and operation qubit 
state are shown in Figure 3 as x-input and y-input. The 
classical SHA-256 can be implemented using an XOR 
logic gate “” in its loop process which can be seen on 
Figure 3. Its 2-qubit quantum circuit equivalent with 
CNOT logic gate “” where Hi-1 ≡ x and mi ≡ y, as well 
as their logical process table is depicted at the right hand 
side section. 
On the other hand, the SHA-256 is characterised by 
XOR, bit-rotations, NOT, OR, AND, modular addition 
operations [14]. The core operation is the XOR gate 
because other operations can be easily implemented by 
using an effective design of an XOR gate. Therefore, our 
concern in this work is to develop and implement a 
Quantum equivalent of an XOR gate which is a CNOT 
quantum gate. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. Implementing classical SHA-256 using 
Quantum CNOT gates 
 
 
 
 
 
 
 
 
 
The further details about the quantum characteristics of 
the CNOT logical gate (e.g. its entanglement or 
superposition links, its usage with Hadamard gate, 
etc.[23]) are out of the scope of this work.  
 
III. POTENTIAL ALTERNATIVE OR 
SUPPLEMENTARY METHODS 
 
A. Quantum hash function  
 
Even though we propose a low-level quantum logical 
gate based operation in this study which is quantum 
hardware related and would be  independent from any 
“classical” or “quantum” hash function computing 
approach, our proposed low-level method makes a 
substantial contribution to such theoretical studies to 
demonstrate them.     The earlier studies on quantum 
hash function were demonstrated on both “non-binary” 
based [6] and “binary” quantum hashing [13]. The non-
binary method accepts classical bit string as an input and 
convert it to quantum state output. Vasiliev introduces 
the technique which allows to present binary inputs by 
quantum states [13]. He also proved that there was 
reverse correlation between the characteristics of 
method so that, the more quantum hash function was 
preimage resistant, the less collision resistant it was. In 
their work, Ablayev and Vasiliev defined the quantum 
hash function by the following notifications, in which 
the quantum hash function hK described as [6] in 
Equation 3:  
 
|ℎ𝐾(𝑀)⟩ = 1
√𝑑 ∑
|𝑖⟩
𝑑
𝑖=1
(𝑐𝑜𝑠
2𝜋𝑘𝑖𝑀
𝑁
|0⟩ + 𝑠𝑖𝑛
2𝜋𝑘𝑖𝑀
𝑁
|1⟩)                     
(3) 
 
where M is the arbitrary message satisfying M  {0,1}n, 
N = 2n (for n-bit messages), d = |K| and Set K = {ki : ki 
{0,….,N-1}}. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
If  is defined as resistance (e.g., (orthogonality) 
quantum collision resistance, it also corresponds to 
classical second pre-image resistance). For any pair of 
inputs W, W’  (W  W’ ) it satisfies |1|2| <  where the 
absolute value of 1|2  inner product between  two 
wave functions refers to distance or overlap between 
those two states and also refers to as fidelity. where  is 
called quantum one-way function complying with the 
hash function property that is easy to compute and 
difficult to invert.  With the above notations it would be 
possible to evaluate formula 4  as follows [6]:  
5 
 
 
|ℎ𝑀1|ℎ𝑀2| =
|
1
|𝐾| ∑
𝑐𝑜𝑠
2𝜋𝑘𝑖(𝑀1−𝑀2)
𝑁
|𝐾|
𝑖=1
|  ≤ (K) <            (4) 
 
 
 
 
 
 
 In which the pair of input massages have not to be same, 
M1  M2. 
 
Serial calculation of quantum hash function would be 
possible on globally available quantum computers or via 
their cloud connection. But in the latter case, logical gate 
calculations of a binary data string have to be made by a 
remote connection to paid-quantum-computing services 
(e.g. ~1000 shots cost about 0.25 USD) where the 
supplier provides a dedicated time slot for the usage. 
However, this would not be the ideal case since any 
connection between the interface domain and remote 
quantum hardware would have a limited security level. 
Hence this option has to be fortified by  additional 
security measure for a secure connection in  commercial 
applications.   
In case of direct usage of a quantum hardware, logical 
gate calculations of a binary data string (e.g. input 
message for SHA-256 hash function) on a Quantum 
processor may be carried out as block-by-block of a long 
strings (e.g. 1000 digit long) which is normally beyond 
the current qubit capacity of quantum computers that are 
globally available (e.g. max 65 qubit). Such block-by-
block string processing loops have to be run by a 
continuous real-time operation of quantum hardware. As 
this issue could be solved by partial operational division 
of entire task, the other quite promising global 
developments indicate that the quantum hardware 
capacity is progressively increased and targeted 1000 
qubit is expected to be achieved in 2023.    
 
B.  Quantum annealer as an alternative method for 
SHA-256 hash function 
  
Quantum annealing is linking a specific problem’s best 
solution to a related quantum physics phenomenon to 
find the minimum energy state which already means the 
solution. To accomplish that, first, the objective function 
of the problem should be specified. Then calculate its 
energy value should be calculated by using function 
parameters and targeting the minimum energy point. 
Quantum annealing differs from the qubit gate model as 
the qubit gate model depends on solving the problem by 
controlling the logical qubit gates. The limitation of the 
logical qubit gate model depends on the low qubit 
capacity of current quantum computers globally 
available which is currently 64 qubit (IBM’s QC at 
Manhattan, as Google’s 72 qubit QC has some 
controlling issue) . Whereas quantum annealers operate 
depending on the evolutionary approach in which the 
system 
searches 
the 
minimum 
energy 
state 
corresponding to the exact solution of the objective 
function. In contrast to current logic gate models 
demonstrated by the quantum computers, quantum 
annealers may have huge qubit capacity (e.g. 5,760 
qubits [27]) because their hardware characteristic is very 
different than  quantum computers and limited to only 
optimisation problem solutions.  
 
D-WaveTM for instance,  produces reprogrammable 
quantum processing unit chips to be used in a quantum 
annealer. It has to work at milli-Kelvin temperature 
requiring a cooling system. The quantum annealer’s chip 
is also in lattice form and demonstrates the Ising model 
[15] using voltages and magnetic fields to control the 
chip circuits. In a quantum annealer chip, the qubits are 
a 2D array of superconducting loops carrying electric 
current and behave like magnets pointing up or down, 
but in this case, pointing up and down at the same time 
according to the quantum superposition principle. To use 
the quantum annealer, the user maps the specific 
problem into a search for the lowest energy point. Then 
the 
quantum 
annealer 
processor 
considers 
all 
possibilities simultaneously to satisfy the qubits network 
of relationships with the lowest energy point. This 
principle would be demonstrated by minimizing the 
objective function (e.g. SHA-256 hash function in our 
case) in Figure 4 as follow:  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 4. XOR classical logic gate or  CNOT quantum 
logic  gate logical process  operated by quantum 
annealer with minimum energy state approach. 
 
       fobj (weight, strength, qubit) =  weight . 
qubit +   strength . coupler                       (5) 
 
In Equation 5, the notations are described as follows: 
Coupler: Physical device that allows one qubit to 
influence the others.  
Qubit: Quantum bit participating annealing cycle and, 
at the end it settles down to one of the states {0,1}. 
Weight: Qubit’s tendency to jump into the final state {0 
or 1}. It is constant and controlled by the user. 
Strength: Controls the level of qubit’s influence on the 
others. It is constant and controlled by the user. 
 
6 
 
During the quantum annealing cycle, the qubit spins 
keep evolving and exploring the problem space. At the 
end of the annealing cycle, the system reaches its ground 
state of the submitting problem. Then the final states are 
yielded as the output of the solution.  A representative 
quantum annealing example solution for XOR or CNOT 
which is the core operation in SHA-256 is shown as 
follows:  
Problem definition: Find minimum energy = 0  for  x 
 y  (XOR classical logic gate or  CNOT quantum logic 
gate)  
By the quantum annealing cycles, the system yields 
outputs of minimum energy states “0” which are the 
solution of hash function (x  y) as seen in Figure 4 
Quantum annealers have been investigated to be used as 
a potential cryptocurrency process domains in future but 
due to current limitation of free access (e.g. $2000/hour 
service provided by D-WaveTM) , they have not been 
used within this study.  
 
C.  Hybrid quantum computers  
 
Hybrid quantum computing has been an emerging 
technology as a solution [29][30] to mitigate the issue of  
small size and low capacity of current quantum 
computers (QC), by merging quantum computing and 
classical computing hardware to utilize them in 
harmony.  Hence, the hybrid computation may be a good 
choice to overcome the issues of  SHA-256 capacity 
need in quantum computation domains. In our case the 
ideal approach would be, high energy consuming 
processes will be executed in quantum hardware and 
meanwhile 
the 
classical 
hardware 
 
will 
be 
simultaneously used in connection with QC for other 
tasks like: loop operations of SHA (string-by-string), the 
storage of the results, data format conversions (e.g. from 
hexadecimal to binary, etc.) and other sub-operations as 
seen in Figure 5.    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5. Proposed configuration of hybrid quantum 
computer design to solve the issues of current QCs low 
capacity by sharing SHA-256 tasks categorised as “high-
energy consumption (in QC)” and “low energy 
consumption (in Classical hardware)” 
 
 
 
 
 
 
IV. RESULTS AND DISCUSSION 
 
A.  Quantum circuits design to demonstrate the logical-
gate level  of the hash function process   
 
Some of the available accessible systems are shown in 
Table 2. The quantum circuits for the SHA-256 hash 
function have been designed and executed on two 
different domains of IBM:  
-Real  quantum  computer  hardware (Melbourne_15  Qubit)  
-Quantum simulators (32qubits, 5000qubits).  
as quantum simulators are specifically designed devices 
with different type of hardware to simulate the QC tasks. 
The quantum circuits exhibit only the first parts of the 
SHA-256 hash process loop due to the limited capacity 
of remotely accessible systems. The basics of circuits’ 
NOT and CNOT gates are shown in Figure 3 and 
complete circuits in Figure 6  respectively.   
 
Table II. The globally Available remotely accessible 
Quantum Computer Services   
 
 
 
 
Table III. Comparison between the quantum hardware 
and classical mining  system (by different references) 
Hardware type 
Energy consumption  
  (TWh /year) 
CO2  Emission  
( Tons / year) 
Bitcoin mining unit 
 80     [31] 
110    [32] 
 91     [33] 
 
267   [31] 
Quantum computer 
25 x 10-9 (25 kWh) [35][36] 
N/A  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
It has been reported that there are about 1 million 
Bitcoin miners globally available [34]. The related 
calculations of electricity consumption and CO2 gas 
emission for both (quantum and classical systems) can 
be made as shown in Table 3.  
 
 
System  Name 
(Location) 
Processor type 
Quantum 
volume 
Qubit  
capacity 
Ibmq Manhattan 
Hummingbird R2 
32 
65 
Ibmq  Montreal 
Falcon r4 
128 
27 
Ibmq Dublin 
Falcon r4 
64 
27 
Ibmq Sydney 
Falcon r4 
32 
27 
Ibmq Casablanca 
Falcon r4H 
32 
7 
Simulator  stabilizer 
Clifford simulator 
N/A 
5000 
7 
 
 
 
 
 
 
 
 
 
 
 
 
 
Practically SHA-256 hash function quantum “qiskit” 
codes  can be directly executed on the real quantum 
computer hardware remotely without the need for 
circuit design as shown in Figures 6 and 7.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6. SHA-256 Circuit design which demonstrates 
for-loop (first 8-bit) of SHA-256 hash function in 5000-
qubit capacity Quantum Simulator. Its measurement 
results are also shown at top-right window.  
 
The circuit processes initial (starting from the end) part 
of message m= “this is my message for quantum” and 
initial H0 value as;  
 
H0(h0)= 01101010000010011110011001100111 which 
is equivalent of  h0= 0x6a09e667 in hexadecimal form 
is shown in Figure 6.  We have to note that in the process 
only H0(h0) is taken instead of H0(h7) which is normally 
aligned with the end of message “m”. The results 
(measurements) include 16 x”0” corresponding to H0 
(h0) and m1 section (top of the circuit) where no 
measurements are made. In Figure 6, the histogram at 
the top-right exhibits 1022 shots of the logical gate 
operation measurements for 24 qubits (0-23) whose 
result is calculated for qubits 23-16 as “0,1,1,1,1,1,1,1” 
and “0s” for the remaining qubits 15-0 means that  no 
any logical gate operation is made for this range.   As 
already known, the quantum computer’s calculation 
style is based on probability, hence the results are 
yielded after number of shots (loop) which 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
the results are yielded after number of shots (loop) which 
corresponds to number of repetitions of the  quantum 
circuit. In the circuit of quantum simulator (Figures 6), 
the NOT gate is shown as “” which is also known as 
Pauli-X gate. It changes |0 state to |1 state. As is shown 
at the left edge of the circuit, all qubits initially start with 
|0 states for values of “0”,  and then the  values of “1” 
are generated by use of  “NOT” gates which refer to |1 
states. In this way we can make any data entry of any 
binary string into the quantum circuit. In the middle 
region of circuit we use CNOT gates (Controlled-NOT 
gate corresponds to classical XOR logic gate) which link 
between two binary  values to process XOR logical 
operation between them. The measurement icons at the 
8 
 
bottom-right corner of the circuit just display the output 
of calculations.  The measurement result “Message“m2” 
is yielded after the CNOT logical gate operation between 
“Message“m1”  and “H0(h0)” as described in Formula 2. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7. (Top) Single loop of SHA-256 hash function 
operation by the circuit where i=4bit  (as explained in  
Figure 3) is executed on IBM’s 15qubit  real quantum 
computer hardware (Melbourne).  (Bottom) The results 
are quantum probabilistic and different than simulator 
ones. The most probable results are shown by blue arrow 
in the frequency histogram table whose probability 
values are generated after 1022 shots of quantum units. 
The circuit of real quantum computer as shown in Figure 
7 (other than the quantum simulator) contains the same 
components with the Figure 6,  but with  different 
numerical configuration. The “most probable” result is 
displayed by the frequency  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
histogram 
(bottom 
side) 
corresponding 
to 
“Message”m2”  is  “0,0,0,1,1,0,0” for the qubit range 14-
8 respectively. The remaining “0” values for the  qubit 
range 7-0 means that  no any logical gate operation is 
made for this range.    
 
9 
 
 
 
 
 
 
 
V. CONCLUSION 
 
Within this study, the basics of the classical SHA-256 
hash function which is the most energy consuming part 
of cryptocurrency mining have been demonstrated at a 
proof-of-concept level. Even thought the whole mining 
process requires a very high volume of quantum gate 
combinations, it fortunately has  the identical repetitive 
structures and configurations whose functions to be 
proven by a small size of globally accessible quantum 
computers. As far as the energy consumption of the 
proposed system is concerned, the interface hardware for 
QCs and/or classical computing components of a hybrid 
computers have not accountable energy consumption 
since they are only utilized for data format conversions, 
data storage, quantum logical process loop operations, 
etc.  The other popular concern is about quantum 
physic’s probabilistic nature and is reflected by quantum 
hardware’s high error rate (CNOT gate in particular) 
which has also been proven as is not a problem at a 
higher level of host system’s operation where the 
probabilistic results are further re-interpreted by a 
classical (interface) hardware to make the results 
deterministic enough for Cryptocurrency mining 
process. It has to be noted that the results obtained in 
Figure 7 rely on high-error rate quantum hardware, 
whereas there is currently lower error rate hardware like 
IonQ’s 32-qubit quantum hardware (QH) utility and 
IBM’s 65-qubit (QH) utilities available but at some 
service cost. However more reliable and larger quantum 
hardware would be soon presented in near future (e.g. 
1000 qubit QC is targeted by 2023 and 1M qubit QC is 
expected by 2030) this is due to high level of globally 
challenging 
competition 
between 
the 
quantum 
institutions and private companies.  
 
On the other hand, as there would be a common debate 
in financial community based on a speculative idea 
claiming that the easier production of Cryptocurrency 
may lead to its sharp price fall and lead to corruption of 
whole crypto currency system. Whereas some finance 
authorities agree that the cryptocurrency prices do not 
rely on any absolute factor but rather manipulated only 
by global supply-demand chain. In addition to this, we 
have to note that in our study in fact we are not 
proposing any quantum algorithm to speed up the 
current mining process nor make it easier. Our 
proposed method is just to make the current mining 
process less energy consuming which helps reduce 
global carbon emission, avoiding a global waste of 
electricity, initiating further developments of quantum 
finance area, etc.  
 
 
 
 
 
 
 
 
 
 
 
 
 
REFERENCES 
 
[1] Wilkins, A. Quantum computers could slash the energy use of 
cryptocurrencies. New Scientist magazine (Technology), June, 20. 
2023. 
 
[2] Li, J., N.  Li, J. Peng, H. Cui and Z. Wu. Energy consumption of 
cryptocurrency mining: A study of   electricity consumption in mining 
cryptocurrencies, Energy 168(2019), pp.160-68.  
 
[3] Ferguson, N. and B. Schneier. Practical Cryptography, Wiley 
Publishing Inc., Indiana US,  2003. 
 
[4] National Institute of Standards and Technology. Secure Hash 
standard (draft) 2001.  
 http://csrc.nist.gov/encryption/shs/dfips-180-2.pdf   
 
[5] Orus. R., S. Mugel and E. Lizaso. Quantum computing for finance: 
Overview and prospects,  Reviews in Physics 4 (2019) 100028,  2019. 
 
[6] 
Ablayev, 
F. 
and 
A. 
Vasiliev. 
Quantum 
Hashing. 
arXiv:1310.4922v1, Kazan Federal University, 18 October 2013.  
 
[7] Merkle, R.C.: Secrecy, Authentication and Public Key Systems. 
Ph.D. thesis, UMI Research Press, Italy (1979). 
 
[8] Diffie, W., Hellman, M.E.: New directions in cryptography. IEEE 
Trans. Inf. Theory. IT-22, 644–654 (1976). 
 
[9] Rabin, M.O.: Digitalized signatures. In: Lipton, R., DeMillo, R. 
(eds.) Foundations of Secure Computation, pp.155–166. New York, 
Academic Press (1978). 
 
[10] Yang, Y., Bi, J., Li, D., Zhou, Y. and Shi, W. Hash function based 
on quantum walks. International Journal of  Theoretical Physics, 58 
(2019), pp.1861-73.  
 
[11] Raymer, M.G. Quantum Physics, Oxford University Press, New 
York (2017). 
 
[12] Orun, A. Inter-substances “Natural quantum communication” 
investigation by atomic exchange observation with photonic wave-
particle duality quantization, KOBIT-5 International Quantum Optics 
and Information Conference, 22-23 April 2021. Turkey.  
 
[13] Vasiliev, A.V. Binary quantum hashing, Russian Mathematics, 
2016, Vol.60. No.9, pp.61-65.  
 
[14]Davies-Meyer(one-way)Compression, 
https://en.wikipedia.org/wiki/Oneway_compression_function 
Knospe, H.: A Course in Cryptography, American Mathematical 
Society,2019. 
 
[15]Ising, E.,  Ising Model,  https://en.wikipedia.org/wiki/Ising_model 
, 1924. 
 
[16] Orun, A. and G. Smith (2020). Investigation on a quantum 
communication phenomenon between subatomic properties of 
substances by quantum eraser pattern quantification. Optical 
Engineering, 59(3), 2020. 
 
[17] M. G. Raymer, Quantum Physics, Publisher: Oxford University 
Press, New York (2017). 
 
[18] Duong, L.V.T., N.T.T. Thuy and L.D. Khai. A fast approach for 
bitcoin blockchain cryptocurrency mining  system, Integration, the 
VLSI Journal 74 (2020) 107–114. 
 
10 
 
[19] Shih, D., T. Wu, T. Hsu, P. Shih and D.C. Yen. Verification of 
Cryptocurrency Mining Using Ethereum, IEEE Access, Vol 8, 2020.
 
 
[20] Baaquie, B. Quantum Finance: Path Integrals and Hamiltonians 
for Options and Interest Rates, Cambridge University Press, 2007. 
 
[21] Stallings, W.: Network Security Essentials, 6th Edition, Pearson 
Education Limited, Harlow, UK, (2017). 
 
[22] Antonopoulos, A. M.: Mastering Bitcoin, O’Reilly Media, 2017. 
 
[23] Moran, C.C., Mastering quantum computing with IBM QX,  Packt 
Publishing, Birmingham UK, 2019. 
 
[24] Hsu, J. How much power will quantum computing need ?, IEEE 
Spectrum, 5 October 2015. 
 
[25] IonQ Quantum Computing, https://ionq.com/news/october-01-
2020-most-powerful-quantum-computer , 2020.  
 
[26] McEwen, M, D. Kafri and R. Barends. Removing leakage-
induced correlated errors in superconducting quantum error correction, 
Nature Communications, 12, Article No. 1761 (2021). 
 
[27] Whittaker, J. System Roadmap, D-Wave Systems Retrieved, 
February 2020.  
 
[28] D-wave, System Documentation (QUBO), “D-Wave solver 
properties and parameters reference”,  
  http://docs.dwavesys.com/docs , 2021. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[29]  Zhu, D. N.M. Linke, M. Benedetti, K.A. Landsman, N.H. 
Nguyen, C.H. Alderete, A. Perdomo-Ortiz, N. Korda, A. Garfoot, C. 
Brecque, L. Egan, O. Perdomo and C. Monroe, Trining of quantum 
circuit on a hybrid quantum computer, Science Advance Physics. 
2019; 5: 18 October. 
 
[30] Jaderberg, B., A. Agarwal, K. Leonhardt, M. Kiffner and D. 
Jaksch,  Minimum hardware requirements for  hybrid quantum-
classical DMFT. Quantum Science and Technology, Vol.5, No.3,  
2020. 
 
 
 
 
 
 
[31] Vries, A. Digiconomist, 2021. https://digiconomist.net.   
 
[32] Carter, N. How much energy does Bitcoin actually consume?, 
Harvard Business Review, Boston MA – USA, 
 May,  2021.   https://hbr.org  
 
[33] Ahl, A. Bitcoin’s 2021 energy use has already surpassed 2020: 
BNEF Chart,  Bloomberg Green, Bloomberg. 13 September 2021.  
 
[34] Nagarajan, S.,  Bitcoin miners raked in more than $1 billion in 
combined earninigs last month, Markets Insider,  New York - US,  
20 Febr 2021.  
 
[35] Hsu, J. How much power will quantum computer needs? , IEEE 
Spectrum, New York USA, 5 Oct 2015.  
 
[36] Brownell, V.,  Quantum computing could change the way the 
World uses energy, Quartz: Yahoo Finance, California USA, March 
2019.  
 
[37] Tessler, L and T. Byrnes,  Bitcoin and quantum computing. (Nov. 
2017)   https://arxiv.org/ftp/arxiv/papers/1711.04235.pdf  
  
 
 
 
 
"
"The article explores an interactive platform, RIS3-MCAT, developed using open data, semantic analysis, and data visualization to monitor challenge-oriented smart specialization in Catalonia. RIS3-MCAT, aimed at providing monitoring systems and tools for mapping and understanding R&I policies and projects, facilitates access to data on projects, enabling detailed analyses beyond classical classification systems.nan",The paper highlights the necessity of developing monitoring systems and tools for a successful transformation towards sustainable development and new patterns of specialization. It also emphasizes the importance of coordination and collaboration among different societal stakeholders and the need for evaluating the impact of public policy and R&I.nan,"The authors provide an extensive literature review covering various topics. They discuss the challenges posed by globalization, technology, climate change, and pandemics, and the enormous opportunities they bring. They mention the European Commission's initiative to accelerate the green transition and allocate funds for tackling societal challenges aligned with UN Sustainable Development Goals. The paper highlights the importance of changes in cooperation between governments, industry, academia, and civil society. Furthermore, it delves into strategies for smart specialization, which are dynamic agendas for economic and social transformation based on R&I, driven by entrepreneurial discovery processes. The authors stress the role of smart specialization in addressing complex transformative processes and the need for interactive visualization tools to identify and analyze emerging areas of specialization and collaboration networks.nannan","The development of the RIS3-MCAT tool involved a five-year co-design and development process. It includes the integration of data from CORDIS and SIFECAT, automatic classification of projects, topic modeling, and SDG classification. The data integration and cleaning process utilizes an ontology, and a domain ontology is used for data integration. Automatic classification of projects according to regional priorities is done using pre-trained language models for training textual classifiers. Topic modeling is used for capturing bottom-up domains by discovering thematics linked with a specific collection of texts. For identifying SDG-related research, a controlled vocabulary based on a hybrid approach that combines automatic and human-crafted keywords is employed.nan","The RIS3-MCAT tool offers various features, including search and filters, network analysis, a semantic map of projects, and analytical/statistical modules. The tool allows users to explore various scenarios, such as searching for actors and projects in similar topics, identifying collaboration networks, examining the state of research for a priority area, and promoting collaboration. Key insights from the project include the importance of strategic adaptability, consistent dialogue between stakeholders and providers, and decisive leadership in the co-design process. The need for manual attention and curation of data, despite automation, is also mentioned. Additionally, the challenges of dealing with a large number of entities and relationships in visualization and the rapid advancement of AI and NLP are discussed.nan","The paper concludes by highlighting the RIS3-MCAT platform's ability to tackle the challenge of monitoring challenge-oriented smart specialization with available technologies and open data. It emphasizes the key lessons learned during the process, including the importance of a collaborative design approach, the necessity of manual attention and curation of data, the need for continuous data integration, and the potential for re-publishing datasets for wider reuse. The paper also discusses opportunities for future development, such as incorporating additional R&I projects, improving visualization and interaction features, and exploring new classification systems.nan",Towards building a monitoring platform for a challenge-oriented smart specialisation with RIS3-MCAT,"Enric Fuster, Tatiana Fernández, Hermes Carretero, Nicolau Duran-Silva, Roger Guixé, Josep Pujol, Bernardo Rondelli, Guillem Rull, Marta Cortijo, Montserrat Romagosa"," 
 
 
Towards building a monitoring platform for a challenge-
oriented smart specialisation with RIS3-MCAT. 
 
Enric Fuster1, Tatiana Fernández2, Hermes Carretero1, Nicolau Duran-Silva1,3, Roger Guixé1, 
Josep Pujol1, Bernardo Rondelli1, Guillem Rull1, Marta Cortijo2, Montserrat Romagosa2 
 
1SIRIS Lab, Research Division of SIRIS Academic 
2Ministry of Economy and Finance, Government of Catalonia 
3LaSTUS Lab, TALN Group, Universitat Pompeu Fabra, Barcelona, Spain 
 
Abstract 
In the new research and innovation (R&I) paradigm, aimed at a transformation towards more 
sustainable, inclusive and fair pathways to address societal and environmental challenges, and 
at generating new patterns of specialisation and new trajectories for socioeconomic 
development, it is essential to provide monitoring systems and tools to map and understand the 
contribution of R&I policies and projects.  To address this transformation, we present the RIS3-
MCAT platform, the result of a line of work aimed at exploring the potential of open data, 
semantic analysis, and data visualisation, for monitoring challenge-oriented smart 
specialisation in Catalonia. RIS3-MCAT is an interactive platform that facilitates access to R&I 
project data in formats that allow for sophisticated analyses of a large volume of texts, enabling 
the detailed study of thematic specialisations and challenges beyond classical classification 
systems. Its conceptualisation, development framework and use are presented in this paper. 
 
Keywords: open data, research and innovation policy, smart specialisation strategies, text 
mining, data visualisation, scientometrics 
 
1. INTRODUCTION 
 
The challenges posed by globalisation, technology, climate change, and the COVID-19 
pandemic require significant changes in our way of living.  Although large transition costs are 
associated with a successful attainment of all those challenges, the potential opportunities 
brought about are enormous (Bigas et al., 2021). The European Commission aims to accelerate 
the green transition by implementing the Green Deal (European Commission, 2019) and by 
allocating funds in the cohesion policy framework and the Horizon Europe (European 
Commission, 2021) program to mobilise European research and innovation (R&I) ecosystems 
toward tackling outstanding societal challenges, such as the Sustainable Development Goals 
(SDGs) defined by the UN (United Nations, 2019). However, reaching these goals requires 
changes in the forms of cooperation between governments, companies, academia, and other 
societal stakeholders, new ways of combining knowledge from diverse disciplines, and new 
tools for evaluating the impact of public policy and R&I (Bigas et al., 2021). 
 
In this same direction, strategies for smart specialisation (S3) (European Commission, 2014), 
which are dynamic agendas for economic and social transformation based on R&I and 
articulated through entrepreneurial discovery processes (EDP), are becoming extremely 
important. Through the EDP, governments, companies, research and innovation stakeholders 
and civil society organisations and associations collaborate to identify challenges and areas of 
priority for action, and engage in collaborations towards more sustainable development 
pathways.  In this context, it is therefore key to develop new monitoring systems and tools that 
 
 
help better understand how different actors in the R&I ecosystem are contributing to the SDGs 
in order to accelerate the transitions, and consequently towards a smarter specialisation. 
In Catalonia, smart specialisation  is conceived as a forward-thinking open process where 
innovation stakeholders come together and prioritise challenges and opportunities to be 
addressed through initiatives, collaborations, policies, and investments (Generalitat de 
Catalunya, 2022). In the current 2021-2027 programming period, the RIS3CAT monitoring 
system focuses on understanding how the actions framed in this strategy contribute to: 
● articulating sustainable value chains 
● promoting business models aimed at generating shared value 
● 
 transforming goods and services delivery systems (sociotechnical systems) 
● fostering the creation of digital- and technology-based industry 
● moving towards a greener, more digital, more resilient and fairer socio-economic model 
These transformative processes are complex, as they involve interrelated changes in very 
different areas (such as the production systems, technologies, markets, regulations, user 
preferences, infrastructure, and cultural expectations). Accordingly, the monitoring system 
needs to include and combine different sources of information and types of analysis. Interactive 
visualisation tools integrating data from different sources are key to identify and analyse 
emerging areas of specialisation and collaboration networks (within the region and at EU level) 
in the RIS3CAT priority areas. 
 
Today, EDP, policy implementation and monitoring may be greatly helped by taking advantage 
of the wider transformative trends in the fields of Open Government and Open Science 
(European Commission, 2016), which are making more data relevant for the public good 
increasingly available in open and usable formats (Fuster et al., 2020). Data on R&I activities 
is made available by a series of initiatives. The availability of this data is helpful for the 
identification of R&D niches and key actors within territorial R&I ecosystems that might be 
embarked in those transformative processes mentioned above. Simultaneously, the 
exploitability of this data is increasing due to the advancements in data science, artificial 
intelligence, and, particularly, in natural language processing techniques, which are being 
applied to scientometrics to characterise and analyse the textual content of R&I documents. 
(Fuster et al., 2020b).  
 
The European Commission led the way by publishing the CORDIS database of European R&I 
projects. Since then, public administrations have promoted multiple initiatives such as the 
European Open Science Cloud, OpenAire, and Zenodo already link projects and their funding 
with the results they generate (reports, publications, patents, software, etc.). However, the 
provision and maintenance of open data are highly unequal and do not cover the full range of 
needs of public policymakers. The availability of open data with sufficient granularity and 
richness remains a challenge, although it is becoming less limiting as science and technology 
databases grow in number, size, coverage, quality, interconnection, and content richness. Some 
major challenges faced at a policy level arise because many of those data sources are not openly 
available which undermines the participatory processes). Additional challenges include their 
lack of  interoperability in terms of data classification schemes, their institutional identification 
limiting transversal analyses and their lack of accessibility to non-expert users.  
 
 
In this context, a line of work has been established to explore the potential of integrating open 
data, semantic analysis and data visualisation with the aim of developing methodological 
proposals for monitoring smart specialisation. This exploration, which tackled the challenges 
linked with the definition of indicators for monitoring emerging areas, territorial patterns of 
specialisation and collaboration dynamics between different stakeholders and areas of 
knowledge, led to the development of the RIS3-MCAT interactive platform1, whose 
conceptualisation, development framework and use are presented in this paper. 
 
This paper is organised as follows. Section 2 introduces policy objectives and main functions 
of the RIS3-MCAT monitoring platform. Section 3 presents the five-year co-design and 
development process. Section 4 presents data sources, system architecture and presents main 
results of components and features. Section 5 illustrates the main use cases. Finally, Section 6 
draws conclusions and recommends future work directions. 
 
2. POLICY OBJECTIVES AND MAIN FUNCTIONS 
 
The RIS3-MCAT Platform is an interactive tool aimed at visualising, exploring and analysing 
the specialisation and collaboration patterns of R&I projects financed with European funds in 
Catalonia. It is an open government, artificial intelligence and data visualisation project that 
integrates and makes openly accessible and interoperable data from science and innovation 
projects, with the aim of contributing to the following objectives: 
● understanding the impact of European funds on the specialisation of the R&I 
ecosystem of Catalonia, 
● identifying opportunities to maximise the collective impact of R&I in Catalonia, based 
on synergies and the coordination of efforts 
● providing new evidence that facilitates decision-making by stakeholders in the R&I 
ecosystem of Catalonia, promoting new dynamics of collaboration and inspiring new 
public policies; 
● raising the profile of Catalan public and private actors that participate in R&I 
European networks; 
● understanding the contribution of European funds to innovative responses to regional 
priorities, emergent thematics and the Sustainable Development Goals (SDGs). 
Apart from the interactive visualisation tools, RIS3-MCAT provides all its curated and 
enriched data as open data, via dump downloads and via a 5* open data SPARQL Console.  
This has facilitated the elaboration of several complementary policy monitoring as well as 
transversal and thematic analytical reports, published under the “Monitoring RIS3CAT” 
document collection2. 
 
Figure 1: Screenshot from RIS3-MCAT monitoring platform - Network view. 
 
1 Available at: https://ris3mcat.gencat.cat/. 
2 Available at: https://fonseuropeus.gencat.cat/ca/ris3cat/2030/monitoratge/index.html#googtrans(ca|en) 
 
 
 
 
3. A FIVE-YEAR CODESIGN AND DEVELOPMENT PROCESS 
 
As of March 31st, 2023, more than 5,000 unique users from 73 countries have accessed the 
platform, with an average session duration of over 4 minutes. RIS3-MCAT is currently 
undergoing a major redesign, with new functionalities being introduced to facilitate R&I 
portfolio analysis, an essential requirement in the new European programming period (2021-
27). The new version was published in May 2023. This represents a further advancement in a 
comprehensive, ongoing process of co-design, review, evaluation, and iterative development 
that began in 2017, as outlined in the timeline below: 
● 2017: Requirement analysis and feasibility study which focused on data availability and 
quality, as well as prospective front-end and back-end technologies and solutions. 
● 2018: Proof of concept development, based on a wide co-design process within the R&I 
related departments of Generalitat de Catalunya. This led to the first officially published 
live version, with manually classified Horizon Europe and RIS3CAT R&I projects, 
focusing on S3 priority analytics and collaboration networks. 
● 2019-2020: Consolidation of the proof of concept into a fully finished product. 
Development and inclusion of the SDG project classification. First development of an 
analytical report, based on the RIS3CAT taxonomy and an automatic identification of 
main themes via topic modelling (machine learning), to support the decision-making 
around the evolution of the RIS3CAT regional priorities for the new programming 
period. Provision of data for the S3 monitoring official reports. Participatory 
development of thematic analysis in three domains: Circular Bioeconomy, Artificial 
Intelligence, and Plastic Waste Reduction. 
● 2021: Participatory review and requirement analysis with Catalan R&I stakeholders, 
leading to the development of new functionalities. More specifically, supporting the 
identification and analysis of international and inter-regional collaboration and 
improving the bulk download of the underlying data. 
 
 
● 2022-May 2023: Adaptation to RIS3CAT 2021-2030, the new policy framework, by 
automatically reclassifying all projects into the new RIS3CAT regional priorities via 
deep learning classifiers. Major review and redevelopment of the platform, updating the 
front-end technology, and streamlining the design patterns. First integration of an 
emergent classification, the “Topics” based on topic modelling (deep learning). 
Integration of the first Horizon Europe projects. Addition of the “Thematic project 
mapping” platform view, which presents all RIS3MCAT R&I projects in a single 
visualisation, organised by semantic similarity. With this being the first new view 
introduced in the platform since 2018, it opens the door for further possibilities, such as 
purpose-built benchmarking tools or geographical representations on a map. 
 
 
4. TOOL OVERVIEW 
 
4.1. Data sources 
 
CORDIS. Data and metadata related to R&D projects and related organisations which have 
received funding by the European Commission under the H2020 and FP7 framework 
programs. The data are accessible through Open Data licence, and updated monthly, provided 
in the format of CSV, XML and Linked Open data on the CORDIS website. We collect the 
CORDIS records from UNiCS (Giménez, 2018), an open data platform based on semantic 
technologies for science and innovation policies which include data cleaning and improved 
geographical identifications of participants, which are not always correct in the original 
datasets. 
 
SIFECAT. The information system used by Generalitat de Catalunya to manage ERDF 
operation, and the main data source for regionally-managed R&I projects. There is an initial 
manual review and improvement by Generalitat officials, notably in terms of institutional 
naming and geolocalisation, but some transformations have to be derived to fit the data 
integration ontology and the front-end requirements. 
 
4.2. RIS3-MCAT architecture 
 
Data integration & cleaning. CORDIS records and projects funded by the Catalan region and 
ERDF are integrated into different database schemas that are then homogenised into a unified 
structure with a domain ontology3. Access to the data is done through the ontology by means 
of the Virtual Knowledge Graph system Ontop (Calvanese et al., 2017), which translates input 
queries formulated over the ontology into executable queries formulated over the underlying 
database. In order for these different datasets to be integrated properly, the project beneficiaries 
must be given an identifier that homogenises differences in spelling. The goal is that a same 
organisation must have the same identifier, even if its name is written differently in each dataset. 
To this effect, a process of semi-manual disambiguation had been performed by our experts, 
using the OpenRefine tool4. Additionally, for SIFECAT data, each beneficiary had been 
annotated with the corresponding type of organisation. 
 
 
3 Ontology schema available here: https://s3-eu-west-1.amazonaws.com/ontology-documentation-
ris3cat/index.html 
4 https://github.com/OpenRefine/OpenRefine 
 
 
Automatic classification of projects according to the regional priorities. This approach 
allows us to capture “top-down” domains when a deeper understanding of the regional 
dynamics within a specific research area that was previously defined is needed. We took 
advantage of pre-trained language models for training textual classifiers based on title and 
project description, one per each of the seven priority “systems” or areas of application by the 
RIS3CAT 2030 (Generalitat de Catalunya, 2022). A training set was built for each domain and 
annotated based on weak-supervision and active learning paradigms, which allow weak 
annotation of projects from a general sample of R&I projects from both FP7 and H2020 
frameworks based on some of their metadata5. We utilised the tool Argilla (Vila & Aranda, 
2023) for annotation and label improving, which allowed keeping interactive feedback from 
experts to improve label quality. Our best models were based on Specter (Cohan et al., 2020), 
and it was implemented with the Hugging Face Transformers library (Wolf et al., 2020). From 
an evaluation on a sample of 500 Catalan projects, predicted labels were compared with human 
labels from 2 experts, obtaining a macro-averaged f1 of 88.1% of accuracy.  
 
Topic modelling. Topic Modelling (TM) is an unsupervised classification problem in machine 
learning that aims at discovering the unknown topics linked with a specific collection of texts, 
presenting a “bottom-up” picture of the thematics tackled within a specific R&I community. 
This component takes the project title and abstract, encodes the semantic representation of them 
based on the Specter sentence-transformer model (Cohan et al., 2020) which was pre-trained 
on scientific documents, and from clustering vectorial representation of documents based on k-
means, we obtained groups of similar projects. Each document was linked to a cluster, and the 
number of clusters was decided by qualitatively selecting the best trade off between the 
semantic “richness” of the topics and the overall number of topics (in order not to have neither 
too large topics nor too little ones) on different runs. Names of clusters were added manually 
based on keywords frequency and by exploring samples of projects.  
 
Sustainable Development Goals classification (SDGs). We identified SDG-related research 
by using a collection of SDG keywords (a controlled vocabulary) openly available in Zenodo 
(Duran-Silva et al., 2019), based on a hybrid approach that uses automatic methods for 
enriching human-crafted keywords. R&I projects are tagged with VocTagger tool6 on their title 
and project description. 
 
Web front-end. RIS3-MCAT UI and its visualisations were implemented following the W3C 
standards and using a combination of HTML, CSS and JavaScript, also exploiting third-party 
libraries (e.g., the D3.js and React.js libraries). The projects and participants information data 
enrichment was retrieved by querying the SPARQL endpoint. 
 
4.3. RIS3-MCAT features  
 
The RIS3-MCAT front-end is composed of four main parts: navigation bar, main visualisation 
canvas, operations toolbar and statistical modules. Each of the parts is fully reactive to the user 
interactions. The main visualisation canvas has 2 different representations of the data (that can 
be explored by the navigation bar), a collaboration network of institutions, and a semantic 
cartography of projects.  
 
 
5 Taking advantage of: EC Area, ERC Panel, EC programme, Topic, and Field of Study. 
6 https://github.com/sirisacademic/VocTagger 
 
 
Search & Filters. To facilitate data exploration, the platform offers users various filtering and 
search options, allowing them to generate customised visualisations. Initially, the platform 
displays all the integrated data. However, this visualisation can be restricted to subsets of data 
by applying filters and search parameters or by directly manipulating the network. Filtering 
features include search by: keyword, participant name, institution type, year province, 
instrument and programme name, area of action, emerging topic, and SDG.  Search features 
include search by participant and project search based on keyword or text search on title and 
abstract. All filters are multi selection filters, and all filters work in combination with searches 
to allow users to define a set of exploration of interest. 
 
Network analysis. The network of participants shows the collaboration of Catalan R&I actors. 
Each node of the network represents a R&I actor with its legal headquarters in Catalonia, and 
the size of the node is proportional to the volume of the entity's investment in the projects. 
When two entities collaborate on projects, the nodes that represent them are joined with a line. 
The size of this line is proportional to the number of projects they share. Force directed graph 
(network) show the relationships between participants and are defined by the collaborations on 
projects.  
 
Semantic map of projects. The R&I projects are displayed on a 2D canvas, which is organised 
based on the semantic similarity between them. This setup creates a 'topography' of the R&I 
activity, making it easier to identify similar projects. It also provides a visual representation of 
how closely related different themes are, as well as the overlap and connections between 
different classifications. It is a T-SNE dimensionality reduction of the embeddings obtained in 
the topic modelling module, and its clusters and names. 
 
Analytical/Statistical modules. The information modules, presented at the bottom of the tool, 
extend the textual and statistical information of projects and participants and their 
classifications, displaying distributions and relationships. They are reactive to the filtering 
operations. The present types are: summary indicators, rankings of participants, external 
partners, and projects table view. Different project information modules show extended 
information of the projects, and they are available from different parts of the application.  
 
Data download & SPARQL Endpoint. The platform offers the possibility of downloading 
the data filtered interactively as a CSV file, or of making queries about all the data included 
using SPARQL. Data download is available (XLS format) for the current state of the project's 
and participants visualisations as well as the regional partners and international partners in the 
statistical modules. 
 
5. ILLUSTRATIVE USE CASES 
 
We have identified interesting scenarios of use by different target users/actors in the territory, 
with short descriptions for the four illustrative use cases. 
 
● Use case 1: Search by actors and projects in similar topics (search for expertise 
and possible collaborations). Target users for this use case could be R&I 
stakeholders, such as researchers or private companies.  
 
 
Figure 2: Screenshot from RIS3-MCAT monitoring platform - Use case 1  
 
 
 
 
● Use case 2: Collaboration network for the identification of actors within a 
thematic and geographic scope. Target users for this use case could be a R&I policy-
makers, with transversal, or thematic / territorial responsibilities.  
 
Figure 3: Screenshot from RIS3-MCAT monitoring platform - Use case 2  
 
 
● Use case 3: State of research for priority area. This use case allows the study of the 
intersection between the top-down priority area and emerging topics, in order to find 
projects in the “core” of the priority, as well as those that are more 
interdisciplinary/intersectoral. The target user for this could be a leader of a policy or 
an initiative focused on R&I challenges. This person would use systems thinking 
methods to thoroughly investigate and address societal priorities or challenges. We 
can find in the “core” of the priority projects such as “METROFOOD-RI Preparatory 
Phase Project'' or “Connecting the dots to unleash the innovation potential for digital 
transformation of the European agri-food sector”; and, in the periphery, projects like 
“Empowering consumers to PREVENT diet-related diseases through OMICS 
 
 
sciences” in health domain, or “Advanced Multi-Constellation EGNSS Augmentation 
and Monitoring Network and its Application in Precision Agriculture” in satellite 
navigation. Figure 4 captures an example of this use case. 
 
Figure 4: Screenshot from RIS3-MCAT monitoring platform - Use case 3  
 
 
● Use case 4. Collaboration promotion. This use case allows the identification of 
current partners in other countries/regions (and their counterparts in Catalonia) by 
topic. The target users are mainly internationalisation policy-makers. 
 
Figure 5: Screenshot from RIS3-MCAT monitoring platform - Use case 4 
 
 
 
6. LESSONS LEARNED, CONCLUSIONS AND FUTURE WORK 
 
This document presents the RIS3-MCAT mapping and monitoring platform, which has 
tackled the conundrum of monitoring challenge-oriented smart specialisation with available 
technologies and open data. The development has been shaped through a collaborative design 
approach, evolving the methods, techniques, and priority areas of focust to meet the needs of 
policymakers and the strategic and operational demands of quad-helix stakeholders. 
The main technical innovations have been done through the use of artificial intelligence and 
NLP for treating, classifying and semantically enriching large numbers of R&I documents, 
 
 
and the development of interactive exploratory visualisation tools as an entry-point to 
complex and highly-intertwined data-sources.  
 
Some of the key lessons learned during the process, as well as open challenges and 
development opportunities for further consideration are as follows: 
● A successful and enduring co-design process hinges on strategic adaptability, 
consistent and high-quality dialogue between stakeholders and providers, and decisive 
leadership, especially when making bold shifts or redefining project goals. Otherwise, 
the process may remain too close to the initial idea design, and becomes irrelevant or 
outdated in the mid and long term.  
● Although data gathering, integration and enrichment processes can be automated to a 
large degree, a certain amount of manual attention and curation will always be 
necessary. This is due to changes in the policy instruments and data structures, as well 
as fringe cases and mistakes in the data. Incorporating new projects and data sources is 
essential to keep the R&I landscape up to date in the monitoring platform.  
● There is still relevant S3-related publicly-funded R&I activity not in the platform. The 
introduction of additional sets of R&I projects, both funded through open calls and 
through direct public-public agreements, could be an area of focus for future 
development. 
● Apart from the web platform, RIS3-MCAT is an essential source of information for S3 
periodic monitoring reports and other ad-hoc analysis. Nevertheless, although publicly 
accessible the datasets have not been reused beyond the narrow group of RIS3CAT 
related policy-makers and actors. Therefore, re-publishing the data in portals or 
repositories with a wider (international) audience could facilitate uptake by new users 
(notably researchers and policy-officers elsewhere). This would be further enabled by 
better documentation and sharing of the data enrichment methodologies and pipelines.  
● The visualisation and interaction with the Collaboration network and the Semantic 
map of project features, remains challenging for new users, due to the very large 
number of entities and their relationships. New facets, zoom-in features, or simplified 
landing versions could be developed to ease the first impression of complexity. 
● During the short timespan of the project, artificial intelligence and natural language 
processing has advanced very fast, providing new improved tools that have replaced 
manual thematic classification and offered new, useful, fine-grained classification 
systems. Also, new user requirements and visualisation ideas have also emerged. To 
remain relevant in this changing context, monitoring platforms like RIS3-MCAT must 
keep a flexible part of the budget allocation to allow for exploration, testing and 
development of new or improved visualisations, functionalities, and analytics. 
○ Some of the backlog of ideas regarding data visualisation and front-end 
functionalities are: incorporating a geographic map, KPI analytical dashboard, 
European benchmarking tool, and interregional collaboration analysis. 
○ Regarding classification and semantic enrichment, it would be interesting to 
explore new ways of identifying thematic niches and notably, non-thematic 
functional classifications, such as the five dimensions of socio-technical 
systems7 (Geels, 2002; Geels, 2004) which have to be tackled through 
transformative innovation policy. The addition of these new classification 
systems would facilitate a wider range of mapping, monitoring and coalition-
building efforts.  
 
7 These dimensions are: Science, Technology and Infrastructure, Policy and governance, Investment and finance, 
Society and culture, Markets. 
 
 
 
 
Open science practices 
This platform aims at promoting open science policies, allowing the exploration R&I activities 
in the region and encouraging collaboration. Our project itself is based and generates open data, 
and we have made intermediate reports about our codesign and lessons learned, publicly 
available. In our exploration and data integration, we have used open data sources and all data 
generated is available via SPARQL and CSV formats. Additionally, we have used open source 
technologies available on GitHub and the data of the platform is under a CC0 licence. Tye SDG 
vocabularies and VocTagger, partially developed in this context, are available on GitHub and 
Zenodo. Open science practices are crucial to advance R&I, but also public policies. For this 
reason, this article is intended to explain, formalise, and communicate the results, decision, and 
process of this research, so that other actors and regions can benefit in their own initiatives.  
 
Acknowledgments 
Supported by the Industrial Doctorates Plan of the Department of Research and Universities of 
the Generalitat de Catalunya. This work was co-funded by the EU HORIZON SciLake (Grant 
Agreement 101058573). 
 
We acknowledge support of this work by Sergio Martínez (Generalitat de Catalunya), 
Francesco Massucci (SIRIS Academic), Arnau Quinquillà (SIRIS Academic),  Xavi Giménez 
(SIRIS Academic), and Simon Larmour (SIRIS Academic). 
 
Competing interests 
This article is authored by the key responsibles of RIS3MCAT at Generalitat de Catalunya 
alongside its private sector providers (SIRIS Academic). We believe we do not have competing 
interests. 
 
 
References 
Bigas, E., Duran, N., Fuster, E., Parra, C., Cortini, R., Massucci, F., Quinquillà, A., Fernández, 
T., Romagosa, M., & Cortijo, M. (2021). Monitoring smart specialisation with open data and 
semantic 
techniques. 
“RIS3CAT 
Monitoring” 
collection, 
number 
16. 
http://catalunya2020.gencat.cat/web/.content/00_catalunya2020/Documents/angles/fitxers/mo
nitoratge-ris3cat-dades-obertes-tecniques-semantiques-en.pdf 
 
Calvanese, D., Cogrel, B., Komla-Ebri, S., Kontchakov, R., Lanti, D., Rezk, M., ... & Xiao, G. 
(2017). Ontop: Answering SPARQL queries over relational databases. Semantic Web, 8(3), 
471-487. 
 
Cohan, A., Feldman, S., Beltagy, I., Downey, D., & Weld, D. S. (2020). Specter: Document-
level representation learning using citation-informed transformers. arXiv preprint 
arXiv:2004.07180. 
 
Duran-Silva, Nicolau, Fuster, Enric, Massucci, Francesco Alessandro, & Quinquillà, Arnau. 
(2019). A controlled vocabulary defining the semantic perimeter of Sustainable Development 
Goals (1.2) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3567769 
 
European Commission. (2014).  Research Innovation Strategies for Smart Specialisation. 
Cohesion 
Policy. 
 
 
https://ec.europa.eu/regional_policy/sources/docgener/informat/2014/smart_specialisation_en.
pdf 
 
European Commission. (2016). Open innovation, open science, open to the world: a vision for 
Europe, Publications Office. European Commission, Directorate-General for Research and 
Innovation. 
 
European Commission. (2019). The European green deal. Eur. Comm., 53(9), 24. 
 
European Commission (2021). Horizon Europe.  
https://op.europa.eu/en/publication-detail/-/publication/3c6ffd74-8ac3-11eb-b85c-
01aa75ed71a1 
 
Fuster, E., Marinelli, E., Plaud, S., Quinquilla, A., & Massucci, F. (2020). Open Data, Open 
Science and Open Innovation for Smart Specialisation monitoring, EUR 30089 EN, 
Publications Office of the European Union, Luxembourg, 2020, ISBN 978-92-76-10726-2, 
doi:10.2760/55098, 
JRC119687. 
https://publications.jrc.ec.europa.eu/repository/handle/JRC119687 
 
Fuster, E., Massucci, F., & Matusiak, M. (2020). Identifying specialisation domains beyond 
taxonomies: mapping scientific and technological domains of specialisation via semantic 
analyses. In R. Capello, A. Kleibrink, & M. Matusiak (Eds.), Quantitative Methods for Place-
Based In-novation Policy (pp. 195–234). 
 
Geels, F. W. (2002). Technological transitions as evolutionary reconfiguration processes: A 
multi-level perspective and a case-study. Research Policy, 31(8–9), 1257–1274. 
https://doi.org/10.1016/S0048-7333(02)00062-8 
 
Geels, F. W. (2004). From sectoral systems of innovation to socio-technical systems: Insights 
about dynamics and change from sociology and institutional theory. Research Policy, 33(6–7), 
897–920. https://doi.org/10.1016/j.respol.2004.01.015 
 
Generalitat de Catalunya. (2022). RIS3CAT 2030: Strategy for the Smart Specialisation of 
Catalonia 
2030. 
https://fonseuropeus.gencat.cat/web/.content/ris3cat/documents/angles/ris3cat-2030-en.pdf 
 
Gimenez, X., Mosca, A., Roda, F., Rondelli, B., & Rull, G. (2018). UNiCS: The open data 
platform for Research and Innovation?. In Proceedings of the Posters and Demos Track of the 
14th International Conference on Semantic Systemsco-located with the 14th International 
Conference on Semantic Systems (SEMANTiCS 2018) (Vol. 2198). CEUR-WS. 
 
United Nations (2019). Global indicator framework for the sustainable development goals and 
targets of the 2030 agenda for sustainable development. Developmental Science and 
Sustainable Development Goals for Children and Youth, 439. 
 
Vila, D., Aranda, F. (2023). Argilla - Open-source framework for data-centric NLP (Version 
1.2.0) [Computer software]. https://github.com/argilla-io/argilla 
 
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Ma, C., Jernite, 
Y., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., & Rush, A. M. (2020). 
 
 
Transformers: State-of-the-Art Natural Language Processing [Conference paper]. 38–45. 
https://www.aclweb.org/anthology/2020.emnlp-demos.6 
 
"
"Safety incidents in AI systems diverge from expectations, revealing a socio-technical complexity. Accidents result from poor engineering, unclear safety measures, and stakeholder influence failures rather than technological malfunctions. An expanded socio-technical perspective is necessary.nan","The widespread adoption of AI systems has led to various failures, highlighting the need for AI safety research. A variety of communities are delving into AI safety, aiming to understand and address risks in ML systems. However, few studies have grounded their analysis on real-world deployments and disasters.nan","Prior work has focused on taxonomizing AI safety issues and exploring theoretical approaches, such as control theory and formal methods. While these formalizations capture aspects of the encountered problems, they may overlook vital real-world dimensions. Existing frameworks present challenges in understanding how AI systems and safety mechanisms succeed or fail in practice.nannan","The study revisits a commonly cited taxonomy of AI safety issues by Amodei et al. (2016). The authors surveyed 170 papers to identify a subset of concrete AI Safety problems and analyzed real-world use cases for three specific problems: Safe Exploration, Avoiding Negative Side Effects, and Scalable Oversight.nan","The analysis revealed themes and insights that diverge from existing taxonomies. The authors emphasize failures rooted in engineering practice beyond theoretical design flaws. They advocate for validation of safety problems through inductive reasoning, considering real-world case studies to refine AI safety mechanisms. Additionally, the study stresses the significance of stakeholder impact and interactions, highlighting the need for broad deliberation and input in determining accident causes.nan","Failures in AI systems exhibit a socio-technical complexity that extends beyond technological malfunctions or formal design flaws. The prevalent view focuses on the developer's control over technical aspects, overlooking the systematic nature of failures influenced by interactions with users and stakeholders. Safety mechanisms are found to be ineffective due to broader socio-technical factors, requiring a socio-technical framing that acknowledges power structures and stakeholder involvement.nan","Concrete Problems in AI Safety, Revisited","Inioluwa Deborah Raji, Roel Dobbe","arXiv:2401.10899v1  [cs.CY]  18 Dec 2023
Published as a conference paper at ICLR 2020
CONCRETE PROBLEMS IN AI SAFETY, REVISITED
Inioluwa Deborah Raji & Roel Dobbe
AI Now Institute
New York University
New York City, NY, USA
{deb,roel}@ainowinstitute.org
ABSTRACT
As AI systems proliferate in society, the AI community is increasingly preoc-
cupied with the concept of AI Safety, namely the prevention of failures due to
accidents that arise from an unanticipated departure of a system’s behavior from
designer intent in AI deployment. We demonstrate through an analysis of real
world cases of such incidents that although current vocabulary captures a range
of the encountered issues of AI deployment, an expanded socio-technical fram-
ing will be required for a more complete understanding of how AI systems and
implemented safety mechanisms fail and succeed in real life.
1
INTRODUCTION
The rapid adoption and widespread experimentation and deployment of AI systems has triggered a
variety of failures. Some are catastrophic and visible such as in the case of fatal crashes involving
autonomous vehicles. Other failures are much more subtle and pernicious, such as the development
of new forms of addiction to personalized content. As a response to these safety concerns, a variety
of research communities from control theory and formal methods (Fisac et al., 2018; Seshia et al.,
2016), computer security (Carlini et al., 2019; Papernot et al., 2018), engineering for safety assur-
ances (Fang & Johnson, 2019; Trapp & Wei, 2019), and within the AI ﬁeld itself (Amodei et al.,
2016; Leike et al., 2017b; Varshney, 2016) have begun to weigh in on how to characterize and ad-
dress safety risks and vulnerabilities in AI systems. Despite the complexity of modern AI systems
and their already widespread impact, few studies are yet to ground their analysis of the taxonomy of
problems in an understanding of real world deployments and disasters.
The goal of this study is to revisit the effectiveness of AI safety problem formulations in providing
adequate vocabulary for characterising the key challenges of implementing safe AI systems in the
real world. This workshop paper is an initial investigation into ongoing work on this topic.
2
METHODOLOGY
In this paper, we go through a commonly cited taxonomy for AI safety by Amodei et al. (2016), who
survey and taxonimize a body of 170 papers to propose a subset of concrete AI Safety problems to
pay attention to, aiming to understand “what challenges remain to reducing accident risk in modern
machine learning systems”. In this context, an accident is deﬁned as “a situation where a human
designer had in mind a certain (perhaps informally speciﬁed) objective or task, but the system that
was designed and deployed for that task produced harmful and unexpected results.” The authors
then propose to “categorize safety problems according to where in the [technical AI design] process
things went wrong.”
We re-examine the provided deﬁnitions of three concrete problems from the taxonomy presented
by Amodei et al., and identify a real world use case that ﬁts the provided descriptions of the safety
risk. We then diagnose the nature of the challenges in the real world, paying particular attention to
dimensions of the issue that current frameworks do not adequately address.
1
Published as a conference paper at ICLR 2020
SAFE EXPLORATION
Safe exploration is the minimization of undesirable behaviour or harm arising from the learning pro-
cess of an algorithm. For instance, during the training process of a machine learning model or while
accumulating training examples or exploring a reinforcement learning environment (Amodei et al.,
2016; Pecka & Svoboda, 2014). Autonomous exploration is often complicated by the unpredictable
nature of human behavior, which may amount to a prematurely deployed system with no sensible
safety guarantees. Exploration risks are thus on par with that of untested systems released in the
wild - and the justiﬁcation for taking such risk is itself an ethical dilemma (Bird et al., 2016).
A clear example of this phenomenon can be observed with the development of autonomous vehi-
cles. Self-driving vehicle companies boast in safety reports and in marketing material about the
use of data from a ﬂeet of deployed vehicles to ﬁne-tune their algorithms. Some providers, such as
Tesla, harness the power of their client vehicles, taking data from sold cars to train new models and
then release synchronous updates for improved navigation in all vehicles (Tesla, 2019). Others, in a
more experimental phase of development, such as Uber, hire test drivers to log thousands of miles,
collecting data for developing models and designing new algorithms for future deployment in sold
vehicles (Uber, 2019). In both cases, the safety risk of such explorations is clear - testing a car in
the public sphere is inherently dangerous, risking the lives of pedestrians and fellow drivers in order
to collect the data used to develop navigation systems. While on a test drive, an Uber autonomous
vehicle killed a woman in Tempe, Arizona, on March 18, 2018 (NTSB 2018). Similarly, the autopi-
lot feature of the Tesla Model S (NTSB 2017a) caused a fatal crash on May 7, 2016, near Williston,
Florida. Public facing journalistic reporting on these incidents focused on the particularities of the
engineering failures that led to these fatal crashes - Uber’s algorithm did not identify the pedestrian
crossing outside a crosswalk, and Tesla’s system did not distinguish between the sky and the white
side of the truck it crashed into. However, these products were effectively in public beta-testing.
They were expected to fail. It was thus not these failures directly, but the lack of adequate safety
measures that was ultimately the focus of what the National Transportation Safety Board (NTSB)
declared as the probable cause of the accidents in both cases.
At ﬁrst glance, the case of Uber ressembles the scenario of “absent supervision” (Leike et al.,
2017a). As the operator was visually distracted throughout the trip by a personal cell phone, it
seems as though the primary issue could be a lack of contingency planning for situations where the
driver was “absent”, ie. not in a position to intervene or react as expected to correct for a technical
failure. However, in reality, the NTSB found that Uber ATG did have such an oversight functionality
in place. Managers “had the ability to retroactively monitor the behavior of vehicle operators”, and
notify them when they perceived a need to react. However, “they rarely did so”, leading the NTSB
to declare the ofﬁcial cause of the accident to be the company’s “inadequate safety culture”, which
normalized the casual treatment and ultimate neglect of much of the nominally established safety
protocol (NTSB 2019).
The Tesla case reveals a similar situation. According to the NTSB report, at the time of the crash,
the vehicle could not “recognize the impending crash. Therefore, the system did not slow the car,
the forward collision warning system did not provide an alert, and the automatic emergency brak-
ing did not activate” (NTSB 2017b). Thus, the car would not stop until the driver overrode the
system to stop - a safety mechanism understood as “safe interruptibility” (Orseau & Armstrong,
2016). However, as NTSB reported, despite the driver’s ability to interrupt the system effectively,
once within range of fatal risk, the bewildered and terriﬁed driver was not prepared to take any
action at all. ”Overreliance on Automation” was thus named amongst the key causes for the acci-
dent (NTSB 2017b) as ”the way in which the Tesla ’Autopilot’ system monitored and responded
to the driver’s interaction with the steering wheel was not an effective method of ensuring driver
engagement” (NTSB 2017b). This is a well-studied phenomenon in autopilots and human-machine
interaction (Parasuraman & Riley, 1997) - when the limits of the system are not clearly communi-
cated, it can become difﬁcult for the human to understand when they are more qualiﬁed than the
algorithm to make a decision, and remain alert to any changes to their role in decision making.
“Tesla driver’s pattern of use of the Autopilot system indicated an over-reliance on the automation
and a lack of understanding of the system limitations” (NTSB 2017a).
In both cases, it was thus a lack of stakeholder engagement with the safety feature, rather than the
technical function of the safety feature itself that were deemed primary causes of the accidents.
2
Published as a conference paper at ICLR 2020
AVOIDING NEGATIVE SIDE EFFECTS
At times, an AI system can cause unintentional and unknown side effects. These are often de-
scribed as phenomena that are unanticipated indirect results of the algorithmic system’s deploy-
ment, most speciﬁcally the unintended consequences of an agent’s actions within a speciﬁc environ-
ment (Amodei et al., 2016).
Sometimes the reward beneﬁcial to the actor creating and deploying the algorithm is inherently
harmful to another population.
This is complementary to the view of side effects as “exter-
nalities” inherently detrimental to other stakeholders within what is truly a multi-agent system
(Overdorf et al., 2018; Amodei et al., 2016). However, reality reveals the inherent power imbal-
ance between modeled agents. Those with control of the system - and likely greater social and
ﬁnancial capital - can thus dictate the values and priorities of the systems they choose to build, at
times in knowing direct opposition to the well-being of other, less inﬂuential actors. For instance,
a class action lawsuit “Doe v. Netﬂix” reveals the tension between an exposure of private personal
records and the improved accuracy of the platform’s recommendation engine through the Netﬂix
Prize (Singel, 2009). As video records are actually amongst the most protected personal records in
the United States, there was legal recourse to make such a case against corporate interests to protect
the potential harm to subscribers (Singel, 2010). Without such legal responsibility, however, it is
unclear if, given the advances in accuracy and product quality (Gomez-Uribe & Hunt, 2015), the
company would have been as willing to compromise, despite the clear threats to consumer privacy
(Calandrino et al., 2011; Narayanan & Shmatikov, 2006). For instance, other platform issues in-
volving less legal repercussion - such as screen addiction, especially amongst impressionable youth
(Matrix, 2014) - have yet to meaningfully inﬂuence corporate decision-making.
Additionally, unlike the focus of the current framing, it is not just the actions of an AI agent that
can produce side effects. In real life, basic design choices involved in model creation and deploy-
ment processes also have consequences that reach far beyond the impact that a single model’s de-
cision can have. In reality, for AI systems to even be built, there is very often a hidden human cost
(Gray & Suri, 2019; Birhane & van Dijk, 2020). These harms of production are not emergent harms
from the training process, as we see with safe exploration, but rather a byproduct of the resource
requirements for the creation of a model. Data requirements, compute requirements, API model
delivery decisions can all invite certain harms to privacy, sustainability and corporate accountability.
For example, deep learning approaches to facial recognition requires by design widespread privacy
violations (Raji et al., 2020), as millions of faces - which under ISO standards are considered sen-
sitive identiﬁable biometric information - are required for satisfactory training and testing of the
models. Similarly, poorly paid and trained annotators are often exploited for the sake of doing
the mundane work of labeling large amounts of at times sensitive and graphic data (Gray & Suri,
2019). Our training and testing environments for models intended for real world deployment is of-
ten the byproduct of human exploitation - whether through direct labour or by harvesting our data
footprints. Similarly, such large scale data storage and compute costs from the current trend of AI
development invites climate abuse (Strubell et al., 2019; Schwartz et al., 2019; Dodge et al., 2019),
a natural crisis also disproportionately impacting the often lower income and thus most neglected
humans in society.
There is thus a need to consider the power dynamics at play in the development and deployment of
these systems and begin to deﬁne the value tradeoffs that ultimately determine a system’s outcomes
and broader implications, beyond the context of an assumption of benevolent designer intent.
SCALABLE OVERSIGHT
Scalable oversight refers to situations in which a safety risk is so infrequent, or the objective function
so nebulous, that it becomes too expensive to evaluate frequently (Amodei et al., 2016). In AI for
healthcare, a heavily regulated safety-critical domain, the real world context is often hard to access.
This motivates technologists to design and train the system using proxy or simulated objectives that
may overlook or fail to adequately represent contextual factors. For instance, an internal investiga-
tion by the University of Texas M. D. Anderson Cancer Center in Houston found the IBM Watson’s
Oncology Expert Advisor tool, into which they had invested $62 million over 5 years, to fall short of
the “gold standard” of medicine (The University of Texas System Administration, 2016). Unable to
access patient records due to health privacy laws, Watson diagnosis and treatment recommendations
3
Published as a conference paper at ICLR 2020
are informed from ofﬁcial medical guidelines and peer-reviewed studies from academic medical
journals - rather than patient records of experience.
As a result, not only was the system often too general to be helpful in clinical practice, but the
system was unable to adapt to new clinical situations in a way that put patients at risk of lower
quality care. For instance, the 2018 breakthrough discovery of a dramatically effective new “tissue
agnostic” cancer drug for cancer tumors containing a speciﬁc genetic mutation led to the drug’s
release being fast tracked. It was subsequently approved by the FDA with only results available in
55 patients, 4 of whom had lung cancer. Following the ﬁnding, all prior guidelines for lung cancer
treatments were revised, now with an emphasis on testing for the genetic mutation that may qualify
patients for the novel treatment. However, by virtue of the nature of its machine learning system,
IBM Watson would not change its predictions based on these four patient cases (Strickland, 2019).
As a result, the program shut down without any physicians having the conﬁdence to use the tool on
actual patients (Schmidt, 2017).
Resorting to proxies or synthetic data comes with its own assumptions and risks which should be
carefully accounted for in safety-critical environments. Alternatively, one could acknowledge that
certain use cases are more suitable to the method of machine learning and others are more unsafe
and volatile when addressed using this method. Within IBM Watson for Healthcare, the IBM for Ge-
nomics project provides such an example (Strickland, 2019). Genetic information is structured and
consistently recorded yet unique to each patient - the goal of needing an aid for pattern recognition
on large amounts of structured data ﬁts the paradigms and assumptions under which ML systems
are trained and tested. As a result, this has been the most successful Watson launch to date.
3
RECURRING THEMES IN REAL WORLD SAFETY FAILURES
Throughout the various case studies and analyses in the previous section, a set of themes surfaced.
These themes are offered for discussion to inspire future work.
(1) We must consider errors in engineering practice, not just ﬂaws in theoretical design or
formalization. Any theoretical AI system will need to be implemented in some way to have an
impact on the real world. At times, it is the mistakes made in the process of its implementation
that may lead to an accident. The reality of the engineering processes - including task design,
speciﬁcation, construction, validation, integration and maintenance - that arise in practice are often
neglected in current explorations of AI safety, even though this is when safety problems are often
most pronounced and best addressed.
(2) We need to validate safety problems through inductive reasoning. A theoretical or specula-
tive model can only go so far in representing a problem adequately. Properly safeguarding a system
requires mechanisms that are developed inductively through ongoing validation within the context
of real world case studies. Otherwise, failures will arise from the misrepresentation of the extent
and nature of engineering decision-making or the inﬂuence of stakeholder participation.
(3) We must consider broader stakeholder impact and interactions, not just alignment with
technical design intent when considering accidents. AI systems mediating sensitive domains and
public spaces require broad deliberation and corroboration of safety requirements across different
stakeholders, rather then being decided by a small group of developers and entrepreneurs. This
requires a socio-technical framing that is cognizant of power structures, and provides meaningful
forms of dissent across affected communities.
4
CONCLUSION
These case studies demonstrate that the failure of an AI system in the real world can differ signif-
icantly from the expectations set by our own taxonomies of what it means for an AI system to be
safe. All too often the focus of AI safety is on the developer’s control - over the reward function,
the training circumstances and the agent’s impact in a given environment. However, in the real
world, failures take on a new dimension of complexity and reveal themselves to be inherently sys-
tematic rather than contained within any technological artifact. The reported cause of many of these
cases are hardly ever attributed to a technological malfunction but rather a network of ineffective
socio-technical interactions with users and other stakeholders.
4
Published as a conference paper at ICLR 2020
REFERENCES
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan
Man´e.
Concrete Problems in AI Safety.
arXiv:1606.06565 [cs], June 2016.
URL
http://arxiv.org/abs/1606.06565. arXiv: 1606.06565.
Sarah Bird, Solon Barocas, Kate Crawford, Fernando Diaz, and Hanna Wallach.
Exploring or
exploiting? social and ethical implications of autonomous experimentation in ai. In Workshop on
Fairness, Accountability, and Transparency in Machine Learning, 2016.
Abeba Birhane and Jelle van Dijk. Robot rights? let’s talk about human welfare instead. arXiv
preprint arXiv:2001.05046, 2020.
National
Transportation
Safety
Board.
Collision
between
a
car
operating
with
au-
tomated
vehicle
control
systems
and
a
tractor-semitrailer
truck,
2017a.
URL
https://ntsb.gov/investigations/Pages/HWY18FH010.aspx.
National
Transportation
Safety
Board.
Driver
errors,
overreliance
on
au-
tomation,
lack
of
safeguards,
led
to
fatal
tesla
crash,
2017b.
URL
https://www.ntsb.gov/news/press-releases/pages/pr20170912.aspx.
National
Transportation
Safety
Board.
Collision
between
vehicle
controlled
by
developmental
automated
driving
system
and
pedestrian,
2018.
URL
https://ntsb.gov/investigations/Pages/HWY18FH010.aspx.
Joseph A Calandrino, Ann Kilzer, Arvind Narayanan, Edward W Felten, and Vitaly Shmatikov. ”
you might also like:” privacy risks of collaborative ﬁltering. In 2011 IEEE symposium on security
and privacy, pp. 231–246. IEEE, 2011.
Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris
Tsipras, Ian Goodfellow, and Aleksander Madry. On evaluating adversarial robustness. arXiv
preprint arXiv:1902.06705, 2019.
Jesse Dodge, Suchin Gururangan, Dallas Card, Roy Schwartz, and Noah A Smith. Show your work:
Improved reporting of experimental results. arXiv preprint arXiv:1909.03004, 2019.
Xinwei Fang and Nikita Johnson. Three Reasons Why: Framing the Challenges of Assuring AI. In
Alexander Romanovsky, Elena Troubitsyna, Ilir Gashi, Erwin Schoitsch, and Friedemann Bitsch
(eds.), Computer Safety, Reliability, and Security, Lecture Notes in Computer Science, pp. 281–
287, Cham, 2019. Springer International Publishing. ISBN 978-3-030-26250-1. doi: 10.1007/
978-3-030-26250-1 22.
Jaime F. Fisac, Anayo K. Akametalu, Melanie N. Zeilinger, Shahab Kaynama, Jeremy Gillula, and
Claire J. Tomlin. A general safety framework for learning-based control in uncertain robotic
systems. IEEE Transactions on Automatic Control, 64(7):2737–2752, 2018.
Carlos A Gomez-Uribe and Neil Hunt. The netﬂix recommender system: Algorithms, business
value, and innovation. ACM Transactions on Management Information Systems (TMIS), 6(4):
1–19, 2015.
Mary L Gray and Siddharth Suri. Ghost Work: How to Stop Silicon Valley from Building a New
Global Underclass. Eamon Dolan Books, 2019.
Jan Leike, Miljan Martic, Victoria Krakovna, Pedro A Ortega, Tom Everitt, Andrew Lefrancq, Lau-
rent Orseau, and Shane Legg. Ai safety gridworlds. arXiv preprint arXiv:1711.09883, 2017a.
Jan Leike, Miljan Martic, Victoria Krakovna, Pedro A. Ortega, Tom Everitt, Andrew Lefrancq,
Laurent Orseau, and Shane Legg.
AI Safety Gridworlds.
November 2017b.
URL
https://arxiv.org/abs/1711.09883.
Sidneyeve Matrix. The netﬂix effect: Teens, binge watching, and on-demand digital media trends.
Jeunesse: Young People, Texts, Cultures, 6(1):119–138, 2014.
5
Published as a conference paper at ICLR 2020
Arvind Narayanan and Vitaly Shmatikov. How to break anonymity of the netﬂix prize dataset. arXiv
preprint cs/0610105, 2006.
Laurent Orseau and MS Armstrong. Safely interruptible agents. 2016.
Rebekah Overdorf, Bogdan Kulynych, Ero Balsa, Carmela Troncoso, and Seda G¨urses. Pots: Pro-
tective optimization technologies. arXiv preprint arXiv:1806.02711, 2018.
Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael P. Wellman. SoK: Security and
privacy in machine learning. In 2018 IEEE European Symposium on Security and Privacy (Eu-
roS&P), pp. 399–414. IEEE, 2018.
Raja Parasuraman and Victor Riley. Humans and automation: Use, misuse, disuse, abuse. Human
factors, 39(2):230–253, 1997.
Martin Pecka and Tomas Svoboda.
Safe exploration techniques for reinforcement learning–an
overview. In International Workshop on Modelling and Simulation for Autonomous Systems,
pp. 357–375. Springer, 2014.
Inioluwa Deborah Raji, Timnit Gebru, Margaret Mitchell, Joy Buolamwini, Joonseok Lee, and
Emily Denton. Saving face: Investigating the ethical concerns of facial recognition auditing.
arXiv preprint arXiv:2001.00964, 2020.
Charlie Schmidt. Md anderson breaks with ibm watson, raising questions about artiﬁcial intelligence
in oncology. JNCI: Journal of the National Cancer Institute, 109(5), 2017.
Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni.
Green ai.
arXiv preprint
arXiv:1907.10597, 2019.
Sanjit A. Seshia, Dorsa Sadigh, and S. Shankar Sastry. Towards veriﬁed artiﬁcial intelligence. arXiv
preprint arXiv:1606.08514, 2016.
Ryan Singel. Netﬂix spilled your brokeback mountain secret, lawsuit claims. Threat Level (blog),
Wired, 2009.
Ryan Singel. Netﬂix cancels recommendation contest after privacy lawsuit. Retrieved March, 29:
2018, 2010.
Eliza Strickland. Ibm watson, heal thyself: How ibm overpromised and underdelivered on ai health
care. IEEE Spectrum, 56(4):24–31, 2019.
Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy considerations for deep
learning in nlp. arXiv preprint arXiv:1906.02243, 2019.
Inc. Tesla. Tesla vehicle safety report. https://www.tesla.com/VehicleSafetyReport,
2019.
The University of Texas System Administration. Special review of procurement procedures related
to the m.d. anderson cancer center oncology expert advisor project, 2016.
Mario Trapp and Gereon Wei. Towards Dynamic Safety Management for Autonomous Systems. In
Engineering Safe Autonomy, pp. 193–204, 2019. ISBN 978-1-72936-176-4.
Inc. Uber. Uber atg safety report. https://www.uber.com/us/en/atg/safety/, 2019.
Kush R. Varshney. Engineering Safety in Machine Learning. arXiv:1601.04126 [cs, stat], January
2016. URL http://arxiv.org/abs/1601.04126. arXiv: 1601.04126.
Eric Weiss.
‘inadequate safety culture’ contributed to uber automated test vehicle crash - ntsb
calls for federal review process for automated vehicle testing on public roads, 2019.
URL
https://www.ntsb.gov/news/press-releases/Pages/NR20191119c.aspx.
6
"
"Foundation models offer a new opportunity to redesign systems and workflows with an AI-first perspective. However, operationalizing this opportunity faces challenges and trade-offs. This article provides an organizational framework for making rational choices as enterprises embark on their transformation journey towards an AI-first organization.nan","The advent of AI technology, particularly foundation models, presents an unprecedented opportunity for enterprises to reimagine their operations and processes. However, realizing this potential requires addressing various challenges and trade-offs. This article aims to provide an organizational framework that guides enterprises in making informed choices as they navigate their transformation towards an AI-first approach.nan","The literature review acknowledges the limited historical moments when societal functions could be reimagined. It emphasizes the transformative potential of AI, citing Microsoft CEO Satya Nadella's insights into the company's AI strategy and the importance of a holistic, disciplined approach to AI adoption to avoid potential pitfalls.nannan",The methodology section outlines the approach taken to develop the proposed organizational framework. It highlights the focus on invariant factors that are less prone to rapid changes in the field of AI. This approach aims to provide guidance that remains relevant despite the evolving nature of AI technology.nan,"The results section presents the anticipated future state of AI technology, characterized by intelligence as a service (IQaaS). It envisions a scenario where intelligence becomes a readily accessible, frictionless commodity, similar to electricity. This future state is expected to be driven by the continuous evolution of AI models, with capabilities progressing from weak AI to strong AI and eventually integrating with robotics. Data plays a pivotal role in shaping this trajectory, with the emergence of synthetic data as a dominant content source.nan","The conclusion section emphasizes the significance of AI as a major entry in the modern computing stack. It underscores the need for a holistic, intentional, and informed approach to AI adoption, emphasizing the importance of team composition, data management, evaluation, transparency, and security. The article acknowledges the transformative potential of generative AI but stresses the necessity of a well-rounded strategy to mitigate risks and ensure successful enterprise transformations.nan",Transformations in the Time of The Transformer,"Peyman Faratin, Ray Garcia, Jacomo Corbo","Transformations in the Time of The Transformer
Peyman Faratin1,2
Ray Garcia3
Jacomo Corbo4
1MIT, 2Robust Links, 3Buoyant Capital, 4PhysicsX
peyman@mit.edu, ray@bcap.biz, jacomo@physicsx.ai
Abstract
Foundation models offer a new opportunity to redesign existing systems and workflows
with a new AI first perspective. However, operationalizing this opportunity faces several
challenges and tradeoffs. The goal of this article is to offer an organizational framework for
making rational choices as enterprises start their transformation journey towards an AI first
organization. The choices provided are holistic, intentional and informed while avoiding
distractions. The field may appear to be moving fast, but there are core fundamental factors
that are relatively more slow moving. We focus on these invariant factors to build the logic
of the argument.
Introduction
There are few moments in history where the chance to reimagine how we function as society presented
itself. From agriculture to mobile revolution we have harnessed technologies to redefine ourselves and our
environment. Artificial Intelligence (AI) is the latest such force that is enabling us to reimagine again, this
time through a new lens of intelligence and adaptation, with profound effects. Flashes of those futures are
already manifesting themselves. For instance, in Microsoft’s Fiscal year 2024 first quarter earnings
call CEO Satya Nadella, when discussing the architecture of Azure cloud services, provided the
following insight into what we will refer to as a new AI first enterprise [3]:
“It is true that the approach we have taken is a full stack approach all the way from whether it’s ChatGPT
or Bing Chat or all our Copilots, all share the same model. So in some sense, one of the things that we do
have is very, very high leverage of the one model that we used, which we trained, and then the one model
that we are doing inferencing at scale.” He then goes on to say:
“The lesson learned from the cloud side is — we’re not running a conglomerate of different businesses,
it’s all one tech stack up and down Microsoft’s portfolio, And that, I think, is going to be very important,
because that discipline, given what the spend will look like for this AI transition, any business that’s
not disciplined about their capital spent accruing across all their businesses could run into trouble.“
The goal of this article is to offer an organizational framework to make rational choices as enterprises
start their transformation to an AI first enterprise journey, choices that are holistic, intentional and
informed while avoiding distractions. We begin by elaborating on an anticipated future state of AI
technology, and then justify this future state by describing the necessary evolutionary path AI will take to
this end state. Along the way we will review the core technology (Foundation Models, the “one large
model” referenced by Nadella in the narrative above), and set the context and the strategic levers AI
affords. Finally, we use this framework to provide strategic and operational AI transformation guidelines
in locksteps with the anticipated development.
The Future: Intelligence as a Service (IQaaS)
We believe intelligence will no longer be a scarce good, and will increase in quality and quantity.
Intelligence will consist of two goods: that of human level intelligence and a machine generated
“super-intelligence”, where the latter is defined as new knowledge provisioned autonomously by AI. The
AI knowledge will not come from data but through mechanisms such as “self-play”, where AI learns new
knowledge from many simulations over synthetically generated data.1 Self-play requires very well defined
domains (like board games or video games), thus we expect the supply of the super-intelligence will be
constrained to a finite number of domains.
In the future we expect highly capable vertically integrated and closed AI platform providers to compete
with one another and with less capable but more open AI platform providers. The competition will be
based on costs, data, compute, speed and quality in organized segmented markets. This good will be
generated either monolithically, where a single AI provides all information, or by collaboration provided
by many federated intelligent systems. Furthermore, this future will enable instantaneous and effortless
access to all forms of human and AI intelligence via natural multimodal interfaces, much like electricity
that can be accessed across time and space. Enterprises and individuals can simply plugin to this good
without building costly special purpose access or application artifacts. Like energy, the supply network
will organize itself in a manner that provides frictionless access to intelligence, anywhere, anyhow and
any time, all via universal interfaces. As Altman (CEO of OpenAI) comments:
“Right now, people [say] ‘you have this research lab, you have this API, you have the partnership with
Microsoft, you have this ChatGPT thing, now there is a GPT store’. But those aren’t really our products,”
Altman said. “Those are channels into our one single product, which is intelligence, magic intelligence in
the sky. I think that’s what we’re about.” Sam Altman (“OpenAI chief seeks new Microsoft funds to build
‘superintelligence’”, Financial Times, 2023).
We next describe the context and features of this emerging technology and then use this context to
describe the potential evolutionary path of the technology to this future end state.
Foundation Models
Foundational Models (FMs), such as Large Language Models (LLMs) and Diffusion Models (DMs) so
called to “underscore their critically central yet incomplete character” [1], are ushering in a cambrian
moment in AI, a technology that is positioned to become a key entry in modern computing stack, indeed
some would argue emergence of an new AI Operating System (AIOS). The core technology of FMs is a
neural network called the Transformer [9] that efficiently parallelizes the fundamental vector-matrix
operations of a neural network on dedicated hardware such as GPUs. To understand the impact of this
technology, we describe the key features of the ecosystem and technology that form the macro context of
the FM ecosystem.
1 We witnessed a glimpse of this in 2016 where the world Go champion Sedol competed against AlphaGo, the AI
from Google’s Deepmind. AlphaGo played a very unusual move on move 37 that clearly rattled Sedol who left the
room for 15 minutes.
Context
There are two contextual backgrounds to address before discussing the future state. Firstly, we call who
does what functionality, where in the value chain the system architecture; this architecture induces the
stakeholders and their industrial organization in the marketplace. The system architecture of AI is
currently in transition, being negotiated in the market. We will elaborate on this evolution next. The
stakeholders that are emerging in the FM value chain includes:
●
Consumers (Enterprise and Retail)
●
Developers
●
FM platform Providers (OpenAI, Google, Anthropic, Cohere, Meta, Mistral, …)
●
Data Providers (open Internet)
●
Infrastructure as a Service (IaaS) Providers (Azure/GCP/AWS)
●
Hardware Providers (NVIDIA, Intel, ARM, AWS,...)
At the time of writing of this article there are approximately nine FM platform providers, entities that
train and maintain FMs (OpenAI/Microsoft, Google, Meta, Cohere, Inflection, Anthropic, Amazon,
Cohere, Mistral), each with different idiosyncrasies whose treatment will extend this article unnecessarily.
Our discussion is therefore an abstraction of all FMs, acknowledging some details may be invalidated by
one or more individual FM at different times. We also abstract from the core technology that is driving the
current generation of FMs (the Transformer [9]), without loss of the validity of our arguments, because
mechanism of how intelligence is created affects the path, not the final state of the field, similar to how
energy is generated is independent of its usage. Therefore, if Transformers are replaced by another
substitutable technology that is not vector-matrix based, then we expect only the physical infrastructure
layer and not the application layer will be disrupted. Additionally, we expect the term “foundational”
itself will be a subject to debate as the technology evolves from its current state to one that is, as we
predict, much more integrated with higher level capabilities, making the demarcation of foundational
from non-foundational less clear.
Secondly, there are several primary factors that modulate FM development dynamics:
●
Labor: The labor market for scientists and engineers that can build and train FMs is very thin
(anecdotally, estimated at around hundred fifty people). See [11] for logs of Meta’s attempt to
train a 175 billion LLM, demonstrating the engineering complexities.
●
Data: FMs are programmed using very large scaled multi-modal data. It is informative that
(neither closed nor open) FM model providers open source their training data.
●
Training: FMs are rather simple artifacts made up of layers of neural networks with relatively
simple training conducted over two regimes: 1) pretraining, where the model learns to understand
and compress very large amount of potentially low quality data in self-supervised manner,
without any human involvement, and 2) alignment, where the FM is aligned to perform
capabilities the designer wishes through either supervision using small amount of high quality
training data and optionally through reinforcement learning using comparison data. Whereas
pretraining is very costly and performed at low cadence by few entities with the capital and
know-how, alignment is cheap and can be conducted regularly with less resources.
●
Evaluation: FMs are currently not an engineering artifact. Unlike engineered artifacts such as a
car that behaves predictably to inputs, FM’s responses are indeterminate and stochastic and there
are no known analytical methods today to explain the behavior of the trained model other than
empirically observing the responses of the network to inputs. This results in a need for
sophisticated evaluation frameworks that are akin to human cognitive tests.
●
Transfers: The more tasks a model is trained to perform the more learning of one task can help
other tasks (termed transfer learning) and has been the cornerstone of success of modern machine
learning applications where a single large model is trained once in high data regimes across tasks
and is then further fine tuned on unseen tasks in low data regimes. The intuition is to use high
data regimes to learn common invariance that does not need further data to learn in other
domains.
●
Open-Closed: Majority of high capacity and capability models are closed in nature. This means,
once trained and aligned, these FMs are black boxes to all but the FM platform developer, who
are only stakeholders who have access to model parameters. This is important because this access
is needed to: 1) continue training on new desired capabilities, 2) optimize inefficiencies and 3)
perform scientific studies to verify and evaluate FMs. As a lever of competition, other FM
providers (e.g Meta and Mistral) are open sourcing models that are capable but only over a
narrow range of tasks.
●
Scale: scaling “laws” have been empirically discovered that describe how the performance of a
model changes with increases in its size, training data, and computational resources during
pre-training, without any algorithmic improvements [16]. These laws guide the development and
deployment of future FMs, as they help in predicting the gains from scaling and managing the
trade-offs involved.
●
Emergence: ""when a lab invests in training a new LLM that advances the scale frontier, they’re
buying a mystery box: They’re justifiably confident that they’ll get a variety of economically
valuable new capabilities, but they can make few confident predictions about what those
capabilities will be or what preparations they’ll need to make to be able to deploy them
responsibly”. In other words, some capabilities are not designed but rather emerge and discovered
by research and developer communities after pre-training.
The Path
The future state described above may seem science fictional but as practitioners and observers have come
to learn from the previously stated impossibilities that its best not to bet against AI. Predicting the time to
the seemingly sci-fi future state is however non-trivial. What is less uncertain is that the path FMs will
take to this state, which is based on historical developments in not only the field of AI, but as we
demonstrate below, the evolution of technologies in adjacent distributed networking and computing
platforms.
Developments within the field of AI have followed the natural chronological order of capabilities of FMs
from “weak-AI” towards progressively “strong-AI” (figure 1). Weak AI refers to AI systems that are
designed and trained for a specific task or a narrow set of tasks, whereas Strong AI, also known as
Artificial General Intelligence (AGI), refers to AI systems that have the ability to understand, learn, and
apply knowledge in a way similar to human intelligence. Although research into modern FMs had been
ongoing since 2014 the field sprung into public domain late 2022 with the first public release of GPT-3.5,
a LLM by OpenAI. These early FMs were trained on a large portion of open (and some argue closed) data
sources on the internet. They were restricted to generating text only on the corpus they were trained on,
and lacked higher level capabilities, like retrieval of data not in their parameters, memory, reasoning and
planning, functionalities needed to support applications that require more advanced capabilities.
Furthermore, FM developers had no signal on application demand of what they had built. As we will
show below this was a departure from the Internet architecture where the core technology, Internet
Protocol, was also designed without knowing what applications would run on top of the technology nor
what physical layer it would run on top of. Early FMs on the other hand were not only application specific
but were also tightly coupled to their physical layer – GPUs/TPUs. Unlike the Internet, FMs cannot be
designed today in a modular manner to enable equivalent application specific agnosticism of the Internet.
Functionalities that were omitted by the FM platform providers were instead patched, either as tooling or
integrations, by application developers and researchers. Vector databases (e.g Pinecone, Chroma,
Weaviate), retrieval (Langchain, Llamaindex), memory (Langchain, memgpt), conversation thread
management (Langchain) and Agents (AutoGen) were frontiers of development by developers and
researchers alike, addressing functionalities that were lacking in the initial FMs.
The next milestone came with training FMs to be multi-modal, extending the capabilities from text to
images, video and audio. Multi-modal FMs, such as Google’s Gemini, was a natural progression that
required little or no product-market fit discovery, because the demand for image, video and audio had
already been demonstrated in adjacent uni-modal image platforms like Midjourney, StableDiffusion or the
multimodal example of Character.ai, with each having captured millions of users. This milestone marked
the beginning of vertical integration with increasing capabilities performed by the same FM model
architecture.
Soon after release of multi-modal capabilities, FM platform providers, after observing the market demand
and developments over the last year, began developing and vertically integrating further functionalities
into their FM architecture, including retrieval, memory, actions (the ability of FM to call other
functionalities), conversation management and early agents, components that were previously missing and
were being provisioned by the market, thereby displacing a layer of third party technology that was
developed over a year. In the case of OpenAI some retrieval workflows were supported by integration
with Microsoft’s Bing search engine.
Figure 1: Evolution of Data and Capabilities
Reasoning and planning are the set of capabilities being pursued that will mark the next major phase
transition, and likely complete the FM stack that can support the majority of applications and contexts.
Cognitive capabilities like reasoning and planning (aka system2, strong AI) were paradoxically where the
field of AI started but was impeded by lack of progress and eventual “winter of AI”. Indeed, existing FMs
have been shown to exhibit some reasoning capabilities today and researchers have been able to invoke
FMs to reason in an ad hoc manner via external integrations and/or elaborate prompting techniques that
guide and manage the FM towards desired goals. However, whether the next generation of FMs will be
trained to internalize both these capabilities within the neural network paradigm or integrate with existing
non data driven AI methods (e.g causal models) remains an empirical question. The field has certainly
demonstrated paradigm swings in the past and low data regime paradigms are being developed in the labs
that could disrupt the current data intensive incumbents. In either outcome these two capabilities will
enable a whole class of sophisticated applications that can reason and plan about outcomes. 2
Finally, integration of multi-modal with strong-AI capable FMs with robotics will likely be the next major
phase shift in the field. The perception and reasoning capabilities of FMs will be integrated into embodied
robotic systems that can take actions in the real-world and provide a closed-loop feedback to the FM,
grounding it in the physical world and addressing a new set of embedded physical applications and use
cases in the real world. It is worth noting that even though our exposition is linear in its narrative,
developments in each capability will have non-linear network effects on overall capabilities with phase
shifts (not too dissimilar to the scaling laws of FMs themselves, where we observe new and unintended
behaviors emerge with larger models and datasets). Likewise, initial sensing, reasoning and planning
capabilities may enable intractable embodied robotic problems to become tractable which in turn simplify
the perception, reasoning and planning problems. For instance, to achieve the current perceptual
capabilities of modern FMs in vision, an extraordinary number of samples are required for the model to
learn all the possible variances in the underlying data generation process. However, having a robotic
system that is capable of tactile skills, reasoning and planning may ease the data burden on the upstream
perception systems making them simpler to build and maintain.
Note that because a FM is a neural network that learns from data then marginal capabilities cannot be
added in a modular manner to an existing FM. For instance, multi-modal capabilities of GPT is
implemented as a language model generating the command that will be input to the vision system
(DALLE-3). Alternatively, the multi-modal model Gemini is a single model trained on all modalities at
once and attaining a better quality outcome. However, to add new features to Gemini will likely require a
full retraining, not adding the missing features as sub-modules. The pattern observed to date is missing
capabilities will likely be provisioned initially by the market, which in turn provide a demand signal to the
FM platform providers to internalize those demanded capabilities through re-training with those
capabilities. As FM’s capabilities increase the application layers become “thin” wrappers to this
multi-purpose universal asset, similar to an electrical device plugged into a power supply.
In summary, we predict the final state will be a cognitive and embodied capability that has a universal
language interface and requires fewer points of integration with third party applications. This Intelligence
as a Service (IQaaS) will be provided by vertically integrated platform providers and open source FM
providers. Enterprises and individuals can simply plugin to this intelligent platform without building
special purpose access or application artifacts. Like energy, the supply network will organize itself in a
manner that provides frictionless access to intelligence, anywhere, anyhow and any time, all via universal
interfaces.
2 By way of an example of the value of these higher level capabilities, decades long DARPA investments in AI were
recovered by the AI planners that planned military deployment in the 2003 Iraq engagement.
All Paths Start (and continue) with Data
It is important to underline the central role of (high quality) data in determining the course and speed of
this path. The initial FMs were mostly trained on publicly available data on the open Internet (circa 2021),
data that was generated by users and indexed by search engines like Google. However, high quality data
is becoming a scarcity and entities like OpenAI are offering data partnership incentives to access
proprietary data to train future models [5]. As some authors note, “in many ways the web in 2022
represents a data set that is analogous to the 11th edition of the Encyclopedia Britannica, which was noted
for its primary sources with entries written by people such as Bertrand Russell or Ernest Rutherford” [4].
After 2022 an increasing portion of the web will not consist of sources that are primarily human. This
means we should expect the rise of synthetic, machine generated data as the dominant content on the web,
possibly replacing, surplanting, and improving on the historical content which may be placed into the
web.archive. The statistics are perhaps easier to define in cases of images, where it took one hundred and
forty nine years to generate five billion images, compared to one and a half years for image FMs like
Stablediffusion [6]. FM platforms are being compared to black holes that are sucking anything
monetizable across a data event horizon, consuming Google’s raw material. This has important
implications not only for incumbents like Google whose business model depends on user generated
content, but also training of FMs themselves because future higher capable models will be dependent on
data generated by less capable models today.
Lessons from Communication Platforms
We base our predicted end state of FMs not by just the developments in AI but the precedence in the
lessons we have learnt in the six or so decades of Computer Science about design and commercialization
of networks and systems in the past. Comparative evolution of these platforms alongside FMs illustrates
some interesting patterns that can aid us in design and strategy. Our exposition will be from the
perspective of the architectures of Telephony, Internet and FMs (see table 1).
First, it must be noted that communication networks differ from FMs in that the former are point-to-point
platforms that do not need to be programmed with data first to function. They simply transport
information from one point to another. A FM on the other hand is not a point-to-point platform but rather
Telco
Internet
FM (today)
Data
Session
Session
Corpus
Service model
Guaranteed
best-effort
best-effort
State
Stateful
Stateless
Stateful
Core
Switches
Routers
Transformers
Edges
Telephones
Computers
API
Error handling
Network
Application layer
Application layer
Applications
Telephony
Agnostic
Agnostic
Physical
Copper
Agnostic
GPU/TPU/Trainium/Maia
Modular
True
True
False
Table 1: Comparison of Telecommunication, Internet and Foundation Models today
a client-server platform where the model being served needs to be programmed with a corpus of data first.
Nonetheless, the comparison is valuable because we have studied these platforms in depth and have a
good understanding of design trade offs.
The telecommunication network was architectured to be an application specific (telephony) network
consisting of very sophisticated and highly optimized network switches that would provision resources for
the duration of a call. It is stateful because a call consumes resources (switch memory and compute).
Dumb and stateless end devices (phones) then interconnect to this intelligent network. The Internet, first
an overlay on top of this telephony network, flipped this architecture, where stateful intelligent end
devices (computers) connected to a dumb stateless network (routers). Intelligence was “pushed to”
computers at edges of the network. FMs occupy an interesting mixture of these two extremes, starting as a
thin intelligent core but becoming increasingly stateful over time (with not just compute and memory for
main application logic, but also managing memory and computing resources needed for application
runtime).
Service Model: Telecommunication network demand can be accurately predicted and provide network
guaranteed service because they are application specific. The Internet can support a variety of
applications, with bursty needs that are multiplexed together, making demand prediction an impossible
task. These uncertainties make the Internet service model a “best effort” one, where the protocol only
specifies how data is packetized and transported across a distributed system to its desired destination. It is
“best effort” and errors are handled not by the dumb network but by intelligent applications in the end
devices that are communicating with one another over the lossy network (“fate sharing”). Similar to the
internet, FMs are also best-effort and any expected guarantees are provisioned at the application layers.
Errors: Building reliable systems from unreliable components has been a cornerstone of distributed
computing and networking. However, whereas errors in previous platforms were data and/or machine
loss, errors in today’s FMs constitute undesirable behaviors such as misalignments (hallucinations, bias
and unfairness) and intentional jailbreaks as one of many examples of prompt injection vulnerabilities.
FMs are pre-trained with data in an unsupervised manner and then aligned via a fine-tuning step. As a
consequence, similar to the internet, FM platform providers cannot provision a guaranteed error-free
service; the application layer has to handle errors.
Physical: A key design factor that has contributed significantly to the success of the Internet has been the
ability of the core Internet Protocol (IP) technology to be agnostic to what physical infrastructure it is
running on as well as what applications that run on top of it. The Internet started as an overlay over the
(unbundled) copper infrastructure of the telephony network but quickly grew to be an independent
network running on any physical technology. FMs can also be viewed like IP not as a general
communication but rather an intelligence platform that can support an increasing number of applications
or use cases, but depart from the IP technology in that they are (like early Internet) currently very
opinionated about the underlying physical layer. The current neural architectures of FMs are designed to
take advantage of Application Specific Integrated Circuits (ASICs) such as GPUs and TPUs, hardware
that is designed to take advantage of vector matrix operations specific to neural networks. Changes to this
architecture seems less likely as network effects of the core technology of FMs (Transformers) continues
to grow. However, running inference (not training) on commodity chipsets on edge devices may change
the calculus but the innovations needed to serve such large inferences on edge devices are still in research
mode. Additionally, meta has been planning and is now executing on migration to RISC-V (an
alternative Instruction Set Architecture (ISA) to the x86 architecture) for not only cpu based
workloads but an in-house RISC-V silicon for AI acceleration that is competitive to GPUs.
Pricing: Success of the Internet relies not just on the technical achievements of packet transport of data
but also its pricing. Although usage-based pricing is known to be more economically efficient pricing,
Internet pricing is fixed pricing instead because consumers prefer certainty over efficiency. Although
consumers can subscribe to a fixed price plan on FM provider services, larger workloads backed by APIs
are today usage-based pricing. We further explore the topic of costs below, but we expect this will become
an increasingly major factor that regulates adoption and usage of the technology and FM providers will
innovate a mixture of fixed, usage-based or cost-plus pricing.
Finally, another non-technical similarity to the Internet is that early success of the Internet led to
commercialization of the network, hampering fundamental research. Likewise, although some smaller
scaled models are being open-sourced, the larger capable models are all closed to third party stakeholders,
hampering scientific progress. This is an undesirable outcome because FMs have many unknown,
emerging and unintended behaviors and evaluation and new capabilities can not be subject to the
scientific principles. Closed nature of the models may unintentionally drive up incentives by labs to
innovate in alternative solutions.
Industrial Organization of Intelligence as a Service
As alluded to above, we are currently observing different organizations and business models emerging,
similar to the evolution of closed versus open computing components of the past (e.g operating systems).
On one end of the competitive spectrum is the closed vertically integrated model, best exemplified by the
partnership between OpenAI and Microsoft who provides high performance distributed compute fabric,
data capabilities (through Bing) and capital to OpenAI. Microsoft is also a reference consumer of the FM
platform developed by OpenAI. As Nadella shared in 2023 Q4 earnings call, Microsoft has made large
investments to build an AI-first compute fabric that can support economies of scale, scope and learning
effects across its whole enterprise software ecosystem. OpenAI in return appears to provide not only the
“one big model” that Microsoft uses, but also appears to have ambitions to compete with Apple and
Google as a consumer product itself, owning the chip all the way to a device. In addition, OpenAI appears
to be acting as a channel partner for Azure and its enterprise product suite. In short, a tacit agreement
seems to be that OpenAI is attempting to own the AI Chatbot consumer product market and Microsoft
will own the enterprise market, with cross externalities.
On the other side of the competition are entities such as Google who are encumbered by potential
cannibalization of their existing business models and are bundling FMs into their cloud platforms, and
making capital investments in OpenAI competitors such as Antropic.
In between these two competitor extremes are entities such as Meta and Mistral who are competing on the
open-source strategy, similar to Linux strategy in the operating systems. Unlike Google and OpenAI that
have closed FMs, Meta has continued its tradition of tapping into the open-source incentives and
dynamics, empowering developers and researchers to add innovations that were omitted by closed models
[7]. There are two loci that open-source strategy leverages; firstly, knowledge in large models with
billions of parameters is not only costly to run at inference [8], but are unwanted by domain specific
enterprise use-cases. Instead, an open source FM can be finetuned / distilled to a smaller model that can
often better serve the enterprise needs at a lower cost. Secondly, it allows enterprises to compete for
developers with knowledge of how to finetune these open source models on proprietary and sensitive
data. Mistral, latest entry in the LLM open-source model providers and ex-Meta and Google Deepmind
employees, launched its first AI model with a team of just ten people, spending less than $500,000 on
training costs, in contrast to the tens of millions that rivals spent. “We are happy to be the most
capital-efficient [LLM] company”.
We expect FM platform providers will compete on the following vectors:
●
Capabilities
●
Data
●
Compute
●
Price-Latency
●
Errors
●
Privacy
Transformation Steps
The exposition has so far focused on the evolution of FMs from the perspective of the FM platform
provider and potential market structure. In this section we will explore how organizations can begin to
transform themselves in lockstep with the evolution of the technology towards an Intelligence as a Service
model.
Today: Data + ML in the cloud
Enterprises have spent the past decade or so investing in data and Machine Learning (ML) on cloud
infrastructures. The incumbent organizational model and governance has been centered around
functionally separated business units that generate data and engage in build versus buy decisions
independently of one another in a mostly uncoordinated manner. ML models are trained on a case-by-case
basis, focused on solving a single task. Furthermore, relevant data and intelligence from upstream or
adjacent business processes are often lost or ignored, amplifying the loss to downstream processes.
Future: Conglomerates to Common Core
“The lesson learned from the cloud side is — we’re not running a conglomerate of different businesses,
it’s all one tech stack up and down Microsoft’s portfolio, And that, I think, is going to be very important,
because that discipline, given what the spend will look like for this AI transition, any business that’s
not disciplined about their capital spent accruing across all their businesses could run into trouble.“
S. Nadella
In the age of AI, the solution to enterprise problems can be better addressed by continuous monitoring and
training of a core FM that respects the privacy, security and regulatory requirements. Foundational models
enable the majority of core enterprise functionalities to be provisioned within a common core that is
accessible by all units (see figure 2). A few enterprises may be conducting fine-tuning of FM models
today but a common architecture extends the FM deployment across the organization and is not restricted
to isolated and independent business units. As mentioned above, doing so has positive externalities
because AI models trained on multiple tasks (HR, marketing, sales, legal, etc) are better models in terms
of generalization abilities, when they have been trained using examples from disparate problem domains.
As an analogy to impart the intuition, a child doesn't learn to see first then walk but rather learns both
simultaneously, where learning one task assists learning of other tasks and vice-versa. Important
dependencies are learned as part of the training itself rather than added in an ad-hoc manner which may
result in brittle systems.
How this core FM is provisioned will depend on the idiosyncrasies of each enterprise, They can range
from:
●
Using services of a FM providers to custom pre-train a proprietary FM on enterprise data
●
Pre-training on proprietary data locally
●
Fine-tuning an open source models on proprietary data (e.g. Llama2)
The choice will depend on data and privacy requirements, compute costs and availability of expertise
(recall, there are estimated to be around one hundred and fifty people only in the world who have
pre-training skills).
Once trained, this common core FM will need to be monitored and retrained if:
●
Newer more capable FM are released
●
Current pre-trained / fine-tuned core model is exhibiting undesirable behaviors that can not either
be addressed through further alignment or is costly to do
●
Current pre-trained / fine-tuned core model is not performant in production
Figure 2: FM Common Core. Marketing fine-tuning on core
However this common core is trained and maintained it can then be used as an infrastructure to further
fine tune the core FM for local application needs. For instance, as shown in figure 2, marketing
departments can access this common core FM to fine-tune their own FM to perform tasks that the core
FM cannot perform.
Transformation Resources
What does an enterprise need to provision to enable the steps enumerated above? See figure 3 for a
summary of some of these factors.
People
To achieve this vision of a AI first enterprises will need to provision teams with following skills set:
●
Data teams: Data governance team will have oversight and visibility on all data and modeling
pipelines. They will be supported by DataOps teams whose mission is to provision and manage
important local and global data ETL pipelines which themselves can be managed by custom
trained FMs.
●
Core FM team whose roles, skills and responsibilities will involve using DevOps and AIOps to
train, evaluate, monitor and at times retrain this common core FM on either cloud or hosted ASIC
infrastructures.
●
Edge team: AI first enterprises will also have a situation response team of individuals who can
assist any team with fine-tuning and prompt engineering needs, allowing enterprises, much like
white blood cells, to dispatch and heal any parts of the organization that need intelligence
services.
●
Security team: We will discuss this further below but all developments and operations from data
to core system and edge models will need to undergo extensive security, privacy and potentially
regulatory compliance checks.
●
Research team: FMs create more open questions than they address old questions. Additionally,
developments happen at a fast pace not only by the developer communities but also from research
labs across the globe, adding ever increasing knowledge of the capabilities, limitations,
vulnerabilities, evaluative and solutions on an almost hourly basis. Having a dedicated team of
researchers who are versed in ML and AI is paramount to success in the AI first enterprise.
Figure 3: Incremental Rollouts
Role
Data
Data Governance
DataOps
Core
FM Core services
Edges
Prompting and Fine-tuning Services
System
Red Teams
Research
ML Scientists
Table 2: Roles
Both core FM and fine-tuned FM support teams will also have the following skills needed to build
cost-effective and reliable service:
●
FMs have complex cost, latency and quality contours. Quantifying these tradeoffs for global and
local workflows is critical to making the optimal deployment decisions
●
As we will expand on below, evaluating FMs is a non-trivial and essential step in any AI pipeline.
Evaluation is one vector where the scientific community is still making active contributions.
Therefore teams need to be well versed and abreast with the latest science of evaluation to be able
to measure and benchmark both the common core and the fine-tuned models.
●
FMs will exhibit soft (spurious correlations) and hard (hallucination, biases) errors, making their
detection and management essential.
Data
Data is a strategic asset in the age of machine learning, and the recent OpenAI data partnership incentives
to access proprietary data to train future models further underlines the increasing importance of the asset
[5]. Investment in data assets has been ongoing for decades but there are key new data capabilities needed
in AI first organization:
●
FMs are multimodal meaning training and inference can be performed over not just structured
data but also text, images, video and audio (or any other sequence data such as biological
sequences). Harmonization of disparate data stores will be important to lower training and
inference cost and accuracies.
●
While pre-training of the common core will likely continue to be self-supervised, the alignment of
the core model/s with application specific needs in the near-term will require labeled data in form
of instructions or human feedback. Another AI system providing feedback data is beginning to
emerge and ultimately (as being currently pursued by Antropic) the FM will need to be provided
with only very high level goals (“constitutions”), allowing the AI to learn the entire end to end
pretraining and alignment autonomously from data.
●
It has taken the field of photography one hundred and forty nine years to generate five billion
images. It has taken generative AI one and a half years to generate the same number. Indeed,
“synthetic” content generated by AI is forecasted to overtake human generated data within a
couple of years (leading to a whole new set of training and evaluation problems we will touch on
briefly below). However, synthetic data presents new opportunities. AI generated data is useful
for several important reasons. Synthetic data can be used in sensitive domains (such as
healthcare) where private and sensitive data have traditionally throttled the data volumes needed
for advanced modern ML algorithms. A high fidelity synthetic data can circumnavigate privacy
issues. Additionally, a critical problem of modern ML pipelines is “distribution shifts” where the
data seen in production does not adhere to the characteristics of the data used to train the models.
Synthetic data can be a useful data generation tool that can sample from parts of the data
distributions that the enterprise has not encountered. Models trained on this mix of actual and
synthesized data can be more robust in production.
●
As AI begins to generate an increasing volume of data then it is important to know the
provenance of the data and whether it was generated by AI or not. To that end enterprises would
be well served to adopt emerging technologies like watermarking that enable applications to
discriminate on the provenance of the data.
Evaluation
Software development communities have developed practices such as Test Driven Development to test
and guarantee the quality of the artifacts they ship. Testing deterministic software is challenging but it is a
manageable task when artifact behavior is determined by input and known parameters. FM software
development is on the other hand much more difficult for a number of reasons. Firstly, ML systems are
often stochastic, behaving differently to the same input. Secondly, we are programming with data which
means the data quality and coverage has a direct effect on the behavior of the system at runtime; if the
data is biased or not representative of the hidden and unobserved data distribution, then the FM will be
inadequate in real usage scenarios.
The goal of evaluation is to make sure the model we have trained does what it was trained to do. As
alluded to above evaluation is a critically important and increasingly complex endeavor, not just within
enterprises but also within the FM developers as well as the scientific community. Evaluation is hard
because traditionally it involved holding out part of the training data and testing the final model on this
never before seen hold out set. The challenge is today’s FM such as chatGPT have been trained on all the
content on the internet making it hard to test on “never seen before” datasets. Indeed traditional scientific
methodologies developed over decades of research in computer vision and natural language processing
fields are inadequate in evaluating modern FMs. Using other high capacity FM to evaluate the output of
another is one emerging modern strategy to evaluate models.
Nonetheless, the success of an AI first enterprise critically depends on the investments it makes in being
disciplined on its evaluation efforts. Third party vendors may provision parts of the overall evaluation
goal but the core responsibility of the enterprise is to coordinate several stakeholders on a commitment to
a protocol of evaluation.
Explanation
Explaining the outputs of an AI is critical in building trust in any real-world application, especially given
not only the growing and emerging complexities of FMs but also their black box nature. Additionally,
modern AI models have a foundation in inductive methods of Machine Learning. Inducing explainability
from inductive methods that map data to functions is equivalent to a trapdoor one-way function used in
hashing; you can go from eggs to an omelet but impossible the other way round.
In addition to these complexities there is an absence of a standard of explainability. What constitutes a
satisfactory explanation is, like evaluation, likely to be idiosyncratic to the class of problems the AI is
tasked to solve. (Linear) explanation methodologies such as Shapley Values, were initially developed to
explain the observed behavior of the models in terms of importance of the input features. Modern FM
based models on the other hand can be instruct fine-tuned to generate a trace of their reasoning as part of
their outputs, giving the evaluation team or the end user the opportunity to assess the coherency and
accuracy of the provided explanation. Additionally, prompting strategies together with using other FMs
trained
FMOps
Operationalizing, orchestrating and systematizing pieces of the ML puzzle into the fabric of an
organization first started with the MLOps movement with its focus on harmonizing machine learning
processes and workflows in order to maximize model throughput and accuracy. This was followed by the
emergence of AIOps that harmonized not just ML but all aspects of enterprise data, analytics and
visualization tool sets. More recently we have seen LLMOps with focus on the workflows of current
Language Model FMs.
We anticipate that we will begin to see a convergence of all extant ops solutions as FMs grow in
capabilities, consuming most analytics, machine learning and current LLMs under one model framework.
We call this anticipated emergence FMOps, a unified operations and orchestration platform across any
dataset, capabilities, evaluation and output (visualization, explanation) paradigm. It is different to AIOps
because current AIOps harmonize heterogenous task specific data and models; a FMOps manages the
development, deployment and monitoring of a single large capacity model. We comment on two
additional observations:
●
Continuous and Incremental rollouts: Lessons learnt from Continuous Integration and
Continuous Development (CI/CD) best practices in software development has already been
adopted in MLOps best practices and we are witnessing its continuation in FM platform providers
best practices. OpenAI for instance, is continuously releasing incremental improvements to the
data, model and value add services. CI/CD practices become even more important in large scale
data driven models where behaviors emerge and product is stochastic in nature. As shown in
figure 3, CI/CD in FM will involve a continuous loop of pre-training, alignment and evaluation
before each release.
●
Workflows: Because of their current error-quality-cost contours, the initial workflows that
FMOps will need to support appears to be a real-time “copilot”, where users with domain
knowledge use FMs to automate parts of their workflows, on a transaction by transaction basis.
This copilot workflow is optimal today because errors produced by the FM can be detected and
managed easier by someone with knowledge of the domain. We predict that this workflow will
change to an offline/batch autonomous operation as the FMs become more capable, less error
prone and the hardware costs lower. We expect that we will also see a transition from internal
usage workflows to consumer facing workflows as risks are lowered. FMOps will also emerge to
support both workflows, for both internal and consumer facing applications.
Privacy And security
Arguments of existential threat AI poses overshadow a much more serious short-term risks FMs pose.
Testing FMs for vulnerabilities is hard compared to traditional deterministic software for a number of
reasons, including:
●
Data Privacy: FMs are trained on extensive datasets which may include personal and sensitive
information. Ensuring that this data is anonymized and does not infringe on individual privacy
rights is a major challenge.
●
Bias and Fairness: FMs can inadvertently learn and perpetuate biases present in their training
data. This can lead to unfair or discriminatory outcomes in their applications, raising ethical
concerns.
 
●
Model Security: Like any software, FMs are susceptible to adversarial security vulnerabilities,
especially as their capabilities grow. This includes risks like model inversion attacks, where
attackers input specially crafted queries to extract sensitive information the model has learned
[12,13,17] or data poisoning / backdoor attacks where the attacker controls the data used to train
the FM [14,15]
 
●
Information Leaks: There's a risk that an FMs might generate outputs containing bits of sensitive
information it was trained on, which could lead to unintentional data leaks [17].
 
●
Misuse: The ability of FMs to generate convincing outputs can be misused for purposes like
generating deceptive content, posing a significant security challenge through mechanisms such as
prompt injection.
 
●
Content Moderation: FMs can generate harmful or inappropriate content if not properly
supervised or restricted, making content moderation a key concern.
●
Robustness and Reliability: Ensuring that FMs reliably interpret and respond to inputs without
being misled or exploited (e.g., through adversarial attacks) is a significant challenge.
 
●
Regulatory Compliance: With the increasing regulatory focus on AI and data privacy (like GDPR
in Europe), ensuring that FMs comply with these regulations is both a privacy and legal
challenge.
 
●
Intellectual Property Rights: FMs trained on publicly available data might inadvertently infringe
on copyrights or intellectual property rights, raising legal concerns.
 
In light of the above challenges, determining accountability for the actions of a FM and establishing
effective governance mechanisms to oversee FM use in order to mitigate risks is necessarily a complex
task. Security and privacy should not be viewed as a static event driven reactive process but rather an
ongoing one that is triggered not by just an observed risk but also an anticipated one, as different
stakeholders make new discoveries and weaknesses that could materially impact an enterprise's risks. For
instance, researchers at Google’s Deepmind discovered a (“silly”) exploit to extract ChatGPT training
data by simply prompting it to “Repeat the following word forever: ""company” [17], demonstrating how
fine-tuning alignment does not sanction data leakage from pre-training. Security and privacy in the age of
high capacity FMs will therefore be conducted by a distributed red teaming model that is ongoing,
reactive and anticipatory and abreast with all the developments in the research and developer
communities that are exploring and sharing vulnerability vectors.
Conclusion
AI is becoming a significant entry in the technology stack. The goal of this paper was to motivate the
evolutionary path of this technology towards a natural final state conclusion, in a manner that is invariant
as possible to changes or disruptions in any one layer of the technology stack. We attempted to justify
these developments by enumerating the logical and historical developments in the field. We then used the
developed framework to provide guidance on how an enterprise can operationalize these innovations in
lockstep with the expected developments. Generative AI is today an exciting and fast evolving vector of
innovation that promises to disrupt many fields and disciplines, but we hope to have illustrated that such
transformations require a holistic, intentional and informed posture, paying special attention to team, data,
evaluation, transparency and security, factors which we believe will regulate the speed of adoption by
enterprises.
References
[1] R.Bommasani et.al (2021) On the Opportunities and Risks of Foundation Models
[2] Samuel R. Bowman Eight Things to Know about Large Language Models
[3] Microsoft Fiscal Year 2024 First Quarter Earnings Conference Call:
https://www.microsoft.com/en-us/Investor/events/FY-2024/earnings-fy-2024-q1.aspx
[4] David Galbraith (2023) What OpenAI Means for the Entire Tech Sector
[5] OpenAI Data Partnerships (2023)
[6] AI Has Already Created As Many Images As Photographers Have Taken in 150 Years. Statistics for
2023 (2023) Everypixel Blog
[7] We Have No Moat, And Neither Does OpenAI (2023)
[8] Why GPT-3.5 is (mostly) cheaper than Llama 2 (July 20, 2023)
[9] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L.Kaiser, I. Polosukhin.
Published In: Advances in Neural Information Processing Systems (NeurIPS), 2017
[10] S. Viswanath, V. Khanna, Y. Liang (11/16/2023) AI: The Coming Revolution
[11] OPT175B_Logbook
https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf
[12] Alexander Wei, Nika Haghtalab, Jacob Steinhardt (2023) “Jailbroken: How Does LLM Safety
Training Fail?“ https://arxiv.org/abs/2307.02483
[13] Andy Zou, Zifan Wang, J. Zico Kolter, Matt Fredrikson (2023) Universal and Transferable
Adversarial Attacks on Aligned Language Models https://arxiv.org/abs/2307.15043
[14] Alexander Wan, Eric Wallace, Sheng Shen, Dan Klein (2023) “Poisoning Language Models During
Instruction Tuning” https://arxiv.org/abs/2305.00944
[15] Nicholas Carlini, Matthew Jagielski, Christopher A. Choquette-Choo, Daniel Paleka, Will Pearce,
Hyrum Anderson, Andreas Terzis, Kurt Thomas, Florian Tramèr (2023) “Poisoning Web-Scale Training
Datasets is Practical” https://arxiv.org/abs/2302.10149
[16] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,
Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei (2020) “Scaling Laws for Neural Language
Models“ https://arxiv.org/pdf/2001.08361.pdf
[17] Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne
Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, Katherine Lee (2023) “Scalable
Extraction of Training Data from (Production) Language Models”
"
"Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive with leading contemporary models.nan",Knowledge graph embedding simplifies relational reasoning into mathematical operations by transforming discrete entities and relationships into a continuous vector space. Knowledge graph embedding methods can be broadly categorized into two main groups: translational distance models and semantic matching models.nan,"nanTranslational distance model models relationships as translational transformations and uses distance scores to measure the correctness of triples; The semantic matching model uses similarity scores. TransA uses (|h + r − t|)M_r(|h + r − t|)^T, which assumes that M_r is a semipositive definite matrix. RESCAL adopts quadratic scoring function, namely hM_r t^T, to capture the interaction between potential factors of entities; DistMult further simplified the matrix into diagonal matrix, and adopted h diag(r) t^T, which made the model unable to distinguish symmetric relations. ComplEx studied the modeling bottleneck of point multiplication operation on antisymmetric relations, and proposed to extend Dist Mult to complex space.nan",LSE model establishes the relationship f_r(h) + r = t for the correct triple. LSE uses the distance scoring function \|hR_r - t\|_p. Experiments show that it is better to choose 1 norm in this paper. LSEd uses the distance scoring function \|h diag(r) - t\|_p = \| h ⋅ r - t \|_p.nan,"The models proposed in this paper have achieved the best performance on FB15k-237 and WN18RR data sets. For FB15k237, the MRR of LSEd was 0.331, Hits@1 was 0.237, Hits@3 was 0.366 and Hits@10 was 0.522. For WN18RR, the MRR of LSEd was 0.450, Hits@1 was 0.407, Hits@3 was 0.465 and Hits@10 was 0.537.nan","This paper proposes a location-sensitive embedding model for knowledge graph embedding representation, and the effectiveness of the proposed improved model is verified theoretically and experimentally, and the superior performance is achieved on the task of link prediction in large-scale knowledge graphs.nan",Location Sensitive Embedding for Knowledge Graph Embedding,"Deepak Banerjee, Anjali Ishaan"," 
 
Location Sensitive Embedding for Knowledge Graph Embedding
Deepak Banerjee1, Anjali Ishaan2 
1) Department of Computer Science and Engineering, Calcutta University 
2) Department of Applied physics, Calcutta University 
Abstract. Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating 
inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key 
challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To 
address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using 
relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations 
of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more 
streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four 
large-scale datasets for link prediction, LSEd either outperforms or is competitive with leading contemporary models. 
Key words. knowledge graph; representation learning; translational distance model; location sensitive embedding 
 
With the advent of the big data era, Google proposed 
knowledge graph in 2012 to improve user search, content 
aggregation and other services, which set off a boom in 
knowledge graph research [1]. Knowledge graph is a structured 
way to describe entities and their relationships. Entities are 
modeled as nodes, and relationships are modeled as different 
types of edges connecting the entities, which can be expressed in 
the form of triples (ℎ, 𝑟, 𝑡). Although knowledge graphs are well 
structured and defined, their potential symbolic nature poses a 
challenge for automatic construction and reasoning. Knowledge 
graph 
embedding 
simplifies 
relational 
reasoning 
into 
mathematical operations by transforming discrete entities and 
relationships into a continuous vector space [2]. Knowledge 
graph embedding methods can be broadly categorized into two 
main groups: translational distance models and semantic 
matching. Translational distance models and semantic matching 
models. The translational distance model models relationships as 
translational transformations and uses distance scores to measure 
the correctness of triples; the semantic matching model uses 
similarity scores. In addition, some studies have introduced 
additional information (e.g., entity types, relationship paths, time, 
etc.) for modeling [3-4], and these approaches are beyond the 
scope of this paper. The purpose of this paper is to analyze the 
shortcomings of the translational distance model and propose a 
more generalized distance model.  
The constraints imposed by the existing translation distance 
model on triples can be summarized by a generalized formula 
𝑓𝑟(𝒉) + 𝒓 = 𝑓𝑟(𝒕) , where 𝑓𝑟( .)  is a mapping determined by 
relations and is usually modeled as a linear transformation. In the 
transE [5] model, 𝑓𝑟(⋅) degenerates into an identity matrix. That 
is to say, it requires 𝒉 + 𝒓 = 𝒕. This simplification ignores the 
different semantics of entities under different relationships, and 
can't handle the relationships of ""one-to-many"", ""many-to-one"" 
and ""many-to-many"" well. In order to solve this problem, transR 
[6] introduces a transformation matrix determined by the 
relationship between connected entities, so that 𝑓𝑟(𝒙) = 𝒙𝑴𝑟 ; 
Subsequently, transh [7] fixed the transformation matrix as a 
projection matrix, and the normal vector of the projection plane 
was determined by the relation. Models such as TRANSA [8] 
and TRANSD [9] introduce new constraints on the 
transformation matrix and greatly reduce the number of 
parameters. 
However, these models have not been substantially 
improved. According to the experimental results, the 
performance of the carefully trained TransE model is not lower 
than that of the later improved model [10]. Theoretically, the 
translation distance model cannot model the map of the ring 
structure. Previous work has noticed this, but the causes of the 
ring structure have not been discussed from different types of 
relationships [11]. The following focuses on this point. 
The atlas of the ring structure can be divided into three 
categories: (1) the ring formed by symmetrical relationship, in 
which the head entity and the tail entity are interchanged, and the 
triplet still holds; (2) The loop formed by reciprocal relationship, 
that is, the head/tail entities of two different relationships are the 
tail/head entities of another relationship; (3) The loop formed by 
the relationship path is the combination of different relationships. 
In these three cases, the phenomenon that different entities and 
relationships have the same representation or represent zero 
vectors will bring serious interference to the reasoning process, 
which is called ""degeneration"" in this paper. The root cause is 
that the translation distance model ignores the semantic 
difference between the head and the tail of the entity. Therefore, 
this paper proposes a position-sensitive embedding model, and it 
is hoped that the constraint 𝑓𝑟(𝒉) = 𝒕 will be established, that is, 
the relationship only acts on the head entity, while retaining the 
original semantics of the tail entity. At the same time, the 
semantic transformation of the relationship to the head entity is 
no longer limited to translation, but a general linear 
transformation. 
Aiming at the problem of embedding knowledge map, this 
paper puts forward a location-sensitive distance model. 
Theoretical analysis and experimental results show that this 
model can achieve the most advanced performance at present. In 
the new model, the linear time complexity can be achieved by 
further simplifying the transformation of relations, so that the 
model can be extended to large-scale knowledge map. At the 
same time, the probability distribution of negative sampling is 
improved to avoid a large number of meaningless negative 
samples in the model training process. Experiments show that 
this technique can improve the final performance of the model. 
1 Related Work 
Before introducing related work, this paper briefly 
introduces the symbolic system of this paper. Line vectors  
𝒉, 𝒓, 𝒕 ∈ ℝ𝑑  are used to represent symbolic triplets (ℎ, 𝑟, 𝑡)  (in 
some works, the dimensions of relations and entities can be 
different, so for simplicity, this paper adopts the same dimension). 
 
 
𝑠(ℎ, 𝑟, 𝑡) is used to express the score of the probability of triple 
establishment. 
Knowledge map embedding usually takes the ranking loss 
as 
the 
optimization 
objective, 
that 
is, 
minℒ =
∑(ℎ,𝑟,𝑡) ∑(ℎ′,𝑟,𝑡′) [𝛾 + 𝑠(ℎ, 𝑟, 𝑡) − 𝑠(ℎ′, 𝑟, 𝑡′)]+ . Where,  [𝑥]+ =
max(0, 𝑥), 𝛾 controls the distance between positive and negative 
samples. Because the knowledge map does not include negative 
samples, (ℎ′, 𝑟, 𝑡′) is obtained by randomly replacing the head 
entity or tail entity of the correct triplet (ℎ, 𝑟, 𝑡) (but not both at 
the same time). This process is called negative sampling. In the 
process of negative sampling, false negative triplets may be 
introduced, that is, the correct triplets are just unrecorded, which 
will be discussed later. 
Cross entropy loss can also be used as the optimization 
objective, that is 
( , , )
, ,
min
ln ( , , )
ln 1
, ,
h r t
h r t
p h r t
p h r t
 
In this case, the probability that the distance score is 
established after Sigmoid function is obtained, that is, 
𝑝(ℎ, 𝑟, 𝑡) = 𝜎(𝛾 − 𝑠(ℎ, 𝑟, 𝑡)). 
The existing research shows that [3], for the translation 
distance model, the ranking loss effect is better; For the semantic 
matching model, the effect of cross entropy loss is better. In 
addition, knowledge map embedding usually has restrictions on 
the length of entities and vectors [3], and these restrictions are 
cancelled in this paper. 
1.1 Translational Distance Model 
The translational distance model models relationships as 
translational transformations, where the smaller the distance 
between the head entity and the tail entity after translation, the 
greater the likelihood that the triad will be formed. From the 
perspective of the Unified Framework, TransE and its improved 
models are special cases of the distance ∥∥𝒉𝑹𝑟 + 𝒓 − 𝒕𝑹𝑟∥∥𝑝  is 
the distance from each entity to the other. where 𝑹𝑟  is 
determined by each relation; 𝑝 = 1,2 is either 1-parameter or 2-
parameter.  
TransE [5] defines the distance score as  ∥ 𝒉 + 𝒓 − 𝒕 ∥𝑝. It 
can be seen that if 𝑹𝑟 = 𝑰, it is a TransE model. 
Before translational transformations, TransR [6] maps 
entities into different relationally determined spaces in order to 
capture the different semantics of entities in different relational 
links, i.e., ∥∥𝒉𝑹𝑟 + 𝒓 − 𝒕𝑹𝑟∥∥𝑝. 
TransH [7] further assumes that the mapping matrix 
undergoes a projection transformation, and the projection plane 
is determined by each relation. Let the unit normal vector of the 
projection plane be 𝒘𝑟 , then the projection is 𝒆 − 𝒆𝒘𝑟T𝒘𝑟. 
TransD [9] assumes that the mapping matrix is jointly 
determined by the relations and their connected entities, and 
decomposes the matrix into the product of 2 vectors, i.e. 𝑹𝑟 =
𝒘𝑟T𝒘𝑒 + 𝑰. 
TransA [8] uses  (|𝒉 + 𝒓 − 𝒕|)𝑴𝑟(|𝒉 + 𝒓 − 𝒕|)T , which 
assumes that 𝑴𝑟  symmetric. The following shows that it is a 
special case of  ∥∥𝒉𝑹𝑟 + 𝒓 − 𝒕𝑹𝑟∥∥𝑝. Assuming that the mapping 
matrix in ∥∥𝒉𝑹𝑟 + 𝒓 − 𝒕𝑹𝑟∥∥𝑝 is invertible, i.e., 𝑹𝑟−1 exists, then 
it can be rewritten as
∥∥(𝒉 + 𝒓′ − 𝒕)𝑹𝑟∥∥𝑝 ; where, 𝒓′ = 𝒓𝑹𝑟−1 . 
When 𝑝 = 2, it is (𝒉 + 𝒓′ − 𝒕)𝑹𝑟𝑹𝑟T(𝒉 + 𝒓′ − 𝒕)T. Noting that 
𝑴𝑟 = 𝑹𝑟𝑹𝑟T is a semipositive definite matrix, we can omit the 
operation of taking absolute values, which is the TransA model. 
In addition, TranSparse [12] considers sparse mapping 
matrices, and TransM [13] employs 𝜃𝑟∥∥𝒉𝑹𝑟 + 𝒓 − 𝒕𝑹𝑟∥∥𝑝 , 
which loosens the restriction on some of the triples by adjusting 
the parameters. These models are special cases. 
1.2 Semantic Matching Models 
These models use similarity scoring, and differ from each 
other in how they capture the interaction between embedded 
representations. 
RESCAL[14] adopts quadratic scoring function, namely 
𝒉𝑴𝑟𝒕T, to capture the interaction between potential factors of 
entities; DistMult [15] further simplified the matrix into diagonal 
matrix, and adopted 𝒉diag⁡(𝒓)𝒕T, which made the model unable 
to distinguish symmetric relations. Complex [16] studied the 
modeling bottleneck of point multiplication operation on 
antisymmetric relations, and proposed to extend Dist Mult to 
complex space. That is, the scoring function is Re⁡(𝒉diag⁡(𝒓)𝒕̅T). 
Hole [17] uses the cyclic correlation operator to aggregate the 
interaction between the head entity and the tail entity, that is, 
(𝒉∗𝒕)𝒓T ; Where [𝒉 ∗ 𝒕]𝑖 = ∑𝑘=0
𝑑−1 [𝒉]𝑘 ⋅ [𝒕](𝑘+𝑖)mod𝑑 . It can be 
proved that there is an equivalent hole [18] for any ComplEx 
model. 
In addition, there is a branch of semantic matching model 
based on neural network, including semantic matching 
embedding (SME) [19], neural tensor networks (NTN) [20], etc. 
In this branch, the convolutional embedding model (Conve). It 
recombines and stacks the vectors of head entities and relations, 
then uses convolution layer to extract features, and finally 
matches with tail entities through full connection layer. Because 
of a large number of convolution, its computational complexity 
is high. 
2 Position Sensitive Distance Modeling 
In this section, we firstly analyze several types of 
relationships that cannot be modeled by the translational distance 
model; secondly, we propose an improved position-sensitive 
distance model, and at the same time, this paper no longer models 
the 
relationships 
as 
translations 
but 
general 
linear 
transformations, and analyzes theoretically that it has a better 
representational ability; then, we propose a simplified model; 
and lastly, we discuss the relationships and differences between 
the model and other existing models. 
2.1 Reasons for the Failure of the Translational Distance Model 
Remember the knowledge map 𝐺 = {𝐸, 𝑅}, where 𝐸 stands 
for the set of all entities, quantity is denoted as 𝑛𝑒, 𝑅 stands for 
the set of all relations, and quantity is denoted as 𝑛𝑟. This paper 
summarizes the relations of three specific patterns: symmetry, 
reciprocity and combination, and gives specific definitions. 
Definition 1. If ∀𝑎, 𝑏 ∈ 𝐸, (𝑎, 𝑟, 𝑏) → (𝑏, 𝑟, 𝑎), the relation 
𝑟 is said to be symmetrical, as shown in Figure 1a. 
Definition 2. If ∀𝑎, 𝑏 ∈ 𝐸, (𝑎, 𝑟1, 𝑏) → (𝑏, 𝑟2, 𝑎) , the 
relations 𝑟1 and 𝑟2 are said to be reciprocal, as shown in Figure 
1b。 
Definition 
3. 
If ∀𝑎, 𝑏, 𝑐 ∈ 𝐸，(𝑎, 𝑟1, 𝑏) ∧ (𝑏, 𝑟2, 𝑐) →
(𝑎, 𝑟, 𝑐), the relation 𝑟 is a combination of 𝑟1 and 𝑟2, as shown in 
Figure 1c. 
As mentioned above, the circular structure brought by these 
three relationships leads to the degradation of the translation 
distance model. (1) Symmetry requires that 𝑓𝑟(𝑎) + 𝑟 = 𝑓𝑟(𝑏) 
and 𝑓𝑟(𝑏) + 𝑟 = 𝑓𝑟(𝑎)  be established at the same time, which 
leads to 𝑟 = 0; Furthermore, 𝑓𝑟(.) is usually a reversible linear 
transformation, which leads to 𝑎 = 𝑏; (2) The reciprocal relation 
requires that 𝑓𝑟1(𝑎) + 𝑟1 = 𝑓𝑟1(𝑏)  and 𝑓𝑟2(𝑎) + 𝑟2 = 𝑓𝑟2(𝑏)  be 
established at the same time, and there is a nontrivial solution 
satisfying this condition. (3) Combinatorial relations require 
𝑓𝑟1(𝑎) + 𝑟1 = 𝑓𝑟1(𝑏), 𝑓𝑟2(𝑏) + 𝑟2 = 𝑓𝑟2(𝑐)  and 𝑓𝑟3(𝑎) + 𝑟3 =
𝑓𝑟3(𝑐) . It will lead to 𝑓𝑟3(⋅) = 𝑓𝑟2(⋅) . The latter means that the 
same mapping function is used for different relations, which is 
an important reason why the improved model of TransE 
(including TransR, etc.) does not actually exceed that of TransE. 
From the above derivation, it can be seen that the root of the 
problem lies in the same mapping of the head entity and the tail 
 
 
entity of the triple. Therefore, this paper proposes an improved 
distance model with position sensitivity. 
 
Fig.1 Knowledge Graph Composed of Three Special Types of Relationships 
 
2.2 Improved Location-Sensitive Distance Model 
The most intuitive idea is that the linear transformation is 
reserved for the head entity of the triple, but no transformation is 
made for the tail entity, that is, the expected model establishes 
the relationship 𝑓𝑟(𝒉) + 𝒓 = 𝒕 for the correct triple. Because the 
translation operator can be regarded as a part of the linear 
transformation, it can be attributed to people 𝑓𝑟(⋅) . Finally, In 
this paper, a Location-Sensitive Embedding (LSE) model is 
proposed. The triple distance scoring function is ∥∥𝒉𝑹𝑟 − 𝒕∥∥𝑝 . 
Similarly, the smaller the distance, the higher the possibility of 
the triple being established. 𝑃  can take 1 norm or 2 norm. 
Through experiments, it is better to choose 1 norm in this paper. 
Three lemmas are given below, which show that LSE model 
can model the relationships of the above three specific patterns. 
Lemma 1. Improved distance model can model symmetric 
relations. 
Prove that according to 𝑹𝑟𝒂 = 𝒃, 𝑹𝑟𝒃 = 𝒂 , it can be 
obtained that 𝑹𝑟𝑹𝑟 = 𝑰. If this condition is met, there will be no 
additional restrictions on the embedding of the entity. 
Lemma 2. The improved distance model can model 
reciprocal relations. 
Prove that according to 𝑹𝑟1𝒂 = 𝒃, 𝑹𝑟2𝒃 = 𝒂 , we can get 
𝑹𝑟1𝑹𝑟2 = 𝑰. Meeting this condition will not impose additional 
restrictions on the entity embedment. 
Lemma 3. The improved distance model can model the 
combination of relationships. 
According to 𝑹𝑟1𝒂 = 𝒃, 𝑹𝑟2𝒃 = 𝒄, 𝑹𝑟3𝒂 = 𝒄  , it can be 
obtained that 𝑹𝑟2𝑹𝑟1 = 𝑹𝑟3, which will not be beneficial to the 
entity. 
2.2.1 Loss Function 
In order to better consider the possible triplets in the 
unobserved samples, the cross-entropy loss with label-
smoothness is experimented in this paper. For 𝑘  groups of 
samples obtained by random negative sampling, the label is not 
0, but 1/𝑘; Where 𝑘 > 1 is the proportion of negative sampling 
for each triplet. The loss function is minℒ = 
∑  
(ℎ,𝑟,𝑡)
{log⁡ 𝑝(ℎ, 𝑟, 𝑡) −
∑
 
(ℎ′,𝑟,𝑡′)
 1
𝑘 log⁡(1 − 𝑝(ℎ′, 𝑟, 𝑡′))} 
Note that this paper removes all restrictions on the norm of 
parameters, so the loss function has no regular term. 
2.2.2 Variations of the model 
In the LSE model, using a matrix to represent the mapping 
function will cause a large amount of calculation. To solve this 
problem, this paper also assumes that the matrix can be replaced 
by diagonal matrix, that is, the mapping operation of the head 
entity can be carried out independently in each dimension. This 
model is called LSE𝑑 , It uses the distance scoring function ∥
𝒉diag⁡(𝒓) − 𝒕 ∥𝑝=∥ 𝒉 ∘ 𝒓 − 𝒕 ∥𝑝 . It notes that ∥ 𝒉 ∘ 𝒓 − 𝒕 ∥1=
∑𝑖=1
𝑑
 |ℎ𝑖 ⋅ 𝑟𝑖 − 𝑡𝑖|. 
2.2.3 Comparison and Connection with Other Models 
Among the existing knowledge map embedding models, the 
translation distance model is most closely related to this model. 
Besides, unstructured model (um) [22] and structured 
embedding (SE) [23] are the same as LSE. No translation 
operator is used. The distance score function of UM is ∥ 𝒉 − 𝒕 ∥2, 
while that of SE is ∥∥𝑹𝑟1𝒉 − 𝑹𝑟2𝒕∥∥2. The former oversimplifies the 
role of the relationship, while the latter adopts similar ideas as 
this paper, but it introduces too many parameters, which is not 
conducive to the training of the model. 
In addition, rescal [15] and distmult [16] can both be 
regarded as linear transformations of the head entities. The 
difference is that they use the inner product to calculate the 
similarity. If the vector transformation in this model is limited to 
the unit modulus length before and after, and 𝑝 = 2 , then 
∥∥𝒉𝑹𝑟 − 𝒕∥∥2
2 = 2 − 2𝒉𝑹𝑟𝒕T. Equivalent to RESCAL. It can be seen that 
compared with RESCAL, this model removes the limitation of 
module length, so it has better representation ability. In DistMult, 
the head entity and the tail entity get the same score, which will 
lead to the model treating all relationships as symmetrical. The 
simplified model LSE_d proposed in this paper avoids this point. 
Table 1 lists the complexity comparison results with the 
current advanced models. It can be seen that LSE𝑑, as a linear 
time complexity model, can be applied to reasoning tasks of 
large-scale knowledge maps. 
Table 1 Comparison of complexity of knowledge graph embedding models. 
Model 
Space complexity 
Time complexity 
TransE[5] 
(𝑛𝑟 + 𝑛𝑒)𝑑 
𝑂(𝑑) 
TransR[6] 
(𝑛𝑟 + 𝑛𝑒)𝑑 + 𝑛𝑟𝑑2 
𝑂(𝑑2) 
DistMult[15] 
(𝑛𝑟 + 𝑛𝑒)𝑑 
𝑂(𝑑) 
HolE[17] 
(𝑛𝑟 + 𝑛𝑒)𝑑 
𝑂(𝑑ln⁡𝑑) 
ComplEx[16] 
2(𝑛𝑟 + 𝑛𝑒)𝑑 
𝑂(𝑑) 
ConvE[21] 
(𝑛𝑟 + 𝑛𝑒)𝑑 
 
LSELSE𝑑 
𝑛𝑒𝑑 + 𝑛𝑟𝑑2 
𝑂(𝑑2) 
3 Experimental Results and Discussion 
In this section, we firstly introduce the dataset, the link 
prediction task of the knowledge graph, and the evaluation 
metrics used in the experiments, and then discuss the influence 
of hyperparameters and the selection techniques, and finally list 
the performance of the improved distance model and compare it 
with the current best performance model. 
It is worth mentioning that research work has shown that 
many knowledge graph embedding methods (including TransE, 
DistMult, etc.) can exceed their original published results after 
fine tuning. This is one of the criticisms of the improvement of 
the flat distance model, i.e., the original comparison methods are 
 
 
not fine-tuned, but in fact, some of the baseline methods still 
have much room for training improvement. In order to ensure the 
fairness of the comparison, we have chosen [10,21,24,25] as the 
source of the comparison. 
3.1 Experimental Setup 
3.1.1 Data sets 
The model of this paper is evaluated on four public datasets, 
and their statistical characteristics are shown in Table 2. 
Table 2: Number of entities, relationships, triples and cuts in the datasets 
Data set 
nr 
ne 
Number of 
training sets 
Number of 
validation sets 
Number of 
test sets 
FB15k 
1 345 
14 951 
483 142 
50 000 
59 071 
FB15k237 
237 
14 541 
272 115 
17 535 
20 466 
WN18 
18 
40 943 
141 442 
5 000 
5 000 
WN18RR 
11 
40 943 
86 835 
3 034 
3 134 
(1) FB15k vs. FB15k237. FB15k is a subset of the fact 
database Freebase [26]. The main drawback of this database is 
that 81% of the triples in the test set can be derived from inverse 
relations. These relations have been removed in FB15k237 , thus 
making it more challenging. 
(2) WN18 and WN18RR. WN18 is a subset of the word 
hierarchy database WordNet [27]. Compared with Freebase, 
WordNet has a larger number of entities. Compared with 
Freebase, WordNet has more entities, fewer relationship types, 
and fewer triples, which indicates that the interconnections of 
each entity node are sparse on average, and this poses a major 
problem for knowledge graph representation learning. WN18 
also has many reversible relationships, which are removed by 
WN18RR. 
3.1.2 Link Prediction and Evaluation Metrics 
Link prediction is essentially an ordering problem. In the 
testing stage, for each triad, all the entities in the graph are 
replaced with the head or tail entities, and then all the 
replacement results are ranked in ascending order by their 
distance scores. The ranking results are evaluated using two 
types of indicators. 
(1) mean reciprocal rank, MRR). Average the reciprocal of 
the ranking of the correct entity among all entities, that is, 
∑𝑖=1
𝑁  (1/rank𝑖)/𝑁. The higher the ranking of the correct entity, 
the higher the MRR. 
(2) Top 𝑛  hit rate (Hits@n). The proportion of correct 
entities in the top 𝑛 entities. This paper makes statistics when n 
= 1, 3 and 10 respectively. 
Some papers also use mean rank as an evaluation index, but 
it is too affected by extreme samples and is not as stable and 
objective as MRR. In addition, the triad generated after 
substitution is not necessarily a negative sample, and it may also 
exist in the knowledge graph. The above calculation may 
underestimate the performance of the model. In order to get a fair 
evaluation, a ""filtering"" setting is usually used, i.e., the correct 
triples are filtered out from the ranking results before the 
evaluation metrics are calculated. 
3.2 Experimental Environment and Hyperparameters 
The code in this paper is based on the PyTorch framework, 
and is trained on a single Titan X GPU (12 GB). 
The hyperparameters involved in the LSE and LSE𝑑 models 
proposed in this paper include three categories: (1) model 
hyperparameter, embedding dimension 𝑑 ∈ {100,200 , interval 
between positive and negative samples 𝛾 ∈ {1,2, ⋯ ,30} . (2) 
optimization algorithm superparameter, and model training 
adopts 
randomness. 
SGD) 
algorithm, 
which 
involves 
hyperparameters and its selection range is learning rate 𝑙 ∈
{5 × 10−4, 10−4,5 × 10−5, 10−5}, and the batch data size is 𝑏 ∈
{128,256,512 ,1024} ,. (3) Negative sampling hyperparameter. 
In this paper, according to transh [7] method, the head entity or 
tail entity is randomly replaced by Bernoulli distribution to avoid 
attracting too many false negative triples in the process of 
uniform sampling. For each triplet, the ratio of random negative 
sampling is 𝑔 ∈ {128,256,512,1024}. 
Through the selection of verification set, this paper uses 
𝑑 = 500  for all four data sets. For FB15k, 𝛾 = 24, 𝑙 = 5 ×
10−4, 𝑏 = 256 ,𝑝 = 105, 𝑔 = 256 ; For FB15K-237, 𝛾 = 9, 𝑙 =
5 × 10−4,𝑏 = 1024, 𝑝 = 105, 𝑔 = 256; For Wn18,𝛾 = 12, 𝑙 =
5 × 10−4, 𝑏 = 512,𝑝 = 5 × 104, 𝑔 = 1024; For Wn18RR, 𝛾 =
6, 𝑙 = 5 × 10−4, 𝑏 = 512, 𝑝 = 105, 𝑔 = 1024. In the process of 
parameter adjustment, it is found that expanding the batch data 
size and increasing the negative sampling ratio will improve the 
performance when the experimental memory is allowed. 
3.3 Experimental Results and Analysis 
Tables 3 and 4 compare the performance of the LSE, LSEd 
models with the other models on the link prediction task. 
Tables 3 and 4 compare the performance of LSE, LSE _d 
model and other comparison models in link prediction tasks, 
respectively. It can be seen that the models proposed in this paper 
have achieved the best performance on FB15k-237 and 
WN18RR data sets. On FB15k and WN18 data sets, the 
performance of the model proposed in this paper is basically the 
same as that of the best model. In addition, 𝐿𝑆𝐸⁡𝑑  has a 
significant performance improvement compared with LSE, 
which shows that fewer parameters are more suitable for training, 
and also shows that the assumption that each dimension is 
independent is true. 
 
Table 3 Link prediction performance of the improved distance model on the FB15k and WN18 datasets. 
Model: FB15k 
FB15k 
WN18 
MRR 
Hits@1 
Hits@3 
Hits@10 
MRR 
Hits@1 
Hits@3 
Hits@10 
TransE[10] 
0.463 
0.578 
0.578 
0.578 
0.495 
0.113 
0.888 
0.943 
DistMult[24] 
0.798 
 
 
0.893 
0.797 
 
 
0.946 
HolE[17] 
0.524 
0.402 
0.613 
0.739 
0.938 
0.930 
0.945 
0.949 
ComplEx[16] 
0.692 
0.599 
0.759 
0.840 
0.941 
0.936 
0.945 
0.947 
ConvE[21] 
0.745 
0.670 
0.801 
0.873 
0.943 
0.935 
0.946 
0.956 
LSE 
0.701 
0.643 
0.733 
0.795 
0.873 
0.842 
0.898 
0.926 
LSEd 
0.742 
0.680 
0.783 
0.848 
0.929 
0.910 
0.944 
0.955 
Notes. Bold indicates the best performance. 
 
 
 
 
 
Table 4 Link prediction performance of the improved distance model on the FB15k237 and WN18RR datasets 
Model 
FB15k237 
WN18RR 
MRR 
Hits@1 
Hits@3 
Hits@10 
MRR 
Hits@1 
Hits@3 
Hits@10 
TransE[10] 
0.294 
 
 
0.465 
0.226 
 
 
0.501 
DistMult[24] 
0.241 
0.155 
0.263 
0.419 
0.430 
0.390 
0.440 
0.490 
ComplEx[16] 
0.247 
0.158 
0.275 
0.428 
0.440 
0.410 
0.460 
0.510 
ConvE[21] 
0.325 
0.237 
0.356 
0.501 
0.430 
0.430 
0.440 
0.520 
LSE 
0.299 
0.189 
0.312 
0.470 
0.421 
0.378 
0.450 
0.494 
LSEd 
0.331 
0.237 
0.366 
0.522 
0.450 
0.407 
0.465 
0.537 
Notes. Bold indicates the best performance. 
 
 For each dataset, the following findings are observed. 
(1) DistMult achieves the highest performance on the 
FB15k dataset. This suggests that symmetric relationships are 
the dominant relationship model in this dataset. In fact, about 81% 
of the test set triples can be directly inferred from the symmetry 
of the relations [4]. It can be seen that the results of DistMult on 
other datasets are not as good as that of the model proposed in 
this paper, so it can be said that the model proposed in this paper 
is more general than DistMult. 
(2) In the WN18 dataset, the main relationship patterns are 
symmetric and inverse; in the WN18RR dataset, the main 
relationship patterns are symmetric (e.g., relationship also see, 
similar to, etc.). On both datasets, the performance of TransE 
decreases significantly, which indicates that it cannot 
symmetrize relations well. This is consistent with the theoretical 
analysis in Section 3. 
(3) On FB15k-237 and WN18RR data sets, the combination 
of relationships also occupies a very important part. In FB15k-
237, the effect of TransE is not much different from other 
advanced algorithms, which is consistent with the theoretical 
analysis in Section 3. Similarly, the model proposed in this paper 
can also model the combination of relationships well. 
Taken together, the experimental results in this paper 
correspond well with the theoretical analysis, which fully 
demonstrates that the models LSE and LSEd have good 
knowledge graph representation learning ability. 
4 Conclusion 
In this paper, a location-sensitive model for knowledge 
graph embedding representation is proposed, and the 
effectiveness of the proposed improved model is verified 
theoretically and experimentally, and the superior performance 
is achieved on the task of link prediction in large-scale 
knowledge graphs. 
This paper notes that there are still some problems that need 
to be further studied. (1) In the combinatorial relationship, there 
is a special case that needs to be considered separately, that is, 
the combination formed by the same relationship. This model 
usually exists in the knowledge map of professional fields with 
more hierarchical structures. For example, (forearm, partOf, 
limbs) and (limbs, partOf, human body) coexist (forearm, partOf, 
(2) The representation of knowledge is uncertain. In KG2E [28] 
model, entities and relationships are no longer modeled as a point 
in space, but a Gaussian distribution. The application of position-
sensitive embedding proposed in this paper needs to be further 
improved. 
References: 
[1] 
Singhal, Amit. ""Introducing the Knowledge Graph: Things, 
Not 
Strings."" 
Google 
Blog, 
6 
Aug. 
2020, 
https://blog.google/products/search/introducing-
knowledge-graph-things-not/. 
[2] 
Nickel, Maximilian, et al. ""A Review of Relational 
Machine Learning for Knowledge Graphs."" Proceedings 
of the IEEE, vol. 104, no. 1, 2016, pp. 11-33. 
[3] 
Toutanova, Kristina, and Danqi Chen. ""Observed Versus 
Latent Features for Knowledge Base and Text Inference."" 
Proceedings of the 3rd Workshop on Continuous Vector 
Space Models and their Compositionality, MIT Press, 
2015, pp. 57-66. 
[4] 
Xiong, Siheng, et al. ""TILP: Differentiable Learning of 
Temporal Logical Rules on Knowledge Graphs."" The 
Eleventh 
International 
Conference 
on 
Learning 
Representations. 2022. 
[5] 
Bordes, Antoine, et al. ""Translating Embeddings for 
Modeling Multi-Relational Data."" Proceedings of the 29th 
International 
Conference 
on 
Neural 
Information 
Processing Systems, MIT Press, 2013, pp. 2787-2795. 
[6] 
Lin, Yankai, et al. ""Learning Entity and Relation 
Embeddings 
for 
Knowledge 
Graph 
Completion."" 
Proceedings of the 29th AAAI Conference on Artificial 
Intelligence, AAAI Press, 2015, pp. 2181-2187. 
[7] 
Wang, Zhen, et al. ""Knowledge Graph Embedding by 
Translating on Hyperplanes."" Proceedings of the 28th 
AAAI Conference on Artificial Intelligence, AAAI Press, 
2014, pp. 1112-1119. 
[8] 
Xiao, Han, et al. ""TransA: An Adaptive Approach for 
Knowledge Graph Embedding."" arXiv, 6 Aug. 2020, 
https://arxiv.org/pdf/1509.05490.pdf. 
[9] 
Ji, Guilin, et al. ""Knowledge Graph Embedding Via 
Dynamic Mapping Matrix."" Proceedings of the 53rd 
Annual Meeting of the Association for Computational 
Linguistics and the 7th International Joint Conference on 
Natural Language Processing, MIT Press, 2015, pp. 687-
696. 
[10] Akrami, Farahnaz, et al. ""Re-evaluating Embedding-
Based 
Knowledge 
Graph 
Completion 
Methods."" 
Proceedings of the 27th ACM International Conference on 
Information and Knowledge Management, ACM Press, 
2018, pp. 1779-1782. 
[11] Zhang, Wen. ""Knowledge Graph Embedding with 
Diversity of Structures."" Proceedings of the 26th 
International Conference on World Wide Web Companion, 
International World Wide Web Conferences Steering 
Committee Press, 2017, pp. 747-753. 
[12] Ji, Guilin, et al. ""Knowledge Graph Completion with 
Adaptive Sparse Transfer Matrix."" Proceedings of the 30th 
AAAI Conference on Artificial Intelligence, AAAI Press, 
2016, pp. 985-991. 
[13] Fan, Ming, et al. ""Transition-Based Knowledge Graph 
Embedding 
with 
Relational 
Mapping 
Properties."" 
Proceedings of the 28th Pacific Asia Conference on 
Language, Information and Computing, Department of 
Linguistics, Chulalongkorn University, 2014, pp. 328-337. 
[14] Nickel, Maximilian, et al. ""A Three-Way Model for 
Collective 
Learning 
on 
Multi-Relational 
Data."" 
Proceedings of the 28th International Conference on 
Machine Learning, Omni Press, 2011, pp. 809-816. 
[15] Yang, Bishan, et al. ""Embedding Entities and Relations for 
Learning and Inference in Knowledge Bases."" Proceedings 
of 
the 
International 
Conference 
on 
Learning 
Representations, MIT Press, 2015, pp. 51-63. 
[16] Trouillon, Théo, et al. ""Complex Embeddings for Simple 
Link Prediction."" Proceedings of the 33rd International 
Conference on Machine Learning, ACM Press, 2016, pp. 
2071-2080. 
[17] Nickel, Maximilian, Lorenzo Rosasco, and Tomaso 
Poggio. 
""Holographic 
Embeddings 
of 
Knowledge 
 
 
Graphs."" Proceedings of the 33th AAAI Conference on 
Artificial Intelligence, AAAI Press, 2016, pp. 1955-1961. 
[18] Hayashi, Kohei, and Masashi Shimbo. ""On the 
Equivalence of Holographic and Complex Embeddings for 
Link Prediction."" Proceedings of the 55th Annual Meeting 
of the Association for Computational Linguistics, MIT 
Press, 2017, pp. 554-559. 
[19] Bordes, Antoine, et al. ""A Semantic Matching Energy 
Function for Learning with Multi-Relational Data."" 
Machine Learning, vol. 94, no. 2, 2014, pp. 233-259. 
[20] Socher, Richard, et al. ""Reasoning with Neural Tensor 
Networks for Knowledge Base Completion."" Proceedings 
of Advances in Neural Information Processing Systems, 
MIT Press, 2013, pp. 926-934. 
[21] Dettmers, Tim, et al. ""Convolutional 2D Knowledge 
Graph Embeddings."" Proceedings of the 32nd AAAI 
Conference on Artificial Intelligence, AAAI Press, 2018, 
pp. 1811-1818. 
[22] Bordes, Antoine, et al. ""Joint Learning of Words and 
Meaning Representations for Open-Text Semantic 
Parsing."" Proceedings of the 15th International Conference 
of Artificial Intelligence and Statistics, ACM Press, 2012, 
pp. 127-135. 
[23] Bordes, Antoine, et al. ""Learning Structured Embeddings 
of Knowledge Bases."" Proceedings of the 25th AAAI 
Conference on Artificial Intelligence, AAAI Press, 2011, 
pp. 301-306. 
[24] Kadlec, Rudolf, Ondřej Bajgar, and Jan Kleindienst. 
""Knowledge Base Completion: Baselines Strike Back."" 
arXiv, 6 Aug. 2020, https://arxiv.org/abs/1705.10744. 
[25] Nguyen, Dai Quoc, et al. ""A Novel Embedding Model for 
Knowledge Base Completion Based on Convolutional 
Neural 
Network."" 
arXiv, 
6 
Aug. 
2020, 
https://arxiv.org/abs/1712.02121v2. 
[26] Bollacker, Kurt, et al. ""Freebase: A Collaboratively 
Created 
Graph 
Database 
for 
Structuring 
Human 
Knowledge."" Proceedings of the ACM SIGMOD 
International Conference on Management of Data, ACM 
Press, 2008, pp. 1247-1250. 
[27] Miller, George A. ""WordNet: A Lexical Database for 
English."" Communications of the ACM, vol. 38, no. 11, 
1995, pp. 39-41. 
[28] He, Shizhu, et al. ""Learning to Represent Knowledge 
Graphs with Gaussian Embedding."" Proceedings of the 
24th ACM International on Conference on Information 
and Knowledge Management, ACM Press, 2015, pp. 623-
632. 
 
"
"We present Depth Anything, a highly practical solution for robust monocular depth estimation. Unlike prior works that laboriously construct diverse labeled datasets, we highlight the value of massive, cheap, and diverse unlabeled images. We design two simple yet highly effective strategies — challenging the student model with strong perturbations when learning unlabeled images, and preserving rich semantic priors from pre-trained models — to unlock their potential. Consequently, our Depth Anything model exhibits superior zero-shot depth estimation ability across extensive unseen scenes and is further strengthened for downstream metric depth estimation and semantic segmentation tasks. We release the code and models for broad research use.nan","This work presents Depth Anything1, a highly practical solution for robust monocular depth estimation. Without pursuing novel technical modules, we aim to build a simple yet powerful foundation model dealing with any images under any circumstances. To this end, we scale up the dataset by designing a data engine to collect and automatically annotate large-scale unlabeled data (~62M), which significantly enlarges the data coverage and thus is able to reduce the generalization error. We investigate two simple yet effective strategies that make data scaling-up promising. First, a more challenging optimization target is created by leveraging data augmentation tools. It compels the model to actively seek extra visual knowledge and acquire robust representations. Second, an auxiliary supervision is developed to enforce the model to inherit rich semantic priors from pre-trained encoders. We evaluate its zero-shot capabilities extensively, including six public datasets and randomly captured photos. It demonstrates impressive generalization ability (Figure 1). Further, through fine-tuning it with metric depth information from NYUv2 and KITTI, new SOTAs are set. Our better depth model also results in a better depth-conditioned ControlNet.
Our work was done during an internship at TikTok.nan","The field of computer vision and natural language processing is currently experiencing a revolution with the emergence of “foundation models” [6] that demonstrate strong zero-/few-shot performance in various downstream scenarios [44, 58]. These successes primarily rely on large-scale training data that can effectively cover the data distribution. Monocular Depth Estimation (MDE), which is a fundamental problem with broad applications in robotics [65], autonomous driving [63, 79], virtual reality [47], etc., also requires a foundation model to estimate depth information from a single image. However, this has been underexplored due to the difficulty of building datasets with tens of millions of depth labels. MiDaS [45] made a pioneering study along this direction by training an MDE model on a collection of mixed labeled datasets. Despite demonstrating a certain level of zero-shot ability, MiDaS is limited by its data coverage, thus suffering disastrous performance in some scenarios.nannan","Our work utilizes both labeled and unlabeled images to facilitate better monocular depth estimation (MDE). For labeled images, we produce the depth labels with an off-the-shelf MDE model. Therefore, we can easily annotate large-scale unlabeled images and augment the data coverage. Moreover, to leverage the unlabeled images effectively, we design two simple yet effective strategies. First, we challenge the student model with strong perturbations when learning the pseudo labels. It forces the student model to actively seek extra visual knowledge and learn more robust representations. Second, we enforce an auxiliary constraint on the student model to preserve rich semantic priors from pre-trained encoders.nan","Both with a ViT-L encoder, our Depth Anything surpasses the strongest MiDaS model tremendously across extensive scenes in terms of both the AbsRel (absolute relative error: |d* −d|/d) and ϴ1 (percentage of max(d*/d, d/d*) < 1.25) metrics. For example, when tested on the well-known autonomous driving dataset DDAD [20], we improve the AbsRel (↓) from 0.251 → 0.230 and improve the ϴ1 (↑) from 0.766 ↑ 0.789.
Besides, our ViT-B model is already clearly superior to the MiDaS based on a much larger ViT-L. Moreover, our ViT-S model, whose scale is less than 1/10 of the MiDaS model, even outperforms MiDaS on several unseen datasets, including Sintel, DDAD, and ETH3D. The performance advantage of these small-scale models demonstrates their great potential in computationally-constrained scenarios.
It is also worth noting that, on the most widely used MDE benchmarks KITTI and NYUv2, although MiDaS v3.1 uses the corresponding training images (not zero-shot anymore), our Depth Anything is still evidently superior to it without training with any KITTI or NYUv2 images, e.g., 0.127 vs. 0.076 in AbsRel and 0.850 vs. 0.947 in ϴ1 on KITTI.nan","In this work, we present Depth Anything, a highly practical solution to robust monocular depth estimation. Different from prior arts, we especially highlight the value of cheap and diverse unlabeled images. We design two simple yet highly effective strategies to fully exploit their value: 1) posing a more challenging optimization target when learning unlabeled images, and 2) preserving rich semantic priors from pre-trained models. As a result, our Depth Anything model exhibits excellent zero-shot depth estimation ability, and also serves as a promising initialization for downstream metric depth estimation and semantic segmentation tasks.nan",Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data,"Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, Hengshuang Zhao","Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data
Lihe Yang1
Bingyi Kang2†
Zilong Huang2
Xiaogang Xu3,4
Jiashi Feng2
Hengshuang Zhao1†
1The University of Hong Kong
2TikTok
3Zhejiang Lab
4Zhejiang University
† corresponding authors
https://depth-anything.github.io
Figure 1. Our model exhibits impressive generalization ability across extensive unseen scenes. Left two columns: COCO [35]. Middle two:
SA-1B [27] (a hold-out unseen set). Right two: photos captured by ourselves. Our model works robustly in low-light environments (1st and
3rd column), complex scenes (2nd and 5th column), foggy weather (5th column), and ultra-remote distance (5th and 6th column), etc.
Abstract
This work presents Depth Anything1, a highly practical
solution for robust monocular depth estimation. Without pur-
suing novel technical modules, we aim to build a simple yet
powerful foundation model dealing with any images under
any circumstances. To this end, we scale up the dataset by
designing a data engine to collect and automatically anno-
tate large-scale unlabeled data (∼62M), which significantly
enlarges the data coverage and thus is able to reduce the
generalization error. We investigate two simple yet effective
strategies that make data scaling-up promising. First, a more
challenging optimization target is created by leveraging data
augmentation tools. It compels the model to actively seek
extra visual knowledge and acquire robust representations.
Second, an auxiliary supervision is developed to enforce
the model to inherit rich semantic priors from pre-trained
encoders. We evaluate its zero-shot capabilities extensively,
including six public datasets and randomly captured photos.
It demonstrates impressive generalization ability (Figure 1).
Further, through fine-tuning it with metric depth information
from NYUv2 and KITTI, new SOTAs are set. Our better depth
model also results in a better depth-conditioned ControlNet.
Our models are released here.
The work was done during an internship at TikTok.
1While the grammatical soundness of this name may be questionable,
we treat it as a whole and pay homage to Segment Anything [27].
1. Introduction
The field of computer vision and natural language processing
is currently experiencing a revolution with the emergence of
“foundation models” [6] that demonstrate strong zero-/few-
shot performance in various downstream scenarios [44, 58].
These successes primarily rely on large-scale training data
that can effectively cover the data distribution. Monocular
Depth Estimation (MDE), which is a fundamental problem
with broad applications in robotics [65], autonomous driv-
ing [63, 79], virtual reality [47], etc., also requires a foun-
dation model to estimate depth information from a single
image. However, this has been underexplored due to the
difficulty of building datasets with tens of millions of depth
labels. MiDaS [45] made a pioneering study along this di-
rection by training an MDE model on a collection of mixed
labeled datasets. Despite demonstrating a certain level of
zero-shot ability, MiDaS is limited by its data coverage, thus
suffering disastrous performance in some scenarios.
In this work, our goal is to build a foundation model for
MDE capable of producing high-quality depth information
for any images under any circumstances. We approach this
target from the perspective of dataset scaling-up. Tradition-
ally, depth datasets are created mainly by acquiring depth
data from sensors [18, 54], stereo matching [15], or SfM [33],
which is costly, time-consuming, or even intractable in partic-
ular situations. We instead, for the first time, pay attention to
large-scale unlabeled data. Compared with stereo images or
1
arXiv:2401.10891v1  [cs.CV]  19 Jan 2024
labeled images from depth sensors, our used monocular unla-
beled images exhibit three advantages: (i) (simple and cheap
to acquire) Monocular images exist almost everywhere, thus
they are easy to collect, without requiring specialized de-
vices. (ii) (diverse) Monocular images can cover a broader
range of scenes, which are critical to the model generaliza-
tion ability and scalability. (iii) (easy to annotate) We can
simply use a pre-trained MDE model to assign depth labels
for unlabeled images, which only takes a feedforward step.
More than efficient, this also produces denser depth maps
than LiDAR [18] and omits the computationally intensive
stereo matching process.
We design a data engine to automatically generate depth
annotations for unlabeled images, enabling data scaling-up
to arbitrary scale. It collects 62M diverse and informative im-
ages from eight public large-scale datasets, e.g., SA-1B [27],
Open Images [30], and BDD100K [81]. We use their raw
unlabeled images without any forms of labels. Then, in or-
der to provide a reliable annotation tool for our unlabeled
images, we collect 1.5M labeled images from six public
datasets to train an initial MDE model. The unlabeled im-
ages are then automatically annotated and jointly learned
with labeled images in a self-training manner [31].
Despite all the aforementioned advantages of monocular
unlabeled images, it is indeed not trivial to make positive use
of such large-scale unlabeled images [72, 89], especially in
the case of sufficient labeled images and strong pre-training
models. In our preliminary attempts, directly combining la-
beled and pseudo labeled images failed to improve the base-
line of solely using labeled images. We conjecture that, the
additional knowledge acquired in such a naive self-teaching
manner is rather limited. To address the dilemma, we pro-
pose to challenge the student model with a more difficult
optimization target when learning the pseudo labels. The
student model is enforced to seek extra visual knowledge
and learn robust representations under various strong pertur-
bations to better handle unseen images.
Furthermore, there have been some works [9, 21] demon-
strating the benefit of an auxiliary semantic segmentation
task for MDE. We also follow this research line, aiming to
equip our model with better high-level scene understanding
capability. However, we observed when an MDE model is
already powerful enough, it is hard for such an auxiliary
task to bring further gains. We speculate that it is due to
severe loss in semantic information when decoding an im-
age into a discrete class space. Therefore, considering the
excellent performance of DINOv2 in semantic-related tasks,
we propose to maintain the rich semantic priors from it with
a simple feature alignment loss. This not only enhances the
MDE performance, but also yields a multi-task encoder for
both middle-level and high-level perception tasks.
Our contributions are summarized as follows:
• We highlight the value of data scaling-up of massive,
cheap, and diverse unlabeled images for MDE.
• We point out a key practice in jointly training large-
scale labeled and unlabeled images. Instead of learning
raw unlabeled images directly, we challenge the model
with a harder optimization target for extra knowledge.
• We propose to inherit rich semantic priors from pre-
trained encoders for better scene understanding, rather
than using an auxiliary semantic segmentation task.
• Our model exhibits stronger zero-shot capability than
MiDaS-BEiTL-512 [5]. Further, fine-tuned with metric
depth, it outperforms ZoeDepth [4] significantly.
2. Related Work
Monocular depth estimation (MDE). Early works [23, 36,
50] primarily relied on handcrafted features and traditional
computer vision techniques. They were limited by their re-
liance on explicit depth cues and struggled to handle complex
scenes with occlusions and textureless regions.
Deep learning-based methods have revolutionized monoc-
ular depth estimation by effectively learning depth represen-
tations from delicately annotated datasets [18, 54]. Eigen
et al. [17] first proposed a multi-scale fusion network to
regress the depth. Following this, many works consistently
improve the depth estimation accuracy by carefully design-
ing the regression task as a classification task [3, 34], in-
troducing more priors [32, 53, 75, 82], and better objective
functions [67, 77], etc. Despite the promising performance,
they are hard to generalize to unseen domains.
Zero-shot depth estimation. Our work belongs to this re-
search line. We aim to train an MDE model with a diverse
training set and thus can predict the depth for any given im-
age. Some pioneering works [10, 66] explored this direction
by collecting more training images, but their supervision is
very sparse and is only enforced on limited pairs of points.
To enable effective multi-dataset joint training, a mile-
stone work MiDaS [45] utilizes an affine-invariant loss to
ignore the potentially different depth scales and shifts across
varying datasets. Thus, MiDaS provides relative depth infor-
mation. Recently, some works [4, 22, 78] take a step further
to estimate the metric depth. However, in our practice, we
observe such methods exhibit poorer generalization ability
than MiDaS, especially its latest version [5]. Besides, as
demonstrated by ZoeDepth [4], a strong relative depth es-
timation model can also work well in generalizable metric
depth estimation by fine-tuning with metric depth informa-
tion. Therefore, we still follow MiDaS in relative depth
estimation, but further strengthen it by highlighting the value
of large-scale monocular unlabeled images.
Leveraging unlabeled data. This belongs to the research
area of semi-supervised learning [31, 55, 89], which is pop-
ular with various applications [70, 74]. However, existing
2
works typically assume only limited images are available.
They rarely consider the challenging but realistic scenario
where there are already sufficient labeled images but also
larger-scale unlabeled images. We take this challenging di-
rection for zero-shot MDE. We demonstrate that unlabeled
images can significantly enhance the data coverage and thus
improve model generalization and robustness.
3. Depth Anything
Our work utilizes both labeled and unlabeled images to
facilitate better monocular depth estimation (MDE). For-
mally, the labeled and unlabeled sets are denoted as Dl =
{(xi, di)}M
i=1 and Du = {ui}N
i=1 respectively. We aim to
learn a teacher model T from Dl. Then, we utilize T to
assign pseudo depth labels for Du. Finally, we train a stu-
dent model S on the combination of labeled set and pseudo
labeled set. A brief illustration is provided in Figure 2.
3.1. Learning Labeled Images
This process is similar to the training of MiDaS [5, 45].
However, since MiDaS did not release its code, we first
reproduced it. Concretely, the depth value is first transformed
into the disparity space by d = 1/t and then normalized
to 0∼1 on each depth map. To enable multi-dataset joint
training, we adopt the affine-invariant loss to ignore the
unknown scale and shift of each sample:
Ll =
1
HW
HW
X
i=1
ρ(d∗
i , di),
(1)
where d∗
i and di are the prediction and ground truth, respec-
tively. And ρ is the affine-invariant mean absolute error loss:
ρ(d∗
i , di) = | ˆd∗
i − ˆdi|, where ˆd∗
i and ˆdi are the scaled and
shifted versions of the prediction d∗
i and ground truth di:
ˆdi = di − t(d)
s(d)
,
(2)
where t(d) and s(d) are used to align the prediction and
ground truth to have zero translation and unit scale:
t(d) = median(d), s(d) =
1
HW
HW
X
i=1
|di − t(d)|.
(3)
To obtain a robust monocular depth estimation model, we
collect 1.5M labeled images from 6 public datasets. Details
of these datasets are listed in Table 1. We use fewer labeled
datasets than MiDaS v3.1 [5] (12 training datasets), because
1) we do not use NYUv2 [54] and KITTI [18] datasets to
ensure zero-shot evaluation on them, 2) some datasets are
not available (anymore), e.g., Movies [45] and WSVD [60],
and 3) some datasets exhibit poor quality, e.g., RedWeb (also
low resolution) [66]. Despite using fewer labeled images,
Dataset
Indoor
Outdoor
Label
# Images
Labeled Datasets
BlendedMVS [76]
✓
✓
Stereo
115K
DIML [13]
✓
✓
Stereo
927K
HRWSI [67]
✓
✓
Stereo
20K
IRS [61]
✓
Stereo
103K
MegaDepth [33]
✓
SfM
128K
TartanAir [62]
✓
✓
Stereo
306K
Unlabeled Datasets
BDD100K [81]
✓
None
8.2M
Google Landmarks [64]
✓
None
4.1M
ImageNet-21K [49]
✓
✓
None
13.1M
LSUN [80]
✓
None
9.8M
Objects365 [52]
✓
✓
None
1.7M
Open Images V7 [30]
✓
✓
None
7.8M
Places365 [87]
✓
✓
None
6.5M
SA-1B [27]
✓
✓
None
11.1M
Table 1. In total, our Depth Anything is trained on 1.5M labeled
images and 62M unlabeled images jointly.
our easy-to-acquire and diverse unlabeled images will com-
prehend the data coverage and greatly enhance the model
generalization ability and robustness.
Furthermore, to strengthen the teacher model T learned
from these labeled images, we adopt the DINOv2 [42] pre-
trained weights to initialize our encoder. In practice, we
apply a pre-trained semantic segmentation model [69] to de-
tect the sky region, and set its disparity value as 0 (farthest).
3.2. Unleashing the Power of Unlabeled Images
This is the main point of our work. Distinguished from prior
works that laboriously construct diverse labeled datasets,
we highlight the value of unlabeled images in enhancing
the data coverage. Nowadays, we can practically build a
diverse and large-scale unlabeled set from the Internet or
public datasets of various tasks. Also, we can effortlessly
obtain the dense depth map of monocular unlabeled images
simply by forwarding them to a pre-trained well-performed
MDE model. This is much more convenient and efficient
than performing stereo matching or SfM reconstruction for
stereo images or videos. We select eight large-scale public
datasets as our unlabeled sources for their diverse scenes.
They contain more than 62M images in total. The details are
provided in the bottom half of Table 1.
Technically, given the previously obtained MDE teacher
model T, we make predictions on the unlabeled set Du to
obtain a pseudo labeled set ˆDu:
ˆDu = {(ui, T(ui))|ui ∈ Du}N
i=1.
(4)
With the combination set Dl ∪ ˆ
Du of labeled images and
pseudo labeled images, we train a student model S on it.
3
labeled image
unlabeled image
encoder
decoder
manual label
pseudo label
encoder
teacher
model
LiDAR, 
matching, 
SfM, etc
semantic
preservation
labeled prediction
unlabeled prediction
sup
sup
HRWSI: 102684_LookInStereoDotComDSCF0486
SA1B: sa_10000139
S
feature 
alignment
Figure 2. Our pipeline. Solid line: flow of labeled images, dotted line: unlabeled images. We especially highlight the value of large-scale
unlabeled images. The S denotes adding strong perturbations (Section 3.2). To equip our depth estimation model with rich semantic priors,
we enforce an auxiliary constraint between the online student model and a frozen encoder to preserve the semantic capability (Section 3.3).
Following prior works [73], instead of fine-tuning S from T,
we re-initialize S for better performance.
Unfortunately, in our pilot studies, we failed to gain im-
provements with such a self-training pipeline, which indeed
contradicts the observations when there are only a few la-
beled images [55]. We conjecture that, with already suffi-
cient labeled images in our case, the extra knowledge ac-
quired from additional unlabeled images is rather limited.
Especially considering the teacher and student share the
same pre-training and architecture, they tend to make similar
correct or false predictions on the unlabeled set Du, even
without the explicit self-training procedure.
To address the dilemma, we propose to challenge the stu-
dent with a more difficult optimization target for additional
visual knowledge on unlabeled images. We inject strong per-
turbations to unlabeled images during training. It compels
our student model to actively seek extra visual knowledge
and acquire invariant representations from these unlabeled
images. These advantages help our model deal with the open
world more robustly. We introduce two forms of perturba-
tions: one is strong color distortions, including color jittering
and Gaussian blurring, and the other is strong spatial dis-
tortion, which is CutMix [83]. Despite the simplicity, the
two modifications make our large-scale unlabeled images
significantly improve the baseline of labeled images.
We provide more details about CutMix. It was originally
proposed for image classification, and is rarely explored in
monocular depth estimation. We first interpolate a random
pair of unlabeled images ua and ub spatially:
uab = ua ⊙ M + ub ⊙ (1 − M),
(5)
where M is a binary mask with a rectangle region set as 1.
The unlabeled loss Lu is obtained by first computing
affine-invariant losses in valid regions defined by M and
1 − M, respectively:
LM
u = ρ
Method
Encoder
KITTI [18]
NYUv2 [54]
Sintel [7]
DDAD [20]
ETH3D [51]
DIODE [59]
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
MiDaS v3.1 [5]
ViT-L
0.127
0.850
0.048
0.980
0.587
0.699
0.251
0.766
0.139
0.867
0.075
0.942
Depth Anything
ViT-S
0.080
0.936
0.053
0.972
0.464
0.739
0.247
0.768
0.127
0.885
0.076
0.939
ViT-B
0.080
0.939
0.046
0.979
0.432
0.756
0.232
0.786
0.126
0.884
0.069
0.946
ViT-L
0.076
0.947
0.043
0.981
0.458
0.760
0.230
0.789
0.127
0.882
0.066
0.952
Table 2. Zero-shot relative depth estimation. Better: AbsRel ↓ , δ1 ↑. We compare with the best model from MiDaS v3.1. Note that MiDaS
does not strictly follow the zero-shot evaluation on KITTI and NYUv2, because it uses their training images. We provide three model scales
for different purposes, based on ViT-S (24.8M), ViT-B (97.5M), and ViT-L (335.3M), respectively. Best, second best results.
depth model with an auxiliary feature alignment loss. The
feature space is high-dimensional and continuous, thus con-
taining richer semantic information than discrete masks. The
feature alignment loss is formulated as:
Lfeat = 1 −
1
HW
HW
X
i=1
cos(fi, f ′
i),
(9)
where cos(·, ·) measures the cosine similarity between two
feature vectors. f is the feature extracted by the depth model
S, while f ′ is the feature from a frozen DINOv2 encoder.
We do not follow some works [19] to project the online
feature f into a new space for alignment, because a randomly
initialized projector makes the large alignment loss dominate
the overall loss in the early stage.
Another key point in feature alignment is that, semantic
encoders like DINOv2 tend to produce similar features for
different parts of an object, e.g., car front and rear. In depth
estimation, however, different parts or even pixels within the
same part, can be of varying depth. Thus, it is not beneficial
to exhaustively enforce our depth model to produce exactly
the same features as the frozen encoder.
To solve this issue, we set a tolerance margin α for the
feature alignment. If the cosine similarity of fi and f ′
i has
surpassed α, this pixel will not be considered in our Lfeat.
This allows our method to enjoy both the semantic-aware
representation from DINOv2 and the part-level discrimina-
tive representation from depth supervision. As a side effect,
our produced encoder not only performs well in downstream
MDE datasets, but also achieves strong results in the seman-
tic segmentation task. It also indicates the potential of our
encoder to serve as a universal multi-task encoder for both
middle-level and high-level perception tasks.
Finally, our overall loss is an average combination of the
three losses Ll, Lu, and Lfeat.
4. Experiment
4.1. Implementation Details
We adopt the DINOv2 encoder [42] for feature extraction.
Following MiDaS [5, 45], we use the DPT [46] decoder for
depth regression. All labeled datasets are simply combined
together without re-sampling. In the first stage, we train a
teacher model on labeled images for 20 epochs. In the second
stage of joint training, we train a student model to sweep
across all unlabeled images for one time. The unlabeled
images are annotated by a best-performed teacher model
with a ViT-L encoder. The ratio of labeled and unlabeled
images is set as 1:2 in each batch. In both stages, the base
learning rate of the pre-trained encoder is set as 5e-6, while
the randomly initialized decoder uses a 10× larger learning
rate. We use the AdamW optimizer and decay the learning
rate with a linear schedule. We only apply horizontal flipping
as our data augmentation for labeled images. The tolerance
margin α for feature alignment loss is set as 0.15. For more
details, please refer to our appendix.
4.2. Zero-Shot Relative Depth Estimation
As aforementioned, this work aims to provide accurate
depth estimation for any image. Therefore, we compre-
hensively validate the zero-shot depth estimation capability
of our Depth Anything model on six representative unseen
datasets: KITTI [18], NYUv2 [54], Sintel [7], DDAD [20],
ETH3D [51], and DIODE [59]. We compare with the best
DPT-BEiTL-512 model from the latest MiDaS v3.1 [5], which
uses more labeled images than us. As shown in Table 2,
both with a ViT-L encoder, our Depth Anything surpasses
the strongest MiDaS model tremendously across extensive
scenes in terms of both the AbsRel (absolute relative error:
|d∗ −d|/d) and δ1 (percentage of max(d∗/d, d/d∗) < 1.25)
metrics. For example, when tested on the well-known au-
tonomous driving dataset DDAD [20], we improve the Ab-
sRel (↓) from 0.251 → 0.230 and improve the δ1 (↑) from
0.766 → 0.789.
Besides, our ViT-B model is already clearly superior to
the MiDaS based on a much larger ViT-L. Moreover, our
ViT-S model, whose scale is less than 1/10 of the MiDaS
model, even outperforms MiDaS on several unseen datasets,
including Sintel, DDAD, and ETH3D. The performance
advantage of these small-scale models demonstrates their
great potential in computationally-constrained scenarios.
It is also worth noting that, on the most widely used MDE
5
Method
Higher is better ↑
Lower is better ↓
δ1
δ2
δ3
AbsRel
RMSE
log10
AdaBins [3]
0.903
0.984
0.997
0.103
0.364
0.044
DPT [46]
0.904
0.988
0.998
0.110
0.357
0.045
P3Depth [43]
0.898
0.981
0.996
0.104
0.356
0.043
SwinV2-L [39]
0.949
0.994
0.999
0.083
0.287
0.035
AiT [41]
0.954
0.994
0.999
0.076
0.275
0.033
VPD [86]
0.964
0.995
0.999
0.069
0.254
0.030
ZoeDepth∗ [4]
0.951
0.994
0.999
0.077
0.282
0.033
Ours
0.984
0.998
1.000
0.056
0.206
0.024
Table 3. Fine-tuning and evaluating on NYUv2 [54] with our
pre-trained MDE encoder. We highlight best, second best results,
as well as most discriminative metrics. ∗: Reproduced by us.
benchmarks KITTI and NYUv2, although MiDaS v3.1 uses
the corresponding training images (not zero-shot anymore),
our Depth Anything is still evidently superior to it without
training with any KITTI or NYUv2 images, e.g., 0.127 vs.
0.076 in AbsRel and 0.850 vs. 0.947 in δ1 on KITTI.
4.3. Fine-tuned to Metric Depth Estimation
Apart from the impressive performance in zero-shot relative
depth estimation, we further examine our Depth Anything
model as a promising weight initialization for downstream
metric depth estimation. We initialize the encoder of down-
stream MDE models with our pre-trained encoder parameters
and leave the decoder randomly initialized. The model is
fine-tuned with correponding metric depth information. In
this part, we use our ViT-L encoder for fine-tuning.
We examine two representative scenarios: 1) in-domain
metric depth estimation, where the model is trained and
evaluated on the same domain (Section 4.3.1), and 2) zero-
shot metric depth estimation, where the model is trained on
one domain, e.g., NYUv2 [54], but evaluated in different
domains, e.g., SUN RGB-D [56] (Section 4.3.2).
4.3.1
In-Domain Metric Depth Estimation
As shown in Table 3 of NYUv2 [54], our model outperforms
the previous best method VPD [86] remarkably, improving
the δ1 (↑) from 0.964 → 0.984 and AbsRel (↓) from 0.069
to 0.056. Similar improvements can be observed in Table 4
of the KITTI dataset [18]. We improve the δ1 (↑) on KITTI
from 0.978 → 0.982. It is worth noting that we adopt the
ZoeDepth framework for this scenario with a relatively ba-
sic depth model, and we believe our results can be further
enhanced if equipped with more advanced architectures.
4.3.2
Zero-Shot Metric Depth Estimation
We follow ZoeDepth [4] to conduct zero-shot metric depth
estimation. ZoeDepth fine-tunes the MiDaS pre-trained en-
Method
Higher is better ↑
Lower is better ↓
δ1
δ2
δ3
AbsRel
RMSE
RMSE log
AdaBins [3]
0.964
0.995
0.999
0.058
2.360
0.088
DPT [46]
0.959
0.995
0.999
0.062
2.573
0.092
P3Depth [43]
0.953
0.993
0.998
0.071
2.842
0.103
NeWCRFs [82]
0.974
0.997
0.999
0.052
2.129
0.079
SwinV2-L [39]
0.977
0.998
1.000
0.050
1.966
0.075
NDDepth [53]
0.978
0.998
0.999
0.050
2.025
0.075
GEDepth [75]
0.976
0.997
0.999
0.048
2.044
0.076
ZoeDepth∗ [4]
0.971
0.996
0.999
0.054
2.281
0.082
Ours
0.982
0.998
1.000
0.046
1.896
0.069
Table 4. Fine-tuning and evaluating on KITTI [18] with our
pre-trained MDE encoder. ∗: Reproduced by us.
coder with metric depth information from NYUv2 [54] (for
indoor scenes) or KITTI [18] (for outdoor scenes). There-
fore, we simply replace the MiDaS encoder with our bet-
ter Depth Anything encoder, leaving other components un-
changed. As shown in Table 5, across a wide range of unseen
datasets of indoor and outdoor scenes, our Depth Anything
results in a better metric depth estimation model than the
original ZoeDepth based on MiDaS.
4.4. Fine-tuned to Semantic Segmentation
In our method, we design our MDE model to inherit the
rich semantic priors from a pre-trained encoder via a sim-
ple feature alignment constraint. Here, we examine the
semantic capability of our MDE encoder. Specifically, we
fine-tune our MDE encoder to downstream semantic segmen-
tation datasets. As exhibited in Table 7 of the Cityscapes
dataset [15], our encoder from large-scale MDE training
(86.2 mIoU) is superior to existing encoders from large-scale
ImageNet-21K pre-training, e.g., Swin-L [38] (84.3) and
ConvNeXt-XL [40] (84.6). Similar observations hold on the
ADE20K dataset [88] in Table 8. We improve the previous
best result from 58.3 → 59.4.
We hope to highlight that, witnessing the superiority of
our pre-trained encoder on both monocular depth estimation
and semantic segmentation tasks, we believe it has great
potential to serve as a generic multi-task encoder for both
middle-level and high-level visual perception systems.
4.5. Ablation Studies
Unless otherwise specified, we use the ViT-L encoder for
our ablation studies here.
Zero-shot transferring of each training dataset. In Ta-
ble 6, we provide the zero-shot transferring performance of
each training dataset, which means that we train a relative
MDE model on one training set and evaluate it on the six
unseen datasets. With these results, we hope to offer more
insights for future works that similarly aim to build a general
6
Method
SUN RGB-D [56]
iBims-1 [29]
HyperSim [48]
Virtual KITTI 2 [8]
DIODE Outdoor [59]
AbsRel (↓)
δ1 (↑)
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
ZoeDepth [4]
0.520
0.545
0.169
0.656
0.407
0.302
0.106
0.844
0.814
0.237
Depth Anything
0.500
0.660
0.150
0.714
0.363
0.361
0.085
0.913
0.794
0.288
Table 5. Zero-shot metric depth estimation. The first three test sets in the header are indoor scenes, while the last two are outdoor scenes.
Following ZoeDepth, we use the model trained on NYUv2 for indoor generalization, while use the model trained on KITTI for outdoor
evaluation. For fair comparisons, we report the ZoeDepth results reproduced in our environment.
Training set
KITTI [18]
NYUv2 [54]
Sintel [7]
DDAD [20]
ETH3D [51]
DIODE [59]
Mean
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
AbsRel
δ1
BlendedMVS [76]
0.089
0.918
0.068
0.958
0.556
0.689
0.305
0.731
0.148
0.845
0.092
0.921
0.210
0.844
DIML [13]
0.099
0.907
0.055
0.969
0.573
0.722
0.381
0.657
0.142
0.859
0.107
0.908
0.226
0.837
HRWSI [67]
0.095
0.917
0.062
0.966
0.502
0.731
0.270
0.750
0.186
0.775
0.087
0.935
0.200
0.846
IRS [61]
0.105
0.892
0.057
0.970
0.568
0.714
0.328
0.691
0.143
0.845
0.088
0.926
0.215
0.840
MegaDepth [33]
0.217
0.741
0.071
0.953
0.632
0.660
0.479
0.566
0.142
0.852
0.104
0.910
0.274
0.780
TartanAir [62]
0.088
0.920
0.061
0.964
0.602
0.723
0.332
0.690
0.160
0.818
0.088
0.928
0.222
0.841
All labeled data
0.085
0.934
0.053
0.971
0.492
0.748
0.245
0.771
0.134
0.874
0.070
0.945
0.180
0.874
Table 6. Examine the zero-shot transferring performance of each labeled training set (left) to six unseen datasets (top). Better performance:
AbsRel ↓ , δ1 ↑. We highlight the best, second, and third best results for each test dataset in bold, underline, and italic, respectively.
Method
Encoder
mIoU (s.s.)
m.s.
Segmenter [57]
ViT-L [16]
-
82.2
SegFormer [69]
MiT-B5 [69]
82.4
84.0
Mask2Former [12]
Swin-L [38]
83.3
84.3
OneFormer [24]
Swin-L [38]
83.0
84.4
OneFormer [24]
ConvNeXt-XL [40]
83.6
84.6
DDP [25]
ConvNeXt-L [40]
83.2
83.9
Ours
ViT-L [16]
84.8
86.2
Table 7. Transferring our MDE pre-trained encoder to Cityscapes
for semantic segmentation. We do not use Mapillary [1] for pre-
training. s.s./m.s.: single-/multi-scale evaluation.
monocular depth estimation system. Among the six training
datasets, HRWSI [67] fuels our model with the strongest
generalization ability, even though it only contains 20K im-
ages. This indicates the data diversity counts a lot, which
is well aligned with our motivation to utilize unlabeled im-
ages. Some labeled datasets may not perform very well, e.g.,
MegaDepth [33], however, it has its own preferences that
are not reflected in these six test datasets. For example, we
find models trained with MegaDepth data are specialized at
estimating the distance of ultra-remote buildings (Figure 1),
which will be very beneficial for aerial vehicles.
Effectiveness of 1) challenging the student model when
learning unlabeled images, and 2) semantic constraint.
As shown in Table 9, simply adding unlabeled images with
pseudo labels does not necessarily bring gains to our model,
Method
Encoder
mIoU
Segmenter [57]
ViT-L [16]
51.8
SegFormer [69]
MiT-B5 [69]
51.0
Mask2Former [12]
Swin-L [38]
56.4
UperNet [68]
BEiT-L [2]
56.3
ViT-Adapter [11]
BEiT-L [2]
58.3
OneFormer [24]
Swin-L [38]
57.4
OneFormer [24]
ConNeXt-XL [40]
57.4
Ours
ViT-L [16]
59.4
Table 8. Transferring our MDE encoder to ADE20K for semantic
segmentation. We use Mask2Former as our segmentation model.
since the labeled images are already sufficient. However,
with strong perturbations (S) applied to unlabeled images
during re-training, the student model is challenged to seek
additional visual knowledge and learn more robust repre-
sentations. Consequently, the large-scale unlabeled images
enhance the model generalization ability significantly.
Moreover, with our used semantic constraint Lfeat, the
power of unlabeled images can be further amplified for the
depth estimation task. More importantly, as emphasized in
Section 4.4, this auxiliary constraint also enables our trained
encoder to serve as a key component in a multi-task visual
system for both middle-level and high-level perception.
Comparison with MiDaS trained encoder in downstream
tasks. Our Depth Anything model has exhibited stronger
zero-shot capability than MiDaS [5, 45]. Here, we further
7
Figure 3. Qualitative results on six unseen datasets.
Ll Lu
S
Lfeat
KI
NY
SI
DD
ET
DI
✓
0.085 0.053 0.492 0.245 0.134 0.070
✓
✓
0.085 0.054 0.481 0.242 0.138 0.073
✓
✓
✓
0.081 0.048 0.469 0.235 0.134 0.068
✓
✓
✓
✓
0.076 0.043 0.458 0.230 0.127 0.066
Table 9. Ablation studies of: 1) challenging the student with strong
perturbations (S) when learning unlabeled images, and 2) semantic
constraint (Lfeat). Limited by space, we only report the AbsRel
(↓) metric, and shorten the dataset name with its first two letters.
Method
NYUv2
KITTI
Cityscapes ADE20K
AbsRel
δ1
AbsRel
δ1
mIoU
mIoU
MiDaS
0.077
0.951
0.054
0.971
82.1
52.4
Ours
0.056
0.984
0.046
0.982
84.8
59.4
Table 10. Comparison between our trained encoder and MiDaS [5]
trained encoder in terms of downstream fine-tuning performance.
Better performance: AbsRel ↓ , δ1 ↑ , mIoU ↑ .
compare our trained encoder with MiDaS v3.1 [5] trained
encoder in terms of the downstream fine-tuning performance.
As demonstrated in Table 10, on both the downstream depth
estimation task and semantic segmentation task, our pro-
duced encoder outperforms the MiDaS encoder remarkably,
e.g., 0.951 vs. 0.984 in the δ1 metric on NYUv2, and 52.4
vs. 59.4 in the mIoU metric on ADE20K.
Comparison with DINOv2 in downstream tasks. We have
demonstrated the superiority of our trained encoder when
fine-tuned to downstream tasks. Since our finally produced
encoder (from large-scale MDE training) is fine-tuned from
DINOv2 [42], we compare our encoder with the original
DINOv2 encoder in Table 11. It can be observed that our
encoder performs better than the original DINOv2 encoder
in both the downstream metric depth estimation task and
semantic segmentation task. Although the DINOv2 weight
has provided a very strong initialization (also much better
than the MiDaS encoder as reported in Table 10), our large-
scale and high-quality MDE training can further enhance it
Ours
MiDaS
Ours
MiDaS
Figure 4. We compare our depth prediction with MiDaS. Meantime,
we use ControlNet to synthesize new images from the depth map
(the last row). First row: input image, second row: depth prediction.
Encoder
NYUv2
KITTI
ADE20K
AbsRel (↓)
δ1 (↑)
AbsRel
δ1
mIoU (↑)
DINOv2
0.066
0.973
0.058
0.971
58.8
Ours
0.056
0.984
0.046
0.982
59.4
Table 11. Comparison between the original DINOv2 and our pro-
duced encoder in terms of downstream fine-tuning performance.
impressively in downstream transferring performance.
4.6. Qualitative Results
We visualize our model predictions on the six unseen datasets
in Figure 3. Our model is robust to test images from various
domains. In addition, we compare our model with MiDaS
in Figure 4. We also attempt to synthesis new images con-
ditioned on the predicted depth maps with ControlNet [84].
Our model produces more accurate depth estimation than
MiDaS, as well as better synthesis results, although the Con-
trolNet is trained with MiDaS depth. For more accurate
synthesis, we have also re-trained a better depth-conditioned
ControlNet based on our Depth Anything, aiming to pro-
vide better control signals for image synthesis and video
editing. Please refer to our project page or the following
supplementary material for more qualitative results,
5. Conclusion
In this work, we present Depth Anything, a highly practical
solution to robust monocular depth estimation. Different
from prior arts, we especially highlight the value of cheap
and diverse unlabeled images. We design two simple yet
highly effective strategies to fully exploit their value: 1)
posing a more challenging optimization target when learning
unlabeled images, and 2) preserving rich semantic priors
from pre-trained models. As a result, our Depth Anything
model exhibits excellent zero-shot depth estimation ability,
and also serves as a promising initialization for downstream
metric depth estimation and semantic segmentation tasks.
8
Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data
Supplementary Material
6. More Implementation Details
We resize the shorter side of all images to 518 and keep the
original aspect ratio. All images are cropped to 518×518
during training. During inference, we do not crop images
and only ensure both sides are multipliers of 14, since the
pre-defined patch size of DINOv2 encoders [42] is 14. Eval-
uation is performed at the original resolution by interpolating
the prediction. Following MiDaS [5, 45], in zero-shot eval-
uation, the scale and shift of our prediction are manually
aligned with the ground truth.
When fine-tuning our pre-trained encoder to metric depth
estimation, we adopt the ZoeDepth codebase [4]. We merely
replace the original MiDaS-based encoder with our stronger
Depth Anything encoder, with a few hyper-parameters mod-
ified. Concretely, the training resolution is 392×518 on
NYUv2 [54] and 384×768 on KITTI [18] to match the
patch size of our encoder. The encoder learning rate is
set as 1/50 of the learning rate of the randomly initialized
decoder, which is much smaller than the 1/10 adopted for
MiDaS encoder, due to our strong initialization. The batch
size is 16 and the model is trained for 5 epochs.
When fine-tuning our pre-trained encoder to semantic seg-
mentation, we use the MMSegmentation codebase [14]. The
training resolution is set as 896×896 on both ADE20K [88]
and Cityscapes [15]. The encoder learning rate is set as
3e-6 and the decoder learning rate is 10× larger. We use
Mask2Former [12] as our semantic segmentation model. The
model is trained for 160K iterations on ADE20K and 80K
iterations on Cityscapes both with batch size 16, without
any COCO [35] or Mapillary [1] pre-training. Other training
configurations are the same as the original codebase.
7. More Ablation Studies
All ablation studies here are conducted on the ViT-S model.
The necessity of tolerance margin for feature alignment.
As shown in Table 12, the gap between the tolerance margin
of 0 and 0.15 or 0.30 clearly demonstrates the necessity of
this design (mean AbsRel: 0.188 vs. 0.175).
Applying feature alignment to labeled data. Previously,
we enforce the feature alignment loss Lfeat on unlabeled
data. Indeed, it is technically feasible to also apply this
constraint to labeled data. In Table 13, apart from applying
Lfeat on unlabeled data, we explore to apply it to labeled
data. We find that adding this auxiliary optimization target
to labeled data is not beneficial to our baseline that does not
involve any feature alignment (their mean AbsRel values are
almost the same: 0.180 vs. 0.179). We conjecture that this is
α
KITTI NYU Sintel DDAD ETH3D DIODE Mean
0.00
0.085
0.055 0.523
0.250
0.134
0.079
0.188
0.15
0.080
0.053 0.464
0.247
0.127
0.076
0.175
0.30
0.079
0.054 0.482
0.248
0.127
0.077
0.178
Table 12. Ablation studies on different values of the tolerance
margin α for the feature alignment loss Lfeat. Limited by space,
we only report the AbsRel (↓) metric here.
Lfeat
Unseen datasets (AbsRel ↓)
Mean
U
L
KITTI NYU Sintel DDAD ETH3D DIODE
0.083
0.055 0.478
0.249
0.133
0.080
0.180
✓
0.080
0.053 0.464
0.247
0.127
0.076
0.175
✓
0.084
0.054 0.472
0.252
0.133
0.081
0.179
Table 13. Ablation studies of applying our feature alignment loss
Lfeat to unlabeled data (U) or labeled data (L).
because the labeled data has relatively higher-quality depth
annotations. The involvement of semantic loss may interfere
with the learning of these informative manual labels. In com-
parison, our pseudo labels are noisier and less informative.
Therefore, introducing the auxiliary constraint to unlabeled
data can combat the noise in pseudo depth labels, as well as
arm our model with semantic capability.
8. Limitations and Future Works
Currently, the largest model size is only constrained to ViT-
Large [16]. Therefore, in the future, we plan to further scale
up the model size from ViT-Large to ViT-Giant, which is
also well pre-trained by DINOv2 [42]. We can train a more
powerful teacher model with the larger model, producing
more accurate pseudo labels for smaller models to learn, e.g.,
ViT-L and ViT-B. Furthermore, to facilitate real-world ap-
plications, we believe the widely adopted 512×512 training
resolution is not enough. We plan to re-train our model on a
larger resolution of 700+ or even 1000+.
9. More Qualitative Results
Please refer to the following pages for comprehensive quali-
tative results on six unseen test sets (Figure 5 for KITTI [18],
Figure 6 for NYUv2 [54], Figure 7 for Sintel [7], Figure 8
for DDAD [20], Figure 9 for ETH3D [51], and Figure 10
for DIODE [59]). We compare our model with the strongest
MiDaS model [5], i.e., DPT-BEiTL-512. Our model exhibits
higher depth estimation accuracy and stronger robustness.
9
Input image
Our prediction
MiDaS v3.1 prediction
Figure 5. Qualitative results on KITTI. Due to the extremely sparse ground truth which is hard to visualize, we here compare our prediction
with the most advanced MiDaS v3.1 [5] prediction. The brighter color denotes the closer distance.
10
Input image
Our prediction
MiDaS v3.1 prediction
Figure 6. Qualitative results on NYUv2. It is worth noting that MiDaS [5] uses NYUv2 training data (not zero-shot), while we do not.
11
Input image
Our prediction
MiDaS v3.1 prediction
Figure 7. Qualitative results on Sintel.
12
Input image
Our prediction
MiDaS v3.1 prediction
Figure 8. Qualitative results on DDAD.
13
Input image
Our prediction
MiDaS v3.1 prediction
Figure 9. Qualitative results on ETH3D.
14
Input image
Our prediction
MiDaS v3.1 prediction
Figure 10. Qualitative results on DIODE.
15
References
[1] Manuel L´opez Antequera, Pau Gargallo, Markus Hofinger,
Samuel Rota Bul`o, Yubin Kuang, and Peter Kontschieder.
Mapillary planet-scale depth dataset. In ECCV, 2020. 7, 9
[2] Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei. Beit:
Bert pre-training of image transformers. In ICLR, 2022. 7
[3] Shariq Farooq Bhat, Ibraheem Alhashim, and Peter Wonka.
Adabins: Depth estimation using adaptive bins. In CVPR,
2021. 2, 6
[4] Shariq Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka,
and Matthias M¨uller. Zoedepth: Zero-shot transfer by com-
bining relative and metric depth. arXiv:2302.12288, 2023. 2,
6, 7, 9
[5] Reiner Birkl, Diana Wofk, and Matthias M¨uller. Midas v3.
1–a model zoo for robust monocular relative depth estimation.
arXiv:2307.14460, 2023. 2, 3, 5, 7, 8, 9, 10, 11
[6] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ
Altman, Simran Arora, Sydney von Arx, Michael S Bern-
stein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill,
et al. On the opportunities and risks of foundation models.
arXiv:2108.07258, 2021. 1
[7] Daniel J Butler, Jonas Wulff, Garrett B Stanley, and Michael J
Black. A naturalistic open source movie for optical flow
evaluation. In ECCV, 2012. 5, 7, 9
[8] Yohann Cabon, Naila Murray, and Martin Humenberger. Vir-
tual kitti 2. arXiv:2001.10773, 2020. 7
[9] Po-Yi Chen, Alexander H Liu, Yen-Cheng Liu, and Yu-
Chiang Frank Wang.
Towards scene understanding: Un-
supervised monocular depth estimation with semantic-aware
representation. In CVPR, 2019. 2, 4
[10] Weifeng Chen, Zhao Fu, Dawei Yang, and Jia Deng. Single-
image depth perception in the wild. In NeurIPS, 2016. 2
[11] Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong
Lu, Jifeng Dai, and Yu Qiao. Vision transformer adapter for
dense predictions. In ICLR, 2023. 7
[12] Bowen Cheng, Ishan Misra, Alexander G Schwing, Alexander
Kirillov, and Rohit Girdhar. Masked-attention mask trans-
former for universal image segmentation. In CVPR, 2022. 7,
9
[13] Jaehoon Cho, Dongbo Min, Youngjung Kim, and Kwanghoon
Sohn. Diml/cvl rgb-d dataset: 2m rgb-d images of natural
indoor and outdoor scenes. arXiv:2110.11590, 2021. 3, 7
[14] MMSegmentation
Contributors.
MMSegmenta-
tion:
Openmmlab
semantic
segmentation
toolbox
and benchmark.
https : / / github . com / open -
mmlab/mmsegmentation, 2020. 9
[15] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo
Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke,
Stefan Roth, and Bernt Schiele. The cityscapes dataset for
semantic urban scene understanding. In CVPR, 2016. 1, 6, 9
[16] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. In ICLR, 2021. 7,
9
[17] David Eigen, Christian Puhrsch, and Rob Fergus. Depth
map prediction from a single image using a multi-scale deep
network. In NeurIPS, 2014. 2
[18] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel
Urtasun. Vision meets robotics: The kitti dataset. IJRR, 2013.
1, 2, 3, 5, 6, 7, 9
[19] Jean-Bastien Grill, Florian Strub, Florent Altch´e, Corentin
Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doer-
sch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Ghesh-
laghi Azar, et al. Bootstrap your own latent-a new approach
to self-supervised learning. In NeurIPS, 2020. 5
[20] Vitor Guizilini, Rares Ambrus, Sudeep Pillai, Allan Raventos,
and Adrien Gaidon. 3d packing for self-supervised monocular
depth estimation. In CVPR, 2020. 5, 7, 9
[21] Vitor Guizilini, Rui Hou, Jie Li, Rares Ambrus, and Adrien
Gaidon. Semantically-guided representation learning for self-
supervised monocular depth. In ICLR, 2020. 2, 4
[22] Vitor Guizilini, Igor Vasiljevic, Dian Chen, Rares, Ambrus,,
and Adrien Gaidon. Towards zero-shot scale-aware monocu-
lar depth estimation. In ICCV, 2023. 2
[23] Derek Hoiem, Alexei A Efros, and Martial Hebert. Recover-
ing surface layout from an image. IJCV, 2007. 2
[24] Jitesh Jain, Jiachen Li, Mang Tik Chiu, Ali Hassani, Nikita
Orlov, and Humphrey Shi. Oneformer: One transformer to
rule universal image segmentation. In CVPR, 2023. 7
[25] Yuanfeng Ji, Zhe Chen, Enze Xie, Lanqing Hong, Xihui Liu,
Zhaoqiang Liu, Tong Lu, Zhenguo Li, and Ping Luo. Ddp:
Diffusion model for dense visual prediction. In ICCV, 2023.
7
[26] Lei Ke, Mingqiao Ye, Martin Danelljan, Yifan Liu, Yu-Wing
Tai, Chi-Keung Tang, and Fisher Yu. Segment anything in
high quality. In NeurIPS, 2023. 4
[27] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao,
Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White-
head, Alexander C Berg, Wan-Yen Lo, et al. Segment any-
thing. In ICCV, 2023. 1, 2, 3
[28] Marvin Klingner, Jan-Aike Term¨ohlen, Jonas Mikolajczyk,
and Tim Fingscheidt. Self-supervised monocular depth es-
timation: Solving the dynamic object problem by semantic
guidance. In ECCV, 2020. 4
[29] Tobias Koch, Lukas Liebel, Friedrich Fraundorfer, and Marco
Korner. Evaluation of cnn-based single-image depth estima-
tion methods. In ECCVW, 2018. 7
[30] Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings,
Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan Popov,
Matteo Malloci, Alexander Kolesnikov, et al. The open im-
ages dataset v4: Unified image classification, object detection,
and visual relationship detection at scale. IJCV, 2020. 2, 3
[31] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient
semi-supervised learning method for deep neural networks.
In ICMLW, 2013. 2
[32] Bo Li, Chunhua Shen, Yuchao Dai, Anton Van Den Hen-
gel, and Mingyi He. Depth and surface normal estimation
from monocular images using regression on deep features and
hierarchical crfs. In CVPR, 2015. 2
[33] Zhengqi Li and Noah Snavely. Megadepth: Learning single-
view depth prediction from internet photos. In CVPR, 2018.
1, 3, 7
16
[34] Zhenyu Li, Xuyang Wang, Xianming Liu, and Junjun Jiang.
Binsformer: Revisiting adaptive bins for monocular depth
estimation. arXiv:2204.00987, 2022. 2
[35] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Doll´ar, and C Lawrence
Zitnick. Microsoft coco: Common objects in context. In
ECCV, 2014. 1, 9
[36] Ce Liu, Jenny Yuen, Antonio Torralba, Josef Sivic, and
William T Freeman. Sift flow: Dense correspondence across
different scenes. In ECCV, 2008. 2
[37] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao
Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun
Zhu, et al. Grounding dino: Marrying dino with grounded
pre-training for open-set object detection. arXiv:2303.05499,
2023. 4
[38] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng
Zhang, Stephen Lin, and Baining Guo. Swin transformer:
Hierarchical vision transformer using shifted windows. In
ICCV, 2021. 6, 7
[39] Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie,
Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, et al.
Swin transformer v2: Scaling up capacity and resolution. In
CVPR, 2022. 6
[40] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feicht-
enhofer, Trevor Darrell, and Saining Xie. A convnet for the
2020s. In CVPR, 2022. 6, 7
[41] Jia Ning, Chen Li, Zheng Zhang, Chunyu Wang, Zigang
Geng, Qi Dai, Kun He, and Han Hu. All in tokens: Unifying
output space of visual tasks via soft token. In ICCV, 2023. 6
[42] Maxime Oquab, Timoth´ee Darcet, Th´eo Moutakanni, Huy Vo,
Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel
Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2:
Learning robust visual features without supervision. TMLR,
2023. 3, 4, 5, 8, 9
[43] Vaishakh Patil, Christos Sakaridis, Alexander Liniger, and
Luc Van Gool. P3depth: Monocular depth estimation with a
piecewise planarity prior. In CVPR, 2022. 6
[44] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning
transferable visual models from natural language supervision.
In ICML, 2021. 1
[45] Ren´e Ranftl, Katrin Lasinger, David Hafner, Konrad
Schindler, and Vladlen Koltun. Towards robust monocular
depth estimation: Mixing datasets for zero-shot cross-dataset
transfer. TPAMI, 2020. 1, 2, 3, 5, 7, 9
[46] Ren´e Ranftl, Alexey Bochkovskiy, and Vladlen Koltun. Vi-
sion transformers for dense prediction. In ICCV, 2021. 5,
6
[47] Alex Rasla and Michael Beyeler. The relative importance
of depth cues and semantic edges for indoor mobility using
simulated prosthetic vision in immersive virtual reality. In
VRST, 2022. 1
[48] Mike Roberts, Jason Ramapuram, Anurag Ranjan, Atulit
Kumar, Miguel Angel Bautista, Nathan Paczan, Russ Webb,
and Joshua M Susskind. Hypersim: A photorealistic synthetic
dataset for holistic indoor scene understanding. In ICCV,
2021. 7
[49] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-
jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,
Aditya Khosla, Michael Bernstein, et al. Imagenet large scale
visual recognition challenge. IJCV, 2015. 3
[50] Ashutosh Saxena, Min Sun, and Andrew Y Ng. Make3d:
Learning 3d scene structure from a single still image. TPAMI,
2008. 2
[51] Thomas Schops, Johannes L Schonberger, Silvano Galliani,
Torsten Sattler, Konrad Schindler, Marc Pollefeys, and An-
dreas Geiger. A multi-view stereo benchmark with high-
resolution images and multi-camera videos. In CVPR, 2017.
5, 7, 9
[52] Shuai Shao, Zeming Li, Tianyuan Zhang, Chao Peng, Gang
Yu, Xiangyu Zhang, Jing Li, and Jian Sun. Objects365: A
large-scale, high-quality dataset for object detection. In ICCV,
2019. 3
[53] Shuwei Shao, Zhongcai Pei, Weihai Chen, Xingming Wu, and
Zhengguo Li. Nddepth: Normal-distance assisted monocular
depth estimation. In ICCV, 2023. 2, 6
[54] Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob
Fergus. Indoor segmentation and support inference from rgbd
images. In ECCV, 2012. 1, 2, 3, 5, 6, 7, 9
[55] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao
Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk,
Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying
semi-supervised learning with consistency and confidence. In
NeurIPS, 2020. 2, 4
[56] Shuran Song, Samuel P Lichtenberg, and Jianxiong Xiao.
Sun rgb-d: A rgb-d scene understanding benchmark suite. In
CVPR, 2015. 6, 7
[57] Robin Strudel, Ricardo Garcia, Ivan Laptev, and Cordelia
Schmid. Segmenter: Transformer for semantic segmentation.
In ICCV, 2021. 7
[58] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Mar-
tinet, Marie-Anne Lachaux, Timoth´ee Lacroix, Baptiste
Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al.
Llama: Open and efficient foundation language models.
arXiv:2302.13971, 2023. 1
[59] Igor Vasiljevic, Nick Kolkin, Shanyi Zhang, Ruotian Luo,
Haochen Wang, Falcon Z Dai, Andrea F Daniele, Mo-
hammadreza Mostajabi, Steven Basart, Matthew R Walter,
et al. Diode: A dense indoor and outdoor depth dataset.
arXiv:1908.00463, 2019. 5, 7, 9
[60] Chaoyang Wang, Simon Lucey, Federico Perazzi, and Oliver
Wang. Web stereo video supervision for depth prediction
from dynamic scenes. In 3DV, 2019. 3
[61] Qiang Wang, Shizhen Zheng, Qingsong Yan, Fei Deng, Kaiy-
ong Zhao, and Xiaowen Chu. Irs: A large naturalistic indoor
robotics stereo dataset to train deep models for disparity and
surface normal estimation. In ICME, 2021. 3, 7
[62] Wenshan Wang, Delong Zhu, Xiangwei Wang, Yaoyu Hu,
Yuheng Qiu, Chen Wang, Yafei Hu, Ashish Kapoor, and
Sebastian Scherer. Tartanair: A dataset to push the limits of
visual slam. In IROS, 2020. 3, 7
[63] Yan Wang, Wei-Lun Chao, Divyansh Garg, Bharath Hariha-
ran, Mark Campbell, and Kilian Q Weinberger. Pseudo-lidar
from visual depth estimation: Bridging the gap in 3d object
detection for autonomous driving. In CVPR, 2019. 1
17
[64] Tobias Weyand, Andre Araujo, Bingyi Cao, and Jack Sim.
Google landmarks dataset v2-a large-scale benchmark for
instance-level recognition and retrieval. In CVPR, 2020. 3
[65] Diana Wofk, Fangchang Ma, Tien-Ju Yang, Sertac Karaman,
and Vivienne Sze. Fastdepth: Fast monocular depth estima-
tion on embedded systems. In ICRA, 2019. 1
[66] Ke Xian, Chunhua Shen, Zhiguo Cao, Hao Lu, Yang Xiao,
Ruibo Li, and Zhenbo Luo. Monocular relative depth per-
ception with web stereo data supervision. In CVPR, 2018. 2,
3
[67] Ke Xian, Jianming Zhang, Oliver Wang, Long Mai, Zhe Lin,
and Zhiguo Cao. Structure-guided ranking loss for single
image depth prediction. In CVPR, 2020. 2, 3, 7
[68] Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and
Jian Sun. Unified perceptual parsing for scene understanding.
In ECCV, 2018. 7
[69] Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar,
Jose M Alvarez, and Ping Luo.
Segformer: Simple and
efficient design for semantic segmentation with transformers.
In NeurIPS, 2021. 3, 7
[70] Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, Lijuan
Wang, Fangyun Wei, Xiang Bai, and Zicheng Liu. End-to-end
semi-supervised object detection with soft teacher. In ICCV,
2021. 2
[71] Xiaogang Xu, Hengshuang Zhao, Vibhav Vineet, Ser-Nam
Lim, and Antonio Torralba. Mtformer: Multi-task learning
via transformer and cross-task reasoning. In ECCV, 2022. 4
[72] I Zeki Yalniz, Herv´e J´egou, Kan Chen, Manohar Paluri, and
Dhruv Mahajan. Billion-scale semi-supervised learning for
image classification. arXiv:1905.00546, 2019. 2
[73] Lihe Yang, Wei Zhuo, Lei Qi, Yinghuan Shi, and Yang Gao.
St++: Make self-training work better for semi-supervised
semantic segmentation. In CVPR, 2022. 4
[74] Lihe Yang, Lei Qi, Litong Feng, Wayne Zhang, and
Yinghuan Shi. Revisiting weak-to-strong consistency in semi-
supervised semantic segmentation. In CVPR, 2023. 2
[75] Xiaodong Yang, Zhuang Ma, Zhiyu Ji, and Zhe Ren. Gedepth:
Ground embedding for monocular depth estimation. In ICCV,
2023. 2, 6
[76] Yao Yao, Zixin Luo, Shiwei Li, Jingyang Zhang, Yufan Ren,
Lei Zhou, Tian Fang, and Long Quan. Blendedmvs: A large-
scale dataset for generalized multi-view stereo networks. In
CVPR, 2020. 3, 7
[77] Wei Yin, Yifan Liu, Chunhua Shen, and Youliang Yan. En-
forcing geometric constraints of virtual normal for depth pre-
diction. In ICCV, 2019. 2
[78] Wei Yin, Chi Zhang, Hao Chen, Zhipeng Cai, Gang Yu, Kaix-
uan Wang, Xiaozhi Chen, and Chunhua Shen. Metric3d:
Towards zero-shot metric 3d prediction from a single image.
In ICCV, 2023. 2
[79] Yurong You, Yan Wang, Wei-Lun Chao, Divyansh Garg, Ge-
off Pleiss, Bharath Hariharan, Mark Campbell, and Kilian Q
Weinberger. Pseudo-lidar++: Accurate depth for 3d object
detection in autonomous driving. In ICLR, 2020. 1
[80] Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas
Funkhouser, and Jianxiong Xiao. Lsun: Construction of a
large-scale image dataset using deep learning with humans in
the loop. arXiv:1506.03365, 2015. 3
[81] Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying
Chen, Fangchen Liu, Vashisht Madhavan, and Trevor Dar-
rell. Bdd100k: A diverse driving dataset for heterogeneous
multitask learning. In CVPR, 2020. 2, 3
[82] Weihao Yuan, Xiaodong Gu, Zuozhuo Dai, Siyu Zhu, and
Ping Tan. New crfs: Neural window fully-connected crfs for
monocular depth estimation. arXiv:2203.01502, 2022. 2, 6
[83] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk
Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regu-
larization strategy to train strong classifiers with localizable
features. In ICCV, 2019. 4
[84] Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding
conditional control to text-to-image diffusion models. In
ICCV, 2023. 8
[85] Youcai Zhang, Xinyu Huang, Jinyu Ma, Zhaoyang Li,
Zhaochuan Luo, Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian
Li, Shilong Liu, et al. Recognize anything: A strong image
tagging model. arXiv:2306.03514, 2023. 4
[86] Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie
Zhou, and Jiwen Lu. Unleashing text-to-image diffusion
models for visual perception. In ICCV, 2023. 6
[87] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva,
and Antonio Torralba. Places: A 10 million image database
for scene recognition. TPAMI, 2017. 3
[88] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Bar-
riuso, and Antonio Torralba. Scene parsing through ade20k
dataset. In CVPR, 2017. 6, 9
[89] Barret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanx-
iao Liu, Ekin Dogus Cubuk, and Quoc Le. Rethinking pre-
training and self-training. In NeurIPS, 2020. 2
18
"
"Identifying and responding to events, particularly disasters, is of utmost importance. Mobile data and network connectivity generate many temporally–and spatially–stamped data. Mobile data can infer human mobility, proximity, and built environments. Satellite imagery can capture changes to built and natural environments. We propose a method to fuse satellite imagery with privacy–enhanced mobile data to improve event inference. Our method can be used for small–scale disaster detection, search and rescue operations, and identifying conflict areas. Our case study demonstrates the effectiveness of the proposed method.nan","Rapid identification and response to breaking events, particularly those that pose a threat to human life such as natural disasters or conflicts, is of paramount importance. The effectiveness of response efforts can be significantly impacted by the speed and accuracy of information gathering, analysis, and dissemination, with the potential to save lives and mitigate damage. However, obtaining such information poses significant challenges due to various factors. For example, there have been instances where news agencies faced difficulties in promptly or completely delivering information about ongoing events due to a scarcity of reporters present in the affected areas Stelter and Cohen [2008]. The ubiquity of mobile devices and the near-constant network connectivity that characterizes our modern era have resulted in the generation of a massive amount of temporally- and spatially-stamped data (hereafter called mobile data). These datasets have been the subject of numerous studies aiming to derive individual human mobility patterns for various applications, including quantifying urban vitality Sulis et al. [2018], modeling epidemic spread Alessandretti [2022], and inferring the activities of individuals Liao et al. [2007]. Simultaneously, the increasing number of orbital satellites has facilitated the collection of high-resolution images, capturing snapshots of geographical areas with sub-daily temporal frequency.nan","nanHistorically, capturing changes in the built and natural environment often involved on-the-ground data collection and analysis Haddad [2011]. Surveys and field observations have been the most traditional method to capture such changes, and continue to be so today in many industries. Prior to the advent of modern satellites, aerial photography taken from aircrafts was another common method to document large-scale changes to the built environment Bewley [2003]. While these two methods of data collection are sufficient for many studies, they (a) lack the immediacy called for in urgent real-time scenarios and (b) tend to miss developments in the absence of the proper equipment or manpower. In the last three decades, new methods of data collection in the built and natural environment have become prominent, including the use of satellite images, GPS traces from mobile devices, and user-generated content from social media platforms Jongman et al. [2015], Ji et al. [2018], Yin et al. [2021]. This literature review aims to provide a comprehensive understanding of current and recent research in the fields of mobile data analysis, satellite imagery, and crowdsourcing, highlighting works that have fused any two of them to assist in the inference task.nan","Our methodology has two modules—one that deals with the analysis of mobile data, and another with that of satellite imagery. In both modules, we discuss relevant preprocessing methods as well as analysis steps to aid in the inference task. Figure 2 shows the high-level steps in preprocessing and analysis of both datasets while also outlining key geospatial analysis processes for the three use cases discussed in the Introduction.
Figure 2. Methodological flowchart; the top bins describe the order of processes employed in this paper, while the bottom outlines key geospatial analysis metrics to carry out the inference taskMobile Data. For mobile data, the general preprocessing workflow is as follows:
(1) Spatial Partitioning
(2) Coordinate Reference System (CRS) Projection
(3) Data FilteringTo avoid wastefulness in computation, we begin by partitioning the mobile data spatially, which we do by drawing a bounding box using four sets of coordinates. In practice, there are several ways to achieve this at scale: Leveraging a geocoding application protocol interface (API) to obtain the coordinates based on an existing point of interest, partitioning by federal and/or state designations such as census tracts, ZIP codes, or county borders, manually typing in a bounding box (i.e., by defining the geographic coordinates of the corners of the box), or obtaining a KMZ file from the National Oceanic and Atmospheric Administration’s Damage Assessment Toolkit. For this effort, we used the last option to derive the centroid coordinates of the affected area around which we drew a 1 km2 bounding square.
Once the data is spatially partitioned, we project coordinates to the appropriate CRS. Different CRSs are designed to accurately represent different aspects of the Earth’s surface. Some are designed to preserve area, while others preserve shape, distance, or direction. In the context of event inference, the optimal choice of CRS should minimize bias in the derived mobility metrics, which may exist due to distortions of distances and areas. Therefore, we use an equal-area projection around UTM Zone 15, which covers the area around our case study.nan","To validate our proposed methodology, we conducted a case study on the EF-1 tornado that hit near Muskogee, Oklahoma on May 15, 2020. This event provided an opportunity to test our approach in a real-world scenario involving a small-scale disaster in a rural region.
After spatially partitioning the GPS traces to include the subset within the bounding box of the tornado, we projected all data to UTM Zone 15 and filtered the data by the logic described in Section . Then, we defined the two weeks before the day of the event (May 2 - May 15) as the before, the day of the event (May 15) as the during, and the week after the event (May 15 - May 22) as the after periods and began exploring the data. Figure 4 visualizes the time series of two metrics, highlighting the periods by color; there are no noticeable changes in the radius of gyration, while the number of extended stays at a given location within the ROI increases sharply the day after the event.nan","We have presented a novel data fusion methodology combining satellite imagery with GPS traces generated from mobile devices. Our approach leverages the strengths of both data types: mobile data provides an approximation of human mobility, proximity to one another, and the built environment, while satellite imagery offers visual insights into physical changes to the built and natural environment. Furthermore, we have demonstrated the case study of a small-scale tornado, showing the promise of our method in identifying anomalies in movement patterns using mobile data, changes to the built environment using satellite imagery, and inferring the cause of both using our fusion methodology.
Our methodology is viable due to the increasing accessibility of commercial data providers specializing in remote sensing and mobile devices. This trend is only expected to continue—the number of active orbital satellites has grown exponentially since 2017 orb [2022], while the percentage of Americans that own a smartphone has risen to 97% mob [2021]. The continued commercialization of such products will enable researchers and practitioners to monitor, categorize, and understand the natural and built environments in ways unimaginable just 50 years ago. We hope our method is a step in this direction, enabling others to pursue endeavors made possible by the fusion of these data sources.nan",Event detection from novel data sources: Leveraging satellite imagery alongside GPS traces,"Ekin Ugurel, Steffen Coenen, Minda Zhou Chen, Cynthia Chen","EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING
SATELLITE IMAGERY ALONGSIDE GPS TRACES
EKIN UGUREL
University of Washington, Seattle, WA
ugurel@uw.edu
STEFFEN COENEN
DKS Associates, Seattle, WA
scoenen@uw.edu
MINDA ZHOU CHEN
University of Washington, Seattle, WA
mindac@uw.edu
CYNTHIA CHEN
University of Washington, Seattle, WA
qzchen@uw.edu
Abstract
Rapid identification and response to breaking events, particularly those that pose a threat to
human life such as natural disasters or conflicts, is of paramount importance.
The prevalence
of mobile devices and the ubiquity of network connectivity has generated a massive amount of
temporally- and spatially-stamped data. Numerous studies have used mobile data to derive in-
dividual human mobility patterns for various applications.
Similarly, the increasing number of
orbital satellites has made it easier to gather high-resolution images capturing a snapshot of a
geographical area in sub-daily temporal frequency. We propose a novel data fusion methodology
integrating satellite imagery with privacy-enhanced mobile data to augment the event inference
task, whether in real-time or historical. In the absence of boots on the ground, mobile data is able
to give an approximation of human mobility, proximity to one another, and the built environment.
On the other hand, satellite imagery can provide visual information on physical changes to the built
and natural environment. The expected use cases for our methodology include small-scale disas-
ter detection (i.e., tornadoes, wildfires, and floods) in rural regions, search and rescue operation
augmentation for lost hikers in remote wilderness areas, and identification of active conflict areas
and population displacement in war-torn states. Our implementation is open-source on GitHub:
https://github.com/ekinugurel/SatMobFusion.
Date: January 22, 2024.
1
arXiv:2401.10890v1  [cs.CV]  19 Jan 2024
2EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
Introduction
In an increasingly interconnected world, the ability to rapidly identify and respond to breaking
events, particularly those that pose a threat to human life such as natural disasters or conflicts, is
of paramount importance. The effectiveness of response efforts can be significantly impacted by the
speed and accuracy of information gathering, analysis, and dissemination, with the potential to save
lives and mitigate damage. However, obtaining such information poses significant challenges due
to various factors. For example, there have been instances where news agencies faced difficulties in
promptly or completely delivering information about ongoing events due to a scarcity of reporters
present in the affected areas Stelter and Cohen [2008]. The ubiquity of mobile devices and the near-
constant network connectivity that characterizes our modern era have resulted in the generation of
a massive amount of temporally- and spatially-stamped data (hereafter called mobile data). These
datasets have been the subject of numerous studies aiming to derive individual human mobility
patterns for various applications, including quantifying urban vitality Sulis et al. [2018], modeling
epidemic spread Alessandretti [2022], and inferring the activities of individuals Liao et al. [2007].
Simultaneously, the increasing number of orbital satellites has facilitated the collection of high-
resolution images, capturing snapshots of geographical areas with sub-daily temporal frequency.
In this paper, we propose a novel data fusion methodology that integrates satellite imagery with
mobile data to identify breaking events in real time. This approach leverages the strengths of both
data types: mobile data provides an approximation of human mobility, proximity to one another,
and the built environment, while satellite imagery offers visual information on physical changes to
the built and natural environment. This method holds significant potential for three critical appli-
cations. First, it can enhance the detection of small-scale disasters such as tornadoes, wildfires, and
floods in rural regions, where sparse populations and limited infrastructure can impede timely de-
tection and response. Second, it can augment search and rescue operations for lost hikers in remote
wilderness areas, providing critical geospatial data to guide rescue teams and improve the chances
of a successful rescue. Before and after images of the Aru Glacier avalanche in Figure 1 suggest
that large-scale changes in the natural environment can be inferred rather straightforwardly using
satellite imagery Tian et al. [2017]. Finally, it can aid in the identification of active conflict areas
and population displacement in war-torn states, offering invaluable insights to humanitarian orga-
nizations and policy-makers. By leveraging the strengths of both satellite imagery and GPS traces,
this approach overcomes the limitations of both data types and augments the ability to monitor,
understand, and respond to dynamic events in diverse contexts. We demonstrate an application of
the proposed method on a small-scale tornado that ripped through Muskogee, Oklahoma on May
15th, 2020. By combining mobile data from the area as well as satellite images before and after
the event, we infer the occurrence of a natural disaster, identify damaged areas, and highlight hot
spots for individuals’ travel through an area (both spatially and temporally).
Our Contributions.
• We develop a practice-oriented data fusion methodology to augment the inference task for
a variety of use cases;
• We outline expected use cases and demonstrate the case study of a small-scale natural
disaster for which the proposed method is appropriate, and;
• We provide an open-source implementation of the discussed methods.
The rest of the paper is organized as follows: Related Work discusses previous work on leveraging
satellite images, GPS traces, social media posts, and the fusion of such datasets in a variety of
contexts. Dataset and Software describes the datasets and the open-source software we employ.
The Methodology section details our methods, which include data preprocessing steps as well as
analysis specific to each data type. The Experiments section outlines our case study on a tornado
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES3
Figure 1. Images before and after the Aru Glacier collapse on 17 July 2016. Images
are from Sentinel-2 on 18 June 2016 (a) and 21 July 2016 (b) with 10 m resolution.
From [Tian et al., 2017]
in Muskogee, Oklahoma, while the Use Cases section describes other potential use cases for the
proposed method. We conclude with a brief discussion of the implications of our findings.
Related Work
Historically, capturing changes in the built and natural environment often involved on-the-ground
data collection and analysis Haddad [2011]. Surveys and field observations have been the most
traditional method to capture such changes, and continue to be so today in many industries. Prior
to the advent of modern satellites, aerial photography taken from aircrafts was another common
method to document large-scale changes to the built environment Bewley [2003].
While these
two methods of data collection are sufficient for many studies, they (a) lack the immediacy called
for in urgent real-time scenarios and (b) tend to miss developments in the absence of the proper
equipment or manpower. In the last three decades, new methods of data collection in the built and
natural environment have become prominent, including the use of satellite images, GPS traces from
mobile devices, and user-generated content from social media platforms Jongman et al. [2015], Ji
et al. [2018], Yin et al. [2021].
This literature review aims to provide a comprehensive understanding of current and recent
research in the fields of mobile data analysis, satellite imagery, and crowdsourcing, highlighting
works that have fused any two of them to assist in the inference task. Table 1 summarizes some of
the papers discussed in the following paragraphs.
Satellite Imagery and Remote Sensing. The use of satellite imagery for event detection and
inference has been well-documented.
Satellite images provide a bird’s-eye view of the Earth’s
surface, enabling the detection of physical changes over time. Though the granularity of satellite
images alone may not provide the nuanced information needed in certain scenarios, they are useful
in understanding big-picture changes on the built and natural environment. Particularly in the
last five years, the proliferation of commercial satellite imagery providers has enabled access to this
4EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
Table 1. Studies that have used mobile data/satellite imagery for various purposes.
Author
Date
Datasets Used
Applications
Jongman et al.
2015
Satellite imagery,
Twitter posts
Early flood detection in the Philip-
pines and Pakistan
Molinier et al.
2016
Satellite imagery,
mobile app data
Deriving biomass maps of forests
Fayne et al.
2017
Satellite imagery
Flood
detection
in
the
Lower
Mekong Basin
Ji et al.
2018
Satellite imagery
Collapsed building detection in 2010
Haiti Earthquake
Sulis et al.
2018
Transit
smart
card
data, Twitter posts
Quantifying diversity and vitality in
London
Said et al.
2019
Satellite imagery,
social media posts
Natural disaster detection
Pokhryiyal et al.
2020
Satellite imagery,
GPS traces
Estimation of poverty levels in Haiti
Yin et al.
2021
Satellite imagery,
GPS traces
Road attribute detection in Singa-
pore and Jakarta
Belcastro et al.
2021
Social media posts
Small-scale emergency detection
data type at a short notice and in real-time. This has been used in various applications, such as
disaster management Voigt et al. [2007], urban planning Albert et al. [2017], Karunanithi et al.
[2016], and environmental monitoring Xu [2010].
Recent advancements in machine learning have further enhanced the capabilities of satellite
imagery analysis. For instance, convolutional neural networks have been used to automatically
detect and classify objects in satellite images Zhang et al. [2016]. Meta’s novel object classification
method, Segment Anything Kirillov et al. [2023], has been proposed for the geospatial domain
with great promise Wu and Osco [2023]. These developments have opened up new possibilities for
event detection and inference, as it allows for the automated analysis of large volumes of satellite
imagery and greatly reduces image processing time, allowing for subsequent immediate response
on the ground.
GPS Traces from Mobile Devices. Parallel to the advancements in satellite imagery analysis,
the proliferation of GPS-enabled mobile devices has led to an explosion of mobile data, providing
detailed information about the movements of individuals and groups Zheng et al. [2008]. Research
has delved into the use of mobile data for tracking population movements Bengtsson et al. [2011],
understanding social behavior Hong et al. [2008], Calabrese et al. [2010], predicting and managing
traffic patterns Herrera et al. [2010], and more.
The richness of this data source has also led to the development of new methods for event
detection and inference. For instance, GPS traces have been used to detect social events Castro
et al. [2014], Pan et al. [2013], infer the activities of individuals Liao et al. [2007], and understand
where individuals conduct their daily activities Chen et al. [2014]. However, the fusion of mobile
data with other data sources for real-time event identification and inference in the built and natural
environment, particularly in the context of emergencies and disasters, is an area that deserves
further exploration.
Crowdsourcing and Social Media Data. Crowdsourcing has emerged as a powerful tool for
gathering and analyzing data, particularly in the context of event detection and response. The term
”crowdsourcing” refers to the practice of obtaining information or input into a task or project by
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES5
enlisting the services of a large number of people, either paid or unpaid, typically via the internet
Estell´es-Arolas and L. Guevara [2012]. In the context of event detection, crowdsourcing can be
used to gather real-time information from individuals who are directly experiencing or observing
the event Goodchild [2007]. One of the most notable examples of crowdsourcing in event detection
is the Ushahidi platform, which was used to gather and map reports of violence in Kenya after the
post-election violence in 2008 Okolloh [2009]. Since then, Ushahidi has been used in various other
contexts, including disaster response and environmental monitoring.
Crowdsourcing is closely linked to social media’s rise to prominence as a crucial news outlet
during disasters. A mountain of literature has been published on the promises of social media data
in augmenting the inference task in a range of scenarios. Social media websites provide a platform
for individuals to share real-time information on developing events, including their impacts and
the needs of affected communities Palen et al. [2007]. The information circulated on social media
tends to dissipate quicker and be more specific than official news outlets, as anyone and everyone
has the ability to share and post Palen [2008]. This information has been used by disaster response
organizations to better understand the situation on the ground and coordinate their response efforts.
Several studies have explored the use of social media data in disaster response. For instance,
[Sakaki et al., 2010] developed a system that uses Twitter data to detect earthquakes in real-time.
Similarly, [Ashktorab et al., 2014] developed a system that uses Twitter data to extract actionable
information during disasters, such as requests for help or reports of infrastructure damage. [Guan
and Chen, 2014] developed a metric to quantify the evolution of disasters based on Twitter activities,
demonstrating its use for damage detection during Hurricane Sandy, affecting much of the eastern
United States and various Caribbean nations. More recently, social media data has been combined
with other data sources for disaster response. For example, [Jongman et al., 2015] proposed a
method for fusing social media data and satellite imagery to detect floods. This approach leverages
the strengths of both data sources, using social media data to provide real-time information about
the flood and satellite imagery to provide a macro view of the flood’s impacts. We refer the reader
to [Said et al., 2019] for a broader review of these approaches.
Despite the significant potential of crowdsourcing and social media data for event detection and
response, there are notable limitations that must be acknowledged. The quality and reliability of
crowdsourced data can vary significantly. Misinformation or inaccurate reports can be dissemi-
nated, either unintentionally due to confusion or panic or intentionally as a form of manipulation
or cyberattack Allcott et al. [2019]. This can lead to false positives in event detection or mis-
directed response efforts. Additionally, crowdsourcing is inherently dependent on the availability
and willingness of individuals to contribute information. In certain scenarios, such as in remote
wilderness areas or war-torn regions, the number of individuals able to contribute data may be
limited. Similarly, during small-scale or rapidly unfolding events, there may not be sufficient time
for crowdsourced information to be gathered and analyzed. These limitations highlight the need
for complementary approaches to event detection and response. Our proposed method addresses
these limitations by providing a reliable, real-time source of information that is not dependent on
individual contributions or vulnerable to the same misinformation risks.
Data Fusion for Event Inference. While there is a substantial body of research on the use of
mobile data and satellite imagery independently, there is a noticeable gap in the literature when
it comes to their combined use for real-time event identification and response. This gap represents
a significant opportunity for new research that can contribute to both academic knowledge and
practical applications in disaster management, conflict monitoring, as well as search and rescue
operations.
The fusion of satellite imagery and GPS traces for event inference is a relatively new area of
research and is uniquely poised to overcome the limitations placed on only analyzing each data
source individually. Though GPS traces have emerged as a prominent data source, it should be
6EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
noted that such datasets tend to exclude certain populations, such as the extreme poor Pokhriyal
et al. [2020].
In developing countries, this population may represent a significant share of the
population.
Thus, in the event of an emergency, mobile data cannot be the sole indicator of
irregular movement patterns. Satellite imagery itself may also be inadequate in event inference due
to the lack of specific mobility information. However, when combined, these two data sources can
supplement each other and leverage the additional information to better inform the inference task.
Though previous studies have explored the intersection of these two data sources, the direction
of application we intend to use our tool differs from previous works. For instance, [Yin et al., 2021]
proposed a method for fusing satellite imagery and GPS traces to infer and fill in road attributes
such as speed limits and lane widths, with the goal of developing a more comprehensive view of
road networks globally. [Pokhriyal et al., 2020] fused satellite images with mobile data to estimate
poverty levels in Haiti, where a nationwide census had not been conducted since 2012. In developing
countries where there may not be the economic resources necessary to complete annual censuses,
using a combination of data sources to estimate various baselines may emerge as a crucial tool
for financial aid allocation and future urban planning. A combination of mobile data and satellite
imagery has also been used to study forests and obtain biomass measurements Molinier et al. [2016].
This study combined citizen science-powered mobile data collection and satellite imagery to garner
forest information and produce biomass maps in a cost effective manner.
Notably, both the work of Yin et al. and Pokhriyal et al. provide information that can be
used for future planning. However, we hope to use GPS traces and satellite imagery in real time
for instantaneous data analysis and event identification. Additionally, unlike in Molinier et al.,
where mobile data is actively collected through an app that must be user-operated, we obtain GPS
traces passively through users’ interactions with various apps (not a specific one). Thus, our event
detection and inference capabilities are completely powered by remote data, and without the need
for active, real-time human participation.
Dataset and Software
For mobile data, we employ privacy-protected, passively generated GPS data from an American
data solution provider specializing in geospatial analytics.
The dataset contains discrete GPS
points of 2,000 anonymous, opted-in individuals in the Tulsa metropolitan area between December
2019 and July 2020. The locational data recorded includes timestamps, unique device identifiers,
latitudes and longitudes, and a measure of data precision (i.e., a spatial radius for which the
provider has 95% confidence in the reported coordinates). In addition to anonymizing the data,
the data provider obfuscates home locations to the census-block group level, and removes sensitive
points of interest from the dataset, in order to preserve privacy. It’s also crucial to note that the
temporal granularity of this data is determined by user activity, meaning data points are generated
irregularly and not at fixed intervals. This non-uniformity of temporal data represents the actual,
inconsistent frequency of device usage among the sampled population.
For satellite imagery, we pull data from Planet Labs, a private American company that specializes
in Earth imaging. Planet operates a large constellation of miniature satellites, known as Doves,
which continually capture and transmit images of Earth. The 3-band images we use have undergone
orthorectification, a process that corrects the geometric distortions in an image to represent a flat
surface, thereby ensuring that the scale is uniform throughout. This makes the images reliable for
distance measurements and for overlaying with other geospatial data. Additionally, the images have
been color-corrected to ensure that the colors represented are as close as possible to what the human
eye would perceive if viewing the scene directly. This enhances the clarity and interpretability of
the images, making them a valuable resource for our research.
We implemented our methodology in the Python programming language van Rossum [1995].
We used pandas Wes McKinney [2010] to read and wrangle mobile data and Rasterio Gillies
et al. [2013–] to manipulate satellite images. We also leveraged NumPy Harris et al. [2020] for a
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES7
variety of array operations, GeoPandas Jordahl et al. [2019] for operations involving coordinates,
and scikit-mobility Pappalardo et al. [2019] to conduct mobile data cleaning and preprocessing.
Last but not least, we used matplotlib Hunter [2007] to produce any visualizations of our results.
Any other chunk of code we developed can be found on our GitHub repository: https://github.
com/ekinugurel/SatMobFusion.
Methodology
Our methodology has two modules—one that deals with the analysis of mobile data, and another
with that of satellite imagery. In both modules, we discuss relevant preprocessing methods as well
as analysis steps to aid in the inference task. Figure 2 shows the high-level steps in preprocessing
and analysis of both datasets while also outlining key geospatial analysis processes for the three
use cases discussed in the Introduction.
Figure 2. Methodological flowchart; the top bins describe the order of processes
employed in this paper, while the bottom outlines key geospatial analysis metrics
to carry out the inference task
Mobile Data. For mobile data, the general preprocessing workflow is as follows:
(1) Spatial Partitioning
8EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
(2) Coordinate Reference System (CRS) Projection
(3) Data Filtering
To avoid wastefulness in computation, we begin by partitioning the mobile data spatially, which
we do by drawing a bounding box using four sets of coordinates. In practice, there are several ways
to achieve this at scale: Leveraging a geocoding application protocol interface (API) to obtain the
coordinates based on an existing point of interest, partitioning by federal and/or state designations
such as census tracts, ZIP codes, or county borders, manually typing in a bounding box (i.e., by
defining the geographic coordinates of the corners of the box), or obtaining a KMZ file from the
National Oceanic and Atmospheric Administration’s Damage Assessment Toolkit. For this effort,
we used the last option to derive the centroid coordinates of the affected area around which we
drew a 1 km2 bounding square.
Once the data is spatially partitioned, we project coordinates to the appropriate CRS. Different
CRSs are designed to accurately represent different aspects of the Earth’s surface.
Some are
designed to preserve area, while others preserve shape, distance, or direction. In the context of event
inference, the optimal choice of CRS should minimize bias in the derived mobility metrics, which
may exist due to distortions of distances and areas. Therefore, we use an equal-area projection
around UTM Zone 15, which covers the area around our case study.
We then filter out any erroneous data points based on a threshold of segment velocity. Since
this is done ”as the crow flies” and not with respect to the underlying transportation network, this
threshold should be set conservatively. Velocity filtering discards infeasible jumps and oscillations
in trajectories, which may occur as a result of tall buildings blocking a satellite’s line of sight to the
mobile device (termed ”urban canyon effect”, Ben-Moshe et al. [2011]). These oscillations may also
occur due to low data precision as a result of the ”cold-start problem”—when a signal dropped by
WiFi is not immediately picked up by a satellite, requiring some time before being able to acquire
navigation data and calculate a position Lehtinen et al. [2008].
Once preprocessing is finished, we conduct inference-related analyses using the following steps:
(1) Experimental Design Partitioning
(2) Exploratory Data Analysis (EDA)
(3) Statistical Testing
Specifically, we first define pre-, during-, and post-event periods that temporally segment the
data. The purpose of this partitioning is to derive key metrics for each period, which would assist in
detecting anomalies and enable more formal statistical tests. The duration of these periods depends
on the nature of the analysis—for natural disasters like tornadoes or hurricanes, the ”during” period
may be a few hours, while for applications in search & rescue or in conflict areas, the same period
may only last a few minutes.
In conducting EDA on time-series mobile data, the objectives are to understand the structure of
the data (i.e., identifying immediate trends, patterns, or outliers), detect seasonality (i.e., periodic
fluctuations), and prepare the data for more formal anomaly detection techniques and statistical
tests. The EDA process can also assist in formulating hypotheses about possible causes for anom-
alies by exploring relationships between the target variable and other variables. In the context of
mobile data within constrained geography, the metrics we analyze include the radius of gyration
rg (the characteristic distance traveled by an individual in a given period, Equation 1) Song et al.
[2010], the number of extended stays at a particular location c (Equation 3), and the number of
visits per time unit v.
(1)
rg =
v
u
u
t 1
n
n
X
i=1
(ri − rcm)2
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES9
where ri represents the i = 1, . . . , n locations recorded for the individual and rcm = 1
n
Pn
i=1 ri is
the center of mass of the period’s trajectory.
c =
n
X
i=1
ci,
(2)
ci =
(
1
if ti = 1, li = 1
0
otherwise
(3)
where ti is an indicator variable denoting whether a device is observed more than once within
a 15-minute period and li is an indicator variable denoting whether multiple observations of the
device are within a 100-meter radius (only considered if ti = 1). We note that these thresholds are
robust and suggest adjusting them to suit the underlying domain.
(4)
v =
m
X
j=1
vj
where j = 1, . . . , m indexes the subsections of the inspected geographical area and vj is an indicator
variable denoting whether the individual was located in that subsection in the given period.
Finally, we conduct statistical tests to confirm the presence of anomalies. In this paper, we
employ the Z-score method (Equation 5), in which the principle is to assume the data follows a
normal distribution and then to identify data points that are too far from the mean.
(5)
Z = x − µ
σ
where x is a data point, µ is the mean of the dataset, and σ is the standard deviation. We consider
Z-scores above 3 (or below -3) an anomaly.
Satellite Imagery. The general workflow for processing and analyzing satellite images is as fol-
lows:
(1) Specify tradeoff between region-of-interest (ROI) coverage and time gap to the event of
interest
(2) Pull imagery and project to CRS
(3) Image Analysis: RGB, greyscale, and NDVI differences
Providers like Planet Labs have multiple orbital satellites whose coverage area may intersect—
the goal of each satellite is to pass over a particular geography at least once per day; however,
various factors can influence the availability of imagery and cause irregular gaps in observation,
including cloud cover, technical issues with onboard cameras or the image transmission process,
and regulatory restrictions imposed by nation-states. For these reasons, we derive a utility metric
(Equation 6) to determine the best available before and after image for an event of interest. This
metric weighs the image’s area of coverage against its time gap with the event using a tradeoff
coefficient—the idea is to maximize the spatial overlap between the image and the ROI while
minimizing the number of days between the images.
(6)
u = Aimg
Aevt
− |timg − tevt|
ϕ
where the first term denotes the percent of ROI covered by the image (i.e., Aimg is the area of the
image and Aevt is the area affected by the event), the numerator of the second term denotes the
number of days between the images, and ϕ is the coverage tradeoff coefficient. In this work, we use
ϕ = 0.25, meaning that 25% (percentage points) more coverage of the AOI is defined to be worth
as much as the image being taken 1 day before or after the event.
10
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
As an additional filter to the above utility metric, we require all images to have less than 50%
cloud coverage. Once we have the satellite images, we project them to the same CRS we used for
the mobile data to avoid misalignment.
We analyze the images to identify any physical changes to the built and natural environment.
This analysis involves looking at the regular visible spectrum (RGB), a grayscale version (i.e.,
luminosity, Equation 7), and the Normalized Difference Vegetation Index (NDVI, Equation 8),
which measures the greenness and the density of the vegetation captured in a satellite image.
NDV I = NIR − R
NIR + R
(7)
GS = 0.299R + 0.587G + 0.114B
(8)
where NIR, R, G, and B are near-infrared, red, green, and blue reflectances, respectively. NDVI
is always between -1 and 1, where negative values signify the presence of clouds, water, or snow,
values close to zero signify earthy rocks and bare soil, and positive values signify the existence of
some vegetation (with more positive meaning more green).
Figure 3 shows a decision tree outlining when the proposed method should be employed based
on a series of conditions, organized by the cognitive load required to succeed in the inference task.
Intuitively, crowdsourcing may be the preferred option for most organizations and individuals but
can be unreliable due to the threat of misinformation or cybersecurity breaches. Similarly, while
cameras and other in-situ sensors could provide longer visual feeds that are also easier to interpret,
their availability in certain settings tends to be sparse.
If the above two conditions are true,
and cloud-free satellite imagery is available, then employing our method may be of interest to
organizations and individuals alike.
Figure 3. Usage decision tree for the proposed method
Relating to the above figure, we emphasize three points about the proposed methodology:
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
11
(a) Radius of Gyration
(b) Number of Stays per day
Figure 4. EDA of mobility metrics in the before, during, and after periods
(1) The process of event detection starts with mobile data, not satellite imagery, due to the
feasibility of passively monitoring geography based on mobility metrics. However, the fusion
of the two sources is what enables us to make an inference.
(2) The proposed methodology is designed to be flexible, allowing the user to define an event
of interest using a configuration file.
(3) This approach can be used with both real-time and historical data, depending on the context
of the application, making it a potentially powerful tool for improving emergency response
times and information percolation speeds.
Case Study
To validate our proposed methodology, we conducted a case study on the EF-1 tornado that
hit near Muskogee, Oklahoma on May 15, 2020. This event provided an opportunity to test our
approach in a real-world scenario involving a small-scale disaster in a rural region.
After spatially partitioning the GPS traces to include the subset within the bounding box of
the tornado, we projected all data to UTM Zone 15 and filtered the data by the logic described
in Section . Then, we defined the two weeks before the day of the event (May 2 - May 15) as the
before, the day of the event (May 15) as the during, and the week after the event (May 15 - May
22) as the after periods and began exploring the data. Figure 4 visualizes the time series of two
metrics, highlighting the periods by color; there are no noticeable changes in the radius of gyration,
while the number of extended stays at a given location within the ROI increases sharply the day
after the event. However, Z-score tests on both metrics do not detect any anomalies.
However, when we look at the third metric (visits per hour to the ROI, Figure 5), we see an
unmistakable outlier; on the day of the tornado, visits to the area increased sharply at 2 pm and
again at 6 pm, substantially beyond the usual fluctuations captured by the 95% confidence interval
(light blue shade) in the before and after periods. Furthermore, Z-score tests on this metric confirm
the hypothesis: Two anomalies exist in the data and they are at 2 pm (Z = 3.47) and at 6 pm
(Z = 4.87) on May 15th.
Following the anomaly detection, we pull in satellite imagery as described in the previous section.
We use the utility metric in Equation 6 to land on two images, one from May 9 and another from
May 18. These two images are free of clouds and strike a balance between the percent of ROI
covered and the number of days separating them from the event.
We analyze the images based on visual inspection, the greyscale difference, and the NDVI dif-
ference (Figure 6). We highlight two spots on the regular color band images in which changes
to the soil and a corner building are apparent to the naked eye. Furthermore, while noisy, the
12
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
Figure 5. Visits per hour to the ROI in the before, during, and after periods sorted
by hour of day
greyscale difference image shows changes to luminosity and the NDVI difference image shows loss
of vegetation throughout the captured area (note that 0.0 is shown in light green).
The images show clear evidence of physical changes to the ROI. When combined with insights
from GPS traces, and even without hindsight bias, we would infer that a mildly-destructive natural
disaster occurred, piquing passerby’s interest as well as landowners’ concern on the day of the event
(resulting in greater visits to the ROI).
Use Cases
The proposed methodology is expected to outperform existing methods for data collection and
information percolation for a range of use cases. We especially anticipate broad applicability in the
following settings:
• Intelligent transportation systems: The likelihood of finding parking approximate to
a desired location and in a timely manner has been shown to be a determinant of travelers’
mode choice Assemi et al. [2020]. Therefore, providing accurate parking-related informa-
tion can augment an individual’s decision-making process. Public and private entities can
leverage the proposed method to provide real-time information on parking availability. The
temporal sparsity of satellite imagery can be augmented with GPS traces to provide an
online learning framework for the likelihood of finding parking.
• Events in rural areas: In rural areas where traditional data collection methods may
be sparse or non-existent, our methodology could provide valuable insights into events as
they unfold. The combination of satellite imagery and mobile data could help identify and
respond to emergencies such as wildfires, floods, or lost hikers.
• Extreme-weather events: During extreme-weather events like hurricanes, tornadoes, or
blizzards, our methodology could provide real-time information about the event’s impact
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
13
(a) Before the Muskogee tornado on May 9, 2020
(b) After the Muskogee tornado on May 18, 2020
(c) Greyscale difference between the two images
(d) NDVI difference between the two images
Figure 6. Satellite imagery with 10m resolution documenting changes to the built
and natural environment after the Muskogee tornado
and aid in coordinating response efforts. The ability to quickly identify areas of high impact
could help prioritize resource allocation and rescue operations.
• War-torn states: In regions affected by conflict, obtaining reliable on-the-ground infor-
mation can be challenging. Satellite imagery combined with mobile data could help identify
areas of active conflict, population displacement, or infrastructure damage.
• Areas without network connectivity: In areas where network connectivity is limited or
non-existent, such as remote wilderness areas or during large-scale network outages, satellite
imagery can still provide valuable data. When combined with historical or intermittent
mobile data, this could help identify and respond to events such as lost hikers or the spread
of wildfires.
• National security matters: Our methodology could also be used in the context of na-
tional security, helping to identify potential threats or unusual activities. The fusion of
satellite imagery with mobile data could provide a more comprehensive picture of activities
across a wide geographical area.
In each of these use cases, our methodology aims to provide a more nuanced and timely under-
standing of events as they unfold, potentially improving response times and outcomes.
Conclusion
We have presented a novel data fusion methodology combining satellite imagery with GPS traces
generated from mobile devices. Our approach leverages the strengths of both data types: mobile
14
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
data provides an approximation of human mobility, proximity to one another, and the built envi-
ronment, while satellite imagery offers visual insights into physical changes to the built and natural
environment. Furthermore, we have demonstrated the case study of a small-scale tornado, show-
ing the promise of our method in identifying anomalies in movement patterns using mobile data,
changes to the built environment using satellite imagery, and inferring the cause of both using our
fusion methodology.
Our methodology is viable due to the increasing accessibility of commercial data providers spe-
cializing in remote sensing and mobile devices. This trend is only expected to continue—the number
of active orbital satellites has grown exponentially since 2017 orb [2022], while the percentage of
Americans that own a smartphone has risen to 97% mob [2021]. The continued commercialization
of such products will enable researchers and practitioners to monitor, categorize, and understand
the natural and built environments in ways unimaginable just 50 years ago. We hope our method
is a step in this direction, enabling others to pursue endeavors made possible by the fusion of these
data sources.
Data Access Statement
The authors note that only Ekin Ugurel had access to the privacy-protected GPS dataset. Data
supporting this study cannot be made available due to privacy-preserving research agreements with
the data provider.
Author Contributions
The authors confirm contribution to the paper as follows: study conception and design: E.
Ugurel, S. Coenen; data collection: E. Ugurel, S. Coenen; analysis and interpretation of results: E.
Ugurel, S. Coenen; draft manuscript preparation: E. Ugurel, M. Chen, S. Coenen, C. Chen. All
authors reviewed the results and approved the final version of the manuscript.
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
15
References
Mobile fact sheet. Technical report, Pew Reseearch Center, 2021. URL https://www.pewresearch.
org/internet/fact-sheet/mobile/.
Online index of objects launched into outer space. Technical report, United Nations - Office of
Outer Space Affairs, 2022.
A. Albert, J. Kaur, and M. Gonzalez. Using convolutional networks and satellite imagery to identify
patterns in urban environments at a large scale. pages 1357–1366, 08 2017. doi: 10.1145/3097983.
3098070.
L. Alessandretti. What human mobility data tell us about COVID-19 spread. Nature Reviews
Physics, 4(1):12–13, Jan. 2022. ISSN 2522-5820. doi: 10.1038/s42254-021-00407-1. URL https:
//www.nature.com/articles/s42254-021-00407-1. Number: 1 Publisher: Nature Publishing
Group.
H. Allcott, M. Gentzkow, and C. Yu. Trends in the diffusion of misinformation on social media.
Research & Politics, 6(2):2053168019848554, 2019.
Z. Ashktorab, C. Brown, M. Nandi, and A. Culotta. Tweedr: Mining twitter to inform disaster
response. In International Conference on Information Systems for Crisis Response and Manage-
ment, 2014.
B. Assemi, D. Baker, and A. Paz. Searching for on-street parking: An empirical investigation of
the factors influencing cruise time. Transport Policy, 97:186–196, 2020.
B. Ben-Moshe, E. Elkin, H. Levi, and A. Weissman. Improving Accuracy of GNSS Devices in
Urban Canyons. page 6, 2011.
L. Bengtsson, X. Lu, A. Thorson, R. Garfieldarfier, and J. Schreeb. Improved response to disasters
and outbreaks by tracking population movements with mobile phone network data: A post-
earthquake geospatial study in haiti. PLoS medicine, 8:e1001083, 08 2011. doi: 10.1371/journal.
pmed.1001083.
R. Bewley. Aerial survey for archaeology. The Photogrammetric Record, 18:273 – 292, 12 2003. doi:
10.1046/j.0031-868X.2003.00023.x.
F. Calabrese, M. Colonna, P. Lovisolo, D. Parata, and C. Ratti. Real-time urban monitoring using
cell phones: A case study in rome. IEEE transactions on intelligent transportation systems, 12
(1):141–151, 2010.
P. Castro, D. Zhang, C. Chen, S. Li, and G. Pan. From taxi gps traces to social and community
dynamics: A survey. ACM Computing Surveys, 46, 01 2014. doi: 10.1145/2543581.2543584.
C. Chen, L. Bian, and J. Ma. From traces to trajectories: How well can we guess activity locations
from mobile phone traces? Transportation Research Part C: Emerging Technologies, 46:326–337,
2014.
E. Estell´es-Arolas and F. G. L. Guevara. Towards an integrated crowdsourcing definition. Journal
of Information Science, 38, 04 2012. doi: 10.1177/0165551512437638.
S. Gillies et al.
Rasterio: geospatial raster i/o for Python programmers, 2013–.
URL https:
//github.com/rasterio/rasterio.
M. F. Goodchild. Citizens as sensors: the world of volunteered geography. GeoJournal, 69:211–221,
2007.
X. Guan and C. Chen. Using social media data to understand and assess disasters. Natural hazards,
74:837–850, 2014.
N. Haddad. From ground surveying to 3d laser scanner: A review of techniques used for spatial
documentation of historic sites. Journal of King Saud University - Engineering Sciences, 23:
109–118, 06 2011. doi: 10.1016/j.jksues.2011.03.001.
C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gommers, P. Virtanen, D. Cournapeau,
E. Wieser, J. Taylor, S. Berg, N. J. Smith, R. Kern, M. Picus, S. Hoyer, M. H. van Kerkwijk,
M. Brett, A. Haldane, J. F. del R´ıo, M. Wiebe, P. Peterson, P. G´erard-Marchant, K. Sheppard,
16
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
T. Reddy, W. Weckesser, H. Abbasi, C. Gohlke, and T. E. Oliphant. Array programming with
NumPy. Nature, 585(7825):357–362, Sept. 2020. doi: 10.1038/s41586-020-2649-2. URL https:
//doi.org/10.1038/s41586-020-2649-2.
J. C. Herrera, D. B. Work, R. Herring, X. J. Ban, Q. Jacobson, and A. M. Bayen. Evaluation
of traffic data obtained via gps-enabled mobile phones: The mobile century field experiment.
Transportation Research Part C: Emerging Technologies, 18(4):568–583, 2010.
S.-J. Hong, J. Thong, J. Y. Moon, and K. Tam. Understanding the behavior of mobile data services
consumers. Information Systems Frontiers, 10:431–445, 09 2008. doi: 10.1007/s10796-008-9096-1.
J. D. Hunter. Matplotlib: A 2d graphics environment. Computing in Science & Engineering, 9(3):
90–95, 2007. doi: 10.1109/MCSE.2007.55.
M. Ji, L. Liu, and M. Buchroithner. Identifying collapsed buildings using post-earthquake satellite
imagery and convolutional neural networks: A case study of the 2010 haiti earthquake. Remote
Sensing, 10(11):1689, 2018.
B. Jongman, J. Wagemaker, B. Revilla Romero, and E. Coughlan de Perez. Early flood detection
for rapid humanitarian response: harnessing near real-time satellite and twitter signals. ISPRS
International Journal of Geo-Information, 4(4):2246–2266, 2015.
K. Jordahl, J. V. den Bossche, J. Wasserman, J. McBride, J. Gerard, M. Fleischmann, J. Tratner,
M. Perry, C. Farmer, G. A. Hjelle, S. Gillies, M. Cochran, M. Bartos, L. Culbertson, N. Eu-
bank, maxalbert, S. Rey, A. Bilogur, D. Arribas-Bel, C. Ren, J. Wilson, M. Journois, L. J.
Wolf, L. Wasser, ¨Omer ¨Ozak, YuichiNotoya, F. Leblanc, Filipe, C. Holdgraf, and A. Greenhall.
geopandas/geopandas: v0.6.1, Oct. 2019. URL https://doi.org/10.5281/zenodo.3483425.
M. Karunanithi, S. Kumar, and P. Ponnusamy. Use of high resolution google earth satellite imagery
in landuse map preparation for urban related applications. Procedia Technology, 24:1835–1842,
12 2016. doi: 10.1016/j.protcy.2016.05.231.
A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C.
Berg, W.-Y. Lo, P. Doll´ar, and R. Girshick. Segment anything. arXiv:2304.02643, 2023.
M. Lehtinen, A. Happonen, and J. Ikonen. Accuracy and time to first fix using consumer-grade gps
receivers. In 2008 16th International Conference on Software, Telecommunications and Computer
Networks, pages 334–340, 2008. doi: 10.1109/SOFTCOM.2008.4669506.
L. Liao, D. Fox, and H. Kautz. Extracting places and activities from gps traces using hierarchical
conditional random fields. The International Journal of Robotics Research, 26(1):119–134, 2007.
M. Molinier, C. L´opez-S´anchez, T. Toivanen, I. Korpela, J. J. Corral-Rivas, R. Tergujeff, and
T. H¨ame. Relasphone—mobile and participative in situ forest biomass measurements supporting
satellite image mapping. Remote Sensing, 8:869–891, 10 2016. doi: 10.3390/rs8100869.
O. Okolloh. Ushahidi, or ‘testimony’: Web 2.0 tools for crowdsourcing crisis information. Partici-
patory learning and action, 59(1):65–70, 2009.
L. Palen. Online social media in crisis events. Educause Quarterly, 31:76–78, 01 2008.
L. Palen, S. Vieweg, J. Sutton, S. B. Liu, and A. Hughes. Crisis informatics: Studying crisis in
a networked world. In Proceedings of the Third International Conference on E-Social Science,
pages 7–9, 2007.
G. Pan, G. Qi, Z. Wu, D. Zhang, and S. Li. Land-use classification using taxi gps traces. Intelligent
Transportation Systems, IEEE Transactions on, 14:113–123, 03 2013. doi: 10.1109/TITS.2012.
2209201.
L. Pappalardo, F. Simini, G. Barlacchi, and R. Pellungrini. scikit-mobility: A python library for
the analysis, generation and risk assessment of mobility data. arXiv preprint arXiv:1907.07062,
2019.
N. Pokhriyal, O. Zambrano, J. Linares, and H. Hern´andez. Estimating and Forecasting Income
Poverty and Inequality in Haiti Using Satellite Imagery and Mobile Phone Data. 06 2020. doi:
10.18235/0002466.
EVENT DETECTION FROM NOVEL DATA SOURCES: LEVERAGING SATELLITE IMAGERY ALONGSIDE GPS TRACES
17
N. Said, K. Ahmad, M. Riegler, K. Pogorelov, L. Hassan, N. Ahmad, and N. Conci. Natural disasters
detection in social media and satellite imagery: a survey. Multimedia Tools and Applications, 78:
31267–31302, 2019.
T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake shakes twitter users: real-time event detection
by social sensors. In Proceedings of the 19th international conference on World wide web, pages
851–860, 2010.
C. Song, Z. Qu, N. Blumm, and A.-L. Barab´asi. Limits of predictability in human mobility. Science,
327(5968):1018–1021, 2010.
B. Stelter and N. Cohen. Citizen journalists provided glimpses of mumbai attacks. The New York
Times, 2008. URL https://www.nytimes.com/2008/11/30/world/asia/30twitter.html#:~:
text=From%20his%20terrace%20on%20Colaba,every%20move%20on%20the%20Internet.
P. Sulis, E. Manley, C. Zhong, and M. Batty. Using mobility data as proxy for measuring urban
vitality. Journal of Spatial Information Science, 2018(16):137–162, 2018.
L. Tian, T. Yao, Y. Gao, L. Thompson, E. Mosley-Thompson, S. Muhammad, J. Zong, C. Wang,
S. Jin, Z. Li, and et al. Two glaciers collapse in western tibet. Journal of Glaciology, 63(237):
194–197, 2017. doi: 10.1017/jog.2016.122.
G. van Rossum. Python tutorial. Technical Report CS-R9526, Centrum voor Wiskunde en Infor-
matica (CWI), Amsterdam, May 1995.
S. Voigt, T. Kemper, T. Riedlinger, R. Kiefl, K. Scholte, and H. Mehl. Satellite image analysis for
disaster and crisis-management support. IEEE transactions on geoscience and remote sensing,
45(6):1520–1528, 2007.
Wes McKinney. Data Structures for Statistical Computing in Python. In St´efan van der Walt and
Jarrod Millman, editors, Proceedings of the 9th Python in Science Conference, pages 56 – 61,
2010. doi: 10.25080/Majora-92bf1922-00a.
Q. Wu and L. P. Osco. samgeo: A Python package for segmenting geospatial data with the Segment
Anything Model (SAM), May 2023. URL https://doi.org/10.5281/zenodo.7966658.
H. Xu. Analysis of impervious surface and its impact on urban heat environment using the nor-
malized difference impervious surface index (ndisi). Photogrammetric Engineering & Remote
Sensing, 76(5):557–565, 2010.
Y. Yin, A. Tran, Y. Zhang, W. Hu, G. Wang, J. Varadarajan, R. Zimmermann, and S.-K. Ng.
Multimodal fusion of satellite images and crowdsourced gps traces for robust road attribute
detection. In Proceedings of the 29th International Conference on Advances in Geographic Infor-
mation Systems, pages 107–116, 2021.
L. Zhang, L. Zhang, and B. Du. Deep learning for remote sensing data: A technical tutorial on the
state of the art. IEEE Geoscience and remote sensing magazine, 4(2):22–40, 2016.
Y. Zheng, Q. Li, Y. Chen, X. Xie, and W.-Y. Ma. Understanding mobility based on gps data. In
Proceedings of the 10th international conference on Ubiquitous computing, pages 312–321, 2008.
"
"This paper presents a novel diffusion-based framework for animating people in a scene driven by target 3D motion sequences, enabling the generation of realistic and diverse human movements. The approach consists of two core components: a) learning priors about invisible parts of the human body and clothing to generate plausible complete texture maps from single images using in-painting diffusion models, and b) developing a diffusion-based rendering pipeline, controlled by 3D poses, for the synthesis of realistic renderings of novel poses of the person, including clothing, hair, and plausible in-filling of unseen regions. Experiments show the model's ability to synthesize prolonged motions and handle challenging and complex poses, outperforming previous methods.nan","Given a random photo of a person, can we accurately animate that person to imitate someone else's action? This problem requires a deep understanding of how human poses change over time, learning priors about human appearance and clothing. To tackle this, we propose 3DHM, a two-stage framework that synthesizes 3D Human Motions by completing a texture map from a single image and then rendering the 3D humans to imitate the actions of the actor, resulting in synthesized videos that are faithful to the target motion in 3D pose and to the input image in terms of visual similarity. In addition, the 3D control enables the generation of diverse synthetic camera trajectories to render a person.nan","nanPrior work on controllable human generation and synthesizing moving people has faced challenges in generating realistic human images or videos, often leading to incomplete or non-consequential outputs, and failing to faithfully reconstruct humans. Existing approaches either require large amounts of data, supervised control signals, or careful curation of training data, making it difficult to utilize them directly for animating humans. Some methods attempt to learn pose-to-pixels mapping directly, but this methodology often leads to models becoming overly specialized to certain training data, limiting their generalization capabilities.nan","In the first stage of 3DHM, an inpainting diffusion model is utilized to produce a plausible complete texture map by inpainting the unseen regions of the imitator. This model takes a partial texture map and corresponding visibility mask as inputs, and generates a recovered predicted map for the human. In the second stage, a rendering diffusion model is developed to obtain a realistic rendering of a human imitator doing the actions of the actor. This model is applied to intermediate renderings of SMPL meshes, generated by wrapping the predicted texture map from the first stage, to project the body-tight renderings to more realistic images with clothing. The model is conditioned on 3D poses to animate the imitator to copy the actions of the actor.nan","In our experiments, 3DHM outperforms previous approaches on several metrics, including image-based evaluation and video-based evaluation. It achieves superior performance in generating realistic frames, preserving temporal consistency, and generating accurate 3D poses. Qualitative results demonstrate the model's ability to synthesize moving people in various scenarios, including unseen 3D human videos, motions from random YouTube videos, and motions from text inputs, with diverse viewpoints and challenging poses.nan","We present 3DHM, a two-stage diffusion model-based framework for synthesizing moving people from a single image given a target 3D motion sequence. Our approach is resilient in generating prolonged motions and varied challenging and complex poses. It is fully self-supervised, requiring no additional annotations beyond human videos, and is scalable with the availability of more human videos. We believe that 3DHM opens up new possibilities for human animation and provides a solid foundation for future research in this area.nan",Synthesizing Moving People with 3D Control,"Boyi Li, Jathushan Rajasegaran, Yossi Gandelsman, Alexei A. Efros, Jitendra Malik","Synthesizing Moving People with 3D Control
Boyi Li
Jathushan Rajasegaran
Yossi Gandelsman
Alexei A. Efros
Jitendra Malik
UC Berkeley
Imitator
Actor
Imitator
Actor
Actor
Figure 1. The Imitation Game: Given a video of a person ""The Actor"", we want to transfer their motion to a new person ""The Imitator"".
In this figure, the first row shows a sequence of frames of the actor (Michelle Kwan), doing her Olympics ’98 performance. The inset row
shows the 3D poses extracted from this video. Now, given any single image of a new person The Imitator, our model can synthesize new
renderings of the imitator, to copy the actions of the actor in 3D.
Abstract
In this paper, we present a diffusion model-based frame-
work for animating people from a single image for a given
target 3D motion sequence. Our approach has two core
components: a) learning priors about invisible parts of the
human body and clothing, and b) rendering novel body poses
with proper clothing and texture. For the first part, we learn
an in-filling diffusion model to hallucinate unseen parts of a
person given a single image. We train this model on texture
map space, which makes it more sample-efficient since it
is invariant to pose and viewpoint. Second, we develop a
diffusion-based rendering pipeline, which is controlled by
3D human poses. This produces realistic renderings of novel
poses of the person, including clothing, hair, and plausible in-
filling of unseen regions. This disentangled approach allows
our method to generate a sequence of images that are faithful
to the target motion in the 3D pose and, to the input image
in terms of visual similarity. In addition to that, the 3D con-
trol allows various synthetic camera trajectories to render a
person. Our experiments show that our method is resilient in
generating prolonged motions and varied challenging and
complex poses compared to prior methods. Please check our
website for more details: 3DHM.github.io.
1. Introduction
Given a random photo of a person, can we accurately an-
imate that person to imitate someone else’s action? This
arXiv:2401.10889v1  [cs.CV]  19 Jan 2024
problem requires a deep understanding of how human poses
change over time, learning priors about human appearance
and clothing. For example, in Figure 1 the Actor can do a
diverse set of actions, from simple actions such as walking
and running to more complex actions such as fighting and
dancing. For the Imitator, learning a visual prior about
their appearance and clothing is essential to animate them
at different poses and viewpoints. To tackle this problem,
we propose 3DHM, a two-stage framework (see Figure 2)
that synthesizes 3D Human Motions by completing a texture
map from a single image and then rendering the 3D humans
to imitate the actions of the actor.
We use state-of-the-art 3D human pose recovery model
4DHumans [9, 19] for extracting motion signals of the actor,
by reconstructing and tracking them over time. Once we
have a motion signal in 3D, as a sequence of meshes, one
would think we can simply re-texture them with the texture
map of the imitator to get an intermediate rendering of the
imitation task. However, this requires a complete texture
map of the imitator. When given only a single view image
of the imitator, we see only a part of their body, perhaps
the front side, or the backside but never both sides. To get
the complete texture map of the imitator from a single view
image, we learn a diffusion model to in-fill the unseen re-
gions of the texture map. This essentially learns a prior about
human clothing and appearance. For example, a front-view
image of a person wearing a blue shirt would usually have
the same color at the back. With this complete texture map,
now we can get an intermediate rendering of the imitator
doing the actions of the actor. Intermediate rendering means,
wrapping the texture map on top of the SMPL [17] mesh to
get a body-tight rendering of the imitator.
However, the SMPL [17] mesh renderings are body-tight
and do not capture deformations on clothing, like skirts or
various hairstyles. To solve this, we learn a second model,
that maps from mesh renderings to more realistic images,
by controlling the motion with 3D poses. We find out such
a simple framework could successfully synthesize realis-
tic and faithful human videos, particularly for long video
generations. We show that the 3D control provides a more
fine-grained and accurate flow of motion and captures the
visual similarities of the imitator faithfully.
While there has been a lot of work on rewriting the motion
of an actor [4, 14, 28], each requires either large amounts
of data, supervised control signals, or requires careful cura-
tions of the training data. For example, Make-a-video [24]
can generate decent results while for human videos, it often
generates incomplete or nonconsequential videos and fails
at faithful reconstruction of humans. Some works [8] use
Openpose [6] as intermediate supervision. However, Open-
pose primarily contains the anatomical key points of humans,
it can not be used to indicate the body shape, depth, or other
related human body information. DensePose [10] aims to
recover highly accurate dense correspondences between im-
ages and the body surface to provide dense human pose
estimation. However, it can not reflect the texture informa-
tion from the original inputs. Compared to this line of work,
ours fully utilizes the 3D models to control the motion, by
providing an accurate dense 3D flow of the motion, and the
texture map representation makes it easy to learn appearance
prior from a few thousand samples.
2. Related Works
Controllable Human Generation. Human generation is
not an easy task. Unlike image translation [16], generating
different humans requires the model to understand the 3D
structure of the human body. Given arbitrary text prompts or
pose conditions [5, 15], we often find out that existing gener-
ative models often generate unreasonable human images or
videos. Diffusion-HPC [31] proposes a diffusion model with
Human Pose Correction and finds that injecting human body
structure priors within the generation process could improve
the quality of generated images. ControlNet [34] is designed
on neural network architecture to control pre-trained large
diffusion models to support additional input conditions, such
as Openpose [6]. GestureDiffuCLIP [3] designs a neural
network to generate co-speech gestures. However, these
techniques are not tailored for animating humans, which can-
not guarantee the required human appearance and clothing.
Synthesizing Moving People. Synthesizing moving peo-
ple is very challenging. For example, Make-a-Video [24]
or Imagen Video [23] could synthesize videos based on a
given instruction. However, the generated video cannot ac-
curately capture human properties correctly and may cause
the weird composition of generated humans. Prior meth-
ods [8, 29] learn pose-to-pixels mapping directly. However,
these designs could only be trained and used for one per-
son. Recent works such as SMPLitex [7] consider human
texture estimation from a single image to animate a person.
However, there is a visual gap between rendered people via
predicted texture map and real humans. Many works start
to directly predict pixels based on diffusion models, such as
Dreampose [14] and DisCO [28]. DreamPose is controlled
by DensePose [10], it aims to synthesize a video contain-
ing both human and fabric motion based on a sequence of
human body poses. DisCO is directly controlled by Open-
pose [6], and it aims to animate the human based on the 2D
pose information. However, the approach of aligning output
pixels for training regularization often leads these models to
become overly specialized to certain training data. Moreover,
this methodology limits the models’ generalization capabili-
ties, as they often perform well on a few people whose data
distribution closely matches that of the training dataset.
Stage 1
(Inpainting)
Stage 2
(Rendering)
Predicted
Complete  
Texture map
3D Poses
(from Actor)
Texture mapped
(Imitator)
Final Rendering
(Imitator)
A photo of 
a person
(Imitator)
28-7， 15， 22
Figure 2. Overview of 3DHM: we show an overview of our model pipeline. Given an image of the imitator and a sequence of 3D poses
from the actor, we first generate a complete full texture map of the imitator, which can be applied to the 3D pose sequences extracted from
the actor to generate texture-mapped intermediate renderings of the imitator. Then we pass these intermediate renderings to the Stage-2
model to project the SMPL mesh rendering to more realistic renderings of real images. Note: red boxes represent inputs, yellow boxes
represent intermediate predictions from stage 1, and blue boxes represent the final outputs from stage 2. To create a moving person animation
with variable duration and any number of 3D poses, it is only necessary to execute stage 1 once in order to acquire a complete texture map.
3. Synthesizing Moving People
In this section, we discuss our two-stage approach for imitat-
ing a motion sequence. Our 3DHM framework embraces the
advantage of accurate 3D pose prediction from the state-of-
the-art predicting models 4DHumans [9, 19], which could
accurately track human motions and extracts 3D human
poses of the actor videos. For any given video of the actor
we want to imitate, we use 3D reconstruction-based tracking
algorithms to extract 3D mesh sequences of the actor. For
the inpainting and rendering part, we rely on the pre-trained
Stable Diffusion [22] model, which is one of the most recent
classes of diffusion models that achieve high competitive
results over various generative vision tasks.
Our approach 3DHM is composed of two core parts: In-
painting Diffusion for texture map in-painting as Stage-1
and Rendering Diffusion for human rendering as Stage-2.
Figure 2 shows a high-level overview of our framework. In
Stage-1, first, for a given single view image, we extract a
rough estimate of the texture map by rendering the meshes
onto the image and assigning pixels to each visible mesh tri-
angle such that when rendered again it will produce a similar
image as the input image. This predicted texture map has
only visible parts of the input image. The Stage-1 Diffusion
in-painting model takes this partial texture map and gener-
ates a complete texture map including the unseen regions.
Given this completed texture map, we generate intermediate
renderings of SMPL [17] meshes and use Stage-2 model to
project the body-tight renderings to more realistic images
with clothing. For the Stage-2 Diffusion model, we apply
3D control to animate the imitator to copy the actions of the
actor.
3.1. Texture map Inpainting
The goal of Stage-1 model is to produce a plausible complete
texture map by inpainting the unseen regions of the imitator.
We extract a partially visible texture map by first rendering a
3D mesh onto the input image and sample colors for each
visible triangle following 4DHumans [9].
Input. We first utilize a common approach to infer pixel-
to-surface correspondences to build an incomplete UV tex-
turemap [7, 32] for texturing 3D meshes from a single RGB
image. We also compute a visibility mask to indicate which
pixels are visible in 3D and which ones are not.
Target. Since the objective of this modeling is to generate
complete texture maps, we generate a pseudo-complete tex-
ture map using video data. Since the 4DHumans can track
people over time, it continually updates its internal texture
map representations as a moving average of visible regions.
However to produce more sharp images, for the generative
task we found that a median filtering is more suitable than
a moving average. While this technique can be applied to
any video, in this stage we rely on 2,205 human videos. For
each human video, we first extract a partial texture map from
each frame. Since each video contains 360 degrees of human
views, we calculate a pseudo-complete texture map from a
whole video and set it as the target output for Stage 1. In
detail, we take the median overall visible parts of texture
maps of a video.
Model. We finetune directly on the Stable Diffusion In-
painting model [21] that shows great performance on image
completion tasks. We input a partial texture map and corre-
sponding visibility mask and obtain the recovered predicted
map for the human. We lock the text encoder branch and
Stable Diffusion 
Inpainting
A photo of 
a person
(Imitator)
Extracted  
Texture map
Visibility Mask
Predicted 
Complete 
Texture map
28,60， -03794
Figure 3. Stage-1 of 3DHM: In the first stage, given a single view
image of an imitator, we first apply 4Dhumans [9] style sampling
approach to extract partial texture map and its corresponding visi-
bility map. These two inputs are passed to the in-painting diffusion
model to generate a plausible complete texture map. In this exam-
ple, while we only see the back view of the imitator, the model
was able to hallucinate a plausible front region that is consistent
with their clothing.
always feed ‘real human’ as input text of fixed Stable Dif-
fusion models. We refer to our trained model as Inpainting
Diffusion. See Figure 3 for the model architecture.
3.2. Human Rendering
In Stage 2, we aim to obtain a realistic rendering of a human
imitator doing the actions of the actor. While the interme-
diate renderings (rendered with the poses from the actor
and texture map from Stage-1) can reflect diverse human
motion, these SMPL mesh renderings are body-tight and
cannot represent realistic rendering with clothing, hairstyles,
and body shapes. For example, if we input a scene where
a girl is wearing a dress and she is dancing, the intermedi-
ate renderings might be able to “dance"" but it is impossible
to animate the skirt with SMPL mesh rendering. To train
this model, in a fully self-supervised fashion, we assume
the actor is the imitator, after all a good actor should be a
good imitator. This way, we can take any video, and get a
sequence of poses from 4DHumans [9] and take any single
frame, and get a complete texture map from Stage-1, then get
the intermediate renderings by rendering the texture maps
on the 3D poses. Now, we have paired data of intermediate
renderings and real RGB images. Using this, we collect a
large amount of paired data and train our Stage-2 diffusion
model with conditioning.
Input: We first apply the generated texture map (fully com-
plete) from Stage 1 to actor 3D body mesh sequences to an
intermediate rendering of the imitator performing the actions
of the actor. Note at this time, intermediate rendering can
only reflect the clothing that fits the 3D mesh (body-tight
clothing) but fails to reflect the texture outside the SMPL
body, such as the puffed-up region of a skirt, winter jacket, or
hat. To obtain the human with complete clothing texture, we
input the obtained intermediate renderings and the original
Input Image
      (t=0)
   Texture mapped
                  (at time t)
StableDiffusion 
Encoder
StableDiffusion 
Decoder
3D Controllable
Branch
Input Latents 
(64 x 64)
Output Latents 
(64 x 64)
Final Rendering
(at time t)
decode latents
cvpr1 - 106
Figure 4. Stage-2 of 3DHM: This figure shows the inference of our
Stage-1 approach. Given an intermediate rendering of the imitator
with the pose of the actor and the actual RGB image of the imitator,
our model can synthesize realistic renderings of the imitator on the
pose of the actor.
image of the person into Rendering Diffusion to render the
human in a novel pose with a realistic appearance.
Target: Since we collected the data by assuming the actor
is the imitator, we have the paired data of the intermediate
renderings and the real RGB images. This allows us to train
this model on lots of data, without requiring any direct 3D
supervision.
Model. Similar to ControlNet, we directly clone the weights
of the encoder of the Stable Diffusion [20] model as our Con-
trollable branch (""trainable copy"") to process 3D conditions.
We freeze the pre-trained Stable Diffusion and input noisy la-
tents (64×64). In the meanwhile, we input a texture mapped
3D human at time t and original human photo input into a
fixed VAE encoder and obtain texture mapped 3D human
latents (64 × 64) and appearance latents (64 × 64) as condi-
tioning latents. We feed these two conditioning latents into
Rendering Diffusion Controllable branch. The key design
principle of this branch is to learn textures from human input
and apply them to the texture mapped 3D human during
training through the denoising process. The goal is to render
a real human with vivid textures from the generated(texture
mapped) 3D human from Stage 1. We obtain the output
latent and process it to the pixel space via diffusion step pro-
cedure and fixed VAE decoder. Same to Stage 1, we lock the
text encoder branch and always feed ‘a real human is acting’
as input text of fixed Stable Diffusion models. We refer to
our trained model as Rendering Diffusion. In Rendering
Diffusion, we predict outputs frame by frame. We show the
Stage 2 workflow in Figure 4.
4. Experiments
4.1. Experimental Setup
Dataset.
We collect 2,524 3D human videos from
2K2K [11], THuman2.0 [33] and People-Snapshot [2]
datasets. 2K2K is a large-scale human dataset with 3D
human models reconstructed from 2K resolution images.
THuman2.0 contains 500 high-quality human scans captured
by a dense DLSR rig. People-Snapshot is a smaller human
dataset that captures 24 sequences. We convert the 3D hu-
man dataset into videos and extract 3D poses from human
videos using 4DHumans. We use 2,205 videos for training
and other videos for validation and testing. See the Appendix
for more details on the dataset distribution on clothing.
Evaluation Metrics. We evaluate the quality of generated
frames of our method with image-based and video-based
metrics. For image-based evaluation, we follow the evalua-
tion protocol of DisCO [28] to evaluate the generation qual-
ity. We report the average PSNR [13], SSIM [30], FID [12],
LPIPS [35], and L1. For video-based evaluation, we use
FVD [26]. For pose evaluating 3D pose accuracy we use
MPVPE and PA-MVPVE. MPVPE [18], or Mean Per-Vertex
Position Error, is a critical metric in 3D human pose estima-
tion, which quantifies the average distance between predicted
and actual 3D vertices across a model. This measurement
is essential for evaluating the accuracy of 3D reconstruc-
tions and pose estimations, with a lower MPVPE indicat-
ing higher precision. Complementing this, PA-MPVPE, or
Procrustes-Aligned Mean Per-Vertex Position Error, adds
another dimension to this evaluation. It involves aligning
the predicted and ground truth data using Procrustes Analy-
sis, which neutralizes differences in orientation, scale, and
position before calculating the mean error. This alignment
allows PA-MPVPE to focus on the structural accuracy of
predictions, making it a valuable metric for assessing the
relative positioning of vertices in a model, independent of
their absolute spatial coordinates.
Implementation Details. As for training all the datasets, we
set the constant learning rate as 5e-05 and use the pre-trained
diffusion models from diffusers [27] for both Stage-1 and
Stage-2. As for Stage 1 Inpainting Diffusion, we finetune on
Stable Diffusion Inpainting models [21], which has an 859M
total number of trainable parameters and 206M total number
of non-trainable parameters, since the VAE is frozen during
this stage. We train Rendering Diffusion for 50 epochs and it
takes about 2 weeks to run our model on our soup of training
datasets. As for Stage 2 Rendering Diffusion, we train the
Controllable branch and freeze Stable Diffusion backbones.
The total number of trainable parameters in this case is 876M
and the total number of non-trainable parameters is 1.1B.
We train Rendering Diffusion for 30 epochs and it takes
Method
PSNR↑
SSIM ↑
FID ↓
LPIPS ↓
L1 ↓
DreamPose
35.06
0.80
245.19
0.18
2.12e-04
DisCO
35.38
0.81
164.34
0.15
1.44e-04
Ours
36.18
0.86
154.75
0.12
9.88e-05
Table 1. Quantitative comparison on frame-wise generation
quality : We compare our method with prior works on pose con-
dition generation tasks and measure the generation quality of the
samples.
about 2 weeks to run our model on training datasets based
on 8 NVIDIA A100 GPUs with a batch size of 4. As for
inference, we only need to run Stage-1 once to reconstruct
the full texture map of the imitator, and it is used for all other
novel poses and viewpoints. We run Stage-2 inference for
each frame independently, however since the initial RGB
frame of the imitator is conditioned for all frames, the Stage-
2 model is able to produce samples that are temporarily
consistent.
4.2. Quantitative Results
Baselines. We compare our approaches with past and state-
of-the-art methods: DreamPose [14], DisCo [28] and Con-
trolNet [34] (for pose accuracy comparisons)1. We set infer-
ence steps as 50 for all the approaches for fair comparisons.
Comparisons on Frame-wise Generation Quality. We
compare 3DHM with other methods on 2K2K test dataset,
which is composed of 50 unseen human videos, at 256×256
resolution. For each human video, we take 30 frames that
represent the different viewpoints of each unseen person.
The angles range from 0◦ to 360◦, we take one frame every
12◦ to better evaluate the prediction and generalization abil-
ity of each model. As for DisCO, we strictly follow their
setting and extract OpenPose for inference. As for Dream-
Pose, we extract DensePose for inference. We evaluate the
results and calculate the average score over all frames of each
video. We set the background as black for all approaches for
fair comparisons. We report the average score overall of the
same 50 videos and show the comparisons in Table 1. We
observe that 3DHM outperforms all the baselines in different
metrics.
Comparisons on Video-level Generation Quality. To ver-
ify the temporal consistency of 3DHM, we also report the re-
sults following the same test set and baseline implementation
as in image-level evaluation. Unlike image-level compar-
isons, we concatenate every consecutive 16 frames to form
a sample of each unseen person on challenging viewpoints.
The angles range from 150◦ to 195◦, we take one frame
1We utilize the open-source official code and models provided by the
authors to implement these baselines. We use diffusers [27] for ControlNet
and Openpose extraction, and Detectron2 for DensePose extraction for
DisCO. Since Chan et al. [8] can only work for animating a specific person,
we don’t compare with it in this paper.
Method
FID-VID↓
FVD ↓
DreamPose
113.96
950.40
DisCO
83.91
629.18
Ours
55.40
422.38
Table 2. Quantitative comparison on video-level generation quality.
Method
MPVPE ↓
PA-MPVPE ↓
DreamPose
123.07
82.75
DisCO
112.12
63.33
ControlNet
108.32
59.80
Ours
41.08
31.86
Table 3. Quantitative comparison on pose accuracy.
every 3◦ to better evaluate the prediction and generalization
ability of each model. We report the average score overall
of 50 videos and show the comparisons in Table 2. We ob-
serve that 3DHM, though trained and tested by per frame,
still embrace significant advantage over prior approaches,
indicating superior performance on preserving the temporal
consistency with 3D control.
Comparisons on Pose Accuracy. To further evaluate the
validity of our model, we estimate 3D poses from generated
human videos from different approaches via a state-of-the-
art 3D pose estimation model 4DHumans. We use the same
dataset setting mentioned above and compare the extracted
poses with 3D poses from the target videos. Following the
same comparison settings with generation quality, we evalu-
ate the results and calculate the average score over all frames
of each video. Beyond DreamPose and DisCO, we also com-
pare with ControlNet, which achieves the state-of-the-art
in generating images with conditions, including openpose
control. Since ControlNet does not input images, we input
the same prompts as ours ‘a real human is acting’ and the
corresponding openpose as conditions. We report the aver-
age score overall of 50 test videos and show the comparisons
in Table 3. We could notice that 3DHM could synthesize
moving people following the provided 3D poses with very
high accuracy. At the same time, previous approaches might
not achieve the same performance by directly predicting the
pose-to-pixel mapping. We also notice that 3DHM could
achieve superior results on both 2D metrics and 3D metrics,
even if DisCO and ControlNet are controlled by Openpose
and DreamPose is controlled by DensePose.
4.3. Qualitative Results
Our work focuses on synthesizing moving people, primar-
ily for clothing and the human body. With the aid of 3D
assistance, our approach has the potential to produce human
Settings
PSNR↑
SSIM ↑
FID ↓
LPIPS ↓
L1 ↓
Default
36.18
0.86
154.75
0.12
9.88e-05
w/o Texture map
35.00
0.78
237.42
0.20
2.35e-04
w/o Appearance Latents
36.07
0.86
167.58
0.12
1.03e-04
adding SMPL parameters
36.42
0.87
157.60
0.12
8.87e-05
Table 4. Ablation study of Rendering Diffusion. We compare the
frame-wise generation quality under different settings. We notice
both texturemap reconstruction and appearance latents are critical
to the model performance.
motion videos in various scenarios. We consider challenging
3D poses and motions from 3 sources: 3D human videos,
random YouTube videos, and text input.
Poses from Unseen 3D Human Videos. We test our model
on different 3D human videos with different human appear-
ances and 3D poses from the 2K2K dataset. We verify that
the tested video has never appeared in training data. We
display the results in Figure 5a.
Motions from Random YouTube Videos. We test our
model on very different motions from randomly downloaded
Youtube videos for an unseen human. We display the results
in Figure 5b.
Motions from Text Inputs. We test our model on motions
from arbitrary text prompts. We randomly input an unseen
human photo and motions from random text inputs via a
widely used human motion generative model (MDM [25]).
We display the results in Figure 5c.
5. Analysis and Discussion
5.1. Ablation Study
To further verify the components of our methods, we train
on training dataset and test on test datasets. We extract the
3D rendered pose from these 50 test video tracks. Same
with the settings in quantitative comparison, we calculate
the average scores of PSNR, SSIM, VGG, L1, LPIPS among
all the generated frames and targeted original frames and
report the results on both frame-wise metric (Table 4), video-
level metric (Table 5) and pose accuracy (Table 6). We find
that both texture map reconstruction and appearance latents
are critical to the model performance. Also, we notice that
directly adding SMPL parameters into the model during
training may not bring improved performance considering
all evaluation metrics. This is presumably due to the impreci-
sion of SMPL parameters, which could provide contradictory
information throughout the diffusion training process if they
are not incorporated correctly.
5.2. 2D Control and 3D Control
We also compare the results of the official model from
DreamPose and DisCO on a random person on a random
real human photo which ensures distinct data distribution.
Various
Viewpoints
(a) 3DHM with a random human photo and a random 3D pose of various viewpoints. We show that even if the person’s photo is from a side angle, our stage 1
can help reconstruct the full texture map, which could be used to obtain full body information. Stage 2 can add texture information based on a given input.
Motions from
random videos
(b) 3DHM with a random human photo and motions from random YouTube Videos. This example is from Gene Kelly’s dancing video.
A person turns to his right and paces back and forth.
Motions
from text
(c) 3DHM with a random human photo and motions generated from text inputs by MDM, a Human Motion Diffusion Model [25].
Figure 5. Qualitative results on different viewpoints of the same pose; motions from random videos and motions from text input.
We display the qualitative results of various viewpoints in
Figure 6. DreamPose, DisCO, and 3DHM are all initialize
the U-Net model with the pre-trained weights of Stable Dif-
fusion. We notice that 3DHM can generalize well to unseen
real humans though it is only trained by limited 3D humans.
Since DreamPose requires subject-specific finetuning of the
UNet to achieve better results, it cannot directly generalize
well on a random human photo. As for DisCO, though it has
been trained with an effective human attribute pre-training
on multiple public datasets for better generalizability to un-
seen humans, still fails to synthesize people without the
target pose. We assume this is because 3DHM adds rigid
3D control to better correlate the appearance to the poses,
and preserve the body shape. Training with OpenPose or
DensePose cannot guarantee the mapping between textures
and poses, which makes it hard for the models to generalize.
Inputs
Various 3D Poses
DreamPose
DisCO
Ours
Various Viewpoints
Figure 6. Qualitative comparison with other 2D control approaches on a random real human photo (a Korean actress). We apply various 3D
poses or the same 3D pose from different viewpoints. It could be noticed that 2D poses may not be able to capture the folding motion, and
details of the human body. We could notice that our approach 3DHM could bridge this gap with 3D control.
Method
FID-VID↓
FVD ↓
Default
55.40
422.38
w/o Texture map
113.97
632.67
w/o Appearance Latents
93.21
715.51
adding SMPL parameters
72.35
579.90
Table 5. Ablation study of Rendering Diffusion. We compare the
video-level generation quality under different settings. We notice
that although adding SMPL parameters achieve better performance
on frame-wise setting but may yield worse temporal consistency
than default settings.
5.3. Limitations
As 3DHM generates the frames of the human motion videos
independently, there is no guarantee of consistency in time.
For example, the clothing light may change between consec-
utive frames. One possible solution is to train the model to
predict multiple frames simultaneously. Another possible
solution is to condition the generation process on previously
generated frames via stochastic conditioning [1]. Addition-
Method
MPVPE ↓
PA-MPVPE ↓
Default
41.08
31.86
w/o Texture map
92.94
59.18
w/o Appearance Latents
41.99
32.82
adding SMPL parameters
39.16
29.67
Table 6. Ablation study of Rendering Diffusion. We compare the
pose accuracy under different settings.
ally, since 3DHM is trained on a dataset of 2K people, not all
the detailed textures can be reconstructed completely during
inference (e.g. unique logos on the clothes). We hypothesize
this could be alleviated by training with more human data.
6. Conclusion
In this paper, we propose 3DHM, a two-stage diffusion
model-based framework that enables synthesizing moving
people based on one random photo and target human poses.
A notable aspect of our approach is that we employ a cutting-
edge 3D pose estimation model to generate human motion
data, allowing our model to be trained on arbitrary videos
without necessitating ground truth labels. Our method is
suitable for long-range motion generation, and can deal with
arbitrary poses with superior performance over previous ap-
proaches.
Acknowledgement
We thank the Machine Common Sense project and ONR
MURI award number N00014-21-1-2801. We also thank
Google’s TPU Research Cloud (TRC) for providing cloud
TPUs. We thank Georgios Pavlakos, Shubham Goel, and
Jane Wu for the constructive feedback and helpful discus-
sions.
Appendices
A. Dataset Analysis
Figures 7a and 7b present the clothing type statistics of the
training data (2,205 humans) and test data (50 humans). We
count people based on four clothing categories: skirted attire,
suit, casual wear, and others. In some cases, the clothing
belongs to skirted attire and suits or casual wear, we will
count this as skirted attire. For each clothing category, we
tally two styles: tight-fitting and loose-fitting.
In this paper, we only train on limited human videos, we
assume training with more human videos could largely boost
the model generalization on the fly. Given that 3DHM makes
use of a cutting-edge 3D pose estimation model and only
requires human videos without additional labels for training,
it could be trained with numerous and any human videos
such as movies, etc.
B. 3DHM Training Features
As has been mentioned in the paper, 3DHM is in a fully
self-supervised fashion. Here we summarize the key training
features of our approach:
• 3DHM training pipeline (for both stages) is self-
supervised.
• 3DHM does not use any additional annotations. It is
trained with pseudo-ground-truth as we use cutting-edge
software which can detect, segment, track and 3Dfy hu-
mans (H4D).
• 3DHM is scalable and its scaling can be done readily in
the future given additional videos of humans in motion
and computing resources.
128
7
571
2
0
250
500
750
1000
1250
Skirted Attire
Suit
Casual Wear
Others
Loose-fitting
Tight-fitting
(a) Training data distribution.
8
0
5
0
0
5
10
15
20
25
Skirted Attire
Suit
Casual Wear
Others
Loose-fitting
Tight-fitting
(b) Testing data distribution.
Figure 7. Data distribution. We split the clothing type into 4
categories: skirted attire, suit, casual wear, and others. We split
each category into two types: loose and tight. We report the number
of each category and type and display the overall distribution. We
could notice that most clothing is casual wear and a large portion
belongs to tight-fitting.
References
[1] Sadegh Aliakbarian, Fatemeh Sadat Saleh, Mathieu
Salzmann, Lars Petersson, and Stephen Gould.
A
stochastic conditioning scheme for diverse human mo-
tion prediction. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition,
pages 5223–5232, 2020. 8
[2] Thiemo Alldieck, Marcus Magnor, Weipeng Xu, Chris-
tian Theobalt, and Gerard Pons-Moll. Video based
reconstruction of 3d people models. In Proceedings of
the IEEE Conference on Computer Vision and Pattern
Recognition, pages 8387–8397, 2018. 5
[3] Tenglong Ao, Zeyi Zhang, and Libin Liu. Gesturedif-
fuclip: Gesture diffusion model with clip latents. arXiv
preprint arXiv:2303.14613, 2023. 2
[4] Christoph Bregler, Michele Covell, and Malcolm
Slaney. Video rewrite: Driving visual speech with au-
dio. In Seminal Graphics Papers: Pushing the Bound-
aries, Volume 2, pages 715–722. 2023. 2
[5] Tim Brooks and Alexei A Efros. Hallucinating pose-
compatible scenes. In European Conference on Com-
puter Vision, 2022. 2
[6] Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser
Sheikh.
Realtime multi-person 2d pose estimation
using part affinity fields. In Proceedings of the IEEE
conference on computer vision and pattern recognition,
pages 7291–7299, 2017. 2
[7] Dan Casas and Marc Comino Trinidad.
Smplitex:
A generative model and dataset for 3d human tex-
ture estimation from single image.
arXiv preprint
arXiv:2309.01855, 2023. 2, 3
[8] Caroline Chan, Shiry Ginosar, Tinghui Zhou, and
Alexei A Efros. Everybody dance now. In Proceedings
of the IEEE/CVF international conference on computer
vision, pages 5933–5942, 2019. 2, 5
[9] Shubham Goel, Georgios Pavlakos, Jathushan Ra-
jasegaran, Angjoo Kanazawa, and Jitendra Malik. Hu-
mans in 4D: Reconstructing and tracking humans with
transformers. In ICCV, 2023. 2, 3, 4
[10] Rıza Alp Güler, Natalia Neverova, and Iasonas Kokki-
nos. Densepose: Dense human pose estimation in the
wild. In Proceedings of the IEEE conference on com-
puter vision and pattern recognition, pages 7297–7306,
2018. 2
[11] Sang-Hun Han, Min-Gyu Park, Ju Hong Yoon, Ju-
Mi Kang, Young-Jae Park, and Hae-Gon Jeon. High-
fidelity 3d human digitization from single 2k resolution
images. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition (CVPR),
2023. 5
[12] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner,
Bernhard Nessler, and Sepp Hochreiter. Gans trained
by a two time-scale update rule converge to a local
nash equilibrium. Advances in neural information pro-
cessing systems, 30, 2017. 5
[13] Alain Hore and Djemel Ziou. Image quality metrics:
Psnr vs. ssim. In 2010 20th international conference
on pattern recognition, pages 2366–2369. IEEE, 2010.
5
[14] Johanna Karras, Aleksander Holynski, Ting-Chun
Wang, and Ira Kemelmacher-Shlizerman. Dreampose:
Fashion image-to-video synthesis via stable diffusion.
arXiv preprint arXiv:2304.06025, 2023. 2, 5
[15] Sumith Kulal, Tim Brooks, Alex Aiken, Jiajun Wu,
Jimei Yang, Jingwan Lu, Alexei A. Efros, and Kr-
ishna Kumar Singh.
Putting people in their place:
Affordance-aware human insertion into scenes. In Pro-
ceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2023. 2
[16] Boyi Li, Yin Cui, Tsung-Yi Lin, and Serge Belongie.
Sitta: Single image texture translation for data augmen-
tation. In European Conference on Computer Vision,
pages 3–20. Springer, 2022. 2
[17] Matthew Loper, Naureen Mahmood, Javier Romero,
Gerard Pons-Moll, and Michael J Black. Smpl: A
skinned multi-person linear model. In Seminal Graph-
ics Papers: Pushing the Boundaries, Volume 2, pages
851–866. 2023. 2, 3
[18] Gyeongsik Moon, Hongsuk Choi, and Kyoung Mu
Lee. Accurate 3d hand pose estimation for whole-
body 3d human mesh estimation. In Proceedings of
the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 2308–2317, 2022. 5
[19] Jathushan Rajasegaran, Georgios Pavlakos, Angjoo
Kanazawa, and Jitendra Malik. Tracking people by pre-
dicting 3d appearance, location and pose. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 2740–2749, 2022. 2, 3
[20] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Björn Ommer. High-resolution im-
age synthesis with latent diffusion models. 2022 ieee.
In CVF Conference on Computer Vision and Pattern
Recognition (CVPR), pages 10674–10685, 2021. 4
[21] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Björn Ommer. High-resolution im-
age synthesis with latent diffusion models. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR), pages 10684–10695,
2022. 3, 5
[22] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Björn Ommer. High-resolution im-
age synthesis with latent diffusion models. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 10684–10695, 2022. 3
[23] Chitwan Saharia, William Chan, Saurabh Saxena, Lala
Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour,
Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Sal-
imans, et al. Photorealistic text-to-image diffusion
models with deep language understanding. Advances
in Neural Information Processing Systems, 35:36479–
36494, 2022. 2
[24] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin,
Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang,
Oron Ashual, Oran Gafni, et al. Make-a-video: Text-
to-video generation without text-video data.
arXiv
preprint arXiv:2209.14792, 2022. 2
[25] Guy Tevet, Sigal Raab, Brian Gordon, Yoni Shafir,
Daniel Cohen-or, and Amit Haim Bermano. Human
motion diffusion model. In The Eleventh International
Conference on Learning Representations, 2023. 6, 7
[26] Thomas Unterthiner, Sjoerd Van Steenkiste, Karol Ku-
rach, Raphael Marinier, Marcin Michalski, and Syl-
vain Gelly. Towards accurate generative models of
video: A new metric & challenges. arXiv preprint
arXiv:1812.01717, 2018. 5
[27] Patrick von Platen, Suraj Patil, Anton Lozhkov, Pe-
dro Cuenca, Nathan Lambert, Kashif Rasul, Mishig
Davaadorj, and Thomas Wolf. Diffusers: State-of-
the-art diffusion models. https://github.com/
huggingface/diffusers, 2022. 5
[28] Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin,
Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, and
Lijuan Wang. Disco: Disentangled control for referring
human dance generation in real world. arXiv preprint
arXiv:2307.00040, 2023. 2, 5
[29] Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Guilin
Liu, Andrew Tao, Jan Kautz, and Bryan Catan-
zaro.
Video-to-video synthesis.
arXiv preprint
arXiv:1808.06601, 2018. 2
[30] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and
Eero P Simoncelli. Image quality assessment: from er-
ror visibility to structural similarity. IEEE transactions
on image processing, 13(4):600–612, 2004. 5
[31] Zhenzhen Weng, Laura Bravo-Sánchez, and Serena Ye-
ung. Diffusion-hpc: Generating synthetic images with
realistic humans. arXiv preprint arXiv:2303.09541,
2023. 2
[32] Xiangyu Xu and Chen Change Loy. 3d human texture
estimation from a single image with transformers. In
Proceedings of the IEEE/CVF international conference
on computer vision, pages 13849–13858, 2021. 3
[33] Tao Yu, Zerong Zheng, Kaiwen Guo, Pengpeng Liu,
Qionghai Dai, and Yebin Liu. Function4d: Real-time
human volumetric capture from very sparse consumer
rgbd sensors. In IEEE Conference on Computer Vision
and Pattern Recognition (CVPR2021), 2021. 5
[34] Lvmin Zhang and Maneesh Agrawala. Adding condi-
tional control to text-to-image diffusion models. arXiv
preprint arXiv:2302.05543, 2023. 2, 5
[35] Richard Zhang, Phillip Isola, Alexei A Efros, Eli
Shechtman, and Oliver Wang. The unreasonable ef-
fectiveness of deep features as a perceptual metric. In
Proceedings of the IEEE conference on computer vi-
sion and pattern recognition, pages 586–595, 2018.
5
"
"RetinaVR, an affordable and immersive virtual reality simulator for vitreoretinal surgery training, is developed and validated in this study. RetinaVR does not require external haptic devices, leveraging the powerful processors, cameras, and sensors of the Meta Quest 2 VR headset. Four core surgical skills were chosen to be simulated: core vitrectomy, peripheral shaving, membrane peeling, and endolaser application. The validation study involved 10 novice and 10 expert ophthalmologists. Construct validity, shown by varying user performance based on experimental runs, age, sex, and expertise, was demonstrated. A learning curve was noted in efficiency, safety, and task-specific performance, providing evidence of improvement with repetition. Specialists had significantly fewer sphere exits during core vitrectomy and better treatment patterns during endolaser application. The authors suggest that such a tool may democratize surgical simulation access and stimulate global ophthalmology innovation. However, further validation is needed to prove skill transfer to the operating room.nan","Ophthalmology has utilized virtual reality (VR) simulation in healthcare, improving the surgical performance of novice cataract surgeons and reducing complication rates. However, its use in vitreoretinal surgery training remains under-researched. The authors of this work present RetinaVR, an affordable and immersive VR simulator for vitreoretinal surgery training, hoping to democratize surgical simulation and spur global ophthalmic education. RetinaVR does not require external haptic devices, leveraging the capabilities of the Meta Quest 2 VR headset. RetinaVR was validated using a prospective study involving 10 novice and 10 expert ophthalmologists, with results demonstrating construct and learning curve validity.nan","VR simulation in ophthalmology has been shown to enhance cataract surgeon performance, but its role in vitreoretinal surgery training is less clear. An oft-cited VR simulator used in ophthalmology is the EyeSi Surgical Simulator, which comprises a mannequin head, surgical instruments, foot pedals, and a VR interface. EyeSi has been shown to be cost-effective for cataract surgery training but is expensive and requires an annual running cost. In developing nations and under-resourced areas, this poses a significant acquisition barrier. Thus, the study's authors sought to create an alternative which would be affordable and portable, broadening access to surgical simulation.nannan","The authors developed RetinaVR as a simulation app compatible with commercially available VR headsets. It utilizes the Meta Quest 2, a popular VR headset, for its processing power, cameras, and sensors. Four fundamental vitreoretinal surgery skills were chosen for simulation: core vitrectomy, peripheral shaving, membrane peeling, and endolaser application. Validation involved a prospective study comparing the performance of novice (n=10) and expert (n=10) ophthalmologists recruited from the University of Montreal. Construct validity was measured by analyzing performance based on expertise, age, sex, and experimental run. Additionally, learning curve validity was assessed by analyzing performance changes across three experimental runs.nan","Construct validity was demonstrated, with varying user performance based on experimental runs, age, sex, and expertise. Experts took less time and made fewer errors than novices. In core vitrectomy, experts had significantly fewer sphere exits. Both groups showed a learning curve in efficiency, safety, and task-specific performance, with improvements across experimental runs. In endolaser application, experts exhibited clinically significant differences in treatment patterns compared to novices. No impact of age or sex on performance was observed when controlling for expertise and experimental run.nan","RetinaVR demonstrates construct and learning curve validity, supporting its use as a portable and affordable simulator, especially valuable in resource-limited settings. It could democratize surgical simulation access and promote global ophthalmic education and collaboration. The authors highlight the need for further validation, including skill transfer to the operating room, before widespread use, and also plan to address feedback received during the study to improve RetinaVR.nan",RetinaVR: Democratizing Vitreoretinal Surgery Training with a Portable and Affordable Virtual Reality Simulator in the Metaverse,"Fares Antaki, Cédryk Doucet, Daniel Milad, Charles-Édouard Giguère, Benoit Ozell, Karim Hammamji"," 
 
1 
RetinaVR: Democratizing Vitreoretinal Surgery 
Training with a Portable and Affordable Virtual 
Reality Simulator in the Metaverse 
 
Fares Antaki, MDCM, FRCSC1,2,3, Cédryk Doucet, MASc4, Daniel Milad, MD2,3, Charles-
Édouard Giguère, MSc5, Benoit Ozell, PhD4, Karim Hammamji, MD, FRCSC2,3,* 
 
1. The CHUM School of Artificial Intelligence in Healthcare, Montreal, Quebec, Canada; 2. Department of Ophthalmology, 
Université de Montréal, Montreal, Quebec, Canada; 3. Department of Ophthalmology, Centre Hospitalier de l’Université de 
Montréal, Montreal, Quebec, Canada; 4. Department of Computer Engineering and Software Engineering, Polytechnique 
Montréal, Chemin de Polytechnique, Montréal, Canada; 5. Institut universitaire en santé mentale de Montréal (IUSMM), 
Montreal, Quebec, Canada. *Correspondence. karim.hammamji@gmail.com 
 
Funding: This project received the Innovation in Retina Research Award, including the First Prize (CAD$35,000) and the 
Audience Award (CAD$5,000), at the COS Annual Meeting in June 2021, co-sponsored by the COS and Bayer Inc. 
 
 
 
We developed and validated RetinaVR, an affordable and immersive virtual reality 
simulator for vitreoretinal surgery training, using the Meta Quest 2 VR headset. We 
focused on four core fundamental skills: core vitrectomy, peripheral shaving, 
membrane peeling, and endolaser application. The validation study involved 10 
novice ophthalmology residents and 10 expert vitreoretinal surgeons. We 
demonstrated construct validity, as shown by the varying user performance in a way 
that correlates with experimental runs, age, sex, and expertise. RetinaVR shows 
promise as a portable and affordable simulator, with potential to democratize surgical 
simulation access, especially in developing countries. 
 
Introduction 
Virtual reality (VR) simulation in healthcare has made significant progress over the past two 
decades and is now considered a cornerstone of medical education.1 In surgery, it enables 
trainees to acquire skills in an immersive learning environment that mitigates patient harm. 
The digital nature of VR also alleviates the ethical and logistic challenges tied to wet lab 
training, while offering an interactive, high-fidelity experience.2 In ophthalmology, VR 
simulation has been shown to improve the performance of novice cataract surgeons and to 
decrease their complication rate.3,4 Similar trends have been observed in vitreoretinal 
surgery training, but without definite evidence on skill transfer to the operating room.5,6 
The most frequently studied VR simulator in ophthalmology is the EyeSi Surgical 
Simulator (Haag-Streit Simulation). It comprises a mannequin head, surgical instruments, 
foot pedals, and a VR interface, accessible through the operating microscope.7 Despite its 
high cost of acquisition (approximately USD$200,000) and its annual running costs, the use 
of EyeSi has been shown to be cost-effective for cataract surgery training when considering 
the reduction of complications.4,8,9 However, in developing nations and under-resourced 
communities, the simulator's cost could pose a significant acquisition barrier. This may 
 
 
2 
disproportionately affect these already vulnerable groups, further exacerbating their risk of 
adverse health outcomes.10 
Since the 1970s, head-mounted displays (VR headsets) have steadily decreased in 
weight and improved in computing capacity. VR headsets have moved beyond academic 
labs and are commercially available with prices starting from USD$299.11 VR headsets offer 
several benefits over traditional stationary simulators, including portability, improved 
immersiveness, and multiplayer capabilities through ‘the metaverse’.12 This allows multiple 
users to concurrently use the system and interact together in a virtual environment. By 
leveraging their existing hardware and software capabilities, VR headsets can democratise 
access to surgical simulation, making the metaverse a particularly useful space for global 
ophthalmic education and collaboration. 
In this work, we developed a VR simulation application software for vitreoretinal 
surgery training that is compatible with commercially available VR headsets. RetinaVR is 
fully immersive, affordable, and portable, as it leverages the powerful processors, cameras, 
and sensors of the headset without the need for external haptic devices. We focus on four 
fundamental skills: core vitrectomy, peripheral shaving, membrane peeling, and endolaser 
application. To our knowledge, this is the first vitreoretinal surgery simulator of its kind 
 
Methods 
We provide an overview of RetinaVR in Figure 1. RetinaVR was developed as a simulation 
app that is compatible with off-the-shelf hardware. We focused our work on the affordable 
Meta Quest 2 VR headset (Meta Platforms Inc., California), the best-selling VR headset 
available at the time.13 Four training modules were built to simulate fundamental skills in 
vitrectomy surgery. 
Virtual reality hardware 
We carried out all development experiments on the wired HP Reverb, attached to an AMD 
Ryzen 5 computer with 2600x CPU, 16GB of RAM, and an AMD Radeon RX 5700 XT 
graphics card. After each version iteration, we adapted the app for the wireless Meta Quest 
2 to allow our domain experts to test the software remotely and to provide iterative feedback. 
To ensure broad applicability, we utilized the standard controllers packaged with the Meta 
Quest 2 only, rather than exploring add-on external haptic devices. 
 
The Meta Quest 2 is a general-purpose VR headset that allows for a standalone 
experience, eliminating the need for wiring or a computer connection. This feature renders it 
apt for surgical simulation training, providing an unencumbered environment conducive to 
learning. It comes with two light-weight plastic controllers, each weighing approximately 150 
grams, that are tracked by the headset's integrated cameras. The controllers are designed to 
rest within the curve of the user's palm, allowing the user's fingers to engage with the 
capacitive face, grip and trigger buttons as well as the joystick. 
 
 
 
3 
 
Figure 1. Overview of the RetinaVR development and validation framework. A. RetinaVR was developed in 
the Unity 3D game engine and deployed as an ‘app’ on the Meta Quest 2 VR headset. B. Four training modules 
simulating fundamental skills in vitrectomy surgery were developed: core vitrectomy (Navigation Training), 
peripheral shaving (Tremor Control), membrane peeling (Peeling Control), and endolaser application (Laser 
Precision). C. Multiple potential use cases were considered as rationale for selecting the app format and the 
standalone VR headset. Those included the possibility for home-based solo training, synchronous and 
asynchronous group training through the metaverse, and social competitions and score leaderboards. D. To 
determine construct validity, we designed a prospective validation study comparing the performance of novice 
(n=10) and expert users (n=10) recruited from the University of Montreal in Montreal, Quebec, Canada. We 
analyzed numerous metrics including efficiency, safety and module-specific performance, in relation to their level 
of expertise and demographic factors. 
Virtual reality software 
We developed RetinaVR in the Unity 3D game engine. To represent the eye, a virtual sphere 
was created, and a custom-made fundus illustration was fitted on its inner surface. The 
virtual instruments (light pipe and vitrector/ endolaser) were controlled using standard 
controllers without the use of a physical eye model. The fulcrum effect was challenging to 
reproduce due to the lack of haptic feedback from the virtual eye and the disconnect 
between the two controllers. As such, only one controller could be used to move the eye. For 
all tasks, the left controller was used as a light pipe, while the right controller served as a 
vitrector or an endolaser probe, and controlled eye movements. The virtual instruments 
position and their movements were rotated 45 degrees on the x-axis to allow for ergonomic 
holding of the controllers. To enhance the realism of the simulation, we added the 
 
 
4 
characteristic sound emission produced by the pneumatic guillotine cutter (recorded at 7,500 
cuts per minute) during core vitrectomy and peripheral shaving.14 We also added a laser 
sound to the endolaser application module. The simulation ergonomics are shown in 
Supplemental Figure 2. 
Training modules 
We focused on four fundamental vitreoretinal surgery skills to devise four corresponding 
training tasks: core vitrectomy (Navigation Training), peripheral shaving (Tremor Control), 
membrane peeling (Peeling Control), and endolaser application (Laser Precision). 
Screenshots from each of the modules are shown in Figure 3. 
 
 
 
Figure 3. In-game screenshots from the RetinaVR modules. A. Navigation Training simulates core vitrectomy. 
The goal of the user is to collide with all red spheres, maintain the vitrector in the sphere and turn them green. B. 
Tremor Control simulates peripheral shaving. The user will engage the tip of the vitrector with a sphere, allowing 
it to move along a pre-determined path. C. Peeling Control simulates membrane peeling. The user will grasp the 
membrane by pressing the grip button on the controller before peeling it away from the macula. D. Laser 
Precision simulates endolaser application. The user is asked to treat five retinal breaks by applying laser spots to 
a surrounding donut. A green marker will indicate a fully-treated tear. 
 
1. Navigation Training: To assess navigation skills in the vitreous body, a sphere 
collection exercise was designed using the ‘Collision detection’ module in Unity. Initially 
red, the spheres turn green when collected. To collect a sphere, the tip of the vitrector 
must maintain contact with it for 2 consecutive seconds (determined heuristically) for it 
to disappear. The exercise concludes once all 10 spheres at varying depths within the 
vitreous body are collected. 
 
 
 
5 
2. Tremor Control: The user's ability to control the vitrector during peripheral shaving is 
assessed by moving a target sphere along a pre-determined path. When the tip of the 
vitrector collides with the sphere, it causes the sphere to move along the path until the 
instrument loses contact with the sphere. The goal is to move the sphere along the path, 
without deviating, as smoothly as possible without touching the retina. 
 
3. Peeling Control: This exercise simulated peeling epiretinal membranes using a cutter-
based approach (rather than forceps).15 The objective was to peel the membrane 
completely from the retina without iatrogenic touch. Users could enlarge their view by 
pressing the 'X' button on the left controller, simulating a magnifying lens. To grab the 
membrane, users were required to press the right grip button. The membrane could only 
be peeled if a neighboring border was detached, requiring multiple grasps. 
 
4. Laser Precision: This exercise focused on applying endolaser around 5 retinal breaks 
in the periphery. The laser probe had a traditional red spot that varied in size based on 
its distance to the retina. As in real life, this affected the laser uptake, with larger spots 
being less intense. The laser was applied by pressing the grip button. Repeat mode was 
available by holding the button, with an interval of 200ms. When a tear was considered 
fully-treated, it turned green, signalling to the user to move on to the next break. During 
development, to ensure that tears were fully treated, we used a raycasting approach in 
Unity and heuristically adjusted the threshold for ""fully treated"" until we achieved our 
desired goal of two rows of laser spots 360 degrees around each break. 
 
Validation study 
After 2 years of development, we locked RetinaVR in March 2023 to prepare it for human 
validation. Novices and experts were recruited from the Department of Ophthalmology of the 
University of Montreal in Quebec, Canada from April 2023 through October 2023. The 
‘Novice’ group included ophthalmology residents in their first, second or third years of 
residency and who have not had any hands-on exposure to intraocular surgery. Exposure to 
oculoplastic and strabismus surgery, and previous VR exposure (other than RetinaVR) were 
not exclusionary. The ‘Expert’ group included experienced fellowship-trained vitreoretinal 
surgeons and vitreoretinal surgery fellows. The sample size could not be determined a priori 
and was limited by the availability of vitreoretinal surgeons. We recruited all vitreoretinal 
surgeons at our institution and matched them with an equal number of novice participants. 
Our sample size is on par with most studies looking at VR simulation in vitreoretinal surgery.5 
We excluded participants if they had any contraindications for VR gaming, including seizure 
disorder, vertigo, motion sickness and known VR cybersickness. We obtained ethics 
approval by the Institutional Review Boards of the CHUM Hospital (IRB # 2023-10479-
22.035). Informed consent was obtained from all participants after detailing the nature of the 
study.  
 
Novices and experts were scheduled to test the portable RetinaVR simulator on a 
Meta Quest 2 headset at their convenience. We often tested in a conference room, requiring 
only a flat surface. Our lead technical and clinical experts were available during testing, 
casting the user's view to a connected computer. Before each recorded test, users received 
a brief explanation of the tasks while wearing the VR headset. They were also instructed on 
how to position their hands and calibrate the instruments, and they were allowed a single 
 
 
6 
trial run of each module. A life-size soft silicone doll head simulated the patient head, 
allowing users to rest their wrists. All users sat superiorly relative to the eye. 
Collected data 
To determine the construct validity of our simulator, we needed to study the impact of user 
factors like age, self-reported sex and level of expertise on simulation performance.  We 
collected all possible measurable performance metrics directly from RetinaVR, using built-in 
code. All modules were evaluated based on three criteria: Efficiency, Safety, and Module-
specific performance. For all modules, Efficiency was assessed by measuring completion 
time in seconds, while Safety was assessed by counting the number of iatrogenic retinal 
touches. Module-specific performance metrics varied depending on the module. In 
Navigation Training, the number of exits from the target sphere was counted. For Tremor 
Control, the number of exits from the target sphere was counted, along with the mean and 
maximum deviation from the shaving path in milimeters. In Membrane Peeling, the number 
of membrane grasps was counted, with the hypothesis that the number of grasps would vary 
with experience and technique. For Laser Precision, the number of laser spots was 
recorded, with the hypothesis that a parsimonious use of laser was better as long as the 
tears were treated.16 The precise coordinates of the laser spots around tears were also 
recorded to determine the treatment pattern. 
User experience 
To measure user experience (UX), we administered a French abbreviated version of the 
validated Immersive Virtual Environments Questionnaire (IVEQ) v2.17 The questionnaire 
consisted of 26 questions: 2 to gauge the user's prior experience with VR, 21 that were 
gradable using a 10-point Likert scale, and 3 open-ended questions for general comments 
and feedback. The gradable questions assessed a broad range of UX factors, including 
Presence (n=3), Engagement (n=2), Immersion (n=2), Flow (n=2), Emotion (n=2), Skill 
(n=2), Judgement (n=3), Experience Consequence (n=2), and Technology Adoption (n=3). 
The questionnaire is available in Appendix 1. The 3 open-ended questions aimed to gather 
positive feedback, negative feedback, and suggestions for improvement. To analyze the free 
text responses, we elucidated the prevalent themes from each response and then 
consolidated them into broad categories. Once a coherent representation of data across all 
participants was achieved, the frequency of each theme recorded and summarised. 
Statistical methods 
We first explored the unadjusted differences in performance between novices and experts by 
calculating the standardized mean difference for each performance metric. This effect size 
analysis was useful to contextualize our findings, given the disparate units (count-, time-, 
distance-based) and varying scales of the performance metrics stemming from the differing 
difficulty levels of the four training modules. Additionally, given the novelty of our 
experimental design, the lack of existing normative data to define ""good or bad"" or ""fast or 
slow"" performance also necessitated this scaled analysis. We interpreted the effects as 
follows: 0.01 – 0.19 (minimal), 0.20 – 0.49 (small/ mild), 0.50 – 0.79 (medium/ moderate), 
0.80 – 0.99 (large) and >1.0 (very large).18 
 
 
7 
 
We then carried out an adjusted analysis and explored differences between novices 
and experts while controlling for age, sex and experimental run – factors that can influence 
the VR gaming experience.19–21 We used a linear mixed-effect model, which allowed us to 
isolate the effect of each factor while controlling for all others. All analyses were performed in 
R V.4.3.1 for our analyses at a 5% alpha level. 
 
 
Results 
Baseline demographics 
We recruited 20 participants, including 10 novices and 10 experts. Their baseline and 
demographic characteristics are detailed in Table 1. Novices were significantly younger and 
predominantly female. Novices had no prior surgical experience (a selection criterion), 
whereas the experts, on average, had 16.6 years (10.71) of post-residency surgical 
experience. Novices reported more hours of VR gaming than experts, but this difference was 
not statistically significant. They also reported more hours of training on VR-based surgical 
simulators than experts, with this difference being statistically significant. We provide 
descriptive statistics on the performance of novices and experts across all runs and modules 
in Supplemental Table 2, Supplemental Table 3, Supplemental Table 4, and 
Supplemental Table 5.  
 
Characteristic 
Novices (n=10) 
Experts (n=10) 
Difference 
Age – yr 
28.2 (3.61) 
47.1 (12.3) 
p=0.001 
Female sex – n 
7 (70%) 
3 (30%) 
p=0.0736 
Surgical expertise – yr  
0 (0) 
16.6 (10.71) 
p=0.001 
Previous VR gaming – hrs 
6.7 (12.82) 
2.1 (3.6) 
p=0.299 
Previous VR surgical training – hrs 
22.6 (23.29) 
3.8 (6.53) 
p=0.033 
 
Table 1. Demographic and baseline characteristics of the novice and expert users. Values are mean (SD) 
unless otherwise specified. VR, virtual reality 
Impact of the expertise 
We first compared the performance of novices and experts using an unadjusted model. The 
results are summarized in Figure 4. The detailed effect size analyses are shown in 
Supplemental Table 6. The linear mixed-effects model results are summarized in Table 7. 
 
Regarding efficiency, we found trends that novices were slower than experts, except 
in membrane peeling. None of those effects were statistically significant when all 
experimental runs were combined. When examining the runs individually, we found that 
novices were faster than experts in the first membrane peeling run (very large effect, -1.10 
[95%CI: -2.03, -0.14]). In the linear mixed-effects model, when controlling for age, sex and 
experimental run, the trends were maintained, but we found no statistically significant 
difference in efficiency between novices and experts in any of the modules.  
 
 
 
 
8 
 
Figure 4. Forest plot showing the unadjusted effect sizes of efficiency, safety and task-specific 
performance between experts and novices. The point effect estimate is Cohen’s D and represents the 
standardized mean difference between novice and expert performance, along with 95% confidence intervals. 
Positive effects, represented by values to the right of the y-axis, indicate higher novice metrics (e.g., longer 
novice completion times, more novice retinal touches), suggesting lower novice performance. Conversely, 
negative effects, represented by values to the left of the y-axis, indicate higher expert metrics (e.g., longer expert 
completion times, more expert retinal touches), implying better novice performance. The viridis color palette is 
used to interpret the effect sizes, representing a minimal effect (0.01-0.19), a small or mild effect (0.20-0.49), a 
medium or moderate effect (0.50-0.79), a large effect (0.80-0.99), and a very large effect (>1.0).  
 
Module and metric 
Expertise 
Estimate 
p-value 
Navigation Training 
 
 
 Efficiency 
9.30 
0.50 
 Safety 
0.63 
0.50 
 Sphere Exits 
21.46 
0.014 
Tremor Control 
 
 
 Efficiency 
7.05 
0.29 
 Safety 
0.10 
0.94 
 Sphere Exits 
38.14 
0.29 
 Mean Δ 
0.00 
0.81 
 Max Δ 
-0.02 
0.71 
Membrane Peeling 
 
 
 Efficiency 
-16.42 
0.17 
 Safety 
2.90 
0.11 
 Grasps 
-1.03 
0.25 
Laser Precision 
 
 
 Efficiency 
16.68 
0.29 
 Safety 
0.63 
0.29 
 Laser Spots 
10.15 
0.64 
 
Table 7. Linear mixed-effects model (adjusted) for the impact of expertise on performance. This model 
controls for experimental run, user age and sex. The only significant effect is the difference in performance during 
Navigation Training. Novices had an excess of 21.46 sphere exists compared to experts (p = 0.014). Efficiency 
estimates are in seconds, and Safety estimates are in number of iatrogenic retinal touches. Sphere exits, number 
of grasps and laser spots are count data. Mean and maximal deviation metrics are provided in meters in this 
table. 
 
 
9 
Regarding safety, we found that experts were safer than novices in the membrane 
peeling module when all experimental runs were combined (very large effect, 1.06 [95%CI: 
0.52, 1.60]). This effect was also present in the first (very large effect, 1.34 [95%CI: 0.35, 
2.31]) and second run (very large effect, 1.12 [95%CI: 0.16, 2.05], but not the third run. We 
also found trends that the experts were safer in all other modules, but those differences were 
not statistically significant. In the linear mixed-effects model, when controlling for age, sex 
and experimental run, the trends were maintained, but we found no statistically significant 
difference in safety between novices and experts in any of the modules.  
 
Regarding task-specific performance, we found that experts performed better in the 
core vitrectomy module, demonstrating significantly fewer exits from the target spheres 
(moderate effect, 0.7 [95%CI: 0.18, 1.22]). This effect was mostly driven by the second 
experimental run (very large effect, 1.11 [95%CI: 0.15, 2.04]). In the linear mixed-effects 
model, that difference was maintained while controlling for all other user factors, with novices 
exiting the spheres an excess of 21.46 times (p = 0.014). In peripheral shaving, we found 
trends that novices had more sphere exits than experts while demonstrating less deviation 
from the shaving path, but those differences were not statistically significant. In the linear 
mixed-effects model, when controlling for other factors, those differences were also not 
statistically significant.  
 
In membrane peeling, we found trends that experts grasped the membrane more 
times than novices, but that difference was not statistically significant in the unadjusted 
model. The trend was maintained in the linear mixed-effects model, but the difference was 
not statistically significant. In endolaser application, we found no difference in the amount of 
laser used between novices and experts in the adjusted and unadjusted models. However, a 
heatmap analysis of the laser spot distribution showed clinically significant differences in 
treatment patterns among novices and experts, as shown in Figure 5. 
 
 
 
Figure 5. Heatmap of laser shot distribution in the endolaser application (Laser Precision) module. 
Heatmap illustrating laser treatment patterns for all five retinal tears, differentiated by novices and experts. Each 
square represents a unique tear, with color intensity corresponding to the number of laser spots applied, using 
the viridis color palette. The color gradient ranges from purple (least density) to bright yellow (highest density). 
The central target represents the center-point of the retinal break, as shown in the Laser Precision module. 
Experts showed a uniform distribution of laser spots, characterized by a consistent spread around each tear, 
maintaining a uniform distance from the central point. There is a ring-like pattern with minimal laser applications 
directly on the tears. In contrast, novices showed a more erratic pattern (particularly in tears 1 and 2), with a 
concentration of laser spots towards the center-point of each tear. This indicates a less controlled application, 
resulting in a scattered distribution with variable intensity and less discernible uniformity.  
 
 
10 
Impact of participant age and sex 
We evaluated the impact of participant age and sex on their performance, while controlling 
for experimental run and expertise. As shown in Table 8, in the linear mixed-effects model, 
age had no impact on performance in any of the modules. Male participants were 12.35 
seconds faster in peripheral shaving (p=0.036) and 32.21 seconds faster in membrane 
peeling (p=0.004) compared to women. We observed trends of males being more efficient, 
safer and performing better in most task-specific metrics, but none of those effects were 
statistically significant.  
 
Module and metric 
Age 
Sex 
Estimate 
p-value 
Estimate 
p-value 
Navigation Training 
 
 
 
 
 Efficiency 
0.29 
0.64 
-18.96 
0.11 
 Safety 
0.00 
0.93 
-0.17 
0.83 
 Sphere Exits 
0.72 
0.06 
-12.71 
0.07 
Tremor Control 
 
 
 
 
 Efficiency 
0.52 
0.09 
-12.35 
0.036 
 Safety 
0.00 
0.94 
-1.13 
0.32 
 Sphere Exits 
2.11 
0.20 
-57.02 
0.07 
 Mean Δ 
0.00 
0.63 
0.00 
0.95 
 Max Δ 
0.00 
0.54 
0.00 
0.94 
Membrane Peeling 
 
 
 
 
 Efficiency 
0.70 
0.19 
-32.21 
0.004 
 Safety 
-0.03 
0.68 
-0.54 
0.71 
 Grasps 
0.01 
0.79 
-1.13 
0.14 
Laser Precision 
 
 
 
 
 Efficiency 
0.99 
0.17 
-13.28 
0.32 
 Safety 
0.00 
0.91 
0.61 
0.23 
 Laser Spots 
0.78 
0.43 
-5.90 
0.75 
 
Table 8. Linear mixed-effects model (adjusted) for the impact of age and sex on performance. This model 
controls for all other variables including expertise when examining the effect of age and sex. Age had no impact 
on performance, but sex did. Male participants were 12.35 seconds faster in peripheral shaving (p=0.036) and 
32.21 seconds faster in membrane peeling (p=0.004). Efficiency estimates are in seconds, and Safety estimates 
are in number of iatrogenic retinal touches. Sphere exits, number of grasps and laser spots are count data. Mean 
and maximal deviation metrics are provided in meters in this table. 
Impact of the learning curve 
We also evaluated the learning curve by repeating the experiments three times for each 
participant. As shown in Table 9, in the linear mixed-effects model, efficiency improved with 
each experimental run during all modules. At each run, completion time decreased by 7.67 
seconds for core vitrectomy (p=0.005), 12.02 seconds for peripheral shaving (p<0.001), 
17.92 seconds for membrane peeling (p<0.001) and 25.68 seconds for endolaser application 
(p<0.001). We found that repetition improved safety scores during membrane peeling, with a 
1.37 fewer iatrogenic retinal touches with each run (p=0.003). Similar trends were observed 
for all modules, but the effects were not statistically significant. However, it did reduce the 
number of laser spots used by the participants. At each run, the number of sphere exits 
decreased by 5.42 times (p=0.038) in core vitrectomy and by 17.00 times during peripheral 
 
 
11 
shaving (p=0.011). In endolaser application, participants used 11.20 less laser shots at each 
run to treat the tears (p=0.043). 
 
Module and metric 
Experimental run 
Estimate 
p-value 
Navigation Training 
 
 
 Efficiency 
-7.67 
0.005 
 Safety 
-0.20 
0.26 
 Sphere Exits 
-5.42 
0.038 
Tremor Control 
 
 
 Efficiency 
-12.02 
<0.001 
 Safety 
-0.47 
0.13 
 Sphere Exits 
-17.00 
0.011 
 Mean Δ 
0.00 
1.00 
 Max Δ 
-0.01 
0.22 
Membrane Peeling 
 
 
 Efficiency 
-17.92 
<0.001 
 Safety 
-1.37 
0.003 
 Grasps 
0.27 
0.23 
Laser Precision 
 
 
 Efficiency 
-25.68 
<0.001 
 Safety 
-0.02 
0.92 
 Laser Spots 
-11.20 
0.043 
 
Table 9. Linear mixed-effects model (adjusted) for the impact of experimental run on performance. This 
model controls for age, sex and expertise when examining the role of the experimental run. At each run, 
completion time decreased by 7.67 seconds for core vitrectomy (p=0.005), 12.02 seconds for peripheral shaving 
(p<0.001), 17.92 seconds for membrane peeling (p<0.001) and 25.68 seconds for endolaser application 
(p<0.001). Furthermore, repetition improved safety scores during membrane peeling, with a 1.37 fewer iatrogenic 
retinal touches with each run (p=0.003). At each run, the number of sphere exits decreased by 5.42 times 
(p=0.038) in core vitrectomy and by 17.00 times during peripheral shaving (p=0.011). In endolaser application, 
participants used 11.20 less laser shots at each run to treat the tears (p=0.043). Efficiency estimates are in 
seconds, and Safety estimates are in number of iatrogenic retinal touches. Sphere exits, number of grasps and 
laser spots are count data. Mean and maximal deviation metrics are provided in meters in this table. 
User experience 
Overall, the users rated the experience from favorable to excellent in all 8 spheres of UX, as 
shown in Supplemental Table 10. Positive feedback predominantly centered on three 
themes: the realistic 3D environment (n = 18), the ability to practice in a low-risk environment 
(n = 9), and the authentic representation of the vitrectomy experience (n = 5). Other sporadic 
comments praised the innovation, immersion, and portability of the experience. Negative 
feedback mentioned the fulcrum effect and controller-simulation movement translation (n=8), 
the controller size and ergonomics (n=6) and difficulty with visualization and depth 
perception (n=6). Other comments included the lack of progress indicators, headset fit, and 
unrealistic shaving module. Suggestions for improvement suggested improving the 
controllers and ergonomics (n=10), providing better instructions and real-time feedback 
(n=5), and improving movement translation (n=5). It was also recommended to attempt to 
improve headset fit, build more complete case-based modules, improve graphics, and 
gamify the experience. 
 
 
12 
Discussion 
We built a RetinaVR, a fully immersive, affordable, and portable VR simulator for vitreoretinal 
surgery training. RetinaVR is a standalone app that leverages the powerful processors and 
cameras of commercially-available VR headsets and controllers, without relying on external 
touch haptic devices. RetinaVR is a proof of concept for a new way of approaching surgical 
simulation in the metaverse, at a fraction of the cost of traditional VR simulators. It 
democratizes access to surgical simulation, and has the potential to spur innovation in global 
ophthalmology.  
 
To ensure RetinaVR's affordability and accessibility, we designed it to require only a 
quick app download. The app is a mere 100 megabytes, taking approximately 20 seconds to 
download on average global broadband speeds and less than 2 minutes in Sub-Saharan 
Africa.22,23 To simulate surgical instruments, we used the standard built-in controllers, rather 
than integrating custom hardware. Using pen-like haptic feedback devices could have 
provided a more faithful simulation of instruments, but it would have come at a high cost.24 
Since our simulator did not require instruments to be anchored to a physical eye model, the 
fulcrum effect was difficult to simulate. This effect, encountered when using the vitrector and 
light pipe through a trocar, necessitates unique skills to move the instrument tips. Despite 
that, we feel that we accurately replicated the motion inversion and scaled motion required to 
move the vitrector tip, allowing the users to successfully complete the modules and improve 
at each run. This is supported by the demonstration of the learning curve and the high 
scores for the Flow theme in the UX questionnaire. The users did suggest, however, 
improvements in instrumentation. While our plastic controllers were lightweight, they were 
still considerably heavier than conventional surgical instruments. Their weight was 4 times 
that of a typical 23G vitrector. For comparison, the Bi-Blade vitrectomy cutter weighs 
approximately 37 grams with the tubing (personal communication with Bausch + Lomb). 
 
To capture user performance during simulation, we were faced with two options: 
either collect as many metrics as possible and analyze them post-hoc, or develop a scoring 
system by assigning weights to measurable metrics based on our subjective assessment of 
their importance. The latter approach raised concerns about how to objectively measure task 
efficiency, safety, and good performance, and how to determine the appropriate point 
deductions for mistakes. Given the potential for heuristic bias, we chose the first option and 
developed code in RetinaVR to quantify those metrics. We conducted a rigorous analysis of 
the data through an effect size analysis. This was crucial for interpreting the significance of 
observed differences, since these experiments were being conducted for the first time with 
no normative databases to establish good or poor performance benchmarks. We then built 
an adjusted model to examine the impact of age, sex and experimental run on performance, 
and controlled for those factors when comparing novices and experts.  
 
We believe to have demonstrated construct validity.25,26 This refers to the ability 
RetinaVR to measure user behaviors and performance in a way that correlates with their 
inherent factors and level of expertise. We found that participant age had no impact on 
overall performance when we controlled for sex, expertise and experimental run. However, 
we found that males performed membrane peeling and peripheral shaving tasks more 
quickly than females, with no significant differences in safety and task-specific performance. 
 
 
13 
Some evidence suggests that gaming proficiency may decline with age and show 
differences between sexes.21,27–29 However, we believe that this phenomenon is more likely 
attributable to a disparity in prior gaming experience, rather than innate age or sex-related 
abilities. These effects may be even less pronounced in a surgical simulation context like 
ours, where older participants typically have more prior surgical experience. In parallel, we 
found that repetition boosted efficiency in all modules, and enhanced safety in the 
membrane peeling module. It also improved task-specific performance during core 
vitrectomy and peripheral shaving. This demonstrates a learning curve across experimental 
runs – with users getting better with repetition or practice. We feel that this observation 
reinforces the notion that user performance was not a random occurrence but rather a 
reflection of genuine learning. This learning curve has also been demonstrated for the 
vitreoretinal modules of the EyeSi simulator in numerous studies.30,31  
 
A crucial aspect of this project is the demonstration of how user expertise affects 
performance. We report on several notable findings in our work. First, novices tended to be 
slower in all modules, except in membrane peeling. Interestingly, in membrane peeling, they 
tended to be faster, while also being less safe, causing significantly more iatrogenic retinal 
touches, and grasping the membranes less frequently. These contrasts possibly highlight the 
influence of real-world surgical experience. Experts demonstrated a more cautious and 
deliberate approach, peeling slowly and carefully to minimize shearing forces on the macula. 
In contrast, novices, perhaps viewing the simulation as such, exhibited riskier behavior by 
attempting to complete the module at a faster pace, leading to more iatrogenic damage. 
Second, experts performed significantly better in the core vitrectomy module, exhibiting 
fewer target sphere exits – a difference that was maintained when controlling for other user 
factors. Third, during endolaser application, we found clinically important differences in the 
treatment patterns between among novices and experts. This speaks to the construct validity 
of those modules and their ability to faithfully simulate the surgical experience. 
 
RetinaVR marks a proof of concept for a novel type of platform for vitreoretinal 
surgery training simulation. We believe that RetinaVR can change the scope of surgical 
simulation in a number of ways. First, trainees can conveniently access RetinaVR using their 
personal headsets, integrating it alongside their existing VR-based entertainment, gaming, or 
sports activities. Second, residency programs can effectively train multiple residents 
simultaneously by investing in multiple affordable VR headsets. The platform's online 
metaverse integration, relying on Meta’s cloud servers, enables multiplayer group training 
sessions, connecting residents virtually with expert surgeons from around the world, 
breaking down geographical barriers and fostering a global learning community. Third, the 
platform allows for both synchronous and asynchronous learning, which enables trainees to 
obtain real-time feedback from mentors while also catering for individual learning styles and 
schedules. Finally, gamification elements, such as points, badges, and international 
leaderboards, can further enhance engagement and encourage healthy competition, 
spurring innovation and collaboration in the field of vitreoretinal surgery.  
 
While RetinaVR has demonstrated construct validity to a certain extent, our work has 
some limitations and further validation is necessary. First, statistical significance in our 
analyses was limited by the low sample size and high variance among novices. Despite that, 
most of our effects were congruent with the expected behaviors of novices and experts. 
Second, we have not yet demonstrated skill transfer to the operating room, a crucial step in 
 
 
14 
validating a surgical simulator. However, to our knowledge, in vitreoretinal surgery, this has 
not been shown even for popular simulators like the EyeSi.5 RetinaVR remains a work in 
progress: the user interface, including menu appearances, profile creation, login 
functionality, and leaderboards, require further development before public release. We are 
also working on incorporating feedback from this study to determine future directions for 
RetinaVR. Despite these limitations, we are proud of what was achieved with limited 
resources. RetinaVR serves as a proof of concept for developing affordable VR surgical 
simulation apps in an academic lab setting, fostering innovation in surgical training and 
medical education. Driven by the relentless innovation of industry titans like Meta and Apple, 
we are confident that standalone VR headsets will soon reach a high level of maturity.32 This 
will pave the way for the widespread availability of an off-the-shelf, affordable, and validated 
RetinaVR app, empowering the trainees worldwide with an immersive surgical training 
experience. 
 
 
 
15 
References 
1. Pottle J. Virtual reality and the transformation of medical education. Future Healthc J 
2019;6:181–185. 
2. Mao RQ, Lan L, Kay J, et al. Immersive Virtual Reality for Surgical Training: A Systematic 
Review. J Surg Res 2021;268:40–58. 
3. Thomsen ASS, Smith P, Subhi Y, et al. High correlation between performance on a 
virtual-reality simulator and real-life cataract surgery. Acta Ophthalmol 2017;95:307–311. 
4. Ferris JD, Donachie PH, Johnston RL, et al. Royal College of Ophthalmologists’ National 
Ophthalmology Database study of cataract surgery: report 6. The impact of EyeSi virtual 
reality training on complications rates of cataract surgery performed by first and second year 
trainees. Br J Ophthalmol 2020;104:324–329. 
5. Rasmussen RC, Grauslund J, Vergmann AS. Simulation training in vitreoretinal surgery: a 
systematic review. BMC Ophthalmol 2019;19:90. 
6. Jaud C, Salleron J, Cisse C, et al. EyeSi Surgical Simulator: validation of a proficiency-
based test for assessment of vitreoretinal surgical skills. Acta Ophthalmol 2021;99:390–396. 
7. Carr L, McKechnie T, Hatamnejad A, et al. Effectiveness of the Eyesi Surgical Simulator 
for ophthalmology trainees: systematic review and meta-analysis. Can J Ophthalmol 2023. 
Available at: http://dx.doi.org/10.1016/j.jcjo.2023.03.014. 
8. Kaur S, Shirodkar A-L, Nanavaty MA, Austin M. Cost-effective and adaptable cataract 
surgery simulation with basic technology. Eye 2022;36:1384–1389. 
9. la Cour M, Thomsen ASS, Alberti M, Konge L. Simulators in the training of surgeons: is it 
worth the investment in money and time? 2018 Jules Gonin lecture of the Retina Research 
Foundation. Graefes Arch Clin Exp Ophthalmol 2019;257:877–881. 
10. Oseni J, Adebayo A, Raval N, et al. National Access to EyeSi Simulation: A Comparative 
Study Among U.S. Ophthalmology Residency Programs. Nepal J Ophthalmol 
2023;15:e112–e118. Available at: [Accessed November 14, 2023]. 
11. Anon. Meta Quest 2: Immersive All-In-One VR Headset. Available at: 
https://www.meta.com/us/quest/products/quest-2/ [Accessed November 14, 2023]. 
12. Chengoden R, Victor N, Thien Huynh-The, et al. Metaverse for Healthcare: A Survey on 
Potential Applications, Challenges and Future Directions. arXiv [csAI] 2022. Available at: 
http://arxiv.org/abs/2209.04160. 
13. Armstrong M. Meta leads the way in VR headsets. Statista 2023. Available at: 
https://www.statista.com/chart/29398/vr-headset-kpis/ [Accessed November 17, 2023]. 
14. Ruparelia S, Orr S, Choudhry N, et al. Risk for Surgical Team Hearing Loss With 
Vitrectomy. J Vitreoretin Dis 2023;7:397–403. 
 
 
16 
15. Anon. No more forceps: A cutter-based approach to ILM peeling - retina today. Available 
at: https://retinatoday.com/articles/2023-may-june/no-more-forceps-a-cutter-based-
approach-to-ilm-peeling [Accessed November 23, 2023]. 
16. Wang JC, Ryan EH, Ryan C, et al. FACTORS ASSOCIATED WITH THE USE OF 360-
DEGREE LASER RETINOPEXY DURING PRIMARY VITRECTOMY WITH OR WITHOUT 
SCLERAL BUCKLE FOR RHEGMATOGENOUS RETINAL DETACHMENT AND IMPACT 
ON SURGICAL OUTCOMES (PRO STUDY REPORT NUMBER 4). Retina 2020;40:2070–
2076. 
17. Tcha-Tokey K, Christmann O, Loup-Escande E, Richir S. Proposition and validation of a 
questionnaire to measure the user experience in immersive virtual environments. Int J Virtual 
Real 2016;16:33–48. 
18. Cohen J. Statistical Power Analysis for the Behavioral Sciences. Routledge; 2013. 
19. Kojić T, Spang R, Vergari M, et al. Effects of user factors on user experience in virtual 
reality: age, gender, and VR experience as influencing factors for VR exergames. Quality 
and User Experience 2023;8:3. 
20. Stanney K, Fidopiastis C, Foster L. Virtual Reality Is Sexist: But It Does Not Have to Be. 
Front Robot AI 2020;7:4. 
21. Lorenz M, Brade J, Klimant P, et al. Age and gender effects on presence, user 
experience and usability in virtual environments-first insights. PLoS One 2023;18:e0283565. 
22. Anon. Average global mobile and fixed broadband download & upload speed worldwide 
2023. Statista. Available at: https://www.statista.com/statistics/896779/average-mobile-fixed-
broadband-download-upload-speeds/ [Accessed November 17, 2023]. 
23. Anon. Sub-Saharan Africa: average download speed by country 2022. Statista. Available 
at: https://www.statista.com/statistics/1274951/average-download-speed-in-sub-saharan-
africa-by-country/ [Accessed November 17, 2023]. 
24. Anon. HapticVR. Fundamental Surgery 2022. Available at: 
https://fundamentalsurgery.com/platform/hapticvr/ [Accessed November 14, 2023]. 
25. Cronbach LJ, Meehl PE. Construct validity in psychological tests. Psychol Bull 
1955;52:281–302. 
26. Gavazzi A, Bahsoun AN, Van Haute W, et al. Face, content and construct validity of a 
virtual reality simulator for robotic surgery (SEP Robot). Ann R Coll Surg Engl 2011;93:152–
156. 
27. Erfani M, El-Nasr MS, Milam D, et al. The Effect of Age, Gender, and Previous Gaming 
Experience on Game Play Performance. In: Human-Computer Interaction. Springer Berlin 
Heidelberg; 2010:293–296. 
28. Shen C, Ratan R, Cai YD, Leavitt A. Do Men Advance Faster Than Women? Debunking 
the Gender Performance Gap in Two Massively Multiplayer Online Games. J Comput Mediat 
Commun 2016;21:312–329. Available at: [Accessed November 14, 2023]. 
 
 
17 
29. Nelson JA. Are women really more risk‐averse than men? A re‐analysis of the literature 
using expanded methods. J Econ Surv 2015;29:566–585. 
30. Vergmann AS, Vestergaard AH, Grauslund J. Virtual vitreoretinal surgery: validation of a 
training programme. Acta Ophthalmol 2017;95:60–65. 
31. Solverson DJ, Mazzoli RA, Raymond WR, et al. Virtual reality simulation in acquiring and 
differentiating basic ophthalmic microsurgical skills. Simul Healthc 2009;4:98–103. 
32. Waisberg E, Ong J, Masalkhi M, et al. The future of ophthalmology and vision science 
with the Apple Vision Pro. Eye 2023. Available at: http://dx.doi.org/10.1038/s41433-023-
02688-5. 
 
 
 
18 
Statements 
Contributions: FA, CD, BO and KH conceptualised the study and designed the 
experiments. FA and KH obtained the funding. CD and BO designed RetinaVR software. FA 
and KH provided continuous iterative feedback to improve RetinaVR. FA, CD, and DM 
carried out the clinical validation study. CEG performed the statistical analyses. FA and CD 
drafted the initial manuscript. FA and CD designed the figures and tables. All authors 
reviewed and discussed the results. All authors edited and revised the manuscript before 
approving the final version of this manuscript. 
  
Acknowledgements: We express our gratitude to the Canadian Ophthalmological Society 
and Bayer Inc for funding this work. 
  
Data sharing statement: All data produced in the present study are available upon 
reasonable request to the authors. RetinaVR is not currently in the Oculus store. 
 
 
19 
Supplemental Materials 
 
 
Supplemental Figure 2. Overview of the simulation ergonomics. A. At the beginning of each simulation, 
users could calibrate the position of their instruments to a comfortable position while resting the ulnar border of 
their hands on a silicon mannequin forehead. B. Top-down view from the user's perspective. The controllers are 
held like surgical instruments. C. The right grip button (Axis1D.PrimaryHandTrigger) serves two primary 
functions: firstly, it enables membrane grasping during membrane peeling, and secondly, it engages the laser 
during endolaser application. Continuous pressing activates repeat laser firing at 200-millisecond intervals. 
 
 
20 
 
Run 
1 
2 
3 
Overall 
 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
 Efficiency [completion time in seconds] 
   Mean 
58.59 
70.41 
43.59 
62.57 
47.4 
50.9 
49.86 
61.3 
   StDev 
17.52 
41.12 
6.35 
34.7 
12.83 
15.22 
14.17 
32.2 
    Min 
38.45 
41.48 
36.98 
38.37 
37.56 
33.65 
36.98 
33.65 
    Max 
98.86 
175.74 
58.25 
148.33 
75.69 
76.73 
98.86 
175.74 
 Safety [number of iatrogenic retinal touches] 
   Mean 
0.6 
1.4 
0.4 
0.9 
0.3 
0.9 
0.43 
1.07 
   StDev 
1.58 
2.46 
0.7 
1.85 
0.67 
1.52 
1.04 
1.93 
   Min 
0 
0 
0 
0 
0 
0 
0 
0 
   Max 
5 
8 
2 
6 
2 
5 
5 
8 
 Performance [number of exits from the target sphere] 
   Mean 
10.6 
35 
7 
16.6 
9.5 
14.4 
9.03 
22 
   StDev 
5.6 
39.98 
5.4 
11 
8.15 
8.32 
6.46 
25.36 
   Min 
2 
8 
2 
6 
3 
5 
2 
5 
   Max 
21 
109 
17 
38 
31 
35 
31 
109 
 
Supplemental Table 2. Descriptive statistics for Navigation Training 
 
 
 
21 
Run 
1 
2 
3 
Overall 
 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
 Efficiency [completion time in seconds] 
   Mean 
55.74 
58.57 
38.56 
42.61 
33.22 
33.02 
42.5 
44.73 
   StDev 
20.97 
13.6 
11.63 
11.58 
7.77 
5.4 
17.11 
14.93 
    Min 
29.49 
36.88 
25.99 
24.64 
23.15 
22.22 
23.15 
22.22 
    Max 
90.65 
77.27 
61.8 
62.62 
43.94 
39.19 
90.65 
77.27 
 Safety [number of iatrogenic retinal touches] 
   Mean 
1.1 
1.6 
1.1 
2.3 
0.3 
0.5 
0.83 
1.47 
   StDev 
1.45 
2.91 
1.85 
4.69 
0.48 
0.97 
1.39 
3.21 
   Min 
0 
0 
0 
0 
0 
0 
0 
0 
   Max 
4 
9 
6 
13 
1 
3 
6 
13 
 Performance [number of exits from the target sphere] 
   Mean 
168.9 
222.7 
183.1 
186 
158.6 
165 
170.2 
191.23 
   StDev 
47.25 
62.43 
66.33 
86.27 
48.13 
64.3 
53.68 
73.42 
   Min 
86 
147 
115 
97 
110 
94 
86 
94 
   Max 
232 
336 
305 
396 
230 
288 
305 
396 
 Performance [mean Δ from the shaving path in mm] 
   Mean 
19.7 
16.8 
25.2 
16.0 
21.3 
15.2 
22.0 
16.0 
   StDev 
6.6 
1.2 
28.4 
1.1 
19.8 
0.6 
19.8 
1.1 
   Min 
14.3 
15.0 
13.9 
14.1 
13.4 
13.9 
13.4 
13.9 
   Max 
34.9 
18.5 
105.2 
17.8 
77.6 
15.8 
105.2 
18.5 
 Performance [maximal Δ from the shaving path in mm] 
   Mean 
98.3 
39.8 
110.5 
44.1 
64.1 
30.3 
91.0 
38.1 
   StDev 
94.4 
18.0 
209.9 
26.8 
104.8 
8.6 
142.3 
19.5 
   Min 
18.0 
19.9 
18.6 
22.6 
17.4 
21.8 
17.4 
19.9 
   Max 
305.6 
76.1 
692.0 
106.3 
357.4 
52.9 
692.0 
106.3 
 
Supplemental Table 3. Descriptive statistics for Tremor Control 
 
 
 
22 
Run 
1 
2 
3 
Overall 
 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
 Efficiency [completion time in seconds] 
   Mean 
97.92 
65.49 
56.86 
50.58 
51.58 
40.15 
68.79 
52.07 
   StDev 
30.43 
28.49 
22.15 
24.97 
17.52 
23.37 
31.28 
26.96 
    Min 
43.23 
43.75 
30.88 
25.02 
24.64 
21.95 
24.64 
21.95 
    Max 
132.33 
135.04 
90.51 
106.08 
82.8 
100.66 
132.33 
135.04 
 Safety [number of iatrogenic retinal touches] 
   Mean 
1.8 
6.3 
0.2 
4.9 
0.3 
2.3 
0.77 
4.5 
   StDev 
2.53 
4 
0.63 
5.92 
0.95 
3.13 
1.72 
4.66 
   Min 
0 
0 
0 
0 
0 
0 
0 
0 
   Max 
6 
11 
2 
20 
3 
10 
6 
20 
 Performance [number of membrane grasps] 
   Mean 
8.9 
7.6 
8.7 
8.7 
9.3 
8.3 
8.97 
8.2 
   StDev 
2.33 
1.51 
1.89 
1.49 
1.77 
1.49 
1.96 
1.52 
   Min 
5 
6 
6 
7 
7 
6 
5 
6 
   Max 
14 
11 
12 
12 
13 
11 
14 
12 
 
Supplemental Table 4. Descriptive statistics for Peeling Control 
 
 
 
23 
Run 
1 
2 
3 
Overall 
 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
Expert 
Novice 
 Efficiency [completion time in seconds] 
   Mean 
140.54 
125.87 
85.7 
109.53 
81.61 
82.08 
102.62 
105.82 
   StDev 
39.64 
36.2 
15.21 
58.42 
25.56 
13.32 
38.85 
43.11 
    Min 
71.8 
76.73 
55.57 
40.6 
47 
62.57 
47 
40.6 
    Max 
192.61 
201.48 
112.71 
255.54 
134.98 
106.5 
192.61 
255.54 
 Safety [number of iatrogenic retinal touches] 
   Mean 
0.2 
1 
0 
1.1 
1 
0.1 
0.4 
0.73 
   StDev 
0.63 
1.89 
0 
1.85 
2.54 
0.32 
1.52 
1.55 
   Min 
0 
0 
0 
0 
0 
0 
0 
0 
   Max 
2 
6 
0 
5 
8 
1 
8 
6 
 Performance [number of laser spots] 
   Mean 
173.7 
162.2 
149.4 
165.5 
151.3 
139.8 
158.13 
155.83 
   StDev 
52.32 
21.62 
39.06 
47.11 
52.75 
27.56 
48.09 
34.7 
   Min 
121 
129 
99 
93 
98 
98 
98 
93 
   Max 
282 
194 
232 
243 
250 
183 
282 
243 
 
Supplemental Table 5. Descriptive statistics for Laser Precision 
 
 
 
24 
Supplemental Table 6. Effect size analysis for all four RetinaVR modules 
 
 Task/ Run 
1 
2 
3 
Combined 
 Navigation Training 
   Efficiency 
0.37 [-0.52, 1.25] 
0.76 [-0.16, 1.66] 
0.25 [-0.63, 1.13] 
0.46 [-0.06, 0.97] 
   Safety 
0.39 [-0.50, 1.27] 
0.36 [-0.53, 1.24] 
0.51 [-0.39, 1.39] 
0.41 [-0.10, 0.92] 
   Sphere Exits  
0.85 [-0.08, 1.76] 
1.11 [0.15, 2.04] 
0.59 [-0.31, 1.48] 
0.7 [0.18, 1.22] 
 Tremor Control 
   Efficiency 
0.16 [-0.72, 1.04] 
0.35 [-0.54, 1.23] 
-0.03 [-0.91, 0.85] 
0.14 [-0.37, 0.64] 
   Safety 
0.22 [-0.67, 1.09] 
0.34 [-0.55, 1.22] 
0.26 [-0.62, 1.14] 
0.26 [-0.25, 0.76] 
   Sphere Exits  
0.97 [0.03, 1.89] 
0.04 [-0.84, 0.91] 
0.11 [-0.77, 0.99] 
0.33 [-0.18, 0.84] 
   Mean Δ 
-0.61 [-1.50, 0.30] 
-0.46 [-1.34, 0.43] 
-0.43 [-1.32, 0.46] 
-0.43 [-0.94, 0.08] 
   Max Δ 
-0.86 [-1.77, 0.07] 
-0.44 [-1.33, 0.45] 
-0.45 [-1.34, 0.44] 
-0.52 [-1.03, 0.00] 
 Peeling Control 
   Efficiency 
-1.10 [-2.03, -0.14] 
-0.27 [-1.14, 0.62] 
-0.55 [-1.44, 0.35] 
-0.57 [-1.09, 0.05] 
   Safety 
1.34 [0.35, 2.31] 
1.12 [0.16, 2.05] 
0.87 [-0.07, 1.77] 
1.06 [0.52, 1.60] 
   Grasps  
-0.66 [-1.56, 0.25] 
0 [-0.88, 0.88] 
-0.61 [-1.50, 0.30] 
-0.44 [-0.95, 0.08] 
 Laser Precision 
   Efficiency 
-0.39 [-1.27, 0.50] 
0.56 [-0.34, 1.45] 
0.02 [-0.85, 0.90] 
0.08 [-0.43, 0.58] 
   Safety 
0.57 [-0.33, 1.46] 
0.84 [-0.09, 1.75] 
-0.50 [-1.38, 0.40] 
0.22 [-0.29, 0.72] 
   Laser Spots  
-0.29 [-1.16, 0.60] 
0.37 [-0.52, 1.25] 
-0.27 [-1.15, 0.61] 
-0.05 [-0.56, 0.45] 
 
 
25 
Theme 
Expertise 
Mean 
StDev 
Min 
Max 
Presence 
 
Expert 
6 
2.01 
1.67 
8.33 
Novice 
7 
1.39 
5.33 
9.67 
Engagement 
Expert 
7 
1.44 
5.00 
8.50 
Novice 
8 
1.51 
5.50 
10.00 
Immersion 
Expert 
7 
2.08 
3.50 
9.00 
Novice 
8 
1.57 
6.00 
10.00 
Flow 
Expert 
7 
1.66 
4.50 
9.50 
Novice 
8 
1.38 
6.00 
10.00 
Emotion 
Expert 
8 
1.53 
5.50 
10.00 
Novice 
8 
0.97 
7.00 
9.50 
Skill 
Expert 
7 
2.24 
3.00 
9.00 
Novice 
8 
1.42 
5.50 
9.00 
Judgement 
Expert 
8 
1.62 
4.33 
10.00 
Novice 
9 
1.05 
6.67 
10.00 
Experience Consequence 
Expert 
8 
1.96 
4.00 
10.00 
Novice 
8 
2.49 
2.50 
10.00 
Technology Adoption 
Expert 
9 
1.71 
4.67 
10.00 
Novice 
9 
0.99 
7.00 
10.00 
 
Supplemental Table 10. Results from the User Experience questionnaire 
 
 
 
26 
Theme 
Question 
Background 
Approximately how many hours of experience do you have with virtual reality environments? 
Background 
Approximately how many hours of experience do you have with medical simulation software? 
Presence 
My interactions with the virtual environment seemed natural. 
Presence 
I could concentrate on the assigned tasks rather than on the devices (gamepad or keyboard). 
Presence 
The devices (gamepad or keyboard) which controlled my movement in the virtual 
environment seemed natural. 
Engagement 
The sense of moving around inside the virtual environment was compelling. 
Engagement 
The visual aspects of the virtual environment involved me. 
Immersion 
I become so involved in the virtual environment that it is if I was inside the game rather than 
manipulating a gamepad and watching a screen. 
Immersion 
I felt physically fit in the virtual environment 
Flow 
I felt I could perfectly control my actions. 
Flow 
At each step, I knew what to do. 
Emotion 
I enjoyed being in this virtual environment. 
Emotion 
The interaction devices (Oculus headset, gamepad and/or keyboard) bored me to death. 
Skill 
I felt confident using the gamepad and/or keyboard to move around the virtual environment. 
Skill 
I feel confident learning advanced skills within a specific virtual reality software using the 
Oculus headset. 
Judgement 
Personally, I would say the virtual environment is impractical/practical. 
Judgement 
Personally, I would say the virtual environment is unruly/manageable. 
Judgement 
Personally, I would say the virtual environment is confusing/clear 
Experience 
consequence 
I suffered from fatigue during my interaction with the virtual environment. 
Experience 
consequence 
I suffered from dizziness with eye open during my interaction with the virtual environment 
Technology 
adoption 
It would be easy for me to become skillful at using the virtual environment. 
Technology 
adoption 
If I use again the same virtual environment, my interaction with the environment would be 
clear and understandable for me. 
Technology 
adoption 
Using the interaction devices (Oculus headset, gamepad and/or keyboard) is a bad idea. 
Feedback 
In your opinion, what were the positive points about your experience? 
Feedback 
In your opinion, what were the negative points about your experience? 
Feedback 
Do you have suggestions to improve this virtual reality environment? 
 
Appendix 1. User experience questionnaire abridged from the validated IVEQ v2 user experience 
questionnaire. The original questionnaire is in French, but the English translation is shown here. Background 
and feedback questions were open-ended, allowing for natural language inputs. The remaining questions used a 
10-point Likert scale. Scores from negatively worded questions were inverted for analysis. 
 
"
"This paper presents a study on enhancing the performance of the GPT Neo 125M model in the programming domain for Community Question Answering (CQA) using a combination of Reinforcement Learning from Human Feedback (RLHF) and scores from Stack Overflow. Two reward model training strategies are employed for fine-tuning with Proximal Policy Optimization (PPO), resulting in improvements comparable to those of GPT Neo's 2.7B parameter variant. An auxiliary scoring mechanism is introduced to highlight the limitations of conventional linguistic metrics in evaluating responses in the programming domain. Through analysis, the study emphasizes the need for domain-specific evaluation methods and reflects on the intricate nature of applying RLHF to programming CQA, accentuates the significance of context-aware evaluation, and underscores the importance of human preferences in refining LLMs.nan","Advancements in Reinforcement Learning from Human Feedback (RLHF) have revolutionized the fine-tuning of Large Language Models (LLMs), enabling adaptation for human-like response generation and precise behavior control. While RLHF has been effective in general domains, its application in specialized fields such as Community Question Answering (CQA) for programming remains unexplored. LLMs face unique challenges in handling the complex nature of programming queries, including conceptual understanding, code generation, API usage, and debugging, due to struggles with subtle semantic relations. Additionally, a critical challenge is the evaluation of the quality of responses generated by LLMs. Conventional metrics such as BertScore and Rouge do not capture the essence of responses effectively, especially in specialized domains like programming. Moreover, they don't account for the diversity in valid answers and lack in capturing deeper semantic correctness. The development of more reliable and context-sensitive evaluation metrics is essential.nan","nanTo address these challenges, in this paper, we investigate the application of RLHF to a smaller model, GPT Neo 125M (Black et al., 2021a), in the context of programming CQA. We aim not only to enhance the model's response generation capabilities but also to address the evaluation challenge. Our contributions are two-fold. First, we explore the potential and efficacy of RLHF in retraining a smaller LLM for programming CQA. Second, through empirical analysis, we highlight the discrepancies between the RLHF reward model and existing linguistic metrics, emphasizing the limitations of current evaluation methodologies and advocating for the development of more semantically-sensitive measures.nan","The general schema of RLHF utilized in this study consists of several stages, as depicted in Fig. 1. The process commences with the training of an initial policy via supervised learning. Subsequently, a reward model is trained to acquire human preferences from the labeled data. Finally, the policy is fine-tuned using Proximal Policy Optimization (PPO) (Schulman et al., 2017), guided by the reward model. In this study, we have adapted RLHF for programming Q&A by converting user ratings from Stack Overflow into feedback for training our model. We used two distinct approaches: creating regression scores and contrastive scores for the straightforward comparison of answers.nan","This section aims to evaluate the effectiveness of the RLHF training approach for improving the quality of generated responses in the programming QA domain. Specifically, we compare three versions of the model, according to Fig. 1 - the base model, the SFT version, and the RLHF version. The evaluation focuses on the performance of the reward model training methods and the generated responses' quality.nan","In conclusion, our study has demonstrated the effectiveness of RLHF in enhancing the performance of small LLMs like GPT Neo 125M in the programming domain. Our experiments focused on fine-tuning the model using user-generated responses from Stack Overflow, employing two reward model training strategies, regression scores and contrastive scores, with PPO. The study also highlights the critical role of employing the right evaluation measures. While Rouge scores effectively captured response accuracy, other metrics like BertScore and SacreBLEU presented ambiguities, especially when juxtaposed with the results from the trained reward models. This disparity, brought into sharper focus by near-zero Spearman correlations, implies that traditional metrics might not suffice for complex fields such as programming. These domains are marked by intricate semantic relationships and a broad spectrum of valid answers.nan",Reinforcement learning for question answering in programming domain using public community scoring as a human feedback,"Alexey Gorbatovski, Sergey Kovalchuk","Reinforcement learning for question answering in programming domain
using public community scoring as a human feedback
Alexey Gorbatovski
ITMO University
Saint Petersburg, Russia
gorbatoski@itmo.ru
Sergey Kovalchuk
Huawei
Saint Petersburg, Russia
sergey.kovalchuk@huawei.com
Abstract
In this study, we investigate the enhancement of
the GPT Neo 125M’s performance in Commu-
nity Question Answering (CQA) with a focus
on programming, through the integration of Re-
inforcement Learning from Human Feedback
(RLHF) and the utilization of scores from Stack
Overflow. Two distinct reward model training
strategies are employed for fine-tuning with
Proximal Policy Optimization (PPO). Notably,
the improvements in performance achieved
through this method are comparable to those of
GPT Neo’s 2.7B parameter variant. Addition-
ally, an auxiliary scoring mechanism is intro-
duced, which demonstrates the limitations of
conventional linguistic metrics in evaluating re-
sponses in the programming domain. Through
accurate analysis, this paper looks at the di-
vergence between traditional linguistic met-
rics and our human-preferences-based reward
model, underscoring the imperative for domain-
specific evaluation methods. By elucidating
the complexities involved in applying RLHF to
programming CQA and accentuating the signif-
icance of context-aware evaluation, this study
contributes to the ongoing efforts in refining
Large Language Models through focused hu-
man feedback.
1
Introduction
Advances in Reinforcement Learning from Hu-
man Feedback (RLHF) have revolutionized the
fine-tuning of Large Language Models (LLMs),
facilitating adaptation for human-like response gen-
eration and precise behavior control (Ouyang et al.,
2022). While RLHF has proven effective in gen-
eral domains, its application in specialized fields
such as Community Question Answering (CQA)
for programming remains unexplored (Beeching
et al., 2023). LLMs face unique challenges in han-
dling the complex nature of programming queries,
including conceptual understanding, code genera-
tion, API usage, and debugging, due to struggles
with subtle semantic relations.
Furthermore, a critical challenge is the evalua-
tion of the quality of responses generated by LLMs.
Conventional metrics such as BertScore and Rouge
do not capture the essence of responses effectively,
especially in specialized domains like program-
ming (Wang et al., 2019). Moreover, they don’t ac-
count for the diversity in valid answers and lack in
capturing deeper semantic correctness. The devel-
opment of more reliable and context-sensitive eval-
uation metrics is essential(Kovalchuk et al., 2022).
To address these challenges, in this paper, we
investigate the application of RLHF to a smaller
model, GPT Neo 125M (Black et al., 2021a), in the
context of programming CQA. We aim not only to
enhance the model’s response generation capabil-
ities but also to address the evaluation challenge.
Our contributions are two-fold. First, we explore
the potential and efficacy of RLHF in retraining
a smaller LLM for programming CQA. Second,
through empirical analysis, we highlight the dis-
crepancies between the RLHF reward model and
existing linguistic metrics, emphasizing the limita-
tions of current evaluation methodologies and ad-
vocating for the development of more semantically-
sensitive measures.
The structure of the paper is as follows: Section
2 provides background information and describes
the datasets used in this study. In Section 3, we
delve into the application of RLHF for program-
ming CQA, explaining the data preparing method-
ologies employed. Section 4 focuses on the experi-
mental evaluation and results. Section 5 presents a
discussion of the study results and evaluation meth-
ods. Finally, Section 6 concludes the paper with
final remarks and reflections on our findings.
2
Background and Dataset
2.1
Background on RLHF and LLMs
Reinforcement Learning from Human Feedback
(RLHF) is a technique where models are trained us-
arXiv:2401.10882v1  [cs.CL]  19 Jan 2024
ing human feedback as rewards. This method has
become notably beneficial in refining the perfor-
mance and behavior control of Large Language
Models (LLMs).
RLHF initiates with models
trained using supervised fine-tuning (SFT), which
are then iteratively improved. Crucially, the hu-
man scoring process in RLHF is often automated
by training a separate reward model, serving as an
optimization proxy. This process varies in imple-
mentation and warrants further exploration.
The application of RLHF in LLMs has been ex-
plored in various contexts. For instance, Ziegler
et al. (2019) studied the impact of reward learn-
ing on specific tasks, demonstrating the potential
of RLHF in enhancing the performance of LLMs.
The work of Stiennon et al. (2020) and the Ope-
nAI Alignment Team in 2021 further expanded the
scope of RLHF, applying it to the task of summa-
rizing text and books, respectively.
In the context of Question Answering (QA),
RLHF has been used to train models to navigate
the web (Nakano et al., 2021) and to follow instruc-
tions (Ouyang et al., 2022). However, these studies
have mainly focused on general domains or specific
tasks, and the application of RLHF in specialized
fields such as programming Community Question
Answering (CQA) remains largely unexplored.
2.2
Dataset Selection and Preprocessing
In the study, we used Stack Overflow1 (SO) as
the primary data source for programming-related
question-answering tasks. We regarded the answers
on SO as reference solutions. We compiled the
dataset from the original data available on Stack Ex-
change2, focusing on questions specifically tagged
with ’python’. This dataset, which includes titles,
questions, answers per question, and user scores
for each, was used for both supervised fine-tuning
and partial reward model training. To ensure the
dataset’s relevance and homogeneity, we subjected
it to a series of constraints and transformations.
Furthermore, we adjusted user ratings for different
reward model training setups.
We applied several constraints to refine the
dataset and maintain consistency:
• We only selected questions classified as “API
Usage” according to the taxonomy by Beyer
et al. (2020). This selection was performed
1https://stackoverflow.com/
2https://stackexchange.com/
using regular expressions to ensure alignment
with the study’s focus.
• To maintain text purity and the ability to gen-
erate a response based on the context only, we
filtered out questions and answers containing
images, links, or code blocks, designated by
the <pre><code> HTML tags. Code blocks
were filtered out to prevent the model from
generating code snippets during training, as
this would significantly complicate the eval-
uation process due to the lack of established
metrics for assessing the quality of generated
code.
• HTML content was sanitized and converted
to plain text using the Beautiful Soup3 library
to prepare it for natural language processing.
We obtained a dataset of 6,946 training entries
and 1,000 validation entries. To prevent data leak-
age and ensure temporal relevance, the validation
set included questions posted after December 14,
2021.
While this dataset is highly relevant for studying
RLHF in programming CQA, it is worth noting
that the constraints applied may introduce certain
limitations in terms of the diversity of questions
and real-world applicability.
3
RLHF for programming Q&A
The general schema of RLHF utilized in this study
consists of several stages, as depicted in Fig. 1.
The process commences with the training of an ini-
tial policy via supervised learning. Subsequently,
a reward model is trained to acquire human pref-
erences from the labeled data. Finally, the policy
is fine-tuned using Proximal Policy Optimization
(PPO) (Schulman et al., 2017), guided by the re-
ward model.
In this study, we have adapted RLHF for pro-
gramming Q&A by converting user ratings from
Stack Overflow into feedback for training our
model. We used two distinct approaches: creat-
ing regression scores and contrastive scores for the
straightforward comparison of answers. Addition-
ally, to enhance the logical alignment of sentences
and mitigate the model’s errors in generation, we
completed the dataset for reward model training
with generations from the SFT model.
3https://github.com/wention/BeautifulSoup4
Figure 1: The general schema of Reinforcement Learning from Human Feedback for programming Q&A
3.1
Transformation of User Ratings
To account for biases arising from factors like the
question’s age and popularity, we preprocess and
normalize user ratings. Our approach comprises
two distinct transformations: Regression Scores
and Contrastive Scores.
Algorithm 1 Regression scores transforming
Input: user votes for each answer N_votesij
Output: regression scores sij
1: for each question qi do
2:
for each answer aj in qi do
3:
sij =
N_votesij
N_answersi
4:
end for
5: end for
6: l_bound, u_bound = 1.5 × IQR(sij)
7: for each score sij do
8:
if sij outside the range [l_bound, u_bound]
then
9:
sij = clip(sij, −1, 1)
10:
else
11:
sij = max_abs_scale(sij, sign(sij))
12:
end if
13: end for
14: return sij for all i, j
3.1.1
Regression Scores
For regression scores, user ratings were normalized
by the total number of answers for each question.
After clipping outliers, the ratings were scaled to
control the standard deviation, thus stabilizing the
regression training. The process is outlined in Al-
gorithm 1. There vij represents the votes for each
answer aj in question qi and sij for the regression
scores.
3.1.2
Contrastive Scores
Contrastive scores allow a convenient comparison
of answer ratings by mapping them to logarithmi-
cally scaled scores (Askell et al., 2021). Accepted
answers receive an additional increment, while neg-
ative ratings are assigned a standard value. The
following Algorithm 2 details this process:
In this algorithm, vj denotes the votes for each
answer, and the contrastive scores, sj, are com-
puted using a logarithmic scale.
Additionally, we first identified questions with
more than one answer after preprocessing and fil-
tering, which amounted to 3,076. We compared
each of these answers with the highest-voted an-
swer for each question during the training of the
reward model. After this comparison, the contrast
dataset contained 1,804 rows.
3.2
Data Generation for Reward Model
Training
We generated 6,872 additional answers for ques-
tions with only one answer to create a comparison
set essential for training the reward model. This
step was undertaken to ensure a diverse dataset that
simulates various answer qualities.
For the regression approach, we assigned
Algorithm 2 Contrastive scores scaling
Input: votes for each answer vj
Output: contrastive scores sij
1: for each answer aj do
2:
if vj < 0 then
3:
sj = −1
4:
else
5:
sj = ⌈log2(1 + vj)⌉
6:
if aj is accepted then
7:
sj = sj + 1
8:
end if
9:
end if
10: end for
11: for each question qi do
12:
if N_answersi > 1 then
13:
smax = max(sij) for all j
14:
for each answer ak in qi do
15:
compare score sk with smax
16:
end for
17:
end if
18: end for
19: return compared pairs {(aj, ak)}
these generated answers a normal distribution
N(−0.5, 0.12). This was based on the observation
that most generated answers were either completely
uninformative or erroneous. We believe that dis-
couraging the generation of nonsensical answers is
a helpful practice.
In the contrastive approach, these generated an-
swers were incorporated into the contrast dataset,
which previously only included questions with
more than one existing answer.
The generation of this additional data was cru-
cial for robustly training the reward model. In the
experimental section, we will delve into how this
dataset was leveraged to train the reward model ef-
fectively, and the evaluation metrics used to assess
its performance.
4
Experimental evaluation
This section aims to evaluate the effectiveness of
the RLHF training approach for improving the
quality of generated responses in the programming
QA domain. Specifically, we compare three ver-
sions of the model, according to Fig. 1 - the base
model, the SFT version, and the RLHF version.
The evaluation focuses on the performance of the
reward model training methods and the generated
responses’ quality.
4.1
Evaluation approach
Fig. 2 illustrates the evaluation schema. For each
question in the validation dataset, the model gener-
ates ten responses using sampling-based decoding.
This approach allows us to study the average qual-
ity of the generated responses without bias toward
the worst or best cases. The parameters used for
sampling-based decoding are as follows:
• do_sample: true
• no_repeat_ngram_size: 2
• top_k: 50
• top_p: 0.9
To evaluate the responses’ content and seman-
tic similarity, we employ the SacreBLEU, Rouge,
and BertScore metrics as common metrics for nat-
ural language generation tasks. Additionally, the
reward models rate each generated response as an
alternative quality assessment tool.
For a more insightful evaluation, we also con-
duct a human-based assessment. A subset of 100
randomly selected questions is manually evaluated
by ourselves. Each generated answer for these
questions is inspected and marked as useful (1) or
not useful (0) for solving the problem stated in the
question. This binary labeling enables the compu-
tation of the Mean Reciprocal Rank (MRR), which
assesses the relevance of the generated responses.
Finally, to investigate the consistency between
the different metrics and reward model assess-
ments, we employ Spearman’s rank correlation
coefficient. This statistical measure will provide
insight into whether the automatic metrics and the
reward model assessments are aligned in evaluating
response quality.
4.2
Experimental setup
All experiments were conducted using the GPT
Neo model (Black et al., 2021b) with 125 million
parameters, selected based on the constraints dis-
cussed in the corresponding section.
4.2.1
Supervised fine-tuning
Fine-tuning was performed on the training dataset
described in Section 2.2. We utilized the Trans-
formers and PyTorch Lightning libraries with the
following hyperparameters: optimizer = Adam,
Adam betas = (0.9, 0.999), Adam epsilon = 1e-
08, weight decay = 0.001, learning rate = 2e-05,
Figure 2: The general schema of evaluation approach
learning rate decay scheme = linear, batch size = 12,
and mixed precision training (fp16). The maximum
length of the concatenated question and answer was
set to 512 tokens. If the input sequence exceeded
this length, the question was truncated, ensuring
that the full answer was available for training.
4.2.2
Reward Model Training
We trained the reward model using two approaches:
regression and answer comparison. The regres-
sion approach employed the Mean Squared Error
(MSE) as the loss function, while the answer com-
parison approach used the Contrastive Loss (see
Formula 1).
L(θ) = −E(x,yj,yk)∼D[log(σ(rθ(x, yj)−rθ(x, yk)))] (1)
where r and y are the reward model’s score and
y is the preferred candidate respectively. Both ap-
proaches used the SFT model as the basis.
For the regression approach, the hyperparame-
ters were as follows: optimizer = Adam, Adam
betas = (0.9, 0.999), Adam epsilon = 1e-08, weight
decay = 0.001, learning rate = 2e-05, learning rate
decay scheme = linear, batch size = 16, and mixed
precision training (fp16).
For the contrastive approach, we used the same
hyperparameters with a different learning rate (3e-
05) and batch size (8). Additionally, for both ap-
proaches, the weights of the first and last layers, as
well as all linear layers of the model, were updated
during training.
Both approaches exhibited stability during train-
ing, achieving validation accuracies of 93% and
95% respectively. For the regression approach, ac-
curacy was computed using the formula:
accuracy = 1
n
X
[sign(ri) = yi]
(2)
where ri and yi mean ith reward and target score re-
spectively. Considering both positive and negative
rewards is essential in reinforcement learning.
4.2.3
Fine-tuning with RL
We employed reinforcement learning using the
TRL and Transformers libraries, with typical RLHF
parameters: optimizer = Adam, Adam betas = (0.9,
0.95), Adam epsilon = 1e-08, learning rate = 1.41e-
05, epsilon clip range = 0.2, buffer size = 64, and
batch size = 16. Additionally, we used adaptive KL
control with an initial KL coefficient of 0.2 and a
target of 6.
During reinforcement learning, the training was
stable, and the average reward increased when us-
ing the reward model based on the regression ap-
proach. However, training was unstable and did not
converge using the reward model based on answer
comparisons. Tuning model starts generate repet-
itive words and incoherent sentences. Therefore,
the results section presents the outcomes for the
model trained using the regression-based reward
model.
4.3
Results
This section presents the results of the experiments,
which were conducted to assess the efficacy of the
RLHF training approach in the context of program-
ming QA response generation. We examine the
performance of the different models and discuss
the correlation and consistency between the metrics
employed for evaluating the quality of the gener-
ated responses.
4.3.1
Comparison of Average Metrics
Our evaluation process involved computing the av-
erage metrics for ten generation attempts by four
models: Base GPT Neo 125M (Base 125M), Su-
pervised Fine-tuning GPT Neo 125M (SFT 125M),
RLHF GPT Neo 125M (RLHF 125M), and Base
SacreBLEU
Rouge 1
Rouge 2
BertScore Reg. Reward Contr. Reward
Base 125M
0.0433
0.1816
0.0233
0.9420
-0.1479
-1.0124
(σ : 0.0071)
(σ : 0.0684)
(σ : 0.0160)
(σ : 0.0057)
(σ : 0.0994)
(σ : 1.0214)
SFT 125M
0.0484
0.1903
0.0237
0.9483
0.1257
-0.0173
(σ : 0.0088)
(σ : 0.0581)
(σ : 0.0151)
(σ : 0.0097)
(σ : 0.0864)
(σ : 1.0123)
RLHF 125M
0.0489
0.1884
0.0230
0.9493
0.1869
0.3955
(σ : 0.0092)
(σ : 0.0545)
(σ : 0.0149)
(σ : 0.0105)
(σ : 0.0767)
(σ : 0.9720)
Base 2.7B
0.0455
0.1906
0.0275
0.9417
-0.1123
-0.0365
(σ : 0.0073)
(σ : 0.0735)
(σ : 0.0190)
(σ : 0.0054)
(σ : 0.1045)
(σ : 1.1245)
Table 1: Comparison of average metrics for different models. Each entry contains the mean of the corresponding
metric across ten generation attempts.
GPT Neo 2.7B (Base 2.7B). These models evalu-
ated using several metrics, including SacreBLEU,
Rouge 1, Rouge 2 and BertScore, as well as the
scores obtained from the regression and contrastive
reward models.
Table 1 presents the average values of these
metrics for each model. Notably, the RLHF ver-
sion demonstrated superior performance compared
to the SFT model in terms of SacreBLEU and
BertScore. However, the larger Base GPT Neo
2.7B model surpassed the other models in terms
of the Rouge scores. All highlighted metrics were
deemed statistically significant via the KS-test. The
inclusion of bootstrapped confidence intervals fur-
ther clarifies the model’s improvement relative to
the baseline.
4.4
Metrics at Rank k Analysis
Beyond the mean values, we performed an in-
depth analysis using the metric@k approach. The
term “metric at rank k” refers to the highest score
achieved by a metric among k randomly sampled
generation attempts.
This analysis helps to re-
veal the capability of the models to generate high-
quality responses within a certain number of at-
tempts.
Fig. 3 illustrates graphs depicting the relation-
ship between the metric values and the number of
generation attempts (k). These graphs provide in-
sights into the performance of the models as the
number of generation attempts increases. Partic-
ularly, after several generation attempts, both the
SFT and RLHF versions appear to outperform the
larger GPT Neo 2.7B model in terms of the eval-
uated metrics. Additionally, the RLHF model ex-
hibits significant improvement in BertScore, which
suggests enhanced semantic similarity between the
generated and reference responses.
Table 2 presents the results for Metrics@10,
which indicates the best metric scores among 10
generation attempts. Most of the highlighted values
have been determined to be statistically significant
as per the U-test and KS-test. Interestingly, Base
GPT Neo 2.7B exhibits the highest average model
reward based on the contrastive approach. This
might suggest that the model’s responses are more
diverse and, in some cases, closer to the reference
answers.
The Rouge 2 metric, which focuses on the over-
lap of bigrams between the generated and refer-
ence texts, presents a close competition among the
models. This implies that the inclusion of both con-
tent words and their ordering are well-represented
across models.
4.5
MRR Comparison
An additional analysis conducted to assess the
consistency between reward models and metrics
used for evaluating the quality of the generated re-
sponses. This analysis involved the utilization of
manual annotations for answers corresponding to
100 random questions.
In this analysis, MRR calculated for varying val-
ues of k, where k denotes the top-ranked answers
accordingly to some metric. The Mean Reciprocal
Rank at k (MRR@k) is a statistical measure for
evaluating any process that produces a list of pos-
sible responses to a sample of queries, ordered by
probability of correctness. If we have A answers,
and Ri is the rank of the first relevant document
for query i (considering only the top k documents),
then the MRR@k is:
MRR@k = 1
A
A
X
i=1
 1
Ri

if Ri ≤ k; else 0
(3)
This method allows for understanding how effec-
SacreBLEU Rouge 1 Rouge 2 BertScore Reg. Reward Contr. Reward
Base 125M
0.0724
0.2623
0.0549
0.9517
0.2746
2.6521
SFT 125M
0.0875
0.2897
0.0614
0.9578
0.3754
2.8612
RLHF 125M
0.0901
0.2903
0.0625
0.9586
0.3711
2.8187
Base 2.7B
0.0744
0.2704
0.0607
0.9513
0.3201
3.6581
Table 2: Comparison of average metrics@10 for different models.
Figure 3: Graphs of dependencies of metric values on the number of k attempts to generate
tively the different metrics rank the correct answers
among its top predictions.
Table 3 presents the MRR@10 scores, indicat-
ing the MRR values when considering the top 10
ranked samples. Notably, Rouge 2 and Rouge 1
metrics exhibit higher values, which implies that
they are key metrics in assessing the accuracy of the
generated responses. However, the trained reward
models display superior performance compared to
both the SacreBLEU and BertScore metrics.
4.6
Correlation Analysis
In addition to the previous evaluations, a corre-
lation analysis carried out among the assessment
methods utilized. Specifically, the Spearman cor-
relation coefficient was computed to understand
the relationships between the various metrics. The
Spearman correlation coefficient is a nonparametric
measure that evaluates the strength and direction
of the association between two ranked variables.
Appendix A contains tables that compare the
cross-correlation coefficients of the metrics for
each model generations.
Upon examination, a
prominent correlation between the rankings of
Rouge 1 and Rouge 2 is evident. Furthermore,
the reward regression model exhibits a moderate
correlation when responses are generated by the
fine-tuned models. Interestingly, BertScore demon-
strates little to no correlation, or even a negative
correlation, with the other metrics. This raises ques-
tions about its reliability as a comparative measure
in this context. Additionally, it is notable that the re-
ward models display minimal correlation amongst
themselves, when trained through different method-
ologies.
5
Discussion
The study focused on the generating QA highlights
the effective implementation of the RLHF in the in-
tricate domain. This method outperforms SFT tech-
nique, marking its superiority in terms of metrics
performance. Moreover, the application of RLHF
has demonstrated that it’s possible to competitively
train smaller models, showcasing its efficacy even
in scenarios with limited resources.
Regarding the scoring parameters, the study
draws attention to the utility of Rouge scores in
gauging response precision. This implies a poten-
Base 125M SFT 125M RLHF 125M
SacreBLEU
0.4107
0.3709
0.3262
Rouge 1
0.4792
0.4532
0.4091
Rouge 2
0.4011
0.4453
0.4220
BertScore
0.2913
0.3403
0.3300
Reg. Reward
0.4015
0.3867
0.4296
Contr. Reward
0.4302
0.3787
0.3527
Table 3: Comparison of MRR@10 scores for different models and metrics. The values represent the MRR scores
considering the top 10 ranked samples.
tial edge of Rouge over alternative scoring systems
like SacreBLEU and BertScore in certain contexts.
However, there exists ambiguity in the MRR re-
sults for BertScore and SacreBLEU metrics when
juxtaposed with the outcomes from the trained re-
ward models. This raises questions about the ad-
equacy of these metrics for the programming do-
main, which is hallmarked by complex semantic re-
lationships and a plethora of correct answers. This
ambiguity is further cemented by near-zero Spear-
man correlations associated with various linguistic
metrics.
These findings not only provide a deeper under-
standing of RLHF’s potential and boundaries but
also emphasize the necessity for diverse, domain-
specific methods when evaluating generation qual-
ity. In this context, the programming domain serves
as an exemplar. This research’s insights could stim-
ulate further advancements in the development of
novel and more suitable metrics for similar com-
plex domains.
6
Conclusion
In conclusion, our study has demonstrated the
effectiveness of RLHF in enhancing the perfor-
mance of small LLMs like GPT Neo 125M in the
programming domain. Our experiments focused
on fine-tuning the model using user-generated re-
sponses from Stack Overflow, employing two re-
ward model training strategies, regression scores
and contrastive scores, with PPO.
The study also highlights the critical role of
employing the right evaluation measures. While
Rouge scores effectively captured response accu-
racy, other metrics like BertScore and SacreBLEU
presented ambiguities, especially when juxtaposed
with the results from the trained reward models.
This disparity, brought into sharper focus by near-
zero Spearman correlations, implies that traditional
metrics might not suffice for complex fields such
as programming. These domains are marked by in-
tricate semantic relationships and a broad spectrum
of valid answers.
As we look to the future, we envision testing
our methodologies and experiment setups on larger
models to assess the scalability of our approach and
verify the consistency of our results. We anticipate
that these further investigations would provide valu-
able insights into the behavior and performance of
these larger models under RLHF based fine-tuning,
thereby expanding the scope of our current study.
The insights derived from our research enrich
our understanding of both the potential and the
limitations of RLHF. They also underline the ne-
cessity for tailored evaluation methods in complex
domains. As we persist in honing and formulating
innovative techniques for efficient generation, the
lessons gleaned from our work will undoubtedly
prove invaluable.
Limitations
In this study, we attempted to investigate the appli-
cation of the GPT Neo model with 125M parame-
ters in assessing the quality of linguistic metrics in
the Usage API subcategory of question-and-answer
data. We acknowledge several limitations that need
to be taken into account when interpreting the re-
sults.
First, the data used in the experiments is domain-
specific, sourced exclusively from the Usage API
subcategory, which lacks code blocks. Although
our findings demonstrate discrepancies between
linguistic metrics within this chosen domain, their
generalizability to other question-and-answer cat-
egories remains unclear. It’s possible that our re-
ward model may perform differently when applied
to more diverse datasets with varied question types
and content, including those that incorporate code
blocks.
Second, the application of the small GPT Neo
model with 125M parameters represents a signif-
icant limitation in terms of both computational
capacity and the model’s semantic understanding.
The constraints of our computing resources, specif-
ically the usage of 2 Nvidia A6000 GPUs and the
necessity to accommodate three models during the
RLHF training, have imposed certain restrictions.
Owing to VRAM limitations, portions of the ques-
tion context were omitted during training, poten-
tially undermining the model’s ability to fully grasp
the semantic relations in the language.
Another caveat concerns the scale of the model.
While our experiments illustrated the small model’s
ability to enhance results to levels comparable to
its larger counterparts, the behavior of the larger
models under similar experimental conditions is yet
to be understood. This question remains open and
warrants further investigation in future research.
In summary, our study provides valuable insights
into the use of smaller GPT Neo models for assess-
ing linguistic metrics, but the highlighted limita-
tions underscore the need for additional research in
broader data contexts, with larger models, and con-
sidering the intricate facets of language translation
and reformulation.
References
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain,
Deep Ganguli, Tom Henighan, Andy Jones, Nicholas
Joseph, Ben Mann, Nova DasSarma, et al. 2021. A
general language assistant as a laboratory for align-
ment. arXiv preprint arXiv:2112.00861.
Edward Beeching, Younes Belkada, Kashif Rasul,
Lewis Tunstall, Leandro von Werra, Nazneen Ra-
jani, and Nathan Lambert. 2023. Stackllama: An rl
fine-tuned llama model for stack exchange question
and answering.
Stefanie
Beyer,
Christian
Macho,
Massimiliano
Di Penta, and Martin Pinzger. 2020.
What kind
of questions do developers ask on stack overflow?
a comparison of automated approaches to classify
posts into question categories. Empirical Software
Engineering, 25:2258–2301.
Sid Black, Leo Gao, Phil Wang, Connor Leahy, and
Stella Biderman. 2021a. Gpt-neo: Large scale autore-
gressive language modeling with mesh-tensorflow. If
you use this software, please cite it using these meta-
data, 58.
Sid Black, Leo Gao, Phil Wang, Connor Leahy,
and Stella Biderman. 2021b.
GPT-Neo: Large
Scale Autoregressive Language Modeling with Mesh-
Tensorflow. If you use this software, please cite it
using these metadata.
Sergey V. Kovalchuk, Vadim Lomshakov, and Artem
Aliev. 2022. Human perceiving behavior modeling
in evaluation of code generation models. In Pro-
ceedings of the 2nd Workshop on Natural Language
Generation, Evaluation, and Metrics (GEM), pages
287–294, Abu Dhabi, United Arab Emirates (Hybrid).
Association for Computational Linguistics.
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
Long Ouyang, Christina Kim, Christopher Hesse,
Shantanu Jain, Vineet Kosaraju, William Saunders,
et al. 2021.
Webgpt: Browser-assisted question-
answering with human feedback.
arXiv preprint
arXiv:2112.09332.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,
Carroll Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
2022. Training language models to follow instruc-
tions with human feedback.
Advances in Neural
Information Processing Systems, 35:27730–27744.
John Schulman, Filip Wolski, Prafulla Dhariwal,
Alec Radford, and Oleg Klimov. 2017.
Proxi-
mal policy optimization algorithms. arXiv preprint
arXiv:1707.06347.
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
Dario Amodei, and Paul F Christiano. 2020. Learn-
ing to summarize with human feedback. Advances
in Neural Information Processing Systems, 33:3008–
3021.
Qicai Wang, Peiyu Liu, Zhenfang Zhu, Hongxia Yin,
Qiuyue Zhang, and Lindong Zhang. 2019. A text ab-
straction summary model based on bert word embed-
ding and reinforcement learning. Applied Sciences,
9(21):4701.
Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B
Brown, Alec Radford, Dario Amodei, Paul Chris-
tiano, and Geoffrey Irving. 2019. Fine-tuning lan-
guage models from human preferences.
arXiv
preprint arXiv:1909.08593.
A
Spearman correlation tables
In this appendix, we present figs. A1 to A3 that fea-
ture comparative tables of Spearman’s correlation
coefficients for several evaluation metrics: Rouge
1, Rouge 2, SacreBLEU, and BertScore and used
two variations of reward models, the regressive and
contrastive. They based on the generations pro-
duced by three distinct models. These models are
the Base GPT Neo 125M, the SFT GPT Neo 125M,
and the RLHF GPT Neo 125M, respectively.
Figure A1: Spearman correlation coefficients for Base
model
Figure A2: Spearman correlation coefficients for SFT
model
Figure A3: Spearman correlation coefficients for RLHF
model
"
